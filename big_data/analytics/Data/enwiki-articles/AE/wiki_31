<doc id="26311" url="https://en.wikipedia.org/wiki?curid=26311" title="Rudyard Kipling bibliography">
Rudyard Kipling bibliography

This is a bibliography of works by Rudyard Kipling, including books, short stories, poems, and collections of his works.
Collections.
Some of Kipling's works were collected by him; some others were collected by publishers of "unauthorised" editions ("Abaft the Funnel", "From Sea to Sea", for example). Still others of his works were never collected. The lists given below include all the collections that Kipling acknowledged as his own work. However, it is possible to find other works that appeared in American but not English editions, works that only appeared in an original periodical publication, and some others that only appeared in the Sussex and Burwash editions.
A selection of the most complete collected sets.
The last two of these editions include volume(s) of "uncollected prose".
Poems.
His own collections.
Collections issued during his lifetime by the poet himself include:
Posthumous collections.
Posthumous collections of Rudyard Kipling's poems include:
Individual poems.
Some of Kipling's many poems are:

</doc>
<doc id="26313" url="https://en.wikipedia.org/wiki?curid=26313" title="Roget's Thesaurus">
Roget's Thesaurus

"Roget's Thesaurus" is a widely used English-language thesaurus, created in 1805 by Peter Mark Roget (1779–1869), British physician, natural theologian and lexicographer. It was released to the public on 29 April 1852. The original edition had 15,000 words, and each new edition has been larger. The Karpeles Manuscript Library Museum houses the original manuscript in its collection.
The name "Roget" is trademarked in parts of the world, such as the United Kingdom. By itself, it is not protected in the United States, where use of the name "Roget" in the title of a thesaurus does not necessarily indicate any relationship to Roget directly; it has come to be seen as a generic thesaurus name.
Roget described his thesaurus in the foreword to the first edition:
It is now nearly fifty years since I first projected a system of verbal classification similar to that on which the present work is founded. Conceiving that such a compilation might help to supply my own deficiencies, I had, in the year 1805, completed a classed catalogue of words on a small scale, but on the same principle, and nearly in the same form, as the Thesaurus now published.
"Roget's Thesaurus" is composed of six primary classes. Each class is composed of multiple divisions and then sections. This may be conceptualized as a tree containing over a thousand branches for individual "meaning clusters" or semantically linked words. Although these words are not strictly synonyms, they can be viewed as colours or connotations of a meaning or as a spectrum of a concept. One of the most general words is chosen to typify the spectrum as its headword, which labels the whole group.
Roget's schema of classes and their subdivisions is based on the philosophical work of Leibniz (see Leibniz—Symbolic thought), itself following a long tradition of epistemological work starting with Aristotle. Some of Aristotle's Categories are included in Roget's first class "abstract relations".
External links.
__NOTOC__

</doc>
<doc id="26316" url="https://en.wikipedia.org/wiki?curid=26316" title="Racial segregation">
Racial segregation

Segregation is the separation of humans into ethnic or racial groups in daily life. It may apply to activities such as eating in a restaurant, drinking from a water fountain, using a public toilet, attending school, going to the movies, riding on a bus, or in the rental or purchase of a home. Segregation itself is defined by the European Commission against Racism and Intolerance as "the act by which a (natural or legal) person separates other persons on the basis of one of the enumerated grounds without an objective and reasonable justification, in conformity with the proposed definition of discrimination. As a result, the voluntary act of separating oneself from other persons on the basis of one of the enumerated grounds does not constitute segregation". According to the UN Forum on Minority Issues, "The creation and development of classes and schools providing education in minority languages should not be considered impermissible segregation, if the assignment to such classes and schools is of a voluntary nature".
Racial segregation is generally outlawed, but may exist "de facto" through social norms, even when there is no strong individual preference for it, as suggested by Thomas Schelling's models of segregation and subsequent work. Segregation may be maintained by means ranging from discrimination in hiring and in the rental and sale of housing to certain races to vigilante violence (such as lynchings). Generally, a situation that arises when members of different races mutually prefer to associate and do business with members of their own race would usually be described as "separation" or "de facto separation" of the races rather than "segregation". In the United States, legal segregation was required in some states and came with anti-miscegenation laws (prohibitions against interracial marriage). Segregation, however, often allowed close contact in hierarchical situations, such as allowing a person of one race to work as a servant for a member of another race. Segregation can involve spatial separation of the races, and mandatory use of different institutions, such as schools and hospitals by people of different races.
Historical cases.
Wherever there have been multiracial communities, there has been racial segregation. Only areas with extensive miscegenation, or mixing, such as Hawaii and Brazil, despite some social stratification, seem to be exempt.
Anglo-Saxons in England.
Segregation may have existed in early Anglo-Saxon England, restricting intermarriage and resulting in the displacement of the native British population by Germanic incomers. According to research led by the University College London, Anglo-Saxon settlers enjoyed substantial social and economic advantages over Celtic Britons. However, Stephen Oppenheimer and Bryan Sykes argue that there was no population displacement, as the Anglo-Saxons had relatively little genetic impact on England. In 2002, the BBC used the headline "English and Welsh are races apart" to report a genetic survey of test subjects from market towns in England and Wales.
English settlers in Ireland.
The Statutes of Kilkenny were a series of thirty-five acts passed at Kilkenny in 1366. They forbade the intermarriage between the native Irish and the English settlers in Ireland, the English fostering of Irish children, the English adoption of Irish children and use of Irish names and dress.
French Algeria.
Following its conquest of Ottoman controlled Algeria in 1830, for well over a century France maintained colonial rule in the territory which has been described as "quasi-apartheid". The colonial law of 1865 allowed Arab and Berber Algerians to apply for French citizenship only if they abandoned their Muslim identity; Azzedine Haddour argues that this established "the formal structures of a political apartheid". Camille Bonora-Waisman writes that, "[in contrast with the Moroccan and Tunisian protectorates", this "colonial apartheid society" was unique to Algeria.
This "internal system of apartheid" met with considerable resistance from the Muslims affected by it, and is cited as one of the causes of the 1954 insurrection.
Germany.
In fifteenth-century north-east Germany, people of Wendish, i.e. Slavic, origin were not allowed to join some guilds. According to Wilhelm Raabe, "down into the eighteenth century no German guild accepted a Wend."
The ban on interracial marriage was a part of the Nuremberg Laws, which prohibited sexual relations and marriages between people classified as "Aryan" and "non-Aryan." Such relationships were called "Rassenschande" (race defilement). At first the laws were aimed primarily at Jews but were later extended to "Gypsies, Negroes and their bastard offspring". Aryans found guilty could face incarceration in a concentration camp, while non-Aryans could face the death penalty. To preserve the so-called purity of the German blood, after the war began, the Nazis extended the race defilement law to include all foreigners (non-Germans).
Under the General Government of occupied Poland in 1940, the Nazis divided the population into different groups, each with different rights, food rations, allowed housing strips in the cities, public transportation, etc. In an effort to split Polish identity they attempted to establish ethnic divisions of Kashubians and Gorals (Goralenvolk), based on these groups' alleged "Germanic component."
During the 1930s and 1940s, Jews in Nazi-controlled states were made to wear yellow ribbons or stars of David, and were, along with Romas (Gypsies), discriminated against by the racial laws. Jewish doctors were not allowed to treat Aryan patients nor were Jewish professors permitted to teach Aryan pupils. In addition, Jews were not allowed to use any public transportation, besides the ferry, and were able to shop only from 3–5 pm in Jewish stores. After "Kristallnacht" ("The Night of Broken Glass"), the Jews were fined 1,000,000 marks for damages done by the Nazi troops and SS members.
Jews and Roma were subjected to genocide as "undesirable" racial groups in the Holocaust. The Nazis established ghettos to confine Jews and sometimes Romas into tightly packed areas of the cities of Eastern Europe, turning them into "de facto" concentration camps. The Warsaw Ghetto was the largest of these ghettos, with 400,000 people. The Łódź Ghetto was the second largest, holding about 160,000.
Between 1939 and 1945, at least 1.5 million Polish citizens were transported to the Reich for forced labour (in all, about 12 million forced laborers were employed in the German war economy inside Nazi Germany). Although Nazi Germany also used forced laborers from Western Europe, Poles, along with other Eastern Europeans viewed as racially inferior, were subject to deeper discriminatory measures. They were forced to wear a yellow with purple border and letter "P" (for Polen/Polish) cloth identifying tag sewn to their clothing, subjected to a curfew, and banned from public transportation.
While the treatment of factory workers or farm hands often varied depending on the individual employer, Polish laborers as a rule were compelled to work longer hours for lower wages than Western Europeans – in many cities, they were forced to live in segregated barracks behind barbed wire. Social relations with Germans outside work were forbidden, and sexual relations ("Rassenschande" or "racial defilement") were punishable by death.
Imperial China.
Tang dynasty.
Several laws enforcing racial segregation of foreigners from Chinese were passed by the Han chinese during the Tang dynasty. In 779 the Tang dynasty issued an edict which forced Uighurs to wear their ethnic dress, stopped them from marrying Chinese females, and banned them from pretending to be Chinese. Chinese disliked Uighurs because they practiced usury. The magristrate who issued the orders may have wanted to protect "purity" in Chinese custom. In 836, when Lu Chun was appointed as governor of Canton, he was disgusted to find Chinese living with foreigners and intermarriage between Chinese and foreigners. Lu enforced separation, banning interracial marriages, and made it illegal for foreigners to own property. Lu Chun believed his principles were just and upright. The 836 law specifically banned Chinese from forming relationships with "Dark peoples" or "People of colour", which was used to describe foreigners, such as "Iranians, Sogdians, Arabs, Indians, Malays, Sumatrans", among others.
Qing dynasty.
The Qing Dynasty was founded not by the Han Chinese who form the majority of the Chinese population, but the Manchus, who are today an ethnic minority of China. The Manchus were keenly aware of their minority status, however, it was only later in the dynasty that they banned intermarriage.
Han defectors played a massive role in the Qing conquest of China. Han Chinese Generals who defected to the Manchu were often given women from the Imperial Aisin Gioro family in marriage while the ordinary soldiers who defected were given non-royal Manchu women as wives. The Manchu leader Nurhaci married one of his granddaughters to the Ming General Li Yongfang after he surrendered Fushun in Liaoning to the Manchu in 1618. Jurchen (Manchu) women married most the Han Chinese defectors in Liaodong. Aisin Gioro women were married to the sons of the Han Chinese Generals Sun Sike (Sun Ssu-k'o), Geng Jimao (Keng Chi-mao), Shang Kexi (Shang K'o-hsi), and Wu Sangui (Wu San-kuei).
A mass marriage of Han Chinese officers and officials to Manchu women numbering 1,000 couples was arranged by Prince Yoto and Hongtaiji in 1632 to promote harmony between the two ethnic groups.
Geng Zhongming, a Han bannerman, was awarded the title of Prince Jingnan, and his son Geng Jingmao managed to have both his sons Geng Jingzhong and Geng Zhaozhong become court attendants under Shunzhi and get married to Aisin Gioro women, with Haoge's (a son of Hong Taiji) daughter marrying Geng Jingzhong and Prince Abatai's (Hong Taiji) granddaughter marrying Geng Zhaozhong.
The Qing differentiated between Han Bannermen and ordinary Han civilians. Han Bannermen were made out of Han Chinese who defected to the Qing up to 1644 and joined the Eight Banners, giving them social and legal privileges in addition to being acculturated to Manchu culture. So many Han defected to the Qing and swelled up the ranks of the Eight Banners that ethnic Manchus became a minority within the Banners, making up only 16% in 1648, with Han Bannermen dominating at 75%. It was this multi-ethnic force in which Manchus were only a minority, which conquered China for the Qing.
It was Han Chinese Bannermen who were responsible for the successful Qing conquest of China, they made up the majority of governors in the early Qing and were the ones who governed and administered China after the conquest, stabilizing Qing rule. Han Bannermen dominated the post of governor-general in the time of the Shunzhi and Kangxi Emperors, and also the post of governors, largely excluding ordinary Han civilians from the posts.
To promote ethnic harmony, a 1648 decree from the Manchu Shunzhi Emperor allowed Han Chinese civilian men to marry Manchu women from the Banners with the permission of the Board of Revenue if they were registered daughters of officials or commoners or the permission of their banner company captain if they were unregistered commoners, it was only later in the dynasty that these policies allowing intermarriage were done away with.
The Qing implemented a policy of segregation between the Bannermen of the Eight Banners (Manchu Bannermen, Mongol Bannermen, Han Bannermen) and Han Chinese civilians. This ethnic segregation had cultural and economic reasons: intermarriage was forbidden to keep up the Manchu heritage and minimize sinicization. Han Chinese civilians and Mongol civilians were banned from settling in Manchuria. Han civilians and Mongol civilians were banned from crossing into each other's lands. Ordinary Mongol civilians in Inner Mongolia were banned from even crossing into other Mongol Banners. (A banner in Inner Mongolia was an administrative division and not related to the Mongol Bannermen in the Eight Banners)
These restrictions did not apply Han Bannermen, who were settled in Manchuria by the Qing. Han bannermen were differentiated from Han civilians by the Qing and treated differently.
The Qing Dynasty started colonizing Manchuria with Han Chinese later on in the dynasty's rule, but the Manchu area was still separated from modern-day Inner Mongolia by the Outer Willow Palisade, which kept the Manchu and the Mongols in the area separate.
The policy of segregation applied directly to the banner garrisons, most of which occupied a separate walled zone within the cities in which they were stationed. Manchu Bannermen, Han Bannermen, and Mongol Bannermen were separated from the Han civilian population. While the Manchus followed the governmental structure of the preceding Ming dynasty, their ethnic policy dictated that appointments were split between Manchu noblemen and Han Chinese civilian officials who had passed the highest levels of the state examinations, and because of the small number of Manchus, this insured that a large fraction of them would be government officials.
Italy.
In 1938, the fascist regime led by Benito Mussolini, under pressure from the Nazis, introduced a series of laws instituting an official segregationist policy in the Italian Empire, especially aimed against Jews. This policy enforced various segregationist norms, like the prohibition for Jews to teach or study in ordinary schools and universities, to own industries reputed of major national interest, to work as journalists, to enter the military, and to wed non-Jews.
Some of the immediate consequences of the introduction of the 'provvedimenti per la difesa della razza' (norms for the defence of the race) included many of the best Italian scientists leaving their job, or even Italy. Amongst these, world-renowned physicists Emilio Segrè, Enrico Fermi (whose wife was Jewish), Bruno Pontecorvo, Bruno Rossi, Tullio Levi-Civita, mathematicians Federigo Enriques and Guido Fubini and even the fascist propaganda director, art critic and journalist Margherita Sarfatti, who was one of Mussolini's mistresses. Rita Levi-Montalcini, who would successively win the Nobel Prize for Medicine, was forbidden to work at the university. Albert Einstein, upon approval of the racial law, resigned from honorary membership of the Accademia dei Lincei.
After 1943, when Northern Italy was occupied by the Nazis, Italian Jews were rounded up for the Holocaust.
Jewish segregation.
Jews in Europe generally were forced, by decree or by informal pressure, to live in highly segregated ghettos and shtetls. In 1204 the papacy required Jews to segregate themselves from Christians and to wear distinctive clothing. Forced segregation of Jews spread throughout Europe during the 14th and 15th centuries. In the Russian Empire, Jews were restricted to the so-called Pale of Settlement, the Western frontier of the Russian Empire corresponding roughly to the modern-day countries of Poland, Lithuania, Belarus, Moldova and Ukraine. By the early 20th century, the majority of European Jews lived in the Pale of Settlement.
Jewish population were confined to mellahs in Morocco beginning from the 15th century. In cities, a "mellah" was surrounded by a wall with a fortified gateway. In contrast, rural "mellahs" were separate villages inhabited solely by the Jews.
In the middle of the 19th century, J. J. Benjamin wrote about the life of Persian Jews:
Latin America.
Spanish colonists created caste systems in Latin American countries based on classification by race and race mixture. An extensive nomenclature developed, including the familiar terms "mulatto", "mestizo", and "zambo" (the latter the origin of "sambo"). The Spanish had practiced a form of caste system in Hispania before their expulsion of the Jews and Muslims. While many Latin American countries have long since rendered the system officially illegal through legislation, usually at the time of independence, prejudice based on degrees of perceived racial distance from European ancestry combined with one's socioeconomic status remain, an echo of the colonial caste system.
Norway.
On 16 May 1940 the "Administrasjonsrådet" asked Rikskommisariatet why radio receivers had been confiscated from Jews in Norway. That "Administrasjonsrådet" thereafter "quietly" accepted racial segregation between Norwegian citizens, has been claimed by Tor Bomann-Larsen. Furthermore, he claimed that this segregation "created a precedent. 2 years later (with "NS-styret" in the ministries of Norway) Norwegian police arrested citizens at the addresses where radios had previously been confiscated from Jews.
Rhodesia.
Following a dispute over the terms for the granting of full independence, the British self-governing colony of Rhodesia, governed by a predominantly white minority government, unilaterally declared independence in 1965. Led by Prime Minister Ian Smith, it endured as an unrecognized state under white rule for the next 14 years, with majority rule coming in 1979 with the Internal Settlement between Smith's government and moderate black nationalists, the associated multiracial elections and the reconstitution of the country as Zimbabwe Rhodesia, with Bishop Abel Muzorewa at the helm of a coalition cabinet comprising 12 blacks and five whites. This new order also failed to win legitimacy in the eyes of the world, and British control returned to the country in December 1979, following the Lancaster House Agreement. New elections were held in 1980, and Zimbabwe gained recognized independence in April 1980, with Robert Mugabe as prime minister.
Laws enforcing segregation had been around before 1965, although many institutions simply ignored them. One highly publicized legal battle occurred in 1960 involving the opening of a new theatre that was to be open to all races; the proposed unsegregated public toilets at the newly built Reps Theatre in 1959 caused an argument called "The Battle of the Toilets".
South Africa.
The apartheid system carried out by Afrikaner minority rule enacted a nationwide social policy "separate development" with the National Party victory in 1948, following the "colour bar"-discriminatory legislation dating back to the beginning of the Union of South Africa and the Boer republics before which, while repressive to black South Africans along with other minorities, had not gone nearly so far.
Apartheid laws can be generally divided into following acts. Firstly, the Population Registration Act in 1950 classified residents in South Africa into four racial groups: "black", "white", "Coloured", and "Indian" and noted their racial identities on their identifications. Secondly, the Group Areas Act in 1950 assigned different regions according to different races. People were forced to live in their corresponding regions and the action of passing the boundaries without a permit was made illegal, extending pass laws that had already curtailed black movement. Thirdly, under the Reservation of Separate Amenities Act in 1953, amenities in public area, like hospitals, universities and parks, were labeled separately according to particular races. In addition, the Bantu Education Act in 1953 segregated national education in South Africa as well. Additionally, the government of the time enforced the pass laws, which deprived black South Africans of their right to travel freely within their own country. Under this system black people were severely restricted from urban areas, requiring authorisation from a white employer to enter.
Uprisings and protests against apartheid appeared immediately when apartheid arose. As early as 1949, the youth wing of the African National Congress (ANC) advocated the ending of apartheid and suggested fighting against racial segregation by various methods. During the following decades, hundreds of anti-apartheid actions occurred, including those of the Black Consciousness Movement, students' protests, labor strikes, and church group activism etc. In 1991, the Abolition of Racially Based Land Measures Act was passed, repealing laws enforcing racial segregation, including the Group Areas Act. In 1994, Nelson Mandela won in the first multiracial democratic election in South Africa. His success fulfilled the ending of apartheid in South African history.
United States.
After laws were passed that segregated African Americans and Whites, the lives of those who were negatively affected saw no progress in their quest for equality.
Racial segregation was not a new occurrence as most African Americans had been under slavery before the Civil War with almost four million denied freedom from bondage. The laws passed segregated African Americans to Whites. Signs were used to show African Americans where they could, under legal protection, walk, talk, drink, rest or eat. For those places that were racially mixed, African Americans had to wait until all other White customers were dealt with first. Rules were also enforced that restricted African Americans from entering white stores. The racial segregation affected the lives of African Americans significantly as they were not granted equality.
After the Thirteenth Amendment abolished slavery in America, racial discrimination became regulated by the so-called Jim Crow laws, which mandated strict segregation of the races. Though such laws were instituted shortly after fighting ended in many cases, they only became formalized after the end of Republican-enforced Reconstruction in the 1870s and 80s during a period known as the nadir of American race relations. This legislation that mandated segregation lasted to the mid-1960s.
While the U.S. Supreme Court majority in 1896 "Plessy" explicitly upheld only "separate but equal" facilities (specifically, transportation facilities), Justice John Marshall Harlan in his dissent protested that the decision was an expression of white supremacy; he predicted that segregation would "stimulate aggressions … upon the admitted rights of colored citizens," "arouse race hate" and "perpetuate a feeling of distrust between races. Feelings between whites and blacks were so tense, even the jails were segregated."
American sports were racially segregated until the mid 20th century. In baseball, the "Negro leagues" were established by Rube Foster for non-white players, such as Negro league baseball, which ran through the early 1950s. In basketball, the Black Fives (all-black teams) were established in 1904, and emerged in New York City, Washington, Chicago, Pittsburgh, Philadelphia and other cities. Racial segregation in basketball lasted until 1950 when the NBA became racially integrated.
Many U.S. states banned interracial marriage. While opposed to slavery in the U.S, in a speech in Charleston, Illinois in 1858, Abraham Lincoln stated, "I am not, nor ever have been in favor of bringing about in any way the social and political equality of the white and black races, that I am not, nor ever have been in favor of making voters or jurors of negroes, nor of qualifying them to hold office, nor to intermarry with white people. I as much as any man am in favor of the superior position assigned to the white race". In 1967, Mildred Loving, a black woman, and Richard Loving, a white man, were sentenced to a year in prison in Virginia for marrying each other. Their marriage violated the state's anti-miscegenation statute, the Racial Integrity Act of 1924, which prohibited marriage between people classified as white and people classified as "colored" (persons of African or Native American ancestry). In the "Loving v. Virginia" case in 1967, the Supreme Court invalidated laws prohibiting interracial marriage in the U.S.
Institutionalized racial segregation was ended as an official practice by the efforts of such civil rights activists as Clarence M. Mitchell, Jr., Rosa Parks, and Martin Luther King Jr., working for social and political freedom during the period from the end of World War II through the passage of the Voting Rights Act and the Civil Rights Act of 1964 supported by President Lyndon B. Johnson. Many of their efforts were acts of non-violent civil disobedience aimed at disrupting the enforcement of racial segregation rules and laws, such as refusing to give up a seat in the black part of the bus to a white person (Rosa Parks), or holding sit-ins at all-white diners.
By 1968 all forms of segregation had been declared unconstitutional by the Supreme Court, and by 1970 support for formal legal segregation had dissolved. Brown v. Board of Education of Topeka, Kansas in 1954 outlawed segregation in public schools. The Fair Housing Act of 1968, administered and enforced by the Office of Fair Housing and Equal Opportunity, prohibited discrimination in the sale and rental of housing on the basis of race, color, national origin, religion, sex, familial status, and disability. Formal racial discrimination became illegal in school systems, businesses, the American military, other civil services and the government.
Contemporary segregation.
Bahrain.
On 28 April 2007, the lower house of Bahraini Parliament passed a law banning unmarried migrant workers from living in residential areas. To justify the law MP Nasser Fadhala, a close ally of the government said "bachelors also use these houses to make alcohol, run prostitute rings or to rape children and housemaids".
Sadiq Rahma, technical committee head, who is a member of Al Wefaq said: "The rules we are drawing up are designed to protect the rights of both the families and the Asian bachelors (..) these labourers often have habits which are difficult for families living nearby to tolerate (..) they come out of their homes half dressed, brew alcohol illegally in their homes, use prostitutes and make the neighbourhood dirty (..) these are poor people who often live in groups of 50 or more, crammed into one house or apartment," said Mr Rahma. "The rules also state that there must be at least one bathroom for every five people (..) there have also been cases in which young children have been sexually molested."
Bahrain Centre for Human Rights issued a press release condemning this decision as discriminatory and promoting negative racist attitudes towards migrant workers. Nabeel Rajab, then BCHR vice president, said: "It is appalling that Bahrain is willing to rest on the benefits of these people's hard work, and often their suffering, but that they refuse to live with them in equality and dignity. The solution is not to force migrant workers into ghettos, but to urge companies to improve living conditions for workers – and not to accommodate large numbers of workers in inadequate space, and to improve the standard of living for them."
Canada.
Parts of Canada, particularly British Columbia were highly racialized and featured segregation. Ending in the 1950s and 60s, First Nations were segregated; denied entry to restaurants, made to use separate bathrooms, use different train cars and ride steerage on steamships. Segregation also affected immigrants from China, Japan and India (despite its status as a Dominion).
Since the 1970s, there has been a concern expressed by some academics that major Canadian cities are becoming more segregated on income and ethnic lines. Reports have indicated that the inner suburbs of post-merger Toronto and the southern bedroom communities of Greater Vancouver have become steadily more immigrant and visible minority dominated communities and have lagged behind other neighbourhoods in average income. A CBC panel in Vancouver in 2012 discussed the growing public fear that the proliferation of ethnic enclaves in Greater Vancouver (such as Han Chinese in Richmond and Punjabis in Surrey) amounted to a type of self-segregation. In response to these fears, many minority activists have pointed out that most Canadian neighbourhoods remain predominately White, and yet Whites are never accused of "self-segregation".
The Mohawk tribe of Kahnawake has been criticized for evicting non-Mohawks from the Mohawk reserve. Mohawks who marry outside of their race lose their right to live in their homelands. The Mohawk government claims that its policy of racially exclusive membership is for the preservation of its identity, but there is no exemption for those who adopt Mohawk language or culture. The policy is based on a 1981 moratorium which was made law in 1984. All interracial couples are sent eviction notices regardless of how long they have lived on the reserve. The only exemption is for interracial couples married before the 1981 moratorium.
Although some concerned Mohawk citizens contested the racially exclusive membership policy, the Canadian Human Rights Tribunal ruled that the Mohawk government may adopt policies it deems necessary to ensure the survival of its people.
A long-standing practice of segregation has also been imposed upon the commercial salmon fishery in British Columbia since 1992 when separate commercial fisheries were created for select aboriginal groups on three B.C. river systems. Canadians of other races who fish in the separate fisheries have been arrested, jailed and prosecuted. Although the fishermen who were prosecuted were successful at trial (see the decision in R. v. Kapp), the decision was overturned on appeal. On final appeal, the Supreme Court of Canada ruled in favour of the program on the grounds that segregation of this workplace is a step towards equality in Canada. Affirmative action programs in Canada are protected from equality rights challenges by s. 15(2) of the Canadian Charter of Rights and Freedoms. Segregation continues today, but more than 35%of the fishermen in the BC commercial fishery are of aboriginal ancestry, yet Canadians of aboriginal ancestry comprise less than 4% of BC's population.
Fiji.
Two military coups in Fiji in 1987 removed a democratically elected government led by an Indo Fijian. The coup was supported principally by the ethnic Fijian population. A new constitution was promulgated in 1990, establishing Fiji as a republic, with the offices of President, Prime Minister, two-thirds of the Senate, and a clear majority of the House of Representatives reserved for ethnic Fijians; ethnic Fijian ownership of the land was also entrenched in the constitution. Most of these provisions were ended with the promulgation of the 1997 Constitution, although the President, and 14 of the 32 Senators were still selected by the all-indigenous Great Council of Chiefs. The last of these distinctions were removed by the 2013 Constitution.
Fiji's case is a situation of de facto ethnic segregation. Fiji has a long complex history with more than 3500 years as a divided tribal nation. Unification under the British rule as a colony for 96 years brought other racial groups, particularly immigrants from the Indian subcontinent.
Israel.
Israeli Declaration of Independence proclaims equal rights to all citizens regardless of ethnicity, denomination or race. Israel has a substantial list of laws that demand racial equality (such as prohibition of discrimination, equality in Employment, libel based on race or ethnicity.).
In 2010, the Israeli supreme court sent a message against racial segregation in a case involving the Slonim Hassidic sect of the Ashkenazi Jews, ruling that segregation between Ashkenazi and Sephardi students in a school is illegal. They argue that they seek "to maintain an equal level of religiosity, not from racism." Responding to the charges, the Slonim Haredim invited Sephardi girls to school, and added in a statement: "All along, we said it's not about race, but the High Court went out against our rabbis, and therefore we went to prison."
Due to many cultural differences, and animosity towards a minority perceived to wish to annihilate Israel, a system of passively co-existing communities, segregated along ethnic lines has emerged in Israel, with Arab-Israeli minority communities being left "marooned outside the mainstream". This de facto segregation also exists between different Jewish ethnic groups (""edot"") such as Sepharadim , Ashkenazim and Beta Israel (Jews of Ethiopian descent), which leads to de facto segregated schools, housing and public policy. The government has embarked on a program to shut down such schools, in order to force integration, but some in the Ethiopian community complained that not all such schools have been closed. In a 2007 poll commissioned by the Center Against Racism and conducted by the GeoCartographia Institute, 75% of Israeli Jews would not agree to live in a building with Arab residents, 60% would not accept any Arab visitors at their homes, 40% believed that Arabs should be stripped of their right to vote, and 59% believe that the culture of Arabs is primitive. In 2012, a public opinion poll showed that 53% of the polled Israeli Jews said they would not object to an Arab living in their building, while 42% said they would. Asked whether they would object to Arab children being in their child's class in school, 49% said they would not, 42% said they would. The secular Israeli public was found to be the most tolerant, while the religious and Haredi respondents were the most discriminatory.
Liberia.
Liberian Constitution limits Liberian nationality to Negro people (see also Liberian nationality law).
For example, Lebanese and Indian nationals are active in trading, as well as in the retail and service sectors. Europeans and Americans work in the mining and agricultural sectors. These minority groups have long tenured residence in the Republic, but are precluded from becoming citizens as a result of their race.
Malaysia.
Malaysia has an article in its constitution which distinguishes the ethnic Malays and indigenous peoples of Malaysia—i.e. bumiputra—from the non-Bumiputra such as ethnic Chinese and Indians under the social contract, of which by law would guarantee the former certain special rights and privileges. To question these rights and privileges however is strictly prohibited under the Internal Security Act, legalised by the 10th Article(IV) of the Constitution of Malaysia. The privileges mentioned herein covers—few of which—the economical and education aspects of Malaysians, e.g. the Malaysian New Economic Policy; an economic policy recently criticised by Thierry Rommel—who headed a European Commission's delegation to Malaysia—as an excuse for "significant protectionism" and a quota maintaining higher access of Malays into public universities.
While legal racial segregation in daily life is not practiced, self-segregation does exist.
Mauritania.
Slavery in Mauritania was finally criminalized in August 2007 It was already abolished in 1980 though it was still affecting the descendants of black Africans abducted into slavery before generations, who live now in Mauritania as "black Moors" or "haratin" and who partially still serve the "white Moors", or "bidhan" (the name means literally white-skinned people), as slaves. The number of slaves in the country was not known exactly, but it was estimated to be up to 600,000 men, women and children, or 20% of the population.
For centuries, the so-called Haratin lower class, mostly poor black Africans living in rural areas, have been considered natural slaves by white Moors of Arab/Berber ancestry. Many descendants of the Arab and Berber tribes today still adhere to the supremacist ideology of their ancestors. This ideology has led to oppression, discrimination and even enslavement of other groups in the region of Sudan and Western Sahara. In certain villages in Mauritania there are mosques for lighter-skinned nobles and mosques for black slaves, who are still buried in separate cemeteries.
United Kingdom.
The United Kingdom has no legally sanctioned system of racial segregation and has a substantial list of laws that demand racial equality. However, due to many cultural differences between the pre-existing system of passively co-existing communities, segregation along racial lines has emerged in parts of the United Kingdom, with minority communities being left "marooned outside the mainstream".
The affected and 'ghettoised' communities are often largely representative of Pakistanis, Indians and other Sub-Continentals, and has been thought to be the basis of ethnic tensions, and a deterioration of the standard of living and levels of education and employment among ethnic minorities in poorer areas. These factors are considered by some to have been a cause of the 2001 race riots in Bradford, Oldham and Burnley in the north of England which have large Asian communities. Most British commentators claim it is false that the riots were due to a breakdown of multiculturalism alone, and instead claim that it is more likely to have been caused by other factors such as disillusioned youth, high unemployment by a sizeable proportion of the youth, across all ethnicities, of the United Kingdom.
There may be some indication that such segregation, particularly in residential terms, seems to be the result of the unilateral 'steering' of ethnic groups into particular areas as well as a culture of vendor discrimination and distrust of ethnic minority clients by some estate agents and other property professionals. This may be indicative of a market preference amongst the more wealthy to reside in areas of less ethnic mixture; less ethnic mixture being perceived as increasing the value and desirability of a residential area. This is likely as other theories such as "ethnic self segregation" have sometimes been shown to be baseless, and a majority of ethnic respondents to a few surveys on the matter have been in favour of wider social and residential integration.
United States.
De facto segregation in the United States has increased since the civil rights era in the United States. The Supreme Court ruled in Milliken v. Bradley (1974) that de facto racial segregation was acceptable, as long as schools were not actively making policies for racial exclusion; since then, schools have been segregated due to myriad indirect factors.
Redlining is the practice of denying or increasing the cost of services, such as banking, insurance, access to jobs, access to health care, or even supermarkets to residents in certain, often racially determined, areas. The most devastating form of redlining, and the most common use of the term, refers to mortgage discrimination. Over the next twenty years, a succession of further court decisions and federal laws, including the "Home Mortgage Disclosure Act" and measure to end mortgage discrimination in 1975, would completely invalidate "de jure" racial segregation and discrimination in the U.S., although "de facto" segregation and discrimination have proven more resilient. According to the Civil Rights Project at Harvard University, the actual de facto desegregation of U.S. public schools peaked in the late 1980s; since that time, the schools have, in fact, become more segregated mainly due to the ethnic segregation of the nation with whites dominating the suburbs and minorities the urban centers. According to Rajiv Sethi, an economist at Columbia University, black-white segregation in housing is slowly declining for most metropolitan areas in the US Racial segregation or separation can lead to social, economic and political tensions. Thirty years (the year 2000) after the civil rights era, the United States remained in many areas a residentially segregated society, in which blacks, whites and Hispanics inhabit different neighborhoods of vastly different quality.
Dan Immergluck writes that in 2002 small businesses in black neighborhoods still received fewer loans, even after accounting for businesses density, businesses size, industrial mix, neighborhood income, and the credit quality of local businesses. Gregory D. Squires wrote in 2003 that it is clear that race has long affected and continues to affect the policies and practices of the insurance industry. Workers living in American inner cities have a harder time finding jobs than suburban workers.
The desire of many whites to avoid having their children attend integrated schools has been a factor in white flight to the suburbs. A 2007 study in San Francisco showed that groups of homeowners of all races tended to self-segregate in order to be with people of the same education level and race. By 1990, the legal barriers enforcing segregation had been mostly replaced by decentralized racism, where whites pay more than blacks to live in predominantly white areas. Today, many whites are willing, and are able, to pay a premium to live in a predominantly white neighborhood. Equivalent housing in white areas commands a higher rent. These higher rents are largely attributable to exclusionary zoning policies that restrict the supply of housing. Regulations ensure that all housing units are expensive enough to prevent access by undesirable groups. By bidding up the price of housing, many white neighborhoods effectively shut out blacks, because blacks are unwilling, or unable, to pay the premium to buy entry into these expensive neighborhoods. Conversely, equivalent housing in black neighborhoods is far more affordable to those who are unable or unwilling to pay a premium to live in white neighborhoods. Through the 1990s, residential segregation remained at its extreme and has been called "hypersegregation" by some sociologists or "American Apartheid".
In February 2005, the U.S. Supreme Court ruled in "Johnson v. California" that the California Department of Corrections' unwritten practice of racially segregating prisoners in its prison reception centers – which California claimed was for inmate safety (gangs in California, as throughout the U.S., usually organize on racial lines)— is to be subject to strict scrutiny, the highest level of constitutional review.
Yemen.
In Yemen, the Arab elite practices a form of discrimination against the lower class Akhdam people based on their racial system.

</doc>
<doc id="26317" url="https://en.wikipedia.org/wiki?curid=26317" title="Range">
Range

Range may refer to:

</doc>
<doc id="26318" url="https://en.wikipedia.org/wiki?curid=26318" title="Roslagen">
Roslagen

[[Image:Folklands.png|thumb|300px|Folklands in Svitjod (Uppland/Gästrikland)
red = Tiunda
cyan = Attunda
yellow = Roden / Roslagen
green = Fjärdhundra
The coastline has changed considerably in the last millennium due to post-glacial rebound. Originally there was a sea bay coming in from the north all the way into Uppsala. Roslagen is the modern name for the area which roughly corresponds to what was called Roden in the Middle Ages.]]
Roslagen is the name of the coastal areas of Uppland province in Sweden, which also constitutes the northern part of the Stockholm archipelago.
Historically, it was the name for all the coastal areas of the Baltic Sea, including the eastern parts of lake Mälaren, belonging to Svealand. The name was first mentioned in the year 1493 as "Rodzlagen". Before that the area has been known as "Roden", which is the coastal equivalent to inland Hundreds. When the king would issue a call to leidang, the Viking Age equivalent of military conscript service, a Roden district was responsible for raising a number of ships for the leidang navy.
The name comes from Roslagen word "rodslag", which in coastal Uppland is an old word for a rowing crew of warrior oarsmen. Etymologically, Roden, or Roslagen, is the source of the Finnish and Estonian names for Sweden: "Ruotsi" and "Rootsi".
A person from Roslagen is called "Rospigg" which means "inhabitant of Ros". Swedes from the Roslagen area, that is "the people of Ros", gave name to the Rus' people and through that to the state of Russia (see Rus' (name)).
The area also gives its name to the endangered domesticated Roslag sheep, which originated from the area centuries ago. It is served by the Roslagsbanan, a narrow-gauge railway network from Stockholm.

</doc>
<doc id="26321" url="https://en.wikipedia.org/wiki?curid=26321" title="Ramjet">
Ramjet

A ramjet, sometimes referred to as a flying stovepipe or an athodyd (an abbreviation of aero thermodynamic duct), is a form of airbreathing jet engine that uses the engine's forward motion to compress incoming air without an axial compressor. Ramjets cannot produce thrust at zero airspeed; they cannot move an aircraft from a standstill. A ramjet-powered vehicle, therefore, requires an assisted take-off like a rocket assist to accelerate it to a speed where it begins to produce thrust. Ramjets work most efficiently at supersonic speeds around . This type of engine can operate up to speeds of .
Ramjets can be particularly useful in applications requiring a small and simple mechanism for high-speed use, such as missiles. Weapon designers are looking to use ramjet technology in artillery shells to give added range; a 120 mm mortar shell, if assisted by a ramjet, is thought to be able to attain a range of . They have also been used successfully, though not efficiently, as tip jets on the end of helicopter rotors.
Ramjets differ from pulsejets, which use an intermittent combustion; ramjets employ a continuous combustion process.
As speed increases, the efficiency of a ramjet starts to drop as the air temperature in the inlet increases due to compression. As the inlet temperature gets closer to the exhaust temperature, less energy can be extracted in the form of thrust. To produce a usable amount of thrust at yet higher speeds, the ramjet must be modified so that the incoming air is not compressed (and therefore heated) nearly as much. This means that the air flowing through the combustion chamber is still moving very fast (relative to the engine), in fact it will be supersonic - hence the name Supersonic Combustion Ramjet, or Scramjet.
History.
Cyrano de Bergerac.
"L'Autre Monde: ou les États et Empires de la Lune (Comical History of the States and Empires of the Moon)" was the first of three satirical novels written by Cyrano de Bergerac, that are considered among the first science fiction stories. Arthur C Clarke credited this book with inventing the ramjet, and being the first example of a rocket-powered space flight.
René Lorin.
The ramjet was conceived in 1913 by French inventor René Lorin, who was granted a patent for his device. Attempts to build a prototype failed due to inadequate materials.
Albert Fonó.
In 1915, Hungarian inventor Albert Fonó devised a solution for increasing the range of artillery, comprising a gun-launched projectile which was to be united with a ramjet propulsion unit, thus giving a long range from relatively low muzzle velocities, allowing heavy shells to be fired from relatively lightweight guns. Fonó submitted his invention to the Austro-Hungarian Army, but the proposal was rejected. After World War I, Fonó returned to the subject of jet propulsion, in May 1928 describing an "air-jet engine" which he described as being suitable for high-altitude supersonic aircraft, in a German patent application. In an additional patent application, he adapted the engine for subsonic speed. The patent was finally granted in 1932 after four years of examination (German Patent No. 554,906, 1932-11-02).
Soviet Union.
In the Soviet Union, a theory of supersonic ramjet engines was presented in 1928 by Boris Stechkin. Yuri Pobedonostsev, chief of GIRD's 3rd Brigade, carried out a great deal of research into ramjet engines. The first engine, the GIRD-04, was designed by I.A. Merkulov and tested in April 1933. To simulate supersonic flight, it was fed by air compressed to , and was fueled with hydrogen. The GIRD-08 phosphorus-fueled ramjet was tested by firing it from an artillery cannon. These shells may have been the first jet-powered projectiles to break the speed of sound.
In 1939, Merkulov did further ramjet tests using a two-stage rocket, the R-3. In August of that year, he developed the first ramjet engine for use as an auxiliary motor of an aircraft, the DM-1. The world's first ramjet-powered airplane flight took place in December 1939, using two DM-2 engines on a modified Polikarpov I-15. Merkulov designed a ramjet fighter "Samolet D" in 1941, which was never completed. Two of his DM-4 engines were installed on the Yak-7 PVRD fighter, during World War II. In 1940, the Kostikov-302 experimental plane was designed, powered by a liquid fuel rocket for take-off and ramjet engines for flight. That project was cancelled in 1944.
In 1947, Mstislav Keldysh proposed a long-range antipodal bomber, similar to the Sänger-Bredt bomber, but powered by ramjet instead of rocket. In 1954, NPO Lavochkin and the Keldysh Institute began development of a trisonic ramjet-powered cruise missile, "Burya". This project competed with the R-7 ICBM being developed by Sergei Korolev, and was cancelled in 1957.
Germany.
In 1936, Hellmuth Walter constructed a test engine powered by natural gas. Theoretical work was carried out at BMW and Junkers, as well as DFL. In 1941, Eugen Sänger of DFL proposed a ramjet engine with a very high combustion chamber temperature. He constructed very large ramjet pipes with and diameter and carried out combustion tests on lorries and on a special test rig on a Dornier Do 17Z at flight speeds of up to . Later, with petrol becoming scarce in Germany due to wartime conditions, tests were carried out with blocks of pressed coal dust as a fuel, which were not successful due to slow combustion.
Gorgon IV.
The US Navy developed a series of air-to-air missiles under the name of "Gorgon" using different propulsion mechanisms, including ramjet propulsion. The ramjet Gorgon IVs, made by Glenn Martin, were tested in 1948 and 1949 at Naval Air Station Point Mugu. The ramjet engine itself was designed at the University of Southern California and manufactured by the Marquardt Aircraft Company. The engine was long and in diameter and was positioned below the missile (see photo).
Fritz Zwicky.
Eminent Swiss astrophysicist Fritz Zwicky was research director at Aerojet and holds many patents in jet propulsion. U.S. patents 5121670 and 4722261 are for ram accelerators. The U.S. Navy would not allow Fritz Zwicky to publicly discuss his own invention, U.S. Patent 2,461,797 for the Underwater Jet, a ram jet that performs in a fluid medium. "Time" chronicles Fritz Zwicky's work in the "Missed Swiss", July 11, 1955, and the "Underwater Jet" in the March 14, 1949 issue.
France.
In France, the works of René Leduc were notable. Leduc's Model, the Leduc 0.10 was one of the first ramjet-powered aircraft to fly, in 1949.
The Nord 1500 Griffon reached in 1958.
Engine cycle.
The Brayton cycle is a thermodynamic cycle that describes the workings of the gas turbine engine, the basis of the airbreathing jet engine and others. It is named after George Brayton (1830–1892), the American engineer who developed it, although it was originally proposed and patented by Englishman John Barber in 1791. It is also sometimes known as the Joule cycle.
Design.
A ramjet is designed around its inlet. An object moving at high speed through air generates a high pressure region upstream. A ramjet uses this high pressure in front of the engine to force air through the tube, where it is heated by combusting some of it with fuel. It is then passed through a nozzle to accelerate it to supersonic speeds. This acceleration gives the ramjet forward thrust.
A ramjet is sometimes referred to as a 'flying stovepipe', a very simple device comprising an air intake, a combustor, and a nozzle. Normally, the only moving parts are those within the turbopump, which pumps the fuel to the combustor in a liquid-fuel ramjet. Solid-fuel ramjets are even simpler.
By way of comparison, a turbojet uses a gas turbine-driven fan to compress the air further. This gives greater compression and efficiency and far more power at low speeds, where the ram effect is weak, but is also more complex, heavier and expensive, and the temperature limits of the turbine section limit the top speed and thrust at high speed.
Diffuser.
Ramjets try to exploit the very high dynamic pressure within the air approaching the intake lip. An efficient intake will recover much of the freestream stagnation pressure, which is used to support the combustion and expansion process in the nozzle.
Most ramjets operate at supersonic flight speeds and use one or more conical (or oblique) shock waves, terminated by a strong normal shock, to slow down the airflow to a subsonic velocity at the exit of the intake. Further diffusion is then required to get the air velocity down to a suitable level for the combustor.
Subsonic ramjets do not need such a sophisticated inlet since the airflow is already subsonic and a simple hole is usually used. This would also work at slightly supersonic speeds, but as the air will choke at the inlet, this is inefficient.
The inlet is divergent, to provide a constant inlet speed of .
Combustor.
As with other jet engines, the combustor's job is to create hot air, by burning a fuel with the air at essentially constant pressure. The airflow through the jet engine is usually quite high, so sheltered combustion zones are produced by using 'flame holders' to stop the flames from blowing out.
Since there is no downstream turbine, a ramjet combustor can safely operate at stoichiometric fuel:air ratios, which implies a combustor exit stagnation temperature of the order of for kerosene. Normally, the combustor must be capable of operating over a wide range of throttle settings, for a range of flight speeds/altitudes. Usually, a sheltered pilot region enables combustion to continue when the vehicle intake undergoes high yaw/pitch during turns. Other flame stabilization techniques make use of flame holders, which vary in design from combustor cans to simple flat plates, to shelter the flame and improve fuel mixing. Overfuelling the combustor can cause the normal shock within a supersonic intake system to be pushed forward beyond the intake lip, resulting in a substantial drop in engine airflow and net thrust.
Nozzles.
The propelling nozzle is a critical part of a ramjet design, since it accelerates exhaust flow to produce thrust.
For a ramjet operating at a subsonic flight Mach number, exhaust flow is accelerated through a converging nozzle. For a supersonic flight Mach number, acceleration is typically achieved via a convergent-divergent nozzle.
Performance and control.
Although ramjets have been run as slow as , below about they give little thrust and are highly inefficient due to their low pressure ratios.
Above this speed, given sufficient initial flight velocity, a ramjet will be self-sustaining. Indeed, unless the vehicle drag is extremely high, the engine/airframe combination will tend to accelerate to higher and higher flight speeds, substantially increasing the air intake temperature. As this could have a detrimental effect on the integrity of the engine and/or airframe, the fuel control system must reduce engine fuel flow to stabilize the flight Mach number and, thereby, air intake temperature to reasonable levels.
Due to the stoichiometric combustion temperature, efficiency is usually good at high speeds (around ), whereas at low speeds the relatively poor pressure ratio means the ramjets are outperformed by turbojets, or even rockets.
Types.
Ramjets can be classified according to the type of fuel, liquid or solid; and the booster.
In a liquid fuel ramjet (LFRJ), hydrocarbon fuel (typically) is injected into the combustor ahead of a flameholder which stabilises the flame resulting from the combustion of the fuel with the compressed air from the intake(s). A means of pressurizing and supplying the fuel to the ramcombustor is required, which can be complicated and expensive. Aérospatiale-Celerg designed an LFRJ where the fuel is forced into the injectors by an elastomer bladder which inflates progressively along the length of the fuel tank. Initially, the bladder forms a close-fitting sheath around the compressed air bottle from which it is inflated, which is mounted lengthwise in the tank. This offers a lower-cost approach than a regulated LFRJ requiring a turbopump and associated hardware to supply the fuel.
A ramjet generates no static thrust and needs a booster to achieve a forward velocity high enough for efficient operation of the intake system. The first ramjet-powered missiles used external boosters, usually solid-propellant rockets, either in tandem, where the booster is mounted immediately aft of the ramjet, e.g. Sea Dart, or wraparound where multiple boosters are attached alongside the outside of the ramjet, e.g. SA-4 Ganef. The choice of booster arrangement is usually driven by the size of the launch platform. A tandem booster increases the overall length of the system, whereas wraparound boosters increase the overall diameter. Wraparound boosters will usually generate higher drag than a tandem arrangement.
Integrated boosters provide a more efficient packaging option, since the booster propellant is cast inside the otherwise empty combustor. This approach has been used on solid, for example SA-6 Gainful, liquid, for example ASMP, and ducted rocket, for example Meteor, designs. Integrated designs are complicated by the different nozzle requirements of the boost and ramjet phases of flight. Due to the higher thrust levels of the booster, a differently shaped nozzle is required for optimum thrust compared to that required for the lower thrust ramjet sustainer. This is usually achieved via a separate nozzle, which is ejected after booster burnout. However, designs such as Meteor feature nozzleless boosters. This offers the advantages of elimination of the hazard to launch aircraft from the ejected boost nozzle debris, simplicity, reliability, and reduced mass and cost, although this must be traded against the reduction in performance compared with that provided by a dedicated booster nozzle.
Integral rocket ramjet/ducted rocket.
A slight variation on the ramjet uses the supersonic exhaust from a rocket combustion process to compress and react with the incoming air in the main combustion chamber. This has the advantage of giving thrust even at zero speed.
In a solid fuel integrated rocket ramjet (SFIRR), the solid fuel is cast along the outer wall of the ramcombustor. In this case, fuel injection is through ablation of the propellant by the hot compressed air from the intake(s). An aft mixer may be used to improve combustion efficiency. SFIRRs are preferred over LFRJs for some applications because of the simplicity of the fuel supply, but only when the throttling requirements are minimal, i.e. when variations in altitude or Mach number are limited.
In a ducted rocket, a solid fuel gas generator produces a hot fuel-rich gas which is burnt in the ramcombustor with the compressed air supplied by the intake(s). The flow of gas improves the mixing of the fuel and air and increases total pressure recovery. In a throttleable ducted rocket, also known as a variable flow ducted rocket, a valve allows the gas generator exhaust to be throttled allowing control of the thrust. Unlike an LFRJ, solid propellant ramjets cannot flame out. The ducted rocket sits somewhere between the simplicity of the SFRJ and the unlimited throttleability of the LFRJ.
Flight speed.
Ramjets generally give little or no thrust below about half the speed of sound, and they are inefficient (less than 600 seconds) until the airspeed exceeds due to low compression ratios. Even above the minimum speed, a wide flight envelope (range of flight conditions), such as low to high speeds and low to high altitudes, can force significant design compromises, and they tend to work best optimised for one designed speed and altitude (point designs). However, ramjets generally outperform gas turbine-based jet engine designs and work best at supersonic speeds (Mach 2–4). Although inefficient at slower speeds, they are more fuel-efficient than rockets over their entire useful working range up to at least .
The performance of conventional ramjets falls off above Mach 6 due to dissociation and pressure loss caused by shock as the incoming air is slowed to subsonic velocities for combustion. In addition, the combustion chamber's inlet temperature increases to very high values, approaching the dissociation limit at some limiting Mach number.
Related engines.
Air turboramjet.
Another example of this is the air turboramjet, which has a compressor powered by a gas heated via a heat exchanger within the combustion chamber.
Scramjets.
Ramjets always slow the incoming air to a subsonic velocity within the combustor. Scramjets, or "supersonic combustion ramjet" are similar to ramjets, but some of the air goes through the entire engine at supersonic speeds. This increases the stagnation pressure recovered from the freestream and improves net thrust. Thermal choking of the exhaust is avoided by having a relatively high supersonic air velocity at combustor entry. Fuel injection is often into a sheltered region below a step in the combustor wall. Although scramjet engines have been studied for many decades, only recently have small experimental units been flight tested and then only very briefly (e.g. the Boeing X-43).
As of May, 2010, this engine has been tested to attain for 200 seconds on the X-51A Waverider.
Precooled engines.
A variant of the pure ramjet is the 'combined cycle' engine, intended to overcome the limitations of the pure ramjet. One example of this is the SABRE engine; this uses a precooler, behind which is the ramjet and turbine machinery.
The ATREX engine developed in Japan is an experimental implementation of this concept. It uses liquid hydrogen fuel in a fairly exotic, single-fan arrangement. The liquid hydrogen fuel is pumped through a heat exchanger in the air intake, simultaneously heating the liquid hydrogen, and cooling the incoming air. This cooling of the incoming air is critical to achieving a reasonable efficiency. The hydrogen then continues through a second heat exchanger position after the combustion section, where the hot exhaust is used to further heat the hydrogen, turning it into a very high pressure gas. This gas is then passed through the tips of the fan to provide driving power to the fan at subsonic speeds. After mixing with the air, it is burned in the combustion chamber.
The Reaction Engines Scimitar has been proposed for the LAPCAT hypersonic airliner, and the Reaction Engines SABRE for the Reaction Engines Skylon spaceplane.
Nuclear-powered ramjets.
During the Cold War, the United States designed and ground-tested a nuclear-powered ramjet called Project Pluto. This system used no combustion; a nuclear reactor heated the air instead. The project was ultimately canceled because ICBMs seemed to serve the purpose better, and because a low-flying radioactive missile could cause problems for any allied soldiers.
Ionospheric ramjet.
The upper atmosphere above about contains monatomic oxygen produced by the sun through photochemistry. A concept was created by NASA for recombining this thin gas back to diatomic molecules at orbital speeds to power a ramjet.
Bussard ramjet.
The Bussard ramjet is a spacecraft propulsion concept intended to fuse interstellar wind and exhaust it at high speed from the rear of the vehicle.

</doc>
<doc id="26324" url="https://en.wikipedia.org/wiki?curid=26324" title="Ranma ½">
Ranma ½

"Ranma ½" has a comedic formula and a sex-changing main character, who often willfully transforms into a girl to advance his goals. The series also contains many other characters, whose intricate relationships with each other, unusual characteristics, and eccentric personalities drive most of the stories. Although the characters and their relationships are complicated, they rarely change once they are firmly introduced and settled into the series.
The manga has been adapted into two anime series created by Studio Deen: "Ranma ½" and , which together were broadcast on Fuji Television from 1989 to 1992. In addition, they developed 12 original video animations and three films. In 2011, a live-action television special was produced and aired on Nippon Television. The manga and anime series were licensed by Viz Media for English-language releases in North America. Madman Entertainment released the manga, part of the anime series and the first two movies in Australasia, while MVM Films released the first two movies in the United Kingdom. The "Ranma ½" manga has over 53 million copies in print in Japan. Both the manga and anime are cited as some of the first of their mediums to have become popular in the United States.
Plot.
On a training journey in the Bayankala Mountain Range in the Qinghai Province of China, Ranma Saotome and his father Genma fall into the cursed springs at . When someone falls into a cursed spring, they take the physical form of whatever drowned there hundreds or thousands of years ago whenever they come into contact with cold water. The curse will revert when exposed to hot water until their next cold water exposure. Genma falls into the spring of a drowned panda while Ranma falls into the spring of a drowned girl.
Upon returning to Japan, the pair settle in Nerima, Tokyo at the dojo of Genma's old friend Soun Tendo, a fellow practitioner of or "Anything-Goes School" of martial arts which Genma passed on to Ranma. Genma and Soun agreed years ago that their children would marry and carry on the Tendo Dojo. Soun has three teenaged daughters: the polite and easygoing Kasumi, the greedy and indifferent Nabiki and the rather spiteful, martial arts practicing Akane. Akane, who is Ranma's age, is appointed for bridal duty by her sisters with the reasoning that Akane dislikes men and since Ranma is only a man half of the time, they are perfect together. Both Ranma and Akane refuse the engagement initially, having not been consulted on the decision, but they are generally treated as betrothed and end up helping or saving each other on some occasions. They are frequently found in each other's company and are constantly arguing in their trademark awkward love-hate manner that is a franchise focus.
Ranma goes to school with Akane at , where he meets his recurring opponent Tatewaki Kuno, the conceited kendo team captain who aggressively pursues Akane, but also falls in love with Ranma's female form without ever discovering his curse (despite most other characters knowing it). Nerima serves as a backdrop for more martial arts mayhem with the introduction of Ranma's regular rivals, such as the eternally lost Ryoga Hibiki who traveled half way across Japan getting from the front of his house to the back, where Ranma spent three days waiting for him. Ryoga, seeking revenge on Ranma, followed him to Jusenkyo where he ultimately falls into the Spring of Drown Piglet. Now when splashed with cold water he takes the form of a little black pig. Not knowing this, Akane takes the piglet as a pet and names it P-chan, but Ranma knows and hates him for keeping this secret and taking advantage of the situation. Another rival is the nearsighted Mousse, who also falls into the magic pool and becomes a duck when he gets wet, and finally, there is Ranma's impish grandmaster, Happosai, who spends his time stealing the underwear of schoolgirls.
Ranma's prospective paramours include the martial arts rhythmic gymnastics champion Kodachi Kuno, and his second fiancée and childhood friend Ukyo Kuonji the okonomiyaki vendor, along with the Chinese Amazon Shampoo, supported by her great-grandmother Cologne. As the series progresses, the school becomes more eccentric with the return of the demented, Hawaii-obsessed Principal Kuno and the placement of the power-leeching alternating child/adult Hinako Ninomiya as Ranma's English teacher. Ranma's indecision to choose his true love causes chaos in his romantic and school life.
Production.
Rumiko Takahashi stated that "Ranma ½" was conceived to be a martial arts manga that connects all aspects of everyday life to martial arts. Because her previous series had female protagonists, the author decided that she wanted a male this time. However, she was worried about writing a male main character, and therefore decided to make him half-female. Before deciding on water for initiating his changes, she considered Ranma changing every time he was punched. It was after deciding this that she felt Jusenkyo had to be set in China, as it is the only place that could have such mysterious springs. She drew inspiration for "Ranma ½" from a variety of real-world objects. Some of the places frequently seen in the series are modeled after actual locations in Nerima, Tokyo (both the home of Takahashi and the setting of "Ranma ½").
In a 1990 interview with "Amazing Heroes", Takahashi stated that she had four assistants that draw the backgrounds, panel lines and tone, while she creates the story and layout, and pencils and inks the characters. All her assistants are female, as Takahashi refuses to have males so that the girls will not be distracted. In 1992, she explained her process as beginning with laying out the chapter in the evening so as to finish it by dawn, and resting for a day before calling her assistants. They finish it in two or three nights, usually utilizing five days for a chapter.
Takahashi purposefully aimed the series to be popular with women and children. In 1993, an "Animerica" interviewer talking with Takahashi asked her if she intended the sex-changing theme "as an effort to enlighten a male-dominated society." Takahashi said that she does not think in terms of societal agendas and that she created the "Ranma ½" concept from simply wanting "a simple, fun idea". She added that she, as a woman and while recalling what manga she liked to read as a child, felt that "humans turning into animals might also be fun and märchenhaft... you know, like a fairy tale." In 2013, she revealed that at the start of "Ranma" her editor told her to make it more dramatic, but she felt that was something she could not do. However, she admitted that drama did start to appear at the end. She also sat in on the voice actor auditions for the anime, where she insisted that male and female Ranma be voiced by different actors whose gender corresponded to that of the part.
Media.
Manga.
Written and illustrated by Rumiko Takahashi, "Ranma ½" began publication in "Weekly Shōnen Sunday" issue #36 of 1987, following the ending of her series "Urusei Yatsura". From September 1987 until March 1996, the manga was published on a near weekly basis with the occasional colored page to spruce up the usually black and white stories. After nearly a decade of storylines, the final chapter was published in "Weekly Shōnen Sunday" issue #12 of 1996. The 407 chapters were periodically collected and published by Shogakukan into a total of 38 black and white "tankōbon" volumes from 1988 to 1996. They were reassembled into 38 "shinsōban" from April 2002 to October 2003.
North American publisher Viz Media originally released "Ranma ½" in a monthly comic book format that contained two chapters each from 1992 to 2003, and had the images "flipped" to read left-to-right, causing the art to be mirrored. These were periodically collected into graphic novels. On March 18, 2004, after releasing 21 volumes, Viz announced that it would reprint a number of its graphic novels. The content remained the same, but the novels moved to a smaller format with different covers and a price drop. Each volume covers roughly the same amount of material as the Japanese volumes, but retained its left-to-right format and had minor differences in grouping so that it spans 36 volumes rather than the original 38. The final volume was released in stores on November 14, 2006, thus making it Viz's longest running manga, spanning over 13 years. At Anime Expo on July 7, 2013, Viz Media announced they would began re-releasing the manga in a format that combines two individual volumes into a single large one. With the first volume published on March 11, 2014, it marks the first time the series has been released in North America in its original right-to-left format. Madman Entertainment publishes the two-in-one version in Australasia.
Together with "Spriggan", it was the first manga published in Portugal, by Texto Editora in 1995.
Anime.
An anime television series was created by Studio Deen and aired weekly between April 15, 1989 and September 16, 1989 on Fuji TV for 18 episodes, before being canceled due to low ratings. The series was then reworked by most of the same staff, retitled and launched in a different time slot, running for 143 episodes from October 20, 1989 to September 25, 1992. The anime stays true to the original manga but does differ by keeping Ranma's sex transformation a secret from the high school students, at least throughout most of its length. It also does not introduce Hikaru Gosunkugi until very late in the series, instead, Sasuke Sarugakure, the diminutive ninja retainer of the Kuno family fills a number of Gosunkugi's roles in early storylines but is a major character in his own right. The anime also alters the placement of many story arcs and contains numerous original episodes and characters not adapted from the manga.
Viz Media licensed both anime series in 1993, making "Ranma ½" one of the very first anime titles licensed by Viz. The English dub produced for the series was recorded by The Ocean Group in Vancouver, British Columbia. They released the series on VHS from their own "Viz Video" label, and on DVD a few years later in association with Pioneer Home Entertainment. Their releases collected both anime series as one, separated episodes into what they call "seasons", and changed the ordering of many of the episodes. Viz themselves re-released it on DVD in 2007 using their own DVD production company. At Otakon 2013, Viz announced that they re-acquired the TV series for Blu-ray and DVD release in 2014. The show is streamed on their anime channel service Neon Alley since Autumn 2013. Madman Entertainment licensed some of the series for release in Australasia, although their rights expired after releasing only the first four "seasons" as one series.
Films and original video animations.
Studio Deen also created three theatrical films; "The Battle of Nekonron, China! A Battle to Defy the Rules!" on November 2, 1991; "Battle at Togenkyo! Get Back the Brides" on August 1, 1992; and "Super Indiscriminate Decisive Battle! Team Ranma vs. the Legendary Phoenix" on August 20, 1994. The first two movies are feature length, but the third was originally aired in theaters with two other movies: "Ghost Sweeper Mikami" and "Heisei Dog Stories: Bow".
Following the ending of the TV series, 11 original video animations were released directly to home video, the earliest on December 7, 1993 and the eleventh on June 4, 1996. All but one are based on stories originally in the manga. Twelve years later, a "Ranma" animation was created for the "It's a Rumic World" exhibition of Rumiko Takahashi's artwork. Based on the "Nightmare! Incense of Deep Sleep" manga story from volume 34, it was shown on odd numbered days at the exhibition in Tokyo from July 30 to August 11, 2008. But it was not released until January 29, 2010, when it was put in a DVD box set with the "Urusei Yatsura" and "InuYasha" specials that premiered at the same exhibit. It was then released on DVD and Blu-ray by itself on October 20, 2010. Viz Media also licensed all three movies, and the original 11 OVAs for distribution in North America (however they released the third movie as an OVA). MVM Films has released the first two movies in the United Kingdom, while Madman Entertainment released them in Australasia.
Video games.
There have been fifteen video games based on the "Ranma ½" franchise. While most are fighting games, there have been several RPGs and puzzle games. Only two have been released in Western countries. "Ranma ½: Chōnai Gekitōhen" was released in the US as "Street Combat"; the characters were Americanized, having their appearances completely changed, and the music was changed as well. However, "" was released in both North America and Europe unaltered.
Live action special.
A live action television adaption of "Ranma ½" aired on NTV, in a two-hour time-slot, on December 9, 2011. Although it was initially reported that the special would contain an original story, the movie does take its main plot from one of the manga's early stories with several other early scenes mixed in. The special stars Yui Aragaki as Akane, with Kento Kaku and Natsuna Watanabe playing male and female Ranma respectively. Ryōsei Tayama is cast as the antagonist, the new original character Okamada. The all-girl pop group 9nine contribute "Chikutaku☆2Nite" as the theme song. It was released on both DVD and Blu-ray on March 21, 2012.
Other media.
"The Ranma ½ Memorial Book" was published just as the manga ended in 1996. Acting as an end-cap to the series, it collects various illustrations from the series, features an interview with Takahashi, and includes tidbits about Ranma: summaries of his battles, his daily schedule, trivia, and a few exclusive illustrations. 
A "Movie + OVA Visual Comic" was released to illustrate the theatrical movie "Super Indiscriminate Decisive Battle! Team Ranma vs. the Legendary Phoenix" and the OVA episodes "The One to Carry On" (both parts). It also included information on the voice actors, character designs, and a layout of the Tendo dojo. 
Additionally, guidebooks were released for three of the "Ranma ½" video games; these included not only strategies, but also interviews. Two books including interviews with the cast of the live-action TV drama, and some select stories, were released in 2011.
The music from the "Ranma ½" TV series, films and OVAs have been released on various CDs. Four from the TV series, two from the first movie, one from the second, one from the third movie and OVAs, and three compiling the music by DoCo used in the OVAs. DoCo is a pop group composed of the anime's main female characters' voice actresses. Several compilation albums were also released, some composed of the opening and closing theme songs and others of image songs. Many of the image songs were first released as singles.
Reception.
Rumiko Takahashi said that after "Urusei Yatsura", which was popular with high school and college students, she purposefully aimed "Ranma ½" to be popular among women and children. Both series' peak readership figures were with 15-year-olds, but the distribution of "Ranma ½" readers was skewed towards younger females. By November 2006, it was reported that the series had sold over 49 million manga volumes in Japan. Shogakukan has printed 53 million copies as of November 2011. The series's publication in North America proved highly successful as well, being many Americans' first introduction to manga and its anime adaptation one of the first Japanese animation shows to achieve popularity in the US. Although Lum from Takahashi's first series "Urusei Yatsura" is often cited as the first "tsundere" character in anime and manga, Theron Martin of Anime News Network stated that "Ranma ½"s Akane Tendo is closer to how they would later typically be portrayed in the 2000s. He also suggested that one could argue "Ranma" is an early example of a harem or reverse harem series, due to the main character attracting suitors in both genders.
In an overview of the series, Jason Thompson called "Ranma ½" "the direct ancestor of all comedy-action manga, like "Sumomomo Momomo" and "History's Strongest Disciple Kenichi"", although noted that it was not the first, but only spanned the period when manga and anime sales were at their height. Relating it to Takahashi's other works, he summed the series up as "At the start, the fighting is minimal and it's almost a semi-serious relationship comedy, like "Maison Ikkoku"; then it turns completely ridiculous; and by the climax, when Ranma fights the evil bird-people of Phoenix Mountain in an excessively long and un-funny shonen fight scene, it's like a warmup for "Inuyasha"." He states that "Eventually Takahashi adds too many characters, and the manga starts repeating itself. Because of the lack of a strong story arc, a lot of people stop reading "Ranma ½" at some point in the middle". Reviewing Viz Media's final English volume of the manga, Anime News Network remarked that "Every dimension of Rumiko Takahashi's storytelling skills come into play here: comedy, romance and introspection, and of course, high-flying fantasy martial-arts action." However, they felt some of the action scenes were hard to follow and noted that the mirroring to left-to-right format caused errors with the art.
The "Ranma ½" anime was ranked number 17 on "Anime Insider"'s 2001 list of the Top 50 Anime, although the list was limited to series that were released in North America. It ranked 36th on TV Asahi's 2006 list of Japan's 100 favorite animated TV series, which is based on an online poll of the Japanese people, up from the previous year's list where it ranked 45th. In November 2006, the New York Comic Con announced that it would host the first-ever American Anime Awards. Fans had the chance to vote for their favorite anime online during the month of January 2007. Only the five nominees receiving the most votes for each category were announced on February 5. Among the 12 different categories, "Ranma ½" was voted into the "Best Comedy Anime" category, and the "Ranma ½" OVAs were voted into the "Best Short Series" category. In their review of Viz Media's season five DVD box set, Anime News Network praised the Japanese cast's performance and the animation, but criticized the English version's slight script changes and minor voice actors while praising its main cast. They also remarked that while "Ranma ½" is a classic, after a hundred episodes, the same jokes are just not funny anymore. THEM Anime Reviews' Raphael See called the television series and the OVAs "one of the funniest things [he's] ever seen, anime or otherwise" and also praised the English dub as some of the best. However, he was much more critical of the first two movies particularly for both using the same damsel in distress plot.

</doc>
<doc id="26327" url="https://en.wikipedia.org/wiki?curid=26327" title="Royal Australian Navy">
Royal Australian Navy

The Royal Australian Navy (RAN) is the naval branch of the Australian Defence Force. Following the Federation of Australia in 1901, the ships and resources of the separate colonial navies were integrated into a national force: the Commonwealth Naval Forces. Originally intended for local defence, the navy was granted the title of 'Royal Australian Navy' in 1911, and became increasingly responsible for defence of the region.
Britain's Royal Navy continued to support the RAN and provided additional blue-water defence capability in the Pacific up to the early years of World War II. Then, rapid wartime expansion saw the acquisition of large surface vessels and the building of many smaller warships. In the decade following the war, the RAN acquired a small number of aircraft carriers, the last of these paying off in 1982.
Today, the RAN consists of 47 commissioned vessels, 3 non-commissioned vessels and over 16,000 personnel. The navy is one of the largest and most sophisticated naval forces in the South Pacific region, with a significant presence in the Indian Ocean and worldwide operations in support of military campaigns and peacekeeping missions. The current Chief of Navy is Vice Admiral Tim Barrett.
History.
The Commonwealth Naval Forces were established on 1 March 1901, two months after the federation of Australia, when the naval forces of the separate Australian colonies were amalgamated. A period of uncertainty followed as the policy makers sought to determine the newly established force's requirements and purpose, with the debate focusing upon whether Australia's naval force would be structured mainly for local defence or whether it would be designed to serve as a fleet unit within a larger imperial force, controlled centrally by the British Admiralty. In 1908–09, the decision was made to pursue a compromise solution and Australia agreed to establish a force that would be used for local defence but which would be capable of forming a fleet unit within the imperial naval strategy, albeit without central control. As a result, the navy's force structure was set at "one battlecruiser, three light cruisers, six destroyers and three submarines".
On 10 July 1911, King George V granted the title of "Royal Australian Navy". The first of the RAN's new vessels, the destroyer "Yarra", was completed in September 1910 and by the outbreak of World War I, the majority of the RAN's new fleet had been realised. The Australian Squadron was placed under control of the British Admiralty, and initially it was tasked with capturing many of Germany's South Pacific colonies and protecting Australian shipping from the German East Asia Squadron. Later in the war, most of the RAN's major ships operated as part of Royal Navy forces in the Mediterranean and North Seas, and then later in the Adriatic, and then the Black Sea following the surrender of the Ottoman Turkish Empire.
In 1919, the RAN received a force of six destroyers, three sloops and six submarines from the Royal Navy, but throughout the 1920s and early 1930s, the RAN was drastically reduced in size due to a variety of factors including political apathy and economic hardship as a result of the Great Depression. In this time the focus of Australia's naval policy shifted from defence against invasion to trade protection, and several fleet units were sunk as targets or scrapped. In 1923, the size of the navy had fallen to eight vessels, and by the end of the decade it had fallen further to five, with just 3,500 personnel. In the late 1930s, as international tensions increased, the RAN was modernised and expanded, with the service receiving primacy of funding over the Army and Air Force during this time as Australia began to prepare for war.
Early in World War II, RAN ships again operated as part of Royal Navy formations, many serving with distinction in the Mediterranean, the Red Sea, the Persian Gulf, the Indian Ocean and off the West African coast. Following the outbreak of the Pacific War and the virtual destruction of British naval forces in south-east Asia, the RAN operated more independently, or as part of United States Navy forces. As the navy took on an even greater role, it was expanded significantly and at its height the RAN was the fourth-largest navy in the world, with 39,650 personnel operating 337 warships. A total of 34 vessels were lost during the war, including three cruisers and four destroyers.
After World War II, the size of the RAN was again reduced, but it gained new capabilities with the delivery of two aircraft carriers. The RAN saw action in many Cold War–era conflicts in the Asia-Pacific region and operated alongside the Royal Navy and United States Navy off Korea, Malaysia and Vietnam. Since the end of the Cold War, the RAN has been part of Coalition forces in the Persian Gulf and Indian Ocean, operating in support of Operation Slipper and undertaking counter piracy operations. It also deployed in support of Australian peacekeeping operations in East Timor and the Solomon Islands.
RAN today.
Command structure.
The strategic command structure of the RAN was overhauled during the New Generation Navy changes. The RAN is commanded through Naval Headquarters (NHQ) in Canberra. The professional head is the Chief of Navy (CN), who holds the rank of Vice Admiral. NHQ is responsible for implementing policy decisions handed down from the Department of Defence and for overseeing tactical and operational issues that are the purview of the subordinate commands.
Beneath NHQ are two subordinate commands:
Fleet Command was previously made up of seven Force Element Groups, but after the New Generation Navy changes, this was restructured into four Force Commands:
Fleet.
As of January 2016, the RAN fleet consists of 47 warships, including frigates, submarines, patrol boats and auxiliary ships. Ships commissioned into the RAN are given the prefix HMAS (His/Her Majesty's Australian Ship).
The RAN has two primary bases for its fleet:
In addition, three other bases are home to the majority of the RAN's minor war vessels:
Current ships.
The RAN currently operates 47 commissioned vessels, made up of eight ship classes and three individual ships, plus three non-commissioned vessels.
Aviation.
Fleet Air Arm.
The Fleet Air Arm (previously known as the Australian Navy Aviation Group) provides the RAN's aviation capability. As of 2013, the FAA consists of three active squadrons plus a fourth being activated, operating five helicopter types in the anti-submarine warfare and maritime support roles. The Fleet Air Arm is based at in Nowra, New South Wales, and operates from the RAN's frigates, large amphibious warfare vessels, and large support ships.
LADS Flight.
In addition to the helicopter squadrons of the Fleet Air Arm, the RAN operates an additional flying unit that comes under the operational responsibility of the Australian Hydrographic Service. The Laser Airborne Depth Sounder Flight contains the sole remaining fixed-wing aircraft operated by the RAN, and is based at in Cairns, Queensland.
Clearance Diving Branch.
The Clearance Diving Branch is composed of two "Clearance Diving Teams" (CDT) that serve as parent units for naval clearance divers:
When clearance divers are sent into combat, Clearance Diving Team Three (AUSCDT THREE) is formed.
The CDTs have two primary roles:
Future.
There are currently several major projects underway that will see upgrades to RAN capabilities:
To boost the RAN's amphibious capability during the construction of the "Canberra"-class LHDs, the RAN acquired (a former Bay-class landing ship of the British Royal Fleet Auxiliary) in December 2011, and the support vessel in June 2012.
Future procurement plans include:
Current operations.
The RAN currently has forces deployed on four major operations:
Personnel.
As of June 2011, the RAN has 14,215 permanent full-time personnel, 161 gap year personnel, and 2,150 reserve personnel. The permanent full-time force consisted of 3,357 commissioned officers, and 10,697 enlisted personnel. In June 2010, male personnel made up 82% of the permanent full-time force, while female personnel made up 18%. The RAN has the highest percentage of women in the ADF, compared to the RAAF's 17.8% and the Army's 9.7%.
The following are the current senior Royal Australian Navy officers:
The RAN needs 2,000 recruits, including 700 apprentices, to crew the next generation of warships, such as air warfare destroyers, which enter service next decade. To overcome a lack of Australian recruits, the RAN began to recruit sailors who have been laid off from other western navies.
Ranks and uniforms.
The uniforms of the Royal Australian Navy are very similar in cut, colour and insignia to their British Royal Navy forerunners. However, beginning with the Second World War all RAN personnel began wearing shoulder flashes reading "Australia", a practice continuing today. These are cloth arcs at shoulder height on uniforms, metallic gold on officers' shoulder boards, and embroidered on shoulder slip-ons.
Commissioned officers.
Commissioned officers of the Australian Navy have pay grades ranging from S-1 to O-11. The only O-11 position in the navy is honorary and has only ever been held by royalty, currently being held by HRH The Duke of Edinburgh. The highest position occupied in the current Royal Australian Navy structure is O-9, a vice admiral who serves as the Chief of the Navy. O-8 (rear admiral) to O-11 (admiral of the fleet) are referred to as flag officers, O-5 (commander) and above are referred to as senior officers, while S-1 (midshipman) to O-4 (lieutenant commander) are referred to as junior officers. All officers of the Navy receive a commission from Her Majesty Queen Elizabeth II, Queen of Australia. The Commissioning Scroll issued in recognition of the commission is signed by the Governor General of Australia as Commander-in-Chief and the serving Minister for Defence.
Naval officers are trained at the Royal Australian Naval College (HMAS "Creswell") in Jervis Bay, New South Wales and the Australian Defence Force Academy in Canberra.
Other ranks.
Royal Australian Navy Other Ranks wear "right arm rates" insignia, called "Category Insignia" to indicate speciality training qualifications. The use pattern mirrors that of the Royal Navy, and has since formation. Stars or a Crown are added to these to indicate higher qualifications.
Special insignia.
The Warrant Officer of the Navy (WO-N) is an appointment held by the most senior sailor in the RAN, and holds the rank of warrant officer (WO). However, the WO-N does not wear the WO rank insignia; instead, they wear the special insignia of the appointment. The WO-N appointment has similar equivalent appointments in the other services, each holding the rank of warrant officer, each being the most senior sailor/soldier/airman in that service, and each wearing their own special insignia rather than their rank insignia. The Australian Army equivalent is the Regimental Sergeant Major of the Army (RSM-A) and the Royal Australian Air Force equivalent is the Warrant Officer of the Air Force (WOFF-AF).

</doc>
<doc id="26328" url="https://en.wikipedia.org/wiki?curid=26328" title="Royal Australian Air Force">
Royal Australian Air Force

The Royal Australian Air Force (RAAF), formed March 1921, is the aerial warfare branch of the Australian Defence Force. It directly continues the traditions of the second oldest Air Force in the world, the Australian Flying Corps (AFC), formed on 22 October 1912. The RAAF provides support across a spectrum of operations such as air superiority, precision strikes, intelligence, surveillance and reconnaissance, air mobility, and humanitarian support.
The RAAF has taken part in many of the 20th century's major conflicts. During the Second World War a number of RAAF bomber, fighter, reconnaissance and other squadrons served initially in Britain, and with the Desert Air Force located in North Africa and the Mediterranean, while the majority were later primarily deployed in the South West Pacific Area. Thousands of Australians also served with other Commonwealth air forces in Europe. By the time the war ended, a total of 216,900 men and women served in the RAAF, of whom 10,562 were killed in action.
Later the RAAF served in the Berlin Airlift, Korean War, Malayan Emergency, Indonesia–Malaysia Confrontation and Vietnam War. More recently, the RAAF has participated in operations in East Timor, the Iraq War, the War in Afghanistan, and the military intervention against ISIL.
The RAAF has 259 aircraft, of which 110 are combat aircraft.
History.
Formation, 1912.
The RAAF traces its history back to the Imperial Conference held in London in 1911, where it was decided aviation should be developed within the armed forces of the British Empire. Australia implemented this decision, the first dominion to do so, by approving the establishment of the "Australian Aviation Corps", which initially consisted of the Central Flying School at Point Cook, Victoria, on 22 October 1912. By 1914 the corps was known as the "Australian Flying Corps".
First World War.
Soon after the outbreak of war in 1914, the Australian Flying Corps sent aircraft to assist in capturing German colonies in what is now north-east New Guinea. However, these colonies surrendered quickly, before the planes were even unpacked. The first operational flights did not occur until 27 May 1915, when the Mesopotamian Half Flight was called upon to assist the Indian Army in protecting British oil interests in what is now Iraq.
The corps later saw action in Egypt, Palestine and on the Western Front throughout the remainder of the First World War. By the end of the war, four squadrons—Nos. 1, 2, 3 and 4—had seen operational service, while another four training squadrons—Nos. 5, 6, 7 and 8—had also been established. A total of 460 officers and 2,234 other ranks served in the AFC, whilst another 200 men served as aircrew in the British flying services. Casualties included 175 dead, 111 wounded, 6 gassed and 40 captured.
Inter-war period.
The Australian Flying Corps remained part of the Australian Army until 1919, when it was disbanded along with the First Australian Imperial Force (AIF). Although the Central Flying School continued to operate at Point Cook, military flying virtually ceased until 1920, when the Australian Air Corps (AAC) was formed. The Australian Air Force was formed on 31 March 1921. King George V approved the prefix "Royal" in June 1921 and became effective on 31 August 1921. The RAAF then became the second Royal air arm to be formed in the British Commonwealth, following the British Royal Air Force. When formed the RAAF had more aircraft than personnel, with 21 officers and 128 other ranks and 153 aircraft.
Second World War.
Europe and the Mediterranean.
In September 1939, the RAAF's Air Board directly controlled the Air Force via RAAF Station Laverton, RAAF Station Richmond, RAAF Station Pearce, No. 1 Flying Training School RAAF at Point Cook, RAAF Station Rathmines and five smaller units.
In 1939, just after the outbreak of the Second World War, Australia joined the Empire Air Training Scheme, under which flight crews received basic training in Australia before travelling to Canada for advanced training. A total of 17 RAAF bomber, fighter, reconnaissance and other squadrons served initially in Britain and with the Desert Air Force located in North Africa and the Mediterranean. Thousands of Australians also served with other Commonwealth air forces in Europe during the Second World War. About nine percent of the personnel who served under British RAF commands in Europe and the Mediterranean were RAAF personnel.
With British manufacturing targeted by the German Luftwaffe, in 1941 the Australian government created the Department of Aircraft Production (DAP; later known as the Government Aircraft Factory) to supply Commonwealth air forces, and the RAAF was eventually provided with large numbers of locally built versions of British designs such as the DAP Beaufort torpedo bomber, Beaufighters and Mosquitos, as well as other types such as Wirraways, Boomerangs, and Mustangs.
In the European theatre of the war, RAAF personnel were especially notable in RAF Bomber Command: although they represented just two percent of all Australian enlistments during the war, they accounted for almost twenty percent of those killed in action. This statistic is further illustrated by the fact that No. 460 Squadron RAAF, mostly flying Avro Lancasters, had an official establishment of about 200 aircrew and yet had 1,018 combat deaths. The squadron was therefore effectively wiped out five times over. Total RAAF casualties in Europe were 5,488 killed or missing.
Pacific War.
The beginning of the Pacific War—and the rapid advance of Japanese forces—threatened the Australian mainland for the first time in its history. The RAAF was quite unprepared for the emergency, and initially had negligible forces available for service in the Pacific. In 1941 and early 1942, many RAAF airmen, including Nos. 1, 8, 21 and 453 Squadrons, saw action with the RAF Far East Command in the Malayan, Singapore and Dutch East Indies campaigns. Equipped with aircraft such as the Brewster Buffalo, and Lockheed Hudsons, the Australian squadrons suffered heavily against Japanese Zeros.
During the fighting for Rabaul in early 1942, No. 24 Squadron RAAF fought a brief, but ultimately futile defence as the Japanese advanced south towards Australia. The devastating air raids on Darwin on 19 February 1942 increased concerns about the direct threat facing Australia. In response, some RAAF squadrons were transferred from the northern hemisphere—although a substantial number remained there until the end of the war. Shortages of fighter and ground attack planes led to the acquisition of US-built P-40 Kittyhawks and the rapid design and manufacture of the first Australian fighter, the CAC Boomerang. RAAF Kittyhawks came to play a crucial role in the New Guinea and Solomon Islands campaigns, especially in operations like the Battle of Milne Bay. As a response to a possible Japanese chemical warfare threat the RAAF imported hundreds of thousands of chemical weapons into Australia.
In the Battle of the Bismarck Sea, imported Bristol Beaufighters proved to be highly effective ground attack and maritime strike aircraft. Beaufighters were later made locally by the DAP from 1944. Although it was much bigger than Japanese fighters, the Beaufighter had the speed to outrun them. The RAAF's heavy bomber force was predominantly made up of 287 B-24 Liberators, equipping seven squadrons, which could bomb Japanese targets as far away as Borneo and the Philippines from airfields in Australia and New Guinea. By late 1945, the RAAF had received or ordered about 500 P-51 Mustangs, for fighter/ground attack purposes. The Commonwealth Aircraft Corporation initially assembled US-made Mustangs, but later manufactured most of those used.
By mid-1945, the RAAF's main operational formation in the Pacific, the First Tactical Air Force (1st TAF), consisted of over 21,000 personnel, while the RAAF as a whole consisted of about 50 squadrons and 6,000 aircraft, of which over 3,000 were operational. The 1st TAF's final campaigns were fought in support of Australian ground forces in Borneo, but had the war continued some of its personnel and equipment would likely have been allocated to the invasion of the Japanese mainland, along with some of the RAAF bomber squadrons in Europe, which were to be grouped together with British and Canadian squadrons as part of the proposed Tiger Force. However, the war was brought to a sudden end by the US nuclear attacks on Japan. The RAAF's casualties in the Pacific were around 2,000 killed, wounded or captured.
By the time the war ended, a total of 216,900 men and women served in the RAAF, of whom 10,562 were killed in action; a total of 76 squadrons were formed. With over 152,000 personnel operating nearly 6,000 aircraft it was the world's fourth largest air force.
Service since 1945.
During the Berlin Airlift, in 1948–49, the RAAF Squadron Berlin Air Lift aided the international effort to fly in supplies to the stricken city; two RAF Avro York aircraft were also crewed by RAAF personnel. Although a small part of the operation, the RAAF contribution was significant, flying 2,062 sorties and carrying 7,030 tons of freight and 6,964 passengers.
In the Korean War, from 1950–53, Mustangs from No. 77 Squadron RAAF, stationed in Japan with the British Commonwealth Occupation Force, were among the first United Nations aircraft to be deployed, in ground support, combat air patrol, and escort missions. When the UN planes were confronted by MiG-15 jet fighters, 77 Sqn acquired Gloster Meteors, which enabled some success against the Soviet pilots flying for North Korea. However, the MiGs were superior aircraft and the Meteors were relegated to ground support missions, as the North Koreans gained experience. The air force also operated transport aircraft during the conflict. No. 77 Squadron flew 18,872 sorties, claiming the destruction of 3,700 buildings, 1,408 vehicles, 16 bridges, 98 railway carriages and an unknown number of enemy personnel. Three MiG-15s were confirmed destroyed, and two others probably destroyed. RAAF casualties included 41 killed and seven captured; 66 aircraft – 22 Mustangs and 44 Meteors – were lost.
In July 1952, No. 78 Wing RAAF was deployed to Malta in the Mediterranean where it formed part of a British force which sought to counter the Soviet Union's influence in the Middle East as part of Australia's Cold War commitments. Consisting of No. 75 and 76 Squadrons equipped with de Havilland Vampire jet fighters, the wing provided an air garrison for the island for the next two and half years, returning to Australia in late 1954.
In 1953, a Royal Air Force officer, Air Marshal Sir Donald Hardman, was brought out to Australia to become Chief of the Air Staff. He reorganised the RAAF into three commands: Home Command, Maintenance Command, and RAAF Training Command. Five years later the commands were reorganised as Operational Command and RAAF Support Command. Support Command was made responsible for initial training, supply, administration and distribution of all aircraft, stores, and equipment, for maintenance, repair, and other administration.
In the Malayan Emergency, from 1950–60, six Avro Lincolns from No. 1 Squadron RAAF and a flight of Douglas Dakotas from No. 38 Squadron RAAF took part in operations against the communist guerrillas (labelled as "Communist Terrorists" by the British authorities) as part of the RAF Far East Air Force. The Dakotas were used on cargo runs, in troop movement and in paratroop and leaflet drops within Malaya. The Lincolns, operating from bases in Singapore and from Kuala Lumpur, formed the backbone of the air war against the CTs, conducting bombing missions against their jungle bases. Although results were often difficult to assess, they allowed the government to harass CT forces, attack their base camps when identified and keep them on the move. Later, in 1958, Canberra bombers from No. 2 Squadron RAAF were deployed to Malaya and took part in bombing missions against the CTs.
During the Vietnam War, from 1964–72, the RAAF contributed Caribou STOL transport aircraft as part of the RAAF Transport Flight Vietnam, later redesignated No. 35 Squadron RAAF, UH-1 Iroquois helicopters from No. 9 Squadron RAAF, and English Electric Canberra bombers from No. 2 Squadron RAAF. The Canberras flew 11,963 bombing sorties, and two aircraft were lost. One went missing during a bombing raid. The wreckage of the aircraft was recovered in April 2009, and the remains of Flying Officer Michael Herbert and Pilot Officer Robert Carver were found in late July 2009. The other was shot down by a surface-to-air missile, although both crew were rescued. They dropped 76,389 bombs and were credited with 786 enemy personnel confirmed killed and a further 3,390 estimated killed, 8,637 structures, 15,568 bunkers, 1,267 sampans and 74 bridges destroyed. RAAF transport aircraft also supported anti-communist ground forces. The UH-1 helicopters were used in many roles including medical evacuation and close air support. RAAF casualties in Vietnam included six killed in action, eight non-battle fatalities, 30 wounded in action and 30 injured. A small number of RAAF pilots also served in United States Air Force units, flying F-4 Phantom fighter-bombers or serving as forward air controllers.
Military airlifts were conducted for a number of purposes in the intervening decades, such as the peacekeeping operations in East Timor from 1999. Australia's combat aircraft were not used again in combat until the Iraq War in 2003, when 14 F/A-18s from No. 75 Squadron RAAF operated in the escort and ground attack roles, flying a total of 350 sorties and dropping 122 laser-guided bombs. A detachment of AP-3C Orion maritime patrol aircraft were deployed in the Middle East between 2003 and 2012. These aircraft conducted maritime surveillance patrols over the Persian Gulf and North Arabian Sea in support of Coalition warships and boarding parties, as well as conducting extensive overland flights of Iraq and Afghanistan on intelligence, surveillance and reconnaissance missions, and supporting counter-piracy operations in Somalia.
From 2007 to 2009, a detachment of No. 114 Mobile Control and Reporting Unit RAAF was on active service at Kandahar Airfield in southern Afghanistan.
Approximately 75 personnel deployed with the AN/TPS-77 radar assigned the responsibility to co-ordinate coalition air operations. A detachment of IAI Heron unmanned aerial vehicles has been deployed in Afghanistan since January 2010.
In late September 2014, an Air Task Group consisting of up to eight F/A-18F Super Hornets, a KC-30A Multi Role Tanker Transport, a E-7A Wedgetail Airborne Early Warning & Control aircraft and 400 personnel was deployed to Al Minhad Air Base in the United Arab Emirates as part of the coalition to combat Islamic State forces in Iraq. Operations began on 1 October. A number of C-17 and C-130J Super Hercules transport aircraft based in the Middle East have also been used to conduct airdrops of humanitarian aid and to airlift arms and munitions since August.
Ranks and uniform.
The rank structure of the nascent RAAF was established within the context of the desire to ensure that the service remained separate from both the Army and Navy. While the service's predecessor formations, the AFC and the AAC, had used the Army's rank structure, in November 1920, just prior to the RAAF's foundation, it was decided by the Air Board that the RAAF would adopt the rank structure that had been implemented in the RAF the previous year. As a result, the RAAF's rank structure came to be: Aircraftsman, Leading Aircraftsman, Corporal, Sergeant, Flight Sergeant, Warrant Officer, Pilot Officer, Flying Officer. Flight Lieutenant, Squadron Leader, Wing Commander, Group Captain, Air Commodore, Air Vice Marshal, Air Marshal, Air Chief Marshal, Marshal of the RAAF.
In 1922, the colour of the RAAF winter uniform was determined by Williams on a visit to the Geelong Wool Mill. He asked for one dye dip fewer than the RAN blue (three indigo dips rather than four). There was a change to a lighter blue when an all-seasons uniform was introduced in the 1970s. The original colour and style were re-adopted around 2005. Slip-on rank epaulettes, known as "Soft Rank Insignia" (SRI), displaying the word "AUSTRALIA" are worn on the shoulders of the service dress uniform. When not in the service dress or "ceremonial" uniform, RAAF personnel wear the Auscam DPCU as a working dress. Commencing in mid-2014 DPCU began to be replaced, only in the non-deployed environment, with the General Purpose Uniform (GPU) which is a blue version of the Australian Multicam Pattern.
Roundel.
Originally, the air force used the existing red, white and blue roundel of the Royal Air Force. However, during the Second World War the inner red circle, which was visually similar to the Japanese Hinomaru, was removed after a No. 11 Squadron Catalina was mistaken for a Japanese aircraft by a US Navy Wildcat in the Pacific Theatre.
After the war, a range of options for the RAAF roundel were proposed, including the Southern Cross, a boomerang, a sprig of wattle, and the red kangaroo. On 2 July 1956, the current version of the roundel was formally adopted. This consists of a white inner circle with a red kangaroo surrounded by a royal blue circle. The kangaroo faces left, except when used on aircraft or vehicles, when the kangaroo should always face in the direction of travel. Low visibility versions of the roundel exist, with the white omitted and the red and blue replaced with light or dark grey.
Badge.
The RAAF badge was accepted by the Chester Herald in 1939. The badge is composed of the imperial crown mounted on a circle featuring the words Royal Australian Air Force, beneath which scroll work displays the Latin motto "Per Ardua Ad Astra", which it shares with the Royal Air Force. Surmounting the badge is a wedge-tailed eagle. "Per Ardua Ad Astra" is attributed with the meaning "Through Adversity to the Stars" and is from Sir Henry Rider Haggard's novel "The People of the Mist".
Current strength.
Personnel.
As of 2014, the RAAF had 13,991 permanent full-time personnel and 4,316 part-time active reserve personnel.
Roulettes.
The Roulettes are the RAAF's formation aerobatic display team. They perform around Australia and South-east Asia, and are part of the RAAF Central Flying School (CFS) at RAAF Base East Sale, Victoria. The Roulettes use the Pilatus PC-9 and formations for shows are done in a group of six aircraft. The pilots learn many formations including loops, rolls, corkscrews, and ripple roles. Most of the performances are done at the low altitude of 500 feet (150 metres).
Future procurement.
This list includes aircraft on order or a requirement which has been identified:
See also.
Lists:
Memorials and Museums:

</doc>
<doc id="26329" url="https://en.wikipedia.org/wiki?curid=26329" title="Responsible government">
Responsible government

Responsible government is a conception of a system of government that embodies the principle of parliamentary accountability, the foundation of the Westminster system of parliamentary democracy. Governments (the equivalent of the executive branch) in Westminster democracies are responsible to parliament rather than to the monarch, or, in a colonial context, to the imperial government. If the parliament is bicameral, then the government is responsible first to the parliament's lower house, which is more numerous, directly elected and thus more representative than the upper house.
Responsible government of parliamentary accountability manifests itself in several ways. Ministers account to Parliament for their decisions and for the performance of their departments. This requirement to make announcements and to answer questions in Parliament means that ministers have to have the privileges of the "floor" which are only granted to those who are members of either house of Parliament. Secondly, and most importantly, although ministers are officially appointed by the sovereign authority of the head of state and can theoretically be dismissed at the pleasure of the sovereign, they concurrently retain their office subject to their holding the confidence of the lower house of Parliament. When the lower house has passed a motion of no confidence in the government, the government must immediately resign or submit itself to the electorate in a new general election.
Lastly, the Sovereign is in turn required to effectuate their sovereignty only through these responsible ministers. He or she must never attempt to set up a "shadow" government of executives or advisors and attempt to use them as instruments of government, or to rely upon their, "unofficial" advice. He/she is bound to take no decision or action, which is put into effect under the color of his/her sovereignty, without that action being as a result of the counsel and advisement of his/her responsible ministers. His/her ministers are required to counsel him/her (i.e., explain to him/her and be sure he/she understands any issue that he/she will be called upon to decide); and, to form and have recommendations for him/her (i.e., their advice or advisement) to choose from; which are the ministers’ formal, reasoned, recommendations as to what course of action should be taken.
Canada.
In the history of Canada, responsible government was a major element of the programme of development towards independence. The concept of responsible government is associated in Canada more with self-government than with parliamentary accountability; hence the notion that Newfoundland "gave up responsible government" when it suspended its self-governing status in 1933.
In the aftermath of the American Revolution, the British government was sensitive to unrest in its remaining colonies with large populations of British colonists. After the 1837 Lower Canada Rebellion led by Louis-Joseph Papineau, and the 1837–1838 Upper Canada Rebellion led by William Lyon Mackenzie, Lord Durham was appointed governor general of British North America and had the task of examining the issues and determining how to defuse tensions. In his report, one of his recommendations was that colonies which were developed enough should be granted "responsible government". This term specifically meant the policy that British-appointed governors should bow to the will of elected colonial assemblies.
The first instance of responsible government in the British Empire outside of the United Kingdom itself was achieved by the colony of Nova Scotia in January–February 1848 through the efforts of Joseph Howe. The plaque in the Nova Scotia House of Assembly erected by the Historic Sites and Monuments Board of Canada reads:
First Responsible Government in the British Empire.<br>
The first Executive Council chosen exclusively from the party having a majority in the representative branch of a colonial legislature was formed in Nova Scotia on 2 February 1848. Following a vote of want of confidence in the preceding Council, James Boyle Uniacke, who had moved the resolution, became Attorney General and leader of the Government. Joseph Howe, the long-time campaigner for this "Peaceable Revolution", became Provincial Secretary. Other members of the Council were Hugh Bell, Wm. F. Desbarres, Lawrence O.C. Doyle, Herbert Huntingdon, James McNab, Michael Tobin, and George R. Young.
The colony of New Brunswick soon followed in May 1848 when Lieutenant Governor Edmund Walker Head brought in a more balanced representation of Members of the Legislative Assembly to the Executive Council and ceded more powers to that body.
In the Province of Canada, responsible government was put to the test in 1849, when Reformers in the legislature passed the Rebellion Losses Bill. This was a law that provided compensation to French-Canadians who suffered losses during the Rebellions of 1837–1838 in Lower-Canada. 
The Governor General, Lord Elgin, had serious misgivings about the bill but nonetheless assented to it despite demands from the Tories that he refuse to do so. Elgin was physically assaulted by an English-speaking mob for this, and the Montreal Parliament building was burned to the ground in the ensuing riots. Nonetheless, the Rebellion Losses Bill helped entrench responsible government into Canadian politics.
In time, the granting of responsible government became the first step on the road to complete independence. Canada gradually gained greater and greater autonomy over a considerable period of time through inter imperial and commonwealth diplomacy, including the British North America Act of 1867, the Statute of Westminster of 1931, and even as late as the patriation of the British North America Act in 1982 (see Constitution of Canada).
Australia and New Zealand.
While the various colonies in Australia were either sparsely populated or penal settlements or both, executive power was in the hands of the Governors, who, because of the great distance from their superiors in London and the resulting very slow communication, necessarily exercised vast powers.
However, the early colonists, coming mostly from the United Kingdom, were familiar with the Westminster system and made efforts to reform it to increase the opportunity for ordinary men to participate.
The Governors and London therefore set in motion a gradual process of establishing a Westminster system in the colonies, not so fast as to get ahead of population or economic growth, nor so slow as to provoke clamouring for revolutionary change as happened in America. Initially, this took the form of appointed or partially elected Legislative Councils. Then, during the 1850s, all Australian colonies except Western Australia, along with New Zealand, established both representative and responsible government; Western Australia did the same in 1890.
Cape Colony.
The Cape Colony, in Southern Africa, was under responsible self-government from 1872 until 1910 when it became the Cape Province of the new Union of South Africa.
Under its previous system of representative government, the Ministers of the Cape Government reported directly to the British Imperial Governor, and not to the locally elected representatives in the Cape Parliament. Among Cape citizens of all races, growing anger at their powerlessness in influencing unpopular imperial decisions had repeatedly led to protests and rowdy political meetings – especially during the early "Convict Crisis" of the 1840s.
A popular political movement for responsible government soon emerged, under local leader John Molteno. A protracted struggle was then conducted over the ensuing years as the movement (known informally as "the responsibles") grew increasingly powerful, and used their parliamentary majority to put pressure on the British Governor, withholding public finances from him, and conducting public agitations. Not everyone favoured responsible government though, and pro-imperial press outlets even accused the movement of constituting "crafts and assaults of the devil".
Finally, in 1872, the Colonial Office and new Governor Henry Barkly were won over, and Molteno instituted responsible government, making the Ministers directly responsible to the Cape Parliament, and becoming the Cape's first Prime Minister.
The ensuing period saw an economic recovery, a massive growth in exports and an expansion of the colony's frontiers. Despite political complications that arose from time to time (such as an ill-fated scheme by the British Colonial Office to enforce a confederation in Southern Africa in 1878, and tensions with the Afrikaner-dominated Government of Transvaal over trade and railroad construction), economic and social progress in the Cape Colony continued at a steady pace until a renewed attempt to extend British control over the hinterland caused the outbreak of the Anglo-Boer Wars in 1899.
An important feature of the Cape Colony under responsible government was that it was the only state in southern Africa (and one of very few in the world at the time) to have a non-racial system of voting.
Later however – following the South Africa Act 1909 to form the Union of South Africa – this multi-racial universal suffrage was steadily eroded, and eventually abolished by the Apartheid government in 1948.

</doc>
<doc id="26332" url="https://en.wikipedia.org/wiki?curid=26332" title="Rural flight">
Rural flight

Rural flight (or rural exodus) is the migratory pattern of peoples from rural areas into urban areas. It is urbanization seen from the rural perspective.
In modern times, it often occurs in a region following the industrialization of agriculture—when fewer people are needed to bring the same amount of agricultural output to market—and related agricultural services and industries are consolidated. Rural flight is exacerbated when the population decline leads to the loss of rural services (such as business enterprises and schools), which leads to greater loss of population as people leave to seek those features.
This phenomenon was first articulated through Ernst Georg Ravenstein's Laws of migration in the 1880s, upon which modern theories are based.
Historical trends.
Prior to the Industrial Revolution, rural flight occurred in mostly localized regions. Pre-industrial societies did not experience large rural-urban migration flows primarily due to the inability of cities to support large populations. Lack of large employment industries, high urban mortality, and low food supplies all served as checks keeping pre-industrial cities much smaller than their modern counterparts. Ancient Athens and Rome, scholars estimate, had peak populations of 80,000 and 500,000 paling in comparison with their current populations.
The onset of the Industrial Revolution in Europe in the late 19th century removed many of the checks that had previously constrained urban populations. As food supplies increased and stabilized and industrialized centers moved into place, cities began to support larger populations, sparking the beginning of rural flight on a massive scale. The United Kingdom went from having 20% of the population living in urban areas in 1800 to more than 70% by 1925. While the late 19th century and early 20th century saw much of rural flight focused in Western Europe and the United States, as industrialization spread throughout the world during the 20th century, rural flight and urbanization followed quickly behind. Today, rural flight is an especially distinctive phenomenon in some of the newer urbanized areas including China and more recently sub-Saharan Africa.
Dust bowl.
The shift from mixed subsistence farming to commodity crops and livestock began in the late 19th century. New capital market systems and the railroad network began the trend towards larger farms that employed fewer people per acre. These larger farms used more efficient technologies such as steel plows, mechanical reapers, and higher-yield seed stock, which reduced human input per unit of production. The other issue on the Great Plains was that people were using inappropriate farming techniques for the soil and weather conditions. Most homesteaders had family farms generally considered too small to survive (under 320 acres), and European-American subsistence farming could not continue as it was then practiced.
During the Dust Bowl and the Great Depression of the 1930s, large numbers of people fled rural areas of the Great Plains and the Midwest due to depressed commodity prices and high debt loads exacerbated by several years of drought and large dust storms. Rural flight from the Great Plains has been depicted in literature, such as John Steinbeck's novel "The Grapes of Wrath" (1939), in which a family from the Great Plains migrates to California during the Dust Bowl period of the 1930s.
Modern rural flight.
Post-World War II rural flight has been caused primarily by the spread of industrialized agriculture. Small, labor-intensive family farms have grown into, or have been replaced by, heavily mechanized and specialized industrial farms. While a small family farm typically produced a wide range of crop, garden, and animal products—all requiring substantial labor—large industrial farms typically specialize in just a few crop or livestock varieties, using large machinery and high-density livestock containment systems that require a fraction of the labor per unit produced. For example, Iowa State University reports the number of hog farmers in Iowa dropped from 65,000 in 1980 to 10,000 in 2002, while the number of hogs per farm increased from 200 to 1,400.
The consolidation of the feed, seed, processed grain, and livestock industries has meant that there are fewer small businesses in rural areas. This decrease in turn exacerbated the decreased demand for labor. Rural areas that used to be able to provide employment for all young adults willing to work in challenging conditions, increasingly provide fewer opportunities for young adults. The situation is made worse by the decrease in services such as schools, business, and cultural opportunities that accompany the decline in population, and the increasing age of the remaining population further stresses the social service system of rural areas.
Abandonment of small towns.
The rise of corporate agricultural structures directly affects small rural communities, resulting in decreased populations, decreased incomes for some segments, increased income inequality, decreased community participation, fewer retail outlets and less retail trade, and increased environmental pollution.
Determinants of rural flight.
There are several determinants, push and pull, that contribute to rural flight: lower levels of (perceived) economic opportunity in rural communities versus urban ones, lower levels of government investment in rural communities, greater education opportunities in cities, marriages, increased social acceptance in urban areas, and higher levels of rural fertility.
Economic determinants.
Some migrants choose to leave rural communities out of the desire to pursue greater economic opportunity in urban areas. Greater economic opportunities can be real or perceived. According to the Harris-Todaro Model, migration to urban areas will continue as long as "expected urban real income at the margin exceeds real agricultural product" (127). However, sociologist Josef Gugler points out that while individual benefits of increased wages may outweigh the costs of migration, if enough individuals follow this rationale, it can produce harmful effects such as overcrowding and unemployment on a national level. This phenomenon, when the rate of urbanization outpaces the rate of economic growth, is known as overurbanization. Since the industrialization of agriculture, mechanization has reduced the number of jobs present in rural communities. Some scholars have also attributed rural flight to the effects of globalization as the demand for increased economic competitiveness leads people to choose capital over labor. At the same time, rural fertility rates have historically been higher than urban fertility rates. The combination of declining rural jobs and a persistently high rural fertility rate has led to rural-urban migration streams. Rural flight also contains a positive feedback loop where previous migrants from rural communities assist new migrants in adjusting to city life. Also known as chain migration, migrant networks lower barriers to rural flight. For example, an overwhelming majority of rural migrants in China located jobs in urban areas through migrant networks.
Some families choose to send their children to cities as a form of investment for the future. A study conducted by Bates and Bennett (1974) concluded that rural communities in Zambia that had other viable investment opportunities, like livestock for instance, had lower rates of rural-urban migration as compared to regions without viable investment opportunities. Sending their children into cities can serve as long-term investments with the hope that their children will be able to send remittances back home after getting a job in the city.
Social determinants.
In other instances, rural flight may occur in response to social determinants. A study conducted in 2012 indicated that a significant proportion of rural flight in India occurred due to social factors such as migration with household, marriage, and education. Migration with households and marriage affect women in particular as most often they are the ones required to move with households and move for marriage, especially in developing regions. 
Rural youth may choose to leave their rural communities as a method of transitioning into adulthood, seeking avenues to greater prosperity. With the stagnation of the rural economy and encouragement from their parents, rural youth may choose to migrate to cities out of social norms – demonstrating leadership and self-respect. With this societal encouragement combined with depressed rural economies, rural youth form a large proportion of the migrants moving to urban areas. In Sub-Saharan Africa, a study conducted by Touray in 2006 indicated that about 15% (26 million) of urban migrants were youth. 
Lastly, natural disasters can often be single-point events that lead to temporarily massive rural-urban migration flows. The 1930s Dust Bowl in the United States for example led to the flight of 2.5 million people from the Plains by 1940, many to the new cities in the West. It is estimated that as many as 1 out of every 4 residents in the Plains States left during the 1930s. More recently, drought in Syria from 2006-2011 has prompted a rural exodus to major urban centers. Massive influxes in urban areas, combined with difficult living conditions, have prompted some scholars to link the drought to the arrival of the Arab Spring in Syria.
In the United States and Canada.
The terms are used in the United States and Canada to describe the flight of people from rural areas in the Great Plains and Midwest regions, and to a lesser extent rural areas of the northeast and southeast. It is also particularly noticeable in parts of Atlantic Canada (especially Newfoundland), since the collapse of Atlantic cod fishing fields in 1992.
China.
China, like many other currently industrializing countries, has had a relatively late start to rural flight. Until 1983, the Chinese government, through the hukou system, greatly restricted the ability of their citizens to internally migrate. Since 1983, the Chinese government has slowly lifted the restrictions upon internal migration leading to a great increase in the number of internal migrants, especially towards the city. However, even today, the hukou system limits the ability of rural migrants to receive full access to urban social services at the urban subsidized costs.
As with most examples of rural flight, several factors, both push and pull, have led towards China’s massive urbanization. Income disparity, surplus labor in rural areas due to higher average fertility rates, and improved living conditions all play a role in contributing to the flows of migrants from rural to urban areas. Approximately, 250 million rural migrants now live in cities with 54% of the total Chinese population living in urban areas.
Germany.
Middle ages.
Rural flight has been occurring to some degree in Germany since the 11th century. A corresponding principle of German law is "Stadtluft macht frei" ("city air makes you free"), in longer form "Stadtluft macht frei nach Jahr und Tag" ("city air makes you free after a year and a day"): by custom and, from 1231/32, by statute, a serf who had spent a year and a day in a city was free, and could not be reclaimed by their former master.
German "Landflucht".
"Landflucht" ("flight from the land") refers to the mass migration of peasants into the cities that occurred in Germany (and throughout most of Europe) in the late 19th century.
In 1870 the rural population of Germany constituted 64% of the population; by 1907 it had shrunk to 33%. In 1900 alone, the Prussian provinces of East Prussia, West Prussia, Posen, Silesia, and Pomerania lost about 1,600,000 people to the cities, where these former agricultural workers were absorbed into the rapidly growing factory labor class; One of the causes of this mass-migration was the decrease in rural income compared to the rates of pay in the cities.
Landflucht resulted in a major transformation of the German countryside and agriculture. Mechanized agriculture and migrant workers, particularly Poles from the east (Sachsenganger), became more common. This was especially true in the province of Posen that was gained by Prussia when Poland was partitioned. The Polish population of eastern Germany was one of the justifications for the creation of the "Polish corridor" after World War I and the absorption of the land east of the Oder-Neisse line into Poland after World War II. Also, some labor-intensive enterprises were replaced by much less labor-intensive ones such as game preserves.
The word landflucht has negative connotations in German, as it was coined by agricultural employers, often of the German aristocracy, who were lamenting their labor shortages.
Sweden.
Rural flight and out-migration in Sweden can be traced in two distinct waves. The first, beginning in the 1850s when 82% of the Swedish population lived in rural areas, and continuing till the late 1880s, was mostly due to push factors in the countryside related to poverty, unemployment, low agricultural wages, debt peonage, semi-feudalism, and religious oppression by the State church. Most of the migration was ad-hoc and directed towards emigration to the three big cities of Sweden, America, Denmark, or Germany. Many of these first emigrants were unskilled, barely literate laborers who sought farm work or daily wage labour in the cities.
The second wave started from the late 1890s and reached its peak between 1922 and 1967, with the highest rates of rural flight occurring in the 1920s and the 1950s. This was mostly "pull factors" due to the economic boom and industrial prosperity in Sweden wherein the massive economic expansion and wage increases in the urban areas pulled young people to migrate for work and at the same time drove down work opportunities in the countryside. Between 1925 and 1965, Sweden's GDP per capita increased from USD 850 to USD 6200. Simultaneously, the percentage of the population living in rural areas decreased drastically from 54% in 1925 to 21% in 1965.
Russia and the former Soviet states.
Rural flight began later for Russia and the former states of the USSR than in Western Europe. In 1926 only 18% of Russians lived in urban areas, compared to over 75% at the same time in the United Kingdom. Although the process began later, throughout World War II and the decades immediately proceeding, rural flight proceeded at a rapid pace. By 1965, 53% of Russians lived in urban areas. Statistics compiled by M. Ya Sonin, a Soviet author, in 1959, demonstrate the rapid urbanization of the USSR. Between 1939 and 1959, the rural population declined by 21.3 million, while that of urban centers increased by 39.4 million. Of this dramatic shift in population, rural flight accounts for more than 60% of the change. Generally, most rural migrants tended to settle in cities and towns within their district. Rural flight persisted through the majority of the 20th century. However, with the end of the Soviet Union, rural flight reversed as political and economic instability in the cities prompted many urban dwellers to return to rural villages. 
Rural flight did not occur uniformly throughout the USSR. Western Russia and Ukraine experienced the greatest declines in rural population, 30% and 17% respectively. Conversely, peripheral regions of the USSR, like Central Asia, experienced gains, contradicting the general pattern of rural-urban migration of this period. Increased diversification of crops and labor shortages were primary contributors to the gains in rural population in the periphery.
Rural flight in Russia and the former USSR had several major determinants. The industrialization of agriculture, which came later in Russia and the former USSR, led to declines in available rural jobs. Lower living-standards and tough work also motivated some peasants to migrate to urban areas. In particular, the Soviet "kolkhoz" system (the collective farms in the Soviet Union) aided in maintaining low living-standards for Soviet peasants. Beginning around 1928, the kolkhoz system replaced family farms throughout the Soviet Union. Forced to work long hours for low pay at rates fixed by the government and often unadjusted to inflation, Russian peasants experienced quite low living-conditions - especially compared to urban life. While Brezhnev's wage reforms in 1965 ameliorated the low wages received by peasants, rural life remained suffocating, especially for the skilled and the educated. 
Although migrants came from all segments of society, several groups were more likely to migrate than others. Like other examples of rural flight, the young were more likely than the old to migrate to the cities. Young women under 20 were the most likely segment of the population to leave rural life. This exodus of young women further exacerbated the demographic transitions occurring in rural communities as the rate of natural increase dropped precipitously over the course of the 20th century. Lastly, the skilled and educated were also likely to migrate to urban areas.
Mexico.
Rural flight in Mexico occurred throughout the 1930s up until the present day. Like other developing nations, the beginning of industrialization in Mexico quickly accelerated the rate of rural flight.
In the 1930s, President Cardenas implemented a series of agricultural reforms that led to massive redistribution of agricultural land among the rural peasants. Some commentators have subsequently dubbed the period from 1940-1965 as the "Golden Era for Mexican Migration." During this period, Mexican agriculture grew at an average rate of 5.7% outpacing the natural increase of 3% of the rural population. Concurrently, government policies favoring industrialization led to a massive increase of industrial jobs in the cities. Statistics compiled in Mexico City demonstrate this trend with over 1.8 million jobs created over the course of the 1940s, 50s, and 60s. Young people with schooling were the segment of population most likely to migrate away from rural life to urban life, attracted by the promise of many jobs and a more modern lifestyle as compared to the conservative conditions in rural villages. Additionally, due to the large demand for new workers, many of these jobs had low entrance requirements that also provided on-site job training opening the avenue for migration to many rural residents. From 1940 to about 1965, rural flight occurred in a slow, yet steady pace with both agriculture and industry growing concurrently.
However, as government policies increasingly favored industry over agriculture, rural conditions began to deteriorate. In 1957, the Mexican government began to regulate the price of maize through massive imports in order to keep low urban food costs. This regulation severely undercut the market price of maize lowering the profit margins of small farmers. At the same time, the Green Revolution had entered into Mexican agriculture. Inspired by the work of Norman Borlaug, farmers that employed hybrid seeds and fertilizer supplements were able to double or even triple their yields per acre. Unfortunately, these products came at a relatively high cost, out of the reach of many farmers struggling after the devaluation of the price of maize. The combined effects of the maize price regulation and the Green Revolution was the consolidation of small farms into larger estates. A 1974 study conducted by Osorio concluded that in 1960, about 50.3% of the individual land plots in Mexico contained less than 5 hectares of land. In contrast, the top 0.5% of estates by land spanned 28.3% of all arable land. As many small farmers lost land, they either migrated to the cities or became migrant workers roving from large estate to large estate. Between 1950 and 1970, the proportion of migrant workers increased from 36.7% to 54% of the total population. The centralized pattern of industrial development and government policies overwhelmingly favoring industrialization contributed to massive rural flight in Mexico beginning in the late 1960s until the present day.
Consequences of rural flight.
Rural migrants to cities face several challenges that may hinder their quality of life upon moving into urbanized areas. Many migrants do not have the education or skills to acquire decent jobs in cities and are then forced into unstable, low paying jobs. The steady stream of new rural migrants worsens underemployment and unemployment, common among rural migrants. Employers offer lower wages and poorer labor conditions to rural migrants, who must compete with each other for limited jobs, often unaware of their labor rights. Rural migrants often experience poor living conditions as well. Many cities have exploded in population; services and infrastructure, in these cities, are unable to keep up with population growth. Massive influxes in rural population can lead to severe housing shortages, inadequate water and energy supply, and general slum-like conditions throughout cities.
Additionally, rural migrants often struggle adjusting to city life. In some instances, there are cultural differences between the rural and urban areas of a region. Lost in urban regions, it becomes difficult for them to continue holding onto their cultural traditions. Urban residents may also look down upon these newcomers to the city who are often unaware of city social norms. Both marginalized and separated from their home cultures, migrants face many social challenges when moving to cities.
Women, in particular, face a unique set of challenges. Some women undergo rural flight to escape domestic abuse or forced early marriages. Some parents choose to send women to cities to find jobs in order to send remittances back home. Once in the city, employers may attempt to take advantage of these women preying on their unfamiliarity with labor laws and social networks on which to rely. In the worst of cases, destitution may force women into prostitution, exposing them to social stigma and the risks of sexually transmitted diseases.

</doc>
<doc id="26333" url="https://en.wikipedia.org/wiki?curid=26333" title="Robotech">
Robotech

Robotech is a science fiction franchise. The franchise began with an 85-episode science fiction anime TV series adaptation produced by Harmony Gold USA in association with Tatsunoko Production Co., Ltd. and first released in the United States in 1985. It was adapted from three original Japanese television series.
In the series, "Robotechnology" refers to the scientific advances discovered in an alien starship that crashed on a South Pacific island. With this technology, Earth developed robotic technologies, such as transformable mecha, to fight three successive extraterrestrial invasions.
Name origin.
Prior to the release of the TV series, the name "Robotech" was used by model kit manufacturer Revell on their "Robotech Defenders" line in the mid-1980s. The line consisted of mecha model kits imported from Japan and featured in anime titles such as "The Super Dimension Fortress Macross", "Super Dimension Century Orguss" and "Fang of the Sun Dougram". The kits were originally intended to be a marketing tie-in to a similarly named comic book series by DC Comics, which was cancelled after only two issues.
At the same time, Harmony Gold licensed the "Macross" TV series for direct-to-video distribution in 1984, but their merchandising plans were compromised by Revell's prior distribution of the "Macross" kits. In the end, both parties signed a co-licensing agreement and the "Robotech" name was adopted for the TV syndication of "Macross" combined with "Super Dimension Cavalry Southern Cross" and "Genesis Climber MOSPEADA".
Fictional chronology.
"The "Robotech" chronology, according to Harmony Gold, is illustrated below:
Note: Asterisked works are now considered 'secondary continuity' — that is, that their events exist in the continuity of "Robotech", but 'don't count' when conflicts arise with the primary continuity that comprises the three-part "Robotech" TV series and 2006's "".
In 2002, with the publication of the Wildstorm (DC) comics, Harmony Gold officially decided to retcon the "Robotech" Universe. The following "Robotech" material is now relegated to the status of secondary continuity:
While these materials are not precisely 'retired' or 'removed' from the continuity, their events are subject to critical review, and are strictly subordinate to the 'official' events of the 85-episode animated series.
Television and film.
The original television series.
"Robotech" is a story adapted with edited content and revised dialogue from the animation of three different mecha anime series:
Harmony Gold's cited reasoning for combining these unrelated series was its decision to market "Macross" for American weekday syndication television, which required a minimum of 65 episodes at the time (thirteen weeks at five episodes per week). "Macross" and the two other series each had fewer episodes than required, since they originally aired in Japan as weekly series. On some television stations, the syndicated run was preceded by the broadcast premiere of "", a feature-length pilot.
This combination resulted in a storyline that spans three generations, as mankind must fight three destructive 'Robotech Wars' in succession with various invading forces, each of which is motivated in one way or another by a desire for a powerful energy source called 'Protoculture'. While each of the three animated series used for its footage informs its content, the Robotech storyline is distinct and separate from each of them.
"Robotech: The Movie".
"Robotech: The Movie", also called "Robotech: The Untold Story", is a feature film and was the first new "Robotech" adventure created after the premiere of the original series. It uses footage from the "Megazone 23 Part 1" OVA (Original Video Animation; made-for-video animated feature) combined with scenes from "Southern Cross" and additional original animation produced for the film.
The original plan for the film was to have it set during the Macross Saga, parallel to the SDF-1's return to Earth from Pluto. The film would also have served as a prequel to the Sentinels, as both projects were initially meant to share many characters. Harmony Gold producer Carl Macek worked with the OVA's original creators to make the story and the new ending work. The film had to be changed again after the distributor of the film, Cannon Films, saw an incomplete rough cut of the film and were upset by it. They ordered Macek to remove multiple scenes from the film and to add more violence (most of the scenes removed were scenes setting up characters and showing female characters interacting). Macek reluctantly did what they ordered, and created a new script and rough edit for the film in less than 24 hours. When the distributors saw Macek act out the new film, they were much more pleased with the new cut. The opening night in Texas received a positive response, but Cannon Films pulled out after noting that most attendants were adults; the bulk of the scheduled advertising for the series was targeted to children. The film had limited success in Argentina and Belgium.
In 2011, A&E Home Video released, as a part of their "Robotech: The Complete Series" collection, a 29-minute version of "Robotech: The Movie" containing only footage used from "Southern Cross". There was no attempt to remaster the footage.
"Robotech Wars".
This promotional VHS tape created by Matchbox was included with their "Robotech Wars" playset. This video includes two episodes cobbled together from clips of "The Macross Saga". Titled "To the End of the Universe" and "Battle Royale", these episodes contain no new footage, and are not meant to follow any continuity established in the TV series.
"Robotech: The Sentinels".
This aborted American-produced series would have followed the continuing adventures of Rick and Lisa Hunter and the Robotech Expedition during the events of "The Masters" and "The New Generation". The feature-length pilot is composed of the first three (and only) episodes that were produced. "The Sentinels" featured characters from all three "Robotech" sagas and introduced the SDF-3 along with an overview of their new mission. The series was planned to have total of 65 episodes.
In "Robotech Art 3: The Sentinels", Carl Macek blamed the cancellation of the series on the crash of the Yen/Dollar exchange rate, which caused toy partner Matchbox to withdraw from the project. Harmony Gold lacked the funds to produce the series on its own, and production ceased after only three episodes.
"Robotech II: The Sentinels" was released on VHS by Palladium Books. In 2011, a "remastered" version was released on the A&E DVD set, "Robotech: The Complete Original Series" DVD. This version has opening titles resembling those found on the "Robotech Remastered" DVD's, as well as a new ending with text explaining the fate of the SDF-3. Also, all of the flashback footage used from "The Macross Saga" has been removed, including the re-used footage from the episode "Wedding Bells". 
Proposed sequels.
Carl Macek revealed ideas for another proposed series, "Robotech: The Odyssey", which would have picked up where "The New Generation" and end of "Robotech: The Sentinels" left off, and eventually created a circular storyline that would end where the original "Robotech" began in a giant 260-episode cycle to fill up all the weekdays in a year. According to Macek, "The Odyssey" would have involved the SDF-3 travelling back into the past to the days before the birth of Zor (as well as Scott Bernard's search for the SDF-3). The SDF-3's crew would become citizens of the Robotech Masters' homeworld and change time by becoming a part of its history. Ultimately, it would be revealed that Lynn Minmei was the mother of Zor, making Minmei the focal point of Robotech. The final episode of the Odyssey would be of Zor dying and his Super Dimension Fortress (the SDF-1) being launched into space, and eventually crash landing on Earth in 1999. The next episode after that would be "Boobytrap", episode 1 of the original series which in turn will create an endless loop within the "Robotech" universe. After the failure of "Sentinels", "Odyssey" never went into development, although some of its ideas were worked into the final Jack McKinney novel "The End of the Circle", which wrapped up all of the outstanding plot threads left by the original series and the previous "Robotech" novels.
Fan publication "Macross Life" interviewed Harmony Gold executive Richard Firth in 1986, where he revealed that Macek had "plans through "ROBOTECH V", which would give us an episode for each day of the year for a year and a half." He also said that these two installments would have brought the series to 285 episodes. Regarding the plot, Firth mentioned a "retired Commodore Hunter, whom ever that may be, could very well be speaking at the graduation of the later day cadets or whatever, and they ask him to tell them the story all over again: it comes back the first episode of the series."
Macek himself has never mentioned "Robotech IV" or "V" in any interviews or writings. Taking the three different "generations" of the original series as separate parts, and the canceled as the "fourth" part, Firth could have been referring to the proposed "Robotech: The Odyssey" as "Robotech 5", since it would be a fifth part of the overall saga.
"Robotech 3000".
Macek attempted another sequel with the development of "Robotech 3000". This all-CGI series would have been set a millennium in the future of the "Robotech" universe and feature none of the old series' characters. In the three-minute trailer, an expedition is sent to check on a non-responsive mining outpost and is attacked by "infected" Veritech mecha. The idea was abandoned midway into production after negative reception within the company, negative fan reactions at the FanimeCon anime convention in 2000, and financial difficulties within Netter Digital who was animating the show. The trailer is hosted on the official "Robotech" website, and was included in the 2007 release of the "Robotech: The Shadow Chronicles" 2-Disc Collector's DVD, along with behind-the-scenes motion capture footage.
"Robotech: Mars Force".
In October 2004, veteran animation writer and producer Greg Weisman revealed that he wrote developed an animated spin-off series titled Robotech: Mars Force 
. When asked about the project, Weisman said that he was under a non-disclosure agreement with Harmony Gold and was only allowed to mention that he developed the series.
In 2006, Harmony Gold Creative Director Tommy Yune elaborated on the project in the Space Station Liberty Podcast, saying that Mars Force was a series geared at younger audiences, following the children Robotech Expeditionary Force. A similar plot would later be used for canceled 2014 spin-off, Robotech Academy.
"Robotech UN Public Service Announcement".
A sixty-second public service announcement for the 60th anniversary of the United Nations, featuring Scott Bernard and Ariel, was animated during the production of "The Shadow Chronicles". Although it did not use the original voice actors and the dialogue was somewhat out-of-character, it nonetheless marked the first fully completed "Robotech" footage in many years.
"Robotech: The Shadow Chronicles".
In 2002, director Tommy Yune announced development of a new sequel film, which was untitled until 2004 as "Robotech: Shadow Force". The storyline overlaps with and continues from the unresolved ending of the original series. The title of the story-arc was soon changed to "". The first trailers with finished animation were shown at Anime Expo and Comic-Con International in 2005. It was not until February 2006, when Kevin McKeever, operations coordinator at Harmony Gold, was able to confirm that the pilot movie had been completed. After a series of delays, FUNimation Entertainment was finally announced as the home video, broadcast, and theatrical distributor at the 2006 Comic-Con International in San Diego with the possibility of producing further sequels. Harmony Gold premiered the movie at various film festivals in 2006, and it was first seen by a public audience at MechaCon on August 9, 2006, where it was showcased as a charity screening to help raise funds for the ongoing Hurricane Katrina and Hurricane Rita recovery effort. A limited theatrical run followed in January 2007, and the film was released on DVD on February 6, 2007. A 2-disc collector's edition was released in November 2007.
"Robotech: Love Live Alive".
First revealed in late 2011 in the final minutes of "Carl Macek's Robotech Universe", a documentary on the making of "Robotech" dedicated to the then-recent passing of Macek, "Love Live Alive" is an adaptation of the 1985 "Genesis Climber Mospeada" OVA, "Love Live Alive", incorporating some brand new animation. The film was released on DVD on July 23, 2013 by Lionsgate Home Entertainment.
"Robotech: Shadow Rising" (canceled).
On July 27, 2007, at their Comic-Con International panel, Harmony Gold and Yune unveiled the second entry of the "Shadow Chronicles" production, titled "Robotech: Shadow Rising" and was to be a co-production with FUNimation Entertainment. Pre-production reportedly began on February 2007 and a projected release date of sometime in 2009 was originally expected. Production ceased after Harmony Gold terminated their deal with FUNimation Entertainment due to creative differences.
At Comic-Con 2012, Tommy Yune announced that "Love Live Alive" would pave the way for "Shadow Rising". As of 2015, the Shadow Rising trademark remains abandoned since 2007.
"Robotech Academy" (canceled).
On July 5, 2014, Harmony Gold started a Kickstarter project for "Robotech Academy", which Macek had developed before he died. The goal of this project was to raise US$500,000 to produce a new 24-minute pilot episode. The crowdfunding project was to have closed on August 9, 2014; however, on August 2, the project was canceled with a pledge level of US$194,574, or 39% of its target. Harmony Gold however, announced that further plans to fund the project were being explored. At the 2014 Long Beach Comic Con, it was announced that the producers at Harmony Gold were in talks with at least one New media network on the prospect of producing the show. As of December 7, 2015, the project remains abandoned.
Unofficial and parody productions.
In the 1990s, Seishun Shitemasu, an anime fandubbing group, produced the parodies "Robotech III: Not Necessarily the Sentinels" and "Robotech IV: Khyron's Counterattack", using footage from, respectively, "Gunbuster/Aim For The Top!" and "", continuing the tradition of the original Robotech's adaptation of unrelated anime series into a single continuity.
On July 2, 2010, Ecuadorian animator Patricio "Pat" Mosquera uploaded to YouTube a teaser for "Robotech Skull Knights". On August 17, 2010, second teaser revealed Rick Hunter standing in front of an image of the VF-4 shown in the final episodes of the original series. "Robotech Skull Knights" has not been released yet. In July 2013, Patricio Mosquera was included as an animation director in the staff list in the IMDb page of "Love Live Alive".
On December 31, 2012, Cesar Turturro uploaded to YouTube an Argentinian fan trailer for "Robotech Valkyrie Project". On December, 2013 the first episode was uploaded to YouTube, and in January 2014, the second episode was also uploaded. The series was cancelled after Harmony Gold issued a "cease and desist" letter to the producers. The team was, however, hired to do the CGI effects for "Robotech: Academy".
Proposed live-action film.
On September 7, 2007, "The Hollywood Reporter" stated that Warner Bros. had acquired the film rights to "Robotech" and would be producing a live-action film with an as-yet-unknown release date. Tobey Maguire is producing the film through his Maguire Entertainment banner and is pursuing the lead role, in what the studio plans to be a tentpole science fiction franchise. Maguire stated, "We are very excited to bring "Robotech" to the big screen. There is a rich mythology that will be a great foundation for a sophisticated, smart and entertaining film."
In an interview, Harmony Gold representative Kevin McKeever said that Warner Bros. had approached Harmony Gold about the project, that Harmony Gold would have "a say" in its creative direction, and that it was not expected to affect the production schedule for "". He was unable to confirm any details of budget, casting, expected release date, or storyline, explaining that it was too early in the life of the project for these things to have been decided.
In June 2008, it was reported that Lawrence Kasdan had been hired to write the film, with Charles Roven and Akiva Goldsman joining Tobey Maguire as producers. During the Robotech Panel at Anime Expo 2008, the involvement of Maguire and Kasdan was confirmed, with Kasdan writing the script for the live-action film. Tommy Yune also revealed that the film is planned as a re-imagining of the original "Robotech" universe (with new updated mecha and character designs) and will take place several years in the future, departing from the original cartoon's 2009 setting.
As of November 2008, Alfred Gough and Miles Millar (who both worked in "Smallville", "Spider-Man 2", ', and ') are the writers for the film.
Roven is currently no longer working on the proposed film adaptation of the "Robotech" animated series, but he wished the remaining producers Goldsman and Maguire "fantastic luck" on the project.
The Mania.com website reported on June 23, 2009, that British television writer and novelist Tom Rob Smith "has taken over writing duties" for the proposed film adaptation. Smith wrote for the British soaps "Family Affairs" and "Bad Girls" before writing the critically acclaimed crime suspense novel "Child 44". Smith will be the fourth writer or writing team to be reportedly attached to the upcoming film's pre-production.
In early 2013, "The Hollywood Reporter" announced that Warner Bros. was in talks with commercial director Nic Mathieu to direct the film. On July 24, 2013, it was reported that Leonardo DiCaprio had turned down a role in "" and has shown interest to star as a main character in the upcoming big screen version of "Robotech". DiCaprio is a longtime friend of Tobey Maguire; they co-starred in "The Great Gatsby". Maguire will probably participate in the film as another one of the lead actors — while Nic Mathieu will direct.
On February 4, 2015, Deadline.com reported Gianni Nunori and Mark Canton selected Michael B. Gordon to write the film's script and are looking at Andy Muschietti to direct it.
On March 25, 2015, Variety announced that the "Robotech" franchise had been acquired by Sony Pictures, who views "Robotech" as a potential film franchise. On April 29, 2015, Deadline reported that James Wan is in talks to direct the film. On June 3, 2015, The Hollywood Reporter reported that Wan is confirmed to direct the film.
On July 3, 2015, Kevin McKeever of Harmony Gold announced at Anime Expo that Sony has the rights to release this film worldwide, with the exception of Japan.
On March 27, 2016, Wan told IGN that the film will follow the roots of the franchise.
As of April 4th, 2016, Harmony Gold's Kevin McKeever revealed on the official Robotech Facebook page that their deal with Sony is still not finalized.
Other media.
At the time of its broadcast, Harmony Gold also launched "Robotech" through a popular line of comics to be followed by novels, role-playing games, toys, and other consumer products. With the cancellation of "Robotech II: The Sentinels", many of these licensed products were discontinued, and led to a drought of "Robotech" product through much of the 1990s, except for publishers who continued "The Sentinels" storyline in print.
Art books.
In 1986, Starblaze Graphics published "Robotech Art 1", a reference book containing artwork, Japanese production designs, and episode guides from the original television series. This was followed by "Robotech Art 2", which was largely a collection of art by various American artists and fans. In 1988, Carl Macek collected much of the unused designs from "Robotech II: The Sentinels" into "Robotech Art 3: The Sentinels", which also included his story outline for the rest of the unfinished series, with an explanation behind its cancellation. In 2007, Stone Bridge Press published "The Art of Robotech: The Shadow Chronicles".
Comics.
"Robotech" comics were first published in 1984 with DC Comics' short-lived "Robotech Defenders" and Comico's adaptation of the first episode of the Japanese version of "Macross". However, the first adaptation of the "Robotech" television series did not arrive until 1985 with Comico's "Robotech: The Macross Saga" Number 2, which continued from the first "Macross" issue.
The various comic publishers include:
Collectible card game.
The first "Robotech" collectible card game was released in 2006 by Hero Factory, which had previously produced "Robotech" trading cards.
Music and soundtracks.
Various "Robotech" soundtracks have been released on records, cassettes, and compact discs since 1988.
Novelizations.
Since 1987, "Robotech" was adapted into novel form by "Jack McKinney", a pseudonym for the team of James Luceno and the late Brian Daley, a pair of writers who had been working with Macek since they had collaborated on the animated series "Galaxy Rangers". Using fictitious epigraphs in the style of "Dune", McKinney's novels fleshed out the chronology (including adapting the incomplete "Sentinels" source material) in far greater detail than the original animation. Many "Robotech" fans consider the McKinney series to be an unofficial canon of its own, despite notable divergences in the writing from Harmony Gold's current official animation-based canon. Despite no longer being considered core-continuity by Harmony Gold, the novels have been recently re-issued by Del Rey Books as Omnibus compilations.
Role-playing games.
In 1986, Palladium Books published a role-playing game based on the "Robotech" series, including several books covering the "Sentinels" portion of the storyline. The original "Robotech" RPG line went out of print as of June 30, 2001, but Harmony Gold and Palladium Books signed an agreement in 2007 to produce a new line of Robotech RPG books, beginning with a book covering and promoting the feature-length film "The Shadow Chronicles". The "" sourcebook first book was released on March 21, 2008, followed by sourcebooks covering the Macross, Masters, and New Generation chapters of Robotech (redrafted to reflect the Harmony Gold canon). Other sourcebooks and supplements are reflected in the Palladium Books production pipeline.
On April 18, 2013, Palladium started a campaign on the crowdfunding site Kickstarter for a tabletop miniatures game based on the Robotech RPG called "Robotech: RPG Tactics". The miniatures are being produced by Ninja Division (combining sculpting talents from Soda Pop Miniatures and Cipher Studios), and will feature multi part plastic miniatures that can be posed during assembly. The campaign reached its goal in 3 hours, and was initially scheduled to release in December 2013, but delays have persisted into late 2015.
Toys.
Action figures in the size of the three "Robotech" generations were initially released in 1985 by Matchbox toy company, but then reissued in 1992 by Harmony Gold (Lunk and Corg were only released by Matchbox and Lynn Minmei was only released by Harmony Gold). Each included a weapon and helmet where appropriate. Matchbox also released figures of Zentraedi characters from the first generation. These figures were supposed to represent the size difference between the Humans and the giant Zentraedi forces, but to be correct these figures would have to have been made about tall. None of the larger figures came with weapons but the Armored Zentraedi came with a removable helmet.
Also many toys depicting the vehicles and mecha from the series were released by Matchbox in 1985, Harmony Gold in 1992 and Playmates in 1994 (under the Exosquad line). There were major differences in packaging, toy stickers and colors between the different releases. The vehicles were designed to be used only with the 3 3/4 inch figures. The SDF-1 Playset was only released under the Matchbox line in the 1980s and could be used with both the 3 3/4 and 6 inch figures.
Harmony Gold and Matchbox were unable to sell the 1/55 VF-1 Valkyrie toy originally sold in Japan by Takatoku Toys due to Hasbro licensing it as Jetfire in the Transformers toy line. Because of this, they settled with manufacturing a non-transformable Veritech Fighter that could fit any of the 3 3/4 inch action figures, as well as importing the transformable super deformed Veritech Fighters (originally manufactured in Japan by Bandai as "Macross" VF-1 Valkyrie "Joke machines").
Since the late 1990s, there has been a resurgence of "Robotech"-related toys. In 2001, Toynami released the "Robotech Masterpiece Collection" line, featuring replicas of the Veritech Fighters of "The Macross Saga". Since then, Toynami has become the exclusive toy manufacturer of the "Robotech" franchise - having covered mecha from "The Macross Saga", "The New Generation" and "The Shadow Chronicles".
Video games.
"Robotech" spawned five video game licenses, of which the most recent three were released:
Reception of adaptation.
"Robotech" is often a polarizing subject amongst anime fans. Some critics look down upon the show for its extensive edits to the source material (Westernizing character names, editing for content and chiefly, forging a connection between previously unrelated series), while supporters of the adaptation have pointed out that the weaving of three unrelated series into a contiguous whole necessarily required reworking, and that it helped to maintain a slow but continuous rise in the consumption of anime in the US.
Series writer/actor Gregory Snegoff said in an interview on the now-defunct "Shadow Chronicles News" fansite that, "afterward, we received compliments from the Japanese who thought our dialogue and stories were better than the original," likely a reference to the creators of the latter two series, both of whom worked with the team on "The Sentinels". The producers offers "Megazone 23 Part 1" were very happy with the original plans for "" (where the incomplete film would have been added to the "Robotech" mythos to play part in "The Sentinels" storyline), and worked closely with Carl Macek to plan the new ending and animation. When the film reached a limited release, the new ending was released on a laser disc of Megazone 23, with the title "Present For You." However, "Animag" magazine (issue 11) and "Animerica" magazine (issue 9, volume 4) reports that the staff of "Macross" at Studio Nue and Artland, such as the original story creator and mecha designer Shoji Kawamori and chief director Noboru Ishiguro, expressed their concern over the "Robotech" adaptation, and surprise at its differences.
In 2009, "IGN" ranked "Robotech" as the 34th greatest animated show of all time in their Top 100 list.
Distribution.
Following the original broadcast, the series enjoyed popularity on home video in VHS and DVD formats from the following distributors:

</doc>
<doc id="26340" url="https://en.wikipedia.org/wiki?curid=26340" title="Red China">
Red China

__NOTOC__
The following articles relate to Red China:

</doc>
<doc id="26341" url="https://en.wikipedia.org/wiki?curid=26341" title="Radioteletype">
Radioteletype

Radioteletype (RTTY) is a telecommunications system consisting originally of two or more electromechanical teleprinters in different locations connected by radio rather than a wired link. These machines were later superseded by personal computers (PCs) running software to emulate teleprinters. Radioteletype evolved from earlier landline teleprinter operations that began in the mid-1800s. The US Navy Department successfully tested printing telegraphy between an airplane and ground radio station in 1922. Later that year, the Radio Corporation of America successfully tested printing telegraphy via their Chatham, Massachusetts, radio station to the R.M.S. Majestic. Commercial RTTY systems were in active service between San Francisco and Honolulu as early as April 1932 and between San Francisco and New York City by 1934. The US military used radioteletype in the 1930s and expanded this usage during World War II. From the 1980s, teleprinters were replaced by computers running teleprinter emulation software.
The term radioteletype is used to describe both the original radioteletype system, sometimes described as "Baudot", as well as the entire family of systems connecting two or more teleprinters or PCs using software to emulate teleprinters, over radio, regardless of alphabet, link system or modulation.
In some applications, notably military and government, radioteletype is known by the acronym RATT (Radio Automatic Teletype).
History.
Landline teleprinter operations began in 1849 when a circuit was put in service between Philadelphia and New York City. Émile Baudot designed a system using a five unit code in 1874 that is still in use today. Teleprinter system design was gradually improved until, at the beginning of World War II, it represented the principal distribution method used by the news services.
Radioteletype evolved from these earlier landline teleprinter operations. The US Department of the Navy successfully tested printing telegraphy between an airplane and ground radio station in August 1922. Later that year, the Radio Corporation of America successfully tested printing telegraphy via their Chatham, MA radio station to the R.M.S. Majestic. An early implementation of the Radioteletype was the Watsongraph, named after Detroit inventor Glenn Watson in March 1931. Commercial RTTY systems were in active service between San Francisco and Honolulu as early as April 1932 and between San Francisco and New York City by 1934. The US Military used radioteletype in the 1930s and expanded this usage during World War II. The Navy called radioteletype "RATT" (Radio Automatic Teletype) and the Army Signal Corps called radioteletype "SCRT", an abbreviation of Single-Channel Radio Teletype. The military used frequency shift keying technology and this technology proved very reliable even over long distances.
From the 1980s, teleprinters were replaced by computers running teleprinter emulation software.
Technical description of RTTY.
A radioteletype station consists of three distinct parts: the Teletype or teleprinter, the modem and the radio.
The Teletype or teleprinter is an electromechanical or electronic device. The word "Teletype" was a trademark of the Teletype Corporation, so the terms "TTY", "RTTY", "RATT" and "teleprinter" are usually used to describe a generic device without reference to a particular manufacturer.
Electromechanical teleprinters were heavy, complex and noisy, and have been replaced with electronic units. The teleprinter includes a keyboard, which is the main means of entering text, and a printer or visual display unit (VDU). An alternative input device is a perforated tape reader and, more recently, computer storage media (such as floppy disks). Alternative output devices are tape perforators and computer storage media.
The line output of a teleprinter can be at either digital logic levels (+5 V signifies a logical "1" or "mark" and 0 V signifies a logical "0" or "space") or line levels (-80 V signifies a "1" and +80 V a "0"). When no traffic is passed, the line idles at the "mark" state.
When a key of the teleprinter keyboard is pressed, a 5-bit character is generated. The teleprinter converts it to serial format and transmits a sequence of a "start bit" (a logical 0 or space), then one after the other the 5 data bits, finishing with a "stop bit" (a logical 1 or mark, lasting 1, 1.5 or 2 bits). When a sequence of start bit, 5 data bits and stop bit arrives at the input of the teleprinter, it is converted to a 5-bit word and passed to the printer or VDU. With electromechanical teleprinters, these functions required complicated electromechanical devices, but they are easily implemented with standard digital electronics using shift registers. Special integrated circuits have been developed for this function, for example the 6402 and 6403. These are stand-alone UART devices, similar to computer serial port peripherals.
The 5 data bits allow for only 32 different codes, which cannot accommodate the 26 letters, 10 figures, space, a few punctuation marks and the required control codes, such as carriage return, new line, bell, etc. To overcome this limitation, the teleprinter has two "states", the "unshifted" or "letters" state and the "shifted" or "numbers" or "figures" state. The change from one state to the other takes place when the special control codes "LETTERS" and "FIGURES" are sent from the keyboard or received from the line. In the "letters" state the teleprinter prints the letters and space while in the shifted state it prints the numerals and punctuation marks. Teleprinters for languages using other alphabets also use an additional "third shift" state, in which they print letters in the alternative alphabet.
The modem is sometimes called the terminal unit and is an electronic device which is connected between the teleprinter and the radio transceiver. The transmitting part of the modem converts the digital signal transmitted by the teleprinter or tape reader to one or the other of a pair of audio frequency tones, traditionally 2295/2125 Hz (US) or 2125/1955 Hz (Europe). One of the tones corresponds to the "mark" condition and the other to the "space" condition. These audio tones, then, modulate an SSB transmitter to produce the final audio-frequency shift keying (AFSK) radio frequency signal. Some transmitters are capable of direct frequency-shift keying (FSK) as they can directly accept the digital signal and change their transmitting frequency according to the "mark" or "space" input state. In this case the transmitting part of the modem is bypassed.
On reception, the FSK signal is converted to the original tones by mixing the FSK signal with a local oscillator called the BFO or "beat frequency oscillator". These tones are fed to the demodulator part of the modem, which processes them through a series of filters and detectors to recreate the original digital signal. The FSK signals are audible on a communications radio receiver equipped with a BFO, and have a distinctive "beedle-eeeedle-eedle-eee" sound, usually starting and ending on one of the two tones ("idle on mark").
The transmission speed is a characteristic of the teleprinter while the shift (the difference between the tones representing mark and space) is a characteristic of the modem. These two parameters are therefore independent, provided they have satisfied the minimum shift size for a given transmission speed. Electronic teleprinters can readily operate in a variety of speeds, but mechanical teleprinters require the change of gears in order to operate at different speeds.
Today, both functions can be performed with modern computers equipped with digital signal processors or sound cards. The sound card performs the functions of the modem and the CPU performs the processing of the digital bits. This approach is very common in amateur radio, using specialized computer programs like fldigi, MMTTY or MixW.
Before the computer mass storage era, most RTTY stations stored text on paper tape using paper tape punchers and readers. The operator would type the message on the TTY keyboard and punch the code onto the tape. The tape could then be transmitted at a steady, high rate, without typing errors. A tape could be reused, and in some cases - especially for use with ASCII on NC Machines - might be made of plastic or even very thin metal material in order to be reused many times.
The most common test signal is a series of "RYRYRY" characters, as these form an alternating tone pattern exercising all bits and are easily recognized. Pangrams are also transmitted on RTTY circuits as test messages, the most common one being "The quick brown fox jumps over the lazy dog", and in French circuits, "Voyez le brick géant que j'examine près du wharf"
Technical specification.
The original (or "Baudot") radioteletype system is based almost invariably on the Baudot code or ITA-2 5 bit alphabet. The link is based on character asynchronous transmission with 1 start bit and 1, 1.5 or 2 stop bits. Transmitter modulation is normally FSK (F1B). Occasionally, an AFSK signal modulating an RF carrier (A2B, F2B) is used on VHF or UHF frequencies. Standard transmission speeds are 45.45, 50, 75, 100, 150 and 300 baud.
Common carrier shifts are 85 Hz (used on LF and VLF frequencies), 170 Hz, 425 Hz, 450 Hz and 850 Hz, although some stations use non-standard shifts. There are variations of the standard Baudot alphabet to cover languages written in Cyrillic, Arabic, Greek etc., using special techniques.
Some combinations of speed and shift are standardized for specific services using the original radioteletype system:
Early amateur radioteletype history.
After World War II, amateur radio operators in the US started to receive obsolete but usable Teletype Model 26 equipment from commercial operators with the understanding that this equipment would not be used for or returned to commercial service. "The Amateur Radioteletype and VHF Society" was founded in 1946 in Woodside, NY. This organization soon changed its name to "The VHF Teletype Society" and started US Amateur Radio operations on 2 meters using audio frequency shift keying (AFSK). The first two-way amateur radioteletype QSO of record took place in May 1946 between Dave Winters, W2AUF, Brooklyn,NY and W2BFD, John Evans Williams, Woodside Long Island, NY. On the west coast, amateur RTTY also started on 2 meters. Operation on 80 meters, 40 meters and the other High Frequency (HF) amateur radio bands was initially accomplished using make and break keying since frequency shift keying (FSK) was not yet authorized. In early 1949, the first American transcontinental two-way RTTY QSO was accomplished on 11 meters using AFSK between Tom McMullen (W1QVF) operating at W1AW and Johnny Agalsoff, W6PSW. The stations effected partial contact on January 30, 1949, and repeated more successfully on January 31. On February 1, 1949, the stations exchanged solid print congratulatory message traffic and rag-chewed. Earlier, on January 23, 1949, William T. Knott, W2QGH, Larchmont, NY, had been able to make rough copy of W6PSW's test transmissions. While QSOs could be accomplished, it was quickly realized that FSK was technically superior to make and break keying. Due to the efforts of Merrill Swan, W6AEE, of the "The RTTY Society of Southern California" publisher of "RTTY" and Wayne Green, W2NSD, of "CQ Magazine", Amateur Radio operators successfully petitioned the U.S. Federal Communications Commission (FCC) to amend Part 12 of the Regulations, which was effective on February 20, 1953. The amended Regulations permitted FSK in the non-voice parts of the 80, 40 and 20 meter bands and also specified the use of single channel 60 words-per-minute five unit code corresponding to ITA2. A shift of 850 hertz plus or minus 50 hertz was specified. Amateur Radio operators also had to identify their station callsign at the beginning and the end of each transmission and at ten-minute intervals using International Morse code. Use of this wide shift proved to be a problem for Amateur Radio operations. Commercial operators had already discovered that narrow shift worked best on the HF bands. After investigation and a petition to the FCC, Part 12 was amended, in March 1956, to allow Amateur Radio Operators to use any shift that was less than 900 hertz.
The FCC Notice of Proposed Rule Making (NPRM) that resulted in the authorization of Frequency Shift Keying (FSK) in the amateur high frequency (HF) bands responded to petitions by the American Radio Relay League (ARRL), the National Amateur Radio Council and Mr. Robert Weinstein. The NPRM specifically states this and may be found in its entirety in the December 1951 Issue of QST. While the New RTTY Handbook gives ARRL no credit, it was published by CQ Magazine and its author was a CQ columnist (CQ generally opposed ARRL at that time).
The first RTTY Contest was held by the RTTY Society of Southern California from October 31 to November 1, 1953. Named the RTTY Sweepstakes Contest, twenty nine participants exchanged messages that contained a serial number, originating station call, check or RST report of two or three numbers, ARRL section of originator, local time (0000-2400 preferred) and date. Example: NR 23 W0BP CK MINN 1325 FEB 15. By the late 1950s, the contest exchange was expanded to include band used. Example: NR 23 W0BP CK MINN 1325 FEB 15 FORTY METERS. The contest was scored as follows: one point for each message sent and receipted entirely by RTTY and one point for each message received and acknowledged by RTTY. The final score was computed by multiplying the total number of message points by the number of ARRL sections worked. Two stations could exchange messages again on a different band for added points, but the section multiplier did not increase when the same section was reworked on a different band. Each DXCC entity was counted as an additional ARRL section for RTTY multiplier credit.
"RTTY", later named "RTTY Journal", also published the first listing of stations, mostly located in the continental US, that were interested in RTTY in 1956. Amateur Radio operators used this callbook information to contact other operators both inside and outside the United States. For example, the first recorded USA to New Zealand two-way RTTY QSO took place in 1956 between W0BP and ZL1WB.
By the late 1950s, new organizations focused on amateur radioteletype started to appear. The "British Amateur Radio Teletype Group", BARTG, now known as the "British Amateur Radio Teledata Group" was formed in June 1959. The Florida RTTY Society was formed in September 1959. Amateur Radio operators outside of Canada and the United States began to acquire surplus teleprinter and receive permission to get on the air. The first recorded RTTY QSO in the UK occurred in September 1959 between G2UK and G3CQE. A few weeks later, G3CQE had the first G/VE RTTY QSO with VE7KX. This was quickly followed up by G3CQE QSOs with VK3KF and ZL3HJ. Information on how to acquire surplus teleprinter equipment continued to spread and before long it was possible to work all continents on RTTY.
Amateur Radio operators used various equipment designs to get on the air using RTTY in the 1950s and 1960s. Amateurs used their existing receivers for RTTY operation but needed to add a terminal unit, sometimes called a demodulator, to convert the received audio signals to DC signals for the teleprinter.
Most of the terminal unit equipment used for receiving RTTY signals was homebuilt, using designs published in amateur radio publications. These original designs can be divided into two classes of terminal units: audio-type and intermediate frequency converters. The audio-type converters proved to be more popular with amateur radio operators. The Twin City, W2JAV and W2PAT designs are examples of typical terminal units that were used into the middle 1960s. The late 1960s and early 1970s saw the emergence of terminal units designed by W6FFC, such as the TT/L-2, ST-3, ST-5, and ST-6. These designs were first published in "RTTY Journal" starting in September 1967 and ending in 1970.
Amateur Radio operators needed to modify their transmitters to allow for HF RTTY operation. This was accomplished by adding a frequency shift keyer that used a diode to switch a capacitor in and out of the circuit, shifting the transmitter’s frequency in synchronism with the teleprinter signal changing from mark to space to mark. A very stable transmitter was required for RTTY. The typical frequency multiplication type transmitter that was popular in the 1950s and 1960s would be relatively stable on 80 meters but become progressively less stable on 40 meters, 20 meters and 15 meters. By the middle 1960s, transmitter designs were updated, mixing a crystal-controlled high frequency oscillator with a variable low frequency oscillator, resulting in better frequency stability across all Amateur Radio HF bands.
During the early days of Amateur RTTY, the Worked All Continents – RTTY Award was conceived by the RTTY Society of Southern California and issued by RTTY Journal. The first Amateur Radio station to achieve this WAC – RTTY Award was VE7KX. The first stations recognized as having achieved single band WAC RTTY were W1MX (3.5 MHz); DL0TD (7.0 MHz); K3SWZ (14.0 MHz); W0MT (21.0 MHz) and FG7XT (28.0 MHz). The ARRL began issuing WAC RTTY certificates in 1969.
By the early 1970s, Amateur Radio RTTY had spread around the world and it was finally possible to work more than 100 countries via RTTY. FG7XT was the first Amateur Radio station to claim to achieve this honor. However, Jean did not submit his QSL cards for independent review. ON4BX, in 1971, was the first Amateur Radio station to submit his cards to the DX Editor of RTTY Journal and to achieve this honor. The ARRL began issuing DXCC RTTY Awards on November 1, 1976. Prior to that date, an award for working 100 countries on RTTY was only available via RTTY Journal.
In the 1950s through the 1970s, "RTTY art" was a popular on-air activity. It consisted of (sometimes very elaborate and artistic) pictures sent over rtty through the use of lengthy punched tape transmissions and then printed by the receiving station on paper.
On January 7, 1972, the FCC amended Part 97 to allow faster RTTY speeds. Four standard RTTY speeds were authorized, namely, 60 (45 baud), 67 (50 baud), 75 (56.25 baud) and 100 (75 baud) words per minute. Many Amateur Radio operators had equipment that was capable of being upgraded to 75 and 100 words per minute by changing teleprinter gears. While there was an initial interest in 100 words per minute operation, many Amateur Radio operators moved back to 60 words per minute. Some of the reasons for the failure of 100 words per minute HF RTTY included poor operation of improperly maintained mechanical teleprinters, narrow bandwidth terminal units, continued use of 170 Hz shift at 100 words per minute and excessive error rates due to multipath distortion and the nature of ionospheric propagation.
The FCC approved the use of ASCII by Amateur Radio stations on March 17, 1980 with speeds up to 300 baud from 3.5 to 21.25 MHz and 1200 baud between 28 and 225 MHz. Speeds up to 19.2 kilobaud was authorized on Amateur frequencies above 420 MHz.
The requirement for Amateur Radio operators in the United States to identify their station callsign at the beginning and the end of each digital transmission and at ten-minute intervals using International Morse code was finally lifted by the FCC on June 15, 1983.
Comparison with other modes.
RTTY has a typical baud rate for Amateur operation of 45.45 baud (approximately 60 words per minute). It remains popular as a "keyboard to keyboard" mode in Amateur Radio. RTTY has declined in commercial popularity as faster, more reliable alternative data modes have become available, using satellite or other connections.
For its transmission speed, RTTY has low spectral efficiency. The typical RTTY signal with 170 Hz shift at 45.45 baud requires around 250 Hz receiver bandwidth, over double that required by PSK31. In theory, at this baud rate, the shift size can be decreased to 22.725 Hz, reducing the overall band footprint substantially. Because RTTY, using either AFSK or FSK modulation, produces a waveform with constant power, a transmitter does not need to use a linear amplifier, which is required for many digital transmission modes. A more efficient Class C amplifier may be used.
RTTY, using either AFSK or FSK modulation, is moderately resistant to vagaries of HF propagation and interference, however modern digital modes, such as MFSK, use Forward Error Correction to provide much better data reliability.
Primary users.
Principally, the primary users are those who need robust shortwave communications. Examples are:
One regular service is WLO, transmitting weather information from the United States in English, using ITA-2, with an intended audience of ocean-going vessels and those concerned with them:
Another regular service transmitting RTTY meteorological information is the German Meteorological Service (Deutscher Wetterdienst or DWD). The DWD regularly transmit two programs on various frequencies on LF and HF in standard RTTY (ITA-2 alphabet). The list of callsigns, frequencies, baudrates and shifts (current June 2012) are as follows:
The DWD signals can be easily received in Europe, North Africa and parts of North America.
Pronunciation.
RTTY (in English) may be spoken as "radioteletype", by its letters: R-T-T-Y, or simply as "ritty".

</doc>
<doc id="26344" url="https://en.wikipedia.org/wiki?curid=26344" title="Register transfer language">
Register transfer language

In computer science, register transfer language (RTL) is a kind of intermediate representation (IR) that is very close to assembly language, such as that which is used in a compiler. Academic papers and textbooks also often use a form of RTL as an architecture-neutral assembly language. RTL is also the name of a specific IR used in the GNU Compiler Collection (GCC), and several other compilers, such as Zephyr or the European compiler projects CerCo and CompCert.
In GCC.
In GCC, RTL is generated from the GIMPLE representation, transformed by various passes in the GCC 'middle-end', and then converted to assembly language.
GCC's RTL is usually written in a form which looks like a Lisp S-expression:
This "side-effect expression" says "sum the contents of register 138 with the contents of register 139 and store the result in register 140". The SI specifies the access mode for each registers. In the example it is "SImode", i.e. "access the register as 32-bit integer".
The sequence of RTL generated has some dependency on the characteristics of the processor for which GCC is generating code. However, the meaning of the RTL is more-or-less independent of the target: it would usually be possible to read and understand a piece of RTL without knowing what processor it was generated for. Similarly, the meaning of the RTL doesn't usually depend on the original high-level language of the program.
A register transfer language is a system for expressing in symbolic form the microoperation sequences among the registers of a digital module. It is a convenient tool for describing the internal organization of digital computers in concise and precise manner. It can also be used to facilitate the design process of digital systems.
History.
The idea behind RTL was first described in:
Davidson and Fraser; The Design and Application of a Retargetable Peephole Optimizer; ToPLaS v2(2) 191-202 (April 1980)

</doc>
<doc id="26346" url="https://en.wikipedia.org/wiki?curid=26346" title="Remote procedure call">
Remote procedure call

In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in another address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction. That is, the programmer writes essentially the same code whether the subroutine is local to the executing program, or remote. This is a form of client–server interaction (caller is client, executer is server), typically implemented via a request–response message-passing system. The object-oriented programming analog is remote method invocation (RMI). The RPC model implies a level of location transparency, namely that calling procedures is largely the same whether it is local or remote, but usually they are not identical, so local calls can be distinguished from remote calls. Remote calls are usually orders of magnitude slower and less reliable than local calls, so distinguishing them is useful.
RPCs are a form of inter-process communication (IPC), in that different processes have different address spaces: if on the same host machine, they have distinct virtual address spaces, even though the physical address space is the same; while if they are on different hosts, the physical address space is different. Many different (often incompatible) technologies have been used to implement the concept.
History and origins.
Response–request protocols date to early distributed computing in late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s. In the 1990s, with the popularity of object-oriented programming, the alternative model of remote method invocation (RMI) was widely implemented, such as in Common Object Request Broker Architecture (CORBA, 1991) and Java remote method invocation. RMIs in turn fell in popularity with the rise of the internet, particularly in the 2000s.
Remote procedure calls used in modern operating systems trace their roots back to the RC 4000 multiprogramming system, which used a request-response communication protocol for process synchronization. The idea of treating network operations as remote procedure calls goes back at least to the 1970s in early ARPANET documents. In 1978, Per Brinch Hansen proposed Distributed Processes, a language for distributed computing based on "external requests" consisting of procedure calls between processes.
Bruce Jay Nelson is generally credited with coining the term "remote procedure call" (1981), and the first practical implementation was by Andrew Birrel and Bruce Nelson, called Lupine, in the Cedar environment at Xerox PARC. Lupine automatically generated stubs, providing type-safe bindings, and used an efficient protocol for communication. One of the first business uses of RPC was by Xerox under the name "Courier" in 1981. The first popular implementation of RPC on Unix was Sun's RPC (now called ONC RPC), used as the basis for Network File System.
Message passing.
RPC is a kind of request–response protocol. An RPC is initiated by the "client", which sends a request message to a known remote "server" to execute a specified procedure with supplied parameters. The remote server sends a response to the client, and the application continues its process. While the server is processing the call, the client is blocked (it waits until the server has finished processing before resuming execution), unless the client sends an asynchronous request to the server, such as an XHTTP call. There are many variations and subtleties in various implementations, resulting in a variety of different (incompatible) RPC protocols.
An important difference between remote procedure calls and local calls is that remote calls can fail because of unpredictable network problems. Also, callers generally must deal with such failures without knowing whether the remote procedure was actually invoked. Idempotent procedures (those that have no additional effects if called more than once) are easily handled, but enough difficulties remain that code to call remote procedures is often confined to carefully written low-level subsystems.
Standard contact mechanisms.
To let different clients access servers, a number of standardized RPC systems have been created. Most of these use an interface description language (IDL) to let various platforms call the RPC. The IDL files can then be used to generate code to interface between the client and servers.
Other RPC analogues.
Notable RPC implementations and analogues include:

</doc>
<doc id="26347" url="https://en.wikipedia.org/wiki?curid=26347" title="Russian submarine Kursk (K-141)">
Russian submarine Kursk (K-141)

K-141 "Kursk" (full Russian name Атомная Подводная Лодка «Курск» (АПЛ «Курск»), "Atomnaya Podvodnaya Lodka "Kursk" (APL "Kursk")", meaning "Nuclear-powered submarine "Kursk"") was an Oscar-II class nuclear-powered cruise-missile submarine of the Russian Navy which was lost with all hands when it sank in the Barents Sea on 12 August 2000. It was a Project 949A Антей ("Antey", Antaeus; NATO reporting name "Oscar II") submarine.
It was named after the Russian city of Kursk, around which the largest tank battle in history, the Battle of Kursk, took place in 1943. One of the first vessels completed after the end of the Soviet Union, it was commissioned into the Russian Navy's Northern Fleet.
Construction.
Work on building "Kursk" began in 1990 at Severodvinsk, near Arkhangelsk. Launched in 1994, it was commissioned in December of that year. It was the penultimate Oscar II class submarine designed and approved in the Soviet era.
Capabilities.
The Antey design represented the highest achievement of Soviet nuclear submarine technology. They were the largest attack submarines ever built. It was built to defeat an entire United States aircraft carrier group. A single Type 65 torpedo carried a warhead powerful enough to sink an aircraft carrier. Both missiles and torpedoes could be equipped with nuclear warheads. She was longer than any other Oscar I-class submarine. The senior officers had individual staterooms and the entire crew had access to a gymnasium.
The outer hull, made of high-nickel, high-chrome content stainless steel thick, had exceptionally good resistance to corrosion and a weak magnetic signature which helped prevent detection by U.S. magnetic anomaly detector (MAD) systems. There was a gap to the -thick steel pressure hull. She was designed to remain submerged for up to 120 days. The sail superstructure was reinforced to allow it to break through the Arctic ice.
The submarine was armed with 24 SS-N-19/P-700 Granit cruise missiles, and eight torpedo tubes in the bow: four and four . The Granit missiles with a range of , were capable of supersonic flight at altitudes over . They were designed to swarm enemy vessels and intelligently choose individual targets which terminated with a dive onto the target. The torpedo tubes could be used to launch either torpedoes or anti-ship missiles with a range of . Her weapons included 18 SS-N-16 "Stallion" anti-ship missiles designed to defeat the best Western naval air defenses.
"Kursk" was part of Russia's Northern Fleet, which had suffered funding cutbacks throughout the 1990s. Many of its submarines were anchored and rusting in Zapadnaya Litsa Naval Base, from Murmansk. Little work to maintain all but the most essential front-line equipment, including search and rescue equipment, had occurred. Northern Fleet sailors had gone unpaid in the mid-1990s.
Deployments.
During her five years of service, "Kursk" completed only one mission, a six-month deployment to the Mediterranean during the summer of 1999 to monitor the United States Sixth Fleet responding to the Kosovo crisis. This was due to a lack of funds for fuel. As a result, many of her crew had spent little time at sea and were inexperienced.
Naval exercise and disaster.
"Kursk" joined the "Summer-X" exercise, the first large-scale naval exercise planned by the Russian Navy in more than a decade, on 10 August 2000. It included 30 ships including the fleet's flagship "Pyotr Velikiy" ("Peter the Great"), four attack submarines, and a flotilla of smaller ships. The crew had recently won a citation for its excellent performance and been recognized as the best submarine crew in the Northern Fleet. While it was an exercise, "Kursk" loaded a full complement of combat weapons. It was one of the few ships authorized to carry a combat load at all times.
Explosion.
On the first day of the exercise, "Kursk" successfully launched a Granit missile armed with a dummy warhead. Two days later, on the morning of 12 August, she prepared to fire dummy torpedoes at the "Kirov"-class battlecruiser "Pyotr Velikiy". These practice torpedoes had no explosive warheads and were manufactured and tested at a much lower quality standard. On 12 August 2000, at 11:28 local time (07:28 UTC), there was an explosion while preparing to fire. The Russian Navy's final report on the disaster concluded the explosion was due to the failure of one of "Kursk"'s hydrogen peroxide-fueled Type 65 torpedoes. A subsequent investigation concluded that HTP, a form of highly concentrated hydrogen peroxide used as propellant for the torpedo, seeped through a faulty weld in the torpedo casing. When HTP comes in contact with a catalyst, it rapidly expands by a factor of 5000, generating vast quantities of steam and oxygen. The pressure produced by the expanding HTP ruptured the kerosene fuel tank in the torpedo and set off an explosion equal to of TNT. The submarine sank in relatively shallow water, bottoming at about off Severomorsk, at . A second explosion 135 seconds after the initial event was equivalent to 3-7 tons of TNT. The explosions blew a large hole in the hull and collapsed the first three compartments of the sub, killing or incapacitating all but 23 of the 118 personnel on board.
Rescue attempts.
Though the British and Norwegian navies offered assistance, Russia refused all help. All 118 sailors and officers aboard "Kursk" died. The Russian Admiralty initially told the public that the majority of the crew died within minutes of the explosion, but on 21 August Norwegian and Russian divers found 24 bodies in the ninth compartment, the turbine room at the stern of the boat. Captain-lieutenant Dmitri Kolesnikov wrote a note listing the names of 23 sailors who were alive in the compartment after the ship sank.
"Kursk" carried a potassium superoxide cartridge of a chemical oxygen generator, used to absorb carbon dioxide and chemically release oxygen during an emergency. However, the cartridge became contaminated with sea water and the resulting chemical reaction caused a flash fire which consumed the available oxygen. The investigation showed that some men temporarily survived the fire by plunging under water, as fire marks on the bulkheads indicated the water was at waist level at the time. Ultimately, the remaining crew burned to death or suffocated.
Russian President Vladimir Putin, though immediately informed of the tragedy, was told by the navy that they had the situation under control and rescue was imminent. He waited five days before he ended his holiday at a presidential resort in Sochi on the Black Sea. Only four months into his tenure as President, the public and media were extremely critical of Putin's decision to remain at a seaside resort, and his highly favourable ratings dropped dramatically. The President's response appeared callous and the government's actions looked incompetent. A year later he said, "I probably should have returned to Moscow, but nothing would have changed. I had the same level of communication both in Sochi and in Moscow, but from a PR point of view I could have demonstrated some special eagerness to return."
Submarine recovery.
A consortium formed by the Dutch companies Mammoet and Smit International was awarded a contract by Russia to raise the vessel, excluding the bow. They modified the barge "Giant 4" which raised "Kursk" and recovered the remains of the sailors.
During salvage in 2001, the team first cut the bow off the hull using a tungsten carbide-studded cable. As this tool had the potential to cause sparks which could ignite remaining pockets of volatile gases, such as hydrogen, the operation was carefully executed. Most of the bow was abandoned and the balance of the vessel was towed to Severomorsk and placed in a floating dry dock for forensic analysis.
The remains of "Kursk"s reactor compartment was towed to Sayda Bay on Russia's northern Kola Peninsula – where more than 50 reactor compartments were afloat at pier points – after a shipyard had defuelled the boat in early 2003. The rest of the boat was then dismantled for scrap.
Some torpedo and torpedo tube fragments from the bow were recovered and the balance was destroyed by explosives in 2002.
Official inquiry results.
Finally pushing aside the navy's long-standing blame on a collision with a foreign vessel, a report issued by the government attributed the disaster to a torpedo explosion caused when high-test peroxide (HTP), a form of highly concentrated hydrogen peroxide, leaked from a faulty weld in the torpedo's casing. The report found that the initial explosion destroyed the torpedo room compartment and killed everyone in the first compartment. The blast entered the second and perhaps the third and fourth compartments through an air conditioning vent. All of the 36 men in the command post located in the second compartment were immediately incapacitated by the blast wave and possibly killed. The first explosion caused a fire that raised the temperature of the compartment to more than . The heat triggered the warheads of between five to seven additional torpedoes to detonate, creating an explosion equivalent to 2-3 tons of TNT that was measured 4.2 on the Richter scale on seismographs across Europe and was detected as far away as Alaska.
Other explanation.
Vice-Admiral Valery Ryazantsev differed with the government's official conclusion. He cited inadequate training, poor maintenance, and incomplete inspections that caused the crew to mishandle the weapon. During the examination of the wrecked sub, investigators recovered a partially burned copy of the safety instructions for loading HTP torpedoes, but the instructions were for a significantly different type of torpedo and failed to include essential steps for testing an air valve. The 7th Division, 1st Submarine Flotilla never inspected "Kursk"s crew's qualifications and readiness to fire HTP torpedoes. "Kursk"s crew had no prior experience with and hadn't been trained in handling or firing HTP powered torpedoes. Due to their inexperience and lack of training, compounded by incomplete inspections and oversight, and because the "Kursk"s crew followed faulty instructions when loading the practice torpedo, Ryazantsev believes they set off a chain of events that led to the explosion.

</doc>
<doc id="26350" url="https://en.wikipedia.org/wiki?curid=26350" title="Radiation therapy">
Radiation therapy

Radiation therapy or radiotherapy, often abbreviated RT, RTx, or XRT, is therapy using ionizing radiation, generally as part of cancer treatment to control or kill malignant cells. Radiation therapy may be curative in a number of types of cancer if they are localized to one area of the body. It may also be used as part of adjuvant therapy, to prevent tumor recurrence after surgery to remove a primary malignant tumor (for example, early stages of breast cancer). Radiation therapy is synergistic with chemotherapy, and has been used before, during, and after chemotherapy in susceptible cancers. The subspecialty of oncology that focuses on radiotherapy is called radiation oncology.
Radiation therapy is commonly applied to the cancerous tumor because of its ability to control cell growth. Ionizing radiation works by damaging the DNA of cancerous tissue leading to cellular death. To spare normal tissues (such as skin or organs which radiation must pass through to treat the tumor), shaped radiation beams are aimed from several angles of exposure to intersect at the tumor, providing a much larger absorbed dose there than in the surrounding, healthy tissue. Besides the tumour itself, the radiation fields may also include the draining lymph nodes if they are clinically or radiologically involved with tumor, or if there is thought to be a risk of subclinical malignant spread. It is necessary to include a margin of normal tissue around the tumor to allow for uncertainties in daily set-up and internal tumor motion. These uncertainties can be caused by internal movement (for example, respiration and bladder filling) and movement of external skin marks relative to the tumor position.
Radiation oncology is the medical specialty concerned with prescribing radiation, and is distinct from radiology, the use of radiation in medical imaging and diagnosis. Radiation may be prescribed by a radiation oncologist with intent to cure ("curative") or for adjuvant therapy. It may also be used as palliative treatment (where cure is not possible and the aim is for local disease control or symptomatic relief) or as therapeutic treatment (where the therapy has survival benefit and it can be curative). It is also common to combine radiation therapy with surgery, chemotherapy, hormone therapy, immunotherapy or some mixture of the four. Most common cancer types can be treated with radiation therapy in some way.
The precise treatment intent (curative, adjuvant, neoadjuvant, therapeutic, or palliative) will depend on the tumor type, location, and stage, as well as the general health of the patient. Total body irradiation (TBI) is a radiation therapy technique used to prepare the body to receive a bone marrow transplant. Brachytherapy, in which a radiation source is placed inside or next to the area requiring treatment, is another form of radiation therapy that minimizes exposure to healthy tissue during procedures to treat cancers of the breast, prostate and other organs.
Radiation therapy has several applications in non-malignant conditions, such as the treatment of trigeminal neuralgia, acoustic neuromas, severe thyroid eye disease, pterygium, pigmented villonodular synovitis, and prevention of keloid scar growth, vascular restenosis, and heterotopic ossification. The use of radiation therapy in non-malignant conditions is limited partly by worries about the risk of radiation-induced cancers.
Medical uses.
Different cancers respond to radiation therapy in different ways.
The response of a cancer to radiation is described by its radiosensitivity.
Highly radiosensitive cancer cells are rapidly killed by modest doses of radiation. These include leukemias, most lymphomas and germ cell tumors.
The majority of epithelial cancers are only moderately radiosensitive, and require a significantly higher dose of radiation (60-70 Gy) to achieve a radical cure.
Some types of cancer are notably radioresistant, that is, much higher doses are required to produce a radical cure than may be safe in clinical practice. Renal cell cancer and melanoma are generally considered to be radioresistant but radiation therapy is still a palliative option for many patients with metastatic melanoma. Combining radiation therapy with immunotherapy is an active area of investigation and has shown some promise for melanoma and other cancers.
It is important to distinguish the radiosensitivity of a particular tumor, which to some extent is a laboratory measure, from the radiation "curability" of a cancer in actual clinical practice. For example, leukemias are not generally curable with radiation therapy, because they are disseminated through the body. Lymphoma may be radically curable if it is localised to one area of the body. Similarly, many of the common, moderately radioresponsive tumors are routinely treated with curative doses of radiation therapy if they are at an early stage. For example: non-melanoma skin cancer, head and neck cancer, breast cancer, non-small cell lung cancer, cervical cancer, anal cancer, prostate cancer. Metastatic cancers are generally incurable with radiation therapy because it is not possible to treat the whole body.
Before treatment, a CT scan is often performed to identify the tumor and surrounding normal structures. The patient receives small skin marks to guide the placement of treatment fields. Patient positioning is crucial at this stage as the patient will have to be set-up in the identical position during treatment. Many patient positioning devices have been developed for this purpose, including masks and cushions which can be molded to the patient.
The response of a tumor to radiation therapy is also related to its size. Due to complex radiobiology, very large tumors respond less well to radiation than smaller tumors or microscopic disease. Various strategies are used to overcome this effect. The most common technique is surgical resection prior to radiation therapy. This is most commonly seen in the treatment of breast cancer with wide local excision or mastectomy followed by adjuvant radiation therapy. Another method is to shrink the tumor with neoadjuvant chemotherapy prior to radical radiation therapy. A third technique is to enhance the radiosensitivity of the cancer by giving certain drugs during a course of radiation therapy. Examples of radiosensitizing drugs include: Cisplatin, Nimorazole, and Cetuximab.
The effect of radiotherapy on control of cancer has been shown to be limited to the first five years after surgery, particularly for breast cancer. The difference between breast cancer recurrence in patients who receive radiotherapy vs. those who don't is seen mostly in the first 2–3 years and no difference is seen after 5 years. This is explained in detail here.
Side effects.
Radiation therapy is in itself painless. Many low-dose palliative treatments (for example, radiation therapy to bony metastases) cause minimal or no side effects, although short-term pain flare-up can be experienced in the days following treatment due to oedema compressing nerves in the treated area. Higher doses can cause varying side effects during treatment (acute side effects), in the months or years following treatment (long-term side effects), or after re-treatment (cumulative side effects). The nature, severity, and longevity of side effects depends on the organs that receive the radiation, the treatment itself (type of radiation, dose, fractionation, concurrent chemotherapy), and the patient.
Most side effects are predictable and expected. Side effects from radiation are usually limited to the area of the patient's body that is under treatment. Modern radiation therapy aims to reduce side effects to a minimum and to help the patient understand and deal with side effects that are unavoidable.
The main side effects reported are fatigue and skin irritation, like a mild to moderate sun burn. The fatigue often sets in during the middle of a course of treatment and can last for weeks after treatment ends. The irritated skin will heal, but may not be as elastic as it was before.
Late side effects.
Late side effects occur months to years after treatment and are generally limited to the area that has been treated. They are often due to damage of blood vessels and connective tissue cells. Many late effects are reduced by fractionating treatment into smaller parts.
Cumulative side effects.
Cumulative effects from this process should not be confused with long-term effects—when short-term effects have disappeared and long-term effects are subclinical, reirradiation can still be problematic.
Effects on reproduction.
During the first two weeks after fertilization, radiation therapy is lethal but not teratogenic. High doses of radiation during pregnancy induce anomalies, impaired growth and intellectual disability, and there may be an increased risk of childhood leukemia and other tumours in the offspring.
In males previously having undergone radiotherapy, there appears to be no increase in genetic defects or congenital malformations in their children conceived after therapy. However, the use of assisted reproductive technologies and micromanipulation techniques might increase this risk.
Effects on pituitary system.
Hypopituitarism commonly develops after radiation therapy for sellar and parasellar neoplasms, extrasellar brain tumours, head and neck tumours, and following whole body irradiation for systemic malignancies. Radiation-induced hypopituitarism mainly affects growth hormone and gonadal hormones. In contrast, adrenocorticotrophic hormone (ACTH) and thyroid stimulating hormone (TSH) deficiencies are the least common among people with radiation-induced hypopituitarism. Changes in prolactin-secretion is usually mild, and vasopressin deficiency appears to be very rare as a consequence of radiation.
Radiation therapy accidents.
There are rigorous procedures in place to minimise the risk of accidental overexposure of radiation therapy to patients. However, mistakes do occasionally occur; for example, the radiation therapy machine Therac-25 was responsible for at least six accidents between 1985 and 1987, where patients were given up to one hundred times the intended dose; two people were killed directly by the radiation overdoses. From 2005 to 2010, a hospital in Missouri overexposed 76 patients (most with brain cancer) during a five-year period because new radiation equipment had been set up incorrectly. Although medical errors are exceptionally rare, radiation oncologists, medical physicists and other members of the radiation therapy treatment team are working to eliminate them. ASTRO has launched a safety initiative called Target Safely that, among other things, aims to record errors nationwide so that doctors can learn from each and every mistake and prevent them from happening. ASTRO also publishes a list of questions for patients to ask their doctors about radiation safety to ensure every treatment is as safe as possible.
Use in non-cancerous diseases.
Radiation therapy is used to treat early stage Dupuytren's disease and Ledderhose disease. When Dupuytren's disease is at the nodules and cords stage or fingers are at a minimal deformation stage of less than 10 degrees, then radiation therapy is used to prevent further progress of the disease. Radiation therapy is also used post surgery in some cases to prevent the disease continuing to progress. Low doses of radiation are used typically three gray of radiation for five days, with a break of three months followed by another phase of three gray of radiation for five days.
Technique.
Mechanism of action.
Radiation therapy works by damaging the DNA of cancerous cells. This DNA damage is caused by one of two types of energy, photon or charged particle. This damage is either direct or indirect ionization of the atoms which make up the DNA chain. Indirect ionization happens as a result of the ionization of water, forming free radicals, notably hydroxyl radicals, which then damage the DNA.
In photon therapy, most of the radiation effect is through free radicals. Cells have mechanisms for repairing single-strand DNA damage and double-stranded DNA damage. However, double-stranded DNA breaks are much more difficult to repair, and can lead to dramatic chromosomal abnormalities and genetic deletions. Targeting double-stranded breaks increases the probability that cells will undergo cell death. Cancer cells are generally less differentiated and more stem cell-like; they reproduce more than most healthy differentiated cells, and have a diminished ability to repair sub-lethal damage. Single-strand DNA damage is then passed on through cell division; damage to the cancer cells' DNA accumulates, causing them to die or reproduce more slowly.
One of the major limitations of photon radiation therapy is that the cells of solid tumors become deficient in oxygen. Solid tumors can outgrow their blood supply, causing a low-oxygen state known as hypoxia. Oxygen is a potent radiosensitizer, increasing the effectiveness of a given dose of radiation by forming DNA-damaging free radicals. Tumor cells in a hypoxic environment may be as much as 2 to 3 times more resistant to radiation damage than those in a normal oxygen environment.
Much research has been devoted to overcoming hypoxia including the use of high pressure oxygen tanks, hyperthermia therapy (heat therapy which dilates blood vessels to the tumor site), blood substitutes that carry increased oxygen, hypoxic cell radiosensitizer drugs such as misonidazole and metronidazole, and hypoxic cytotoxins (tissue poisons), such as tirapazamine. Newer research approaches are currently being studied, including preclinical and clinical investigations into the use of an oxygen diffusion-enhancing compound such as trans sodium crocetinate (TSC) as a radiosensitizer.
Charged particles such as protons and boron, carbon, and neon ions can cause direct damage to cancer cell DNA through high-LET (linear energy transfer) and have an antitumor effect independent of tumor oxygen supply because these particles act mostly via direct energy transfer usually causing double-stranded DNA breaks. Due to their relatively large mass, protons and other charged particles have little lateral side scatter in the tissue—the beam does not broaden much, stays focused on the tumor shape, and delivers small dose side-effects to surrounding tissue. They also more precisely target the tumor using the Bragg peak effect. See proton therapy for a good example of the different effects of intensity-modulated radiation therapy (IMRT) vs. charged particle therapy. This procedure reduces damage to healthy tissue between the charged particle radiation source and the tumor and sets a finite range for tissue damage after the tumor has been reached. In contrast, IMRT's use of uncharged particles causes its energy to damage healthy cells when it exits the body. This exiting damage is not therapeutic, can increase treatment side effects, and increases the probability of secondary cancer induction. This difference is very important in cases where the close proximity of other organs makes any stray ionization very damaging (example: head and neck cancers).
This x-ray exposure is especially bad for children, due to their growing bodies, and they have a 30% chance of a second malignancy after 5 years post initial RT.
Dose.
The amount of radiation used in photon radiation therapy is measured in gray (Gy), and varies depending on the type and stage of cancer being treated. For curative cases, the typical dose for a solid epithelial tumor ranges from 60 to 80 Gy, while lymphomas are treated with 20 to 40 Gy.
Preventive (adjuvant) doses are typically around 45–60 Gy in 1.8–2 Gy fractions (for breast, head, and neck cancers.) Many other factors are considered by radiation oncologists when selecting a dose, including whether the patient is receiving chemotherapy, patient comorbidities, whether radiation therapy is being administered before or after surgery, and the degree of success of surgery.
Delivery parameters of a prescribed dose are determined during treatment planning (part of dosimetry). Treatment planning is generally performed on dedicated computers using specialized treatment planning software. Depending on the radiation delivery method, several angles or sources may be used to sum to the total necessary dose. The planner will try to design a plan that delivers a uniform prescription dose to the tumor and minimizes dose to surrounding healthy tissues.
In radiation therapy, three-dimensional dose distributions are often evaluated using the dosimetry technique known as gel dosimetry.
(This section only applies to photon RT although other types of radiation therapy may be fractionated).
The total dose is fractionated (spread out over time) for several important reasons. Fractionation allows normal cells time to recover, while tumor cells are generally less efficient in repair between fractions. Fractionation also allows tumor cells that were in a relatively radio-resistant phase of the cell cycle during one treatment to cycle into a sensitive phase of the cycle before the next fraction is given. Similarly, tumor cells that were chronically or acutely hypoxic (and therefore more radioresistant) may reoxygenate between fractions, improving the tumor cell kill.
Fractionation regimens are individualised between different radiation therapy centers and even between individual doctors. In North America, Australia, and Europe, the typical fractionation schedule for adults is 1.8 to 2 Gy per day, five days a week. In some cancer types, prolongation of the fraction schedule over too long can allow for the tumor to begin repopulating, and for these tumor types, including head-and-neck and cervical squamous cell cancers, radiation treatment is preferably completed within a certain amount of time. For children, a typical fraction size may be 1.5 to 1.8 Gy per day, as smaller fraction sizes are associated with reduced incidence and severity of late-onset side effects in normal tissues.
In some cases, two fractions per day are used near the end of a course of treatment. This schedule, known as a concomitant boost regimen or hyperfractionation, is used on tumors that regenerate more quickly when they are smaller. In particular, tumors in the head-and-neck demonstrate this behavior.
Patients receiving palliative radiation to treat uncomplicated painful bone metastasis should not receive more than a single fraction of radiation. A single treatment gives comparable pain relief and morbidity outcomes to multiple-fraction treatments, and for patients with limited life expectancy, a single treatment is best to improve patient comfort.
One fractionation schedule that is increasingly being used and continues to be studied is hypofractionation. This is a radiation treatment in which the total dose of radiation is divided into large doses. Typical doses vary significantly by cancer type, from 2.2 Gy/fraction to 20 Gy/fraction. The logic behind hypofractionation is to lessen the possibility of the cancer returning by not giving the cells enough time to reproduce and also to exploit the unique biological radiation sensitivity of some tumors. One commonly treated site where there is very good evidence for such treatment is in breast cancer. Short course hypofractionated treatments over 3–4 weeks e.g. 40 Gy in 15 fractions or 42.5 Gy in 16 fractions, have been shown to be as effective as more protracted 5-6 week treatments with respect to both cancer control and cosmesis (UK START and Canadian trials).
One of the best-known alternative fractionation schedules is Continuous Hyperfractionated Accelerated Radiation therapy (CHART). CHART, used to treat lung cancer, consists of three smaller fractions per day. Although reasonably successful, CHART can be a strain on radiation therapy departments.
Another increasingly well-known alternative fractionation schedule, used to treat breast cancer, is called Accelerated Partial Breast Irradiation (APBI). APBI can be performed with either brachytherapy or with external beam radiation. APBI normally involves two high-dose fractions per day for five days, compared to whole breast irradiation, in which a single, smaller fraction is given five times a week over a six-to-seven-week period. An example of APBI where the entire dose is delivered in a single fraction is TARGIT.
Implants can be fractionated over minutes or hours, or they can be permanent seeds which slowly deliver radiation until they become inactive.
Types.
Historically, the three main divisions of radiation therapy are external beam radiation therapy (EBRT or XRT) or teletherapy, brachytherapy or sealed source radiation therapy, and systemic radioisotope therapy or unsealed source radiotherapy. The differences relate to the position of the radiation source; external is outside the body, brachytherapy uses sealed radioactive sources placed precisely in the area under treatment, and systemic radioisotopes are given by infusion or oral ingestion. Brachytherapy can use temporary or permanent placement of radioactive sources. The temporary sources are usually placed by a technique called afterloading. In afterloading a hollow tube or applicator is placed surgically in the organ to be treated, and the sources are loaded into the applicator after the applicator is implanted. This minimizes radiation exposure to health care personnel. Particle therapy is a special case of external beam radiation therapy where the particles are protons or heavier ions. Intraoperative radiation therapy or IORT is a special type of radiation therapy that is delivered immediately after surgical removal of the cancer. This method has been employed in breast cancer (TARGeted Introperative radiation therapy or TARGIT), brain tumors and rectal cancers.
External beam radiation therapy.
The following three sections refer to treatment using x-rays.
Conventional external beam radiation therapy.
Conventional external beam radiation therapy (2DXRT) is delivered via two-dimensional beams using kilovoltage therapy x-ray units or medical linear accelerators which generate high energy x-rays. 2DXRT mainly consists of a single beam of radiation delivered to the patient from several directions: often front or back, and both sides. "Conventional" refers to the way the treatment is "planned" or "simulated" on a specially calibrated diagnostic x-ray machine known as a simulator because it recreates the linear accelerator actions (or sometimes by eye), and to the usually well-established arrangements of the radiation beams to achieve a desired "plan". The aim of simulation is to accurately target or localize the volume which is to be treated. This technique is well established and is generally quick and reliable. The worry is that some high-dose treatments may be limited by the radiation toxicity capacity of healthy tissues which lay close to the target tumor volume. An example of this problem is seen in radiation of the prostate gland, where the sensitivity of the adjacent rectum limited the dose which could be safely prescribed using 2DXRT planning to such an extent that tumor control may not be easily achievable. Prior to the invention of the CT, physicians and physicists had limited knowledge about the true radiation dosage delivered to both cancerous and healthy tissue. For this reason, 3-dimensional conformal radiation therapy is becoming the standard treatment for a number of tumor sites. More recently other forms of imaging are used including MRI, PET, SPECT and Ultrasound.
Stereotactic radiation.
Stereotactic radiation is a specialized type of external beam radiation therapy. It uses focused radiation beams targeting a well-defined tumor using extremely detailed imaging scans. Radiation oncologists perform stereotactic treatments, often with the help of a neurosurgeon for tumors in the brain or spine.
There are two types of stereotactic radiation. Stereotactic radiosurgery (SRS) is when doctors use a single or several stereotactic radiation treatments of the brain or spine. Stereotactic body radiation therapy (SBRT) refers to one or several stereotactic radiation treatments with the body, such as the lungs.
Some doctors say an advantage to stereotactic treatments is that they deliver the right amount of radiation to the cancer in a shorter amount of time than traditional treatments, which can often take 6 to 11 weeks. Plus treatments are given with extreme accuracy, which should limit the effect of the radiation on healthy tissues. One problem with stereotactic treatments is that they are only suitable for certain small tumors.
Stereotactic treatments can be confusing because many hospitals call the treatments by the name of the manufacturer rather than calling it SRS or SBRT. Brand names for these treatments include Axesse, Cyberknife, Gamma Knife, Novalis, Primatom, Synergy, X-Knife, TomoTherapy, Trilogy and Truebeam. This list changes as equipment manufacturers continue to develop new, specialized technologies to treat cancers.
Virtual simulation, 3-dimensional conformal radiation therapy, and intensity-modulated radiation therapy.
The planning of radiation therapy treatment has been revolutionized by the ability to delineate tumors and adjacent normal structures in three dimensions using specialized CT and/or MRI scanners and planning software.
Virtual simulation, the most basic form of planning, allows more accurate placement of radiation beams than is possible using conventional X-rays, where soft-tissue structures are often difficult to assess and normal tissues difficult to protect.
An enhancement of virtual simulation is 3-dimensional conformal radiation therapy (3DCRT), in which the profile of each radiation beam is shaped to fit the profile of the target from a beam's eye view (BEV) using a multileaf collimator (MLC) and a variable number of beams. When the treatment volume conforms to the shape of the tumor, the relative toxicity of radiation to the surrounding normal tissues is reduced, allowing a higher dose of radiation to be delivered to the tumor than conventional techniques would allow.
Intensity-modulated radiation therapy (IMRT).
Intensity-modulated radiation therapy (IMRT) is an advanced type of high-precision radiation that is the next generation of 3DCRT. IMRT also improves the ability to conform the treatment volume to concave tumor shapes, for example when the tumor is wrapped around a vulnerable structure such as the spinal cord or a major organ or blood vessel. Computer-controlled x-ray accelerators distribute precise radiation doses to malignant tumors or specific areas within the tumor. The pattern of radiation delivery is determined using highly tailored computing applications to perform optimization and treatment simulation (Treatment Planning). The radiation dose is consistent with the 3-D shape of the tumor by controlling, or modulating, the radiation beam’s intensity. The radiation dose intensity is elevated near the gross tumor volume while radiation among the neighboring normal tissue is decreased or avoided completely. This results in better tumor targeting, lessened side effects, and improved treatment outcomes than even 3DCRT.
3DCRT is still used extensively for many body sites but the use of IMRT is growing in more complicated body sites such as CNS, head and neck, prostate, breast and lung. Unfortunately, IMRT is limited by its need for additional time from experienced medical personnel. This is because physicians must manually delineate the tumors one CT image at a time through the entire disease site which can take much longer than 3DCRT preparation. Then, medical physicists and dosimetrists must be engaged to create a viable treatment plan. Also, the IMRT technology has only been used commercially since the late 1990s even at the most advanced cancer centers, so radiation oncologists who did not learn it as part of their residency program must find additional sources of education before implementing IMRT.
Proof of improved survival benefit from either of these two techniques over conventional radiation therapy (2DXRT) is growing for many tumor sites, but the ability to reduce toxicity is generally accepted. This is particularly the case for head and neck cancers in a series of pivotal trials performed by Professor Christopher Nutting of the Royal Marsden Hospital. Both techniques enable dose escalation, potentially increasing usefulness. There has been some concern, particularly with IMRT, about increased exposure of normal tissue to radiation and the consequent potential for secondary malignancy. Overconfidence in the accuracy of imaging may increase the chance of missing lesions that are invisible on the planning scans (and therefore not included in the treatment plan) or that move between or during a treatment (for example, due to respiration or inadequate patient immobilization). New techniques are being developed to better control this uncertainty—for example, real-time imaging combined with real-time adjustment of the therapeutic beams. This new technology is called image-guided radiation therapy (IGRT) or four-dimensional radiation therapy.
Another technique is the real-time tracking and localization of one or more small implantable electric devices implanted inside or close to the tumor. There are various types of medical implantable devices that are used for this purpose. It can be a magnetic transponder which senses the magnetic field generated by several transmitting coils, and then transmits the measurements back to the positioning system to determine the location. The implantable device can also be a small wireless transmitter sending out an RF signal which then will be received by a sensor array and used for localization and real-time tracking of the tumor position.
Volumetric modulated arc therapy (VMAT).
Volumetric modulated arc therapy (VMAT) is a new radiation technique, which can achieve highly conformal dose distributions on target volume coverage and sparing of normal tissues. The specificity of this technique is to modify the three parameters during the treatment. VMAT delivers radiation by rotating gantry (usually 360° rotating fields with one or more arcs), changing speed and shape of the beam with a multileaf collimator (MLC) ("sliding window" system of moving) and fluence output rate (dose rate) of the medical linear accelerator. VMAT also has the potential to give additional advantages in patient treatment, such as reduced delivery time of radiation, compared with conventional static field intensity modulated radiotherapy (IMRT).
Particle therapy.
In particle therapy (proton therapy being one example), energetic ionizing particles (protons or carbon ions) are directed at the target tumor. The dose increases while the particle penetrates the tissue, up to a maximum (the Bragg peak) that occurs near the end of the particle's range, and it then drops to (almost) zero. The advantage of this energy deposition profile is that less energy is deposited into the healthy tissue surrounding the target tissue.
Auger therapy.
Auger therapy (AT) makes use of a very high dose of ionizing radiation in situ that provides molecular modifications at an atomic scale. AT differs from conventional radiation therapy in several aspects; it neither relies upon radioactive nuclei to cause cellular radiation damage at a cellular dimension, nor engages multiple external pencil-beams from different directions to zero-in to deliver a dose to the targeted area with reduced dose outside the targeted tissue/organ locations. Instead, the in situ delivery of a very high dose at the molecular level using AT aims for in situ molecular modifications involving molecular breakages and molecular re-arrangements such as a change of stacking structures as well as cellular metabolic functions related to the said molecule structures.
Brachytherapy.
Brachytherapy (internal radiation therapy) is delivered by placing radiation source(s) inside or next to the area requiring treatment. Brachytherapy is commonly used as an effective treatment for cervical, prostate, breast, and skin cancer and can also be used to treat tumours in many other body sites. As with stereotactic radiation, brachytherapy treatments are often known by their brand names. For example, brand names for breast cancer brachytherapy treatments include SAVI, MammoSite, and Contura. Brand names for prostate cancer include Proxcelan, TheraSeed, and I-Seed.
In brachytherapy, radiation sources are precisely placed directly at the site of the cancerous tumour. This means that the irradiation only affects a very localized area – exposure to radiation of healthy tissues further away from the sources is reduced. These characteristics of brachytherapy provide advantages over external beam radiation therapy – the tumour can be treated with very high doses of localized radiation, whilst reducing the probability of unnecessary damage to surrounding healthy tissues. A course of brachytherapy can often be completed in less time than other radiation therapy techniques. This can help reduce the chance of surviving cancer cells dividing and growing in the intervals between each radiation therapy dose.
As one example of the localized nature of breast brachytherapy, the SAVI device delivers the radiation dose through multiple catheters, each of which can be individually controlled. This approach decreases the exposure of healthy tissue and resulting side effects, compared both to external beam radiation therapy and older methods of breast brachytherapy.
Intraoperative radiotherapy.
Intraoperative radiation therapy (IORT) is applying therapeutic levels of radiation to a target area, such as a cancer tumor, while the area is exposed during surgery. The goal of IORT is to improve local tumor control and survival rates for patients with different types of cancer.
Rationale.
The rationale for IORT is to deliver a high dose of radiation precisely to the targeted area with minimal exposure of surrounding tissues which are displaced or shielded during the IORT. Conventional radiation techniques such as external beam radiotherapy (EBRT) following surgical removal of the tumor have several drawbacks: The tumor bed where the highest dose should be applied is frequently missed due to the complex localization of the wound cavity even when modern radiotherapy planning is used. Additionally, the usual delay between the surgical removal of the tumor and EBRT may allow a repopulation of the tumor cells. These potentially harmful effects can be avoided by delivering the radiation more precisely to the targeted tissues leading to immediate sterilization of residual tumor cells. Another aspect is that wound fluid has a stimulating effect on tumor cells. IORT was found to inhibit the stimulating effects of wound fluid.
IORT in Breast Cancer.
The largest experience with IORT and the best evidence for its potentials exists in breast cancer where a substantial number of patients have already been treated using, for example, the TARGIT (TARGeted Intraoperative radioTherapy) technique.
On 11 November 2013 the 5-year results of local recurrence and overall survival from the TARGIT-A trial of TARGIT IORT for breast cancer were published in the Lancet.
3451 patients from 33 centres in 11 countries participated in the trial.
The analysis of the data found that
The conclusion was that TARGIT concurrent with lumpectomy within a risk-adapted approach should be considered as an option for eligible patients with breast cancer carefully selected as per the TARGIT-A trial protocol, as an alternative to postoperative EBRT. The results of TARGIT TARGIT IORT for breast cancer are discussed in a podcast of the TARGIT-A and ELIOT trials on the Lancet website. (full TARGIT IORT paper).
Radioisotope therapy.
Systemic radioisotope therapy (RIT) is a form of targeted therapy. Targeting can be due to the chemical properties of the isotope such as radioiodine which is specifically absorbed by the thyroid gland a thousandfold better than other bodily organs. Targeting can also be achieved by attaching the radioisotope to another molecule or antibody to guide it to the target tissue. The radioisotopes are delivered through infusion (into the bloodstream) or ingestion. Examples are the infusion of metaiodobenzylguanidine (MIBG) to treat neuroblastoma, of oral iodine-131 to treat thyroid cancer or thyrotoxicosis, and of hormone-bound lutetium-177 and yttrium-90 to treat neuroendocrine tumors (peptide receptor radionuclide therapy).
Another example is the injection of yttrium-90 radioactive glass or resin microspheres into the hepatic artery to radioembolize liver tumors or liver metastases. These microspheres are used for the treatment approach known as selective internal radiation therapy. The microspheres are approximately 30 µm in diameter (about one-third of a human hair) and are delivered directly into the artery supplying blood to the tumors. These treatments begin by guiding a catheter up through the femoral artery in the leg, navigating to the desired target site and administering treatment. The blood feeding the tumor will carry the microspheres directly to the tumor enabling a more selective approach than traditional systemic chemotherapy. There are currently two different kinds of microspheres: SIR-Spheres and TheraSphere.
A major use of systemic radioisotope therapy is in the treatment of bone metastasis from cancer. The radioisotopes travel selectively to areas of damaged bone, and spare normal undamaged bone. Isotopes commonly used in the treatment of bone metastasis are strontium-89 and samarium (153Sm) lexidronam.
In 2002, the United States Food and Drug Administration (FDA) approved ibritumomab tiuxetan (Zevalin), which is an anti-CD20 monoclonal antibody conjugated to yttrium-90.
In 2003, the FDA approved the tositumomab/iodine (131I) tositumomab regimen (Bexxar), which is a combination of an iodine-131 labelled and an unlabelled anti-CD20 monoclonal antibody.
These medications were the first agents of what is known as radioimmunotherapy, and they were approved for the treatment of refractory non-Hodgkins lymphoma.
Deep inspiration breath-hold.
Deep inspiration breath-hold (DIBH) is a method of delivering radiotherapy while limiting radiation exposure to the heart and lungs. It is used primarily for treating left-sided breast cancer. The technique involves a patient holding their breath during treatment. There are two basic methods of performing DIBH: free-breathing breath-hold and spirometry-monitored deep inspiration breath hold.
History.
Medicine has used radiation therapy as a treatment for cancer for more than 100 years, with its earliest roots traced from the discovery of x-rays in 1895 by Wilhelm Röntgen. Emil Grubbe of Chicago was possibly the first American physician to use x-rays to treat cancer, beginning in 1896.
The field of radiation therapy began to grow in the early 1900s largely due to the groundbreaking work of Nobel Prize–winning scientist Marie Curie (1867–1934), who discovered the radioactive elements polonium and radium in 1898. This began a new era in medical treatment and research. Through the 1920s the hazards of radiation exposure were not understood, and little protection was used. Radium was believed to have wide curative powers and radiotherapy was applied to many diseases.
Prior to World War 2, the only practical sources of radiation for radiotherapy were radium and its "emanation", radon gas, and the x-ray tube. External beam radiotherapy (teletherapy) began at the turn of the century with relatively low voltage (<150 kV) x-ray machines. It was found that while superficial tumors could be treated with low voltage x-rays, more penetrating, higher energy beams were required to reach tumors inside the body, requiring higher voltages. Orthovoltage X-rays, which used tube voltages of 200-500 kV, began to be used during the 1920s. To reach the most deeply buried tumors without exposing intervening skin and tissue to dangerous radiation doses required rays with energies of 1 MV or above, called "megavolt" radiation. Producing megavolt x-rays required voltages on the x-ray tube of 3 to 5 million volts, which required huge expensive installations. Megavoltage x-ray units were first built in the late 1930s but because of cost were limited to a few institutions. One of the first, installed at St. Bartholomew's hospital, London in 1937 and used until 1960, used a 30 foot long x-ray tube and weighed 10 tons. Radium produced megavolt gamma rays, but was extremely rare and expensive due to its low occurrence in ores. In 1937 the entire world supply of radium for radiotherapy was 50 grams, valued at £800,000, or $50 million in 2005 dollars.
The invention of the nuclear reactor in the Manhattan Project during World War 2 made possible the production of artificial radioisotopes for radiotherapy. Cobalt therapy, teletherapy machines using megavolt gamma rays emitted by cobalt-60, a radioisotope produced by irradiating ordinary cobalt metal in a reactor, revolutionized the field between the 1950s and the early 1980s. Cobalt machines were relatively cheap, robust and simple to use, although due to its 5.27 year half-life the cobalt had to be replaced about every 5 years.
Medical linear particle accelerators, developed since the 1940s, began replacing x-ray and cobalt units in the 1980s and these older therapies are now declining. Linear accelerators can produce higher energies, have more collimited beams, and do not produce radioactive waste with its attendant disposal problems like radioisotope therapies.
With Godfrey Hounsfield’s invention of computed tomography (CT) in 1971, three-dimensional planning became a possibility and created a shift from 2-D to 3-D radiation delivery. CT-based planning allows physicians to more accurately determine the dose distribution using axial tomographic images of the patient's anatomy. The advent of new imaging technologies, including magnetic resonance imaging (MRI) in the 1970s and positron emission tomography (PET) in the 1980s, has moved radiation therapy from 3-D conformal to intensity-modulated radiation therapy (IMRT) and to image-guided radiation therapy (IGRT) tomotherapy. These advances allowed radiation oncologists to better see and target tumors, which have resulted in better treatment outcomes, more organ preservation and fewer side effects.

</doc>
<doc id="26354" url="https://en.wikipedia.org/wiki?curid=26354" title="Ronald Coase">
Ronald Coase

Ronald Harry Coase (; 29 December 1910 – 2 September 2013) was a British economist and author. He was for much of his life the Clifton R. Musser Professor Emeritus of Economics at the University of Chicago Law School, where he arrived in 1964 and remained for the rest of his life. After studying with the University of London External Programme in 1927–29, Coase entered the London School of Economics, where he took courses with Arnold Plant. He received the Nobel Prize in Economics in 1991.
Coase, who believed economists should study real markets and not theoretical ones, established the case for the corporation as a means to pay the costs of operating a marketplace. Coase is best known for two articles in particular: "The Nature of the Firm" (1937), which introduces the concept of transaction costs to explain the nature and limits of firms, and "The Problem of Social Cost" (1960), which suggests that well-defined property rights could overcome the problems of externalities (see Coase theorem). Coase is also often referred to as the "father" of reform in the policy for allocation of the electromagnetic spectrum, based on his article "The Federal Communications Commission" (1959), where he criticises spectrum licensing, suggesting property rights as a more efficient method of allocating spectrum to users. Additionally, Coase's transaction costs approach is currently influential in modern organizational economics, where it was reintroduced by Oliver E. Williamson.
Biography.
Ronald Harry Coase was born in Willesden, a suburb of London, on 29 December 1910. His father, Henry Joseph Coase (1884-1973) was a telegraphist for the post office, as was his mother, Rosalie Elizabeth Coase (née Giles; 1882-1972), before marriage. As a child, Coase had a weakness in his legs, for which he was required to wear leg-irons. Due to this problem, he attended the school for physical defectives. At the age of 12, he was able to enter the Kilburn Grammar School on scholarship. At Kilburn, Coase completed the first year of his BComm degree and then passed on to the University of London. Coase married Marion Ruth Hartung of Chicago, Illinois in Willesden, England, 7 August 1937.
Coase attended the London School of Economics, where he received a bachelor of commerce degree in 1932. During his undergraduate studies, Coase received the Sir Ernest Cassel Travelling Scholarship, awarded by the University of London. He used this to visit the University of Chicago in 1931-1932 and studied with Frank Knight and Jacob Viner. Coase’s colleagues would later admit that they did not remember this first visit. Between 1932-34, Coase was an assistant lecturer at the Dundee School of Economics and Commerce at the University of Dundee. Subsequently, Coase was an assistant lecturer in commerce at the University of Liverpool between 1934–1935 before returning to London School of Economics as a member of staff until 1951. He then started to work at the University at Buffalo and retained his British citizenship after moving to the United States in the 1950s. In 1958, he moved to the University of Virginia. Coase settled at the University of Chicago in 1964 and became the editor of the "Journal of Law and Economics". He was also for a time a trustee of the Philadelphia Society. He received the Nobel Prize in Economics in 1991.
Nearing his 100th birthday, Coase was working on a book concerning the rise of the economies of China and Vietnam. An interview with Coase was conducted by Wang Ning (co-author of the book "How China Became Capitalist") 28–29 December 2010, in Chicago. In the interview, Coase explained the mission of the Coase China Society and his vision of economics and the part to be played by Chinese economists. Coase was honoured and received an honorary doctorate from the University at Buffalo Department of Economics in May 2012.
Coase died in Chicago on 2 September 2013. His wife had died on 17 October 2012. He was praised across the political spectrum, with Slate Magazine calling him "one of the most distinguished economists in the world" and "Forbes" magazine calling him "the greatest of the many great University of Chicago economists". The Washington Post called his work over eight decades "impossible to summarize" while recommending five of his papers to read.
Contributions to economics.
The Nature of the Firm.
In "The Nature of the Firm" (1937) – a brief but highly influential essay – Coase attempts to explain why the economy features a number of business firms instead of consisting exclusively of a multitude of independent, self-employed people who contract with one another. Given that "production could be carried on without any organization is, firms at all", Coase asks, why and under what conditions should we expect firms to emerge?
Since modern firms can only emerge when an entrepreneur of some sort begins to hire people, Coase's analysis proceeds by considering the conditions under which it makes sense for an entrepreneur to seek hired help instead of contracting out for some particular task.
The traditional economic theory of the time (in the tradition of Adam Smith) suggested that, because the market is "efficient" (that is, those who are best at providing each good or service most cheaply are already doing so), it should always be cheaper to contract out than to hire.
Coase noted, however, a number of transaction costs involved in using the market; the cost of obtaining a good or service via the market actually exceeds the price of the good. Other costs, including search and information costs, bargaining costs, keeping trade secrets, and policing and enforcement costs, can all potentially add to the cost of procuring something from another party. This suggests that firms will arise which can internalise the production of goods and services required to deliver a product, thus avoiding these costs. This argument sets the stage for the later contributions by Oliver Williamson: markets and hierarchies are alternative co-ordination mechanisms for economic transactions.
There is a natural limit to what a firm can produce internally, however. Coase notices "decreasing returns to the entrepreneur function", including increasing overhead costs and increasing propensity for an overwhelmed manager to make mistakes in resource allocation. These factors become countervailing costs to the use of the firm.
Coase argues that the size of a firm (as measured by how many contractual relations are "internal" to the firm and how many "external") is a result of finding an optimal balance between the competing tendencies of the costs outlined above. In general, making the firm larger will initially be advantageous, but the decreasing returns indicated above will eventually kick in, preventing the firm from growing indefinitely.
Other things being equal, therefore, a firm will tend to be larger:
The first two costs will increase with the spatial distribution of the transactions organised and the dissimilarity of the transactions. This explains why firms tend to either be in different geographic locations or to perform different functions. Additionally, technology changes that mitigate the cost of organising transactions across space may allow firms to become larger – the advent of the telephone and of cheap air travel, for example, would be expected to increase the size of firms.
The Problem of Social Cost.
Upon publishing his article The Federal Communications Commission in 1959, Coase received negative feedback from the faculty at the University of Chicago over his conclusions and apparent conflicts with A. C. Pigou. According to Coase, "What I said was thought to run counter to Pigou’s analysis by a number of economists at the University of Chicago and was therefore, according to them, wrong. At a meeting in Chicago I was able to convince these economists that I was right and Pigou’s analysis faulty." Coase had presented his paper in 1960 during a seminar in Chicago, to twenty senior economist including George Stigler and Milton Friedman. He gradually won over the usually skeptic audience, in what has later been considered a “paradigm-shifting moment” in the genesis of Chicago Law and Economics. Coase would join the Chicago faculty four years later.
Published in the "Journal of Law and Economics" in 1960, while Coase was a member of the Economics department at the University of Virginia, "The Problem of Social Cost" provided the key insight that it is unclear where the blame for externalities lies. The example he gave was of a rancher whose cattle stray onto the cropland of his neighbour. If the rancher is made to restrict his cattle, he is harmed just as the farmer as if the cattle remain unrestrained.
Coase argued that without transaction costs the initial assignment of property rights makes no difference to whether or not the farmer and rancher can achieve the economically efficient outcome. If the cost of restraining cattle by, say, building a fence, is less than the cost of crop damage, the fence will be built. The initial assignment of property rights determines who builds the fence. If the farmer is responsible for the crop damage, the farmer will pay for the fence (as long the fence costs less than the crop damage). If the rancher is responsible for the crop damage, the rancher will build the fence. The allocation of property rights is primarily an equity issue, with consequences for the distribution of income and wealth, rather than an efficiency issue.
With sufficient transaction costs, initial property rights matter for both equity and efficiency. From the point of view of economic efficiency, property rights should be assigned such that the owner of the rights wants to take the economically efficient action. To elaborate, if it is efficient not to restrict the cattle, the rancher should be given the rights (so that cattle can move about freely), whereas if it is efficient to restrict the cattle, the farmer should be given the rights over the movement of the cattle (so the cattle are restricted).
This seminal argument forms the basis of the famous Coase theorem as labelled by Stigler.
Law and Economics.
Though trained as an economist, Coase spent much of his career working in a law school. He is a central figure in the development of the subfield of law and economics. He viewed law and economics as having two parts, the first "using the economists’ approach and concepts to analyze the working of the legal system, often called the economic analysis of the law"; and the second "a study of the influence of the legal system on the working of the economic system.". Coase said that the second part "is the part of law and economics in which I am most interested."
In his Simons Lecture celebrating the centennial of the University of Chicago, titled "Law and Economics at Chicago," Coase noted that he only accidentally wandered into the field.
Despite wandering accidentally into law and economics, the opportunity to edit the Journal of Law and Economics was instrumental in bringing him to the University of Chicago.
Coase believed that the University of Chicago was the intellectual center of law and economics. He concluded his Simons lecture by stating,
"I am very much aware that, in concentrating in this lecture on law and economics at Chicago, I have neglected other significant contributions to the subject made elsewhere such as those by Guido Calabresi at Yale, by Donald Turner at Harvard, and by others. But it can hardly be denied that in the emergence of the subject of law and economics, Chicago has played a very significant part and one of which the University can be proud."
Coase Conjecture.
Another important contribution of Coase is the Coase Conjecture: an informal argument that durable-goods monopolists do not have market power because they are unable to commit to not lowering their prices in future periods.
Political views.
When asked what he considered his politics to be, Coase stated, "I really don't know. I don't reject any policy without considering what its results are. If someone says there's going to be regulation, I don't say that regulation will be bad. Let's see. What we discover is that most regulation does produce, or has produced in recent times, a worse result. But I wouldn't like to say that all regulation would have this effect because one can think of circumstances in which it doesn't."
Coase admitted that early in life, he aligned himself with socialism.
Guido Calabresi wrote that Coase’s focus on transaction costs in The Nature of the Firm was the result of his socialist beliefs. Reflecting on this, Coase wrote, "It is very difficult to know where one’s ideas come from but for all I know he may well be right." Coase continued:
The Ronald Coase Institute.
Coase was research advisor to the Ronald Coase Institute, an organisation that promotes research on the institutions – the laws, rules, customs, and norms – that govern real economic systems, with particular support for young scholars from developing and transitional countries.
The Coase-Sandor Institute for Law and Economics.
The University of Chicago Law School carries on the legacy of Ronald Coase through the mission of the Coase-Sandor Institute for Law and Economics. Each year, the University of Chicago Law School hosts the Coase Lecture, which was delivered in 2003 by Ronald Coase himself.

</doc>
<doc id="26360" url="https://en.wikipedia.org/wiki?curid=26360" title="Robert Gordis">
Robert Gordis

Robert Gordis (February 6, 1908 – 1992) was an American leading Conservative rabbi. He founded the first Conservative Jewish day school, served as President of the Rabbinical Assembly and the Synagogue Council of America, and was a professor at Jewish Theological Seminary of America from 1940 to 1992.
He wrote one of the first pamphlets explaining Conservative ideology in 1946, and in 1988 he chaired the Commission on the Philosophy of Conservative Judaism which produced the official statement of Conservative ideology "Emet Ve-Emunah".
Gordis was the founding editor in 1951 of the quarterly journal "Judaism".

</doc>
<doc id="26361" url="https://en.wikipedia.org/wiki?curid=26361" title="Richard R. Ernst">
Richard R. Ernst

Richard Robert Ernst (born August 14, 1933) is a Swiss physical chemist and Nobel Laureate.
Born in Winterthur, Switzerland, Ernst was awarded the Nobel Prize in Chemistry in 1991 for his contributions towards the development of Fourier transform Nuclear Magnetic Resonance (NMR) spectroscopy while at Varian Associates, Palo Alto and the subsequent development of multi-dimensional NMR techniques. These underpin applications to both to chemistry with NMR spectroscopy and to medicine with Magnetic Resonance Imaging (MRI).
Early life.
Ernst lived in a house that his grandfather, a merchant, had built in 1898. Ernst's father, Robert Ernst, was teaching as an architect at the technical high school of their town. He also had two sisters. His town had a lot of art and industry in it; a lot of the art had to do with music. Winterthur had a small but first-rank orchestra that was famous throughout Switzerland and also an industry in diesel motors and railway engines.
Ernst soon became interested in both sides. Playing the violoncello brought him into numerous chamber and church music ensembles, and stimulated his interest in musical composition that he tried extensively while in high school. At the age of 13, though, Ernst found in his attic a case filled with chemicals, remainders of an uncle who died in 1923 and was, as a metallurgical engineer, interested in chemistry and photography. "I became almost immediately fascinated by the possibilities of trying out all conceivable reactions with them, some leading to explosions, others to unbearable poisoning of the air in our house, frightening my parents." Ernst said but he had survived and started to read all chemistry books that he could get a hand on, first some 19th-century books from his home library that did not provide much reliable information, and then he emptied the rather extensive city library. Soon, though, he knew that he wanted become a chemist, rather than a composer. "I wanted to understand the secrets behind my chemical experiments and behind the processes in nature."
Education.
After he had finished high school, Ernst started with high expectations and enthusiasm to study chemistry at the famous Swiss Federal Institute of Technology in Zurich (ETH Zurich). But he was disappointed by the state of chemistry in the early 1950s as it was taught at ETH Zurich; the students had to memorize uncountable facts that even the professors did not understand. The physical chemistry lectures did not reveal much insight either, they were limited just to classical thermodynamics. So, Ernst had to return to reading in order to get the knowledge he wanted. He often read the book "Textbook of Physical Chemistry 
" by S. Glasstone. In it he learned about the fundamentals of quantum mechanics, spectroscopy, statistical mechanics, and statistical thermodynamics.
Ernst received both his diploma in chemistry in 1957 and his Ph.D. in physical chemistry in 1962 from ETH Zurich.
Research and career.
Ernst served as faculty at ETH Zurich, Switzerland, from which he is now retired. From 1963 to 1968, Ernst worked as a research chemist with Weston A. Anderson in Palo Alto, California at the Varian Corporation. In 1966, working with an American colleague, Ernst discovered that the sensitivity of NMR techniques (hitherto limited to analysis of only a few nuclei) could be dramatically increased by replacing the slow, sweeping radio waves traditionally used in NMR spectroscopy with short, intense pulses. His discovery enabled analysis of a great many more types of nuclei and smaller amounts of materials.
When he was in California, Ernst regularly attended the meeting on NMR spectroscopy that was held at the Mellon Institute in Pittsburgh. He frequently spoke about the advances he was making. All of the important investigators of NMR in the world were also attendees.
In 1968 he returned to Switzerland to teach at his alma mater. He was made assistant professor in 1970 and full professor in 1976. His second major contribution to the field of NMR spectroscopy was the experimental demonstration of the “two-dimensional” NMR technique first introduced by Jean Jeener at the 1971 AMPERE Summer School. Multi-dimensional NMR enabled a high-resolution study of larger molecules than had previously been accessible to NMR. With Ernst's refinements, scientists were able to determine the 3D structure of organic and inorganic compounds and of biological macromolecules such as proteins; to study the interaction between biological molecules and other substances such as metal ions, water, and drugs; to identify chemical species; and to study the rates of chemical reactions.
Ernst also was credited with many inventions and held several patents in his field.
Awards and honours.
Ernst is a foreign fellow of the Bangladesh Academy of Sciences. He was elected a Foreign Member of the Royal Society (ForMemRS) in 1993. He was awarded the John Gamble Kirkwood Medal in 1989.
The Nobel Prize in Chemistry 1991 was awarded to Richard R. Ernst "for his contributions to the development of the methodology of high resolution nuclear magnetic resonance (NMR) spectroscopy".
MLA style: "The Nobel Prize in Chemistry 1991". Nobelprize.org. Nobel Media AB 2014. Web. 10 Nov 2015. <http://www.nobelprize.org/nobel_prizes/chemistry/laureates/1991/>
He holds Honorary Doctorates from the Technical University of Munich and University of Zurich.
Ernst is member of the World Knowledge Dialogue Scientific Board. Ernst was awarded the Louisa Gross Horwitz Prize of Columbia University in 1991. He was also awarded the Tadeus Reichstein Medal in 2000 and the Romanian National Medal in 2004.
The 2009 Bel Air Film Festival featured the world premiere of a documentary film on Ernst "Science Plus Dharma Equals Social Responsibility". Produced by Carlo Burton, the film takes place in Ernst's hometown in Switzerland.
Personal life.
Ernst is extremely interested and knowledgeable concerning Tibetan Buddhist art. He has studied non-destructive methods of learning the chemistry of the pigments that were using in their paintings.

</doc>
<doc id="26363" url="https://en.wikipedia.org/wiki?curid=26363" title="RIPEMD">
RIPEMD

RIPEMD (RACE Integrity Primitives Evaluation Message Digest) is a family of cryptographic hash functions developed in Leuven, Belgium, by Hans Dobbertin, Antoon Bosselaers and Bart Preneel at the COSIC research group at the Katholieke Universiteit Leuven, and first published in 1996. RIPEMD was based upon the design principles used in MD4, and is similar in performance to the more popular SHA-1. 
RIPEMD-160 is an improved, 160-bit version of the original RIPEMD, and the most common version in the family. RIPEMD-160 was designed in the open academic community, in contrast to the NSA-designed SHA-1 and SHA-2 algorithms. On the other hand, RIPEMD-160 appears to be used somewhat less frequently than SHA-1, which may have caused it to be less scrutinized than SHA. RIPEMD-160 is not known to be constrained by any patents.
As well as 160-bit, there also exist 128-, 256- and 320-bit versions of this algorithm, called RIPEMD-128, RIPEMD-256, and RIPEMD-320, respectively. The 128-bit version was intended only as a drop-in replacement for the original RIPEMD, which was also 128-bit, and which had been found to have questionable security. The 256- and 320-bit versions diminish only the chance of accidental collision and don't have higher levels of security (against preimage attacks) as compared to, respectively, RIPEMD-128 and RIPEMD-160.
In August 2004, a collision was reported for the original RIPEMD. This does not apply to RIPEMD-160.
RIPEMD-160 hashes.
The 160-bit RIPEMD-160 hashes (also termed RIPE "message digests") are typically represented as 40-digit hexadecimal numbers. The following demonstrates a 43-byte ASCII input and the corresponding RIPEMD-160 hash:
RIPEMD-160 behaves with the desired avalanche effect of cryptographic hash functions (small changes, e.g. changing d to c, result in a completely different hash):
The hash of a zero-length string is:

</doc>
<doc id="26364" url="https://en.wikipedia.org/wiki?curid=26364" title="Roman law">
Roman law

Roman law is the legal system of ancient Rome, including Roman Military Jurisdiction and the legal developments spanning over a thousand years of jurisprudence, from the 12 Tables (c. 449 BC), to the "Corpus Juris Civilis" (AD 529) ordered by Eastern Roman Emperor Justinian I. The historical importance of Roman law is reflected by the continued use of Latin legal terminology in many legal systems influenced by it.
After the dissolution of the Western Roman Empire, the Roman law remained in effect in the Eastern Roman Empire. From the 7th century onward, the legal language in the East was Greek.
"Roman law" also denotes the legal system applied in most of Western Europe until the end of the 18th century. In Germany, Roman law practice remained in place longer under the Holy Roman Empire (963–1806). Roman law thus served as a basis for legal practice throughout Western continental Europe, as well as in most former colonies of these European nations, including Latin America, and also in Ethiopia. English and North American common law were influenced also by Roman law, notably in their Latinate legal glossary (for example, "stare decisis", "culpa in contrahendo", "pacta sunt servanda"). Eastern Europe was also influenced by the jurisprudence of the "Corpus Juris Civilis", especially in countries such as medieval Romania (Wallachia, Moldova, and some other medieval provinces/historical regions) which created a new system, a mixture of Roman and local law. Also, Eastern European law was influenced by the "Farmer's Law" of the medieval Byzantine legal system.
Development.
Before the Twelve Tables (754–449 BC), private law comprised the Roman civil law ("ius civile Quiritium") that applied only to Roman citizens, and was bonded to religion; undeveloped, with attributes of strict formalism, symbolism, and conservatism, e.g. the ritual practice of mancipatio (a form of sale). The jurist Sextus Pomponius said, "At the beginning of our city, the people began their first activities without any fixed law, and without any fixed rights: all things were ruled despotically, by kings". It is believed that Roman Law is rooted in the Etruscan religion, emphasising ritual.
The Twelve Tables.
The first legal text is the Law of the Twelve Tables, dating from the mid-5th century BC. The plebeian tribune, C. Terentilius Arsa, proposed that the law should be written, in order to prevent magistrates from applying the law arbitrarily. After eight years of political struggle, the plebeian social class convinced the patricians to send a delegation to Athens, to copy the Laws of Solon; they also dispatched delegations to other Greek cities for like reason. In 451 BC, according to the traditional story (as Livy tells it), ten Roman citizens were chosen to record the laws ("decemviri legibus scribundis"). While they were performing this task, they were given supreme political power ("imperium"), whereas the power of the magistrates was restricted. In 450 BC, the "decemviri" produced the laws on ten tablets ("tabulae"), but these laws were regarded as unsatisfactory by the plebeians. A second decemvirate is said to have added two further tablets in 449 BC. The new Law of the Twelve Tables was approved by the people's assembly.
Modern scholars tend to challenge the accuracy of Roman historians. They generally do not believe that a second decemvirate ever took place. The decemvirate of 451 is believed to have included the most controversial points of customary law, and to have assumed the leading functions in Rome. Furthermore, the question on the Greek influence found in the early Roman Law is still much discussed. Many scholars consider it unlikely that the patricians sent an official delegation to Greece, as the Roman historians believed. Instead, those scholars suggest, the Romans acquired Greek legislations from the Greek cities of Magna Graecia, the main portal between the Roman and Greek worlds. The original text of the Twelve Tables has not been preserved. The tablets were probably destroyed when Rome was conquered and burned by the Gauls in 387 BC.
The fragments which did survive show that it was not a law code in the modern sense. It did not provide a complete and coherent system of all applicable rules or give legal solutions for all possible cases. Rather, the tables contained specific provisions designed to change the then-existing customary law. Although the provisions pertain to all areas of law, the largest part is dedicated to private law and civil procedure.
Early law and jurisprudence.
Many laws include "Lex Canuleia" (445 BC; which allowed the marriage—"ius connubii"—between patricians and plebeians), "Leges Licinae Sextiae" (367 BC; which made restrictions on possession of public lands — "ager publicus" — and also made sure that one of the consuls was plebeian), "Lex Ogulnia" (300 BC; plebeians received access to priest posts), and "Lex Hortensia" (287 BC; verdicts of plebeian assemblies — "plebiscita" — now bind all people).
Another important statute from the Republican era is the "Lex Aquilia" of 286 BC, which may be regarded as the root of modern tort law. However, Rome's most important contribution to European legal culture was not the enactment of well-drafted statutes, but the emergence of a class of professional jurists ("prudentes", sing. "prudens", or "jurisprudentes") and of a legal science. This was achieved in a gradual process of applying the scientific methods of Greek philosophy to the subject of law, a subject which the Greeks themselves never treated as a science.
Traditionally, the origins of Roman legal science are connected to Gnaeus Flavius. Flavius is said to have published around the year 300 BC the formularies containing the words which had to be spoken in court to begin a legal action. Before the time of Flavius, these formularies are said to have been secret and known only to the priests. Their publication made it possible for non-priests to explore the meaning of these legal texts. Whether or not this story is credible, jurists were active and legal treatises were written in larger numbers the 2nd century BC. Among the famous jurists of the republican period are Quintus Mucius Scaevola who wrote a voluminous treatise on all aspects of the law, which was very influential in later times, and Servius Sulpicius Rufus, a friend of Marcus Tullius Cicero. Thus, Rome had developed a very sophisticated legal system and a refined legal culture when the Roman republic was replaced by the monarchical system of the principate in 27 BC .
Pre-classical period.
In the period between about 201 to 27 BC, we can see the development of more flexible laws to match the needs of the time. In addition to the old and formal "ius civile" a new juridical class is created: the "ius honorarium", which can be defined as "The law introduced by the magistrates who had the right to promulgate edicts in order to support, supplement or correct the existing law." With this new law the old formalism is being abandoned and new more flexible principles of "ius gentium" are used.
The adaptation of law to new needs was given over to juridical practice, to magistrates, and especially to the praetors. A praetor was not a legislator and did not technically create new law when he issued his edicts ("magistratuum edicta"). In fact, the results of his rulings enjoyed legal protection ("actionem dare") and were in effect often the source of new legal rules. A Praetor's successor was not bound by the edicts of his predecessor; however, he did take rules from edicts of his predecessor that had proved to be useful. In this way a constant content was created that proceeded from edict to edict ("edictum traslatitium").
Thus, over the course of time, parallel to the civil law and supplementing and correcting it, a new body of praetoric law emerged. In fact, praetoric law was so defined by the famous Roman jurist Papinian (Amilius Papinianus—died in 212 AD): ""Ius praetorium est quod praetores introduxerunt adiuvandi vel supplendi vel corrigendi iuris civilis gratia propter utilitatem publicam"" ("praetoric law is that law introduced by praetors to supplement or correct civil law for public benefit"). Ultimately, civil law and praetoric law were fused in the "Corpus Juris Civilis".
Classical Roman law.
The first 250 years of the current era are the period during which Roman law and Roman legal science reached its greatest degree of sophistication. The law of this period is often referred to as the "classical period of Roman law". The literary and practical achievements of the jurists of this period gave Roman law its unique shape.
The jurists worked in different functions: They gave legal opinions at the request of private parties. They advised the magistrates who were entrusted with the administration of justice, most importantly the praetors. They helped the praetors draft their edicts, in which they publicly announced at the beginning of their tenure, how they would handle their duties, and the formularies, according to which specific proceedings were conducted. Some jurists also held high judicial and administrative offices themselves.
The jurists also produced all kinds of legal punishments. Around AD 130 the jurist Salvius Iulianus drafted a standard form of the praetor's edict, which was used by all praetors from that time onwards. This edict contained detailed descriptions of all cases, in which the praetor would allow a legal action and in which he would grant a defense. The standard edict thus functioned like a comprehensive law code, even though it did not formally have the force of law. It indicated the requirements for a successful legal claim. The edict therefore became the basis for extensive legal commentaries by later classical jurists like Paulus and Domitius Ulpianus. The new concepts and legal institutions developed by pre-classical and classical jurists are too numerous to mention here. Only a few examples are given here:
Post-classical law.
By the middle of the 3rd century, the conditions for the flourishing of a refined legal culture had become less favourable. The general political and economic situation deteriorated as the emperors assumed more direct control of all aspects of political life. The political system of the principate, which had retained some features of the republican constitution, began to transform itself into the absolute monarchy of the dominate. The existence of a legal science and of jurists who regarded law as a science, not as an instrument to achieve the political goals set by the absolute monarch, did not fit well into the new order of things. The literary production all but ended. Few jurists after the mid-3rd century are known by name. While legal science and legal education persisted to some extent in the eastern part of the Empire, most of the subtleties of classical law came to be disregarded and finally forgotten in the west. Classical law was replaced by so-called vulgar law.
Substance.
Public law.
The Roman Republic's constitution or "mos maiorum" ("custom of the ancestors") was an unwritten set of guidelines and principles passed down mainly through precedent. Concepts that originated in the Roman constitution live on in constitutions to this day. Examples include checks and balances, the separation of powers, vetoes, filibusters, quorum requirements, term limits, impeachments, the powers of the purse, and regularly scheduled elections. Even some lesser used modern constitutional concepts, such as the block voting found in the electoral college of the United States, originate from ideas found in the Roman constitution.
The constitution of the Roman Republic was not formal or even official. Its constitution was largely unwritten, and was constantly evolving throughout the life of the Republic. Throughout the 1st century BC, the power and legitimacy of the Roman constitution was progressively eroding. Even Roman constitutionalists, such as the senator Cicero, lost a willingness to remain faithful to it towards the end of the republic. When the Roman Republic ultimately fell in the years following the Battle of Actium and Mark Antony's suicide, what was left of the Roman constitution died along with the Republic. The first Roman Emperor, Augustus, attempted to manufacture the appearance of a constitution that still governed the Empire. The belief in a surviving constitution lasted well into the life of the Roman Empire.
Private law.
"Stipulatio" was the basic form of contract in Roman law. It was made in the format of question and answer. The precise nature of the contract was disputed, as can be seen below.
"Rei vindicatio" is a legal action by which the plaintiff demands that the defendant return a thing that belongs to the plaintiff. It may only be used when plaintiff owns the thing, and the defendant is somehow impeding the plaintiff's possession of the thing. The plaintiff could also institute an "actio furti" (a personal action) to punish the defendant. If the thing could not be recovered, the plaintiff could claim damages from the defendant with the aid of the "condictio furtiva" (a personal action). With the aid of the "actio legis Aquiliae" (a personal action), the plaintiff could claim damages from the defendant. "Rei vindicatio" was derived from the ius civile, therefore was only available to Roman citizens.
Status.
To describe a person's position in the legal system, Romans mostly used the expression "togeus". The individual could have been a Roman citizen ("status civitatis") unlike foreigners, or he could have been free ("status libertatis") unlike slaves, or he could have had a certain position in a Roman family ("status familiae") either as the head of the family ("pater familias"), or some lower "member".*"alieni iuris"-which lives by someone elses law. Two status types were Senator and Emperor.
Litigation.
The history of Roman Law can be divided into three systems of procedure: that of "legis actiones", the "formulary system", and "cognitio extra ordinem". The periods in which these systems were in use overlapped one another and did not have definitive breaks, but it can be stated that the legis actio system prevailed from the time of the XII Tables (c. 450 BC) until about the end of the 2nd century BC, that the formulary procedure was primarily used from the last century of the Republic until the end of the classical period (c. AD 200), and that of cognitio extraordinarem was in use in post-classical times. Again, these dates are meant as a tool to help understand the types of procedure in use, not as a rigid boundary where one system stopped and another began.
During the republic and until the bureaucratization of Roman judicial procedure, the judge was usually a private person ("iudex privatus"). He had to be a Roman male citizen. The parties could agree on a judge, or they could appoint one from a list, called "album iudicum". They went down the list until they found a judge agreeable to both parties, or if none could be found they had to take the last one on the list.
No one had a legal obligation to judge a case. The judge had great latitude in the way he conducted the litigation. He considered all the evidence and ruled in the way that seemed just. Because the judge was not a jurist or a legal technician, he often consulted a jurist about the technical aspects of the case, but he was not bound by the jurist's reply. At the end of the litigation, if things were not clear to him, he could refuse to give a judgment, by swearing that it wasn't clear. Also, there was a maximum time to issue a judgment, which depended on some technical issues (type of action, etc.).
Later on, with the bureaucratization, this procedure disappeared, and was substituted by the so-called "extra ordinem" procedure, also known as cognitory. The whole case was reviewed before a magistrate, in a single phase. The magistrate had obligation to judge and to issue a decision, and the decision could be appealed to a higher magistrate.
Legacy.
In the East.
When the centre of the Empire was moved to the Greek East in the 4th century, many legal concepts of Greek origin appeared in the official Roman legislation. The influence is visible even in the law of persons or of the family, which is traditionally the part of the law that changes least. For example, Constantine started putting restrictions on the ancient Roman concept of "patria potestas", the power held by the male head of a family over his descendents, by acknowledging that persons "in potestate", the descendents, could have proprietary rights. He was apparently making concessions to the much stricter concept of paternal authority under Greek-Hellenistic law. The "Codex Theodosianus" (438 AD) was a codification of Constantian laws. Later emperors went even further, until Justinian finally decreed that a child "in potestate" became owner of everything it acquired, except when it acquired something from its father.
The codes of Justinian, particularly the "Corpus Juris Civilis" (529-534) continued to be the basis of legal practice in the Empire throughout its so-called "Byzantine" history. Leo III the Isaurian issued a new code, the "Ecloga", in the early 8th century. In the 9th century, the emperors Basil I and Leo VI the Wise commissioned a combined translation of the Code and the Digest, parts of Justinian's codes, into Greek, which became known as the "Basilica". Roman law as preserved in the codes of Justinian and in the Basilica remained the basis of legal practice in Greece and in the courts of the Eastern Orthodox Church even after the fall of the Byzantine Empire and the conquest by the Turks, and also formed the basis for much of the "Fetha Negest", which remained in force in Ethiopia until 1931.
In the West.
In the west, Justinian's political authority never went any farther than certain portions of the Italian and Hispanic peninsulas. Law codes were issued by the Germanic kings, however, the influence of early Eastern Roman codes on some of these is quite discernible. In many early Germanic states, Roman citizens continued to be governed by Roman laws for quite some time, even while members of the various Germanic tribes were governed by their own respective codes.
The "Codex Justinianus" and the Institutes of Justinian were known in Western Europe, and along with the earlier code of Theodosius II, served as models for a few of the Germanic law codes; however, the "Digest" portion was largely ignored for several centuries until around 1070, when a manuscript of the "Digest" was rediscovered in Italy. This was done mainly through the works of glossars who wrote their comments between lines ("glossa interlinearis"), or in the form of marginal notes ("glossa marginalis"). From that time, scholars began to study the ancient Roman legal texts, and to teach others what they learned from their studies. The center of these studies was Bologna. The law school there gradually developed into Europe's first university.
The students who were taught Roman law in Bologna (and later in many other places) found that many rules of Roman law were better suited to regulate complex economic transactions than were the customary rules, which were applicable throughout Europe. For this reason, Roman law, or at least some provisions borrowed from it, began to be re-introduced into legal practice, centuries after the end of the Roman empire. This process was actively supported by many kings and princes who employed university-trained jurists as counselors and court officials and sought to benefit from rules like the famous "Princeps legibus solutus est" ("The sovereign is not bound by the laws", a phrase initially coined by Ulpian, a Roman jurist).
There have been several reasons why Roman law was favored in the Middle Ages. It was because Roman law regulated the legal protection of property and the equality of legal subjects and their wills, and because it prescribed the possibility that the legal subjects could dispose their property through testament.
By the middle of the 16th century, the rediscovered Roman law dominated the legal practice of many European countries. A legal system, in which Roman law was mixed with elements of canon law and of Germanic custom, especially feudal law, had emerged. This legal system, which was common to all of continental Europe (and Scotland) was known as "Ius Commune". This "Ius Commune" and the legal systems based on it are usually referred to as civil law in English-speaking countries.
Only England and the Nordic countries did not take part in the wholesale reception of Roman law. One reason for this is that the English legal system was more developed than its continental counterparts by the time Roman law was rediscovered. Therefore, the practical advantages of Roman law were less obvious to English practitioners than to continental lawyers. As a result, the English system of common law developed in parallel to Roman-based civil law, with its practitioners being trained at the Inns of Court in London rather than receiving degrees in Canon or Civil Law at the Universities of Oxford or Cambridge. Elements of Romano-canon law were present in England in the ecclesiastical courts and, less directly, through the development of the equity system. In addition, some concepts from Roman law made their way into the common law. Especially in the early 19th century, English lawyers and judges were willing to borrow rules and ideas from continental jurists and directly from Roman law.
The practical application of Roman law and the era of the European "Ius Commune" came to an end, when national codifications were made. In 1804, the French civil code came into force. In the course of the 19th century, many European states either adopted the French model or drafted their own codes. In Germany, the political situation made the creation of a national code of laws impossible. From the 17th century, Roman law in Germany had been heavily influenced by domestic (common) law, and it was called "usus modernus Pandectarum". In some parts of Germany, Roman law continued to be applied until the German civil code (Bürgerliches Gesetzbuch, BGB) came into force in 1900.
Colonial expansion spread the civil law system.
Today.
Today, Roman law is no longer applied in legal practice, even though the legal systems of some states like South Africa and San Marino are still based on the old "Ius Commune". However, even where the legal practice is based on a code, many rules deriving from Roman law apply: No code completely broke with the Roman tradition. Rather, the provisions of Roman law were fitted into a more coherent system and expressed in the national language. For this reason, knowledge of Roman law is indispensable to understand the legal systems of today. Thus, Roman law is often still a mandatory subject for law students in civil law jurisdictions.
As steps towards a unification of the private law in the member states of the European Union are being taken, the old "Ius Commune", which was the common basis of legal practice everywhere, but allowed for many local variants, is seen by many as a model.

</doc>
<doc id="26366" url="https://en.wikipedia.org/wiki?curid=26366" title="Reuben James">
Reuben James

Reuben James ( 1776 – 3 December 1838) was a boatswain's mate of the United States Navy, famous for his heroism in the First Barbary War.
Career.
Born in Delaware around 1776, James joined the United States Navy and served on several ships, including the frigate . During the First Barbary War, the American frigate was captured by the Barbary pirates when it ran aground in the city of Tripoli, on the southern shores of the Mediterranean Sea. During the course of the naval blockade of the harbor, there were numerous engagements, the most intense being the Gunboat Battle of August 3, 1804. During the battle, Lieutenant Stephen Decatur boarded a Tripolitan gunboat that he believed was crewed by the men who had mortally wounded his brother after supposedly surrendering. While Lieutenant Decatur was locked in hand-to-hand combat with the Tripolitan commander, another Tripolitan sailor swung his saber at him. According to early accepted accounts, Reuben James interposed himself between the descending sword and his commander, taking the blow on his head. The blow did not kill him, and he recovered later to continue serving in the Navy.
This account, though, is now considered to be in error. No one by the name of James is recorded as having received medical treatment after the battle. Another of Decatur's crewmen, Daniel Frazier, did receive medical treatment for a serious saber slash to the head. This supports some initial accounts that it was Frazier, not James, who saved Decatur's life.
James continued his Naval career, serving many years with Decatur. He was forced to retire in January 1836 because of ill health. He died in 1838 at the U.S. Naval Hospital in Washington, DC.
Influence.
Three warships of the Navy have been named "Reuben James" in his honor:
There are two songs with the title "Reuben James":
James Island of Washington state was named for James.
References.
Other sources.
Wheelan, Joseph. "Jefferson's War: American's First War on Terror 1801--1805", New York: Carroll & Graf Publishers, 2003.

</doc>
<doc id="26367" url="https://en.wikipedia.org/wiki?curid=26367" title="Rockwell International">
Rockwell International

Rockwell International was a major American manufacturing conglomerate in the latter half of the 20th century, involved in aircraft, the space industry, both defense-oriented and commercial electronics, automotive and truck components, printing presses, valves and meters, and industrial automation. It was the ultimate incarnation of a series of companies founded by Colonel Willard Rockwell. At its peak in the 1990s, Rockwell International was No. 27 on the Fortune 500 list, with assets of over $8 billion, sales of $27 billion and 115,000 employees.
Predecessor companies.
Willard F. Rockwell made his fortune with the invention and successful launch of a new bearing system for truck axles in 1919. He merged his Oshkosh, Wisconsin-based operation with the Timken-Detroit Axle Company in 1928, rising to become chairman of its board in 1940.
In 1956 Rockwell Manufacturing Co. bought Walker-Turner from Kearney and Trecker. One year later in 1957, Walker-Turner operations were closed down in Plainfield, New Jersey and moved to Bellefontaine, Ohio and Tupelo, Mississippi.
Timken-Detroit merged in 1953 with the Standard Steel Spring Company, forming the Rockwell Spring and Axle Company. After various mergers with automotive suppliers, it comprised about 10 to 20 factories in the Upper Midwestern U.S. and southern Ontario, and in 1958 renamed itself Rockwell-Standard Corporation.
Pittsburgh-based Rockwell Standard then acquired and merged with Los Angeles-based North American Aviation to form North American Rockwell in September 1967. It then purchased or merged with Miehle-Goss-Dexter, the largest supplier of printing presses, and in 1973 acquired Collins Radio, a major avionics supplier. Finally, in 1973 the company merged with Rockwell Manufacturing, run by Willard Rockwell, Jr., to form Rockwell International. In the same year, the company acquired Admiral Radio and TV for $500 million. In 1979, the appliance division was sold to Magic Chef.
Rockwell International also drew on the strengths of several of George Westinghouse's concerns, and Westinghouse is considered a co-founder of the company.
Products.
The various Rockwell companies list a large number of firsts in their histories, including the World War II North American P-51 Mustang fighter and the North American B-25 Mitchell bomber, and the Korean War-era North American F-86 Sabre fighter jet, as well as the Apollo spacecraft, the Rockwell B-1 Lancer bomber, the Space Shuttle orbiter, and most of the Navstar Global Positioning System satellites.
Rocketdyne, which had been spun off by North American in 1955, was re-merged into Rockwell, and by that time produced most of the rocket engines used in the United States. Rockwell also purchased the Aero Design and Engineering Company from William and Rufus Travis Amis. Rockwell redesigned the company's Aero Commander aircraft, introducing its new design as the Rockwell Commander 112 and Commander 114.
The company developed a desktop calculator based on a MOSFET chip for use by its engineers. In 1967 Rockwell set up its own manufacturing plant to produce them, starting what would become Rockwell Semiconductor. One of its major successes came in the early 1990s when it introduced the first low-cost 14.4 kbit/s modem chip set, which was used in a huge number of modems.
Collins radios were fitted to 80% of the airliners which were based in First World Countries. Collins designed and built the radios that communicated the Apollo moon landings and the high frequency radio network that allows worldwide communication with U.S. military aircraft. Rockwell designed and built the third stage of the Minuteman intercontinental ballistic missile, and the Advanced Inertial Reference Sphere inertial navigation system that provided its navigation. It also built inertial navigation systems for the fleet of ballistic missile submarines. 
In addition to the manufacture of nuclear missiles and bombers, Rockwell also produced key components of the bombs they carried, including plutonium triggers at the Rocky Flats plant in Colorado. Rockwell ran the weapons plant from 1975 to 1990.
Rockwell built heavy-duty truck axles and drive-trains in the U.S., along with power windows, seats and locks. Rockwell also built yachts and business jets and owned large amounts of real estate.
It was also involved in providing custom electronic intelligence equipment to the Imperial Iranian Air Force as part of Project Ibex and paid bribes to the Shah of Iran in order to secure contracts there.
Apex and break-up.
With the death of company founder and first CEO Willard F. Rockwell in 1978, and the stepping down of his son Willard Rockwell, Jr. in 1979 as the second CEO, Bob Anderson became CEO and led the company through the 1980s when it became the largest U.S. defense contractor and largest NASA contractor. Rockwell also acquired the privately held Allen-Bradley Company for $1.6 billion in February 1985 — $1 billion of which was cash to the owners of Allen Bradley — and became a producer of railroad electronics.
During the 1980s, Anderson, his CFO Bob dePalma and the Rockwell management team built the company to #27 on the Fortune 500 list. It boasted sales of $12 billion and assets of over $8 billion. Its workforce of over 100,000 was organized into nine major divisions — Space, Aircraft, Defense Electronics, Commercial Electronics, Light Duty Automotive Components, Heavy Duty Automotive Components, Printing Presses, Valves and Meters, and Industrial Automation. Rockwell International was a major employer in Southern California, northern Ohio, northern Georgia, eastern Oklahoma, Michigan, west Texas, Iowa, Illinois, Wisconsin and western Pennsylvania.
Anderson stepped down as CEO in February 1988, leaving the company to president Donald R. Beall. The completion of the Space Shuttle program and cancellation of the B-1 bomber had led to a decline in revenues, and Beall sought to diversify the company away from government contracts. The end of the Cold War and the perceived "peace dividend", however, prompted accelerated divestitures and sweeping management reforms. From 1988 to 2001 the company moved its headquarters four times: from Pittsburgh, Pennsylvania to El Segundo, California to Seal Beach, California to Costa Mesa, California to Milwaukee, Wisconsin.
At the end of the 1980s, the company sold its valve and meter division, formerly Rockwell Manufacturing, to British Tyre & Rubber. It also sold its printing press division to an internal management team. Following the "peace dividend" after the fall of the Soviet bloc, the company sold its defense and aerospace business, including what was once North American Aviation and Rocketdyne, to Boeing Integrated Defense Systems in December 1996. In the 1990s, the company spun off its semiconductor products as Conexant Technologies (CNXT), which is publicly traded and based in Newport Beach, California. Rockwell International also spun off its automotive division as a publicly traded company, Meritor Automotive, based in Troy, Michigan, which then merged with Arvin Industries to form Arvin Meritor. That company is now known as Meritor, Inc.
In 2001, what remained of Rockwell International was split into two companies, Rockwell Automation and Rockwell Collins — both publicly traded companies — ending the run of what had once been a massive and diverse conglomerate. The split was structured so that Rockwell Automation was the legal successor of the old Rockwell International, while Rockwell Collins was the spin-off.
Research laboratory.
Rockwell International had a major research laboratory complex in Thousand Oaks, Ventura County, California. It was founded and built by North American Aviation in 1962, as the North American Science Center. In 1973 it became the Rockwell International Science Center.
The laboratory did independent contract research for the U.S. Government, and also provided research services for the company's business units. It was famous for its research in: advanced materials, particularly ceramics; for its infrared imagers; for its research in liquid-crystal displays; and for its high-speed electronics. The laboratory invented Metal Organic Chemical Vapor Deposition (MOCVD). It also achieved fame in selected areas of information science, notably human-computer interaction, augmented reality, multimedia systems, and diagnostics. Rockwell Science Center led the United States Army Research Laboratory's Advanced Displays Federated Laboratory Consortium in the late 1990s. In 2000, the infrared imaging division of the laboratory moved into a new building in Camarillo, California.
After Rockwell International's breakup in 2001, the laboratory was spun off as a semi-autonomous company called Rockwell Scientific, half owned by Rockwell Collins and half owned by Rockwell Automation. In 2006 the main laboratory and infrared imaging division were sold to Teledyne Corporation. Teledyne made the laboratory complex in Thousand Oaks into its corporate headquarters. A reduced but active research and development operation continues there, under the name Teledyne Scientific & Imaging, LLC.

</doc>
<doc id="26368" url="https://en.wikipedia.org/wiki?curid=26368" title="Richard I of England">
Richard I of England

Richard I (8 September 1157 – 6 April 1199) was King of England from 6 July 1189 until his death. He also ruled as Duke of Normandy (as Richard IV), Duke of Aquitaine, Duke of Gascony, Lord of Cyprus, Count of Poitiers, Count of Anjou, Count of Maine, Count of Nantes, and Overlord of Brittany at various times during the same period. He was the third of five sons of King Henry II of England and Eleanor of Aquitaine. He was known as or Richard the Lionheart because of his reputation as a great military leader and warrior. He was also known in Occitan as Oc e No ("Yes and No"), because of his reputation for terseness.
By the age of 16, Richard had taken command of his own army, putting down rebellions in Poitou against his father. Richard was a central Christian commander during the Third Crusade, leading the campaign after the departure of Philip II of France and scoring considerable victories against his Muslim counterpart, Saladin, although he did not retake Jerusalem from Saladin.
Richard spoke langue d'oïl, a French dialect, and lenga d'òc, a Romance language spoken in southern France and nearby regions. He was born in England, where he spent his childhood; before becoming king, however, he lived for most of his adult life in the Duchy of Aquitaine in the southwest of France. Following his accession he spent very little time, perhaps as little as six months, in England; most of his life as king was spent on Crusade, in captivity, or in actively defending his lands in France. Rather than regarding his kingdom as a responsibility requiring his presence as ruler, he has been perceived as preferring to use it merely as a source of revenue to support his armies. Nevertheless, he was seen as a pious hero by his subjects. He remains one of the few kings of England remembered by his epithet, rather than regnal number, and is an enduring iconic figure both in England and in France.
Early life and accession in Aquitaine.
Childhood.
Richard was born on 8 September 1157, probably at Beaumont Palace, in Oxford, England, son of King Henry II and Eleanor of Aquitaine. He was a younger brother of Count William IX of Poitiers, Henry the Young King and Duchess Matilda of Saxony. As the third legitimate son of King Henry II, he was not expected to ascend the throne. He was also an elder brother of Duke Geoffrey II of Brittany; Queen Eleanor of Castile; Queen Joan of Sicily; and Count John of Mortain, who succeeded him as king. Richard was the younger maternal half-brother of Countess Marie of Champagne and Countess Alix of Blois. The eldest son of Henry II and Eleanor, William, died in 1156, before Richard's birth. Richard is often depicted as having been the favourite son of his mother. His father was Norman-Angevin and great-grandson of William the Conqueror. Contemporary historian Ralph of Diceto traced his family's lineage through Matilda of Scotland to the Anglo-Saxon kings of England and Alfred the Great, and from there linked them to Noah and Woden. According to Angevin legend, there was even infernal blood in the family.
While his father visited his lands from Scotland to France, Richard probably spent his childhood in England. His first recorded visit to the European continent was in May 1165, when his mother took him to Normandy. He was wet-nursed by a woman called Hodierna, and when he became king he gave her a generous pension. Little is known about Richard's education. Although he was born in Oxford and brought up in England up to his eighth year, it is not known to what extent he used or understood English; he was an educated man who composed poetry and wrote in Limousin (lenga d'òc) and also in French. During his captivity, English prejudice against foreigners was used in a calculated way by his brother John to help destroy the authority of Richard's chancellor, William Longchamp, who was a Norman. One of the specific charges laid against Longchamp, by John's supporter Hugh, Bishop of Coventry, was that he could not speak English. This indicates that by the late 12th century a knowledge of English was expected of those in positions of authority in England.
Richard was said to be very attractive; his hair was between red and blond, and he was light-eyed with a pale complexion. He was apparently of above average height: according to Clifford Brewer he was . As with his supposed lack of English, the question of his stature is one made from a lack of evidence as his remains have been lost since at least the French Revolution, and his exact height is unknown. John, his youngest brother (by the same father and mother), was known to be only . The Itinerarium peregrinorum et gesta regis Ricardi, a Latin prose narrative of the Third Crusade, states that: "He was tall, of elegant build; the colour of his hair was between red and gold; his limbs were supple and straight. He had long arms suited to wielding a sword. His long legs matched the rest of his body."
From an early age he showed significant political and military ability, becoming noted for his chivalry and courage as he fought to control the rebellious nobles of his own territory. His elder brother Henry the Young King was crowned king of England during his father's lifetime.
Marriage alliances were common among medieval royalty: they led to political alliances and peace treaties, and allowed families to stake claims of succession on each other's lands. In March 1159 it was arranged that Richard would marry one of the daughters of Ramon Berenguer IV, Count of Barcelona; however, these arrangements failed, and the marriage never took place. Henry the Young King was married to Marguerite, daughter of Louis VII of France, on 2 November 1160. Despite this alliance between the Plantagenets and the Capetians, the dynasty on the French throne, the two houses were sometimes in conflict. In 1168, the intercession of Pope Alexander III was necessary to secure a truce between them. Henry II had conquered Brittany and taken control of Gisors and the Vexin, which had been part of Marguerite's dowry.
Early in the 1160s there had been suggestions Richard should marry Alys, Countess of the Vexin (Alice), fourth daughter of Louis VII; because of the rivalry between the kings of England and France, Louis obstructed the marriage. A peace treaty was secured in January 1169 and Richard's betrothal to Alys was confirmed. Henry II planned to divide his and Queen Eleanor's territories among their three eldest surviving sons: Henry would become King of England and have control of Anjou, Maine, and Normandy; Richard would inherit Aquitaine from his mother and become Count of Poitiers; and Geoffrey would become Duke of Brittany through marriage alliance with Constance, heiress apparent to the region as the daughter, and only child, of Conan IV, Duke of Brittany. At the ceremony where Richard's betrothal was confirmed, he paid homage to the King of France for Aquitaine, thus securing ties of vassalage between the two.
After Henry II fell seriously ill in 1170, he put in place his plan to divide his kingdom, although he would retain overall authority over his sons and their territories. In 1171 Richard left for Aquitaine with his mother, and Henry II gave him the duchy of Aquitaine at the request of Eleanor. Richard and his mother embarked on a tour of Aquitaine in 1171 in an attempt to pacify the locals. Together they laid the foundation stone of St Augustine's Monastery in Limoges. In June 1172 Richard was formally recognised as the Duke of Aquitaine when he was granted the lance and banner emblems of his office; the ceremony took place in Poitiers and was repeated in Limoges, where he wore the ring of St Valerie, who was the personification of Aquitaine.
Revolt against Henry II.
According to Ralph of Coggeshall, Henry the Young King instigated rebellion against Henry II; he wanted to reign independently over at least part of the territory his father had promised him, and to break away from his dependence on Henry II, who controlled the purse strings. There were rumors that Eleanor might have encouraged her sons to revolt against their father.
Henry the Young King abandoned his father and left for the French court, seeking the protection of Louis VII; his younger brothers, Richard and Geoffrey, soon followed him, while the five-year-old John remained in England. Louis gave his support to the three sons and even knighted Richard, tying them together through vassalage.
Jordan Fantosme, a contemporary poet, described the rebellion as a "war without love".
The three brothers made an oath at the French court that they would not make terms with Henry II without the consent of Louis VII and the French barons. With the support of Louis, Henry the Young King attracted many barons to his cause through promises of land and money; one such baron was Philip, Count of Flanders, who was promised £1,000 and several castles. The brothers also had supporters ready to rise up in England. Robert de Beaumont, 3rd Earl of Leicester, joined forces with Hugh Bigod, 1st Earl of Norfolk, Hugh de Kevelioc, 5th Earl of Chester, and William I of Scotland for a rebellion in Suffolk. The alliance with Louis was initially successful, and by July 1173 the rebels were besieging Aumale, Neuf-Marché, and Verneuil, and Hugh de Kevelioc had captured Dol in Brittany. Richard went to Poitou and raised the barons who were loyal to himself and his mother in rebellion against his father. Eleanor was captured, so Richard was left to lead his campaign against Henry II's supporters in Aquitaine on his own. He marched to take La Rochelle but was rejected by the inhabitants; he withdrew to the city of Saintes, which he established as a base of operations.
In the meantime Henry II had raised a very expensive army of more than 20,000 mercenaries with which to face the rebellion. He marched on Verneuil, and Louis retreated from his forces. The army proceeded to recapture Dol and subdued Brittany. At this point Henry II made an offer of peace to his sons; on the advice of Louis the offer was refused. Henry II's forces took Saintes by surprise and captured much of its garrison, although Richard was able to escape with a small group of soldiers. He took refuge in Château de Taillebourg for the rest of the war. Henry the Young King and the Count of Flanders planned to land in England to assist the rebellion led by the Earl of Leicester. Anticipating this, Henry II returned to England with 500 soldiers and his prisoners (including Eleanor and his sons' wives and fiancées), but on his arrival found out that the rebellion had already collapsed. William I of Scotland and Hugh Bigod were captured on 13 and 25 July respectively. Henry II returned to France and raised the siege of Rouen, where Louis VII had been joined by Henry the Young King after abandoning his plan to invade England. Louis was defeated and a peace treaty was signed in September 1174, the Treaty of Montlouis.
When Henry II and Louis VII made a truce on 8 September 1174, its terms specifically excluded Richard. Abandoned by Louis and wary of facing his father's army in battle, Richard went to Henry II's court at Poitiers on 23 September and begged for forgiveness, weeping and falling at the feet of Henry, who gave Richard the kiss of peace. Several days later, Richard's brothers joined him in seeking reconciliation with their father. The terms the three brothers accepted were less generous than those they had been offered earlier in the conflict (when Richard was offered four castles in Aquitaine and half of the income from the duchy): Richard was given control of two castles in Poitou and half the income of Aquitaine; Henry the Young King was given two castles in Normandy; and Geoffrey was permitted half of Brittany. Eleanor remained Henry II's prisoner until his death, partly as insurance for Richard's good behaviour.
Final years of Henry II's reign.
After the conclusion of the war, the process of pacifying the provinces that had rebelled against Henry II began. The King travelled to Anjou for this purpose, and Geoffrey dealt with Brittany. In January 1175 Richard was dispatched to Aquitaine to punish the barons who had fought for him. The historian John Gillingham notes that the chronicle of Roger of Howden is the main source for Richard's activities in this period. According to the chronicle, most of the castles belonging to rebels were to be returned to the state they were in 15 days before the outbreak of war, while others were to be razed. Given that by this time it was common for castles to be built in stone, and that many barons had expanded or refortified their castles, this was not an easy task. Roger of Howden records the two-month siege of Castillon-sur-Agen; while the castle was "notoriously strong", Richard's siege engines battered the defenders into submission. On this campaign Richard acquired the name "the Lion" or "the Lionheart";
he is referred to as "this our lion" ("hic leo noster") as early as 1187 in the "Topographia Hibernica" of Giraldus Cambrensis, while the byname "lionheart" ("le quor de lion") is first recorded in Ambroise's "L'Estoire de la Guerre Sainte" in the context of the Accon campaign of 1191.
Henry seemed unwilling to entrust any of his sons with resources that could be used against him. It was suspected that Henry had appropriated Princess Alys, Richard's betrothed, the daughter of Louis VII of France by his second wife, as his mistress. This made a marriage between Richard and Alys technically impossible in the eyes of the Church, but Henry prevaricated: he regarded Alys's dowry, Vexin in the Île-de-France, as valuable. Richard was discouraged from renouncing Alys because she was the sister of King Philip II of France, a close ally.
After his failure to overthrow his father, Richard concentrated on putting down internal revolts by the nobles of Aquitaine, especially in the territory of Gascony. The increasing cruelty of his rule led to a major revolt there in 1179. Hoping to dethrone Richard, the rebels sought the help of his brothers Henry and Geoffrey. The turning point came in the Charente Valley in the spring of 1179. The well-defended fortress of Taillebourg seemed impregnable. The castle was surrounded by a cliff on three sides and a town on the fourth side with a three-layer wall. Richard first destroyed and looted the farms and lands surrounding the fortress, leaving its defenders no reinforcements or lines of retreat. The garrison sallied out of the castle and attacked Richard; he was able to subdue the army and then followed the defenders inside the open gates, where he easily took over the castle in two days. Richard the Lionheart's victory at Taillebourg deterred many barons from thinking of rebelling and forced them to declare their loyalty to him. It also won Richard a reputation as a skilled military commander.
In 1181–1182 Richard faced a revolt over the succession to the county of Angoulême. His opponents turned to Philip II of France for support, and the fighting spread through the Limousin and Périgord. The excessive cruelty of Richard's punitive campaigns aroused even more hostility. 
However, with support from his father and from the Young King, Richard the Lionheart eventually succeeded in bringing the Viscount Aimar V of Limoges and Count Elie of Périgord to terms.
After Richard had subdued his rebellious barons he again challenged his father. From 1180 to 1183 the tension between Henry and Richard grew, as King Henry commanded Richard to pay homage to Henry the Young King, but Richard refused. Finally, in 1183 Henry the Young King and Geoffrey, Duke of Brittany, invaded Aquitaine in an attempt to subdue Richard. Richard's barons joined in the fray and turned against their duke. However, Richard and his army succeeded in holding back the invading armies, and they executed any prisoners. The conflict paused briefly in June 1183 when the Young King died. With the death of Henry the Young King, Richard became the eldest surviving son and therefore heir to the English crown. King Henry demanded that Richard give up Aquitaine (which he planned to give to his youngest son John as his inheritance). Richard refused, and conflict continued between them. Henry II soon gave John permission to invade Aquitaine.
To strengthen his position, in 1187, Richard allied himself with 22-year-old Philip II, the son of Eleanor's ex-husband Louis VII by Adele of Champagne. Roger of Howden wrote:
The King of England was struck with great astonishment, and wondered what alliance could mean, and, taking precautions for the future, frequently sent messengers into France for the purpose of recalling his son Richard; who, pretending that he was peaceably inclined and ready to come to his father, made his way to Chinon, and, in spite of the person who had the custody thereof, carried off the greater part of his father's treasures, and fortified his castles in Poitou with the same, refusing to go to his father.
Overall, Howden is chiefly concerned with the politics of the relationship between Richard and King Philip. Gillingham has addressed theories suggesting that this political relationship was also sexually intimate, which he posits probably stemmed from an official record announcing that, as a symbol of unity between the two countries, the kings of England and France had slept overnight in the same bed. Gillingham has characterized this as "an accepted political act, nothing sexual about it;... a bit like a modern-day photo opportunity."
In exchange for Philip's help against his father, Richard promised to concede to him his rights to both Normandy and Anjou. Richard paid homage to Philip in November 1187. With news arriving of the Battle of Hattin, he took the cross at Tours in the company of other French nobles.
In 1188 Henry II planned to concede Aquitaine to his youngest son John. But Richard refused the thought. He felt that Aquitaine was his and that John was unfit to take over the land once belonging to his beloved mother. This refusal is what finally made Henry II bring Queen Eleanor out of prison. He sent her to Aquitaine and demanded that Richard give up his lands to his mother who would once again rule over those lands.
The following year, Richard attempted to take the throne of England for himself by joining Philip's expedition against his father. On 4 July 1189, the forces of Richard and Philip defeated Henry's army at Ballans. Henry, with John's consent, agreed to name Richard his heir apparent. Two days later Henry II died in Chinon, and Richard the Lionheart succeeded him as King of England, Duke of Normandy, and Count of Anjou. Roger of Howden claimed that Henry's corpse bled from the nose in Richard's presence, which was taken as a sign that Richard had caused his death.
King and Crusader.
Coronation and anti-Jewish violence.
Richard I was officially invested as Duke of Normandy on 20 July 1189 and was crowned king in Westminster Abbey on 3 September 1189. Richard barred all Jews and women from the investiture, but some Jewish leaders arrived to present gifts for the new king. According to Ralph of Diceto, Richard's courtiers stripped and flogged the Jews, then flung them out of court.
When a rumour spread that Richard had ordered all Jews to be killed, the people of London attacked the Jewish population. Many Jewish homes were burned down, and several Jews were forcibly baptised. Some sought sanctuary in the Tower of London, and others managed to escape. Among those killed was Jacob of Orléans, a respected Jewish scholar. Roger of Howden, in his "Gesta Regis Ricardi", claimed that the rioting was started by the jealous and bigoted citizens, and that Richard punished the perpetrators, allowing a forcibly converted Jew to return to his native religion. Baldwin of Forde, Archbishop of Canterbury, reacted by remarking, "If the King is not God's man, he had better be the devil's".
Realising that the assaults could destabilise his realm on the eve of his departure on crusade, Richard ordered the execution of those responsible for the most egregious murders and persecutions, including rioters who had accidentally burned down Christian homes. He distributed a royal writ demanding that the Jews be left alone. The edict was loosely enforced, however, and the following March there was further violence including a massacre at York.
Crusade plans.
Richard had already taken the cross as Count of Poitou in 1187. His father and Philip II had done so at Gisors on 21 January 1188 after receiving news of the fall of Jerusalem to Saladin. After Richard became king, he and Philip agreed to go on the Third Crusade, since each feared that during his absence the other might usurp his territories.
Richard swore an oath to renounce his past wickedness in order to show himself worthy to take the cross. He started to raise and equip a new crusader army. He spent most of his father's treasury (filled with money raised by the Saladin tithe), raised taxes, and even agreed to free King William I of Scotland from his oath of subservience to Richard in exchange for marks. To raise still more revenue he sold the right to hold official positions, lands, and other privileges to those interested in them. Those already appointed were forced to pay huge sums to retain their posts. William Longchamp, Bishop of Ely and the King's Chancellor, made a show of bidding £ to remain as Chancellor. He was apparently outbid by a certain Reginald the Italian, but that bid was refused.
Richard made some final arrangements on the continent. He reconfirmed his father's appointment of William Fitz Ralph to the important post of seneschal of Normandy. In Anjou, Stephen of Tours was replaced as seneschal and temporarily imprisoned for fiscal mismanagement. Payn de Rochefort, an Angevin knight, was elevated to the post of seneschal of Anjou. In Poitou the ex-provost of Benon, Peter Bertin, was made seneschal, and finally in Gascony the household official Helie de La Celle was picked for the seneschalship there. After repositioning the part of his army he left behind to guard his French possessions, Richard finally set out on the crusade in summer 1190. (His delay was criticised by troubadours such as Bertran de Born.) He appointed as regents Hugh de Puiset, Bishop of Durham, and William de Mandeville, 3rd Earl of Essex—who soon died and was replaced by Richard's chancellor William Longchamp. Richard's brother John was not satisfied by this decision and started scheming against William. When Richard was raising funds for his crusade, he was said to declare, "I would have sold London if I could find a buyer."
Occupation of Sicily.
In September 1190 Richard and Philip arrived in Sicily. After the death of King William II of Sicily his cousin Tancred had seized power and had been crowned early in 1190 as King Tancred I of Sicily, although the legal heir was William's aunt Constance, wife of the new Emperor Henry VI. Tancred had imprisoned William's widow, Queen Joan, who was Richard's sister, and did not give her the money she had inherited in William's will. When Richard arrived he demanded that his sister be released and given her inheritance; she was freed on 28 September, but without the inheritance. The presence of foreign troops also caused unrest: in October, the people of Messina revolted, demanding that the foreigners leave. Richard attacked Messina, capturing it on 4 October 1190. After looting and burning the city Richard established his base there, but this created tension between Richard and Philip Augustus. He remained there until Tancred finally agreed to sign a treaty on 4 March 1191. The treaty was signed by Richard, Philip and Tancred. Its main terms were:
The two kings stayed on in Sicily for a while, but this resulted in increasing tensions between them and their men, with Philip Augustus plotting with Tancred against Richard. The two kings finally met to clear the air and reached an agreement, including the end of Richard's betrothal to Philip's sister Alys (who had supposedly been the mistress of Richard's father Henry II).
Conquest of Cyprus.
In April 1191 Richard left Messina for Acre, but a storm dispersed his large fleet. After some searching, it was discovered that the ship carrying his sister Joan and his new fiancée Berengaria was anchored on the south coast of Cyprus, along with the wrecks of several other vessels, including the treasure ship. Survivors of the wrecks had been taken prisoner by the island's ruler, Isaac Komnenos.
On 1 May 1191 Richard's fleet arrived in the port of Lemesos (Limassol) on Cyprus. He ordered Isaac to release the prisoners and treasure. Isaac refused, so Richard landed his troops and took Limassol. Various princes of the Holy Land arrived in Limassol at the same time, in particular Guy of Lusignan. All declared their support for Richard provided that he support Guy against his rival, Conrad of Montferrat.
The local magnates abandoned Isaac, who considered making peace with Richard, joining him on the crusade, and offering his daughter in marriage to the person named by Richard. Isaac changed his mind, however, and tried to escape. Richard's troops, led by Guy de Lusignan, conquered the whole island by 1 June. Isaac surrendered and was confined with silver chains because Richard had promised that he would not place him in irons. Richard named Richard de Camville and Robert of Thornham as governors. He later sold the island to the Knights Templar, and it was subsequently acquired, in 1192, by Guy of Lusignan and became a stable feudal kingdom.
The rapid conquest of the island by Richard is more important than it may seem. The island occupies a key strategic position on the maritime lanes to the Holy Land, whose occupation by the Christians could not continue without support from the sea. Cyprus remained a Christian stronghold until the battle of Lepanto (1571). Richard's exploit was well publicised and contributed to his reputation, and he also derived significant financial gains from the conquest of the island.
Richard left Cyprus for Acre on 5 June with his allies.
Marriage.
Before leaving Cyprus on crusade, Richard married Berengaria of Navarre, first-born daughter of King Sancho VI of Navarre. Richard first grew close to her at a tournament held in her native Navarre. The wedding was held in Limassol on 12 May 1191 at the Chapel of St. George and was attended by Richard's sister Joan, whom he had brought from Sicily. The marriage was celebrated with great pomp and splendour, many feasts and entertainments, and public parades and celebrations followed commemorating the event. Among the other grand ceremonies was a double coronation. Richard caused himself to be crowned King of Cyprus, and Berengaria Queen of England and of Cyprus, too. When Richard married Berengaria he was still officially betrothed to Alys, and he pushed for the match in order to obtain the Kingdom of Navarre as a fief, as Aquitaine had been for his father. Further, Eleanor championed the match, as Navarre bordered Aquitaine, thereby securing the southern border of her ancestral lands. Richard took his new wife on crusade with him briefly, though they returned separately. Berengaria had almost as much difficulty in making the journey home as her husband did, and she did not see England until after his death. After his release from German captivity Richard showed some regret for his earlier conduct, but he was not reunited with his wife. The marriage remained childless.
In the Holy Land.
King Richard landed at Acre on 8 June 1191. He gave his support to his Poitevin vassal Guy of Lusignan, who had brought troops to help him in Cyprus. Guy was the widower of his father's cousin Sibylla of Jerusalem and was trying to retain the kingship of Jerusalem, despite his wife's death during the Siege of Acre the previous year. Guy's claim was challenged by Conrad of Montferrat, second husband of Sibylla's half-sister, Isabella: Conrad, whose defence of Tyre had saved the kingdom in 1187, was supported by Philip of France, son of his first cousin Louis VII of France, and by another cousin, Duke Leopold V of Austria. Richard also allied with Humphrey IV of Toron, Isabella's first husband, from whom she had been forcibly divorced in 1190. Humphrey was loyal to Guy and spoke Arabic fluently, so Richard used him as a translator and negotiator.
Richard and his forces aided in the capture of Acre, despite the king's serious illness. At one point, while sick from scurvy, Richard is said to have picked off guards on the walls with a crossbow, while being carried on a stretcher. Eventually Conrad of Montferrat concluded the surrender negotiations with Saladin's forces inside Acre and raised the banners of the kings in the city. Richard quarrelled with Leopold V of Austria over the deposition of Isaac Komnenos (related to Leopold's Byzantine mother) and his position within the crusade. Leopold's banner had been raised alongside the English and French standards. This was interpreted as arrogance by both Richard and Philip, as Leopold was a vassal of the Holy Roman Emperor (although he was the highest-ranking surviving leader of the imperial forces). Richard's men tore the flag down and threw it in the moat of Acre. Leopold left the crusade immediately. Philip also left soon afterwards, in poor health and after further disputes with Richard over the status of Cyprus (Philip demanded half the island) and the kingship of Jerusalem. Richard, suddenly, found himself without allies.
Richard had kept 2,700 Muslim prisoners as hostages against Saladin fulfilling all the terms of the surrender of the lands around Acre. Philip, before leaving, had entrusted his prisoners to Conrad, but Richard forced him to hand them over to him. Richard feared his forces being bottled up in Acre as he believed his campaign could not advance with the prisoners in train. He therefore ordered all the prisoners executed. He then moved south, defeating Saladin's forces at the Battle of Arsuf north of Jaffa on 7 September 1191. Saladin attempted to harass Richard's army into breaking its formation in order to defeat it in detail. Richard maintained his army's defensive formation, however, until the Hospitallers broke ranks to charge the right wing of Saladin's forces. Richard then ordered a general counterattack, which won the battle. Arsuf was an important victory. The Muslim army was not destroyed, despite the considerable casualties it suffered, but it did rout; this was considered shameful by the Muslims and boosted the morale of the Crusaders. In November 1191, following the fall of Jaffa, the Crusader army advanced inland towards Jerusalem. The army then marched to Beit Nuba, only 12 miles from Jerusalem. Muslim morale in Jerusalem was so low that the arrival of the Crusaders would probably have caused the city to fall quickly. However, the weather was appallingly bad, cold with heavy rain and hailstorms; this, combined with the fear that the Crusader army, if it besieged Jerusalem, might be trapped by a relieving force, led to the decision to retreat back to the coast. Richard attempted to negotiate with Saladin, but this was unsuccessful. In the first half of 1192 he and his troops refortified Ascalon.
An election forced Richard to accept Conrad of Montferrat as King of Jerusalem, and he sold Cyprus to his defeated protégé, Guy. Only days later, on 28 April 1192, Conrad was stabbed to death by Hashshashin (Assassins) before he could be crowned. Eight days later Richard's own nephew Henry II of Champagne was married to the widowed Isabella, although she was carrying Conrad's child. The murder has never been conclusively solved, and Richard's contemporaries widely suspected his involvement.
The Crusader army made another advance on Jerusalem, and in June 1192 it came within sight of the city before being forced to retreat once again, this time because of dissension amongst its leaders. In particular, Richard and the majority of the army council wanted to force Saladin to relinquish Jerusalem by attacking the basis of his power through an invasion of Egypt. The leader of the French contingent, the Duke of Burgundy, however, was adamant that a direct attack on Jerusalem should be made. This split the Crusader army into two factions, and neither was strong enough to achieve its objective. Richard stated that he would accompany any attack on Jerusalem but only as a simple soldier; he refused to lead the army. Without a united command the army had little choice but to retreat back to the coast.
There commenced a period of minor skirmishes with Saladin's forces, punctuated by another defeat in the field for the Ayyubid army at the Battle of Jaffa. Baha' al-Din, a contemporary Muslim soldier and biographer of Saladin, recorded a tribute to Richard's martial prowess at this battle: “I have been assured … that on that day the king of England, lance in hand, rode along the whole length of our army from right to left, and not one of our soldiers left the ranks to attack him. The Sultan was wroth thereat and left the battlefield in anger…” Both sides realised that their respective positions were growing untenable. Richard knew that both Philip and his own brother John were starting to plot against him, and the morale of Saladin's army had been badly eroded by repeated defeats. However, Saladin insisted on the razing of Ascalon's fortifications, which Richard's men had rebuilt, and a few other points. Richard made one last attempt to strengthen his bargaining position by attempting to invade Egypt—Saladin's chief supply-base—but failed. In the end, time ran out for Richard. He realised that his return could be postponed no longer since both Philip and John were taking advantage of his absence. He and Saladin finally came to a settlement on 2 September 1192. The terms provided for the destruction of Ascalon's fortifications, allowed Christian pilgrims and merchants access to Jerusalem, and initiated a three-year truce.
Captivity, ransom and return.
Bad weather forced Richard's ship to put in at Corfu, in the lands of the Byzantine Emperor Isaac II Angelos, who objected to Richard's annexation of Cyprus, formerly Byzantine territory. Disguised as a Knight Templar, Richard sailed from Corfu with four attendants, but his ship was wrecked near Aquileia, forcing Richard and his party into a dangerous land route through central Europe. On his way to the territory of his brother-in-law Henry the Lion, Richard was captured shortly before Christmas 1192 near Vienna by Leopold V, Duke of Austria, who accused Richard of arranging the murder of his cousin Conrad of Montferrat. Moreover, Richard had personally offended Leopold by casting down his standard from the walls of Acre.
Duke Leopold kept him prisoner at Dürnstein Castle under the care of Leopold's ministerialis Hadmar of Kuenring. His mishap was soon known to England, but the regents were for some weeks uncertain of his whereabouts. While in prison, Richard wrote "Ja nus hons pris" or "Ja nuls om pres" ("No man who is imprisoned"), which is addressed to his half-sister Marie de Champagne. He wrote the song, in French and Occitan versions, to express his feelings of abandonment by his people and his sister. The detention of a crusader was contrary to public law, and on these grounds Pope Celestine III excommunicated Duke Leopold.
On 28 March 1193 Richard was brought to Speyer and handed over to Henry VI, Holy Roman Emperor, who imprisoned him in Trifels Castle. Henry VI was aggrieved by the support the Plantagenets had given to the family of Henry the Lion and by Richard's recognition of Tancred in Sicily. Henry VI needed money to raise an army and assert his rights over southern Italy and continued to hold Richard for ransom. In response Pope Celestine III excommunicated Henry VI, as he had Duke Leopold, for the continued wrongful imprisonment of Richard. Richard famously refused to show deference to the emperor and declared to him, "". Despite his complaints, the conditions of his captivity were not severe.
The emperor demanded that marks (100,000 pounds of silver) be delivered to him before he would release the king, the same amount raised by the Saladin tithe only a few years earlier, and 2–3 times the annual income for the English Crown under Richard. Eleanor of Aquitaine worked to raise the ransom. Both clergy and laymen were taxed for a quarter of the value of their property, the gold and silver treasures of the churches were confiscated, and money was raised from the scutage and the carucage taxes. At the same time, John, Richard's brother, and King Philip of France offered marks for the Emperor to hold Richard prisoner until Michaelmas 1194. The emperor turned down the offer. The money to rescue the King was transferred to Germany by the emperor's ambassadors, but "at the king's peril" (had it been lost along the way, Richard would have been held responsible), and finally, on 4 February 1194 Richard was released. Philip sent a message to John: "Look to yourself; the devil is loose".
Later years and death.
In Richard's absence, his brother John revolted with the aid of Philip; amongst Philip's conquests in the period of Richard's imprisonment was Normandy. Richard forgave John when they met again and named him as his heir in place of their nephew, Arthur.
Richard began his reconquest of Normandy. The fall of the Château de Gisors to the French in 1196 opened a gap in the Norman defences. The search began for a fresh site for a new castle to defend the duchy of Normandy and act as a base from which Richard could launch his campaign to take back the Vexin from French control. A naturally defensible position was identified perched high above the River Seine, an important transport route, in the manor of Andeli. Under the terms of the Treaty of Louviers (December 1195) between Richard and Philip II, neither king was allowed to fortify the site; despite this, Richard intended to build the vast Château Gaillard. Richard tried to obtain the manor through negotiation. Walter de Coutances, Archbishop of Rouen, was reluctant to sell the manor as it was one of the diocese's most profitable, and other lands belonging to the diocese had recently been damaged by war. When Philip besieged Aumale in Normandy, Richard grew tired of waiting and seized the manor, although the act was opposed by the Church. Walter de Coutances issued an interdict against the duchy of Normandy prohibiting church services from being performed in the region. Roger of Howden detailed "the unburied bodies of the dead lying in the streets and square of the cities of Normandy". Construction began with the interdict hanging over Normandy, but it was later repealed in April 1197 by Pope Celestine III, after Richard made gifts of land to Walter de Coutances and the diocese of Rouen, including two manors and the prosperous port of Dieppe.
Royal expenditure on castles declined from the levels spent under Henry II, attributed to a concentration of resources on Richard's war with the king of France. However, the work at Château Gaillard was some of the most expensive of its time and cost an estimated £15,000 to £20,000 between 1196 and 1198. This was more than double Richard's spending on castles in England, an estimated £7,000. Unprecedented in its speed of construction, the castle was mostly complete in just two years, when most construction on such a scale would have taken the best part of a decade. According to William of Newburgh, in May 1198 Richard and the labourers working on the castle were drenched in a "rain of blood". While some of his advisers thought the rain was an evil omen, Richard was undeterred.
As no master-mason is mentioned in the otherwise detailed records of the castle's construction, military historian Allen Brown has suggested that Richard himself was the overall architect; this is supported by the interest Richard showed in the work through his frequent presence. In his final years, the castle became Richard's favourite residence, and writs and charters were written at Château Gaillard bearing ""apud Bellum Castrum de Rupe"" (at the Fair Castle of the Rock). Château Gaillard was ahead of its time, featuring innovations that would be adopted in castle architecture nearly a century later. Richard later boasted that he could hold the castle "were the walls made of butter". Allen Brown described Château Gaillard as "one of the finest castles in Europe", and military historian Sir Charles Oman wrote that:
Determined to resist Philip's designs on contested Angevin lands such as the Vexin and Berry, Richard poured all his military expertise and vast resources into war on the French King. He organised an alliance against Philip, including Baldwin IX of Flanders, Renaud, Count of Boulogne, and his father-in-law King Sancho VI of Navarre, who raided Philip's lands from the south. Most importantly, he managed to secure the Welf inheritance in Saxony for his nephew, Henry the Lion's son Otto of Poitou, who was elected Otto IV of Germany in 1198.
Partly as a result of these and other intrigues, Richard won several victories over Philip. At Fréteval in 1194, just after Richard's return to France from captivity and money-raising in England, Philip fled, leaving his entire archive of financial audits and documents to be captured by Richard. At the Battle of Gisors (sometimes called Courcelles) in 1198, Richard took "Dieu et mon Droit"—"God and my Right"—as his motto (still used by the British monarchy today), echoing his earlier boast to the Emperor Henry that his rank acknowledged no superior but God.
In March 1199, Richard was in the Limousin suppressing a revolt by Viscount Aimar V of Limoges. Although it was Lent, he "devastated the Viscount's land with fire and sword". He besieged the puny, virtually unarmed castle of Châlus-Chabrol. Some chroniclers claimed that this was because a local peasant had uncovered a treasure trove of Roman gold, which Richard claimed from Aimar in his position as feudal overlord.
In the early evening of 25 March 1199, Richard was walking around the castle perimeter without his chainmail, investigating the progress of sappers on the castle walls. Missiles were occasionally shot from the castle walls, but these were given little attention. One defender in particular amused the king greatly—a man standing on the walls, crossbow in one hand, the other clutching a frying pan he had been using all day as a shield to beat off missiles. He deliberately aimed at the king, which the king applauded; however, another crossbowman then struck the king in the left shoulder near the neck. He tried to pull this out in the privacy of his tent but failed; a surgeon, called a "butcher" by Howden, removed it, "carelessly mangling" the King's arm in the process. The wound swiftly became gangrenous. Accordingly, Richard asked to have the crossbowman brought before him; called alternatively Pierre (or Peter) Basile, John Sabroz, Dudo, and Bertrand de Gourdon (from the town of Gourdon) by chroniclers, the man turned out (according to some sources, but not all) to be a boy. This boy claimed that Richard had killed the boy's father and two brothers, and that he had killed Richard in revenge. The boy expected to be executed; Richard, as a last act of mercy, forgave him, saying, "Live on, and by my bounty behold the light of day," before ordering that the boy be freed and sent away with 100 shillings. Richard then set his affairs in order, bequeathing all his territory to his brother John and his jewels to his nephew Otto.
Richard died on 6 April 1199 in the arms of his mother; it was later said that "As the day was closing, he ended his earthly day." Because of the nature of Richard's death, he was later referred to as "the Lion (that) by the Ant was slain". According to one chronicler, Richard's last act of chivalry proved fruitless when the infamous mercenary captain Mercadier had the crossbowman flayed alive and hanged as soon as Richard died.
Richard's heart was buried at Rouen in Normandy, his entrails in Châlus (where he died), and the rest of his body at the feet of his father at Fontevraud Abbey in Anjou. In 2012, scientists analysed the remains of Richard's heart and found that it had been embalmed with various substances, including frankincense, a symbolically important substance because it had been present both at the birth and embalming of the Christ.
Henry Sandford, Bishop of Rochester (1226-1235) announced that he had seen a vision of Richard ascending to Heaven in March 1232 (along with Stephen Langton, the former Archbishop of Canterbury), the king having presumably spent 33 years in purgatory as expiation for his sins.
Richard produced no legitimate heirs and acknowledged only one illegitimate son, Philip of Cognac. As a result, he was succeeded by his brother John as King of England. However, his French territories initially rejected John as a successor, preferring his nephew Arthur of Brittany, the son of their late brother Geoffrey, whose claim was by modern standards better than John's. The lack of any direct heirs from Richard was the first step in the dissolution of the Angevin Empire.
Character and sexuality.
Contemporaries considered Richard as both a king and a knight famed for personal martial prowess; this was, apparently, the first such instance of this combination. He was known as a valiant and competent military leader and individual fighter, courageous and generous, but on the other hand also as prone to the sins of lust, pride, greed, and above all guilty of excessive cruelty. Ralph of Coggeshall, summarising Richard's career, deplores that the king was one of "the immense cohort of sinners".
He was criticised by chroniclers for having taxed the clergy both for the Crusade and for his ransom, whereas the church and the clergy were usually exempt from taxes. 
In the historiography of the second half of the 20th century much interest was shown in Richard's sexuality, in particular whether there was cogent evidence of homosexuality. The topic had not been raised by Victorian or Edwardian historians, a fact which was itself denounced as a "conspiracy of silence" by John Harvey (1948). The argument primarily drew on accounts of Richard's behaviour, as well as of his confessions and penitences, and of his childless marriage. Richard did have had at least one illegitimate child (Philip of Cognac), and there are reports on his sexual relations with local women during his campaigns. Historians remain divided on the question of Richard's sexuality. Harvey's argument in favour of his homosexuality has gained limited support but has been disputed by other historians, most notably John Gillingham (1994), who argues that Richard was probably heterosexual. Flori (1999) again argued in favour of Richard's homosexuality, based on Richard's two public confessions and penitences (in 1191 and 1195) which, according to Flori, "must have" referred to the sin of sodomy. Flori, however, concedes that contemporary accounts of Richard taking women by force exist, concluding that he probably had sexual relations with both men and women. 
Flori and Gillingham nevertheless agree that accounts of bed-sharing do not support the suggestion that Richard had a sexual relationship with King Philip II, as had been suggested other modern authors.
Legacy.
Heraldry.
The second Great Seal of Richard I (1198) was the first Royal emblem of England to feature "three lions passant-guardant", shown on his shield, so that Richard is likely to have introduced the heraldic design of what is still the Royal arms of England. 
In his earlier Great Seal of 1189, he had used either one or two "lions rampants combatants", which arms he may have adopted from his father. Richard is also credited with having originated the English crest of a "lion statant" (now "statant-guardant"). The coat of three lions continues to represent England on several coins of the pound sterling, forms the basis of several emblems of English national sports teams (such as the England national football team), and endures as one of the most recognisable national symbols of England.
Medieval folklore.
Around the middle of the 13th century, various legends developed that, after Richard's capture, his minstrel Blondel travelled Europe from castle to castle, loudly singing a song known only to the two of them (they had composed it together). Eventually, he came to the place where Richard was being held, and Richard heard the song and answered with the appropriate refrain, thus revealing where the king was incarcerated. The story was the basis of André Ernest Modeste Grétry's opera "Richard Coeur-de-Lion" and seems to be the inspiration for the opening to Richard Thorpe's film version of "Ivanhoe". It seems unconnected to the real Jean 'Blondel' de Nesle, an aristocratic trouvère. It also does not correspond to the historical reality, since the king's jailers did not hide the fact; on the contrary, they publicised it.
At some time around the 16th century, tales of Robin Hood started to mention him as a contemporary and supporter of King Richard the Lionheart, Robin being driven to outlawry, during the misrule of Richard's evil brother John, while Richard was away at the Third Crusade.
Modern reception.
Richard's reputation over the years has "fluctuated wildly", according to historian John Gillingham.
While contemporary sources emphasize his stern and unforgiving nature and his excessive cruelty, his image is already transformed into romance, depicting him as generous-hearted "preux chevalier", a few decades after his death.
Richard left an indelible imprint on the imagination extending to the present, in large part because of his military exploits, and his popular image tended to be dominated by the positive qualities of chivalry and military competence. This is reflected in Steven Runciman's final verdict of Richard I: "he was a bad son, a bad husband, and a bad king, but a gallant and splendid soldier." ("History of the Crusades" Vol. III) Meanwhile, Muslim writers during the Crusades period and after wrote of him: "Never have we had to face a bolder or more subtle opponent."
Victorian England was divided on Richard: many admired him as a crusader and man of God, erecting an heroic statue to him outside the Houses of Parliament. The late-Victorian scholar William Stubbs, on the other hand, thought him "a bad son, a bad husband, a selfish ruler, and a vicious man". During his ten years' reign, he was in England for no more than six months, and was totally absent for the last five years. Stubbs argued that:
He was a bad king: his great exploits, his military skill, his splendour and extravagance, his poetical tastes, his adventurous spirit, do not serve to cloak his entire want of sympathy, or even consideration, for his people. He was no Englishman, but it does not follow that he gave to Normandy, Anjou, or Aquitaine the love or care that he denied to his kingdom. His ambition was that of a mere warrior: he would fight for anything whatever, but he would sell everything that was worth fighting for. The glory that he sought was that of victory rather than conquest.
In World War I, when British troops commanded by General Edmund Allenby captured Jerusalem, the British press printed cartoons of Richard the Lionheart looking down from the heavens with the caption reading, "At last my dream has come true." General Allenby protested against his campaign being presented as a latter day Crusade, however, stating "The importance of Jerusalem lay in its strategic importance, there was no religious impulse in this campaign."
Depictions in modern fiction.
Richard appears as a major or minor character in many works of fiction, both written and audio-visual. As noted above, Richard appears in connection with Robin Hood in Sir Walter Scott's novel "Ivanhoe". He is one of the main characters in Scott's "The Talisman", set during the Third Crusade. The opera Riccardo Primo by George Frideric Handel is based on Richard's invasion of Cyprus.
Richard is a major character in James Goldman's "The Lion in Winter", which references the alleged homosexual affair between Richard and Philip II of France. Richard was played by Sir Anthony Hopkins in Anthony Harvey's "The Lion in Winter" and Andrew Howard played him in the 2003 remake directed by Andrei Konchalovsky, which also starred Patrick Stewart as his father Henry II.
Richard appears in many other fictional accounts of the Third Crusade and its sequel, for example Graham Shelby's "The Kings of Vain Intent" and "The Devil is Loose". Richard is a major character in Norah Lofts' novel "The Lute Player", in Martha Rofheart's "Lionheart!: A Novel of Richard I, King of England", in Cecelia Holland's "The King's Witch, "Gore Vidal's "A Search For the King" and in Sharon Kay Penman's "The Devil's Brood" and "Lionheart". He also appears in three of Angus Donald's "Outlaw Chronicles" series of novels based on the legend of Robin Hood. Richard was played by Henry Wilcoxon in Cecil B. DeMille's 1935 epic, "The Crusades", by Ian Hunter in "The Adventures of Robin Hood" (1938), by George Sanders in "King Richard and the Crusaders" (1954), by Dermot Walsh in the "Richard the Lionheart (TV series)" (1962-1963), and Sean Connery in the climax of ' (1991). In Ridley Scott's 2010 film "Robin Hood", actor Danny Huston portrayed Richard, the film depicts the king's death as during the siege of Chalus Castle. In the 2013 film "Richard The Lionheart" directed by Stefano Milla, actor Chandler Maness portrayed Richard as a young and petulant prince. In the sequel, ', Chandler Maness reprises his role as Richard, to lead a rebellion against his father.

</doc>
<doc id="26369" url="https://en.wikipedia.org/wiki?curid=26369" title="RFPolicy">
RFPolicy

The RFPolicy states a method of contacting vendors about security vulnerabilities found in their products. It was originally written by hacker and security consultant Rain Forest Puppy.
The policy gives the vendor five working days to respond to the reporter of the bug. If the vendor fails to contact the reporter in those five days, the issue is recommended to be disclosed to the general community. The reporter should help the vendor reproduce the bug and work out a fix. The reporter should delay notifying the general community about the bug if the vendor provides feasible reasons for requiring so.
If the vendor fails to respond or shuts down communication with the reporter of the problem in more than five working days, the reporter should disclose the issue to the general community. When issuing an alert or fix, the vendor should give the reporter proper credits about reporting the bug.

</doc>
<doc id="26370" url="https://en.wikipedia.org/wiki?curid=26370" title="Robert Jordan">
Robert Jordan

James Oliver Rigney, Jr., (October 17, 1948 – September 16, 2007) better known by his pen name Robert Jordan, was an American author of epic fantasy. He is best known for The Wheel of Time series, which comprises 14 books and a prequel novel. He is one of the several writers who have written 7 original Conan the Barbarian novels that are highly acclaimed to this day. Rigney also wrote historical fiction under his pseudonym Reagan O'Neal, a western as Jackson O'Reilly, and dance criticism as Chang Lung. Additionally, he ghostwrote an "international thriller" that is still believed to have been written by someone else.
Biography.
Early life and education.
Jordan was born in Charleston, South Carolina. He served two tours in Vietnam (from 1968 to 1970) with the United States Army as a helicopter gunner. He was awarded the Distinguished Flying Cross with oak leaf cluster, the Bronze Star with "V" and oak leaf cluster, and two Vietnamese Gallantry Crosses with palm. After returning from Vietnam he attended The Citadel, where he received an undergraduate degree in physics; after graduating he was employed by the United States Navy as a nuclear engineer. He began writing in 1977.
Personal life.
He was a history buff and enjoyed hunting, fishing, sailing, poker, chess, pool, and pipe collecting. He described himself as a "High Church" Episcopalian and received communion more than once a week. He lived with his wife, Harriet McDougal, who works as a book editor (currently with Tor Books; she was also Jordan's editor) in a house built in 1797. 
Illness.
On March 23, 2006, Jordan disclosed in a statement that he had been diagnosed with cardiac amyloidosis, and that with treatment, his median life expectancy was four years, though he said he intended to beat the statistics. He later posted on his Dragonmount blog to encourage his fans not to worry about him and announce that he intended to have a long and fully creative life.
He began chemotherapy treatment at Mayo Clinic in Rochester, Minnesota, in early April 2006. Jordan was enrolled in a study using the drug Revlimid just approved for multiple myeloma but not yet tested on primary amyloidosis. 
Death.
Jordan died at approximately 2:45 p.m. EDT on September 16, 2007, and his funeral service was held on Wednesday, September 19, 2007. Jordan was cremated and his ashes buried in the churchyard of St. James Church in Goose Creek, outside Charleston, South Carolina.

</doc>
<doc id="26371" url="https://en.wikipedia.org/wiki?curid=26371" title="Ratatoskr">
Ratatoskr

In Norse mythology, Ratatoskr (Old Norse, generally considered to mean "drill-tooth" or "bore-tooth") is a squirrel who runs up and down the world tree Yggdrasil to carry messages between the Veðrfölnir, perched atop Yggdrasil, and the wyrm Níðhöggr, who dwells beneath one of the three roots of the tree. Ratatoskr is attested in the "Poetic Edda", compiled in the 13th century from earlier traditional sources, and the "Prose Edda", written in the 13th century by Snorri Sturluson.
Etymology.
The name "Ratatoskr" contains two elements: "rata-" and "-toskr". The element "toskr" is generally held to mean "tusk". Guðbrandur Vigfússon theorized that the "rati-" element means "the traveller". He says that the name of the legendary drill Rati may feature the same term. According to Vigfússon, "Ratatoskr" means "tusk the traveller" or "the climber tusk."
Sophus Bugge theorized that the name "Ratatoskr" is a loanword from Old English meaning "Rat-tooth." Bugge's basis hinges on the fact that the "-toskr" element of the compound does not appear anywhere else in Old Norse. Bugge proposed that the "-toskr" element is a reformation of the Old English word "tūsc" (Old Frisian "tusk") and, in turn, that the element "Rata-" represents Old English "ræt" ("rat").
According to Albert Sturtevant, "far as the element "Rata-" is concerned, Bugge's hypothesis has no valid foundation in view of the fact that the [Old Norse word "Rata" (gen. form of "Rati"*) is used in "]" (106, 1) to signify the instrument which Odin employed for "boring" his way through the rocks in quest of the poet's mead [...]" and that ""Rati*" must then be considered a native Norse word meaning "The Borer, Gnawer" [...]".
Sturtevant says that Bugge's theory regarding the element "-toskr" may appear to be supported by the fact that the word does not appear elsewhere in Old Norse. Sturtevant, however, disagrees. Sturtevant says that the Old Norse proper name "Tunne" (derived from Proto-Norse "*Tunþē") refers to "a person who is characterized as having some peculiar sort of "tooth"" and theorizes a Proto-Germanic form of "-toskr". Sturtevant concludes that "the fact that the Norse word occurs only in the name "Rata-toskr" is no valid evidence against this assumption, for there are many Norse "hapax legomena" of native origin, as is attested by the equivalents in the Mod Scandinavian dialects." Modern scholars have accepted this etymology, listing the name "Ratatoskr" as meaning "drill-tooth" (Jesse Byock, Andy Orchard, Rudolf Simek) or "bore-tooth" (John Lindow).
Attestations.
In the "Poetic Edda" poem "Grímnismál", the god Odin (disguised as "Grímnir") says that Ratatoskr runs up and down Yggdrasil bringing messages between the eagle perched atop it and Níðhöggr below it:
Ratatoskr is described in the "Prose Edda"s "Gylfaginning" chapter 16, in which High states that
An eagle sits at the top of the ash, and it has knowledge of many things. Between its eyes sits the hawk called Vedrfolnir [...]. The squirrel called Ratatosk [...] runs up and down the ash. He tells slanderous gossip, provoking the eagle and Nidhogg.
Theories.
According to Rudolf Simek, "the squirrel probably only represents an embellishing detail to the mythological picture of the world-ash in "Grímnismál". Hilda Ellis Davidson, describing the world tree, states the squirrel is said to gnaw at it—furthering a continual destruction and re-growth cycle, and posits the tree symbolizes ever-changing existence. John Lindow points out that Yggdrasil is described as rotting on one side and as being chewed on by four harts and Níðhöggr, and that, according to the account in "Gylfaginning", it also bears verbal hostility in the fauna it supports. Lindow adds that "in the sagas, a person who helps stir up or keep feuds alive by ferrying words of malice between the participants is seldom one of high status, which may explain the assignment of this role in the mythology to a relatively insignificant animal".
Richard W. Thorington Jr. and Katie Ferrell theorize that "the role of Ratatosk probably derived from the habit of European tree squirrels ("Sciurus vulgaris") to give a scolding alarm call in response to danger. It takes little imagination for you to think that the squirrel is saying nasty things about you."

</doc>
<doc id="26374" url="https://en.wikipedia.org/wiki?curid=26374" title="Reel (dance)">
Reel (dance)

The reel is a folk dance type as well as the accompanying dance tune type. In Scottish country dancing, the reel is one of the four traditional dances, the others being the jig, the strathspey and the waltz, and is also the name of a dance figure (see below).
In Irish dance, a reel is any dance danced to music in "reel time" (see below). In Irish stepdance, the reel is danced in soft shoes and is one of the first dances taught to students. There is also a treble reel, danced in hard shoes to reel music.
History.
The reel is indigenous to Scotland. The earliest reference was in a witchcraft trial of 1590, where the accused was reported to have "daunced this reill or short dance." However, the form may go back to the Middle Ages. The name is probably of Old Norse origins, cognate with Suio-Gothic "rulla", meaning "to whirl." This became Anglo-Saxon "hreol" and Gaelic "ruidhle" or "ruidhleadh", which is the origin of the word now.
After being introduced to Ireland in the late eighteenth century it thrived. Later it was introduced to North America, and remains central in the traditions of Cape Breton fiddling and square dancing.
Reel music.
Reel music is notated in simple meter, either as or . For example the same reel "Rakish Paddy" is notated in time with an "alla breve" ("cut time") time signature in "O'Neill's Music of Ireland, New & Revisited" but in time in "English, Welsh, Scottish & Irish Fiddle Tunes" each measure in both cases spanning the same part of the melody.
All reels have the same structure, consisting largely of quaver (eighth note) movement with an accent on the first and third beats of the bar. A reel is distinguished from a hornpipe by consisting primarily of even beats. Reels usually have two parts (A and B); in most reels each part is repeated (AABB), but in others it is not (ABAB). Each part (A and B) typically has eight bars, which in turn are divisible into four-bar and two-bar phrases. (An exception is the "auld reel" of Shetland which tends to irregular structure and may have been influenced by the Norwegian halling.) The example of Jimmy Shand performing Mairi's Wedding follows the pattern ABABB, giving a pattern of 40 bars. The group of 32 bars (four times eight) is itself repeated three or four times before a second reel is introduced. The grouping of two or more tunes in medleys or "sets" is typical in Celtic dance music. Today many Irish reels are supplemented with new compositions and by tunes from other traditions which are easily adapted as reels. It is the most popular tune-type within the Irish dance music tradition.
Reels are popular in the folk music of South West England. It crossed the Atlantic ocean with Irish and British immigration and thus entered the musical tradition of Atlantic and French-speaking Canada including that of Quebecers and Acadians. Reels are featured in many pieces of Quebec singers and bands; for example: La Bolduc, La Bottine Souriante and even the more modern "néo-trad" group Les Cowboys Fringants (like the song "Mon Pays suivi du Reel des aristocrates").

</doc>
<doc id="26376" url="https://en.wikipedia.org/wiki?curid=26376" title="Remedy">
Remedy

Remedy, Remedies, The Remedy or Remediation may refer to:

</doc>
<doc id="26377" url="https://en.wikipedia.org/wiki?curid=26377" title="Reichsmarine">
Reichsmarine

The Reichsmarine (English: Navy of the Realm) was the name of the German Navy during the Weimar Republic and first two years of Nazi Germany. It was the naval branch of the "Reichswehr", existing from 1919 to 1935. In 1935, it became known as the "Kriegsmarine", a branch of the Wehrmacht; a change implemented by Adolf Hitler.
Vorläufige Reichsmarine.
The "Vorläufige Reichsmarine" (Provisional Imperial Navy) was formed after the end of World War I from the "Kaiserliche Marine".
The provisions of the Versailles Treaty restricted the German Navy to 15,000 men and no submarines, while the fleet was limited to six pre-dreadnought battleships, six cruisers and 12 destroyers. Replacements for the outdated battleships were restricted to a maximum size of 10,000 tons.
Reichsmarine.
Extent and equipment.
The Treaty of Versailles limited the size and armament of the "Reichsmarine" and prevented it from introducing new technologies. The restrictions were intended to prevent the German Navy from becoming a threat to the Allied powers. On the other hand, the Allies had made certain that the "Reichsmarine" would be in the foreseeable future the strongest power in the Baltic Sea, in order to serve as a counterweight against the new Soviet Union, which was viewed with distrust by the Allies.
Germany was only allowed six battleships, six cruisers, twelve destroyers, and twelve torpedo boats. The "Reichsmarine" tried to meet the arms restrictions with secret armament and technical innovations such as the introduction of the pocket battleship. The legal weight limit for the ships were 35,000 tons.
List of "Reichsmarine" ships:

</doc>
<doc id="26378" url="https://en.wikipedia.org/wiki?curid=26378" title="Rift Valley fever">
Rift Valley fever

Rift Valley fever (RVF) is a viral disease that can cause mild to severe symptoms. --> The mild symptoms may include: fever, muscle pains, and headaches which often last for up to a week. --> The severe symptoms may include: loss of sight beginning three weeks after the infection, infections of the brain causing severe headaches and confusion, and bleeding together with liver problems which may occur within the first few days. --> Those who have bleeding have a chance of death as high as 50%.
The disease is caused by the RVF virus, which is of the "Phlebovirus" type. --> It is spread by either touching infected animal blood, breathing in the air around an infected animal being butchered, drinking raw milk from an infected animal, or the bite of infected mosquitoes. --> Animals such as cows, sheep, goats, and camels may be affected. --> In these animals it is spread mostly by mosquitoes. --> It does not appear that one person can infect another person. --> The disease is diagnosed by finding antibodies against the virus or the virus itself in the blood.
Prevention of the disease in humans is by vaccinating animals against the disease. --> This must be done before an outbreak occurs because if it is done during an outbreak it may worsen the situation. --> Stopping the movement of animals during an outbreak may also be useful. --> As may decreasing mosquito numbers and avoiding their bites. --> There is a human vaccine; however, as of 2010 it is not widely available. --> There is no specific treatment and medical efforts are supportive.
Outbreaks of the disease have only occurred in Africa and Arabia. --> Outbreaks usually occur during periods of increased rain which increase the number of mosquitoes. The disease was first reported among livestock in Rift Valley of Kenya in the early 1900s, and the virus was first isolated in 1931.
Signs and symptoms.
In humans, the virus can cause several syndromes. Usually, sufferers have either no symptoms or only a mild illness with fever, headache, muscle pains, and liver abnormalities. In a small percentage of cases (< 2%), the illness can progress to hemorrhagic fever syndrome, meningoencephalitis (inflammation of the brain and tissues lining the brain), or affect the eye. Patients who become ill usually experience fever, generalised weakness, back pain, dizziness, and weight loss at the onset of the illness. Typically, people recover within two to seven days after onset.
About 1% of people with the disease die of it. In livestock, the fatality level is significantly higher. Pregnant livestock infected with RVF abort virtually 100% of foetuses. An epizootic (animal disease epidemic) of RVF is usually first indicated by a wave of unexplained abortions.
Other signs in livestock include vomiting and diarrhoea, respiratory disease, fever, lethargy, anorexia and sudden death in young animals.
Cause.
Virology.
The virus belongs to the Bunyaviridae family. This is a family of enveloped negative single stranded RNA viruses. All Bunyaviruses have an outer lipid envelope with two glycoproteins—G(N) and G(C)—required for cell entry. They deliver their genome into the host-cell cytoplasm by fusing their envelope with an endosomal membrane.
The virus' G(C) protein has a class II membrane fusion protein architecture similar to that found in flaviviruses and alphaviruses. This structural similarity suggests that there may be a common origin for these viral families.
Transmission.
The virus is transmitted through mosquito vectors, as well as through contact with the tissue of infected animals. Two species—"Culex tritaeniorhynchus" and "Aedes vexans"—are known to transmit the virus. Other potential vectors include "Aedes caspius", "Aedes mcintosh", "Aedes ochraceus," "Culex pipiens", "Culex antennatus", "Culex perexiguus", "Culex zombaensis" and "Culex quinquefasciatus". Contact with infected tissue is considered to be the main source of human infections. The virus has been isolated from two bat species: the Peter's epauletted fruit bat ("Micropteropus pusillus") and the aba roundleaf bat ("Hipposideros abae"), which are believed to be reservoirs for the virus.
Diagnosis.
Diagnosis relies on viral isolation from tissues, or serological testing with an ELISA.
Prevention.
A vaccine has been conditionally approved for use in animals in the US.
Epidemiology.
RVF outbreaks occur across sub-Saharan Africa, with outbreaks occurring elsewhere infrequently. In Egypt in 1977–78, an estimated 200,000 people were infected and there were at least 594 deaths.
2006/07 outbreak in Kenya and Somalia.
In November 2006, a Rift Valley fever outbreak occurred in Kenya. The victims are from the North Eastern Province and Coast Province of Kenya, which had received heavy rain in recent months, causing floods and creating breeding grounds for mosquitoes, which spread the virus of the fever from infected livestock to humans.
By 7 January 2007, about 75 people had died and another 183 were infected. The outbreak forced the closure of livestock markets in the North Eastern Province, affecting the economy of the region.
The outbreak was subsequently reported to have moved into Maragua and Kirinyaga districts of Central Province of Kenya.
On 20 January 2007, the outbreak was reported to have crossed into Somalia from Kenya and killed 14 people in the Lower Jubba region.
As of 23 January 2007, cases had started to crop up at the Kenyan capital, Nairobi. Businesses were suffering large losses, as customers were shunning the common meat joints for the popular "nyama choma" (roast meat), as it was believed to be spreading the fever.
In December 2006 and again in January 2007, Taiwan International Health Action (Taiwan IHA) began operating missions in Kenya consisting of medical experts assisting in training laboratory and health facility personnel, and included donations of supplies, such as mosquito sprays. The United States Centers for Disease Control also set up an assistance mission and laboratory in Kenya.
By the end of January, 2007, some 148 people had died since the outbreak began in December.
As at 14 March 2007, the Kenyan government declared RVF as having diminished drastically after spending an estimated 2.5 million in vaccine and deployment costs. It also lifted the ban on cattle movement in the affected areas.
As of 2 November 2007, 125 cases, including 60 deaths, had been reported from more than 10 localities of White Nile, Sinnar, and Gezira states in Sudan. Young adult males are predominantly affected. More than 25 human samples have been found positive for RVF by PCR or ELISA.
2010 South Africa outbreak.
As of 8 April 2010, the Ministry of Health South Africa had reported 87 human cases infected with Rift Valley fever (RVF), including two deaths in Free State, Eastern Cape and Northern Cape provinces. Most of these cases reported direct contact with RVFV-infected livestock and or were linked to farms with confirmed animal cases of RVF. The human cases are: farmers, veterinarians and farm workers. All cases were confirmed with RVF by test conducted at the National Institute of Communicable Diseases (NICD) in Johannesburg, South Africa.
An ongoing outbreak of Rift Valley fever virus (RVFV) infection is affecting sheep, goats, cattle and wildlife on farms within Free State, Eastern Cape, Northern Cape, Western Cape, Mpumalanga, North West, and Gauteng provinces. As of 29 March 2010, about 78 farms reported laboratory-confirmed animal cases, with extensive livestock deaths.
Outbreak investigations by the Department of Health and the Department of Agriculture, Forestry and Fisheries are ongoing, and are being supported by the South African Field Epidemiology and Training Programme and NICD. The Department of Health and the Department of Agriculture are taking measures to enhance disease surveillance among cattle and in managing the control of the disease outbreak.
Sporadic cases of RVFV infection in animals have been documented in South Africa in recent years. The last major outbreak of the disease in humans occurred between 1974 and 1976, where an estimated 10,000 to 20,000 cases were recorded.
The disease claimed the life of Springbok rugby player Juan Smith's father Giel.
Biological weapon.
Rift Valley fever was one of more than a dozen agents that the United States researched as potential biological weapons before the nation suspended its biological weapons program in 1969 due to possible bomb threats that might cause a panic in the United States.

</doc>
<doc id="26383" url="https://en.wikipedia.org/wiki?curid=26383" title="Rogue state">
Rogue state

Rogue state is a controversial term applied by some international theorists to states they consider threatening to the world's peace. This means meeting certain criteria, such as being ruled by authoritarian regimes that severely restrict human rights, sponsor terrorism, and seek to proliferate weapons of mass destruction. The term is used most by the United States, though the US State Department officially stopped using the term in 2000. However, it has been applied by other countries as well.
Rogue states can also be differentiated from 'pariah states' such as Burma (Myanmar) and Zimbabwe who allegedly abuse the human rights of their populations while not being considered a tangible threat beyond their own borders, although the terms have been used interchangeably.
A common presumption applied to rogue states is that they do not necessarily behave rationally or in their own best interests. In political theory it is generally believed that a stable nation, ruled by a leadership that is subject to broad scrutiny (though not necessarily democratic scrutiny), will tend to act in its own best interests and will not take actions that are directly contrary to its own interests, particularly not to its own survival. Rogue states, however, may not be subject to this assumption and, as such, relations with them may be more complicated and unpredictable.
United States usage.
As early as July 1985, President Reagan had asserted that "we are not going to tolerate … attacks from outlaw states by the strangest collection of misfits, loony tunes, and squalid criminals since the advent of the Third Reich," but it fell to the Clinton administration to elaborate this concept. In the 1994 issue of "Foreign Affairs", National Security Advisor Anthony Lake claimed "the reality of recalcitrant and outlaw states that not only choose to remain outside the family democratic nations but also assault its basic values. Lake labeled five regimes as "rogue states": North Korea, Cuba, Iraq, Iran and Libya. In theory, at least, to be classified as a rogue, a state had to commit four transgressions: pursue weapons of mass destruction, support terrorism, severely abuse its own citizens, and stridently criticize the United States. While four of the listed rogue states met all these transgressions, Cuba, though still known for severely abusing its citizens and its strident criticism of the United States, no longer met all the transgressions required for a rogue state and was put on the list solely because of the political influence of the American Cuban community and specifically that of the Cuban American National Foundation. Syria and Pakistan, two nations which were hardly regarded by the United States as paragons of rectitude, avoided being added to the list because the United States hoped that Damascus could play a constructive role in the Arab-Israeli peace process, and because Washington had long maintained close relations with Islamabad—a vestige of the Cold War. 
Three other nations, Yugoslavia, Sudan, and Afghanistan, were treated as rogue states as well. The US State Department at times labeled Yugoslavia as a rogue state because its leader, Slobodan Milošević, had violated the rights of some of his nation's citizens, including but not limited to accusations of attempted genocide in Croatia and genocide in the eastern Bosnian town of Srebrenica. In August 1995, the Croatian Army military defeated the Republic of Serbian Krajina, a Yugoslav puppet state in Croatia, forcing its Serb population to flee. On August 30, 1995, NATO began bombing Serb targets in Bosnia and Herzegovina, and the Bosnian Serb Army soon withdrew from the vicinity of Sarajevo. On December 14, 1995, the Dayton Agreement was signed between the Balkans' three warring sides and the Yugoslav Wars came to a temporary halt. 
The United States employed several tools to isolate and punish rogue states. Tough unilateral economic sanctions, often at congressional behest, were imposed on or tightened against Iran, Libya, Cuba, Sudan, and Afghanistan. The United States selectively used air-power against Iraq for years after the conclusion of the Gulf War in 1991. Cruise missiles were fired at Afghanistan and Sudan in retaliation for terrorist attacks against U.S. embassies in Kenya and Tanzania in September 1998. In March 1999, NATO launched a massive air-bombing campaign against Yugoslavia in response to the Yugoslav Army's crackdown on ethnic Albanian separatists in the province of Kosovo. After enduring three months of heavy NATO bombardment, the Yugoslav Army withdrew from Kosovo in June 1999.
The Central Intelligence Agency supported a variety of covert actions designed to depose Saddam Hussein, while Congress approved the Iraq Liberation Act in 1998 aimed at providing Iraqi opposition groups with increased financial assistance. Several leading Republicans who would occupy high positions in the George W. Bush administration publicly urged President Clinton in February 1998 to recognize the Iraqi National Congress (INC) as the provisional government of Iraq. Some of these critics, including Paul Wolfowitz and Robert Zoellick, hinted that U.S. ground forces might ultimately be required to help the INC oust Saddam. In all of these anti-rogue efforts, however, Washington found it exceedingly difficult to persuade other nations (with the partial exception of Britain) to support its policies of ostracism and punishment.
In the last six months of the Clinton administration, United States Secretary of State Madeleine Albright announced that the term "rogue state" would be abolished in June 2000, in favour of "states of concern," as three of the rogue states (Libya, Iran, and North Korea) no longer met the four transgressions which defined a rogue state. 
In October 2000, Milošević was ousted from power and the US officially reopened its embassy in Belgrade. The final international sanctions against the nation, which had been in place since the passage of United Nations Security Council resolution 724 in December 1991, were lifted in January 2001; and in 2006, Serbia and Montenegro officially dissolved into two separate states. 
The U.S. invasion of Afghanistan in 2001 ousted the Taliban from power and the US government, which no longer saw the nation's government as a threat, drastically improved relations with the country. The regime of Saddam Hussein was over following after the U.S.-led 2003 invasion of Iraq and relations with Iraq dramatically improved afterwards. Libya was removed from the State Sponsors of Terrorism list in 2006 after achieving success through diplomacy. Relations with Libya also became more mutual following the eight month Libyan Civil War in 2011, which resulted in the National Transitional Council ousting longtime Libyan leader Muammar Gaddafi from power. 
Later terms.
In the aftermath of the September 11 attacks, the Bush administration returned to using a similar term. The concept of "rogue states" was replaced by the Bush administration with the "Axis of Evil" concept (gathering Iraq, Iran, and North Korea). U.S. President George W. Bush first spoke of this "Axis of Evil" during his January 2002 State of the Union Address. More terms, such as Beyond the Axis of Evil and Outposts of Tyranny, would follow suit.
As the U.S. government remains the most active proponent of the "rogue state" expression, the term has received much criticism from those who disagree with U.S. foreign policy. Critics charge that "rogue state" merely means any state that is generally hostile to the U.S., or even one that opposes the U.S. without necessarily posing a wider threat. Some others, such as author William Blum, have written that the term is also applicable to the U.S. and Israel. Both the concepts of rogue states and the "Axis of Evil" have been criticized by certain scholars, including philosopher Jacques Derrida and linguist Noam Chomsky, who considered it more or less a justification of imperialism and a useful word for propaganda.
In "", William Blum claims that the United States of America, because of its foreign policy, is itself a rogue state. Noam Chomsky has asserted the same position, with extensive documentation, throughout the years, especially with regard to the United States role in the Palestinian problem, its disregard for pertinent UN resolutions, etc.
The official term "State Sponsors of Terrorism" used for several decades by the U.S. State Department is roughly equivalent to the former term "rogue state", including for the most part the same countries.
Usage by Turkey.
In 23 February 1999, Turkish President Süleyman Demirel described to Greece as a rogue state because of support PKK which recognized as a terrorist organization by Turkey, United States and European Union. Also, Demirel said that: "Greece serves as a sanctuary for members of the PKK seeking shelter and provides training facilities and logistics to the terrorists." 
On June 28, 2012, after the shot down a Turkish warplane by Syrian Army during the Syrian Civil War, Turkish Prime Minister Recep Tayyip Erdoğan declared to Syria a "rogue state".
Usage in other countries.
While the term is used in the media of many countries, it has only been officially used by the United Kingdom and Ukraine. However, the expression has been criticized by France, Russia, and China.

</doc>
<doc id="26384" url="https://en.wikipedia.org/wiki?curid=26384" title="Rebol">
Rebol

Rebol ( ; historically REBOL) is a cross-platform data exchange language and a multi-paradigm dynamic programming language designed by Carl Sassenrath for network communications and distributed computing. It introduces the concept of dialecting: small, optimized, domain-specific languages for code and data, which is also the most notable property of the language according to its designer Carl Sassenrath:
Douglas Crockford of JavaScript fame has described Rebol as ""a more modern language, but with some very similar ideas to Lisp, in that it's all built upon a representation of data which is then executable as programs"" and as one of JSON's influences.
Originally, the language and its official implementation were proprietary and closed source, developed by REBOL Technologies. Following the discussion with Lawrence Rosen, the Rebol version 3 interpreter was released under the Apache 2.0 license on December 12, 2012. Older versions are only available in binary form, and no source release for them is planned.
Rebol has been used to program Internet applications (both client- and server-side), database applications, utilities, and multimedia applications.
Etymology.
Rebol was initially an acronym for Relative Expression Based Object Language. To align with modern trends in language naming, most writers ceased the practice of writing it in all caps. Sassenrath eventually put the question to the community debate on his blog.
In subsequent writing, Sassenrath adopted the convention of writing the language name as "Rebol".
History.
First released in 1997, Rebol was designed over a 20-year period by Carl Sassenrath, the architect and primary developer of AmigaOS, based on his study of denotational semantics and using concepts from the programming languages Lisp, Forth, Logo, and Self.
REBOL Technologies was founded in 1998.
"REBOL 2", the interpreter, which became the core of extended interpreter editions, was first released in 1999.
"REBOL/Command", which added strong encryption and ODBC access, was released in September 2000.
"REBOL/View" was released in April 2001, adding graphical abilities on the core language.
"REBOL/IOS", an extensible collaboration environment built with REBOL was released in August 2001.
"REBOL/SDK", providing a choice of kernels to bind against, as well as a preprocessor, was released in December 2002.
"Rebol 3", the newest version of the interpreter, had alpha versions released by REBOL Technologies since January 2008. Since its release as an Apache 2 project in December 2012, it is being developed by the Rebol community.
Design.
Ease of use.
One of the Rebol design principles is "to do simple things in simple ways". In the following example the "Visual interface dialect" is used to describe a simple Hello world program with a graphical user interface:
This is how a similar example looks in R3-GUI:
Dialects.
Rebol dialects, commonly known as domain-specific languages (DSLs), are micro-languages optimized for a specific purpose. Dialects can be used to define business rules, graphical user interfaces or sequences of screens during the installation of a program. Users can define their own dialects, reusing any existing Rebol word and giving it a specific meaning in that dialect. Dialects are interpreted by functions processing Rebol blocks (or parsing strings) in a specific way.
An example of Rebol's dialecting abilities can be seen with the word codice_1. In the "data exchange dialect" codice_1 is just a word not having any specific meaning. In the "do dialect", codice_1 is a global variable referring to a native function passing back a function result value. In the "visual interface dialect (VID)", codice_1 is a keyword causing the layout engine to simulate a carriage return, moving the "rendering pen" down to the beginning of the next line.
A Rebol interpreter with graphical abilities must understand and interpret many dialects. The table below lists the most important ones in order of significance.
Syntax.
Rebol syntax is free-form, not requiring specific positioning. However, indentation is recommended to better convey the structure of the text to human readers.
Syntactic properties of different dialects may differ. The common platform for all Rebol dialects is the "data exchange dialect"; other dialects are usually derived from it. In addition to being the common platform for all dialects, the "data exchange dialect" is directly used to represent data and metadata, populate data structures, send data over Internet, and save them in data storage.
In contrast to programming languages like C, the "data exchange dialect" does not consist of declarations, statements, expressions or keywords. A valid "data exchange dialect" text stream is a tree data structure consisting of blocks (the root block is implicit, subblocks are delimited by square brackets), parens (delimited by round brackets), strings (delimited by double quotes or curly brackets suitable for multi-line strings; caret notation is used for unprintable characters), URLs, e-mail addresses, files, paths or other composite values. Unlike ALGOL blocks, Rebol blocks are composite values similar to quoted s-expressions in Lisp. The fact that code is written in the form of Rebol blocks makes the language homoiconic.
Blocks as well as parens may contain other composite values (a block may contain subblocks, parens, strings, ...) or scalar values like words, set-words (words suffixed by the colon), get-words (words prefixed by the colon), lit-words (words prefixed by the apostrophe), numbers, money, characters, etc., separated by whitespace. Note that special characters are allowed in words, so codice_5 is a word unlike codice_6, which is a sequence of three words separated by spaces.
Comments may appear following the semicolon until the end of the line. Multi-line comments or comments not ignored by the lexical parser can be written using "ordinary" datatypes like multi-line strings.
Semantics.
Blocks containing domain-specific language can be submitted as arguments to specific "evaluator" functions.
do.
The most frequently used evaluator is the codice_7 function. It is used by default to interpret the text input to the interpreter console.
The "do dialect" interpreted by the codice_7 function, is an expression-oriented sublanguage of the "data exchange dialect". The main semantic unit of the language is the expression. In contrast to imperative programming languages descending from ALGOL, the "do dialect" has neither keywords, nor statements.
Words are used as case-insensitive variables. Like in all dynamically typed languages, variables don't have an associated type, type is associated with values. The result, i.e. the evaluation of a word is returned, when a word is encountered by the codice_7 function. The set-word form of a word can be used for assignment. While not having statements, assignment, together with functions with side-effects can be used for imperative programming.
Subblocks of the root block evaluate to themselves. This property is used to handle data blocks, for structured programming by submitting blocks as arguments to control functions like codice_10, codice_11, codice_12, etc., and for dialecting, when a block is passed to a specific interpreter function.
A specific problem worth noting is that composite values, assigned to variables, are not copied. To make a copy, the value must be passed to the codice_13 function.
The codice_7 function normally follows a prefix style of evaluation, where a function processes the arguments that follow it. However, infix evaluation using infix operators exists too. Infix evaluation takes precedence over the prefix evaluation. For example,
returns 1, since the infix addition takes precedence over the computation of the absolute value. When evaluating infix expressions, the order of evaluation is left to right, no operator takes precedence over another. For example,
returns 20, while an evaluation giving precedence to multiplication would yield 14. All operators have prefix versions. codice_15 usually evaluates arguments before passing them to a function. So, the below expression:
first reads the Wikipedia Rebol page and then passes the result to the codice_16 function. Parentheses can be used to change the order of evaluation. Using prefix notation, the usage of parentheses in expressions can be avoided.
The simple precedence rules are both an advantage:
as well as a disadvantage:
parse.
The codice_17 function is preferably used to specify, validate, transform and interpret dialects. It does so by matching "parse expressions" at run time.
"Parse expressions" are written in the "parse dialect", which, like the "do dialect", is an expression-oriented sublanguage of the "data exchange dialect". Unlike the "do dialect", the "parse dialect" uses keywords representing operators and the most important nonterminals, infix parsing operators don't have prefix equivalents and use precedence rules ("sequence" has higher precedence than "choice").
Actions can be included to be taken during the parsing process as well and the codice_17 function can be used to process blocks or strings. At the "string parsing" level codice_17 must handle the "low level" parsing, taking into account characters and delimiters. "Block parsing" is higher level, handling the scanning at the level of Rebol values.
The parse dialect belongs to the family of grammars represented by the top-down parsing language or the parsing expression grammar (PEG). The main similarity is the presence of the "sequence" and "choice" operators all the family members have. Parse dialect syntax and the similarities between the parse dialect and the PEG are illustrated by this transliteration of a PEG example that parses an arithmetic expression:
Implementations.
The official Rebol 2.7.8 implementation is available in several editions ("/Core", "/View", "/Command", "/SDK" and "/IOS"). Both "/Core" and "/View" editions are freely redistributable software.
The runtime environment is stored in a single executable file. "Rebol/Core" 2.7.8, the console edition, is about 300 KB and "Rebol/View" 2.7.8, the graphical user interface edition, is about 650 KB in size.
"Rebol/View" provides platform-independent graphics and sound access, and comes with its own windowing toolkit and extensible set of styles (GUI widgets). Extended editions, such as "Rebol/Command" 2.7.8 or "Rebol/SDK" 2.7.8 require a paid license; they add features like ODBC data access, and the option to create standalone executable files.
Rebol 2.101.0 has been released under the Apache 2.0 license. The tentative version numbering strategy is that the number will not be officially bumped to 3.0.0 until the community has fully finalized the specification.

</doc>
<doc id="26386" url="https://en.wikipedia.org/wiki?curid=26386" title="Red Hat">
Red Hat

Red Hat, Inc. is an American multinational software company providing open-source software products to the enterprise community. Founded in 1993, Red Hat has its corporate headquarters in Raleigh, North Carolina, with satellite offices worldwide.
Red Hat has become associated to a large extent with its enterprise operating system Red Hat Enterprise Linux and with the acquisition of open-source enterprise middleware vendor JBoss. Red Hat also offers Red Hat Enterprise Virtualization (RHEV), an enterprise virtualization product. Red Hat provides storage, operating system platforms, middleware, applications, management products, and support, training, and consulting services.
Red Hat creates, maintains, and contributes to many free software projects. It has acquired several proprietary software product codebases through corporate mergers and acquisitions and has released such software under open source licenses. , Red Hat is the second largest corporate contributor to Linux after Intel.
History.
In 1993 Bob Young incorporated the ACC Corporation, a catalog business that sold Linux and Unix software accessories. In 1994 Marc Ewing created his own Linux distribution, which he named Red Hat Linux (Ewing had worn a red Cornell University lacrosse hat, given to him by his grandfather, while attending Carnegie Mellon University). Ewing released the software in October, and it became known as the Halloween release. Young bought Ewing's business in 1995, and the two merged to become Red Hat Software, with Young serving as chief executive officer (CEO).
Red Hat went public on August 11, 1999, achieving the eighth-biggest first-day gain in the history of Wall Street. Matthew Szulik succeeded Bob Young as CEO in December of that year. Bob Young went on to found the online print on demand and self-publishing company, Lulu in 2002. Before its IPO, Red Hat had received some funding from Joyce Young, the aunt of founder Bob Young. When Red Hat went public, she cashed in enough stock to recoup her initial investment, then left the remaining stock to linger, "for fun". Her return on investment was so great that, by January 2000 she was a millionaire, allowing her to donate to the Hamilton Community Foundation in June 2000.
On November 15, 1999, Red Hat acquired Cygnus Solutions. Cygnus provided commercial support for free software and housed maintainers of GNU software products such as the GNU Debugger and GNU Binutils. One of the founders of Cygnus, Michael Tiemann, became the chief technical officer of Red Hat and the vice president of open source affairs. Later Red Hat acquired WireSpeed, C2Net and Hell's Kitchen Systems.
In February 2000, "InfoWorld" awarded Red Hat its fourth consecutive "Operating System Product of the Year" award for Red Hat Linux 6.1. Red Hat acquired Planning Technologies, Inc in 2001 and AOL's iPlanet directory and certificate-server software in 2004.
Red Hat moved its headquarters from Durham to North Carolina State University's Centennial Campus in Raleigh, North Carolina in February 2002. In the following month Red Hat introduced Red Hat Linux Advanced Server, later renamed Red Hat Enterprise Linux (RHEL). Dell, IBM, HP and Oracle Corporation announced their support of the platform.
In December 2005 "CIO Insight" magazine conducted its annual "Vendor Value Survey", in which Red Hat ranked #1 in value for the second year in a row. Red Hat stock became part of the NASDAQ-100 on December 19, 2005.
Red Hat acquired open-source middleware provider JBoss on June 5, 2006, and JBoss became a division of Red Hat. On September 18, 2006, Red Hat released the Red Hat Application Stack, which integrated the JBoss technology and which was certified by other well-known software vendors. On December 12, 2006, Red Hat stock moved from trading on NASDAQ (RHAT) to the New York Stock Exchange (RHT). In 2007 Red Hat acquired MetaMatrix and made an agreement with Exadel to distribute its software.
On March 15, 2007, Red Hat released Red Hat Enterprise Linux 5, and in June acquired Mobicents. On March 13, 2008, Red Hat acquired Amentra, a provider of systems integration services for service-oriented architecture, business process management, systems development and enterprise data services. Amentra operates as an independent company.
On July 27, 2009, Red Hat replaced CIT Group in Standard and Poor’s 500 stock index, a diversified index of 500 leading companies of the U.S. economy. This was reported as a major milestone for Linux.
On December 15, 2009, it was reported that Red Hat will pay to settle a class action lawsuit related to the restatement of financial results from July 2004. The suit had been pending in US District Court in North Carolina. Red Hat reached the proposed settlement agreement and recorded a one-time charge of for the quarter that ended Nov. 30.
On January 10, 2011, Red Hat announced that it would expand its headquarters in two phases, adding 540 employees to the Raleigh operation, and investing over . The state of North Carolina is offering up to in incentives. The second phase involves "expansion into new technologies such as software visualization and technology cloud offerings".
On August 25, 2011, Red Hat announced it would move about 600 employees from the N.C. State Centennial Campus to Two Progress Plaza downtown. A ribbon cutting ceremony was held June 24, 2013, in the re-branded Red Hat Headquarters.
In 2012, Red Hat became the first one-billion dollar open source company, reaching in annual revenue during its fiscal year.
On October 16, 2015, Red Hat announced its acquisition of IT automation startup Ansible, rumoured for an estimated .
Fedora Project.
Red Hat sponsors the Fedora Project, a community-supported open-source project that aims to promote the rapid progress of free and open-source software and content. Fedora aims for rapid innovation using open processes and public forums.
The Fedora Project Board, which comprises community leaders and representatives of Red Hat, leads the project and steers the direction of the project and of Fedora, the Linux distribution it develops. Red Hat employees work with the code alongside community members, and many innovations within the Fedora Project make their way into new releases of Red Hat Enterprise Linux.
Business model.
Red Hat partly operates on a professional open-source business model based on open code, development within a community, professional quality assurance, and subscription-based customer support. They produce open-source code, so more programmers can make further adaptations and improvements.
Red Hat sells subscriptions for the support, training, and integration services that help customers in using open-source software. Customers pay one set price for unlimited access to services such as Red Hat Network and up to 24/7 support.
In September 2014, however, CEO Jim Whitehurst announced that Red Hat was "in the midst of a major shift from client-server to cloud-mobile...(T)he prize is the chance to establish open source as the default choice of this next era, and to position Red Hat as the provider of choice for enterprises' entire cloud infrastructure."
Programs and projects.
One Laptop per Child.
Red Hat engineers work with the One Laptop per Child initiative (a non-profit organization established by members of the MIT Media Lab) to design and produce an inexpensive laptop and provide every child in the world with access to open communication, open knowledge, and open learning. The XO-4 laptop, the machine of this project, runs a slimmed-down version of Fedora 17 as its operating system.
Dogtail.
Dogtail, an open-source automated graphical user interface (GUI) test framework initially developed by Red Hat, consists of free software released under the GNU General Public License (GPL) and is written in Python. It allows developers to build and test their applications. Red Hat announced the release of Dogtail at the 2006 Red Hat Summit.
MRG.
Red Hat MRG is a clustering infrastructure platform intended for integrated high-performance computing (HPC). The acronym MRG stands for "Messaging Realtime Grid".
Red Hat Enterprise MRG replaces the Red Hat Enterprise Linux RHEL, a Linux distribution developed by Red Hat, kernel in order to provide extra support for real-time computing, together with middleware support for message brokerage and scheduling workload to local or remote virtual machines, grid, and cloud infrastructures.
The Tuna performance-monitoring tool runs in the MRG environment.
The platform strives to incorporate all the above aspects of HPC into one IT infrastructure for better performance, reliability, and interoperability. It claims to simplify and automate a range of IT tasks of deployment, operation, managing and monitoring of clustered and distributed infrastructure and applications.
Opensource.com.
Red Hat produces the online publication Opensource.com. The site highlights ways open source principles apply in domains other than software development. The site tracks the application of open source philosophy to business, education, government, law, health, and life.
The company originally produced a newsletter called Under the Brim. Wide Open magazine first appeared in March 2004 as a means for Red Hat to share technical content with subscribers on a regular basis. The Under the Brim newsletter and Wide Open magazine merged in November 2004 to become Red Hat Magazine. In January 2010, Red Hat Magazine became Opensource.com.
Red Hat Exchange.
In 2007 Red Hat announced that it had reached an agreement with some free software and open source (FOSS) companies that allowed it to make a distribution portal called Red Hat Exchange, reselling FOSS software with the original branding intact. However, by 2010 Red Hat had abandoned the Exchange program to focus their efforts more on their Open Source Channel Alliance which began in April 2009.
Red Hat Subscription Manager.
Red Hat Subscription Manager (RHSM) combines content delivery with subscription management.
OpenShift.
Red Hat operates OpenShift, a cloud computing platform as a service, supporting applications written in Node.js, PHP, Perl, Python, Ruby, JavaEE and more.
OpenStack.
Red Hat Enterprise Linux OpenStack Platform delivers an integrated foundation to create, deploy, and scale a secure and reliable public or private OpenStack cloud. Red Hat Enterprise Linux OpenStack Platform combines the world’s leading enterprise Linux and the fastest-growing cloud infrastructure platform to give you the agility to scale and quickly meet customer demands without compromising on availability, security, or performance.
CloudForms.
Red Hat CloudForms is Red Hat's Cloud Management Platform that provides hybrid cloud management of virtual infrastructure based on VMware vSphere, Red Hat Enterprise Virtualization, Microsoft Hyper-V, OpenStack, and Amazon EC2. Red Hat CloudForms is based on the upstream ManageIQ.org project that Red Hat open sourced. Code in ManageIQ.org is from the over acquisition of ManageIQ in 2012.
Other projects.
Red Hat has some employees working full-time on free and open source software projects, such as two full-time employees working on the free software "radeon" (David Airlie and Jerome Glisse) and one full-time employee working on the free software "nouveau" graphic drivers.
Utilities and tools.
Over and above Red Hat's major products and acquisitions, Red Hat programmers have produced software programming-tools and utilities to supplement standard Unix and Linux software. Some of these Red Hat "products" have found their way from specifically Red Hat operating environments via open-source channels to a wider community. Such utilities include:
The Red Hat website lists the organization's major involvements in free and open-source software projects.
Community projects under the aegis of Red Hat include:
Subsidiaries.
Red Hat India.
Red Hat, Inc created its subsidiary Red Hat India to deliver Red Hat software, support, and services to customers in India. Colin Tenwick, vice president and general manager of Red Hat EMEA said that "the opening of Hat India is in response to the rapid adoption of Red Hat Linux in the subcontinent. Demand for open source solutions from the Indian markets is rising and Red Hat wants to play a major role in this region". Red Hat India has worked with local companies to enable adoption of open source technology in both government and education.
In 2006 Red Hat India had a distribution network of more than 70 channel partners spanning 27 cities across India. Red Hat India's channel partners included Ashtech Infotech Pvt Ltd, Efensys Technologies, Embee Software, Allied Digital Services, and Softcell Technologies. Distributors include Integra Micro Systems and Ingram Micro.
Mergers and acquisitions.
Red Hat's first major acquisition involved Delix Computer GmbH-Linux Div, the Linux-based operating-system division of Delix Computer, a German computer company, on July 30, 1999.
Red Hat acquired Cygnus Solutions, a company that provided commercial support for free software, on January 11, 2000 - it was the company's largest acquisition, for . Michael Tiemann, co-founder of Cygnus, served as the chief technical officer of Red Hat after the acquisition. Red Hat made the most acquisitions in 2000 with five: Cygnus Solutions, Bluecurve, Wirespeed Communications, Hell's Kitchen Systems, and C2Net. On June 5, 2006, Red Hat acquired open-source middleware provider JBoss for and integrated it as its own division of Red Hat.
On December 14, 1998, Red Hat made its first divestment, when Intel and Netscape acquired undisclosed minority stakes in the company. The next year, on March 9, 1999, Compaq, IBM, Dell and Novell each acquired undisclosed minority stakes in Red Hat.

</doc>
<doc id="26388" url="https://en.wikipedia.org/wiki?curid=26388" title="Reno, Nevada">
Reno, Nevada

Reno is a city in the U.S. state of Nevada. It is located in the Northern portion of the state, approximately from Lake Tahoe. Known as "The Biggest Little City in the World", Reno is famous for its casinos and as the birthplace of Caesars Entertainment Corporation. It is the county seat of Washoe County, located in the northwestern part of the state. The city sits in a high desert at the foot of the Sierra Nevada and its downtown area (along with Sparks) occupies a valley informally known as the Truckee Meadows.
Reno is the most populous Nevada city outside of the Las Vegas–Paradise, NV MSA, with an estimated population of 233,294 in 2013, and is the third most populous city in the state after Las Vegas and Henderson.
Reno is part of the Reno–Sparks metropolitan area, which consists of all of both Washoe and Storey counties, and has a 2013 estimated population of 437,673, making it the second largest metropolitan area in Nevada.
History.
Archaeological finds place the eastern border for the prehistoric Martis people in the Reno area.
As early as the 1850s a few pioneers settled in the Truckee Meadows, a relatively fertile valley through which the Truckee River made its way from Lake Tahoe to Pyramid Lake. In addition to subsistence farming, these early residents could pick up business from travelers along the California Trail, which followed the Truckee westward, before branching off towards Donner Lake, where the formidable obstacle of the Sierra Nevada began.
Gold was discovered in the vicinity of Virginia City in 1850, and a modest mining community developed, but the discovery of silver in 1859 at the Comstock Lode led to a mining rush.
To provide the necessary connection between Virginia City and the California Trail, Charles W. Fuller built a log toll bridge across the Truckee River in 1859. A small community that would service travelers soon grew up near the bridge. After two years, Fuller sold the bridge to Myron C. Lake, who continued to develop the community with the addition of a grist mill, kiln, and livery stable to the hotel and eating house. He renamed it "Lake's Crossing". In 1864, Washoe County was consolidated with Roop County, and Lake's Crossing became the largest town in the county. Lake had earned himself the title "founder of Reno".
By January 1863, the Central Pacific Railroad (CPRR) had begun laying tracks east from Sacramento, California, eventually connecting with the Union Pacific Railroad at Promontory, Utah, to form the First Transcontinental Railroad. Lake deeded land to the CPRR in exchange for its promise to build a depot at Lake's Crossing. Once the railroad station was established, the town of Reno officially came into being on May 9, 1868. CPRR construction superintendent Charles Crocker named the community after Major General Jesse Lee Reno, a Union officer killed in the American Civil War at the Battle of South Mountain.
In 1871, Reno became the county seat of the newly expanded Washoe County, replacing the previous county seat, located in Washoe City. However, political power in Nevada remained with the mining communities, first Virginia City and later Tonopah and Goldfield.
The extension of the Virginia and Truckee Railroad to Reno in 1872 provided a boost to the new city's economy. In the following decades, Reno continued to grow and prosper as a business and agricultural center and became the principal settlement on the transcontinental railroad between Sacramento and Salt Lake City.
As the mining boom waned early in the 20th century, Nevada's centers of political and business activity shifted to the non-mining communities, especially Reno and Las Vegas, and today the former mining metropolises stand as little more than ghost towns. Despite this, Nevada is still the third-largest gold producer in the world, after South Africa and Australia; the state yielded 6.9 percent of the world's supply in 2005 world gold production.
The "Reno Arch" was erected on Virginia Street in 1926 to promote the upcoming Transcontinental Highways Exposition of 1927. The arch included the words "Nevada's Transcontinental Highways Exposition" and the dates of the exposition. After the exposition, the Reno City Council decided to keep the arch as a permanent downtown gateway, and Mayor E.E. Roberts asked the citizens of Reno to suggest a slogan for the arch. No acceptable slogan was received until a $100 prize was offered, and G.A. Burns of Sacramento was declared the winner on March 14, 1929, with "Reno, The Biggest Little City in the World".
Reno took a leap when the state of Nevada legalized open-gambling on March 19, 1931, along with the passage of even more liberal divorce laws than places like Hot Springs, Arkansas, offered. No other state offered what Nevada did in the 1930s, and casinos like the Bank Club and Palace were popular.
Within a few years, the Bank Club, owned by George Wingfield, Bill Graham, and Jim McKay, was the state's largest employer and the largest casino in the world. Wingfield owned most of the buildings in town that housed gaming and took a percentage of the profits, along with his rent.
Ernie Pyle once wrote in one of his columns, "All the people you saw on the streets in Reno were obviously there to get divorces." In Ayn Rand's novel "The Fountainhead", published in 1943, the New York-based female protagonist tells a friend, "I am going to Reno," which is taken as a different way of saying "I am going to divorce my husband." Among others, the Belgian-French writer Georges Simenon, at the time living in the U.S., came to Reno in 1950 in order to divorce his first wife.
The divorce business eventually died as the other states fell in line by passing their own laws easing the requirements for divorce, but gambling continued as a major Reno industry. While gaming pioneers like "Pappy" and Harold Smith of Harold's Club and Bill Harrah of the soon-to-dominate Harrah's casino set up shop in the 1930s, the war years of the 1940s cemented Reno as the place to play for two decades. Beginning in the 1950s, the need for economic diversification beyond gaming fueled a movement for more lenient business taxation.
A disaster occurred on the afternoon of February 5, 1957, when an explosion ripped through the heart of downtown. At 1:03 pm, two explosions, caused by natural gas leaking into the maze of pipes and ditches under the city, and an ensuing fire destroyed five buildings in the vicinity of Sierra and First streets along the Truckee River. Forty-nine people were injured in the disaster, and two were killed. The first explosion hit under the block of shops on the west side of Sierra Street (now the site of the Century Riverside), the second, across Sierra Street, now the site of the Palladio.
The presence of a main east-west rail line, the emerging interstate highway system, favorable state tax climate, and relatively inexpensive land created good conditions for warehousing and distribution of goods.
In the 1980s, Indian gaming rules were relaxed, and starting in 2000, Californian Native casinos began to chip away at Reno's casino industry. Major new construction projects have been completed in the Reno and Sparks areas. A few new luxury communities were recently built in Truckee, California, approximately west of Reno on Interstate 80. Reno also is an outdoor recreation destination, due to its close proximity to the Sierra Nevada, Lake Tahoe, and numerous ski resorts in the region.
In more recent years, the city has gained some notoriety as the subject of the comedy series "Reno 911!" (which is not, however, filmed in the city).
On May 9, 2014, the Reno Historical App was released in conjunction with the City's celebration of its 111th birthday as an incorporated city. The free app puts Reno's history at users' fingertips, allowing them to explore the people, places and moments that have shaped both the city’s and the University’s history.
Geography.
Environmental factors.
Wetlands are an important part of the Reno/Tahoe area. They act as a natural filter for the solids that come out of the water treatment plant. Plant roots absorb nutrients from the water and naturally filter it. Wetlands are home for over 75% of the species in the Great Basin. However, the area's wetlands are at risk of being destroyed due to development around the city. While developers build on top of the wetlands they fill them with dirt destroying the habitat they create for the plants and animals. Washoe County has devised a plan that will help protect these ecosystems: mitigation. In the future, when developers try to build over a wetland, they will be responsible for creating another wetland near Washoe Lake.
The Truckee River serves as Reno's primary source of drinking water. It supplies Reno with of water a day during the summer, and of water per day in the winter. Before the water goes to the homes around the Reno area, it must go to one of two water treatment plants, Chalk Bluff or Glendale Water Treatment Plant. As an attempt to save water, golf courses in Reno, like Arrow Creek Golf Course, have been using treated effluent water instead of treated water from one of Reno's water plants.
The Reno-Sparks wastewater treatment plant discharges tertiary treated effluent to the Truckee River. In the 1990s this capacity was increased from 20 to 30 million U.S. gallons (70 to 110 million liters) per day. While treated, the effluent contains suspended solids, nitrogen, and phosphorus, aggravating water quality concerns of the river and its receiving waters of Pyramid Lake. Local agencies working with the Environmental Protection Agency have developed a number of watershed management strategies to accommodate this expanded effluent discharge; to accomplish this successful outcome, the DSSAM Model was developed and calibrated for the Truckee River in order to analyze the most cost-effective available management strategy set. The resulting management strategies included a package of measures such as land use controls in the Lake Tahoe basin, urban runoff controls in Reno and Sparks, and best management practices for wastewater discharge.
The Reno area is frequently subject to wildfires, causing property damage and sometimes loss of life. In August 1960, the Donner Ridge fire resulted in a loss of electricity to the city for four days. In November 2011, arcing from powerlines caused a fire in Caughlin in southwest Reno that destroyed 26 homes and killed one older man, and only two months later in January 2012 another fire in Washoe Drive sparked by fireplace ashes destroyed 29 homes and killed one older woman. Around 10,000 residents were evacuated, and a state of emergency was declared. The fires came at the end of Reno's longest recorded dry spell.
Geology.
Reno is situated just east of the Sierra Nevada on the western edge of the Great Basin at an elevation of about above sea level. Numerous faults exist throughout the region. Most of these are normal (vertical motion) faults associated with the uplift of the various mountain ranges, including the Sierra Nevada.
In February 2008, an earthquake swarm began to occur, with some quakes registering between 4 and 4.5 on the Richter scale. The earthquakes were centered on the Somersett community in western Reno near the areas of Mogul and Verdi. Many homes in these areas were damaged.
Climate.
Reno sits in the rain shadow of the Sierra Nevada mountain range. Annual rainfall averages . Despite this low amount of rainfall per year, Reno features a steppe climate (Köppen: "BSk") due to its low evapotranspiration. Annual precipitation has ranged from in 1947 to in 1983. The most precipitation in one month was in December 1955 and the most precipitation in 24 hours was on January 21, 1943. Winter has snowfall which is usually light to moderate but can be heavy some days, averaging annually. Snowfall varies with the lowest amounts (roughly 19–23 inches annually) at the lowest part of the valley at and east of the Reno–Tahoe International Airport at , while the foothills of the Carson Range to the west ranging from in elevation just a few miles west of downtown can receive up to two to three times as much annual snowfall. The mountains of the Virginia Range to the east can receive more summer thunderstorms and precipitation, and around twice as much annual snowfall above . However, snowfall increases in the Virginia Range are less dramatic as elevation climbs than in the Carson Range to the west, because the Virginia Range is well within the rain shadow of the Sierra Nevada and Carson Range. The most snowfall in the city in one year was in 1971, and the most snowfall in one month was in March 1952.
Most rainfall occurs in winter and spring. The city has 300 days of sunshine per year. Summer thunderstorms can occur between April and October. The eastern side of town and the mountains east of Reno tend to be prone to thunderstorms more often, and these storms may be severe because an afternoon downslope west wind, called a "Washoe Zephyr", can develop in the Sierra Nevada, causing air to be pulled down in the Sierra Nevada and Reno, destroying or preventing thunderstorms, but the same wind can push air upwards against the Virginia Range and other mountain ranges east of Reno, creating powerful thunderstorms.
The monthly daily average temperature ranges from in December to in July, with the diurnal temperature variation reaching in summer, still lower than much of the high desert to the east. There are 3.9 days of + highs, 58 days of + highs, and 2.5 nights with sub- lows annually; the temperature does not rise above freezing on only 5.1 days. The all-time record high temperature is , which occurred on July 10 and 11, 2002, and again on July 5, 2007. The all-time record low temperature is , which occurred on January 21, 1916. In addition, the region is windy throughout the year; observers such as Mark Twain have commented about the "Washoe Zephyr", northwestern Nevada's distinctive wind.
Demographics.
As of the census of 2010, there were 225,221 people, 90,924 households, and 51,112 families residing in the city. The population density was 2,186.6 per square mile (844.2/km²). There were 102,582 housing units at an average density of 995.9 per square mile (384.5/km²). The racial makeup of the city was 74.2% White, 2.9% African American, 1.3% Native American, 6.3% Asian, 0.7% Pacific Islander, 10.5% some other race, and 4.2% from two or more races. Hispanic or Latino of any race were 24.3% of the population. Non-Hispanic Whites were 62.5% of the population in 2010, down from 88.5% in 1980.
At the 2010 census, there were 90,924 households, out of which 29.8% had children under the age of 18 living with them, 38.4% were headed by married couples living together, 11.8% had a female householder with no husband present, and 43.8% were non-families. 32.1% of all households were made up of individuals, and 9.7% were someone living alone who was 65 years of age or older. The average household size was 2.43, and the average family size was 3.10.
In the city the 2010 population was spread out with 22.8% under the age of 18, 12.5% from 18 to 24, 28.2% from 25 to 44, 24.9% from 45 to 64, and 11.7% who were 65 years of age or older. The median age was 34.6 years. For every 100 females there were 103.4 males. For every 100 females age 18 and over, there were 102.7 males.
In 2011 the estimated median income for a household in the city was $44,846, and the median income for a family was $53,896. Males had a median income of $42,120 versus $31,362 for females. The per capita income for the city was $25,041. About 9.6% of families and 14.4% of the population were below the poverty line, including 15.1% of those under age 18 and 12.8% of those age 65 or over. The population was 180,480 at the 2000 census; in 2010, its population had risen to 225,221, making it the third-largest city in the state after Las Vegas and Henderson, and the largest outside of Clark County. Reno lies north of the Nevada state capital, Carson City, and northeast of Lake Tahoe in a shrub-steppe environment. Reno shares its eastern border with the city of Sparks and is the larger of the principal cities of the Reno–Sparks, Nevada Metropolitan Statistical Area (MSA), a metropolitan area that covers Storey and Washoe counties. The MSA had a combined population of 425,417 at the 2010 census. The MSA is combined with the Fernley Micropolitan Statistical Area to form the Reno-Sparks-Fernley Combined Statistical Area, which had a total population of 477,397 at the 2010 census.
Economy.
Before the late 1950s, Reno was the gambling capital of the United States, but in the last twenty years Las Vegas' rapid growth, American Airlines' 2000 buyout of Reno Air, and the growth of Native American gaming in California have reduced its business. Older casinos were torn down (Mapes Hotel, Fitzgerald's Nevada Club, Primadonna, Horseshoe Club, Harold's Club, Palace Club), or smaller casinos like the Comstock, Sundowner, Golden Phoenix, Kings Inn, Money Tree, Virginian, and Riverboat were either closed or were converted into condos.
Because of its location, Reno has traditionally drawn the majority of its California tourists and gamblers from the San Francisco Bay Area and Sacramento, while Las Vegas has historically served more tourists from Southern California and the Phoenix area.
Several local large hotel casinos have shown significant growth and have moved gaming further away from the Virginia Street core. These larger hotel casinos are the Atlantis, the Peppermill and the Grand Sierra Resort. The Peppermill was chosen as the most outstanding Reno gaming/hotel property by "Casino Player" and "Nevada" magazines. In 2005, the Peppermill Reno began a $300 million Tuscan-themed expansion.
In an effort to bring more tourism to the area, Reno holds several events throughout the year, most of which have been extremely successful. They include Hot August Nights (a classic car convention), Street Vibrations (a motorcycle fan gathering and rally), The Great Reno Balloon Race, a Cinco de Mayo celebration, bowling tournaments (held in the National Bowling Stadium), and the Reno Air Races.
Several large commercial developments were constructed during the mid-2000s boom, such as The Summit in 2007 and Legends at Sparks Marina in 2008.
Reno is the location of the corporate headquarters for numerous companies, including Braeburn Capital, Hamilton, EE Technologies, and Port of Subs. International Game Technology, Bally Technologies and GameTech have development and manufacturing presence in Reno.
Top employers.
According to Reno's 2013 Comprehensive Annual Financial Report, the top employers in the city are:
Culture.
The Nevada Museum of Art, located at 160 West Liberty Street in Reno, Nevada, is the only American Alliance of Museums (AAM) accredited art museum in the state of Nevada.
Libraries.
Washoe County Library System has locations throughout Reno and its surrounding communities.
Reno in media.
Movies filmed in Reno include:
Music videos filmed in Reno include:
The young adult author Ellen Hopkins has written a series of novels called "Crank" set in Reno. Also, many of the short stories included in Claire Vaye Watkins' collection "Battleborn" are set in the city.
American songwriter Richard Fariña composed a song named "Reno Nevada"; it was first released on Richard & Mimi Fariña's debut album "Celebrations For A Grey Day" in 1965. The song was famously covered by Fairport Convention in 1968 and by Iain Matthews in 1971.
Thomas Dolby composed a song named "Road to Reno" as part of his "A Map of the Floating City" album, released in 2011.
Sports.
Reno is home to the Reno Aces, the minor league baseball Triple-A affiliate of the Arizona Diamondbacks, playing in Greater Nevada Field, a downtown ballpark opened in 2009. Reno has hosted multiple professional baseball teams in the past, most under the Reno Silver Sox name. The Reno Astros, a former professional, unaffiliated baseball team, played at Moana Stadium until 2009.
In basketball, the Reno Bighorns, who joined the NBA Development League in 2008, play at the Reno Events Center. They are an affiliate of the Sacramento Kings.
Reno is host to both amateur and professional combat sporting events such as mixed martial arts and boxing. The "Fight of the Century" between Jack Johnson and James J. Jeffries was held in Reno in 1910. Boxer Ray Mancini fought four of his last five fights in Reno against Bobby Chacon, Livingstone Bramble, Hector Camacho, and Greg Haugen.
The Reno Barons, an independent professional indoor football team, played at the Reno Events Center in 2011.
Reno is expected to be the future home of an ECHL ice hockey team, currently named the Reno Raiders, but construction on a suitable arena has yet to begin as of the 2014-2015 season. The franchise has been dormant since 1998, when it was named the Reno Rage, and earlier the Reno Renegades, and played in the now-defunct West Coast Hockey League (WCHL).
The Reno–Tahoe Open is northern Nevada's only PGA Tour event, held at Montrêux Golf & Country Club in Reno. As part of the FedEx Cup, the tournament follows 132 PGA Tour professionals competing for a share of the event's $3 million purse. The Reno-Tahoe Open Foundation has donated more than $1.8 million to local charities.
Reno has a college sports scene, with the Nevada Wolf Pack appearing in football bowl games and an Associated Press Top Ten ranking in basketball in 2007.
In 2004, the city completed a $1.5 million whitewater park on the Truckee River in downtown Reno which hosts whitewater events throughout the year. The course runs Class 2 and 3 rapids with year-round public access. The north channel features more aggressive rapids, drop pools and "holes" for rodeo kayak-type maneuvers. The milder south channel is set up as a kayak slalom course and a beginner area.
Reno is home to two roller derby teams, the Battle Born Derby Demons and the Reno Roller Girls. The Battle Born Derby Demons compete on flat tracks locally and nationally. They are the only derby team locally to compete in a national Derby league.
Reno is the home of the National Bowling Stadium, which hosts the United States Bowling Congress (USBC) Open Championships every three years.
Recreation.
Reno is home to a variety of recreation activities including both seasonal and year-round. In the summer, Reno locals can be found near three major bodies of water: Lake Tahoe, the Truckee River, and Pyramid Lake. The Truckee River originates at Lake Tahoe and flows west to east through the center of downtown Reno before terminating at Pyramid Lake to the north. The river is a major part of Artown, held in the summer at Wingfield Park. Washoe Lake is a popular kite and windsurfing location because of its high wind speeds during the summer.
Skiing and snowboarding are among the most popular winter sports and draw in many tourists. There are 18 ski resorts (8 major resorts) located as close as and as far as from the Reno–Tahoe International Airport, including Northstar California, Sierra-at-Tahoe, Alpine Meadows, Squaw Valley, Sugar Bowl, Diamond Peak, Heavenly Mountain, and Mount Rose. Other popular Reno winter activities include snowshoeing, ice skating, and snowmobiling. There are many bike paths to ride in the summer time. International bike competitions are held in Lake Tahoe over the summer time.
Air races.
The Reno Air Races, also known as the National Championship Air Races, are held each September at the Reno Stead Airport.
Government.
Reno has a democratic municipal government. The city council is the core of the government, with seven members. Five of these council people represent districts of Reno, and are vetted in the primary by the citizens of each district. In general, the top two vote earners in each ward make the ballot for the city-wide election. The other two council members are the at-large member, who represents the entire city, and the mayor, who is elected by the people of the city. The council has several duties, including setting priorities for the city, promoting communication with the public, planning development, and redevelopment.
There is an elected city attorney who is responsible for civil and criminal cases. The City Attorney represents the city government in court, and prosecutes misdemeanors.
The city's charter calls for a council-manager form of government, meaning that the council appoints only two positions, the city manager, who implements and enforces the policies and programs the council approves, and the city clerk. The city manager is in charge of the budget and workforce for all city programs. The city clerk, who records the proceedings of the council, makes appointments for the council, and makes sure efficient copying and printing services are available.
In 2010, there was a ballot question asking whether the Reno city government and the Washoe County government should explore the idea of becoming one combined governmental body. Fifty-four percent of voters approved of the ballot measure to make an inquiry into consolidating the governments.
Fire department.
The city of Reno is protected by the Reno Fire Department (RFD) manning 14 fire stations. The RFD operates a fire apparatus fleet of 20 engines, 5 trucks, 2 rescue units, 2 hazardous material units, various support units, 2 technical rescue support units, 15 brush units, 3 water tenders, and 3 water rescue entry vehicles. In 2008, the RFD responded to over 38,000 emergency calls.
Education.
Public schools.
Public education is provided by the Washoe County School District.
Public charter schools.
Reno has many charter schools, which include Academy for Career Education, serving grades 10–12, opened 2002; Alpine Academy Charter High School, serving grades 9–12, opened 2009; Bailey Charter Elementary School, serving grades K-6, opened 2001; Coral Academy of Science, serving grades K-12, opened 2000; Davidson Academy, serving grades 6–12, opened 2006; High Desert Montessori School, serving grades PreK-7, opened 2002; I Can Do Anything Charter School, serving grades 9–12, opened 2000; Rainshadow Community Charter High School, serving grades 9–12, opened 2003; Sierra Nevada Academy Charter School, serving grades PreK-8, opened 1999; and TEAM A (Together Everyone Achieves More Academy), serving grades 9–12, opened 2004.
Private schools.
Reno has a few private elementary schools such as Legacy Christian School, Excel Christian School, Lamplight Christian School, and Nevada Sage Waldorf School as well as private high schools, the largest of which are Bishop Manogue High School and Sage Ridge School.
Infrastructure.
Transportation.
Roads.
Reno was historically served by the Victory Highway and a branch of the Lincoln Highway. After the formation of the U.S. Numbered Highways system, U.S. Route 40 was routed along 4th Street through downtown Reno, before being replaced by Interstate 80. The primary north-south highway through Reno is U.S. Route 395/Interstate 580.
Bus.
The Regional Transportation Commission of Washoe County (RTC) has a bus system that provides intracity buses, intercity buses to Carson City, and an on-demand shuttle service for disabled persons. The bus system has its main terminal on 4th Street in downtown Reno and secondary terminals in Sparks and at Meadowood Mall in south Reno.
Numerous shuttle and excursion services are offered connecting the Reno–Tahoe International Airport to various destinations:
Greyhound and Silver State Trailways stop at a downtown terminal. Megabus stops at the Silver Legacy Reno.
Rail.
Reno was historically a stopover along the First Transcontinental Railroad; the modern Overland Route continues to run through Reno. Reno was historically the southern terminus of the Nevada–California–Oregon Railway (NCO) and the northern terminus of the Virginia and Truckee Railroad. Using the NCO depot and right of way, the Western Pacific Railroad historically provided rail service to Reno. In the early 20th century, Reno also had a modest streetcar system. Downtown Reno has two historic train depots, the inactive Nevada-California-Oregon Railroad Depot and the still active Amtrak depot, originally built by the Southern Pacific Railroad.
Amtrak provides daily passenger service to Reno via the "California Zephyr" and multiple Amtrak Thruway Motorcoaches connecting to trains departing from Sacramento.
Air.
The city is served by Reno–Tahoe International Airport, with general aviation traffic handled by Reno Stead Airport. Reno–Tahoe International Airport is the second busiest commercial airport in the state of Nevada after McCarran International Airport in Las Vegas. Reno was the hub and headquarters of the defunct airline Reno Air.
Utilities.
Potable water for the city of Reno is provided by the Truckee Meadows Water Authority. The Truckee River is the primary water source, with purification being done at two plants, Chalk Bluff and Glendale. The Chalk Bluff plant's main intakes are west of Reno in Verdi, with the water flowing through a series of flumes and ditches to the plant itself. Alternative intakes are located below the plant along the banks of the Truckee River itself. The Glendale plant is sited alongside the river, and is fed by a rock and concrete rubble diversion dam a short distance upstream.
Sewage treatment for the majority of the Truckee Meadows region takes place at the Truckee Meadows Water Reclamation Facility at the eastern edge of the valley. Treated effluent returns to the Truckee River by way of Steamboat Creek.
Electrical power and natural gas are provided by NV Energy, formerly Sierra Pacific. Power comes from multiple sources, including Tracy-Clark Station to the east, and the Steamboat Springs binary cycle power plants at the southern end of town.
Twin towns – Sister cities.
Reno has eight sister cities:

</doc>
<doc id="26390" url="https://en.wikipedia.org/wiki?curid=26390" title="Riemann integral">
Riemann integral

In the branch of mathematics known as real analysis, the Riemann integral, created by Bernhard Riemann, was the first rigorous definition of the integral of a function on an interval. For many functions and practical applications, the Riemann integral can be evaluated by the fundamental theorem of calculus or approximated by numerical integration.
The Riemann integral is unsuitable for many theoretical purposes. Some of the technical deficiencies in Riemann integration can be remedied with the Riemann–Stieltjes integral, and most disappear with the Lebesgue integral.
Overview.
Let be a non-negative real-valued function on the interval , and let
be the region of the plane under the graph of the function and above the interval (see the figure on the top right). We are interested in measuring the area of . Once we have measured it, we will denote the area by:
The basic idea of the Riemann integral is to use very simple approximations for the area of . By taking better and better approximations, we can say that "in the limit" we get exactly the area of under the curve.
Note that where can be both positive and negative, the definition of is modified so that the integral corresponds to the "signed area" under the graph of : that is, the area above the -axis minus the area below the -axis.
Definition.
Partitions of an interval.
A partition of an interval ["a", "b"] is a finite sequence of numbers of the form
Each is called a subinterval of the partition. The mesh or norm of a partition is defined to be the length of the longest subinterval, that is,
A tagged partition formula_5 of an interval ["a", "b"] is a partition together with a finite sequence of numbers formula_6 subject to the conditions that for each , formula_7. In other words, it is a partition together with a distinguished point of every subinterval. The mesh of a tagged partition is the same as that of an ordinary partition.
Suppose that two partitions formula_5 and formula_9 are both partitions of the interval . We say that formula_9 is a refinement of formula_5 if for each integer "i", with formula_12, there exists an integer formula_13 such that formula_14 and such that formula_15 for some "j" with formula_16. Said more simply, a refinement of a tagged partition breaks up some of the subintervals and adds tags to the partition where necessary, thus it "refines" the accuracy of the partition.
We can define a partial order on the set of all tagged partitions by saying that one tagged partition is greater or equal to another if the former is a refinement of the latter.
Riemann sums.
Choose a real-valued function which is defined on the interval . The "Riemann sum" of with respect to the tagged partition together with is:
Each term in the sum is the product of the value of the function at a given point, and the length of an interval. Consequently, each term represents the (signed) area of a rectangle with height and width . The Riemann sum is the (signed) area of all the rectangles.
Riemann integral.
Loosely speaking, the Riemann integral is the limit of the Riemann sums of a function as the partitions get finer. If the limit exists then the function is said to be integrable (or more specifically Riemann-integrable). The Riemann sum can be made as close as desired to the Riemann integral by making the partition fine enough.
One important requirement is that the mesh of the partitions must become smaller and smaller, so that in the limit, it is zero. If this were not so, then we would not be getting a good approximation to the function on certain subintervals. In fact, this is enough to define an integral. To be specific, we say that the Riemann integral of "f" equals "s" if the following condition holds:
For all ε > 0, there exists δ such that for any tagged partition formula_18 and formula_19 whose mesh is less than δ, we have
Unfortunately, this definition is very difficult to use. It would help to develop an equivalent definition of the Riemann integral which is easier to work with. We develop this definition now, with a proof of equivalence following. Our new definition says that the Riemann integral of "f" equals "s" if the following condition holds:
For all ε > 0, there exists a tagged partition formula_21 and formula_22 such that for any tagged partition formula_23 and formula_19 which is a refinement of formula_21 and formula_22, we have
Both of these mean that eventually, the Riemann sum of "f" with respect to any partition gets trapped close to "s". Since this is true no matter how close we demand the sums be trapped, we say that the Riemann sums converge to "s". These definitions are actually a special case of a more general concept, a net.
As we stated earlier, these two definitions are equivalent. In other words, "s" works in the first definition if and only if "s" works in the second definition. To show that the first definition implies the second, start with an ε, and choose a δ that satisfies the condition. Choose any tagged partition whose mesh is less than δ. Its Riemann sum is within ε of "s", and any refinement of this partition will also have mesh less than δ, so the Riemann sum of the refinement will also be within ε of "s".
To show that the second definition implies the first, it is easiest to use the Darboux integral. First, one shows that the second definition is equivalent to the definition of the Darboux integral; for this see the article on Darboux integration. Now we will show that a Darboux integrable function satisfies the first definition. Fix ε, and choose a partition formula_28 such that the lower and upper Darboux sums with respect to this partition are within formula_29 of the value "s" of the Darboux integral. Let
If "r" = 0, then "f" is the zero function, which is clearly both Darboux and Riemann integrable with integral zero. Therefore, we will assume that "r" > 0. If "m" > 1, then we choose δ such that
If "m" = 1, then we choose δ to be less than one. Choose a tagged partition formula_18 and formula_19 with mesh smaller than δ. We must show that the Riemann sum is within ε of "s" .
To see this, choose an interval formula_34, then 
where "mj" and "Mj" are respectively, the infimum and the supremum of "f" on formula_36. If all intervals had this property, then this would conclude the proof, because each term in the Riemann sum would be bounded by a corresponding term in the Darboux sums, and we chose the Darboux sums to be near "s". This is the case when "m" = 1, so the proof is finished in that case.
Therefore, we may assume that "m" > 1. In this case, it is possible that one of the formula_37. Instead, it may stretch across two of the intervals determined by formula_28. (It cannot meet three intervals because δ is assumed to be smaller than the length of any one interval.) In symbols, it may happen that
(We may assume that all the inequalities are strict because otherwise we are in the previous case by our assumption on the length of δ.) This can happen at most "m"−1 times.
To handle this case, we will estimate the difference between the Riemann sum and the Darboux sum by subdividing the partition formula_18 at formula_41. The term formula_42 in the Riemann sum splits into two terms:
Suppose, without loss of generality, that formula_44. Then
so this term is bounded by the corresponding term in the Darboux sum for "yj". To bound the other term, notice that
It follows that, for some (indeed any) formula_47,
Since this happens at most "m"−1 times, the distance between the Riemann sum and a Darboux sum is at most formula_29. Therefore, the distance between the Riemann sum and "s" is at most ε.
Examples.
Let formula_50 be the function which takes the value 1 at every point. Any Riemann sum of "f" on [0, 1 will have the value 1, therefore the Riemann integral of "f" on 1 is 1.
Let formula_51 be the indicator function of the rational numbers in [0, 1; that is, "I"Q takes the value 1 on rational numbers and 0 on irrational numbers. This function does not have a Riemann integral. To prove this, we will show how to construct tagged partitions whose Riemann sums get arbitrarily close to both zero and one.
To start, let formula_23 and formula_53 be a tagged partition (each "ti" is between "xi" and formula_54). Choose ε > 0. The "ti" have already been chosen, and we can't change the value of "f" at those points. But if we cut the partition into tiny pieces around each "ti", we can minimize the effect of the "ti". Then, by carefully choosing the new tags, we can make the value of the Riemann sum turn out to be within ε of either zero or one—our choice!
Our first step is to cut up the partition. There are "n" of the "ti", and we want their total effect to be less than ε. If we confine each of them to an interval of length less than formula_55, then the contribution of each "ti" to the Riemann sum will be at least formula_56 and at most formula_57. This makes the total sum at least zero and at most ε. So let δ be a positive number less than formula_55. If it happens that two of the "ti" are within δ of each other, choose δ smaller. If it happens that some "ti" is within δ of some "xj", and "ti" is not equal to "xj", choose δ smaller. Since there are only finitely many "ti" and "xj", we can always choose δ sufficiently small.
Now we add two cuts to the partition for each "ti". One of the cuts will be at formula_59, and the other will be at formula_60. If one of these leaves the interval 1, then we leave it out. "ti" will be the tag corresponding to the subinterval 
If "ti" is directly on top of one of the "xj", then we let "ti" be the tag for both intervals:
We still have to choose tags for the other subintervals. We will choose them in two different ways. The first way is to always choose a rational point, so that the Riemann sum is as large as possible. This will make the value of the Riemann sum at least 1−ε. The second way is to always choose an irrational point, so that the Riemann sum is as small as possible. This will make the value of the Riemann sum at most ε.
Since we started from an arbitrary partition and ended up as close as we wanted to either zero or one, it is false to say that we are eventually trapped near some number "s", so this function is not Riemann integrable. However, it is Lebesgue integrable. In the Lebesgue sense its integral is zero, since the function is zero almost everywhere. But this is a fact that is beyond the reach of the Riemann integral.
There are even worse examples. "I"Q is equivalent (that is, equal almost everywhere) to a Riemann integrable function, but there are non-Riemann integrable bounded functions which are not equivalent to any Riemann integrable function. For example, let "C" be the Smith–Volterra–Cantor set, and let "I""C" be its indicator function. Because "C" is not Jordan measurable, "I""C" is not Riemann integrable. Moreover, no function "g" equivalent to "I""C" is Riemann integrable: "g", like "I""C", must be zero on a dense set, so as in the previous example, any Riemann sum of "g" has a refinement which is within ε of 0 for any positive number ε. But if the Riemann integral of "g" exists, then it must equal the Lebesgue integral of "I""C", which is 1/2. Therefore, "g" is not Riemann integrable.
Similar concepts.
It is popular to define the Riemann integral as the Darboux integral. This is because the Darboux integral is technically simpler and because a function is Riemann-integrable if and only if it is Darboux-integrable.
Some calculus books do not use general tagged partitions, but limit themselves to specific types of tagged partitions. If the type of partition is limited too much, some non-integrable functions may appear to be integrable.
One popular restriction is the use of "left-hand" and "right-hand" Riemann sums. In a left-hand Riemann sum, formula_63 for all "i", and in a right-hand Riemann sum, formula_64 for all "i". Alone this restriction does not impose a problem: we can refine any partition in a way that makes it a left-hand or right-hand sum by subdividing it at each "ti". In more formal language, the set of all left-hand Riemann sums and the set of all right-hand Riemann sums is cofinal in the set of all tagged partitions.
Another popular restriction is the use of regular subdivisions of an interval. For example, the formula_65th regular subdivision of 1 consists of the intervals 
Again, alone this restriction does not impose a problem, but the reasoning required to see this fact is more difficult than in the case of left-hand and right-hand Riemann sums.
However, combining these restrictions, so that one uses only left-hand or right-hand Riemann sums on regularly divided intervals, is dangerous. If a function is known in advance to be Riemann integrable, then this technique will give the correct value of the integral. But under these conditions the indicator function "I"Q will appear to be integrable on 1 with integral equal to one: Every endpoint of every subinterval will be a rational number, so the function will always be evaluated at rational numbers, and hence it will appear to always equal one. The problem with this definition becomes apparent when we try to split the integral into two pieces. The following equation ought to hold:
If we use regular subdivisions and left-hand or right-hand Riemann sums, then the two terms on the left are equal to zero, since every endpoint except 0 and 1 will be irrational, but as we have seen the term on the right will equal 1.
As defined above, the Riemann integral avoids this problem by refusing to integrate "I"Q. The Lebesgue integral is defined in such a way that all these integrals are 0.
Properties.
Linearity.
The Riemann integral is a linear transformation; that is, if "f" and "g" are Riemann-integrable on ["a", "b"] and α and β are constants, then
Because the Riemann integral of a function is a number, this makes the Riemann integral a linear functional on the vector space of Riemann-integrable functions.
Integrability.
A bounded function on a compact interval is Riemann integrable if and only if it is continuous almost everywhere (the set of its points of discontinuity has measure zero, in the sense of Lebesgue measure). This is known as the or Lebesgue's criterion for Riemann integrability or the Riemann–Lebesgue theorem. The criterion has "nothing to do" with the Lebesgue integral. It is due to Lebesgue and uses his measure zero, but makes use of neither Lebesgue's general measure or integral.
The integrability condition can be proven in various ways, one of which is sketched below.
In particular, any set that is at most countable has Lebesgue measure zero, and thus a bounded function (on a compact interval) with only finitely or countably many discontinuities is Riemann integrable.
An indicator function of a bounded set is Riemann-integrable if and only if the set is Jordan measurable. The Riemann integral can be interpreted measure-theoretically as the integral with respect to the Jordan measure.
If a real-valued function is monotone on the interval it is Riemann-integrable, since its set of discontinuities is at most countable, and therefore of Lebesgue measure zero.
If a real-valued function on is Riemann-integrable, it is Lebesgue-integrable. That is, Riemann-integrability is a "stronger" (meaning more difficult to satisfy) condition than Lebesgue-integrability.
If "f""n" is a uniformly convergent sequence on with limit "f", then Riemann integrability of all "f""n" implies Riemann integrability of "f", and
However, the Lebesgue monotone convergence theorem (on a monotone pointwise limit) does not hold. In Riemann integration, taking limits under the integral sign is far more difficult to logically justify than in Lebesgue integration.
Generalizations.
It is easy to extend the Riemann integral to functions with values in the Euclidean vector space R"n" for any "n". The integral is defined component-wise; in other words, if then
In particular, since the complex numbers are a real vector space, this allows the integration of complex valued functions.
The Riemann integral is only defined on bounded intervals, and it does not extend well to unbounded intervals. The simplest possible extension is to define such an integral as a limit, in other words, as an improper integral:
This definition carries with it some subtleties, such as the fact that it is not always equivalent to compute the Cauchy principal value formula_72. For example, consider the function "f"("x") which is 0 at , 1 for , and −1 for . By symmetry, formula_73 always, regardless of "a". But there are many ways for the interval of integration to expand to fill the real line, and other ways can produce different results; in other words, the multivariate limit does not always exist. Computing formula_74 yields "a", and computing formula_75 yields −"a". In general, this improper Riemann integral is undefined. Even standardizing a way for the interval to approach the real line does not work because it leads to disturbingly counterintuitive results. If we agree (for instance) that the improper integral should always be formula_72, then the integral of the translation is −2, so this definition is not invariant under shifts, a highly undesirable property. In fact, not only does this function not have an improper Riemann integral, its Lebesgue integral is also undefined (it equals formula_77).
Unfortunately, the improper Riemann integral is not powerful enough. The most severe problem is that there are no widely applicable theorems for commuting improper Riemann integrals with limits of functions. In applications such as Fourier series it is important to be able to approximate the integral of a function using integrals of approximations to the function. For proper Riemann integrals, a standard theorem states that if "f""n" is a sequence of functions that converge uniformly to "f" on a compact set ["a", "b"], then formula_78. On non-compact intervals such as the real line, this is false. For example, take "f""n"(x) to be "n"−1 on and zero elsewhere. For all "n" we have:
The sequence ("f""n") converges uniformly to the zero function, and clearly the integral of the zero function is zero. Consequently,
This demonstrates that for integrals on unbounded intervals, uniform convergence of a function is not strong enough to allow passing a limit through an integral sign. This makes the Riemann integral unworkable in applications (even though the Riemann integral assigns both sides the correct value), because there is no other general criterion for exchanging a limit and a Riemann integral, and without such a criterion it is difficult to approximate integrals by approximating their integrands.
A better route is to abandon the Riemann integral for the Lebesgue integral. The definition of the Lebesgue integral is not obviously a generalization of the Riemann integral, but it is not hard to prove that every Riemann-integrable function is Lebesgue-integrable and that the values of the two integrals agree whenever they are both defined. Moreover, a function ƒ defined on a bounded interval is Riemann-integrable if and only if it is bounded and the set of points where "f" is discontinuous has Lebesgue measure zero.
An integral which is in fact a direct generalization of the Riemann integral is the Henstock–Kurzweil integral.
Another way of generalizing the Riemann integral is to replace the factors in the definition of a Riemann sum by something else; roughly speaking, this gives the interval of integration a different notion of length. This is the approach taken by the Riemann–Stieltjes integral.
In multivariable calculus, the Riemann integrals for functions from R"n"→R are multiple integrals.

</doc>
<doc id="26392" url="https://en.wikipedia.org/wiki?curid=26392" title="Run-length encoding">
Run-length encoding

Run-length encoding (RLE) is a very simple form of lossless data compression in which "runs" of data (that is, sequences in which the same data value occurs in many consecutive data elements) are stored as a single data value and count, rather than as the original run. This is most useful on data that contains many such runs. Consider, for example, simple graphic images such as icons, line drawings, and animations. It is not useful with files that don't have many runs as it could greatly increase the file size.
RLE may also be used to refer to an early graphics file format supported by CompuServe for compressing black and white images, but was widely supplanted by their later Graphics Interchange Format. RLE also refers to a little-used image format in Windows 3.x, with the extension rle, which is a Run Length Encoded Bitmap, used to compress the Windows 3.x startup screen.
Typical applications of this encoding are when the source information comprises long substrings of the same character or binary digit.
Example.
For example, consider a screen containing plain black text on a solid white background. There will be many long runs of white pixels in the blank space, and many short runs of black pixels within the text. A hypothetical scan line, with B representing a black pixel and W representing white, might read as follows:
With a run-length encoding (RLE) data compression algorithm applied to the above hypothetical scan line, it can be rendered as follows:
This can be interpreted as a sequence of twelve Ws, one B, twelve Ws, three Bs, etc.
The run-length code represents the original 67 characters in only 18. While the actual format used for the storage of images is generally binary rather than ASCII characters like this, the principle remains the same. Even binary data files can be compressed with this method; file format specifications often dictate repeated bytes in files as padding space. However, newer compression methods such as DEFLATE often use LZ77-based algorithms, a generalization of run-length encoding that can take advantage of runs of strings of characters (such as codice_3).
Run-length encoding can be expressed in multiple ways to accommodate data properties as well as additional compression algorithms. For instance, one popular method encodes run lengths for runs of two or more characters only, using an "escape" symbol to identify runs, or using the character itself as the escape, so that any time a character appears twice it denotes a run. On the previous example, this would give the following:
This would be interpreted as a run of twelve Ws, a B, a run of twelve Ws, a run of three Bs, etc. In data where runs are less frequent, this can significantly improve the compression rate.
One other matter is the application of additional compression algorithms. Even with the runs extracted, the frequencies of different characters may be large, allowing for further compression; however, if the run lengths are written in the file in the locations where the runs occurred, the presence of these numbers interrupts the normal flow and makes it harder to compress. To overcome this, some run-length encoders separate the data and escape symbols from the run lengths, so that the two can be handled independently. For the example data, this would result in two outputs, the string "codice_5" and the numbers (codice_6).
History and applications.
Run-length encoding schemes were employed in the transmission of television signals as far back as 1967. It is particularly well suited to palette-based bitmapped images such as computer icons, and was a popular image compression method on early online services such as CompuServe before the advent of more sophisticated formats such as GIF. It does not work well at all on continuous-tone images such as photographs, although JPEG uses it quite effectively on the coefficients that remain after transforming and quantizing image blocks.
Common formats for run-length encoded data include Truevision TGA, PackBits, PCX and ILBM. The ITU also describes a standard to encode run-length-colour for fax machines, known as T.45. The standard, which is combined with other techniques into Modified Huffman coding, is relatively efficient because most faxed documents are generally white space, with occasional interruptions of black.

</doc>
<doc id="26397" url="https://en.wikipedia.org/wiki?curid=26397" title="Red–black tree">
Red–black tree

A red–black tree is a kind of self-balancing binary search tree. Each node of the binary tree has an extra bit, and that bit is often interpreted as the color (red or black) of the node. These color bits are used to ensure the tree remains approximately balanced during insertions and deletions.
Balance is preserved by painting each node of the tree with one of two colors (typically called 'red' and 'black') in a way that satisfies certain properties, which collectively constrain how unbalanced the tree can become in the worst case. When the tree is modified, the new tree is subsequently rearranged and repainted to restore the coloring properties. The properties are designed in such a way that this rearranging and recoloring can be performed efficiently.
The balancing of the tree is not perfect, but it is good enough to allow it to guarantee searching in Big-O notation time, where "n" is the total number of elements in the tree. The insertion and deletion operations, along with the tree rearrangement and recoloring, are also performed in time.
Tracking the color of each node requires only 1 bit of information per node because there are only two colors. The tree does not contain any other data specific to its being a red–black tree so its memory footprint is almost identical to a classic (uncolored) binary search tree. In many cases the additional bit of information can be stored at no additional memory cost.
History.
In 1972 Rudolf Bayer invented a data structure that was a special order-4 case of a B-tree. These trees maintained all paths from root to leaf with the same number of nodes, creating perfectly balanced trees. However, they were not binary search trees. Bayer called them a "symmetric binary B-tree" in his paper and later they became popular as 2-3-4 trees or just 2-4 trees.
In a 1978 paper, "A Dichromatic Framework for Balanced Trees", Leonidas J. Guibas and Robert Sedgewick derived the red-black tree from the symmetric binary B-tree. The color "red" was chosen because it was the best-looking color produced by the color laser printer available to the authors while working at Xerox PARC. Another response from professor Guibas states that it was because of the red and black pens available to them to draw the trees.
In 1993, Andersson introduced the idea of right leaning tree to simplify insert and delete operations.
In 1999, Okasaki showed how to make insert operation purely functional. Its balance function needed to take care of only 4 unbalanced cases and one default balanced case.
The original algorithm used 8 unbalanced cases, but reduced that to 6 unbalanced cases. Sedgewick showed that the insert operation can be implemented in just 46 lines of Java code.
In 2008, Sedgewick proposed the left-leaning red–black tree, leveraging Andersson's idea that simplified algorithms. Sedgewick originally allowed nodes whose two children are red making his trees more like 2-3-4 trees but later this restriction was added making new trees more like 2-3 trees. Sedgewick implemented the insert algorithm in just 33 lines, significantly shortening his original 46 lines of code.
Terminology.
A red–black tree is a special type of binary tree, used in computer science to organize pieces of comparable data, such as text fragments or numbers.
The leaf nodes of red–black trees do not contain data. These leaves need not be explicit in computer memory—a null child pointer can encode the fact that this child is a leaf—but it simplifies some algorithms for operating on red–black trees if the leaves really are explicit nodes. To save memory, sometimes a single sentinel node performs the role of all leaf nodes; all references from internal nodes to leaf nodes then point to the sentinel node.
Red–black trees, like all binary search trees, allow efficient in-order traversal (that is: in the order Left–Root–Right) of their elements. The search-time results from the traversal from root to leaf, and therefore a balanced tree of "n" nodes, having the least possible tree height, results in search time.
Properties.
In addition to the requirements imposed on a binary search tree the following must be satisfied by a 
These constraints enforce a critical property of red–black trees: "the path from the root to the farthest leaf is no more than twice as long as the path from the root to the nearest leaf". The result is that the tree is roughly height-balanced. Since operations such as inserting, deleting, and finding values require worst-case time proportional to the height of the tree, this theoretical upper bound on the height allows red–black trees to be efficient in the worst case, unlike ordinary binary search trees.
To see why this is guaranteed, it suffices to consider the effect of properties 4 and 5 together. For a red–black tree "T", let "B" be the number of black nodes in "property 5". Let the shortest possible path from the root of "T" to any leaf consist of "B" black nodes. Longer possible paths may be constructed by inserting red nodes. However, property 4 makes it impossible to insert more than one consecutive red node. Therefore, ignoring any black NIL leaves, the longest possible path consists of "2*B " nodes, alternating black and red (this is the worst case). Counting the black NIL leaves, the longest possible path consists of "2*B-1" nodes.
"The shortest possible path has all black nodes, and the longest possible path alternates between red and black nodes". Since all maximal paths have the same number of black nodes, by property 5, this shows that "no path is more than twice as long as any other path".
Analogy to B-trees of order 4.
A red–black tree is similar in structure to a B-tree of order 4, where each node can contain between 1 and 3 values and (accordingly) between 2 and 4 child pointers. In such a B-tree, each node will contain only one value matching the value in a black node of the red–black tree, with an optional value before and/or after it in the same node, both matching an equivalent red node of the red–black tree.
One way to see this equivalence is to "move up" the red nodes in a graphical representation of the red–black tree, so that they align horizontally with their parent black node, by creating together a horizontal cluster. In the B-tree, or in the modified graphical representation of the red–black tree, all leaf nodes are at the same depth.
The red–black tree is then structurally equivalent to a B-tree of order 4, with a minimum fill factor of 33% of values per cluster with a maximum capacity of 3 values.
This B-tree type is still more general than a red–black tree though, as it allows ambiguity in a red–black tree conversion—multiple red–black trees can be produced from an equivalent B-tree of order 4. If a B-tree cluster contains only 1 value, it is the minimum, black, and has two child pointers. If a cluster contains 3 values, then the central value will be black and each value stored on its sides will be red. If the cluster contains two values, however, either one can become the black node in the red–black tree (and the other one will be red).
So the order-4 B-tree does not maintain which of the values contained in each cluster is the root black tree for the whole cluster and the parent of the other values in the same cluster. Despite this, the operations on red–black trees are more economical in time because you don't have to maintain the vector of values. It may be costly if values are stored directly in each node rather than being stored by reference. B-tree nodes, however, are more economical in space because you don't need to store the color attribute for each node. Instead, you have to know which slot in the cluster vector is used. If values are stored by reference, e.g. objects, null references can be used and so the cluster can be represented by a vector containing 3 slots for value pointers plus 4 slots for child references in the tree. In that case, the B-tree can be more compact in memory, improving data locality.
The same analogy can be made with B-trees with larger orders that can be structurally equivalent to a colored binary tree: you just need more colors. Suppose that you add blue, then the blue–red–black tree defined like red–black trees but with the additional constraint that no two successive nodes in the hierarchy will be blue and all blue nodes will be children of a red node, then it becomes equivalent to a B-tree whose clusters will have at most 7 values in the following colors: blue, red, blue, black, blue, red, blue (For each cluster, there will be at most 1 black node, 2 red nodes, and 4 blue nodes).
For moderate volumes of values, insertions and deletions in a colored binary tree are faster compared to B-trees because colored trees don't attempt to maximize the fill factor of each horizontal cluster of nodes (only the minimum fill factor is guaranteed in colored binary trees, limiting the number of splits or junctions of clusters). B-trees will be faster for performing rotations (because rotations will frequently occur within the same cluster rather than with multiple separate nodes in a colored binary tree). For storing large volumes, however, B-trees will be much faster as they will be more compact by grouping several children in the same cluster where they can be accessed locally.
All optimizations possible in B-trees to increase the average fill factors of clusters are possible in the equivalent multicolored binary tree. Notably, maximizing the average fill factor in a structurally equivalent B-tree is the same as reducing the total height of the multicolored tree, by increasing the number of non-black nodes. The worst case occurs when all nodes in a colored binary tree are black, the best case occurs when only a third of them are black (and the other two thirds are red nodes).
Applications and related data structures.
Red–black trees offer worst-case guarantees for insertion time, deletion time, and search time. Not only does this make them valuable in time-sensitive applications such as real-time applications, but it makes them valuable building blocks in other data structures which provide worst-case guarantees; for example, many data structures used in computational geometry can be based on red–black trees, and the Completely Fair Scheduler used in current Linux kernels uses red–black trees.
The AVL tree is another structure supporting search, insertion, and removal. It is more rigidly balanced than red–black trees, leading to slower insertion and removal but faster retrieval. This makes it attractive for data structures that may be built once and loaded without reconstruction, such as language dictionaries (or program dictionaries, such as the opcodes of an assembler or interpreter).
Red–black trees are also particularly valuable in functional programming, where they are one of the most common persistent data structures, used to construct associative arrays and sets which can retain previous versions after mutations. The persistent version of red–black trees requires space for each insertion or deletion, in addition to time.
For every 2-4 tree, there are corresponding red–black trees with data elements in the same order. The insertion and deletion operations on 2-4 trees are also equivalent to color-flipping and rotations in red–black trees. This makes 2-4 trees an important tool for understanding the logic behind red–black trees, and this is why many introductory algorithm texts introduce 2-4 trees just before red–black trees, even though 2-4 trees are not often used in practice.
In 2008, Sedgewick introduced a simpler version of the red–black tree called the left-leaning red–black tree by eliminating a previously unspecified degree of freedom in the implementation. The LLRB maintains an additional invariant that all red links must lean left except during inserts and deletes. Red–black trees can be made isometric to either 2-3 trees, or 2-4 trees, for any sequence of operations. The 2-4 tree isometry was described in 1978 by Sedgewick. With 2-4 trees, the isometry is resolved by a "color flip," corresponding to a split, in which the red color of two children nodes leaves the children and moves to the parent node. The tango tree, a type of tree optimized for fast searches, usually uses red–black trees as part of its data structure.
Operations.
Read-only operations on a red–black tree require no modification from those used for binary search trees, because every red–black tree is a special case of a simple binary search tree. However, the immediate result of an insertion or removal may violate the properties of a red–black tree. Restoring the red–black properties requires a small number (Big-O notation or amortized ) of color changes (which are very quick in practice) and no more than three tree rotations (two for insertion). Although insert and delete operations are complicated, their times remain .
Insertion.
Insertion begins by adding the node as any binary search tree insertion does and by coloring it red. Whereas in the binary search tree, we always add a leaf, in the red–black tree, leaves contain no information, so instead we add a red interior node, with two black leaves, in place of an existing black leaf.
What happens next depends on the color of other nearby nodes. The term "uncle node" will be used to refer to the sibling of a node's parent, as in human family trees. Note that:
There are several cases of red–black tree insertion to handle:
Each case will be demonstrated with example C code. The uncle and grandparent nodes can be found by these functions:
Case 1: The current node N is at the root of the tree. In this case, it is repainted black to satisfy property 2 (the root is black). Since this adds one black node to every path at once, property 5 (all paths from any given node to its leaf nodes contain the same number of black nodes) is not violated.
Case 2: The current node's parent P is black, so property 4 (both children of every red node are black) is not invalidated. In this case, the tree is still valid. Property 5 (all paths from any given node to its leaf nodes contain the same number of black nodes) is not threatened, because the current node N has two black leaf children, but because N is red, the paths through each of its children have the same number of black nodes as the path through the leaf it replaced, which was black, and so this property remains satisfied.
Note that inserting is actually in-place, since all the calls above use tail recursion.
In the algorithm above, all cases are chained in order, except in insert case 3 where it can recurse to case 1 back to the grandparent node: this is the only case where an iterative implementation will effectively loop. Because the problem of repair is escalated to the next higher level but one, it takes maximally iterations to repair the tree (where is the height of the tree). Because the probability for escalation decreases exponentially with each iteration the average insertion cost is constant.
Removal.
In a regular binary search tree when deleting a node with two non-leaf children, we find either the maximum element in its left subtree (which is the in-order predecessor) or the minimum element in its right subtree (which is the in-order successor) and move its value into the node being deleted (as shown here). We then delete the node we copied the value from, which must have fewer than two non-leaf children. (Non-leaf children, rather than all children, are specified here because unlike normal binary search trees, red–black trees can have leaf nodes anywhere, so that all nodes are either internal nodes with two children or leaf nodes with, by definition, zero children. In effect, internal nodes having two leaf children in a red–black tree are like the leaf nodes in a regular binary search tree.) Because merely copying a value does not violate any red–black properties, this reduces to the problem of deleting a node with at most one non-leaf child. Once we have solved that problem, the solution applies equally to the case where the node we originally want to delete has at most one non-leaf child as to the case just considered where it has two non-leaf children.
Therefore, for the remainder of this discussion we address the deletion of a node with at most one non-leaf child. We use the label M to denote the node to be deleted; C will denote a selected child of M, which we will also call "its child". If M does have a non-leaf child, call that its child, C; otherwise, choose either leaf as its child, C.
If M is a red node, we simply replace it with its child C, which must be black by property 4. (This can only occur when M has two leaf children, because if the red node M had a black non-leaf child on one side but just a leaf child on the other side, then the count of black nodes on both sides would be different, thus the tree would violate property 5.) All paths through the deleted node will simply pass through one fewer red node, and both the deleted node's parent and child must be black, so property 3 (all leaves are black) and property 4 (both children of every red node are black) still hold.
Another simple case is when M is black and C is red. Simply removing a black node could break Properties 4 (“Both children of every red node are black”) and 5 (“All paths from any given node to its leaf nodes contain the same number of black nodes”), but if we repaint C black, both of these properties are preserved.
The complex case is when both M and C are black. (This can only occur when deleting a black node which has two leaf children, because if the black node M had a black non-leaf child on one side but just a leaf child on the other side, then the count of black nodes on both sides would be different, thus the tree would have been an invalid red–black tree by violation of property 5.) We begin by replacing M with its child C. We will "relabel" this child C (in its new position) N, and its sibling (its new parent's other child) S. (S was previously the sibling of M.)
In the diagrams below, we will also use P for N's new parent (M's old parent), SL for S's left child, and SR for S's right child (S cannot be a leaf because if M and C were black, then P's one subtree which included M counted two black-height and thus P's other subtree which includes S must also count two black-height, which cannot be the case if S is a leaf node).
We will find the sibling using this function:
We can perform the steps outlined above with the following code, where the function codice_1 substitutes codice_2 into codice_3's place in the tree. For convenience, code in this section will assume that null leaves are represented by actual node objects rather than NULL (the code in the "Insertion" section works with either representation).
If both N and its original parent are black, then deleting this original parent causes paths which proceed through N to have one fewer black node than paths that do not. As this violates property 5 (all paths from any given node to its leaf nodes contain the same number of black nodes), the tree must be rebalanced. There are several cases to consider:
Case 1: N is the new root. In this case, we are done. We removed one black node from every path, and the new root is black, so the properties are preserved.
Again, the function calls all use tail recursion, so the algorithm is in-place.
In the algorithm above, all cases are chained in order, except in delete case 3 where it can recurse to case 1 back to the parent node: this is the only case where an iterative implementation will effectively loop. No more than loops back to case 1 will occur (where is the height of the tree). And because the probability for escalation decreases exponentially with each iteration the average removal cost is constant.
Additionally, no tail recursion ever occurs on a child node, so the tail recursion loop can only move from a child back to its successive ancestors. If a rotation occurs in case 2 (which is the only possibility of rotation within the loop of cases 1–3), then the parent of the node N becomes red after the rotation and we will exit the loop. Therefore, at most one rotation will occur within this loop. Since no more than two additional rotations will occur after exiting the loop, at most three rotations occur in total.
Proof of asymptotic bounds.
A red black tree which contains "n" internal nodes has a height of .
Definitions:
Lemma: A subtree rooted at node "v" has at least formula_1 internal nodes.
Proof of Lemma (by induction height):
Basis: h("v") = 0
If "v" has a height of zero then it must be "null", therefore bh("v") = 0. So:
Inductive Step: "v" such that h("v") = k, has at least formula_1 internal nodes implies that formula_4 such that h(formula_4) = k+1 has at least formula_6 internal nodes.
Since formula_4 has h(formula_4) > 0 it is an internal node. As such it has two children each of which have a black-height of either bh(formula_4) or bh(formula_4)-1 (depending on whether the child is red or black, respectively). By the inductive hypothesis each child has at least formula_11 internal nodes, so formula_4 has at least:
internal nodes.
Using this lemma we can now show that the height of the tree is logarithmic. Since at least half of the nodes on any path from the root to a leaf are black (property 4 of a red–black tree), the black-height of the root is at least h(root)/2. By the lemma we get:
Therefore, the height of the root is .
Parallel algorithms.
Parallel algorithms for constructing red–black trees from sorted lists of items can run in constant time or time, depending on the computer model, if the number of processors available is asymptotically proportional to the number of items where . Fast search, insertion, and deletion parallel algorithms are also known.
Popular Culture.
A red-black-tree was referenced correctly in an episode of Missing (Canadian TV series) as noted by Robert Sedgewick in one of his lectures:

</doc>
<doc id="26399" url="https://en.wikipedia.org/wiki?curid=26399" title="RMS Laconia">
RMS Laconia

Two different ocean liners of the Cunard Steamship Lines have been named RMS "Laconia". Although one was launched ten years after the other, and was the subject of a TV movie, they are easily confused; they had similar careers, looked the same, and met similar fates.

</doc>
