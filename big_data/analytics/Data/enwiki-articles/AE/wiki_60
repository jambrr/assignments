<doc id="28113" url="https://en.wikipedia.org/wiki?curid=28113" title="Timeline for September following the September 11 attacks">
Timeline for September following the September 11 attacks

This article summarizes the events in the remaining days of September 2001 following the September 11 attacks which relate to the attacks. All times, except where otherwise noted, are in Eastern Daylight Time (EDT), or .
September 2001.
Friday, September 14.
The National Day of Prayer and Remembrance

</doc>
<doc id="28117" url="https://en.wikipedia.org/wiki?curid=28117" title="SAC">
SAC

SAC or Sac may refer to:

</doc>
<doc id="28118" url="https://en.wikipedia.org/wiki?curid=28118" title="Strategic Air Command">
Strategic Air Command

Strategic Air Command (SAC) was both a Department of Defense Specified Command and a United States Air Force (USAF) Major Command (MAJCOM) responsible for Cold War command and control of two of the three components of the U.S. military's strategic nuclear strike forces, the so-called "Nuclear Triad," with SAC having control of land-based strategic bomber aircraft and intercontinental ballistic missiles (ICBMs). SAC also operated all strategic reconnaissance aircraft, all strategic airborne command post aircraft, and all USAF aerial refueling aircraft, to include those in the Air Force Reserve (AFRES) and Air National Guard (ANG), with the exception of those KB-50, KC-97, HC-130 and MC-130 aircraft operated by Tactical Air Command (TAC), Military Airlift Command (MAC), Air Force Special Operations Command (AFSOC) from May 1990 onward, or associated AFRES and ANG aerial refueling aircraft gained by TAC, MAC or AFSOC.
SAC primarily consisted of the Second Air Force (2AF), Eighth Air Force (8AF) and the Fifteenth Air Force (15AF), while SAC headquarters (HQ SAC) included Directorates for Operations & Plans, Intelligence, Command & Control, Maintenance, Training, Communications, and Personnel. At a lower echelon, headquarters divisions included Aircraft Engineering, Missile Concept, and Strategic Communications.
In 1992, as part of an overall post-Cold War reorganization of the U.S. Air Force, SAC was disestablished as both a Specified Command and as a MAJCOM, and its personnel and equipment redistributed among the Air Combat Command (ACC), Air Mobility Command (AMC), Pacific Air Forces (PACAF), United States Air Forces in Europe (USAFE), and Air Education and Training Command (AETC), while SAC's central headquarters complex at Offutt AFB, Nebraska was concurrently transferred to the newly created United States Strategic Command (USSTRATCOM), which was established as a joint Unified Combatant Command to replace SAC's Specified Command role. In 2009, SAC's USAF MAJCOM role was re-activated and re-designated as Air Force Global Strike Command.
Background.
The Strategic Air Forces of the United States during World War II included General Carl Spaatz's European command, United States Strategic Air Forces in Europe (USSTAF), consisting of the 8AF and 15AF, and the United States Strategic Air Forces in the Pacific (USASTAF) and its Twentieth Air Force (20AF).
The Operation Overlord air plan for the strategic bombing of both Germany and German military forces in continental Europe prior to the 1944 invasion of France used several Air Forces, primarily those of the USAAF and those of the Royal Air Force (RAF), with command of air operations transferring to the Supreme Commander of the Allied Expeditionary Force on 14 April 1944.
Planning to reorganize for a separate and independent postwar U.S. Air Force had begun by the fall of 1945, with the Simpson Board tasked to plan, "...the reorganization of the Army and the Air Force...". In January 1946, Generals Eisenhower and Spaatz agreed on an Air Force organization composed of the Strategic Air Command, the Air Defense Command, the Tactical Air Command, the Air Transport Command and the supporting Air Technical Service Command, Air Training Command, the Air University, and the Air Force Center.
Establishment and transfer to USAF.
Strategic Air Command was originally established in the U.S. Army Air Forces on 21 March 1946, acquiring part of the personnel and facilities of the Continental Air Forces (CAF), the World War II command tasked with the air defense of the continental United States (CONUS). At the time, CAF headquarters was located at Bolling Field (later Bolling AFB) in the District of Columbia and SAC assumed occupancy of its headquarters facilities until relocating SAC headquarters (HQ SAC) to nearby Andrews Field (later Andrews AFB), Maryland as a tenant activity until assuming control of Andrews Field in October 1946.
SAC initially totaled 37,000 USAAF personnel. In addition to Bolling Field and, seven months later, Andrews Field, SAC also assumed responsibility for:
SAC also had seven additional CAF bases transferred on 21 March 1946 which remained in SAC through the 1947 establishment of the U.S. Air Force as an independent service. Those installations included:
On 31 March 1946, the following additional installation was also assigned to SAC:
Under the first SAC Commander in Chief, General George C. Kenney, initial units reporting to the Strategic Air Command headquarters on 21 March 1946 included the Second Air Force, the IX Troop Carrier Command and the 73d Air Division.
Fifteenth Air Force was assigned to SAC on 31 March (15th AF's 263rd Army Air Force Base Unit—with SAC's radar detachments—transferred the same date directly under HQ SAC ), while the IX Troop Carrier Command was inactivated the same date and its assets redistributed within SAC.
With postwar demobilization still underway, eight of the ten assigned bomb groups were inactivated before the Eighth Air Force was assigned to SAC on 7 June 1946
Despite the pressures of demobilization, SAC continued the training and evaluation of bomber crews and units still on active duty in the postwar Army Air Forces. Radar Bomb Scoring became the preferred method of evaluating bomber crews, with the last of 888 simulated bomb runs scored against a bombing site near San Diego, California during 1946, subsequently increasing to 2,449 bomb runs by 1947. In the wake of the successful employment of air-dropped nuclear weapons against Hiroshima and Nagasaki to effectively end World War II, SAC became the focus of the nation's nuclear strike capability, to the extent that Joint Chiefs of Staff (JCS) Publication 1259/27 on 12 December 1946 identified that, "...the 'air atomic' strategic air force should only come under the orders of the JCS."
In addition to the strategic bombing mission, SAC also devoted significant resources to aerial reconnaissance. In 1946, SAC's reconnaissance aircraft inventory consisted of F-2 photo variants of the C-45 Expeditor support aircraft, but by 1947 SAC had acquired an F-9C squadron consisting of twelve photo-reconnaissance variants of the B-17G Flying Fortress. An F-13 squadron, the F-13 later re-designated as the RB-29 Superfortress, was also established. SAC conducted routine aerial reconnaissance missions near the Soviet borders or near the 12-mile international waters limit, although some missions actually penetrated into Soviet airspace. The flight profiles of these missions—above 30,000 feet and in excess of 300 knots—made interception by Soviet air forces difficult until the Soviet's 1948 introduction of the MiG-15 jet fighter. Project Nanook, the Cold War’s first Top Secret reconnaissance effort, used the first RB-29 missions for mapping and visual reconnaissance in the Arctic and along the northern Soviet coast. Later missions were Project LEOPARD along the Chukchi Peninsula, followed by Projects RICKRACK, STONEWORK, and COVERALLS.
In 1946, the US possessed only nine atomic bombs and twenty-seven B-29s capable at any one time of delivering them. Furthermore, it was later determined that an attack by the 509th Composite Bomb Group during the 1947 to 1948 time frame would have required at least five to six days just to transfer custody of the bombs from United States Atomic Energy Commission (AEC) sites to SAC and deploy the aircraft and weapons to forward operating bases before launching nuclear strikes.
Unfortunately, postwar budget and personnel cuts had had an insidious effect on SAC as its Deputy Commander, Major General Clements McMullen, implemented mandated force reductions. This continued to wear down SAC as a command and morale plummeted. As a result, by the end of 1947, only two of SAC's eleven groups were combat ready. After the 1948 Bikini Atoll nuclear tests, the "Half Moon" Joint Emergency War Plan developed in May 1948 proposed dropping 50 atomic bombs on twenty Soviet cities, with President Harry S. Truman approving "Half Moon" during the June 1948 Berlin Blockade, (Truman sent B-29s to Europe in July). SAC also ordered special ELINT RB-29s to detect improved Soviet radars and, in cooperation with the 51st Air Force Base Unit, SAC also monitored radioactive fallout from Soviet atomic testing on Novaya Zemlya.
In terms of overall Air Force basing and infrastructure, SAC continued to acquire an ever-increasing share of USAF infrastructure and the USAF associated budget. In 1947, before the USAF was established as an independent service, construction commenced on Limestone AAF, Maine (later renamed Loring AFB), a new SAC installation specifically designed to accommodate the B-36 Peacemaker. Fort Dix AAF, New Jersey (later McGuire AFB); Spokane AAF, Washington (later Fairchild AFB); and Wendover Field, Utah (later Wendover AFB) were also transferred to SAC between 30 April and 1 September 1947. Following establishment of the USAF as a separate service, those bases subsequently added to SAC in the United States included:
In addition to bases under its operational control, SAC also maintained tenant wings at several bases under the control of other USAF MAJCOMs. These non-SAC bases with SAC tenants included Amarillo AFB, Texas; Eglin AFB, Florida; Lowry AFB, Colorado; Mather AFB, California; Robins AFB, Georgia; Seymour Johnson AFB, North Carolina; Sheppard AFB, Texas; and Wright-Patterson AFB, Ohio. SAC also often maintained a presence at former SAC bases that the command subsequently relinquished to other MAJCOMs, to include but not limited to Altus AFB, Oklahoma; MacDill AFB, Florida; Homestead AFB, Florida; and Travis AFB, California.
Run-up to Korea and start of the Cold War.
SAC transferred to the United States Air Force on 26 September 1947, concurrent with the latter's establishment as a separate military service. Units directly under SAC HQ included the 8AF and 15AF, as well as the 311th Air Division, 4th Fighter Wing, 82nd Fighter Wing, 307th Bomb Wing, and two reconnaissance units, the 311th Reconnaissance Wing and the 46th Reconnaissance Squadron. The 56th Fighter Wing was subsequently assigned to SAC on 1 October 1947.
Following the establishment of the U.S. Air Force, most SAC installations on U.S. territory were renamed as "Air Force Base" during late 1947 and into 1948, while non-U.S. installations were renamed as "Air Base."
In May 1948, in an exercise versus Air Defense Command's "Blue" force, a SAC "Red" strike force simulated attacks on Eastern Seaboard targets as far south as Virginia. After a "scathing" 1948 Lindbergh review of SAC operations in the air and at six SAC bases, General Kenney was removed as Commanding General on 15 October 1948 and replaced on 19 October 1948 by 8AF's commander, Lieutenant General Curtis LeMay. Upon Lemay's assumption of command, SAC had only 60 nuclear-capable aircraft, none of which possessed a realistic long range capability against the Soviet Union.
The B-29D, which had become the B-50 in December 1945, was first delivered to SAC in June 1948. This was followed by SAC's first Convair B-36 Peacemaker bomber arriving at Kirtland AFB, New Mexico in September 1948.
In November 1948, LeMay had SAC's headquarters and its command post moved from Andrews AFB, Maryland to Offutt AFB, Nebraska. At Offutt, the command moved into the "A Building," a three-story facility which had previously been used by the Glenn L. Martin Company during World War II. Concurrent with establishment of this new headquarters facility, Lemay also increased SAC Radar Bomb Scoring (RBS) runs the same year to 12,084. SAC also enhanced its organic fighter escort capability by initiating replacement of its World War II vintage piston-engine F-51D Mustang and F-82E Twin Mustang fighter aircraft with F-84G Thunderjets.
In January 1949, SAC conducted simulated raids on Wright-Patterson AFB, Ohio. Assessments of these simulated raids by, "...LeMay's entire command...were appalling," despite the SAC deputy commander, Major General McMullen, having instructed all bomber units to improve their effectiveness. To motivate crews and improve operational effectiveness command-wide, SAC established a competition, the first so-called "Bomb Comp" in 1948. Winners of this inaugural event were the 43rd Bombardment Group (unit) and, for aircrew award, a B-29 team from the 509th Bombardment Group.
Given its global operating environment, SAC also opened its own survival school at Camp Carson, Colorado in 1949, later moving this school to Stead AFB, Nevada in 1952 before transferring the school to the Air Training Command in 1954.
SAC also created Emergency War Plan 1–49 (EWP 1-49), which outlined the means for delivering 133 atomic bombs, "...the entire stockpile...in a single massive attack..." on 70 Soviet cities over a 30-day period.
The first Soviet atomic bomb test occurred on 29 August 1949 and the Joint Chiefs of Staff (JCS) subsequently identified SAC's primary objective was to damage or destroy the Soviet Union's ability to deliver nuclear weapons. The JCS further defined SAC's secondary objective was to stop any Soviet advances into Western Europe, and its tertiary objective was the previous EWP 1-49 industrial mission.
Korean War.
In July 1950, in response to combat operations on the Korean peninsula, SAC dispatched ten nuclear-capable bombers to Guam and deployed four B-29 bomber wings in Korea for tactical operations, although this action caused SAC commander Lemay to comment, “...too many splinters were being whittled off the stick”..
Initial SAC B-29 successes against North Korea in the summer of 1950 were countered by subsequent Soviet MiG-15 fighter-interceptors, and SAC's 27th Fighter Escort Wing began escorting the bombers with F–84 Thunderjets. Ground-directed bombing (GDB) was subsequently used for close air support (CAS) missions after three SAC radar bomb scoring (RBS) squadron detachments (Dets C, K, & N) arrived at Pusan in September 1950. In 1951, SAC "began to eliminate its combat groups", transferring medium bombardment groups "to Far East Air Forces (FEAF) Bomber Command for combat." In 1951, LeMay convinced the Air Staff to allow SAC to approve nuclear targets, and he continued refusing to submit war plans for JCS review, which the JCS eventually came to accept (of 20,000 candidates in 1960, SAC designated 3,560 as bombing targets—mostly Soviet air defense: airfields and suspected missile sites.)
Although experimented with prior to World War II, SAC refined aerial refueling to a fine art. SAC's in-flight refueling mission began in July 1952 when its 31st Fighter-Escort Wing refueled sixty F-84G Thunderjets from Turner AFB, Georgia to Travis AFB, California non-stop with fuel from twenty-four KB-29P Superfortresses modified into aerial tankers. Exercise FOX PETER ONE followed with 31st FEW fighters being refueled Hickam AFB en route to Hawaii.
On 15 March 1953, a 38th Strategic Reconnaissance Squadron RB-50 returned fire on a Soviet MiG-15, while a 343d Strategic Reconnaissance Squadron RB-50 was shot down over the Sea of Japan 2 days after the Korean Armistice, while on 7 November 1954, an RB-29 was shot down near Hokkaido Island in northern Japan. By the time of the 27 July 1953 Korean War cease-fire, SAC B-29s had flown over 21,000 sorties and dropped nearly 167,000 tons of bombs, with thirty-four B-29s lost in combat and forty-eight B-29s were lost to damage or crashes.
The Cold War and massive retaliation.
SAC's first jet strategic bomber was the swept-wing B-47 medium bomber, which first entered service in 1951 and became operational within SAC in 1953. The B-47 was a component of the October 1953 "New Look" strategy, which articulated, in part, that: ""...to minimize the threat...the major purpose of air defense was not to shoot down enemy bombers--it was to allow SAC...to get into the air"[--and" not be destroyed on the ground"[--to allow]" massive retaliation".".
Concern of a bomber gap grew after the 1955 Soviet Aviation Day and the Soviets rejected the "Open Skies" Treaty proposed at the Geneva Summit on 21 July 1955. US bomber strength peaked with "over 2,500 bombers" after production "of over 2,000 B-47s and almost 750 B-52s" (circa 1956, 50% of SAC aircraft & 80% of SAC bombers were B-47s).
In an effort to concurrently enhance it reconnaissance capabilities, SAC also received several RB-57D Canberra aircraft in April 1956, with the aircraft initially based at Turner AFB, Georgia. In 1957, these aircraft were forward deployed to Rhein-Main Air Base, West Germany, in order to conduct reconnaissance missions along the borders of the Soviet Union and other Warsaw Pact nations. However, an unintended consequence of this deployment was that Hawker Hunter fighters of the Royal Air Force stationed in the United Kingdom and in continental Europe often intercepted these classified RB-57 missions as they returned to Rhein-Main AB from over the Baltic.
Since it was designed as medium bomber, SAC's B-47 Stratojet traded speed for range. Because of this shorter range, and in order to better enable the B-47 fleet to reach its target sets in the Soviet Union, SAC routinely deployed its US-based B-47 wings to overseas forward operating bases in North Africa, Spain and Turkey. This program, in effect from 1957 to 1966, was known as "Reflex" with Sixteenth Air Force (16AF), a SAC numbered air force permanently stationed in Europe, having tactical and administrative control of the forward deployed aircraft and units.
Beginning in 1955, SAC also moved a portion of its bomber and aerial refueling aircraft to a 24-hour alert status, either on the ground or airborne. By 1960, fully one third of SAC's bombers and aerial refueling aircraft were on 24-hour alert, with those crews and aircraft not already airborne ready to take off from designated alert sites at their respective bases within fifteen minutes. Bomber aircraft on ground alert were armed with nuclear weapons while aerial tanker aircraft were sufficiently fueled to provide maximum combat fuel offload to the bombers.
Concurrent with this increased alert posture and in order to better hone strategic bombing skillsets, the 1955 SAC Bombing and Navigation Competition was characterized by radar bomb scoring (RBS) runs on Amarillo, Denver, Salt Lake City, Kansas City, San Antonio and Phoenix; and the 1957 competition (nicknamed "Operation Longshot") had three targets: Atlanta, Kansas City, and St. Louis. This use of RBS with simulated target areas utilizing mobile and fixed bomb scoring sites adjacent to major cities, industrial areas, military installations and dedicated bombing ranges throughout the United States. This format would continue through successive SAC Bombing and Navigation Competitions through the remainder of the 1950s, 1960s, 1970s and 1980s. Commencing in the late 1950s, in addition to representation from every SAC wing with a bombing and/or air refueling mission, later SAC competitions would also include participating bomber and aerial refueling units from the Royal Air Force's Bomber Command and (after 30 April 1968) its successor, RAF Strike Command.
Nuclear Bunkers, SAC Ground Alert, and transfer of SAC's Fighter-Escort Wings.
It was described as the "Western Pentagon," specifically a, "...four-story, reinforced concrete and masonry office building..." above ground and a "...segregated, adjacent three-story below ground command post." This was the description of what would become Building 500 at Offutt AFB and the new headquarters complex built expressly for SAC, with construction commencing in 1955. SAC headquarters moved from the A Building at Offutt AFB to Building 500 in 1957. The underground nuclear bunker had 24-inch thick walls and base floor, 10-inch thick intermediate floors, and 24-to-42-inch thick roof. It also contained a war room with six 16-foot data display screens and the capacity to sustain up to 800 people underground for two weeks. The below ground bunker portion of the headquarters complex also contained an IBM 704 computer, which was used to develop monthly weather forecasts at targets, as well as for computing fuel consumption and fallout cloud patterns for planning strike routes and egress routes (e.g., determining the timing as to which targets to bomb first).
In 1957, SAC also constructed The Notch, a facility alternatively known as the 8th Air Force Combat Operations Center (COC) and the Westover Communications Annex, since it was a sub-post of nearby Westover AFB. A 3-story nuclear bunker located on Bare Mountain, Massachusetts, The Notch was built with three-foot thick walls, 1.5 foot thick steel blast doors, and 20 feet underground to protect 350 people for 35 days. The Notch was shut down as a SAC facility in 1970 when 8th Air Force was relocated to Barksdale AFB, Louisiana.
Despite this investment in "hardened" headquarters and command and control facilities, the 1957 Gaither Commission identified, "...little likelihood of SAC's bombers surviving Soviet first strike since there was no way to detect an incoming attack until the first nuclear weapon warhead landed." As a result, SAC's bombers and tankers began sitting armed ground alert at their respective bases on 1 Oct 57.
In another organizational change during this time period, SAC's fighter escort wings were transferred to Tactical Air Command (TAC) during 1957 and 1958. Finally, during January 1958's Exercise Fir Fly, SAC "faker" aircraft (twelve B-47s) simulated bombing strikes against metropolitan areas and military installations in the United States defended by Air Defense Command's 28th Air Division.
Nuclear missiles, aircrew readiness, airborne alert, and strategic reconnaissance.
After SAC's 1st Missile Division was activated on 18 March 1957, SAC HQ established the Office of Assistant CINCSAC (SAC MIKE) at the Air Force Ballistic Missile Division in California on 1 January 1958. SAC MIKE was responsible for missile development liaison, the intermediate range Jupiter and Thor missiles having been transferred to SAC for alert in 1958.
Beginning on 1 February 1958, a SAC Liaison Team was also located at the NORAD Command Post at Ent AFB, Colorado, and the two commands agreed that direct land line communications should connect SAC bases with NORAD's Air Defense Direction Centers. Also in the late 1950s, SAC continued to enhance its intelligence collection activities and develop innovative means of improving the survivability of its forces to surprise attack. From 1958–, a SAC Detachment (TUSLOG Det 50) operated at Incirlik AB, Turkey, monitoring Soviet missile telemetry from the Kapustin Yar and Tyuratam launch complexes, while in 1959, SAC's Operation Big Star studied, prototyped and evaluated the potential of deploying of Minuteman I ICBMs on civilian railroad tracks via USAF-operated locomotives and trains.
President Eisenhower approved the first Atlas ICBM launch by a SAC crew for 9 September 1959 at Vandenberg AFB.
While missile operations continued to ramp up, robust training for flight crews to ensure survivability for strike missions also continued. In some instances SAC bombers would oppose ADC fighter-interceptors simulating Soviet interceptors. Conversely, SAC assisted ADC readiness by simulating Soviet bomber threats to the continental United States that ADC fighters would respond to. However, following a mid-air collision between an ADC F-102 and a SAC B-47 during a 17 December 1959 Quick Kick exercise, simulated NORAD fighter attacks were prohibited against SAC bombers.
On 18 March 1960, SAC intercontinental missiles began alert at Maine's Snark Missile Launch Complex adjacent to Presque Isle AFB. The following month, on 22 April 1960, SAC turned over the last British-based PGM-17 Thor IRBM to the Royal Air Force. This was soon followed by SAC's first Titan I ICBMs at Lowry AFB's Titan I Missile Complex 1A in Colorado being placed on alert that June.
Beginning in November 1959, in order to counter Soviet surface-to-air missile threats, SAC began adding low-altitude bombing training for its manned bomber force as an adjunct to its legacy high-altitude training. Use of low level flight route corridors known as "Oil Burner" routes (later renamed "Olive Branch" routes in the 1970s), and the first of three SAC RBS trains were utilized starting in 1960. On 30 June 1960, SAC had 696 aircraft on alert in the Zone of Interior, also known as the ZI (referred to today as the Continental United States, or CONUS) and at overseas bases. These 696 aircraft were 113 B-52s, 346 B-47s, 85 KC-135s, and 152 KC-97s. SAC's Emergency War Order (EWO) required the first aircraft to be airborne within 8 minutes and all aircraft to be airborne within 15 minutes after notification.
During the mid-1950s, having recalled numerous World War II USAAF and Korean War USAF combat veteran pilots, navigators, bombardiers and aircrewmen from inactive reserve status back to various lengths of active duty, SAC took the lead in integrating the Air Force's reserve components into the overall SAC structure. By the beginning of the 1960s, SAC had also engineered the assignment of KC-97 Stratotanker aerial refueling aircraft to Air National Guard groups and wings and having them fall under SAC's operational claimancy.
On 11 August 1960, President Eisenhower approved the creation of the Joint Strategic Target Planning Staff (JSTPS), co-located at SAC headquarters at Offutt AFB.) JSTPS also included non-SAC agencies tasked with preparing the Single Integrated Operation Plan, or SIOP, and the National Strategic Target List for nuclear war.
On 1 July 1960, a SAC RB-47 with a six-man crew was shot down in international airspace over the Barents Sea by a Soviet MiG-19. Four of the crewman were killed and two surviving crewmen were captured and held in Lubyanka Prison in Moscow for seven months.
On 3 February 1961, SAC's Boeing EC-135 Looking Glass, began operations as the Airborne Command Post for the Nuclear Triad and the Post-Attack Command and Control System. From this date and for the next 29 1/2 years, until 24 July 1990, SAC would maintain at least one Looking Glass aircraft continuously aloft 24 hours a day, 365 days a year, with an embarked SAC general officer and battle staff, ready to assume command of all strategic nuclear strike forces in the event that SAC headquarters was destroyed in a Soviet first strike. 
SAC's airborne alerts during this period also included Operation Chrome Dome for the bomber and tanker force. Although ostensibly a peacetime mission, Chrome Dome placed heavy demands on flight crews and five B-52 aircraft were lost to airborne mishaps during the operation's eight-year period.
On 11 May 1961, SAC took delivery of its first B-58 Hustler supersonic medium bomber, assigning it to the 305th Bombardment Wing at Bunker Hill AFB. Optimized for high-altitude, high-speed penetration into Soviet territory prior to Soviet advancements in high-altitude surface-to-air missiles, the B-58 was expensive to operate and inefficient at lower altitudes. Its service in SAC would be comparatively short, eventually being replaced by the FB-111 by 1970.
After an early 1961 development by SAC of a Radar Bomb Scoring (RBS) field kit for use in the U.S. Army's Nike surface-to-air missile systems, SAC aircraft flew several mock penetrations into Air Defense Command sectors in the 1961 SAGE/Missile Master test program, as well as the joint SAC-NORAD Sky Shield II exercise followed by Sky Shield III on 2 September 1962.
In 1961, following the Berlin Crisis, President John F. Kennedy increased the number of SAC aircraft on alert to 50 percent and during periods of increased tensions SAC kept some B-52 airborne in the event of a surprise attack.
In 1962, SAC gained full control of the various "Q Areas" developed by Sandia Laboratories for nuclear weapon storage adjacent to Loring AFB (Site E (Maine)/Caribou AFS), Ellsworth AFB (Site F (South Dakota)/Rushmore AFS), Fairchild AFB (Site G (Washington)/Deep Creek AFS), Travis AFB (Site H (California)/Fairfield AFS), and Westover AFB (Site I (Massachusetts)/Stony Brook AFS). These adjunct sites were subsequently converted to USAF-operated and maintained weapon storage areas (WSAs) in the same manner as WSAs on other SAC bases.
The solid fuel LGM-30A Minuteman I was first deployed in 1962 and the LGM-25C Titan II reached operational service in 1963. Project Added Effort phased out all first-generation ICBMs beginning on 1 May 1964 when Atlas-D were taken off alert at Vandenberg AFB's 576th SMS (LGM-30F Minuteman II replaced Minuteman I in 1965).
In October 1962, a SAC BRASS KNOB mission U-2 piloted by Major Richard S. Heyser detected Soviet intermediate range ballistic missiles in Cuba. BRASS KNOB operations involving multiple U-2 aircraft were subsequently commenced at a forward operating location at McCoy AFB, Florida the same month. On the morning of 27 October, a SAC RB-47H of the 55th Strategic Reconnaissance Wing, forward deployed to Kindley AFB, Bermuda crashed on takeoff, killing all four crewmembers, while later that afternoon, a 4028th Strategic Reconnaissance Squadron U-2 forward deployed to McCoy AFB for BRASS KNOB operations was shot down over Cuba by an SA-2 Guideline missile, killing the pilot, Major Rudolf Anderson.
Throughout the early 1960s, the Kennedy Administration, under the aegis of Secretary of Defense McNamara, cancelled numerous SAC modernization programs. This included the Mach 3 North American B-70 Valkyrie in 1961, the GAM-87 Skybolt missile in 1962, and the Rocky Mountain Deep Underground Support Center in 1963. The B-70's demise came due to its design as a high-altitude bomber with very limited low-altitude performance, making it vulnerable to rapid advances in Soviet high altitude surface-to-air missile defense systems. The following year, Skybolt, an air-launched ballistic missile, was cancelled following numerous test failures and the perceived greater reliability of land-based and submarine-based ballistic missile systems. Although initially entering service in 1957, SAC's 2nd-generation aerial refueling aircraft, the KC-135 Stratotanker, had reached sufficient inventory numbers to allow SAC to begin divestiture of its KC-97 Stratofreighter tankers, transferring them to SAC-gained Air Force Reserve and Air National Guard units. As the KC-135 became the primary aerial tanker in active service, SAC employed the aircraft for several non-stop B-52 and KC-135 flights around the world, demonstrating that SAC no longer needed to depend on Reflex stations at air bases in Spain and Britain.)
Vietnam War and latter half of the Cold War.
SAC's air war in Vietnam.
After the Secretary of Defense rejected LeMay's November 1964 proposal for a "...strategic air campaign against 94 targets in North Vietnam...", thirty SAC B-52s were deployed to Andersen AFB, Guam on 17 February 1965, representing the first increment of SAC aircraft forward deployed for the Vietnam War. The following month, in March 1965, the Strategic Air Command Advanced Echelon (SACADVON) was established as a "...liaison unit for CINCSAC located at MACV Headquarters to assist with the B-52 effort.".
On 23 May 1965, SAC B-52s began unarmed missions for radar mapping "...and later to test bombing with the assistance of ground homing beacons...". SAC began saturation bombing on 18 June 1965 (8000 tons per month in 1966) and conducted Operation Arc Light missions from 1965 until the end of hostilities involving U.S. forces in 1973.
All B-52 missions in 1965 were against targets in South Vietnam (RVN) except for the December "...Duck Flight mission hit a suspected VC supply storage area [for which part of the target box was in Laos." In April 1966, Vietnam operations began with the B-52D model, a 1956 model designed to use the AGM-28 Hound Dog cruise missile and the ADM-20 Quail aerial decoys for low altitude operations and modified in late 1965 by Project Big Belly to increase conventional bomb capacity.
SAC's RBS Squadrons were discontinued when most detachment personnel transferred to Vietnam from 1966 to 1973 for Combat Skyspot ground-directed bombing operations. The first "Quick Reaction" bombing was the "Pink Lady" mission on 6 July 1966 using SAC B-52s to support the U.S. Army's 1st Air Cavalry Division. The 1972 Operation Linebacker II also used Skyspot for Hanoi/Haiphong bombings in North Vietnam which resulted in the loss of 25 SAC aircrew members.
By May 1967, SACADVON had moved to Seventh Air Force headquarters at Tan Son Nhut Air Base, South Vietnam to schedule and coordinate "...strikes for the 7th AF and MACV.". From a level of 161,921 military and 20,215 civilian assigned to SAC in June 1968, SAC lost 13,698 first term airmen from November 1968 to May 1969 in a three phase drawdown known as Project 693 to comply with Public Law 90-364.
While conventional bombing, air refueling and strategic air reconnaissance operations in Southeast Asia increasingly occupied SAC's operational commitments, SAC's primary mission of nuclear deterrence continued to remain its primary focus. In 1969, "...SAC's B-52s and B-58s could carry B28, B41, B43, B53, and BA53 nuclear weapons" (SAC had 311 nuclear AGM-28 Hound Dog| missiles at the end of the year.) This also coincided with the B-58 Hustler's in-progress retirement from SAC's active inventory and its replacement with the FB-111.
On 18 March 1969, along the South Vietnamese border, SAC first bombed Cambodia (Operation Menu through 26 May 1970 was controlled by Skyspot). On 17 February 1970, SAC conducted the first "GOOD LOOK" bombing of Laos at the Plaine des Jarres after B-52 photorecon missions (GOOD LOOK ALPHA in August 1969 and GOOD LOOK BRAVO ) and the observations of a Skyspot installation in Thailand. SAC transferred "...HQ 8th AF...to Andersen AFB, Guam on 1 April 1970 to oversee B-52 operations and to complement SACADVON". 8th AF took over from Third Air Division the generation of "frag" orders based on daily strike requests and amendments from COMUSMACV.
In 1970, SAC deployed the LGM-30G Minuteman III ICBM with multiple independently targetable reentry vehicle or MIRVs, for striking 3 targets, while concurrently retiring the B-58 Hustler supersonic bomber.
1972 saw the commencement of Operation Linebacker II, a combined Seventh Air Force and U.S. Navy Task Force 77 aerial bombing campaign, conducted against targets in North Vietnam during the final period of US involvement in the Vietnam War. Linebacker II was conducted from 18 December to 29 December 1972, leading to several informal names such as "The December Raids" and "The Christmas Bombings." Unlike the previous Operation Rolling Thunder and Operation Linebacker interdiction operations, Linebacker II, would be a "maximum effort" bombing campaign to destroy major target complexes in the Hanoi and Haiphong areas which could only be accomplished by SAC B-52s. It saw the largest heavy bomber strikes launched by the U.S. Air Force since the end of World War II. Linebacker II was a modified extension of the Operation Linebacker bombings conducted from May to October 1972, with the emphasis of the new campaign shifted to attacks by B-52 Stratofortress heavy bombers rather than smaller tactical fighter aircraft. During Linebacker II, a total of 741 B-52 sorties were dispatched from bases in Thailand and Guam to bomb North Vietnam and 729 actually completed their missions. Overall SAC losses during Linebacker II numbered fifteen B-52s. The U.S. government claimed that the operation had succeeded in forcing North Vietnam's Politburo to return to the negotiating table, with the Paris Peace Accords signed shortly after the operation.
By early 1973, offensive SAC air operations in Southeast Asia ceased and numerous SAC aircrewmen who had been shot down and captured as prisoners of war by North Vietnam were repatriated to the United States.
Post-Vietnam, 1970s budget cuts, 1980s renewal, and the Cold War redux.
With the Vietnam War draw-down, reduced defense budgets forced SAC to inactivate several wings, close multiple bases in CONUS and Puerto Rico, and retire older B-52B, B-52C, B-52E and B-52F aircraft.
In 1973, the National Emergency Airborne Command Post, or NEACP, aircraft entered SAC's inventory. Consisting of four Boeing E-4 aircraft, these highly modified Boeing 747 airframes were assigned to the 55th Strategic Reconnaissance Wing at Offutt AFB and were forward deployed as necessary to support the National Command Authority.
By 1975, SAC's manned bomber strength included several hundred B-52D, B-52G, B-52H and FB-111A aircraft, and "...SAC's first major exercise in 23 years" was Exercise Global Shield 79. As for the ICBM force, SAC reached a peak strength of 1000 Minuteman II and III and 54 Titan II ICBMs on active status before seeing reductions and retirements through a combination of obsolescing systems and various arms reduction treaties with the Soviet Union.
By 1977, SAC had been pinning its hopes for a new manned strategic bomber in the form of the Rockwell B-1A Lancer. However, on 30 June 1977, President Jimmy Carter Carter announced that the B-1A would be canceled in favor of ICBMs, submarine-launched ballistic missiles (SLBMs), and a fleet of modernized B-52s armed with air-launched cruise missiles (ALCMs).
On 1 December 1979, SAC assumed control of the ballistic missile warning system (BMEWS) and all Space Surveillance Network facilities from the inactivating Aerospace Defense Command (ADC). These activities would later be (transferred to Air Force Space Command (AFSPC) when the latter was established in 1982. SAC also continued to operate the Air Force's entire KC-135 aerial refueling fleet, its EC-135 LOOKING GLASS and E-4 NEACAP command post aircraft, as well the entire strategic reconnaissance aircraft fleet consisting of the U-2, SR-71, RC-135, and WC-135.
In 1981, SAC received a new air refueling tanker aircraft to supplement the aging KC-135 Stratotanker force. Based on the McDonnell Douglas DC-10 commercial airliner, the KC-10A Extender was deployed equipped with improved military avionics, aerial refueling, and satellite communications equipment. That same year, President Ronald Reagan reversed the 1977 Carter administration decision regarding the B-1, directing that 100 examples of a refined version of the aircraft, now designated the B-1B Lancer, be procured as a long-range combat aircraft for SAC.
The LGM-118A Peacekeeper ICBM reached SAC in 1986, and the 114 Peacekeepers had a total warhead yield of about 342 megatons. This also served to offset the retirement of the obsolescent and maintenance-intensive LGM-25C Titan II ICBM, the last example of which was deactivated in May 1987. An additional underground "16,000 square-foot, two-story reinforced concrete" command post for HQ SAC was also constructed at Offutt AFB from 1986 to 1989 from a design by Leo A. Daly, who had designed the adjoining 1957 bunker. The first Rockwell B-1B Lancer was also delivered to SAC in 1987. 
On 22 November 1988, the Northrop Grumman B-2 Spirit, under development as the Advanced Technology Bomber (ATB), a so-called "black program" since 1979, was officially acknowledged and rolled out for the first time for public display. The first "stealth bomber" designed for SAC, the aircraft made its first flight in May 1989.
End of the Cold War and Operation Desert Storm.
SAC reorganization at the end of the Cold War began as early as 1988 when the Carlucci Commission planned the closure of Mather Air Force Base, California, an ATC undergraduate navigator training (UNT) base with a tenant SAC B-52 and KC-135 bomb wing and a tenant SAC-gained AFRES KC-135 air refueling wing; and Pease Air Force Base, New Hampshire, a SAC base with an FB-111 and KC-135 bomb wing and a tenant SAC-gained ANG KC-135 air refueling wing.
On 1 July 1989, the 1st Combat Evaluation Group reporting directly to SAC headquarters was split with most HQ 1CEVG organizations transferring to SAC HQ (e.g., the Command Instrument Flight Division) and RBS personnel, equipment, and radar stations becoming the 1st Electronic Combat Range Group. Airborne NEACP alerts ended in 1990 and during 1991's Operation Desert Storm to liberate Kuwait from Iraqi invasion and occupation, SAC bomber, tanker and reconnaissance aircraft flew operations (e.g., B-52s with conventional bombs and conventional warhead AGM-86 ALCMs) near Iraq from bases in Great Britain, Turkey, Cyprus, Diego Garcia, Saudi Arabia, and the United Arab Emirates.
Following Operation Desert Storm, the dissolution of the Soviet Union and the "de facto" end of the Cold War, President George H. W. Bush and Secretary of Defense Dick Cheney directed SAC to take all bomber and refueling aircraft and Minuteman II ICBM's off of continuous nuclear alert on 27 September 1991 and placing said aircraft on quick reaction ground alert.
The 31 May 1992 major reorganization of the USAF organizational structure subsequently disestablished SAC, moving its bomber, reconnaissance and aerial command post aircraft and all SAC ICBMs, along with all Tactical Air Command aircraft, to the newly established Air Combat Command (ACC). The newly established Air Mobility Command (AMC) inherited most of SAC's KC-135 Stratotanker aircraft and the entire KC-10 Extender aerial refueling tanker force, while some KC-135s were reassigned directly to USAFE and PACAF, with one additional air refueling wing assigned to the Air Education and Training Command (AETC) as the KC-135 formal training unit.
Land-based ICBMs were later transferred from ACC to Air Force Space Command (AFSPC), while manned bombers remained in ACC. USAF nuclear forces in ACC and AFSPC were then combined with the United States Navy's Fleet Ballistic Missile submarine forces to form the United States Strategic Command (USSTRATCOM), which took over the SAC Headquarters complex at Offutt AFB.
In 2009, the entire land-based USAF ICBM force and that portion of the USAF manned bomber force that was still nuclear-capable, e.g., the B-2 Spirit and B-52 Stratofortress, was transferred to the newly established Air Force Global Strike Command (AFGSC), while the B-1 Lancer conventional bomber force remained in ACC. In 2015, these B-1 units were also transferred to Global Strike Command, which assumed responsibility for all current and future USAF bomber forces.
Commemoration and new commands.
The SAC Museum located adjacent to Offutt AFB was moved in 1998 near Interstate 80 in Nebraska and renamed as the Strategic Air and Space Museum.
Organizations commemorating SAC include the Strategic Air Command Veterans Association, the SAC Society, the B-47 Stratojet Association, the B-52 Stratofortress Association, the FB-111 Association, the SAC Airborne Command Control Association, the Association of Air Force Missileers, the SAC Elite Guard Association and the Strategic Air Command Memorial Amateur Radio Club. After the Cold War, SAC histories included a 1996 almanac and a 2006 organizational history.
In 2009, the Air Force Global Strike Command (AFGSC) was activated with the lineage of Strategic Air Command. AFGSC, headquartered at Barksdale AFB, Louisiana, is one of two USAF component commands assigned to United States Strategic Command (USSTRATCOM). AFGSC currently consists of Eighth Air Force (8AF), responsible for the nuclear-capable manned heavy bomber force, and Twentieth Air Force (20AF), responsible for the ICBM force.
Lineage.
Strategic Air Command in the United Kingdom was among the command's largest overseas concentrations of forces, with additional forces under SAC's 16th Air Force at air bases in North Africa, Spain and Turkey during the 1950s and 1960s.
SAC "Provisional" wings were also located in Kadena AB, Okinawa and U-Tapao Royal Thai Navy Airfield / U-Tapao AB, Thailand during the Vietnam War
SAC also maintained bomber, tanker, and/or reconnaissance aircraft assets at the former Ramey AFB, Puerto Rico in the 1950s, 1960s and 1970s, and at Andersen AFB, Guam; RAF Mildenhall, RAF Fairford and RAF Alconbury in the United Kingdom; Moron AB, Spain; Lajes Field, Azores (Portugal); Diego Garcia, BIOT; and the former NAS Keflavik, Iceland through the 1990s.
SAC also conducted operations from RAF Fairford, RAF Alconbury and RAF Mildenhall in the United Kingdom, Moron AB in Spain, Lajes Field in the Azores (Portugal), RAF Akrotiri in Cyprus, Incirlik AB in Turkey, Diego Garcia in the British Indian Ocean Territory, and from multiple air bases in Egypt, Saudi Arabia, Oman, and the United Arab Emirates during the first Gulf War (Operations Desert Shield and Desert Storm) from 1990 to 1991.

</doc>
<doc id="28119" url="https://en.wikipedia.org/wiki?curid=28119" title="Scheme (programming language)">
Scheme (programming language)

Scheme is a functional programming language and one of the two main dialects of the programming language Lisp. Unlike Common Lisp, the other main dialect, Scheme follows a minimalist design philosophy specifying a small standard core with powerful tools for language extension.
Scheme was created during the 1970s at the MIT AI Lab and released by its developers, Guy L. Steele and Gerald Jay Sussman, via a series of memos now known as the Lambda Papers. It was the first dialect of Lisp to choose lexical scope and the first to require implementations to perform tail-call optimization, giving stronger support for functional programming and associated techniques such as recursive algorithms. It was also one of the first programming languages to support first-class continuations. It had a significant influence on the effort that led to the development of Common Lisp.
The Scheme language is standardized in the official IEEE standard and a "de facto" standard called the "Revised Report on the Algorithmic Language Scheme" (R"n"RS). The most widely implemented standard is R5RS (1998); a new standard, R6RS, was ratified in 2007. Scheme has a diverse user base due to its compactness and elegance, but its minimalist philosophy has also caused wide divergence between practical implementations, so much that the Scheme Steering Committee calls it "the world's most unportable programming language" and "a "family" of dialects" rather than a single language.
History.
Origins.
Scheme started in the 1970s as an attempt to understand Carl Hewitt's Actor model, for which purpose Steele and Sussman wrote a "tiny Lisp interpreter" using Maclisp and then "added mechanisms for creating actors and sending messages." Scheme was originally called "Schemer", in the tradition of other Lisp-derived languages like Planner or "Conniver". The current name resulted from the authors' use of the ITS operating system, which limited filenames to two components of at most six characters each. Currently, "Schemer" is commonly used to refer to a Scheme programmer.
R6RS.
A new language standardization process began at the 2003 Scheme workshop, with the goal of producing an R6RS standard in 2006. This process broke with the earlier R"n"RS approach of unanimity.
R6RS features a standard module system, allowing a split between the core language and libraries. A number of drafts of the R6RS specification were released, the final version being R5.97RS. A successful vote resulted in the ratification of the new standard, announced on August 28, 2007.
Currently the newest releases of various Scheme implementations, such as Chez Scheme, Racket, Ikarus, Larceny and Ypsilon, support the R6RS standard. There is a portable reference implementation of the proposed implicitly phased libraries for R6RS, called psyntax, which loads and bootstraps itself properly on various older Scheme implementations.
R6RS introduces numerous significant changes to the language. The source code is now specified in Unicode, and a large subset of Unicode characters may now appear in Scheme symbols and identifiers, and there are other minor changes to the lexical rules. Character data is also now specified in Unicode. Many standard procedures have been moved to the new standard libraries, which themselves form a large expansion of the standard, containing procedures and syntactic forms that were formerly not part of the standard. A new module system has been introduced, and systems for exception handling are now standardized. Syntax-rules has been replaced with a more expressive syntactic abstraction facility (syntax-case) which allows the use of all of Scheme at macro expansion time. Compliant implementations are now "required" to support Scheme's full numeric tower, and the semantics of numbers have been expanded, mainly in the direction of support for the IEEE 754 standard for floating point numerical representation.
R7RS.
The R6RS standard has caused controversy because it is seen to have departed from the minimalist philosophy. In August 2009, the Scheme Steering Committee which oversees the standardization process announced its intention to recommend splitting Scheme into two languages: a large modern programming language for programmers, and a subset of the large version retaining the minimalism praised by educators and casual implementors; two working groups were created to work on these two new versions of Scheme. The Scheme Reports Process site has links to the working groups charters, public discussions and issue tracking system.
The ninth draft of R7RS (small language) was made available on April 15, 2013. A vote ratifying this draft closed on May 20, 2013, and the final report has been available since August 6, 2013.
Distinguishing features.
Scheme is primarily a functional programming language. It shares many characteristics with other members of the Lisp programming language family. Scheme's very simple syntax is based on s-expressions, parenthesized lists in which a prefix operator is followed by its arguments. Scheme programs thus consist of sequences of nested lists. Lists are also the main data structure in Scheme, leading to a close equivalence between source code and data formats (homoiconicity). Scheme programs can easily create and evaluate pieces of Scheme code dynamically.
The reliance on lists as data structures is shared by all Lisp dialects. Scheme inherits a rich set of list-processing primitives such as codice_1, codice_2 and codice_3 from its Lisp progenitors. Scheme uses strictly but dynamically typed variables and supports first-class functions. Thus, functions can be assigned as values to variables or passed as arguments to functions.
This section concentrates mainly on innovative features of the language, including those features that distinguish Scheme from other Lisps. Unless stated otherwise, descriptions of features relate to the R5RS standard.
"In examples provided in this section, the notation "===> result" is used to indicate the result of evaluating the expression on the immediately preceding line. This is the same convention used in R5RS."
Fundamental design features.
This subsection describes those features of Scheme that have distinguished it from other programming languages from its earliest days. These are the aspects of Scheme that most strongly influence any product of the Scheme language, and they are the aspects that all versions of the Scheme programming language, from 1973 onward, share.
Minimalism.
Scheme is a very simple language, much easier to implement than many other languages of comparable expressive power. This ease is attributable to the use of lambda calculus to derive much of the syntax of the language from more primitive forms. For instance of the 23 s-expression-based syntactic constructs defined in the R5RS Scheme standard, 11 are classed as derived or library forms, which can be written as macros involving more fundamental forms, principally lambda. As R5RS says (R5RS sec. 3.1): "The most fundamental of the variable binding constructs is the lambda expression, because all other variable binding constructs can be explained in terms of lambda expressions."
Example: a macro to implement codice_4 as an expression using codice_5 to perform the variable bindings.
<syntaxhighlight lang="Scheme">
(define-syntax let
</syntaxhighlight>
Thus using codice_4 as defined above a Scheme implementation would rewrite "codice_7" as "codice_8", which reduces implementation's task to that of coding procedure instantiations.
In 1998 Sussman and Steele remarked that the minimalism of Scheme was not a conscious design goal, but rather the unintended outcome of the design process. "We were actually trying to build something complicated and discovered, serendipitously, that we had accidentally designed something that met all our goals but was much simpler than we had intended...we realized that the lambda calculus—a small, simple formalism—could serve as the core of a powerful and expressive programming language."
Lexical scope.
Like most modern programming languages and unlike earlier Lisps such as Maclisp, Scheme is lexically scoped: all possible variable bindings in a program unit can be analyzed by reading the text of the program unit without consideration of the contexts in which it may be called. This contrasts with dynamic scoping which was characteristic of early Lisp dialects, because of the processing costs associated with the primitive textual substitution methods used to implement lexical scoping algorithms in compilers and interpreters of the day. In those Lisps, it was perfectly possible for a reference to a free variable inside a procedure to refer to quite distinct bindings external to the procedure, depending on the context of the call.
The impetus to incorporate lexical scoping, which was an unusual scoping model in the early 1970s, into their new version of Lisp, came from Sussman's studies of ALGOL. He suggested that ALGOL-like lexical scoping mechanisms would help to realize their initial goal of implementing Hewitt's Actor model in Lisp.
The key insights on how to introduce lexical scoping into a Lisp dialect were popularized in Sussman and Steele's 1975 Lambda Paper, "Scheme: An Interpreter for Extended Lambda Calculus", where they adopted the concept of the lexical closure (on page 21), which had been described in an AI Memo in 1970 by Joel Moses, who attributed the idea to Peter J. Landin.
Lambda calculus.
Alonzo Church's mathematical notation, the lambda calculus, has inspired Lisp's use of "lambda" as a keyword for introducing a procedure, as well as influencing the development of functional programming techniques involving the use of higher-order functions in Lisp. But early Lisps were not suitable expressions of the lambda calculus because of their treatment of free variables.
The introduction of lexical scope resolved the problem by making an equivalence between some forms of lambda notation and their practical expression in a working programming language. Sussman and Steele showed that the new language could be used to elegantly derive all the imperative and declarative semantics of other programming languages including ALGOL and Fortran, and the dynamic scope of other Lisps, by using lambda expressions not as simple procedure instantiations but as "control structures and environment modifiers." They introduced continuation-passing style along with their first description of Scheme in the first of the Lambda Papers, and in subsequent papers they proceeded to demonstrate the raw power of this practical use of lambda calculus.
Block structure.
Scheme inherits its block structure from earlier block structured languages, particularly ALGOL. In Scheme, blocks are implemented by three "binding constructs": codice_4, codice_10 and codice_11. For instance, the following construct creates a block in which a symbol called codice_12 is bound to the number 10:
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
Blocks can be nested to create arbitrarily complex block structures according to the need of the programmer. The use of block structuring to create local bindings alleviates the risk of namespace collision that can otherwise occur.
One variant of codice_4, codice_10, permits bindings to refer to variables defined earlier in the same construct, thus:
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
The other variant, codice_11, is designed to enable mutually recursive procedures to be bound to one another.
<syntaxhighlight lang="Scheme">
 (if (= n 0)
 1
 (- n (male (female (- n 1)))))))
 (male (lambda (n)
 (if (= n 0)
 0
 (- n (female (male (- n 1))))))))
 '()
 (cons (cons (female i)
 (male i))
 (loop (+ i 1)))))))
===> ((1 . 0) (1 . 0) (2 . 1) (2 . 2) (3 . 2) (3 . 3) (4 . 4) (5 . 4) (5 . 5))
</syntaxhighlight>
All procedures bound in a single codice_11 may refer to one another by name, as well as to values of variables defined earlier in the same codice_11, but they may not refer to "values" defined later in the same codice_11.
A variant of codice_4, the "named let" form, has an identifier after the codice_4 keyword. This binds the let variables to the argument of a procedure whose name is the given identifier and whose body is the body of the let form. The body may be repeated as desired by calling the procedure. The named let is widely used to implement iteration.
Example: a simple counter
<syntaxhighlight lang="Scheme">
 (loop (+ n 1)))))
===> (1 2 3 4 5 6 7 8 9 10)
</syntaxhighlight>
Like any procedure in Scheme the procedure created in the named let is a first class object.
Proper tail recursion.
Scheme has an iteration construct, codice_21, but it is more idiomatic in Scheme to use tail recursion to express iteration. Standard-conforming Scheme implementations are required to optimize tail calls so as to support an unbounded number of active tail calls (R5RS sec. 3.5)—a property the Scheme report describes as "proper tail recursion"—making it safe for Scheme programmers to write iterative algorithms using recursive structures, which are sometimes more intuitive. Tail recursive procedures and the "named codice_4" form provide support for iteration using tail recursion.
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
First-class continuations.
Continuations in Scheme are first-class objects. Scheme provides the procedure codice_23 (also known as codice_24) to capture the current continuation by packing it up as an escape procedure bound to a formal argument in a procedure provided by the programmer. (R5RS sec. 6.4) First-class continuations enable the programmer to create non-local control constructs such as iterators, coroutines, and backtracking.
Continuations can be used to emulate the behavior of return statements in imperative programming languages. The following function codice_25, given function codice_26 and list codice_27, returns the first element codice_28 in codice_27 such that codice_30 returns true.
<syntaxhighlight lang="scheme">
 (if (func x)
 (return-immediately x)))
 lst)
===> 7
===> #f
</syntaxhighlight>
The following example, a traditional programmer's puzzle, shows that Scheme can handle continuations as first-class objects, binding them to variables and passing them as arguments to procedures.
<syntaxhighlight lang="scheme">
(let* ((yin
</syntaxhighlight>
When executed this code displays a counting sequence: codice_31
Shared namespace for procedures and variables.
In contrast to Common Lisp, all data and procedures in Scheme share a common namespace, whereas in Common Lisp functions and data have separate namespaces making it possible for a function and a variable to have the same name, and requiring special notation for referring to a function as a value. This is sometimes known as the "Lisp-1 vs. Lisp-2" distinction, referring to the unified namespace of Scheme and the separate namespaces of Common Lisp.
In Scheme, the same primitives that are used to manipulate and bind data can be used to bind procedures. There is no equivalent of Common Lisp's codice_32, codice_33 and codice_34 primitives.
<syntaxhighlight lang="Scheme">
f
===> 10
f
===> 26
===> 18
f
===> 13
===> 21
===> (101 102 103)
</syntaxhighlight>
Implementation standards.
This subsection documents design decisions that have been taken over the years which have given Scheme a particular character, but are not the direct outcomes of the original design.
Numerical tower.
Scheme specifies a comparatively full set of numerical datatypes including complex and rational types, which is known in Scheme as the numerical tower (R5RS sec. 6.2). The standard treats these as abstractions, and does not commit the implementor to any particular internal representations.
Numbers may have the quality of exactness. An exact number can only be produced by a sequence of exact operations involving other exact numbers—inexactness is thus contagious. The standard specifies that any two implementations must produce equivalent results for all operations resulting in exact numbers.
The R5RS standard specifies procedures codice_35 and codice_36 which can be used to change the exactness of a number. codice_36 produces "the exact number that is numerically closest to the argument." codice_35 produces "the inexact number that is numerically closest to the argument". The R6RS standard omits these procedures from the main report, but specifies them as R5RS compatibility procedures in the standard library (rnrs r5rs (6)).
In the R5RS standard, Scheme implementations are not required to implement the whole numerical tower, but they must implement "a coherent subset consistent with both the purposes of the implementation and the spirit of the Scheme language" (R5RS sec. 6.2.3). The new R6RS standard does require implementation of the whole tower, and "exact integer objects and exact rational number objects of practically unlimited size and precision, and to implement certain procedures...so they always return exact results when given exact arguments" (R6RS sec. 3.4, sec. 11.7.1).
Example 1: exact arithmetic in an implementation that supports exact 
rational complex numbers.
<syntaxhighlight lang="Scheme">
x
===> 509/60+1/3i
===> #t
</syntaxhighlight>
Example 2: Same arithmetic in an implementation that supports neither exact 
rational numbers nor complex numbers but does accept real numbers in rational notation.
<syntaxhighlight lang="Scheme">
xr
===> 8.48333333333333
xi
===> 0.333333333333333
===> #f
===> #f
</syntaxhighlight>
Both implementations conform to the R5RS standard but the second does not conform to R6RS because it does not implement the full numerical tower.
Delayed evaluation.
Scheme supports delayed evaluation through the codice_39 form and the procedure codice_40.
<syntaxhighlight lang="Scheme">(define a 10)
===> 22
===> 70
===> 22
</syntaxhighlight>
The lexical context of the original definition of the promise is preserved, and its value is also preserved after the first use of codice_40. The promise is only ever evaluated once.
These primitives, which produce or handle values known as promises, can be used to implement advanced lazy evaluation constructs such as streams.
In the R6RS standard, these are no longer primitives, but instead are provided as part of the R5RS compatibility library (rnrs r5rs (6)).
In R5RS, a suggested implementation of codice_39 and codice_40 is given, implementing the promise as a procedure with no arguments (a thunk) and using memoization to ensure that it is only ever evaluated once, irrespective of the number of times codice_40 is called (R5RS sec. 6.4).
SRFI 41 enables the expression of both finite and infinite sequences with extraordinary economy. For example, this is a definition of the fibonacci sequence using the functions defined in SRFI 41:
<syntaxhighlight lang="Scheme">
(define fibs
===> 218922995834555169026
</syntaxhighlight>
Order of evaluation of procedure arguments.
Most Lisps specify an order of evaluation for procedure arguments. Scheme does not. Order of evaluation—including the order in which the expression in the operator position is evaluated—may be chosen by an implementation on a call-by-call basis, and the only constraint is that "the effect of any concurrent evaluation of the operator and operand expressions is constrained to be consistent with some sequential order of evaluation." (R5RS sec. 4.1.3)
<syntaxhighlight lang="Scheme">
===> 3
</syntaxhighlight>
ev is a procedure that describes the argument passed to it, then returns the value of the argument. In contrast with other Lisps, the appearance of an expression in the operator position (the first item) of a Scheme expression is quite legal, as long as the result of the expression in the operator position is a procedure.
In calling the procedure "+" to add 1 and 2, the expressions (ev +), (ev 1) and (ev 2) may be evaluated in any order, as long as the effect is not as if they were evaluated in parallel. Thus the following three lines may be displayed in any order by standard Scheme when the above example code is executed, although the text of one line may not be interleaved with another, because that would violate the sequential evaluation constraint.
Hygienic macros.
In the R5RS standard and also in later reports, the syntax of Scheme can easily be extended via the macro system. The R5RS standard introduced a powerful hygienic macro system that allows the programmer to add new syntactic constructs to the language using a simple pattern matching sublanguage (R5RS sec 4.3). Prior to this, the hygienic macro system had been relegated to an appendix of the R4RS standard, as a "high level" system alongside a "low level" macro system, both of which were treated as extensions to Scheme rather than an essential part of the language.
Implementations of the hygienic macro system, also called codice_45, are required to respect the lexical scoping of the rest of the language. This is assured by special naming and scoping rules for macro expansion, and avoids common programming errors that can occur in the macro systems of other programming languages. R6RS specifies a more sophisticated transformation system, codice_46, which has been available as a language extension to R5RS Scheme for some time.
<syntaxhighlight lang="Scheme">
(define-syntax when
</syntaxhighlight>
Invocations of macros and procedures bear a close resemblance—both are s-expressions—but they are treated differently. When the compiler encounters an s-expression in the program, it first checks to see if the symbol is defined as a syntactic keyword within the current lexical scope. If so, it then attempts to expand the macro, treating the items in the tail of the s-expression as arguments without compiling code to evaluate them, and this process is repeated recursively until no macro invocations remain. If it is not a syntactic keyword, the compiler compiles code to evaluate the arguments in the tail of the s-expression and then to evaluate the variable represented by the symbol at the head of the s-expression and call it as a procedure with the evaluated tail expressions passed as actual arguments to it.
Most Scheme implementations also provide additional macro systems. Among popular ones are syntactic closures, explicit renaming macros and codice_47, a non-hygienic macro system similar to codice_48 system provided in Common Lisp.
Environments and eval.
Prior to R5RS, Scheme had no standard equivalent of the codice_49 procedure which is ubiquitous in other Lisps, although the first Lambda Paper had described codice_50 as "similar to the LISP function EVAL" and the first Revised Report in 1978 replaced this with codice_51, which took two arguments. The second, third and fourth revised reports omitted any equivalent of codice_49.
The reason for this confusion is that in Scheme with its lexical scoping the result of evaluating an expression depends on where it is evaluated. For instance, it is not clear whether the result of evaluating the following expression should be 5 or 6:
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
If it is evaluated in the outer environment, where codice_53 is defined, the result is the sum of the operands. If it is evaluated in the inner environment, where the symbol "+" has been bound to the value of the procedure "*", the result is the product of the two operands.
R5RS resolves this confusion by specifying three procedures that return environments, and providing a procedure codice_49 that takes an s-expression and an environment and evaluates the expression in the environment provided. (R5RS sec. 6.5) R6RS extends this by providing a procedure called codice_55 by which the programmer can specify exactly which objects to import into the evaluation environment.
Treatment of non-boolean values in boolean expressions.
In most dialects of Lisp including Common Lisp, by convention the value codice_56 evaluates to the value false in a boolean expression. In Scheme, since the IEEE standard in 1991, all values except #f, including codice_56's equivalent in Scheme which is written as '(), evaluate to the value true in a boolean expression. (R5RS sec. 6.3.1)
Where the constant representing the boolean value of true is codice_58 in most Lisps, in Scheme it is codice_59.
Disjointness of primitive datatypes.
In Scheme the primitive datatypes are disjoint. Only one of the following predicates can be true of any Scheme object: codice_60, codice_61, codice_62, codice_63, codice_64, codice_65, codice_66, codice_67, codice_68. (R5RS sec 3.2)
Within the numerical datatype, by contrast, the numerical values overlap. For example, an integer value satisfies all of the codice_69, codice_70, codice_71, codice_72 and codice_63 predicates at the same time. (R5RS sec 6.2)
Equivalence predicates.
Scheme has three different types of equivalence between arbitrary objects denoted by three different "equivalence predicates", relational operators for testing equality, codice_74, codice_75 and codice_76:
Type dependent equivalence operations also exist in Scheme: codice_84 and codice_85 compare two strings (the latter performs a case-independent comparison); codice_86 and codice_87 compare characters; codice_88 compares numbers.
Comments.
Up to the R5RS standard, the standard comment in Scheme was a semicolon, which makes the rest of the line invisible to Scheme. Numerous implementations have supported alternative conventions permitting comments to extend for more than a single line, and the R6RS standard permits two of them: an entire s-expression may be turned into a comment (or "commented out") by preceding it with codice_89 (introduced in SRFI 62) and a multiline comment or "block comment" may be produced by surrounding text with codice_90 and codice_91.
Input/output.
Scheme's input and output is based on the "port" datatype. (R5RS sec 6.6) R5RS defines two default ports, accessible with the procedures codice_92 and codice_93, which correspond to the Unix notions of standard input and standard output. Most implementations also provide codice_94. Redirection of input and standard output is supported in the standard, by standard procedures such as codice_95 and codice_96. Most implementations provide string ports with similar redirection capabilities, enabling many normal input-output operations to be performed on string buffers instead of files, using procedures described in SRFI 6. The R6RS standard specifies much more sophisticated and capable port procedures and many new types of port.
The following examples are written in strict R5RS Scheme.
Example 1: With output defaulting to (current-output-port):
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
Example 2: As 1, but using optional port argument to output procedures
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
Example 3: As 1, but output is redirected to a newly created file
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
Example 4: As 2, but with explicit file open and port close to send output to file
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
Example 5: As 2, but with using call-with-output-file to send output to a file.
<syntaxhighlight lang="Scheme">
</syntaxhighlight>
Similar procedures are provided for input. R5RS Scheme provides the predicates codice_97 and codice_98. For character input and output, codice_99, codice_100, codice_101 and codice_102 are provided. For writing and reading Scheme expressions, Scheme provides codice_103 and codice_104. On a read operation, the result returned is the end-of-file object if the input port has reached the end of the file, and this can be tested using the predicate codice_105.
In addition to the standard, SRFI 28 defines a basic formatting procedure resembling Common Lisp's codice_106 function, after which it is named.
Redefinition of standard procedures.
In Scheme, procedures are bound to variables. At R5RS the language standard formally mandated that programs may change the variable bindings of built-in procedures, effectively redefining them. (R5RS "Language changes") For example, one may extend codice_107 to accept strings as well as numbers by redefining it:
<syntaxhighlight lang="Scheme">
(set! +
===> 6
===> "123"
</syntaxhighlight>
In R6RS every binding, including the standard ones, belongs to some library, and all exported bindings are immutable. (R6RS sec 7.1) Because of this, redefinition of standard procedures by mutation is forbidden. Instead, it is possible to import a different procedure under the name of a standard one, which in effect is similar to redefinition.
Nomenclature and naming conventions.
In Standard Scheme, procedures that convert from one datatype to another contain the character string "->" in their name, predicates end with a "?", and procedures that change the value of already-allocated data end with a "!". These conventions are often followed by Scheme programmers.
In formal contexts such as Scheme standards, the word "procedure" is used in preference to "function" to refer to a lambda expression or primitive procedure. In normal usage the words "procedure" and "function" are used interchangeably. Procedure application is sometimes referred to formally as "combination".
As in other Lisps, the term "thunk" is used in Scheme to refer to a procedure with no arguments. The term "proper tail recursion" refers to the property of all Scheme implementations, that they perform tail-call optimization so as to support an indefinite number of active tail calls.
The form of the titles of the standards documents since R3RS, "Revisedn Report on the Algorithmic Language Scheme", is a reference to the title of the ALGOL 60 standard document, "Revised Report on the Algorithmic Language Algol 60," The Summary page of R3RS is closely modeled on the Summary page of the ALGOL 60 Report.
Review of standard forms and procedures.
The language is formally defined in the standards R5RS (1998) and R6RS (2007). They describe standard "forms": keywords and accompanying syntax, which provide the control structure of the language, and standard procedures which perform common tasks.
Standard forms.
This table describes the standard forms in Scheme. Some forms appear in more than one row because they cannot easily be classified into a single function in the language.
Forms marked "L" in this table are classed as derived "library" forms in the standard and are often implemented as macros using more fundamental forms in practice, making the task of implementation much easier than in other languages.
Note that codice_108 is defined as a library syntax in R5RS, but the expander needs to know about it to achieve the splicing functionality. In R6RS it is no longer a library syntax.
Standard procedures.
The following two tables describe the standard procedures in R5RS Scheme. R6RS is far more extensive and a summary of this type would not be practical.
Some procedures appear in more than one row because they cannot easily be classified into a single function in the language.
String and character procedures that contain "-ci" in their names perform case-independent comparisons between their arguments: upper case and lower case versions of the same character are taken to be equal.
Implementations of - and / that take more than two arguments are defined but left optional at R5RS.
Scheme Requests for Implementation.
Because of Scheme's minimalism, many common procedures and syntactic forms are not defined by the standard. In order to keep the core language small but facilitate standardization of extensions, the Scheme community has a "Scheme Request for Implementation" (SRFI) process by which extension libraries are defined through careful discussion of extension proposals. This promotes code portability. Many of the SRFIs are supported by all or most Scheme implementations.
SRFIs with fairly wide support in different implementations include:
A full list of accepted (finalized) SRFIs is available at http://srfi.schemers.org/final-srfis.html
Implementations.
The elegant, minimalist design has made Scheme a popular target for language designers, hobbyists, and educators, and because of its small size, that of a typical interpreter, it is also a popular choice for embedded systems and scripting. This has resulted in scores of implementations, most of which differ from each other so much that porting programs from one implementation to another is quite difficult, and the small size of the standard language means that writing a useful program of any great complexity in standard, portable Scheme is almost impossible. The R6RS standard specifies a much broader language, in an attempt to broaden its appeal to programmers.
Almost all implementations provide a traditional Lisp-style read–eval–print loop for development and debugging. Many also compile Scheme programs to executable binary. Support for embedding Scheme code in programs written in other languages is also common, as the relative simplicity of Scheme implementations makes it a popular choice for adding scripting capabilities to larger systems developed in languages such as C. Gambit, Chicken, and Bigloo work by compiling Scheme to C, which makes embedding particularly easy. In addition, Bigloo's compiler can be configured to generate JVM bytecode, and it also features an experimental bytecode generator for .NET.
Some implementations support additional features. For example, Kawa and JScheme provide integration with Java classes, and the Scheme to C compilers often make it easy to use external libraries written in C, up to allowing the embedding of actual C code in the Scheme source. Another example is Pvts, which offers a set of visual tools for supporting the learning of Scheme.
Usage.
Scheme is widely used by a number of schools; in particular, a number of introductory Computer Science courses use Scheme in conjunction with the textbook "Structure and Interpretation of Computer Programs" (SICP). For the past 12 years, PLT has run the ProgramByDesign (formerly TeachScheme!) project, which has exposed close to 600 high school teachers and thousands of high school students to rudimentary Scheme programming. MIT's old introductory programming class 6.001 was taught in Scheme, Although 6.001 has been replaced by more modern courses, SICP continues to be taught at MIT.
The textbook "How to Design Programs" by Matthias Felleisen, currently at Northeastern University, is used by some institutes of higher education for their introductory computer science courses. Both Northeastern University and Worcester Polytechnic Institute use Scheme exclusively for their introductory courses Fundamentals of Computer Science (CS2500) and Introduction to Program Design (CS1101), respectively. Rose-Hulman uses Scheme in its more advanced Programming Language Concepts course. Indiana University's introductory class, C211, is taught entirely in Scheme. The introductory class at UC Berkeley, CS 61A, was until recently taught entirely in Scheme, save minor diversions into Logo to demonstrate dynamic scope; all course materials, including lecture webcasts, are available online free of charge. The introductory computer science courses at Yale and Grinnell College are also taught in Scheme. Programming Design Paradigms, a mandatory course for the Computer science Graduate Students at Northeastern University, also extensively uses Scheme.
The introductory Computer Science course at the University of Minnesota - Twin Cities, CSCI 1901, also uses Scheme as its primary language, followed by a course that introduces students to the Java programming language. In the software industry, Tata Consultancy Services, Asia's largest software consultancy firm, uses Scheme in their month-long training program for fresh college graduates.
Scheme is/was also used for the following:

</doc>
<doc id="28122" url="https://en.wikipedia.org/wiki?curid=28122" title="Society for Psychical Research">
Society for Psychical Research

The Society for Psychical Research (SPR) is a non-profit organisation in the United Kingdom. Its stated purpose is to understand events and abilities commonly described as psychic or paranormal. It claims to be the "first society to conduct organised scholarly research into human experiences that challenge contemporary scientific models." It does not however, since its inception in 1882, hold any corporate opinions: SPR members have a variety of beliefs or lack thereof about the reality and nature of the phenomena studied.
History.
Origins.
The Society for Psychical Research (SPR) originated from a discussion between journalist Edmund Rogers and the physicist William F. Barrett in autumn 1881. This lead to a conference on the 5 and 6 January, 1882 at the headquarters of the British National Association of Spiritualists which the foundation of the Society was proposed. The committee included Barrett, Rogers, Stainton Moses, Charles Massey, Edmund Gurney, Hensleigh Wedgwood and Frederic W. H. Myers. The SPR was formally constituted on the 20 February, 1882 with philosopher Henry Sidgwick as its first president. 
The SPR was the first organisation of its kind in the world, its stated purpose being "to approach these varied problems without prejudice or prepossession of any kind, and in the same spirit of exact and unimpassioned enquiry which has enabled science to solve so many problems, once not less obscure nor less hotly debated."
Other early members included the chemist William Crookes, physicist Oliver Lodge, Nobel laureate Charles Richet and psychologist William James. 
Areas of study included thought-transference, mediumship, Reichenbach phenomena, apparitions and haunted houses and the physical phenomena associated with séances. 
Research.
Much of the early work involved investigating, exposing and in some cases duplicating fake phenomena. In the late 19th century, SPR investigations into séance phenomena led to the exposure of many fraudulent mediums.
Richard Hodgson distinguished himself in that area. In 1884, Hodgson was sent by the SPR to India to investigate Helena Blavatsky and concluded that her claims of psychic power were fraudulent. Among the phenomena that Hodgson investigated was the alleged miraculous Mahatma letters which were said to magically appear over a four-year period in a cabinet in the Shrine Room at the Theosophical headquarters in Madres. Hodgson in his report wrote that the letters were frauds and had been written by Blavatsky herself who had put them in the cabinet from an opening in her bedroom located behind the Shrine room. Hodgson's report was later examined by Vernon Harrison who outlined flaws in his work. Harrison concluded that the letters were forgeries but were not written by Blavatsky but by ex-employees for revenge.
Among the first important works was the two-volume publication in 1886, "Phantasms of the Living" co-authored by Gurney, Myers and Frank Podmore. 
In 1886 and 1887 a series of publications by S. J. Davey, Hodgson and Sidgwick in the SPR journal exposed the slate writing tricks of the medium William Eglinton. Hodgson with his friend, S. J. Davey had staged fake séances for educating the public (including SPR members). Davey gave sittings under an assumed name, duplicating the phenomena produced by Eglinton, and then proceeded to point out to the sitters the manner in which they had been deceived. Because of this, some spiritualist members such as Stainton Moses resigned from the SPR. 
In 1891, Alfred Russel Wallace requested for the Society to properly investigate spirit photography. Eleanor Sidgwick responded with a critical paper in the SPR which cast doubt on the subject and revealed the fraudulent methods that spirit photographers such as Édouard Isidore Buguet, Frederic Hudson and William H. Mumler had utilized.
In 1894, the "Census of Hallucinations" was published which sampled 17, 000 people. Out of these, 1 ,684 persons admitted to having experienced a hallucination of an apparition. 
The SPR investigated many spiritualist mediums such as Eva Carrière and Eusapia Palladino. Due to the exposure of William Hope and other fraudulent mediums, Arthur Conan Doyle led a mass resignation of eighty-four members of the Society for Psychical Research, as they believed the Society was opposed to spiritualism. Science historian William Hodson Brock has noted that "By the 1900s most avowed spiritualists had left the SPR and gone back to the BNAS (the London Spiritualist Alliance since 1884), having become upset by the sceptical tone of most of the SPR's investigations." 
During the early twentieth century, the SPR studied a series of automatic scripts and trance utterances from a group of automatic writers, known as the cross-correspondences. The SPR were to introduce a number of neologisms which have entered the English language, such as 'telepathy', which was coined by Frederic Myers.
The Society is run by a President and a Council of twenty members, and is open to interested members of the public to join. The organisation is based at 49 Marloes Road, Kensington, London, with a library and office open to members, and with large book and archival holdings in Cambridge University Library, Cambridgeshire, England. It publishes the peer reviewed quarterly "Journal of the Society for Psychical Research" ("JSPR"), the irregular "Proceedings" and the magazine "Paranormal Review". It holds an annual conference, regular lectures and two study days per year and supports the "LEXSCIEN" on-line library project.
Famous cases investigated by the Society include Borley Rectory and the Enfield Poltergeist.
Criticism from sceptics.
Sceptics have criticized the SPR for essentially having a secret religious motive. After the publication of Charles Darwin's "On the Origin of Species" (1859), it was difficult for those with a scientific education to retain a belief in tenants of the Judeo-Christian religion. Early SPR members like Henry Sidgwick and Frederic W. H. Myers hoped to cling to something spiritual through psychical research. 
The sceptic and physicist Victor J. Stenger has written:
Ivor Lloyd Tuckett an author of an early sceptical work on psychical research wrote that even though the SPR have collected some valuable work, most of its active members have "no training in psychology fitting them for their task, and have been the victims of pronounced bias, as sometimes they themselves have admitted." Trevor H. Hall an ex-member of the Society for Psychical Research criticized SPR members as "credulous and obsessive wish... to believe." Hall also claimed SPR members "lack knowledge of deceptive methods."
Rationalist writer Edward Clodd claimed that the SPR members William F. Barrett and Oliver Lodge were incompetent researchers to detect fraud and suggested that their spiritualist beliefs were based on magical thinking and primitive superstition. Clodd analyzed the SPR and saw nothing more than "barbaric spiritual philosophy", he mocked the language of SPR members "subliminal consciousness" and "telepathic energy" as a disguise for "bastard supernaturalism." 
Some sceptical members have resigned from the SPR. Eric Dingwall resigned and wrote "After sixty years' experience and personal acquaintance with most of the leading parapsychologists of that period I do not think I could name half a dozen whom I could call objective students who honestly wished to discover the truth."
Psychological study.
A psychological study involving 174 members of the Society for Psychical Research completed a delusional ideation questionnaire and a deductive reasoning task. As predicted, the study showed that "individuals who reported a strong belief in the paranormal made more errors and displayed more delusional ideation than sceptical individuals". There was also a reasoning bias which was limited to people who reported a belief in, rather than experience of, paranormal phenomena. The results suggested that reasoning abnormalities may have a causal role in the formation of paranormal belief.
Presidents.
The following is a list of presidents:
Other societies.
A number of other psychical research organisations use the term 'Society for Psychical Research' in their name.
Further reading.
SPR histories
Scholarly studies
Sceptical

</doc>
<doc id="28123" url="https://en.wikipedia.org/wiki?curid=28123" title="Sniper">
Sniper

A sniper is a marksman or qualified specialist who operates alone, in a pair, or with a sniper team to maintain close visual contact with the enemy and engage targets from concealed positions or distances exceeding the detection capabilities of enemy personnel. Snipers typically have highly selective or specialized training and use crew-served high-precision/special application rifles and optics, and often have sophisticated communication assets to feed valuable combat information back to their units or military bases.
Most sniper teams operate independently, with little combat asset support from their parent units; their job is to deliver discriminatory, highly accurate rifle fire against enemy targets that cannot be engaged successfully by the regular rifleman because of range, size, location, fleeting nature, or visibility. Sniping requires the development of basic infantry skills to a high degree of skill. A sniper's training incorporates a wide variety of subjects designed to increase value as a force multiplier and to ensure battlefield survival. The art of sniping requires learning and repetitively practicing these skills until mastered. A sniper must be highly trained in long range rifle marksmanship and field craft skills to ensure maximum effective engagements with minimum risk.
In addition to marksmanship and long range shooting, military snipers are trained in a variety of techniques: detection, stalking, and target range estimation methods, camouflage, field craft, infiltration, special reconnaissance and observation, surveillance and target acquisition.
Etymology.
The verb "to snipe" originated in the 1770s among soldiers in British India in reference to shooting snipe, which was considered a challenging target for marksmen.
The agent noun "sniper" appears by the 1820s. The term "sniper" was first attested in 1824 in the sense of the word "sharpshooter".
A somewhat older term is "sharp shooter", a calque of 18th-century German "Scharfschütze", in use in British newspapers as early as 1801.
Modern warfare.
Economic effectiveness.
According to figures released by the United States Department of Defense, the average number of rounds expended in Vietnam to kill one enemy soldier with the M-16 was 50,000. The average number of rounds expended by U.S. military snipers to kill one enemy soldier was 1.3 rounds, which equates to a cost of $23,000 per kill for the average soldier, vs. $0.17 per kill for the military sniper. According to the United States Army, the average soldier will hit a man-sized target 10 percent of the time at 300 meters using the M16A2 rifle. Graduates of the U.S. Army sniper school are expected to achieve 90 percent first-round hits at 600 meters, using the M24 Sniper Weapon System (SWS).
Military doctrine.
Different countries use different military doctrines regarding snipers in military units, settings, and tactics.
Generally, a sniper's primary function in modern warfare is to provide detailed reconnaissance from a concealed position and, if necessary, to reduce the enemy's fighting ability by neutralizing high-value targets (especially officers and other key personnel) and in the process pinning down and demoralizing the enemy. Typical sniper missions include managing intelligence information they gather during reconnaissance and surveillance, target acquisition for air-strikes and artillery, assist employed combat force with fire support and counter-sniper tactics, killing enemy commanders, selecting targets of opportunity, and even destruction of military equipment, which tend to require use of anti-materiel rifles in the larger calibers such as the .50 BMG, like the Barrett M82, McMillan Tac-50, and Denel NTW-20.
Soviet and Russian derived military doctrines include squad-level snipers. Snipers have increasingly been demonstrated as useful by US and UK forces in the recent Iraq campaign in a fire support role to cover the movement of infantry, especially in urban areas.
Military snipers from the US, UK, and other countries that adopt their military doctrine are typically deployed in two-man sniper teams consisting of a shooter and spotter. A common practice is for a shooter and a spotter to take turns in order to avoid eye fatigue. In most recent combat operations occurring in large densely populated towns, such as Fallujah, Iraq, two teams would be deployed together to increase their security and effectiveness in an urban environment. A sniper team would be armed with their long range weapon, and a shorter ranged weapon to engage and protect the team should enemies come in close contact. German doctrine of largely independent snipers and emphasis on concealment developed during the Second World War have been most influential on modern sniper tactics, currently used throughout Western militaries (examples are specialized camouflage clothing, concealment in terrain and emphasis on coup d'œil).
Sniper teams.
Sniper rifles are classified as crew-served, as the term is used in the United States military. A sniper team (or sniper cell) consists of a combination of one or more "shooters" with force protection elements and support personnel: such as a "spotter" or a "flanker". Within the Table of Organization and Equipment for both the United States Army and the U.S. Marine Corps, the operator of the weapon has an assistant trained to fulfill multiple roles, in addition to being sniper qualified in the operation of the weapon.
The shooter(s) fires the shot while the spotter(s) assists in observation of targets, atmospheric conditions and handles ancillary tasks as immediate security of their location, communication with other parties; including directing artillery fire and close air support. The flanker(s)' task is to have observed areas not immediately visible to the sniper or spotter and assist with the team's perimeter and rear security, therefore they are usually armed with an assault rifle or battle rifle. Both spotter and flanker carries additional ammunition and associated equipment.
The spotter detects, observes, and assigns targets and watches for the results of the shot. Using their spotting scope and/or rangefinder, they will also read the wind by using physical indicators and the mirage caused by the heat on the ground. Also, in conjunction with the shooter, they will accurately make calculations for distance, angle shooting (slant range), mil dot related calculations, correction for atmospheric conditions and leads for moving targets. It is not unusual for the spotter to be equipped with a notepad and a laptop computer specifically for performing these calculations.
Law enforcement applications.
Law enforcement snipers, commonly called police snipers, and military snipers differ in many ways, including their areas of operation and tactics. A police sharpshooter is part of a police operation and usually takes part in relatively short missions. Police forces typically deploy such sharpshooters in hostage scenarios. This differs from a military sniper, who operates as part of a larger army, engaged in warfare. Sometimes as part of a SWAT team, police snipers are deployed alongside negotiators and an assault team trained for close quarters combat. As policemen, they are trained to shoot only as a last resort, when there is a direct threat to life; the police sharpshooter has a well-known rule: "Be prepared to take a life to save a life." Police snipers typically operate at much shorter ranges than military snipers, generally under and sometimes even less than . Both types of snipers do make difficult shots under pressure, and often perform one-shot kills.
Police units that are unequipped for tactical operations may rely on a specialized SWAT team, which may have a dedicated sniper. Some police sniper operations begin with military assistance. Police snipers placed in vantage points, such as high buildings, can provide security for events. In one high-profile incident, Mike Plumb, a SWAT sniper in Columbus, Ohio, prevented a suicide by shooting a revolver out of the individual's hand, leaving him unharmed.
The need for specialized training for police sharpshooters was made apparent in 1972 during the Munich massacre when the German police could not deploy specialized personnel or equipment during the standoff at the airport in the closing phase of the crisis, and consequently all of the Israeli hostages were killed. The German police only had regular police who were selected if they engaged in hunting as a hobby. While the German army did have snipers in 1972, the use of army snipers in the scenario was impossible due to the German constitution's explicit prohibition of the use of the military in domestic matters. This lack of trained snipers who could be used in civilian roles was later addressed with the founding of the specialized police counter-terrorist unit GSG 9.
Longest recorded sniper kills.
The longest confirmed sniper kill in combat was achieved by Craig Harrison, a Corporal of Horse (CoH) in the Blues and Royals RHG/D of the British Army. In November 2009, Harrison struck two Taliban machine gunners consecutively south of Musa Qala in Helmand Province in Afghanistan at a range of or 1.54 miles using a L115A3 Long Range Rifle.
The QTU Lapua external ballistics software, using continuous doppler drag coefficient (Cd) data provided by Lapua, predicts that such shots traveling would likely have struck their targets after nearly 6.0 seconds of flight time, having lost 93% of their kinetic energy, retaining of their original velocity, and having dropped or 2.8° from the original bore line. Due to the extreme distances and travel time involved, even a light cross-breeze of would have diverted such shots off target, which would have required compensation. The calculation assumes a "flat-fire scenario" (a situation where the shooting and target positions are at equal elevation), utilizing British military custom high pressure .338 Lapua Magnum cartridges, loaded with 16.2 g (250 gr) Lapua LockBase B408 bullets, fired at 936 m/s (3,071 ft/s) muzzle velocity under the following on-site (average) atmospheric conditions: barometric pressure: at sea-level equivalent or on-site, humidity: 25.9%, and temperature: in the region for November 2009, resulting in an air density ρ = 1.0854 kg/m3 at the elevation of Musa Qala.
Harrison mentions in reports that the environmental conditions were perfect for long range shooting, "... no wind, mild weather, clear visibility." In a BBC interview, Harrison reported it took about nine shots for him and his spotter to initially range the target successfully.
Military history.
Before the development of rifling, firearms were smoothbore and inaccurate over long distance. Barrel rifling was invented at the end of the fifteenth century, but was only employed in large cannons. Over time, rifling, along with other gunnery advances, has increased the performance of modern firearms.
Early history.
Early forms of sniping, or marksmanship were used during the American Revolutionary War. For instance, in 1777 at the battle of Saratoga the Colonists hid in the trees and used early model rifles to shoot British officers. Most notably, Timothy Murphy shot and killed General Simon Fraser of Balnain on 7 October 1777 at a distance of about 400 yards. During the Battle of Brandywine, Capt. Patrick Ferguson had a tall, distinguished American officer in his rifle's iron sights. Ferguson did not take the shot, as the officer had his back to Ferguson; only later did Ferguson learn that George Washington had been on the battlefield that day.
A special unit of marksmen was established during the Napoleonic Wars in the British Army. While most troops at that time used inaccurate smoothbore muskets, the British "Green Jackets" (named for their distinctive green uniforms) used the famous Baker rifle. Through the combination of a leather wad and tight grooves on the inside of the barrel (rifling), this weapon was far more accurate, though slower to load. These Riflemen were the elite of the British Army, and served at the forefront of any engagement, most often in skirmish formation, scouting out and delaying the enemy. Another term, "sharp shooter" was in use in British newspapers as early as 1801. In the "Edinburgh Advertiser", 23 June 1801, can be found the following quote in a piece about the North British Militia; "This Regiment has several Field Pieces, and two companies of Sharp Shooters, which are very necessary in the modern Stile of War". The term appears even earlier, around 1781, in Continental Europe, translated from the German Scharfschütze.
First sniper rifle.
The Whitworth rifle was arguably the first long-range sniper rifle in the world. Designed by Sir Joseph Whitworth, a prominent British engineer, it used polygonal rifling instead, which meant that the projectile did not have to bite into grooves as was done with conventional rifling. His rifle was far more accurate than the Pattern 1853 Enfield, which had shown some weaknesses during the recent Crimean War. At trials in 1857 which tested the accuracy and range of both weapons, Whitworth's design outperformed the Enfield at a rate of about three to one. The Whitworth rifle was capable of hitting the target at a range of 2,000 yards, whereas the Enfield could only manage it at 1,400 yards.
During the Crimean War, the first optical sights were designed to fit onto rifles. Much of this pioneering work was the brainchild of Colonel D. Davidson, using optical sights produced by Chance Brothers of Birmingham. This allowed a marksman to observe and target objects more accurately at a greater distance than ever before. The telescopic sight, or scope, was originally fixed and could not be adjusted, which therefore limited its range.
Despite its success at the trials, the rifle was not adopted by the British Army. However, the Whitworth Rifle Company was able to sell the weapon to the French army, and also to the Confederacy during the American Civil War. 
Both the Union and Confederate armies employed sharpshooters. The most notable incident was during the Battle of Spotsylvania Court House, where on 9 May 1864, Union General John Sedgwick was killed at a range of about after saying the enemy "couldn't hit an elephant at this distance."
Second Boer War.
During the Boer War the latest breech-loading rifled guns with magazines and smokeless powder were used by both sides. The British were equipped with the Lee–Metford rifle, while the Boers had received the latest Mauser rifles from Germany. In the open terrain of South Africa the marksmen were a crucial component to the outcome of the battle.
The first British sniper unit began life as the Lovat Scouts, a Scottish Highland regiment formed in 1899, that earned high praise during the Second Boer War (1899–1902). The unit was formed by Lord Lovat and reported to an American, Major Frederick Russell Burnham, the British Army Chief of Scouts under Lord Roberts. Burnham fittingly described these scouts as "half wolf and half jackrabbit.". Just like their Boer scout opponents, these scouts were well practised in the arts of marksmanship, field craft, map reading, observation, and military tactics. They were skilled woodsmen and practitioners of discretion: "He who shoots and runs away, lives to shoot another day." They were also the first known military unit to wear a ghillie suit. 
Hesketh Hesketh-Prichard said of them that "keener men never lived", and that "Burnham was the greatest scout of our time." Burnham distinguished himself in wars in South Africa, Rhodesia, and in Arizona fighting the Apaches, and his definitive work, "Scouting on Two Continents," provides a dramatic and enlightening picture of what a sniper was at the time and how he operated.
After the war, this regiment went on to formally become the first official sniper unit, then better known as "sharpshooters".
World War I.
During World War I, snipers appeared as deadly sharpshooters in the trenches. At the start of the war, only Imperial Germany had troops that were issued scoped sniper rifles. Although sharpshooters existed on all sides, the Germans specially equipped some of their soldiers with scoped rifles that could pick off enemy soldiers showing their heads out of their trench. At first the French and British believed such hits to be coincidental hits, until the German scoped rifles were discovered. During World War I, the German army received a reputation for the deadliness and efficiency of its snipers, partly because of the high-quality lenses that German industry could manufacture.
Soon the British army began to train their own snipers in specialized sniper schools. Major Hesketh Hesketh-Prichard was given formal permission to begin sniper training in 1915, and founded the First Army School of Sniping, Observation, and Scouting at Linghem in France in 1916. Starting with a first class of only six, in time he was able to lecture to large numbers of soldiers from different Allied nations, proudly proclaiming in a letter that his school was turning out snipers at three times the rate of any such other school in the world.
He also devised a metal-armoured double loophole that would protect the sniper observer from enemy fire. The front loophole was fixed, but the rear was housed in a metal shutter sliding in grooves. Only when the two loopholes were lined up—a one-to-twenty chance—could an enemy shoot between them. Another innovation was the use of a dummy head to find the location of an enemy sniper. The papier-mâché figures were painted to resemble soldiers to draw sniper fire. Some were equipped with rubber surgical tubing so the dummy could "smoke" a cigarette and thus appear realistic. Holes punched in the dummy by enemy sniper bullets then could be used for triangulation purposes to determine the position of the enemy sniper, who could then be attacked with artillery fire. He developed many of the modern techniques in sniping, including the use of spotting scopes and working in pairs, and using Kim's Game to train observational skills.
In 1920, he wrote his account of his war time activities in his book "", which is still referenced by modern authors on the subject.
The main sniper rifles used during the First World War were the German Mauser Gewehr 98; the British Pattern 1914 Enfield and Lee–Enfield SMLE Mk III, the Canadian Ross Rifle, the American M1903 Springfield, and the Russian M1891 Mosin–Nagant.
World War II.
During the interbellum, most nations dropped their specialized sniper units, notably the Germans. Effectiveness and dangers of snipers once again came to the fore during the Spanish Civil War. The only nation that had specially trained sniper units during the 1930s was the Soviet Union. Soviet snipers were trained in their skills as marksmen, in using the terrain to hide themselves from the enemy and the ability to work alongside regular forces. This made the Soviet sniper training focus more on "normal" combat situations than those of other nations.
Snipers reappeared as important factors on the battlefield from the first campaign of World War II. During Germany's 1940 campaigns, it appeared that lone, well-hidden French and British snipers could halt the German advance for a significant amount of time. For example, during the pursuit to Dunkirk, British snipers were able to significantly delay the German infantry's advance. This prompted the British once again to increase training of specialized sniper units. Apart from marksmanship, British snipers were trained to blend in with the environment, often by using special camouflage clothing for concealment. However, because the British Army offered sniper training exclusively to officers and non-commissioned officers, the resulting small number of trained snipers in the combat units considerably reduced their overall effectiveness.
During the Winter War, Finnish snipers took a heavy toll of the invading Soviet army. Simo Häyhä is credited with 505 confirmed kills, most with the Finnish version of the iron-sighted bolt-action Mosin–Nagant.
One of the best known battles involving snipers, and the battle that made the Germans reinstate their specialized sniper training, was the Battle of Stalingrad. Their defensive position inside a city filled with rubble meant that Soviet snipers were able to inflict significant casualties on the Wehrmacht troops. Because of the nature of fighting in city rubble, snipers were very hard to spot and seriously dented the morale of the German attackers. The best known of these snipers was probably Vasily Zaytsev, featured in the novel "War of the Rats" and the subsequent film "Enemy At The Gates".
German "Scharfschützen" were prepared before the war, equipped with Karabiner 98 and later Gewehr 43 rifles, but there were often not enough of these weapons available, and as such some were armed with captured scoped Mosin–Nagant 1891/30, SVT or Czech Mauser rifles. The Wehrmacht re-established its sniper training in 1942, drastically increasing the number of snipers per unit with the creation of an additional 31 sniper training companies by 1944. German snipers were at the time the only snipers in the world issued with purpose-manufactured sniping ammunition, known as the 'effect-firing' sS round. The 'effect-firing' sS round featured an extra carefully measured propellant charge and seated a heavy 12.8 gram (198 gr) full-metal-jacketed boat-tail projectile of match-grade build quality, lacking usual features such as a seating ring to improve the already high ballistic coefficient of .584 (G1) further. For aiming optics German snipers used the Zeiss Zielvier 4x (ZF39) telescopic sight which had bullet drop compensation in 50 m increments for ranges from 100 m up to 800 m or in some variations from 100 m up to 1000 m or 1200 m. There were ZF42, Zielfernrohr 43 (ZF 4), Zeiss Zielsechs 6x and other telescopic sights by various manufacturers like the Ajack 4x, Hensoldt Dialytan 4x and Kahles Heliavier 4x with similar features employed on German sniper rifles. Several different mountings produced by various manufacturers were used for mounting aiming optics to the rifles. In February 1945 the Zielgerät 1229 active infrared aiming device was issued for night sniping with the StG 44 assault rifle.
A total of 428,335 individuals received Red Army sniper training, including Soviet and non-Soviet partisans, with 9,534 receiving the sniping 'higher qualification'. During World War ІІ, two six-month training courses for women alone trained nearly 55,000 snipers, of which more than two thousand later served in the army. On average there was at least one sniper in an infantry platoon and one in every reconnaissance platoon, including in tank and even artillery units. Some used the PTRD anti-tank rifle with an adapted scope as an early example of an anti-materiel rifle.
In the United States Armed Forces, sniper training was only very elementary and was mainly concerned with being able to hit targets over long distances. Snipers were required to be able to hit a body over 400 meters away, and a head over 200 meters away. There was almost no instruction in blending into the environment. Sniper training varied from place to place, resulting in wide variation in the qualities of snipers. The main reason the US did not extend sniper training beyond long-range shooting was the limited deployment of US soldiers until the Normandy Invasion. During the campaigns in North Africa and Italy, most fighting occurred in arid and mountainous regions where the potential for concealment was limited, in contrast to Western and Central Europe.
The U.S. Army's lack of familiarity with sniping tactics proved disastrous in Normandy and the campaign in Western Europe where they encountered well trained German snipers. In Normandy, German snipers remained hidden in the dense vegetation and were able to encircle American units, firing at them from all sides. The American and British forces were surprised by how near the German snipers could approach in safety and attack them, as well as by their ability to hit targets at up to 1,000m. A notable mistake made by inexperienced American soldiers was to lie down and wait when targeted by German snipers, allowing the snipers to pick them off one after another. German snipers often infiltrated Allied lines and sometimes when the front-lines moved, they continued to fight from their sniping positions, refusing to surrender until their rations and munitions were exhausted.
Those tactics were also a consequence of changes in German enrollment. After several years of war and heavy losses on the Eastern Front, the German army was forced to rely more heavily on enrolling teenage soldiers. Due to lack of training in more complex group tactics, and thanks to rifle training provided by the Hitlerjugend, those soldiers would often be used as autonomous left-behind snipers. While an experienced sniper would take a few lethal shots and retreat to a safer position, those young boys, due both to disregard for their own safety and to lack of tactical experience would frequently remain in a concealed position and fight until they ran out of ammunition or were killed or wounded. While this tactic would generally end in the demise of the sniper, giving rise to the nickname "Suicide Boys" that was given to those soldiers, this irrational behavior would prove quite disruptive to the Allied forces' progression. After World War II, many elements of German sniper training and doctrine were copied by other countries.
In the Pacific War, the Empire of Japan trained snipers. In the jungles of Asia and the Pacific Islands, snipers posed a serious threat to the U.S, British, and Commonwealth troops. Japanese snipers were specially trained to use the environment to conceal themselves. Japanese snipers used foliage on their uniforms and dug well-concealed hide-outs that were often connected with small trenches. There was no need for long range accuracy because most combat in the jungle took place within a few hundred meters. Japanese snipers were known for their patience and ability to remain hidden for long periods. They almost never left their carefully camouflaged hiding spots. This meant that whenever a sniper was in the area, the location of the sniper could be determined after the sniper had fired a few shots. The Allies used their own snipers in the Pacific, notably the U.S. Marines, who used M1903 Springfield rifles.
Common sniper rifles used during the Second World War include: the Soviet M1891/30 Mosin–Nagant and, to a lesser extent, the SVT-40; the German Mauser Karabiner 98k and Gewehr 43; the British Lee–Enfield No. 4 and Pattern 1914 Enfield; the Japanese Arisaka 97; the American M1903A4 Springfield and M1C Garand. The Italians trained few snipers and supplied them with a scoped Carcano Model 1891.
Training.
Military sniper training aims to teach a high degree of proficiency in camouflage and concealment, stalking, observation and map reading as well as precision marksmanship under various operational conditions. Trainees typically shoot thousands of rounds over a number of weeks, while learning these core skills.
Snipers are trained to squeeze the trigger straight back with the ball of their finger, to avoid jerking the gun sideways. The most accurate position is prone, with a sandbag supporting the stock, and the stock's cheek-piece against the cheek. In the field, a bipod can be used instead. Sometimes a sling is wrapped around the weak arm (or both) to reduce stock movement. Some doctrines train a sniper to breathe deeply before shooting, then hold their lungs empty while they line up and take their shot. Some go further, teaching their snipers to shoot between heartbeats to minimize barrel motion.
Accuracy.
The key to sniping is accuracy, which applies to both the weapon and the shooter. The weapon should be able to consistently place shots within tight tolerances. The sniper in turn must utilize the weapon to accurately place shots under varying conditions.
A sniper must have the ability to accurately estimate the various factors that influence a bullet's trajectory and point of impact such as: range to the target, wind direction, wind velocity, altitude and elevation of the sniper and the target and ambient temperature. Mistakes in estimation compound over distance and can decrease lethality or cause a shot to miss completely.
Snipers zero their weapons at a target range or in the field. This is the process of adjusting the scope so that the bullet's points-of-impact is at the point-of-aim (centre of scope or scope's cross-hairs) for a specific distance. A rifle and scope should retain its zero as long as possible under all conditions to reduce the need to re-zero during missions.
A sandbag can serve as a useful platform for shooting a sniper rifle, although any soft surface such as a rucksack will steady a rifle and contribute to consistency. In particular, bipods help when firing from a prone position, and enable the firing position to be sustained for an extended period of time. Many police and military sniper rifles come equipped with an adjustable bipod. Makeshift bipods known as shooting sticks can be constructed from items such as tree branches or ski poles.
Range and accuracy vary depending on the cartridge and specific ammunition types that are used. Typical ranges for common battle field cartridges are as follows:
U.S. military.
Servicemen volunteer for the rigorous sniper training and are accepted on the basis of their aptitude, physical ability, marksmanship, patience and mental stability. Military snipers may be further trained as forward air controllers (FACs) to direct air strikes or forward observers (FOs) to direct artillery or mortar fire.
Russian Army.
From 2011, the Russian armed forces has run newly developed sniper courses in military district training centres. In place of the Soviet practice of mainly squad sharpshooters, which were often designated during initial training (and of whom only few become snipers "per se"), "new" Army snipers are to be trained intensively for 3 months (for conscripts) or longer (for contract soldiers). The training program includes theory and practice of countersniper engagements, artillery spotting and coordination of air support. The first instructors are the graduates of the Solnechnogorsk sniper training centre.
The method of sniper deployment, according to the Ministry of Defence, is likely to be one three-platoon company at the brigade level, with one of the platoons acting independently and the other two supporting the battalions as needed.
Targeting, tactics and techniques.
Range finding.
The range to the target is measured or estimated as precisely as conditions permit and correct range estimation becomes absolutely critical at long ranges, because a bullet travels with a curved trajectory and the sniper must compensate for this by aiming higher at longer distances. If the exact distance is not known the sniper may compensate incorrectly and the bullet path may be too high or low. As an example, for a typical military sniping cartridge such as 7.62×51mm NATO (.308 Winchester) M118 Special Ball round this difference (or “drop”) from is . This means that if the sniper incorrectly estimated the distance as 700 meters when the target was in fact 800 meters away, the bullet will be 200 millimeters lower than expected by the time it reaches the target.
Laser rangefinders may be used, and range estimation is often the job of both parties in a team. One useful method of range finding without a laser rangefinder is comparing the height of the target (or nearby objects) to their size on the mil dot scope, or taking a known distance and using some sort of measure (utility poles, fence posts) to determine the additional distance. The average human head is in width, average human shoulders are apart and the average distance from a person's pelvis to the top of their head is .
To determine the range to a target without a laser rangefinder, the sniper may use the mil dot reticle on a scope to accurately find the range. Mil dots are used like a slide rule to measure the height of a target, and if the height is known, the range can be as well. The height of the target (in yards) ×1000, divided by the height of the target (in mils), gives the range in yards. This is only in general, however, as both scope magnification (7×, 40×) and mil dot spacing change. The USMC standard is that 1 mil (that is, 1 milliradian) equals 3.438 MOA (minute of arc, or, equivalently, minute of angle), while the US Army standard is 3.6 MOA, chosen so as to give a diameter of 1 yard at a distance of 1000 yards (or equivalently, a diameter of 1 meter at a range of 1 kilometer.) Many commercial manufacturers use 3.5, splitting the difference, since it is easier to work with.
"Explanation: 1 MIL = 1 milli-radian. That is, 1 MIL = 1x10^-3 radian. But, 10^-3 rad x (360 deg/ (2 x Pi) radians) = 0.0573 degrees. Now, 1 MOA = 1/60 degree = 0.01667 degrees. Hence, there are 0.0573/0.01667 = 3.43775 MOA per MIL, where MIL is defined as a milli-radian. On the other hand, defining a mil-dot by the US Army way, to equate it to at , means the Army's mil-dot is approximately 3.6 MOA."
It is important to note that angular mil ("mil") is only an approximation of a milliradian and different organizations use different approximations.
At longer ranges, bullet drop plays a significant role in targeting. The effect can be estimated from a chart, which may be memorized or taped to the rifle, although some scopes come with Bullet Drop Compensator (BDC) systems that only require the range be dialed in. These are tuned to both a specific class of rifle and specific ammunition. Every bullet type and load will have different ballistics. .308 Federal 175 grain (11.3 g) BTHP match shoots at . Zeroed at , a 16.2 MOA adjustment would have to be made to hit a target at . If the same bullet was shot with 168 grain (10.9 g), a 17.1 MOA adjustment would be necessary.
Shooting uphill or downhill is confusing for many because gravity does not act perpendicular to the direction the bullet is traveling. Thus, gravity must be divided into its component vectors. Only the fraction of gravity equal to the cosine of the angle of fire with respect to the horizon affects the rate of fall of the bullet, with the remaineder adding or subtracting negligible velocity to the bullet along its trajectory. To find the correct zero, the sniper multiplies the actual distance to the range by this fraction and aims as if the target were that distance away. For example, a sniper who observes a target 500 meters away at a 45-degree angle downhill would multiply the range by the cosine of 45 degrees, which is 0.707. The resulting distance will be 353 meters. This number is equal to the horizontal distance to the target. All other values, such as windage, time-to-target, impact velocity, and energy will be calculated based on the actual range of 500 meters. Recently, a small device known as a cosine indicator has been developed. This device is clamped to the tubular body of the telescopic sight, and gives an indicative readout in numerical form as the rifle is aimed up or down at the target. This is translated into a figure used to compute the horizontal range to the target.
Windage plays a significant role, with the effect increasing with wind speed or the distance of the shot. The slant of visible convections near the ground can be used to estimate crosswinds, and correct the point of aim. All adjustments for range, wind, and elevation can be performed by aiming off the target, called "holding over" or Kentucky windage. Alternatively, the scope can be adjusted so that the point of aim is changed to compensate for these factors, sometimes referred to as "dialing in". The shooter must remember to return the scope to zeroed position. Adjusting the scope allows for more accurate shots, because the cross-hairs can be aligned with the target more accurately, but the sniper must know exactly what differences the changes will have on the point-of-impact at each target range.
For moving targets, the point-of-aim is ahead of the target in the direction of movement. Known as "leading" the target, the amount of "lead" depends on the speed and angle of the target's movement as well as the distance to the target. For this technique, holding over is the preferred method. Anticipating the behavior of the target is necessary to accurately place the shot.
Hide sites and hiding techniques.
The term "hide site" refers to a covered and concealed position from which a sniper and his team can conduct surveillance and/or fire at targets. A good hide conceals and camouflages the sniper effectively, provides cover from enemy fire and allows a wide view of the surrounding area.
The main purpose of ghillie suits and hide sites is to break up the outline of a person with a rifle.
Many snipers use ghillie suits to hide and stay hidden. Ghillie suits vary according to the terrain into which the sniper wishes to blend. For example, in dry, grassy wasteland the sniper will typically wear a ghillie suit covered in dead grass.
Shot placement.
Shot placement varies considerably with the type of sniper being discussed. Military snipers, who generally do not engage targets at less than , usually attempt body shots, aiming at the chest. These shots depend on tissue damage, organ trauma, and blood loss to make the kill.
Police snipers, who generally engage at much shorter distances, may attempt more precise shot at particular parts of body or particular devices: in one event in 2007 in Marseille, a GIPN sniper took a shot from at the pistol of a police officer threatening to commit suicide, destroying the weapon and preventing the police officer from killing himself.
In a high-risk or instant-death hostage situation, police snipers may take head shots to ensure an instant kill. The snipers aim for the "apricot", or the medulla oblongata, located inside the head, a part of the brain that controls involuntary movement that lies at the base of the skull. Some ballistics and neurological researchers have argued that severing the spinal cord at an area near the second cervical vertebra is actually achieved, usually having the same effect of preventing voluntary motor activity, but the debate on the matter remains largely academic at present.
Target acquisition.
Snipers are trained for the detection, identification, and location of a target in sufficient detail to permit the effective employment of lethal and non-lethal means. Since most kills in modern warfare are by crew-served weapons, reconnaissance is one of the most effective uses of snipers. They use their aerobic conditioning, infiltration skills and excellent long-distance observation equipment and tactics to approach and observe the enemy. In this role, their rules of engagement let them engage only high-value targets of opportunity.
The personnel or materiel, but most often they target the most important enemy personnel such as officers or specialists (e.g. communications operators) so as to cause maximum disruption to enemy operations. Other personnel they might target include those who pose an immediate threat to the sniper, like dog handlers, who are often employed in a search for snipers. A sniper identifies officers by their appearance and behavior such as symbols of rank, talking to radio operators, sitting as a passenger in a car, having military servants, binoculars/map cases or talking and moving position more frequently. If possible, snipers shoot in descending order by rank, or if rank is unavailable, they shoot to disrupt communications.
Some rifles, such as the Denel NTW-20 and Vidhwansak, are designed for a purely anti-materiel (AM) role, e.g. shooting turbine disks of parked aircraft, missile guidance packages, expensive optics, and the bearings, tubes or wave guides of radar sets. A sniper equipped with the correct rifle can target radar dishes, water containers, the engines of vehicles, and any number of other targets. Other rifles, such as the .50 caliber rifles produced by Barrett and McMillan, are not designed exclusively as AM rifles, but are often employed in such a way, providing the range and power needed for AM applications in a lightweight package compared to most traditional AM rifles. Other calibers, such as the .408 Cheyenne Tactical and the .338 Lapua Magnum, are designed to be capable of limited AM application, but are ideally suited as long range anti-personnel rounds.
Baiting.
Baiting is the utilization of dropped objects for potential targets to find and pick up. In the Iraq war, picking up weapons and munitions could be considered evidence of insurgency. Snipers would drop weapons and wait for targets to pick up the weapons so they could engage the target. According to court documents quoted by the Washington Post, the U.S. military's Asymmetric Warfare Group encouraged snipers to drop items "such as detonation cords, plastic explosives and ammunition" then kill Iraqis who handled the items.
Relocating.
Often in situations with multiple targets, snipers use relocation. After firing a few shots from a certain position, snipers move unseen to another location before the enemy can determine where he or she is and mount a counter-attack. Snipers will frequently use this tactic to their advantage, creating an atmosphere of chaos and confusion. In other, rarer situations, relocation is used to eliminate the factor of wind.
Sound masking.
As sniper rifles are often extremely powerful and consequently loud, it is common for snipers to use a technique known as sound masking. When employed by a highly skilled marksman, this tactic can be used as a substitute for a noise suppressor. Very loud sounds in the environment, such as artillery shells air bursting or claps of thunder, can often mask the sound of the shot. This technique is frequently used in clandestine operations, infiltration tactics, and guerrilla warfare.
Psychological warfare.
Due to the surprise nature of sniper fire, high lethality of aimed shots and frustration at the inability to locate and attack snipers, sniper tactics have a significant effect on morale. Extensive use of sniper tactics can be used to induce constant stress in opposing forces. In many ways, the psychological impact imposed by snipers is quite similar to those of landmines, booby-traps, and IEDs (constant threat, high "per event" lethality, inability to strike back).
Historically, captured snipers are often summarily executed. This happened during World War I, and World War II, for example the second Biscari Massacre when 36 suspected snipers were lined up and shot on 14 July 1943.
As a result, if a sniper is in imminent danger of capture, he may discard any items which might indicate his status as a sniper. The risk of captured snipers being summarily executed is explicitly referred to in Chapter 6 of US Army doctrine document FM 3-060.11 entitled "SNIPER AND COUNTERSNIPER TACTICS, TECHNIQUES, AND PROCEDURES":
The negative reputation of snipers can be traced back to the American Revolution, when American "Marksmen" would intentionally target British officers, an act considered uncivilized by the British Army at the time (this reputation would be cemented during the Battle of Saratoga, when Benedict Arnold allegedly ordered his marksmen to target British General Simon Fraser, an act that would win the battle and French support). The British side used specially selected sharpshooters as well, often German mercenaries.
To demoralize enemy troops, snipers can follow predictable patterns. During the 26th of July Movement in the Cuban Revolution, the revolutionaries led by Fidel Castro always killed the foremost man in a group of President Batista's soldiers. Realizing this, none of Batista's men would walk first, as it was suicidal. This effectively decreased the army's willingness to search for rebel bases in the mountains. An alternative approach to this psychological process is to kill the second man in the row, leading to the psychological effect of nobody wanting to follow the "leader".
Counter-sniper tactics.
The occurrence of sniper warfare has led to the evolution of many counter-sniper tactics in modern military strategies. These aim to reduce the damage caused by a sniper to an army, which can often be harmful to both combat capabilities and morale.
The risk of damage to a chain of command can be reduced by removing or concealing features that would otherwise indicate an officer's rank. Modern armies tend to avoid saluting officers in the field, and eliminate rank insignia on battle dress uniforms (BDU). Officers can seek maximum cover before revealing themselves as good candidates for elimination through actions such as reading maps or using radios.
Friendly snipers can be used to hunt the enemy sniper. Besides direct observation, defending forces can use other techniques. These include calculating the trajectory of a bullet by triangulation. Traditionally, triangulation of a sniper's position was done manually, though radar-based technology has recently become available. Once located, the defenders can attempt to approach the sniper from cover and overwhelm him. The United States military is funding a project known as RedOwl (Robot Enhanced Detection Outpost With Lasers), which uses laser and acoustic sensors to determine the exact direction from which a sniper round has been fired.
The more rounds fired by a sniper, the greater the chance the target has of locating him. Thus, attempts to draw fire are often made, sometimes by offering a helmet slightly out of concealment, a tactic successfully employed in the Winter War by the Finns known as "Kylmä-Kalle" (Cold Charlie). They used a shop mannequin or other doll dressed as a tempting target, such as an officer. The doll was then presented as if it were a real man sloppily covering himself. Usually, Soviet snipers were unable to resist the temptation of an apparently easy kill. Once the angle where the bullet came from was determined, a large calibre gun, such as a Lahti L-39 "Norsupyssy" ("Elephant rifle") anti-tank rifle was fired at the sniper to kill him.
Other tactics include directing artillery or mortar fire onto suspected sniper positions, the use of smoke screens, placing tripwire-operated munitions, mines, or other booby-traps near suspected sniper positions. Even dummy trip-wires can be placed to hamper sniper movement. If anti-personnel mines are unavailable, it is possible to improvise booby-traps by connecting trip-wires to hand grenades, smoke grenades or flares. Though these may not kill the sniper, they will reveal his/her location. Booby-trap devices can be placed near likely sniper hides, or along the probable routes to and from the positions. Knowledge of sniper field-craft will assist in this task.
One very old counter-sniper tactic is to tie rags onto bushes or similar items in suspected sniper hides. These rags flutter in the breeze creating random movements in the corner of the sniper's eye, which he/she will often find distracting. The greatest virtue of this tactic is its simplicity and ease of implementation; however, it is unlikely to prevent a skilled sniper from selecting targets, and may in fact provide a sniper with additional information about the wind near the target.
The use of canine units was very successful, especially during the Vietnam War. A trained dog can easily determine direction from the sound of the bullet, and will lie down with its head pointed at the origin of the gunshot. 
Irregular and asymmetric warfare.
The use of sniping (in the sense of shooting at relatively long range from a concealed position) to murder came to public attention in a number of sensational U.S. criminal cases, including the Austin sniper incident of 1966 (Charles Whitman), the John F. Kennedy assassination (Lee Harvey Oswald), and the Beltway sniper attacks of late 2002 (Lee Boyd Malvo). However, these incidents usually do not involve the range or skill of military snipers; in all three cases the perpetrators had U.S. military training, but in other specialties. News reports will often (inaccurately) use the term sniper to describe anyone shooting with a rifle at another person.
Sniping has been used in asymmetric warfare situations, for example in the Northern Ireland Troubles, where in 1972, the bloodiest year of the conflict, the majority of the soldiers killed were shot by concealed IRA riflemen. There were some instances in the early 1990s of British soldiers and RUC personnel being shot with .50 caliber Barrett rifles by sniper teams collectively known as the South Armagh sniper.
The sniper is particularly suited to combat environments where one side is at a disadvantage. A careful sniping strategy can use a few individuals and resources to thwart the movement or other progress of a much better equipped or larger force. Sniping enables a few persons to instil terror in a much larger regular force — regardless of the size of the force the snipers are attached to. It is widely accepted that sniping, while effective in specific instances, is much more effective as a broadly deployed psychological attack or as a force-multiplier.
Snipers are less likely to be treated mercifully than non-snipers if captured by the enemy. The rationale for this is that ordinary soldiers shoot at each other at 'equal opportunity' whilst snipers take their time in tracking and killing individual targets in a methodical fashion with a relatively low risk of retaliation.
War in Iraq.
In 2003, the U.S.-led multinational coalition composed of primarily U.S. and U.K. troops occupied Iraq and attempted to establish a new government in the country. However, shortly after the initial invasion, violence against coalition forces and among various sectarian groups led to asymmetric warfare with the Iraqi insurgency and civil war between many Sunni and Shia Iraqis.
Through November 2005, when the Pentagon had last reported a sniper fatality, the Army had attributed 28 of 2,100 U.S. deaths to enemy snipers. More recently, since 2006, insurgent snipers such as "Juba" have caused problems for American troops. Claims have been made that Juba have shot up to 37 American soldiers in Iraq as of October 2006.
In 2006, training materials obtained by U.S. intelligence showed that snipers fighting in Iraq were urged to single out and attack engineers, medics, and chaplains on the theory that those casualties would demoralize entire enemy units. Among the training materials, there included an insurgent sniper training manual that was posted on the Internet. Among its tips for shooting U.S. troops, there read: "Killing doctors and chaplains is suggested as a means of psychological warfare."
Afghanistan.
Some sniper teams in Afghanistan have killed large numbers of Taliban in quite short periods of time. For example, while in Helmand Province, two British snipers (part of the Welsh Guards Battle group) shot dead a total of 75 Taliban in only 40 days during the summer of 2009. In one session of duty, lasting just two hours, they shot and killed eight Taliban. On another occasion, the same team scored a "Quigley" (i.e., killing two Taliban with a single bullet) at a range of 196 metres.
Taliban snipers have themselves caused problems for coalition forces. For example, over a four-month period in early 2011, two Taliban snipers shot dead two British soldiers and wounded six others at an outpost in Qadrat, Helmand province. In one unusual incident, an unnamed 55-year-old ex-Mujahideen fighter with a motorbike and an old British-made Enfield rifle killed two British soldiers with a single shot, hitting the first in the head and the second in the neck.
Arab Spring.
Sniper activity has been reported during the Arab Spring civil unrest in Libya in 2011, both from anti-governmental and pro-governmental supporters, and in Syria at least from pro-government forces.
Notable military marksmen and snipers.
Even before firearms were available, soldiers such as archers were specially trained as elite marksmen.

</doc>
<doc id="28130" url="https://en.wikipedia.org/wiki?curid=28130" title="Sign">
Sign

A sign is an object, quality, event, or entity whose presence or occurrence indicates the probable presence or occurrence of something else. A natural sign bears a causal relation to its object—for instance, thunder is a sign of storm, or medical symptoms signify a disease. A conventional sign signifies by agreement, as a full stop signifies the end of a sentence; similarly the words and expressions of a language, as well as bodily gestures, can be regarded as signs, expressing particular meanings. The physical objects most commonly referred to as signs (notices, road signs, etc., collectively known as signage) generally inform or instruct using written text, symbols, pictures or a combination of these.
The philosophical study of signs and symbols is called semiotics; this includes the study of semiosis, which is the way in which signs (in the semiotic sense) operate.
Nature.
Semiotics, epistemology, logic, and philosophy of language are concerned about the nature of signs, what they are and how they signify. The nature of signs and symbols and significations, their definition, elements, and types, is mainly established by Aristotle, Augustine, and Aquinas. According to these classic sources, significance is a relationship between two sorts of things: signs and the kinds of things they signify (intend, express or mean), where one term necessarily causes something else to come to the mind. Distinguishing natural signs and conventional signs, the traditional theory of signs (Augustine) sets the following threefold partition of things:
all sorts of indications, evidences, symptoms, and physical signals, there are signs which are "always" signs (the entities of the mind as ideas and images, thoughts and feelings, constructs and intentions); and there are signs that "have" to get their signification (as linguistic entities and cultural symbols). So, while natural signs serve as the source of signification, the human mind is the agency through which signs signify naturally occurring things, such as objects, states, qualities, quantities, events, processes, or relationships. Human language and discourse, communication, philosophy, science, logic, mathematics, poetry, theology, and religion are only some of fields of human study and activity where grasping the nature of signs and symbols and patterns of signification may have a decisive value.
Types.
A sign can denote any of the following:
Christianity.
St. Augustine and Signs.
St. Augustine was the first man who synthesized the classical and Hellenistic theories of signs. For him a sign is a thing which is used to signify other things and to make them come to mind ("De Doctrina Christiana" DDC 1.2.2; 2.1.1). The most common signs are spoken and written words (DDC 1.2.2; 2.3.4-2.4.5). Although God cannot be fully expressible, Augustine gave emphasis to the possibility of God’s communication with humans by signs in Scripture (DDC 1.6.6). Augustine endorsed and developed the classical and Hellenistic theories of signs. Among the main stream in the theories of signs, i.e., that of Aristotle and that of Stoics, the former theory filtered into the works of Cicero (106-43 BC, "De inventione rhetorica" 1.30.47-48) and Quintilian (circa 35-100, "Institutio Oratoria" 5.9.9-10), which regarded the sign as an instrument of inference. In his commentary on Aristotle’s "De Interpretatione", Ammonius said, “according to the division of the philosopher Theophrastus, the relation of speech is twofold, first in regard to the audience, to which speech signifies something, and secondly in regard to the things about which the speaker intends to persuade the audience.” If we match DDC with this division, the first part belongs to DDC Book IV and the second part to DDC Books I-III. Augustine, although influenced by these theories, advanced his own theological theory of signs, with whose help one can infer the mind of God from the events and words of Scripture. 
Books II and III of DDC enumerate all kinds of signs and explain how to interpret them. Signs are divided into natural ("naturalia") and conventional ("data"); the latter is divided into animal ("bestiae") and human ("homines"); the latter is divided into non-words ("cetera") and words ("verba"); the latter is divided into spoken words ("voces") and written words ("litterae"); the latter is divided into unknown signs ("signa ignota") and ambiguous signs ("signa ambigua"); both the former and the latter are divided respectively into particular signs ("signa propria") and figurative signs ("signa translata"), among which the unknown figurative signs belong to the pagans. 
In addition to exegetical knowledge (Quintilian, "Institutio Oratoria" 1.4.1-3 and 1.8.1-21) which follows the order of reading ("lectio"), textual criticism ("emendatio"), explanation ("enarratio"), and judgment ("iudicium"), one needs to know the original language (Hebrew and Greek) and broad background information on Scripture (DDC 2.9.14-2.40.60).
Augustine’s understanding of signs includes several hermeneutical presuppositions as important factors. First, the interpreter should proceed with humility, because only a humble person can grasp the truth of Scripture (DDC 2.41.62). Second, the interpreter must have a spirit of active inquiry and should not hesitate to learn and use pagan education for the purpose of leading to Christian learning, because all truth is God’s truth (DDC 2.40.60-2.42.63). Third, the heart of interpreter should be founded, rooted, and built up in love which is the final goal of the entire Scriptures (DDC 2.42.63).
The sign does not function as its own goal, but its purpose lies in its role as a signification ("res significans", DDC 3.9.13). God gave signs as a means to reveal himself; Christians need to exercise hermeneutical principles in order to understand that divine revelation. Even if the Scriptural text is obscure, it has meaningful benefits. For the obscure text prevents us from falling into pride, triggers our intelligence (DDC 2.6.7), tempers our faith in the history of revelation (DDC 3.8.12), and refines our mind to be suitable to the holy mysteries (DDC 4.8.22). When interpreting signs, the literal meaning should first be sought, and then the figurative meaning (DDC 3.10.14-3.23.33). Augustine suggests the hermeneutical principle that the obscure Scriptural verse is interpreted with the help of plain and simple verses, which formed the doctrine of “scriptura scripturae interpres” (Scripture is the Interpreter of Scripture) in the Reformation Era. Moreover, he introduces the seven rules of Tyconius the Donatist to interpret the obscure meaning of the Bible, which demonstrates his understanding that all truth belongs to God (DDC 3.3.42-3.37.56). In order to apply Augustine’s hermeneutics of the sign appropriately in modern times, every division of theology must be involved and interdisciplinary approaches must be taken.

</doc>
<doc id="28131" url="https://en.wikipedia.org/wiki?curid=28131" title="Standard Alphabet by Lepsius">
Standard Alphabet by Lepsius

The Standard Alphabet is a Latin-based alphabet developed by Karl Richard Lepsius. Lepsius initially used it to transcribe Egyptian hieroglyphs and extended it to write African languages, published in 1854 and 1855, and in a revised edition in 1863. The alphabet was comprehensive but was not used much as it contained a lot of diacritic marks and was difficult to read and typeset at that time.
Vowels.
Vowel length is indicated by a macron ("ā") or a breve ("ă") for long and short vowels, respectively. Open vowels are marked by a line under the letter ("e̱"), while a dot below the letter makes it a close vowel ("ẹ"). Rounded front vowels are written with an umlaut ("ö" and "ü" ), either on top or below, when the space above the letter is needed for vowel length marks (thus "ṳ̄" or "ṳ̆"). Unrounded back vowels are indicated by a corner (˻) below "e" or "i" (not supported by Unicode). (Central vowels may be written as one of these series, or as reduced vowels.) 
As in the , nasal vowels get a tilde ("ã"). 
A small circle below a letter is used to mark both the schwa ("e̥", also "ḁ" etc. for other reduced vowels) and syllabic consonants ("r̥" or "l̥", for instance). 
Diphthongs do not receive any special marking, they are simply juxtaposed ("ai" ). A short sign can be used to distinguish which element of the diphthong is the on- or off-glide ("uĭ, ŭi") Vowels in hiatus can be indicated with a diaeresis when necessary ("aï" ).
Other vowels are "a" with a subscript "e" for ; "a" with a subscript "o" for , and "o̩" for or maybe . The English syllabic is "ṙ̥".
Word stress is marked with an acute accent on a long vowel ("á") and with a grave accent on a short vowel ("à").
Consonants.
The Lepsius letters without predictable diacritics are as follows:
Other consonant sounds may be derived from these. For example, palatal and palatalized consonants are marked with an acute accent: "ḱ" , "ǵ" , "ń" , "χ́" , "š́" , "γ́" , "ž́" , "ĺ" , "‘ĺ" , "ǀ́" , "ṕ" , etc. These can also be written "ky, py" etc.
Labialized velars are written with an over-dot: "ġ" , "n̈" , etc. (A dot on a non-velar letter, as in "ṅ" and "ṙ" in the table above, indicates a guttural articulation.)
Retroflex consonants are marked with an under-dot: "ṭ" , "ḍ" , "ṇ" , "ṣ̌" , "ẓ̌" , "ṛ" , "ḷ" , and "ǀ̣" .
The Semitic "emphatic" consonants are marked with an underline: "ṯ" , "ḏ" , "s̱" , "ẕ" , "δ̱" , "ḻ" .
Aspiration is typically marked by "h": "kh" , but a turned apostrophe (Greek "spiritus asper") is also used: "k̒" , "ģ" . Either convention may be used for voiceless sonorants: "m̒" , "‘l" .
Affricates are generally written as sequences, e.g. "tš" for . But the single letters "č" , "ǰ" , "c̀" , "j̀" , "ț" , and "d̦" are also used.
Implosives are written with a macron: "b̄" , "d̄" , "j̄" , "ḡ" . As with vowels, long (geminate) consonants may also be written with a macron, so this transcription can be ambiguous. 
Lepsius typically characterized ejective consonants as tenuis, as they are completely unaspirated, and wrote them with the Greek "spiritus lenis" ("p’", "t’", etc.), which may be the source of the modern convention for ejectives in the IPA. However, when his sources made it clear that there was some activity in the throat, he transcribed them as emphatics. 
When transcribing consonant letters which are pronounced the same but are etymologically distinct, as in Armenian, diacritics from the original alphabet or roman transliteration may be carried over. Similarly, unique sounds such as Czech "ř" may be carried over into Lepsius transcription. Lepsius used a diacritic "r" under "t᷊" and "d᷊" for some poorly described sounds in Dravidian languages. 
Standard capitalization is used. For example, when written in all caps, "γ" becomes "Γ" (as in "AFΓAN" "Afghan").
Tones.
Tone is marked with an acute or grave accent to the right and near the top or the bottom of the corresponding vowel. The diacritic may be underlined for a lower pitch, distinguishing in all eight possible tones.
Tone is not written directly, but rather needs to be established separately for each language. For example, the acute accent may indicate a high tone, a rising tone, or, in the case of Chinese, any tone called "rising" (上) for historical reasons. 
Low rising and falling tones can be distinguished from high rising and falling tones by underlining the accent mark: . The underline also transcribes the Chinese "yin" tones, under the mistaken impression that these tones are actually lower. Two additional tone marks, without any defined phonetic value, are used for Chinese: "level" maˏ (平) and checked maˎ (入); these may also be underlined.

</doc>
<doc id="28132" url="https://en.wikipedia.org/wiki?curid=28132" title="Sidehill gouger">
Sidehill gouger

Sidehill gougers are North American folkloric creatures adapted to living on hillsides by having legs on one side of their body shorter than the legs on the opposite side. This peculiarity allows them to walk on steep hillsides, although only in one direction; when lured or chased into the plain, they are trapped in an endless circular path. The creature is variously known as the Sidehill Ousel, Gyascutus, Sidewinder, Wampus, Gudaphro, Hunkus, Rickaboo Racker, Prock, Gwinter, or Cutter Cuss.
Sidehill gougers are herbivorous mammals who dwell in hillside burrows, and are occasionally depicted as laying eggs. There are usually 6 to 8 pups to a litter. Since the gouger is footed for hillsides, it cannot stand up on level ground. If by accident a gouger falls from a hill, it can easily be captured or starve to death. 
When a clockwise gouger meets a counter-clockwise gouger, they have to fight to the death since they can only go in one direction.
Gougers are said to have migrated to the west from New England, a feat accomplished by a pair of gougers who clung to each other in a fashion comparable to "a pair of drunks going home from town" with their longer legs on the outer sides. 
A Vermont variation is known as the Wampahoofus. It was reported that farmers crossbreed them with their cows so they could graze easily on mountain sides. There is also a similar mythical creature in France known as the dahu.
Frank C. Whitmore and Nicholas Hotton, in their joint tongue-in-cheek response to an article "Fantastic Animals" ("Smithsonian Magazine", 1972), expounded the taxonomy of sidehill gougers ("Membriinequales declivitous"), noting in particular "the sidehill dodger, which inhabits the Driftless Area of Wisconsin; the dextrosinistral limb ratio approaches unity although the metapodials on the downhill side are noticeably stouter."

</doc>
<doc id="28133" url="https://en.wikipedia.org/wiki?curid=28133" title="Strike">
Strike

Strike may refer to:

</doc>
<doc id="28134" url="https://en.wikipedia.org/wiki?curid=28134" title="Second Vatican Council">
Second Vatican Council

The Second Vatican Council (Latin: "Concilium Oecumenicum Vaticanum Secundum", informally known as "Vatican II") addressed relations between the Roman Catholic Church and the modern world. It was the twenty-first ecumenical council of the Catholic Church and the second to be held at Saint Peter's Basilica in the Vatican. The council, through the Holy See, formally opened under the pontificate of Pope John XXIII on 11 October 1962 and closed under Pope Paul VI on the Feast of the Immaculate Conception on 8th December 1965.
Several changes resulted from the council, including the renewal of consecrated life with a revised charism, ecumenical efforts towards dialogue with other religions, and the call to holiness for everyone including the laity, according to Pope Paul VI "the most characteristic and ultimate purpose of the teachings of the Council".
According to Pope Benedict XVI, the most important and essential message of the council is "the Paschal Mystery as the center of what it is to be Christian and therefore of the Christian life, the Christian year, the Christian seasons". Other changes which followed the council included the widespread use of vernacular languages in the Mass instead of Latin, the subtle disuse of ornate clerical regalia, the revision of Eucharistic prayers, the abbreviation of the liturgical calendar, the ability to celebrate the Mass "versus populum" (with the officiant facing the congregation), as well as "ad orientem" (facing the "East" and the Crucifix), and modern aesthetic changes encompassing contemporary Catholic liturgical music and artwork, many of which remain divisive among the Catholic faithful.
Of those who took part in the council's opening session, four have become pontiffs: Cardinal Giovanni Battista Montini, who on succeeding Pope John XXIII took the name of Paul VI; Bishop Albino Luciani, the future Pope John Paul I; Bishop Karol Wojtyła, who became Pope John Paul II; and Father Joseph Ratzinger, present as a theological consultant, who became Pope Benedict XVI.
Background.
In the 1950s, theological and Biblical studies in the Catholic Church had begun to sway away from the neo-scholasticism and biblical literalism which a reaction to Catholic modernism had enforced since the First Vatican Council. This shift could be seen in theologians such as Karl Rahner, SJ, Michael Herbert, and John Courtney Murray, SJ who looked to integrate modern human experience with church principles based on Jesus Christ, as well as others such as Yves Congar, Joseph Ratzinger and Henri de Lubac who looked to an accurate understanding of scripture and the early Church Fathers as a source of renewal ("ressourcement").
At the same time, the world's bishops faced challenges driven by political, social, economic, and technological change. Some of these bishops sought new ways of addressing those challenges. The First Vatican Council had been held nearly a century before but had been cut short when the Italian Army entered the city of Rome at the end of Italian unification. As a result, only deliberations on the role of the Papacy and the congruent relationship of faith and reason were completed, with examination of pastoral issues concerning the direction of the Church left unaddressed.
Pope John XXIII, however, gave notice of his intention to convene the Council on 25 January 1959, less than three months after his election in October 1958. This sudden announcement, which caught the Curia by surprise, caused little initial official comment from Church insiders. Reaction to the announcement was widespread and largely positive from both religious and secular leaders outside the Catholic Church, and the council was formally summoned by the apostolic constitution "Humanae Salutis" on 25 December 1961. In various discussions before the Council actually convened, Pope John XXIII often said that it was time to open the windows of the Church to let in some fresh air. He invited other Christians outside the Catholic Church to send observers to the Council. Acceptances came from both the Eastern Orthodox and Protestant denominations as internal observers but the observers did not cast votes in the approbation of the conciliar documents.
Chronology.
Preparation.
Pope John XXIII's announcement on 25 January 1959 of his intention to call a general council came as a surprise even to the cardinals present. The Pontiff pre-announced the council under a full moon when the faithful with their candlelights gathered in St. Peter's square and jokingly noted about the brightness of the moon. After which, he instructed the people to go back home and "give their children a kiss of goodnight, from the Pope himself".
He had tested the idea only ten days before with one of them, his Cardinal Secretary of State Domenico Tardini, who gave enthusiastic support to the idea. Although the Pope later said the idea came to him in a flash in his conversation with Tardini, two cardinals had earlier attempted to interest him in the idea. They were two of the most conservative, Ernesto Ruffini and Alfredo Ottaviani, who had already in 1948 proposed the idea to Pope Pius XII and who put it before John XXIII on 27 October 1958.
Actual preparations for the Council took more than two years, and included work from 10 specialised commissions, people for mass media and Christian Unity, and a Central Commission for overall coordination. These groups, composed mostly of members of the Roman Curia, produced 987 proposed constituting sessions, making it the largest gathering in any council in church history. (This compares to Vatican I, where 737 attended, mostly from Europe.) Attendance varied in later sessions from 2,100 to over 2,300. In addition, a varying number of "periti" () were available for theological consultation—a group that turned out to have a major influence as the council went forward. Seventeen Orthodox Churches and Protestant denominations sent observers. More than three dozen representatives of other Christian communities were present at the opening session, and the number grew to nearly 100 by the end of the 4th Council Sessions.
First period: 1962.
Opening.
Pope John XXIII opened the Council on 11 October 1962 in a public session and read the declaration Gaudet Mater Ecclesia before the Council Fathers.
What is needed at the present time is a new enthusiasm, a new joy and serenity of mind in the unreserved acceptance by all of the entire Christian faith, without forfeiting that accuracy and precision in its presentation which characterized the proceedings of the Council of Trent and the First Vatican Council. What is needed, and what everyone imbued with a truly Christian, Catholic and apostolic spirit craves today, is that this doctrine shall be more widely known, more deeply understood, and more penetrating in its effects on men's moral lives. What is needed is that this certain and immutable doctrine, to which the faithful owe obedience, be studied afresh and reformulated in contemporary terms. For this deposit of faith, or truths which are contained in our time-honored teaching is one thing; the manner in which these truths are set forth (with their meaning preserved intact) is something else." .
13 October 1962 marked the initial working session of the Council. That day's agenda included the election for members of the ten conciliar commissions. Each would have sixteen elected and eight appointed members, and were expected to do most of the work of the Council. It had been expected that the members of the preparatory commissions, where the Curia was heavily represented, would be confirmed as the majorities on the conciliar commissions. Senior French Cardinal Achille Liénart addressed the Council, saying that the bishops could not intelligently vote for strangers. He asked that the vote be postponed to give all the bishops a chance to draw up their own lists. German Cardinal Josef Frings seconded that proposal, and the vote was postponed. The first meeting of the Council adjourned after only fifteen minutes.
Commissions.
The bishops met to discuss the membership of the commissions, along with other issues, both in national and regional groups, as well as in gatherings that were more informal. The "schemata" (Latin for drafts) from the preparatory sessions were thrown out, and new ones were created. When the council met on 16 October 1962, a new slate of commission members was presented and approved by the Council. One important change was a significant increase in membership from Central and Northern Europe, instead of countries such as Spain or Italy. More than 100 bishops from Africa, Asia, and Latin America were Dutch or Belgian and tended to associate with the bishops from those countries. These groups were led by Cardinals Bernardus Johannes Alfrink of the Netherlands and Leo Suenens of Belgium.
Issues.
After adjournment on 8 December, work began on preparations for the sessions scheduled for 1963. These preparations, however, were halted upon the death of Pope John XXIII on 3 June 1963, since an ecumenical council is automatically interrupted and suspended upon the death of the Pope who convened it, until the next Pope orders the council to be continued or dissolved. Pope Paul VI was elected on 21 June 1963 and immediately announced that the Council would continue.
Second period: 1963.
In the months prior to the second period, Pope Paul VI worked to correct some of the problems of organization and procedure that had been discovered during the first period. This included inviting additional lay Catholic and non-Catholic observers, reducing the number of proposed schemata to seventeen (which were made more general, in keeping with the pastoral nature of the council) and later eliminating the requirement of secrecy surrounding general sessions.
Pope Paul's opening address on 29 September 1963 stressed the pastoral nature of the council, and set out four purposes for it:
During this period, the bishops approved the constitution on the liturgy, "Sacrosanctum Concilium", and the decree on social communication, "Inter mirifica". Work went forward with the schemata on the Church, bishops and dioceses, and ecumenism. On 8 November 1963, Josef Frings criticized the Holy Office, and drew an articulate and impassioned defense by its Secretary, Alfredo Ottaviani. This exchange is often considered the most dramatic of the council (Cardinal Frings' theological adviser was the young Joseph Ratzinger, who would later as a Cardinal head the same department of the Holy See, and from 2005–13 reign as Pope Benedict XVI). The second period ended on 4 December.
Third period: 1964.
In the time between the second and third periods, the proposed schemata were further revised on the basis of comments from the Council Fathers. A number of topics were reduced to statements of fundamental propositions that could gain approval during the third period, with postconciliar commissions handling implementation of these measures.
At the end of the second period, Cardinal Leo Joseph Suenens of Belgium had asked the other bishops: "Why are we even discussing the reality of the church when half of the church is not even represented here?," referring to women. In response, 15 women were appointed as auditors in September 1964. Eventually 23 women were auditors at the Second Vatican Council, including 10 women religious. There were three Americans among the auditors: Loretto Sr. Mary Luke Tobin, Basilian Sr. Claudia (Anna) Feddish, of the Byzantine rite, and Catherine McCarthy, president of the National Council of Catholic Women. The auditors had no official role in the deliberations, although they attended the meetings of subcommittees working on council documents, particularly texts that dealt with the laity. They also met together on a weekly basis to read draft documents and comment on them.
During the third period, which began on 14 September 1964, the Council Fathers worked through a large volume of proposals. Schemata on ecumenism ("Unitatis redintegratio"); the official view on Protestant and Eastern Orthodox "separated brethren", the Eastern Rite churches ("Orientalium Ecclesiarum"); and the Dogmatic Constitution of the Church ("Lumen gentium") 'were approved and promulgated by the Pope′.
Schemata on the life and ministry of priests and the missionary activity of the Church were rejected and sent back to commissions for complete rewriting. Work continued on the remaining schemata, in particular those on the Church in the modern world and religious freedom. There was controversy over revisions of the decree on religious freedom and the failure to vote on it during the third period, but Pope Paul promised that this schema would be the first to be reviewed in the next period.
Pope Paul closed the third period on 21 November by announcing a change in the Eucharistic fast and formally reaffirming Mary as "Mother of the Church".
Fourth period: 1965.
Eleven schemata remained unfinished at the end of the third period, and commissions worked to give them their final form. Schema 13, on the Church in the modern world, was revised by a commission that worked with the assistance of laymen.
Pope Paul VI opened the last period of the Council on 14 September 1965 with the establishment of the Synod of Bishops. This more permanent structure was intended to preserve close cooperation of the bishops with the Pope after the council.
The first business of the fourth period was the consideration of the decree on religious freedom, "Dignitatis humanae", one of the more controversial of the conciliar documents. The vote was 1,997 for to 224 against, a margin that widened even further by the time the bishops finally signed the decree. The principal work of the rest of the period was work on three documents, all of which were approved by the Council Fathers. The lengthened and revised pastoral constitution on the Church in the modern world, "Gaudium et spes", was followed by decrees on missionary activity, "Ad gentes" and the ministry and life of priests, "Presbyterorum ordinis".
The council also gave final approval to other documents that had been considered in earlier sessions. They included the Dogmatic Constitution on Divine Revelation ("Dei verbum"), decrees on the pastoral office of bishops ("Christus Dominus"), the life of persons in religious orders (expanded and modified from earlier sessions, finally titled "Perfectae caritatis"), education for the priesthood ("Optatam totius"), Christian education ("Gravissimum educationis"), and the role of the laity ("Apostolicam actuositatem").
One of the more controversial documents was "Nostra aetate", which stated that the Jews of the time of Christ, taken indiscriminately, and all Jews today are no more responsible for the death of Christ than Christians.
A major event of the final days of the council was the act of Pope Paul and Orthodox Patriarch Athenagoras of a joint expression of regret for many of the past actions that had led up to the Great Schism between the western and eastern churches.
"The old story of the Samaritan has been the model of the spirituality of the council" (Paul VI., address, 7 December): On 8 December, the Council was formally closed, with the bishops professing their obedience to the Council's decrees. To help carry forward the work of the Council, Pope Paul:
Key Content and Issues.
Liturgy.
The first matter covered by the council was the liturgy, to emphasize "the primacy of God" and "the primacy of adoration," according to Pope Benedict XVI. He said that the most important essential idea of the Council itself is "Paschal Mystery (Christ's passion, death and resurrection) as the center of what it is to be Christian and therefore of the Christian life, the Christian year, the Christian seasons, expressed in Eastertide and on Sunday which is always the day of the Resurrection." Thus, the liturgy, especially the Eucharist, which makes the Paschal Mystery present, is "the summit toward which the activity of the Church is directed; at the same time it is the font from which all her power flows."
The matter that had the most immediate effect on the lives of individual Catholics, was the revision of the liturgy. The central idea was that there ought to be greater lay participation in the liturgy. In the mid-1960s, permissions were granted to celebrate most of the Mass in vernacular languages, including the canon from 1967 onwards. The amount of Scripture read during Mass was greatly expanded, through the introduction of multiple year lectionaries.
Neither the Second Vatican Council nor the subsequent revision of the Roman Missal abolished Latin as the liturgical language of the Roman Rite: the official text of the Roman Missal, on which translations into vernacular languages are to be based, continues to be in Latin and it can still be used in the celebration.
Ecclesiology.
Perhaps the most famous and most influential product of the council is the Dogmatic Constitution on the Church, "Lumen gentium".
In its first chapter, titled ""The Mystery of the Church,"" is the famous statement that: 
The document immediately adds, "Nevertheless, many elements of sanctification and of truth are found outside its visible confines".
According to Pope Paul VI, "the most characteristic and ultimate purpose of the teachings of the Council" is the universal call to holiness: John Paul II calls this "an intrinsic and essential aspect of Council Fathers' teaching on the Church."
Thus in his plan for the millennium, Novo Millennio Ineunte, John Paul II said that "that all pastoral initiatives must be set in relation to holiness" as the first priority of the Church.
Scripture and divine revelation.
The council sought to revive the central role of Scripture in the theological and devotional life of the Church, building upon the work of earlier popes in crafting a modern approach to Scriptural analysis and interpretation. A new approach to interpretation was approved by the bishops. The Church was to continue to provide versions of the Bible in the "mother tongues" of the faithful, and both clergy and laity were to continue to make Bible study a central part of their lives. This affirmed the importance of Sacred Scripture as attested by Providentissimus Deus by Pope Leo XIII and the writings of the Saints, Doctors, and Popes throughout Church history but also approved historically conditioned interpretation of Scripture as presented in Pius XII's 1943 encyclical "Divino afflante Spiritu".
Bishops.
The role of the bishops was brought into renewed prominence, especially when seen collectively, as a college that has succeeded to that of the apostles in teaching and governing the Church. This college was headed by the Pope.
Objections to the council.
The questioning of the validity of the Second Vatican Council continues to be a contending point of rejection and conflict among various religious communities that are not in full communion with the Roman Catholic Church. In particular, two schools of thought may be discerned:
The most recent edition of 1983 Code of Canon Law states that Catholics may not disregard the teaching of an ecumenical council even if it does not propose such as definitive. Accordingly, it also maintains that present living Pope alone judges the criterion of membership for being "in communio" with the Church. The present canon law further articulates: 
Several notable members of clergy opposed particular documents of the Second Vatican Council:
Opposing Traditionalist Catholic groups:
Legacy.
In addition to general spiritual guidance, the Second Vatican Council produced very specific recommendations, such as in the document "Gaudiem et Spes": "Any act of war aimed indiscriminately at the destruction of entire cities of extensive areas along with their population is a crime against God and man himself. It merits unequivocal and unhesitating condemnation."
By "the spirit of Vatican II" is often meant promoting teachings and intentions attributed to the Second Vatican Council in ways not limited to literal readings of its documents, spoken of as the "letter" of the Council (cf. Saint Paul's phrase, "the letter kills, but the Spirit gives life").
The spirit of Vatican II is invoked for a great variety of ideas and attitudes. Bishop John Tong Hon of Hong Kong used it with regard merely to an openness to dialogue with others, saying: "We are guided by the spirit of Vatican II: only dialogue and negotiation can solve conflicts."
In contrast, Michael Novak described it as a spirit that: Such views of the Second Vatican Council were condemned by the Church's hierarchy, and the works of theologians who were active in the Council or who closely adhered to the Council's aspect of reform (such as Hans Küng) have often been criticized by the Church for espousing a belief system that the hierarchy considers radical and misguided. As Dei Verbum reads, "Therefore, following in the footsteps of the Council of Trent and of the First Vatican Council, this present council wishes to set forth authentic doctrine on divine revelation and how it is handed on …", Vatican II did not deny previous councils' correctness.
To mark the fiftieth anniversary of the beginning of Vatican II, in October 2011, Pope Benedict XVI declared the period from October 2012 to the Solemnity of Christ the King at the end of November 2013 a "Year of Faith", as:

</doc>
<doc id="28135" url="https://en.wikipedia.org/wiki?curid=28135" title="Slovene language">
Slovene language

Slovene ( or ) or Slovenian (; "slovenski jezik" or "slovenščina"), belongs to the group of South Slavic languages. It is spoken by approximately 2.5 million speakers worldwide, the majority of whom live in Slovenia. It is the first language of about 2.1 million Slovenian people and is one of the 24 official and working languages of the European Union.
Standard Slovene.
Standard Slovene is the national standard language that was formed in the 18th century, mostly based on Upper and Lower Carniolan dialect groups, the latter being a dialect spoken by Primož Trubar. Unstandardized dialects are more preserved in regions of the Slovene Lands where compulsory schooling was in languages other than Standard Slovene, as was the case with the Carinthian Slovenes in Austria, and the Slovene minority in Italy. For example, the Resian and Torre (Ter) dialects in the Italian Province of Udine differ most from other Slovene dialects.
The distinctive characteristics of Slovene are dual grammatical number, two accentual norms (one characterized by pitch accent), and abundant inflection (a trait shared with many Slavic languages). Although Slovene is basically an SVO language, word order is very flexible, often adjusted for emphasis or stylistic reasons. Slovene has a T-V distinction: second-person plural forms are used for individuals as a sign of respect. Also, Slovene and Slovak are the two modern Slavic languages whose names for themselves literally mean "Slavic" ("slověnьskъ" in old Slavonic).
Classification.
Slovene is an Indo-European language belonging to the Western subgroup of the South Slavic branch of the Slavic languages, together with Serbo-Croatian. It is close to the Chakavian and especially Kajkavian dialects of Serbo-Croatian, but further from the Shtokavian dialect, the basis for the Bosnian, Croatian, Montenegrin, and Serbian standard languages. Furthermore, Slovene shares certain linguistic characteristics with all South Slavic languages, including those of the Eastern subgroup, such as Bulgarian. Although Slovene is almost completely intelligible with the Kajkavian dialects of Serbo-Croatian (especially the variant spoken in Hrvatsko Zagorje on the border with Slovenia), mutual intelligibility with other varieties of Serbo-Croatian is hindered by differences in vocabulary, grammar, and pronunciation. The Slovene language also has many commonalities with the West Slavic languages.
History.
Early history.
Like all Slavic languages, Slovene traces its roots to the same proto-Slavic group of languages that produced Old Church Slavonic. The earliest known examples of a distinct, written Slovene dialect are from the "Freising Manuscripts," known in Slovene as "Brižinski spomeniki". The consensus estimate of their date of origin is between 972 and 1093 (most likely before 1000). These religious writings are among the oldest surviving manuscripts in any Slavic language.
The "Freising Manuscripts" are a record of a proto-Slovene language that was spoken in a much larger territory than modern Slovene, which included most of the present-day Austrian states of Carinthia and Styria, as well as East Tyrol, the Val Pusteria in South Tyrol, and some areas of Upper and Lower Austria. By the 15th century, most of the northern areas were gradually Germanized: the northern border of the Slovene-speaking territory stabilized on the line going from north of Klagenfurt to south of Villach and east of Hermagor in Carinthia, while in Styria it was pretty much identical with the current Austrian-Slovenian border. This linguistic border remained almost unchanged until the late 19th century, when a second process of Germanization took place, mostly in Carinthia. Between the 9th and 12th century, proto-Slovene spread into northern Istria and in the areas around Trieste.
During most of the Middle Ages, Slovene was a vernacular language of the peasantry, although it was also spoken in most of the towns on Slovene territory, together with German or Italian. Although during this time, German emerged as the spoken language of the nobility, Slovene had some role in the courtly life of the Carinthian, Carniolan and Styrian nobility, as well. This is proved by the survival of certain ritual formulas in Slovene (such as the ritual installation of the Dukes of Carinthia). The words "Buge waz primi, gralva Venus!" ("God be With You, Queen Venus!"), with which Bernhard von Spanheim greeted the poet Ulrich von Liechtenstein upon his arrival to Carinthia in 1227 (or 1238), is another example of some level of Slovene knowledge among high nobility in the region.
The first printed Slovene words, "stara pravda" (meaning 'old justice'), appeared in 1515 in Vienna in a poem of the German mercenaries who suppressed the Slovene peasant revolt. Standard Slovene emerged in the second half of the 16th century, thanks to the works of Slovene Lutheran authors, who were active during the Protestant Reformation. The most prominent authors from this period are Primož Trubar, who wrote the first books in Slovene; Adam Bohorič, the author of the first Slovene grammar; and Jurij Dalmatin, who translated the entire Bible into Slovene.
From the high Middle Ages up to the dissolution of the Austro-Hungarian Empire in 1918, in the territory of present-day Slovenia, German was the language of the elite, and Slovene was the language of the common people. During this period, German had a strong influence on Slovene, and many Germanisms are preserved in contemporary colloquial Slovene. Many Slovene scientists before the 1920s also wrote in foreign languages, mostly German, which was the "lingua franca" of science throughout Central Europe at the time.
Recent history.
During the rise of Romantic Nationalism in the 19th century, the cultural movements of Illyrism and Pan-Slavism brought words from Serbo-Croatian and Czech into standard Slovene, mostly to replace words previously borrowed from German. Most of these innovations have remained, although some were dropped in later development. In the second half of the 19th century, many nationalist authors made an abundant use of Serbo-Croatian words: among them were Fran Levstik and Josip Jurčič, who wrote the first novel in Slovene in 1866. This tendency was reversed in the Fin de siècle period by the first generation of modernist Slovene authors (most notably the writer Ivan Cankar), who resorted to a more "pure" and simple language without excessive Serbo-Croatian borrowings.
During the Kingdom of Yugoslavia in the 1920s and 1930s, the influence of Serbo-Croatian increased again. This was opposed by the younger generations of Slovene authors and intellectuals; among the most fierce opponents of an excessive Serbo-Croatian influence on Slovene were the intellectuals associated with the leftist journal "Sodobnost", as well as some younger Catholic activists and authors. After 1945, numerous Serbo-Croatian words that had been used in the previous decades were dropped. The result was that a Slovene text from the 1910s is frequently closer to modern Slovene than a text from the 1920s and 1930s.
Between 1920 and 1941, the official language of the Kingdom of Yugoslavia was defined as "Serbian-Croatian-Slovene". In practice, Slovene was used in Slovenia, both in education and administration. Many state institutions used only Serbo-Croatian, and a Slovene–Serbo-Croatian bilingualism was applied in many spheres of public life in Slovenia. For examples, at the post offices, railways and in administrative offices, Serbo-Croatian was used together with Slovene. However, state employees were expected to be able to speak Slovene in Slovenia.
During the same time, western Slovenia (the Slovenian Littoral and the western districts of Inner Carniola) was under Italian administration and submitted to a violent policy of Fascist Italianization; the same policy was applied to Slovene speakers in Venetian Slovenia, Gorizia and Trieste. Between 1923 and 1943, all public use of Slovene language in these territories was strictly prohibited, and Slovene language activists were persecuted by the state.
After the Carinthian Plebiscite of 1920, a less severe policy of Germanization took place in the Slovene-speaking areas of southern Carinthia which remained under Austrian administration. After the Anschluss of 1938, the use of Slovene was strictly forbidden in Carinthia, as well. This accelerated a process of language shift in Carinthia, which continued throughout the second half of the 20th century: according to the Austro-Hungarian census of 1910, around 17% of inhabitants of Carinthia spoke Slovene in their daily communication; in 1951, this figure dropped under 10%, and by 2001 to a mere 2.8%.
During World War II, Slovenia was divided among the Axis Powers of Fascist Italy, Nazi Germany, and Hungary. Each of the occupying powers tried to either discourage or entirely suppress the Slovene language.
Following World War II, Slovenia became part of the Socialist Federal Republic of Yugoslavia. Slovene was one of the official languages of the federation. In the territory of Slovenia, it was commonly used in almost all areas of public life. One important exception was the Yugoslav army, where Serbo-Croatian was used exclusively, even in Slovenia.
National independence has revitalized the language: since 1991, when Slovenia gained independence, Slovene has been used as an official language in all areas of public life. In 2004 it became one of the official languages of the European Union upon Slovenia's admission.
Joža Mahnič, a literary historian and the then president of Slovenska matica, a prestigious publishing house, said in February 2008 that Slovene is a language rich enough to express everything, including the most sophisticated and specialised texts. In February 2010, Janez Dular, a prominent Slovenian linguist, commented that, although Slovene is not an endangered language, its scope has been shrinking, especially in science and higher education.
Geographic distribution.
The language is spoken by about 2.5 million people, mainly in Slovenia, but also by Slovene national minorities in Friuli-Venezia Giulia, Italy (around 90,000 in Venetian Slovenia, Resia Valley, Canale Valley, Province of Trieste and in those municipalities of the Province of Gorizia bordering with Slovenia), in southern Carinthia and some parts of Styria in Austria (25,000). It is also spoken in Croatia, especially in Istria, Rijeka and Zagreb (11,800-13,100), in southwestern Hungary (3-5,000), in Serbia (5,000), and by the Slovene diaspora throughout Europe and the rest of the world (around 300,000), particularly in the United States (most notably Ohio home to estimated 3,400 speakers), Canada, Argentina, Australia and South Africa.
Dialects.
Slovene is sometimes characterized as the most diverse Slavic language in terms of dialects, with different degrees of mutual intelligibility. Accounts of the number of dialects range from as few as seven dialects, often considered dialect groups or dialect bases that are further subdivided into as many as 50 dialects. Other sources characterize the number of dialects as nine or eight. The Slovene proverb "Every village has its own voice" ("Vsaka vas ima svoj glas") depicts the differences in dialects. Although pronunciation differs greatly from area to area, those differences do not pose major obstacles to understanding. The standard language is mainly used in public presentations or on formal occasions.
The Prekmurje dialect used to have a written norm of its own at one point. The Resian dialects have an independent written norm that is used by their regional state institutions. Speakers of those two dialects have considerable difficulties with being understood by speakers of other varieties of Slovene, needing code-switching to Standard Slovene. Other dialects are mutually intelligible when speakers avoid the excessive usage of regionalisms.
Regionalisms are mostly limited to culinary and agricultural expressions, although there are many exceptions. Some loanwords have become so deeply rooted in the local language that people have considerable difficulties in finding a standard expression for the dialect term (for instance, "kovter" meaning blanket is "prešita odeja" in Standard Slovene, but the latter term is "never" used in speech). Southwestern dialects incorporate a great deal of calques and loanwords from Italian, whereas eastern and northwestern dialects are replete with lexemes of German origin. Usage of such words hinders intelligibility between dialects and is greatly discouraged in formalities.
Phonology.
Slovene has a phoneme set consisting of 21 consonants and 8 vowels.
Consonants.
Slovene has 21 distinctive consonant phonemes.
All voiced obstruents are devoiced at the end of words unless immediately followed by a word beginning with a vowel or a voiced consonant. In consonant clusters, voicing distinction is neutralized and all consonants assimilate the voicing of the rightmost segment. In this context, , and may occur as voiced allophones of , and , respectively (e.g. "vŕh drevésa" ).
The sequences , and occur only before a vowel. Before a consonant or word-finally, they are reduced to , and respectively. This is reflected in the spelling in the case of , but not for and .
Under certain (somewhat unpredictable) circumstances, at the end of a syllable may become , merging with the allophone of in that position.
Vowels.
Slovene has an eight-vowel (according to Peter Jurgec nine-vowel) system, in comparison to the five-vowel system of Serbo-Croatian.
Grammar.
Nouns.
Slovene nouns retain six of the seven Slavic noun cases: nominative, accusative, genitive, dative, locative and instrumental. There is no distinct vocative; the nominative is used in that role. Nouns, adjectives and pronouns have three numbers: singular, plural and a special dual form that indicates exactly two objects.
Nouns in Slovene are either masculine, feminine or neuter gender. In addition, there is a distinction between animate and inanimate nouns, although this is only relevant for masculine nouns and only in the singular. Animate nouns have an accusative singular form that is identical to the genitive, while for inanimate nouns the accusative singular is the same as the nominative. Animacy is based mostly on semantics and is less rigid than gender. Generally speaking a noun is animate if it refers to something that is generally thought to have free will and/or the ability to move of its own accord. This includes all nouns for people and animals. All other nouns are inanimate, including plants and other non-moving life forms, and also groups of people or animals. However, there are some nouns for inanimate objects that are generally animate, which mostly include inanimate objects that are named after people or animals. This includes:
Vocabulary.
T–V distinction.
Slovene, like most other European languages, has a T–V distinction, or two forms of 'you' for formal and informal situations. Although informal address using the 2nd person singular "ti" form (known as "tikanje") is officially limited to friends and family, talk among children, and addressing animals, it is increasingly used among the middle generation to signal a relaxed attitude or lifestyle instead of its polite or formal counterpart using the 2nd person plural "vi" form (known as "vikanje").
An additional nonstandard but widespread use of a singular participle combined with a plural auxiliary verb (known as "polvikanje") signals a somewhat more friendly and less formal attitude while maintaining politeness:
The use of nonstandard forms ("polvikanje") might be frowned upon by many people and would not likely be used in a formal setting.
The use of the 3rd person plural "oni" ('they') form (known as "onikanje" in both direct address and indirect reference) as an ultra-polite form is now archaic or dialectal; it is associated with servant-master relationships in older literature, the child-parent relationship in certain conservative rural communities, and parishioner-priest relationships.
Foreign words.
Foreign words used in Slovene are of various types depending on the assimilation they have undergone. The types are:
The loanwords are mostly from German and Italian, while the more recently borrowed and less assimilated words are typically from English.
Articles.
There are no definite or indefinite articles as in English ("a", "an", "the") or German ("der", "die", "das", "ein", "eine"). A whole verb or a noun is described without articles and the grammatical gender is found from the word's termination. It is enough to say "barka" ("a" or "the barge"), "Noetova barka" ('Noah's ark'). The gender is known in this case to be feminine. In declensions, endings are normally changed; see below. If one should like to somehow distinguish between definiteness or indefiniteness of a noun, one would say "(prav/natanko/ravno) tista barka" ('that (exact) barge') for "the barge" and "neka/ena barka" ('one barge') for "a barge".
Definiteness of a noun phrase can also be discernible through the ending of the accompanying adjective. One should say "rdeči šotor" (that red tent) or "rdeč šotor" ( red tent). This difference is observable only for masculine nouns in nominative or accusative case. Because of the lack of article in Slovene and audibly insignificant difference between the masculine adjective forms, most dialects do not distinguish between definite and indefinite variants of the adjective, leading to hypercorrection when speakers try to use Standard Slovenian.
Writing system.
This alphabet () was derived in the mid-1840s from the system created by Croatianist Ljudevit Gaj. Intended for the Serbo-Croatian language (in all its varieties), it was patterned on the Czech alphabet of the 1830s. Before that was, for example, written as Esh (letter), or Long s; as , , or ; sometimes as as a relic from the now modern Russian yery character , usually transliterated as "y"; as ; as ; as ; as , or .
The standard Slovene orthography, used in almost all situations, uses only the letters of the ISO basic Latin alphabet plus , , and :
The orthography thus underdifferentiates several phonemic distinctions:
In the tonemic varieties of Slovene, the ambiguity is even worse: "e" in a final syllable can stand for any of (although is rare).
The reader is expected to gather the interpretation of the word from the context, as in these examples:
Diacritics.
To compensate for the shortcomings of the standard orthography, Slovene also uses standardized diacritics or accent marks to denote stress, vowel length and pitch accent, much like the closely related Serbo-Croatian. However, as in Serbo-Croatian, use of such accent marks is restricted to dictionaries, language textbooks and linguistic publications. In normal writing, the diacritics are almost never used, except in a few minimal pairs where real ambiguity could arise.
Two different and mutually incompatible systems of diacritics are used. The first is the simpler non-tonemic system, which can be applied to all Slovene dialects. It is more widely used and is the standard representation in dictionaries such as SSKJ. The tonemic system also includes tone as part of the representation. However, neither system reliably distinguishes schwa from the front mid-vowels, nor vocalised l from regular l . Some sources write these as "ǝ" and "ł" respectively, but this is not as common.
Non-tonemic diacritics.
In the non-tonemic system, the distinction between the two mid-vowels is indicated, as well as the placement of stress and length of vowels:
Tonemic diacritics.
The tonemic system uses the diacritics somewhat differently from the non-tonemic system. The high-mid vowels and are written "ẹ ọ" with a subscript dot, while the low-mid vowels and are written as plain "e o".
Pitch accent and length is indicated by four diacritical marks:
The schwa vowel is written ambiguously as "e", but its accentuation will sometimes distinguish it: a long vowel mark can never appear on a schwa, while a grave accent can appear only on a schwa. Thus, only "ȅ" is truly ambiguous.
Regulation.
Standard Slovene spelling and grammar are defined by the Orthographic Committee and the Fran Ramovš Institute of the Slovenian Language, which are both part of the Slovenian Academy of Sciences and Arts ("Slovenska akademija znanosti in umetnosti", SAZU). The newest reference book of standard Slovene spelling (and to some extent also grammar) is the "Slovenski pravopis" ("SP2001"; Slovene Normative Guide). The latest printed edition was published in 2001 (reprinted in 2003 with some corrections) and contains more than 130,000 dictionary entries. In 2003, an electronic version was published.
The official dictionary of modern Slovene, which was also prepared by SAZU, is "Slovar slovenskega knjižnega jezika" ("SSKJ"; Standard Slovene Dictionary). It was published in five volumes by Državna Založba Slovenije between 1970 and 1991 and contains more than 100,000 entries and subentries with accentuation, part-of-speech labels, common collocations, and various qualifiers. In the 1990s, an electronic version of the dictionary was published and it is available online.
The SAZU considers SP2001 to be the normative source on Slovenian language. When dictionary entries in SP2001 and SSKJ differ, the SP2001 entry takes precedence.

</doc>
<doc id="28136" url="https://en.wikipedia.org/wiki?curid=28136" title="Slovak language">
Slovak language

Slovak (, , or "slovenčina" ; not to be confused with "slovenski jezik","slovinščina" or "slovenščina", the native names of the Slovene language) is an Indo-European language that belongs to the West Slavic languages (together with Czech, Polish, Silesian, Kashubian, and Sorbian).
Slovak is the official language of Slovakia where it is spoken by approximately 6.17 million people (2016). Slovak speakers are also found in the United States, the Czech Republic, Argentina, Serbia, Ireland, Romania, Poland, Canada, Hungary, Croatia, the United Kingdom, Australia, Austria, Ukraine and many others worldwide.
Orthography.
Slovak uses the Latin script with small modifications that include the four diacritics (ˇ, ´, ¨, ˆ) placed above certain letters(a-á,ä; c-č; d-ď; dz-dž; e-é; i-í; l-ľ,ĺ; n-ň; o-ó,ô; r-ŕ; s-š; t-ť; u-ú; y-ý; z-ž)
The primary principle of Slovak spelling is the phonemic principle. The secondary principle is the morphological principle: forms derived from the same stem are written in the same way even if they are pronounced differently. An example of this principle is the assimilation rule (see below). The tertiary principle is the etymological principle, which can be seen in the use of "i" after certain consonants and of "y" after other consonants, although both "i" and "y" are pronounced almost, but usually the same way.
Finally, the rarely applied grammatical principle is present when, for example, the basic singular form and plural form of masculine adjectives are written differently with no difference in pronunciation (e.g. pekný = nice – singular versus pekní = nice – plural).
In addition, the following rules are present:
Most foreign words receive Slovak spelling immediately or after some time. For example, "weekend" is spelled "víkend", "software" – "softvér", "gay" – "gej" (both not exclusively), and "quality" is spelled "kvalita." Personal and geographical names from other languages using Latin alphabets keep their original spelling unless a fully Slovak form of the name exists (e.g. "Londýn" for "London").
Slovak features some heterophonic homographs (words with identical spelling but different pronunciation and meaning), the most common examples being "krásne" (beautiful) versus "krásne" (beautifully).
Syntax.
The main features of Slovak syntax are as follows:
Some examples include the following:
Word order in Slovak is relatively free, since strong inflection enables the identification of grammatical roles (subject, object, predicate, etc.) regardless of word placement. This relatively free word order allows the use of word order to convey topic and emphasis.
Some examples are as follows:
The unmarked order is subject–verb–object. Variation in word order is generally possible, but word order is not completely free.
In the above example, the noun phrase "ten veľký muž" cannot be split up, so that the following combinations are not possible:
And the following are stylistically not correct:
Morphology.
Articles.
Slovak does not have articles. The demonstrative pronoun "ten" (fem: "tá", neuter: "to") may be used in front of the noun in situations where definiteness must be made explicit.
Nouns, adjectives, pronouns.
Slovak nouns are inflected for case and number. There are six cases: nominative, genitive, dative, accusative, locative, and instrumental. The vocative is no longer morphologically marked. There are two numbers: singular and plural. Nouns have inherent gender. There are three genders: masculine, feminine, and neuter. Adjectives agree with nouns in case, number, and gender.
Numerals.
The numerals 0–10 have unique forms. 11–19 are formed by the numeral plus "násť." Compound numerals (21, 1054) are combinations of these words formed in the same order as their mathematical symbol is written (e.g. 21 = dvadsaťjeden, literally "twenty one").
The numerals are as follows:
(1) jeden (jedno (neuter), jedna (feminine)),
(2) dva (dve (neuter, feminine)),
(3) tri,
(4) štyri,
(5) päť,
(6) šesť,
(7) sedem,
(8) osem,
(9) deväť,
(10) desať, (11) jedenásť, (12) dvanásť, (13) trinásť, (14) štrnásť, (15) pätnásť, (16) šestnásť, (17) sedemnásť, (18) osemnásť, (19) devätnásť, (20) dvadsať, (21) dvadsaťjeden... (30) tridsať, (31) tridsaťjeden... (40) štyridsať... (50) päťdesiat... (60) šesťdesiat... (70) sedemdesiat... (80) osemdesiat... (90) deväťdesiat... (100) sto, (101) stojeden... (200) dvesto... (300) tristo... (900)deväťsto... (1,000) tisíc... (1,100) tisícsto... (2,000) dvetisíc... (100,000) stotisíc... (200,000) dvestotisíc... (1,000,000) milión... (1,000,000,000) miliarda...
Counted nouns have two forms. The most common form is the plural genitive (e.g. "päť domov" = five houses or "stodva žien" = one hundred two women), while the plural form of the noun when counting the amounts of 2, 3, 4, etc., is the nominative form without counting (e.g. "dva domy" = two houses or "dve ženy" = two women).
Verbs.
Verbs have three major conjugations. Three persons and two numbers (singular and plural) are distinguished. Several conjugation paradigms exist as follows:
Adverbs.
Adverbs are formed by replacing the adjectival ending with the ending -o or -e/-y. Sometimes both -o and -e are possible. Examples include the following:
The comparative/superlative of adverbs is formed by replacing the adjectival ending with a comparative/superlative ending -(ej)ší or -(ej)šie. Examples include the following:
Prepositions.
Each preposition is associated with one or more grammatical cases. The noun governed by a preposition must appear in the case required by the preposition in the given context (e.g. from friends = od priateľov). Priateľov is the genitive case of priatelia. It must appear in this case because the preposition od (=from) always calls for its objects to be in the genitive.
Po has a different meaning depending on the case of its governed noun.
Relationships to other languages.
The Slovak language is a descendant of Proto-Slavic, itself a descendant of Proto-Indo-European. It is closely related to the other West Slavic languages, primarily to Czech. It has been also influenced by German, English, Latin and Hungarian.
Czech.
Although most dialects of Czech and Slovak are mutually intelligible (see Comparison of Slovak and Czech), eastern Slovak dialects are less intelligible to speakers of Czech; they differ from Czech and from other Slovak dialects, and mutual contact between speakers of Czech and speakers of the eastern dialects is limited.
Since the dissolution of Czechoslovakia it has been permitted to use Czech in TV broadcasting and—like any other language of the world—during court proceedings (Administration Procedure Act 99/1963 Zb.). From 1999 to August 2009, the Minority Language Act 184/1999 Z.z., in its section (§) 6, contained the variously interpreted unclear provision saying that "When applying this act, it holds that the use of the Czech language fulfills the requirement of fundamental intelligibility with the state language"; the state language is Slovak and the Minority Language Act basically refers to municipalities with more than 20% ethnic minority population (no such Czech municipalities are found in Slovakia). Since 1 September 2009 (due to an amendment to the State Language Act 270/1995 Z.z.) a language "fundamentally intelligible with the state language" (i.e. the Czech language) may be used in contact with state offices and bodies by its native speakers, and documents written in it and issued by bodies in the Czech Republic are officially accepted. Regardless of its official status, Czech is used commonly both in Slovak mass media and in daily communication by Czech natives as an equal language.
Czech and Slovak have a long history of interaction and mutual influence well before the creation of Czechoslovakia in 1918. Literary Slovak shares significant orthographic features with Czech, as well as technical and professional terminology dating from the Czechoslovak period, but phonetic, grammatical, and vocabulary differences do exist.
Other Slavic languages.
Slavic language varieties tend to be closely related, and have had a large degree of mutual influence, due to the complicated ethnopolitical history of their historic ranges. This is reflected in the many features Slovak shares with neighboring language varieties. Standard Slovak shares high degrees of mutual intelligibility with many Slavic varieties. Despite this closeness to other Slavic varieties, significant variation exists among Slovak dialects. In particular, eastern varieties differ significantly from the standard language, which is based on central and western varieties.
Eastern Slovak dialects have the greatest degree of mutual intelligibility with Rusyn of all the Slovak dialects, but both lack technical terminology and upper register expressions. Polish and Sorbian also differ quite considerably from Czech and Slovak in upper registers, but non-technical and lower register speech is readily intelligible. Some mutual intelligibility occurs with spoken Rusyn, Ukrainian, and even Russian (in this order), although their orthographies are based on the Cyrillic script.
Slovak also exhibits numerous linguistic traits that set it apart from the other West Slavic languages. The Central Slovak dialect, upon which the Standard Slovak language is based, shares various features with South Slavic languages, most notably with the Kajkavian dialect of Serbo-Croatian and with Slovene language. See the table below for examples of some Slavic cognates
English.
weekend – víkend, football – futbal, ham & eggs – hemendex, offside – ofsajd, out (football) – aut,
body check (hockey) – bodyček, couch – gauč
German.
German loanwords include "coins," Slovak "mince", German "Münze"; "to wish", Slovak "vinšovať" (colloquially, the standard term is "želať"), German "wünschen"; "funfair," Slovak "jarmok ", German "Jahrmarkt" and "color," Slovak "farba", German "Farbe".
Hungarian.
Hungarians and Slovaks have had a language interaction ever since the settlement of Hungarians in the Carpathian area. Hungarians adopted many words from various Slavic languages related to agriculture and administration, and a number of Hungarian loanwords are found in Slovak. Some examples are as follows:
Romanian.
Romanian words entered the Slovak language in the course of the so-called "Wallachian colonization" in the 14th–16th century when sheep breeding became common in Slovak mountains. Many of today's Slovak rustic-pastoral words like "bača" ("shepherd"; Rmn. "baci"), "valach" ("young shepherd"; cf. the dated exonym for Romanians, "Valach"), "magura" ("hill"; Rmn. "măgura"), "koliba"("chalet"; Rmn. "coliba"), "bryndza" (a variety of sheep cheese; Rmn. "brânză"), "striga" ("witch", "demon"; Rmn. "strigă/strigoi"), etc. were introduced into the Slovak language by Romanian shepherds during the Late Middle Ages and the Early Modern Times. The Romanian influence is most strongly felt in the dialects of the Moravian Wallachia region.
Dialects.
There are many Slovak dialects, which are divided into the following four basic groups:
The fourth group of dialects is often not considered a separate group, but a subgroup of Central and Western Slovak dialects (see e.g. Štolc, 1968), but it is currently undergoing changes due to contact with surrounding languages (Serbo-Croatian, Romanian, and Hungarian) and long-time geographical separation from Slovakia (see the studies in "Zborník Spolku vojvodinských slovakistov", e.g. Dudok, 1993).
For an external map of the three groups in Slovakia see here.
The dialect groups differ mostly in phonology, vocabulary, and tonal inflection. Syntactic differences are minor. Central Slovak forms the basis of the present-day standard language. Not all dialects are fully mutually intelligible. It may be difficult for an inhabitant of the western Slovakia to understand a dialect from eastern Slovakia and the other way around.
The dialects are fragmented geographically, separated by numerous mountain ranges. The first three groups already existed in the 10th century. All of them are spoken by the Slovaks outside Slovakia (USA, Canada, Croatian Slavonia, and elsewhere), and central and western dialects form the basis of the lowland dialects (see above).
The western dialects contain features common with the Moravian dialects in the Czech Republic, the southern central dialects contain a few features common with South Slavic languages, and the eastern dialects a few features common with Polish and the East Slavonic languages (cf. Štolc, 1994). Lowland dialects share some words and areal features with the languages surrounding them (Serbo-Croatian, Hungarian, and Romanian).

</doc>
<doc id="28142" url="https://en.wikipedia.org/wiki?curid=28142" title="Supercluster">
Supercluster

Superclusters are large groups of smaller galaxy clusters or galaxy groups and are among the largest known structures of the cosmos. The Milky Way is in the Local Group galaxy cluster (that contains more than 54 galaxies), which in turn is in the Laniakea Supercluster. This supercluster spans over 500 million light years, while the Local Group spans over 10 million light years. The number of superclusters in the observable universe is estimated to be 10 million.
Galaxies are grouped into clusters instead of being dispersed randomly. Clusters of galaxies are grouped together to form superclusters. Typically, superclusters contain dozens of individual clusters throughout an area of space about 150 million lightyears across. Unlike clusters, superclusters are not bound together by gravity. They are all shifting away from each other due to the Hubble flow.
The Milky Way galaxy falls within the Local Group, which is a poor and irregular cluster of galaxies. Poor clusters may contain only a few dozen galaxies as compared to rich clusters that can contain hundreds or even thousands. The Local Group is near the Local Supercluster (also known as the Virgo Supercluster) which has a diameter of 100 million lightyears. The Local Supercluster contains a total of about 1015 times the mass of the Sun.
The biggest cluster in the local universe is called the Great Attractor. Its gravity is so strong that the Local Supercluster, including the Milky Way, is moving in a direction towards it at a rate of several hundred kilometers per second. The biggest supercluster outside of the local universe is the Perseus-Pegasus Filament. It contains the Perseus supercluster and it spans about a billion light years, making it the largest known structure in the universe.
Distribution: cosmic voids and sheets.
Research has been done to try to understand the way in which superclusters are arranged in space. Maps are used to display the positions of 1.6 million galaxies. Three-dimensional maps are used to further understand the positions of these superclusters. In order to map them three-dimensionally, the position of the galaxy in the sky as well as the galaxy's redshift are used for calculation. The galaxy's redshift is used with Hubble's Law in order to determine its position in three-dimensional space.
It was discovered from those maps that superclusters of galaxies are not spread uniformly across the universe but they seem to lie along filaments. Maps reveal huge voids where there are extremely few galaxies. Some dim galaxies or hydrogen clouds can be found in some voids, but most galaxies are found in sheets between the voids. The voids themselves are often spherical but the superclusters are not. They can range from being 100 million to 400 million lightyears in diameter. The pattern of sheets and voids contains information about how galaxy clusters formed in the early universe.
There is a sponge analogy used often that compares a sponge to the pattern of clusters of galaxies in the universe – the holes are the voids and the other parts are the locations of the superclusters.
Existence.
The existence of superclusters indicates that the galaxies in our Universe are not uniformly distributed; most of them are drawn together in groups and clusters, with groups containing up to some dozens of galaxies and clusters up to several thousand galaxies. Those groups and clusters and additional isolated galaxies in turn form even larger structures called superclusters.
Their existence was first postulated by George Abell in his 1958 Abell catalogue of galaxy clusters. He called them "second-order clusters", or clusters of clusters.
Superclusters form massive structures of galaxies, called "filaments", "supercluster complexes", "walls" or "sheets", that may span between several hundred million light-years to 10 billion light-years, covering more than 5% of the observable universe. Observations of superclusters likely tell us something about the initial condition of the universe when these superclusters were created. The directions of the rotational axes of galaxies within superclusters may also give us insight and information into the early formation process of galaxies in the history of the Universe.
Interspersed among superclusters are large voids of space in which few galaxies exist. Superclusters are frequently subdivided into groups of clusters called galaxy clouds.

</doc>
<doc id="28143" url="https://en.wikipedia.org/wiki?curid=28143" title="Salicylic acid">
Salicylic acid

Salicylic acid (from Latin "salix", "willow tree", from the bark of which the substance used to be obtained) is a monohydroxybenzoic acid, a type of phenolic acid and a beta hydroxy acid. It has the formula C7H6O3. This colorless crystalline organic acid is widely used in organic synthesis and functions as a plant hormone. It is derived from the metabolism of salicin. In addition to being an important active metabolite of aspirin ("acetylsalicylic acid"), which acts in part as a prodrug to salicylic acid, it is probably best known for its use as a key ingredient in topical anti-acne products. The salts and esters of salicylic acid are known as salicylates.
It is on the WHO Model List of Essential Medicines, the most important medications needed in a basic health system.
Medicinal uses.
Salicylic acid is known for its ability to ease aches and pains and reduce fevers. These medicinal properties, particularly fever relief, have been known since ancient times, and it is used as an anti-inflammatory drug.
In modern medicine, salicylic acid and its derivatives are constituents of some rubefacient products. For example, methyl salicylate is used as a liniment to soothe joint and muscle pain, and choline salicylate is used topically to relieve the pain of mouth ulcers.
As with other hydroxy acids, salicylic acid is a key ingredient in many skin-care products for the treatment of seborrhoeic dermatitis, acne, psoriasis, calluses, corns, keratosis pilaris, acanthosis nigricans, ichthyosis, and warts. The standard treatment for calluses is a 6% aspirin suspension in petroleum jelly, applied on the callus for one hour and then removed with washing. Salicylic acid works as a keratolytic, comedolytic, and bacteriostatic agent, causing the cells of the epidermis to shed more readily, opening clogged pores and neutralizing bacteria within, preventing pores from clogging up again by constricting pore diameter, and allowing room for new cell growth. Because of its effect on skin cells, salicylic acid is used in some shampoos to treat dandruff. Concentrated solutions of salicylic acid may cause hyperpigmentation on people with darker skin types (Fitzpatrick phototypes IV, V, VI), without a broad spectrum sunblock.
Bismuth subsalicylate, a salt of bismuth and salicylic acid, is the active ingredient in stomach relief aids such as Pepto-Bismol, is the main ingredient of Kaopectate, and "displays anti-inflammatory action (due to salicylic acid) and also acts as an antacid and mild antibiotic".
Salicylic acid is used in the production of other pharmaceuticals including 4-aminosalicylic acid, sulpiride, letimide (via Salethamide).
Chemistry.
Salicylic acid has the formula C6H4(OH)COOH, where the OH group is "ortho" to the carboxyl group. It is also known as 2-hydroxybenzoic acid. It is poorly soluble in water (2 g/L at 20 °C). Aspirin (acetylsalicylic acid or ASA) can be prepared by the esterification of the phenolic hydroxyl group of salicylic acid with the acetyl group from acetic anhydride or acetyl chloride. It can also be prepared using the Kolbe-Schmitt reaction.
Plant hormone.
Salicylic acid (SA) is a phenolic phytohormone and is found in plants with roles in plant growth and development, photosynthesis, transpiration, ion uptake and transport. SA also induces specific changes in leaf anatomy and chloroplast structure. SA is involved in endogenous signaling, mediating in plant defense against pathogens. It plays a role in the resistance to pathogens by inducing the production of pathogenesis-related proteins. It is involved in the systemic acquired resistance (SAR) in which a pathogenic attack on one part of the plant induces resistance in other parts. The signal can also move to nearby plants by salicylic acid being converted to the volatile ester, methyl salicylate.
Production.
Salicylic acid is biosynthesized from the amino acid phenylalanine. In "Arabidopsis thaliana" it can also be synthesized via a phenylalanine-independent pathway.
Sodium salicylate is commercially prepared by treating sodium phenolate (the sodium salt of phenol) with carbon dioxide at high pressure (100 atm) and high temperature (390 K) – a method known as the Kolbe-Schmitt reaction. Acidification of the product with sulfuric acid gives salicylic acid:
It can also be prepared by the hydrolysis of aspirin (acetylsalicylic acid) or methyl salicylate (oil of wintergreen) with a strong acid or base.
History.
Hippocrates, Galen, Pliny the Elder and others knew willow bark could ease aches and pains and reduce fevers. It has long been used in Europe and China for the treatment of these conditions. This remedy is also mentioned in texts from ancient Egypt, Sumer, and Assyria. The Cherokee and other Native Americans used an infusion of the bark for fever and other medicinal purposes. The medicinal part of the plant is the inner bark and was used as a pain reliever for a variety of ailments. In 2014, archaeologists identified traces of salicylic acid on 7th century pottery fragments found in east central Colorado. The Reverend Edward Stone, a vicar from Chipping Norton, Oxfordshire, England, noted in 1763 that the bark of the willow was effective in reducing a fever.
The active extract of the bark, called "salicin", after the Latin name for the white willow ("Salix alba"), was isolated and named by the German chemist Johann Andreas Buchner in 1828. A larger amount of the substance was isolated in 1829 by Henri Leroux, a French pharmacist. Raffaele Piria, an Italian chemist, was able to convert the substance into a sugar and a second component, which on oxidation becomes salicylic acid.
Salicylic acid was also isolated from the herb meadowsweet ("Filipendula ulmaria", formerly classified as "Spiraea ulmaria") by German researchers in 1839. While their extract was somewhat effective, it also caused digestive problems such as gastric irritation, bleeding, diarrhea, and even death when consumed in high doses.
Dietary sources.
Unripe fruits and vegetables are natural sources of salicylic acid, particularly blackberries, blueberries, cantaloupes, dates, grapes, kiwi fruits, guavas, apricots, green pepper, olives, tomatoes, radish and chicory; also mushrooms. Some herbs and spices contain quite high amounts, while meat, poultry, fish, eggs and dairy products all have little to no salicylates. Of the legumes, seeds, nuts, and cereals, only almonds, water chestnuts and peanuts have significant amounts.
Mechanism of action.
Salicylic acid has been shown to work through several different pathways. It produces its anti-inflammatory effects via suppressing the activity of cyclooxygenase (COX), an enzyme that is responsible for the production of pro-inflammatory mediators such as the prostaglandins. It does this not by direct inhibition of COX like most other non-steroidal anti-inflammatory drugs (NSAIDs) but instead by suppression of the expression of the enzyme through a yet-unelucidated mechanism. Salicylic acid has also been shown to activate adenosine monophosphate-activated protein kinase (AMPK), and this action may play a role in the anticancer effects of the compound and its prodrugs aspirin and salsalate. In addition, the antidiabetic effects of salicylic acid are likely mediated by AMPK activation primarily through allosteric conformational change that increases levels of phosphorylation. Salicylic acid also uncouples oxidative phosphorylation, which leads to increased ADP:ATP and AMP:ATP ratios in the cell. As a consequence, salicylic acid may alter AMPK activity and work as an anti-diabetic by altering the energy status of the cell. Even in AMPK knock-out mice, however, there is an anti-diabetic effect, demonstrating that there is at least one additional, yet-unidentified action of the compound. Salicylic acid has been shown to regulate c-Myc level at both transcriptional and post-transcription levels. Inhibition of c-Myc may be an important pathway by which aspirin exerts its anti-cancer effect, decreasing the occurrence of cancer in epithelial tissues.
Other uses.
Salicylic acid is used as a food preservative, a bactericidal, and an antiseptic.
Sodium salicylate is a useful phosphor in the vacuum ultraviolet, with nearly flat quantum efficiency for wavelengths between 10 and 100 nm. It fluoresces in the blue at 420 nm. It is easily prepared on a clean surface by spraying a saturated solution of the salt in methanol followed by evaporation.
Safety.
As a topical agent, and as a beta-hydroxy acid (and unlike alpha-hydroxy acids), salicylic acid is capable of penetrating and breaking down fats and lipids, causing moderate chemical burns of the skin at very high concentrations, and may damage the lining of pores in such cases if the solvent is alcohol, acetone, or an oil. Over-the-counter limits are set at 2% for topical preparations expected to be left on the face, and 3% for those expected to be washed off, such as acne cleansers or shampoo. 17% and 27% salicylic acid, which is often sold for wart removal, should not be applied to the face and should not be used for acne treatment. Even for wart removal, such a solution should be applied once or twice a day – more frequent use may lead to an increase in side-effects without an increase in efficacy.
When ingested, salicylic acid has a possible ototoxic effect by inhibiting prestin. It can induce transient hearing loss in zinc-deficient individuals. This finding is based on clinical studies with rats. An injection of salicylic acid induced hearing loss in zinc-deficient rats, while a simultaneous injection of zinc reversed the hearing loss. An injection of magnesium in the zinc-deficient rats did not reverse the induced hearing loss.
There have been no studies specific to topical salicylic acid in pregnancy. Oral salicylic acid has not been associated with an increase in malformations if used during the first trimester, but use of aspirin in late pregnancy has been associated with bleeding, especially intracranial bleeding. The risks of aspirin late in pregnancy are probably not relevant for a topical exposure to salicylic acid, even late in the pregnancy, because of its low systemic levels. Topical salicylic acid is common in many over-the-counter dermatological agents, and the lack of adverse reports suggests a low teratogenic potential.
Salicylic acid overdose can lead to salicylate intoxication, which often presents clinically in a state of metabolic acidosis with compensatory respiratory alkalosis. In patients presenting with an acute overdose, a 16% morbidity rate and a 1% mortality rate are observed.
Some people are hypersensitive to salicylic acid and related compounds.
The United States Food and Drug Administration (FDA) recommends the use of sun protection when using skincare products containing salicylic acid (or any other BHA) on sun-exposed skin areas.
There are data that support an association between exposure to salicylic acid and Reye's Syndrome. The National Reye's Syndrome Foundation cautions against the use of these and other substances similar to aspirin on children and adolescents. Epidemiological research has shown an association between the development of Reye's Syndrome and the use of aspirin (a salicylate compound) for treating the symptoms of influenza-like illnesses, chicken pox, colds, etc. The U.S. Surgeon General, the FDA, the Centers for Disease Control and Prevention, and the American Academy of Pediatrics recommend that aspirin and combination products containing aspirin not be given to children under 19 years of age during episodes of fever-causing illnesses for this reason.

</doc>
<doc id="28144" url="https://en.wikipedia.org/wiki?curid=28144" title="Seaborgium">
Seaborgium

Seaborgium is a synthetic element with symbol Sg and atomic number 106. Its most stable isotope 271Sg has a half-life of 1.9 minutes. A more recently discovered isotope 269Sg has a potentially slightly longer half-life (ca. 2.1 min) based on the observation of a single decay. Chemistry experiments with seaborgium have firmly placed it in group 6 as a heavier homologue to tungsten. Seaborgium is named after Glenn T. Seaborg who was alive at the time the naming was publicized.
Seaborgium belongs to the family of transuranium elements. The element was the first to be named after a living person. 
History.
Discovery.
Scientists working at the Joint Institute for Nuclear Research in Dubna, USSR reported their discovery of element 106 in June 1974.
Synthesis was also reported in September 1974 at the Super HILAC accelerator at the Lawrence Berkeley Laboratory by a joint Lawrence Berkeley/Lawrence Livermore collaboration led by Albert Ghiorso and E. Kenneth Hulet.
They produced the new nuclide by bombarding a target of with ions.
This nuclide decays by α emission with a half-life of 0.9 ± 0.2 seconds.
Naming.
The Berkeley/Livermore collaboration suggested the name "seaborgium" (Sg) to honor the American chemist Glenn T. Seaborg credited as a member of the American group in recognition of his participation in the discovery of several other actinides. The name selected by the team became controversial. The IUPAC adopted "unnilhexium" (symbol "Unh") as a temporary, systematic element name. In 1994 a committee of IUPAC recommended that element 106 be named "rutherfordium" and adopted a rule that no element can be named after a living person. This ruling was fiercely objected to by the American Chemical Society. Critics pointed out that a precedent had been set when einsteinium was proposed as a name during Albert Einstein's life and a survey indicated that chemists were not concerned with the fact that Seaborg was still alive. In 1997, as part of a compromise involving elements 104 to 108, the name "seaborgium" for element 106 was recognized internationally. The name rutherfordium was assigned to element 104 instead.
Chemical properties.
Extrapolated properties.
Seaborgium is projected to be the third member of the 6d series of transition metals and the heaviest member of group 6 in the Periodic Table, below chromium, molybdenum and tungsten. All the members of the group readily portray their group oxidation state of +6 and the state becomes more stable as the group is descended. Thus seaborgium is expected to form a stable +6 state. For this group, stable +5 and +4 states are well represented for the heavier members and the +3 state is known but reducing, except for chromium(III).
Much seaborgium chemical behavior is predicted by extrapolation from its lighter congeners molybdenum and tungsten. Molybdenum and tungsten readily form stable trioxides MO3, so seaborgium should form SgO3. The oxides MO3 are soluble in alkali with the formation of oxyanions, so seaborgium should form a seaborgate ion, SgO42−. In addition, WO3 reacts with acid, suggesting similar amphotericity for SgO3. Molybdenum oxide, MoO3, also reacts with moisture to form a hydroxide MoO2(OH)2, so SgO2(OH)2 is also feasible. The heavier homologues readily form the volatile, reactive hexahalides MX6 (X=Cl,F). Only tungsten forms the unstable hexabromide, WBr6. Therefore, the compounds SgF6 and SgCl6 are predicted, and "eka-tungsten character" may show itself in increased stability of the hexabromide, SgBr6. These halides are unstable to oxygen and moisture and readily form volatile oxyhalides, MOX4 and MO2X2. Therefore, SgOX4 (X=F,Cl) and SgO2X2 (X=F,Cl) should be possible. In aqueous solution, a variety of anionic oxyfluoro-complexes are formed with fluoride ion, examples being MOF5− and MO3F33−. Similar seaborgium complexes are expected.
Experimental chemistry.
Gas phase.
Initial experiments aiming at probing the chemistry of seaborgium focused on the gas thermochromatography of a volatile oxychloride. Seaborgium atoms were produced in the reaction 248Cm(22Ne,4n)266Sg, thermalised, and reacted with an O2/HCl mixture. The adsorption properties of the resulting oxychloride were measured and compared with those of molybdenum and tungsten compounds. The results indicated that seaborgium formed a volatile oxychloride akin to those of the other group 6 elements:
In 2001, a team continued the study of the gas phase chemistry of seaborgium by reacting the element with O2 in a H2O environment. In a manner similar to the formation of the oxychloride, the results of the experiment indicated the formation of seaborgium oxide hydroxide, a reaction well known among the lighter group 6 homologues.
Aqueous phase.
In its aqueous chemistry, seaborgium has been shown to resemble its lighter homologues molybdenum and tungsten, forming a stable +6 oxidation state. Seaborgium was eluted from cation exchange resin using a HNO3/HF solution, most likely as neutral SgO2F2 or the anionic complex ion In contrast, in 0.1 M HNO3, seaborgium does not elute, unlike Mo and W, indicating that the hydrolysis of [Sg(H2O)66+ only proceeds as far as the cationic complex [Sg(OH)5(H2O)]+.
Nucleosynthesis.
Cold fusion experiments.
"This section deals with the synthesis of nuclei of seaborgium by so-called "cold" fusion reactions. These are processes which create compound nuclei at low excitation energy (~10–20 MeV, hence "cold"), leading to a higher probability of survival from fission. The excited nucleus then decays to the ground state via the emission of one or two neutrons only."
The first attempt to synthesise seaborgium in cold fusion reactions was performed in September 1974 by a Soviet team led by G. N. Flerov at the Joint Institute for Nuclear Research at Dubna. They reported producing a 0.48 s spontaneous fission (SF) activity which they assigned to the isotope 259Sg. Based on later evidence it was suggested that the team most likely measured the decay of 260Sg and its daughter 256Rf. The TWG concluded that, at the time, the results were insufficiently convincing.
The Dubna team revisited this problem in 1983–1984 and were able to detect a 5 ms SF activity assigned directly to 260Sg.
The team at GSI studied this reaction for the first time in 1985 using the improved method of correlation of genetic parent-daughter decays. They were able to detect 261Sg (x=1) and 260Sg and measured a partial 1n neutron evaporation excitation function.
In December 2000 a team at GANIL, France studied the reaction and were able to detect 10 atoms of 261Sg and 2 atoms of 260Sg to add to previous data on the reaction.
After a facility upgrade, the GSI team measured the 1n excitation function in 2003 using a metallic lead target. Of significance, in May 2003, the team successfully replaced the lead-208 target with more resistant lead(II) sulfide targets (PbS) which will allow more intense beams to be used in the future. They were able to measure the 1n,2n and 3n excitation functions and performed the first detailed alpha-gamma spectroscopy on the isotope 261Sg. They detected ~1600 atoms of the isotope and identified new alpha lines as well as measuring a more accurate half-life and new EC and SF branchings. Furthermore, they were able to detect the K X-rays from the daughter rutherfordium element for the first time. They were also able to provide improved data for 260Sg, including the tentative observation of an isomeric level. The study was continued in September 2005 and March 2006. The accumulated work on 261Sg was published in 2007.
Work in September 2005 also aimed to begin spectroscopic studies on 260Sg.
The team at the LBNL recently restudied this reaction in an effort to look at the spectroscopy of the isotope 261Sg. They were able to detect a new isomer, 261mSg, decaying by internal conversion into the ground state. In the same experiment, they were also able to confirm a K-isomer in the daughter 257Rf, namely 257m2Rf.
The team at Dubna also studied this reaction in 1974 with identical results as for their first experiments with a Pb-208 target. The SF activities were first assigned to 259Sg and later to 260Sg and/or 256Rf. Further work in 1983–1984 also detected a 5 ms SF activity assigned to the parent 260Sg.
The GSI team studied this reaction for the first time in 1985 using the method of correlation of genetic parent-daughter decays. They were able to positively identify 259Sg as a product from the 2n neutron evaporation channel.
The reaction was further used in March 2005 using PbS targets to begin a spectroscopic study of the even-even isotope 260Sg.
This reaction was studied in 1974 by the team at Dubna. It was used to assist them in their assignment of the observed SF activities in reactions using Pb-207 and Pb-208 targets. They were unable to detect any SF, indicating the formation of isotopes decaying primarily by alpha decay.
The team at Dubna also studied this reaction in their series of cold fusion reactions performed in 1974. Once again they were unable to detect any SF activities. The reaction was revisited in 2006 by the team at LBNL as part of their studies on the effect of the isospin of the projectile and hence the mass number of the compound nucleus on the yield of evaporation residues. They were able to identify 259Sg and 258Sg in their measurement of the 1n excitation function.
The team at Dubna also studied this reaction in their series of cold fusion reactions performed in 1974. Once again they were unable to detect any SF activities.
In 1994, the synthesis of seaborgium was revisited using this reaction by the GSI team, in order to study the new even-even isotope 258Sg. Ten atoms of 258Sg were detected and decayed by spontaneous fission.
Hot fusion experiments.
"This section deals with the synthesis of nuclei of seaborgium by so-called "hot" fusion reactions. These are processes which create compound nuclei at high excitation energy (~40–50 MeV, hence "hot"), leading to a reduced probability of survival from fission and quasi-fission. The excited nucleus then decays to the ground state via the emission of 3–5 neutrons."
This reaction was first studied by Japanese scientists at the Japan Atomic Energy Research Institute (JAERI) in 1998. They detected a spontaneous fission activity which they tentatively assigned to the new isotope 264Sg or 263Db, formed by EC of 263Sg.
In 2006, the teams at GSI and LBNL both studied this reaction using the method of correlation of genetic parent-daughter decays. The LBNL team measured an excitation function for the 4n,5n and 6n channels, whilst the GSI team were able to observe an additional 3n activity. Both teams were able to identify the new isotope 264Sg which decayed with a short lifetime by spontaneous fission.
In 1993, at Dubna, Yuri Lazarev and his team announced the discovery of long-lived 266Sg and 265Sg produced in the 4n and 5n channels of this nuclear reaction following the search for seaborgium isotopes suitable for a first chemical study.
It was announced that 266Sg decayed by 8.57 MeV alpha-particle emission with a projected half-life of ~20 s, lending strong support to the stabilising effect of the Z=108,N=162 closed shells.
This reaction was studied further in 1997 by a team at GSI and the yield, decay mode and half-lives for 266Sg and 265Sg have been confirmed, although there are still some discrepancies. In the recent synthesis of 270Hs (see hassium), 266Sg was found to undergo exclusively SF with a short half-life (TSF = 360 ms). It is possible that this is the ground state, (266gSg) and that the other activity, produced directly, belongs to a high spin K-isomer, 266mSg, but further results are required to confirm this.
A recent re-evaluation of the decay characteristics of 265Sg and 266Sg has suggested that all decays to date in this reaction were in fact from 265Sg, which exists in two isomeric forms. The first, 265aSg has a principal alpha-line at 8.85 MeV and a calculated half-life of 8.9 s, whilst 265bSg has a decay energy of 8.70 MeV and a half-life of 16.2 s. Both isomeric levels are populated when produced directly. Data from the decay of 269Hs indicates that 265bSg is produced during the decay of 269Hs and that 265bSg decays into the shorter-lived 261gRf isotope. This means that the observation of 266Sg as a long-lived alpha emitter is retracted and that it does indeed undergo fission in a short time.
Regardless of these assignments, the reaction has been successfully used in the recent attempts to study the chemistry of seaborgium (see below).
The synthesis of seaborgium was first realized in 1974 by the LBNL/LLNL team. In their discovery experiment, they were able to apply the new method of correlation of genetic parent-daughter decays to identify the new isotope 263Sg. In 1975, the team at Oak Ridge were able to confirm the decay data but were unable to identify coincident X-rays in order to prove that seaborgium was produced. In 1979, the team at Dubna studied the reaction by detection of SF activities. In comparison with data from Berkeley, they calculated a 70% SF branching for 263Sg. The original synthesis and discovery reaction was confirmed in 1994 by a different team at LBNL.
As decay product.
Isotopes of seaborgium have also been observed in the decay of heavier elements. Observations to date are summarised in the table below:
Isotopes.
There are 14 known isotopes of seaborgium (excluding meta-stable and K-spin isomers). The longest-lived is currently 269Sg which decays through alpha decay and spontaneous fission, with a half-life of around 2.1 minutes. The shortest-lived isotope is 258Sg which also decays through alpha decay and spontaneous fission. It has a half-life of 2.9 ms.
Nuclear isomerism.
Initial work identified an 8.63 MeV alpha-decaying activity with a half-life of ~21s and assigned to the ground state of 266Sg. Later work identified a nuclide decaying by 8.52 and 8.77 MeV alpha emission with a half-life of ~21s, which is unusual for an even-even nuclide. Recent work on the synthesis of 270Hs identified 266Sg decaying by SF with a short 360 ms half-life. The recent work on 277Cn and 269Hs has provided new information on the decay of 265Sg and 261Rf. This work suggested that the initial 8.77 MeV activity should be reassigned to 265Sg. Therefore, the current information suggests that the SF activity is the ground state and the 8.52 MeV activity is a high spin K-isomer. Further work is required to confirm these assignments. A recent re-evaluation of the data has suggested that the 8.52 MeV activity should be associated with 265Sg and that 266Sg only undergoes fission.
The recent direct synthesis of 265Sg resulted in four alpha-lines at 8.94,8.84,8.76 and 8.69 MeV with a half-life of 7.4 seconds. The observation of the decay of 265Sg from the decay of 277Cn and 269Hs indicated that the 8.69 MeV line may be associated with an isomeric level with an associated half-life of ~ 20 s. It is plausible that this level is causing confusion between assignments of 266Sg and 265Sg since both can decay to fissioning rutherfordium isotopes.
A recent re-evaluation of the data has indicated that there are indeed two isomers, one with a principal decay energy of 8.85 MeV with a half-life of 8.9 s, and a second isomer which decays with energy 8.70 MeV with a half-life of 16.2 s.
The discovery synthesis of 263Sg resulted in an alpha-line at 9.06 MeV. Observation of this nuclide by decay of 271gDs, 271mDs and 267Hs has confirmed an isomer decaying by 9.25 MeV alpha emission. The 9.06 MeV decay was also confirmed. The 9.06 MeV activity has been assigned to the ground state isomer with an associated half-life of 0.3 s. The 9.25 MeV activity has been assigned to an isomeric level decaying with a half-life of 0.9 s.
Recent work on the synthesis of 271g,mDs was resulted in some confusing data regarding the decay of 267Hs. In one such decay, 267Hs decayed to 263Sg which decayed by alpha emission with a half-life of ~ 6 s. This activity has not yet been positively assigned to an isomer and further research is required.
Retracted isotopes.
In the claimed synthesis of 293Uuo in 1999 the isotope 269Sg was identified as a daughter product. It decayed by 8.74 MeV alpha emission with a half-life of 22 s. The claim was retracted in 2001. This isotope was finally created in 2010.

</doc>
<doc id="28145" url="https://en.wikipedia.org/wiki?curid=28145" title="September 15">
September 15


</doc>
<doc id="28146" url="https://en.wikipedia.org/wiki?curid=28146" title="September 18">
September 18


</doc>
<doc id="28147" url="https://en.wikipedia.org/wiki?curid=28147" title="September 19">
September 19


</doc>
<doc id="28148" url="https://en.wikipedia.org/wiki?curid=28148" title="September 20">
September 20


</doc>
<doc id="28149" url="https://en.wikipedia.org/wiki?curid=28149" title="Serpens">
Serpens

Serpens ("the Serpent", Greek ) is a constellation of the northern hemisphere. One of the 48 constellations listed by the 2nd-century astronomer Ptolemy, it remains one of the 88 modern constellations defined by the International Astronomical Union. It is unique among the modern constellations in being split into two non-contiguous parts, Serpens Caput (Serpent Head) to the west and Serpens Cauda (Serpent Tail) to the east. Between these two halves lies the constellation of Ophiuchus, the "Serpent-Bearer". In figurative representations, the body of the serpent is represented as passing behind Ophiuchus between Mu Serpentis in "Serpens Caput" and Nu Serpentis in "Serpens Cauda".
The brightest star in Serpens is the red giant star Alpha Serpentis, or Unukalhai, in Serpens Caput, with an apparent magnitude of 2.63. Also located in Serpens Caput are the naked-eye globular cluster Messier 5 and the naked-eye variables R Serpentis and Tau4 Serpentis. Notable extragalactic objects include Seyfert's Sextet, one of the densest galaxy clusters known; Arp 220, the prototypical ultraluminous infrared galaxy; and Hoag's Object, the most famous of the very rare class of galaxies known as ring galaxies.
Part of the Milky Way's galactic plane passes through Serpens Cauda, which is therefore rich in galactic deep-sky objects, such as the Eagle Nebula (IC 4703) and its associated star cluster Messier 16. The nebula measures 70 light-years by 50 light-years and contains the Pillars of Creation, three dust clouds that became famous for the image taken by the Hubble Space Telescope. Other striking objects include the Red Square Nebula, one of the few objects in astronomy to take on a square shape; and Westerhout 40, a massive nearby star-forming region consisting of a molecular cloud and an H II region.
History.
In Greek mythology, Serpens represents a snake held by the healer Asclepius. Represented in the sky by the constellation Ophiuchus, Asclepius once killed a snake, but the animal was subsequently resurrected after a second snake placed a revival herb on it before its death. As snakes shed their skin every year, they were known as the symbol of rebirth in ancient Greek society, and legend says Asclepius would revive dead humans using the same technique he witnessed. Although this is likely the logic for Serpens' presence with Ophiuchus, the true reason is still not fully known. Sometimes, Serpens was depicted as coiling around Ophiuchus, but the majority of atlases showed Serpens passing either behind Ophiuchus' body or between his legs.
In some ancient atlases, the constellations Serpens and Ophiuchus were depicted as two separate constellations, although more often they were shown as a single constellation. One notable figure to depict Serpens separately was Johann Bayer; thus, Serpens' stars are cataloged with separate Bayer designations from those of Ophiuchus. When Eugène Delporte established modern constellation boundaries in the 1920s, he elected to depict the two separately. However, this posed the problem of how to disentangle the two constellations, with Deporte deciding to split Serpens into two areas—the head and the tail—separated by the continuous Ophiuchus. These two areas became known as Serpens Caput and Serpens Cauda, "caput" being the Latin word for head and "cauda" the Latin word for tail.
In Chinese astronomy, most of the stars of Serpens represented part of a wall surrounding a marketplace, known as Tianshi, which was in Ophiuchus and part of Hercules. Serpens also contains a few Chinese constellations. Two stars in the tail represented part of Shilou, the tower with the market office. Another star in the tail represented Liesi, jewel shops. One star in the head (Mu Serpentis) marked Tianru, the crown prince's wet nurse, or sometimes rain.
There were two "serpent" constellations in Babylonian astronomy, known as Mušḫuššu and Bašmu. It appears that Mušḫuššu was depicted as a hybrid of a dragon, a lion and a bird, and loosely corresponded to Hydra. Bašmu was a horned serpent (c.f. Ningishzida) and roughly corresponds to the Ὄφις constellation of Eudoxus of Cnidus on which the Ὄφις ("Serpens") of Ptolemy is based.
Characteristics.
Serpens is the only one of the 88 modern constellations to be split into two disconnected regions in the sky: "Serpens Caput" (the head) and "Serpens Cauda" (the tail). The constellation is also unusual in that it depends on another constellation for context; specifically, it is being held by the Serpent Bearer Ophiuchus.
Serpens Caput is bordered by Libra to the south, Virgo and Boötes to the east, Corona Borealis to the north, and Ophiuchus and Hercules to the west; Serpens Cauda is bordered by Sagittarius to the south, Scutum and Aquila to the east, and Ophiuchus to the north and west. Covering 636.9 square degrees total, it ranks 23rd of the 88 constellations in size. It appears prominently in both the northern and southern skies during the Northern Hemisphere's summer. Its main asterism consists of 11 stars, and 108 stars in total are brighter than magnitude 6.5, the traditional limit for naked-eye visibility.
Serpens Caput's boundaries, as set by Eugène Delporte in 1930, are defined by a 15-sided polygon, while Serpens Cauda's are defined by a 25-sided polygon. In the equatorial coordinate system, the right ascension coordinates of Serpens Caput's borders lie between and , while the declination coordinates are between and . Serpens Cauda's boundaries lie between right ascensions of and and declinations of and . The International Astronomical Union (IAU) adopted the three-letter abbreviation "Ser" for the constellation in 1922.
Notable features.
Stars.
Head stars.
Marking the heart of the serpent is the constellation's brightest star, Alpha Serpentis. Traditionally called Unukalhai, is a red giant of spectral type K2III located approximately 23 parsecs distant with a visual magnitude of 2.630 ± 0.009, meaning it can easily be seen with the naked eye even in areas with substantial light pollution. A faint companion is in orbit around the red giant star, although it is not visible to the naked eye. Situated near Alpha is Lambda Serpentis, a magnitude 4.42 ± 0.05 star rather similar to the Sun positioned only 12 parsecs away. Another solar analog in Serpens is the primary of Psi Serpentis, a binary star located slightly further away at approximately 14 parsecs.
Beta, Gamma, and Iota Serpentis form a distinctive triangular shape marking the head of the snake, with Kappa Serpentis being roughly midway between Gamma and Iota. The brightest of the four with an apparent magnitude of roughly 3.67, Beta Serpentis is a white main-sequence star roughly 160 parsecs distant. It is likely that a nearby 10th-magnitude star is physically associated with Beta, although it is not certain. The Mira variable R Serpentis, situated between Beta and Gamma, is visible to the naked eye at its maximum of 5th-magnitude, but, typical of Mira variables, it can fade to below magnitude 14. Gamma Serpentis itself is an F-type subgiant located only 11 parsecs distant and thus is quite bright, being of magnitude 3.84 ± 0.05. The star is known to show solar-like oscillations.
Delta Serpentis, forming part of the body of the snake between the heart and the head, is a multiple star system positioned around 70 parsecs from Earth. Consisting of four stars, the system has a total apparent magnitude of 3.79 as viewed from Earth, although two of the stars, with a combined apparent magnitude of 3.80, provide nearly all the light. The primary, a white subgiant, is a Delta Scuti variable with an average apparent magnitude of 4.23. Positioned very near Delta, both in the night sky and likely in actual space at an estimated distance of around 70 parsecs, is the barium star 16 Serpentis. Another notable variable star visible to the naked eye is Chi Serpentis, an Alpha² Canum Venaticorum variable situated midway between Delta and Beta which varies from its median brightness of 5.33 by 0.03 magnitudes over a period of approximately 1.5 days.
The two stars in Serpens Caput that form part of the Snake's body below the heart are Epsilon and Mu Serpentis, both third-magnitude A-type main-sequence stars. Both have a peculiarity: Epsilon is an Am star, while Mu is a binary. Located slightly northwest of Mu is 36 Serpentis, another A-type main-sequence star. This star also has a peculiarity; it is a binary with the primary component being a Lambda Boötis star, meaning that it has solar-like amounts of carbon, nitrogen, and oxygen, while containing very low amounts of iron peak elements. 25 Serpentis, positioned a few degrees northeast of Mu Serpentis, is a spectroscopic binary consisting of a hot B-type giant and an A-type main-sequence star. The primary is a slowly pulsating B star, which causes the system to vary by 0.03 magnitudes.
Serpens Caput contains many RR Lyrae variables, although most are too faint to be seen without professional photography. The brightest is VY Serpentis, only of 10th magnitude. This star's period has been increasing by approximately 1.2 seconds per century. A variable star of a different kind is Tau4 Serpentis, a cool red giant that pulsates between magnitudes 5.89 and 7.07 in 87 days. This star has been found to display an inverse P Cygni profile, where cold infalling gas on to the star creates redshifted hydrogen absorption lines next to the normal emission lines.
Several stars in Serpens have been found to have planets. The brightest, Omega Serpentis, located between Epsilon and Mu, is an orange giant with a planet of approximately 1.7 Jupiter-masses. NN Serpentis, an eclipsing post-common-envelope binary consisting of a white dwarf and a red dwarf, is very likely to have two planets causing variations in the period of the eclipses. Although it does not have a planet, the solar analog HD 137510 has been found to have a brown dwarf companion within the brown-dwarf desert.
PSR B1534+11 is a system consisting of two neutron stars orbiting each other, one of which is a pulsar with a period of 37.9 milliseconds. Situated approximately 1000 parsecs distant, the system was used to test Albert Einstein's theory of general relativity, validating the system's relativistic parameters to within 0.2% of values predicted by the theory. The X-ray emission from the system has been found to be present when the non-pulsar star intersects the equatorial pulsar wind of the pulsar, and the system's orbit has been found to vary slightly.
Tail stars.
The brightest star in the tail, Eta Serpentis, is similar to Alpha Serpentis' primary in that it is a red giant of spectral class K. This star, however, is known to exhibit solar-like oscillations over a period of approximately 2.16 hours. The other two stars in Serpens Cauda forming its asterism are Theta and Xi Serpentis. Xi, where the asterism crosses over to Mu Serpentis in the head, is a triple star system located approximately 105 parsecs away. Two of the stars, with a combined apparent magnitude of around 3.5, form a spectroscopic binary with an angular separation of only 2.2 milliarcseconds, and thus cannot be resolved with modern equipment. The primary is a white giant with an excess of strontium. Theta, forming the tip of the tail, is also a multiple system, consisting of two A-type main-sequence stars with a combined apparent magnitude of around 4.1 separated by almost half an arcminute.
Lying near the boundary with Ophiuchus are Zeta, Nu, and Omicron Serpentis. All three are 4th-magnitude main-sequence stars, with Nu and Omicron being of spectral type A and Zeta being of spectral type F. Nu is a binary star with a 9th-magnitude companion, while Omicron is a Delta Scuti variable with amplitude variations of 0.01 magnitudes. In 1909, the symbiotic nova RT Serpentis appeared near Omicron, although it only reached a maximum magnitude of 10.
The star system 59 Serpentis, also known as d Serpentis, is a triple star system consisting of a spectroscopic binary containing an A-type star and an orange giant and an orange giant secondary. The system shows irregular variations in brightness between magnitudes 5.17 and 5.2. In 1970, the nova FH Serpentis appeared just slightly north of 59 Serpentis, reaching a maximum brightness of 4.5. Also near 59 Serpentis in the Serpens Cloud are several Orion variables. MWC 297 is a Herbig Be star that in 1994 exhibited a large X-ray flare and increased in X-ray luminosity by five times before returning to the quiescent state. The star also appears to possess a circumstellar disk. Another Orion variable in the region is VV Serpentis, a Herbig Ae star that has been found to exhibit Delta Scuti pulsations. VV Serpentis has also, like MWC 297, been found to have a dusty disk surrounding it, and is also a UX Orionis star, meaning that it shows irregular variations in its brightness.
The star HR 6958, also known as MV Serpentis, is an Alpha2 Canum Venaticorum variable that is faintly visible to the naked eye. The star's metal abundance is ten times higher than the Sun for most metals at the iron peak and up to 1,000 times more for heavier elements. It has also been found to contain excess silicon. Barely visible to the naked eye is HD 172365, a likely post-blue straggler in the open cluster IC 4756 that contains a large excess of lithium. HD 172189, also located in IC 4756, is an Algol variable eclipsing binary with a 5.70 day period. The primary star in the system is also a Delta Scuti variable, undergoing multiple pulsation frequencies, which, combined with the eclipses, causes the system to vary by around a tenth of a magnitude.
As the galactic plane passes through it, Serpens Cauda contains many massive OB stars. Several of these are visible to the naked eye, such as NW Serpentis, an early Be star that has been found to be somewhat variable. The variability is interesting; according to one study, it could be one of the first discovered hybrids between Beta Cephei variables and slowly pulsating B stars. Although not visible to the naked eye, HD 167971 (MY Serpentis) is a Beta Lyrae variable triple system consisting of three very hot O-type stars. A member of the cluster NGC 6604, the two eclipsing stars are both blue giants, with one being of the very early spectral type O7.5III. The remaining star is either a blue giant or supergiant of a late O or early B spectral type. Also an eclipsing binary, the HD 166734 system consists of two O-type blue supergiants in orbit around each other. Less extreme in terms of mass and temperature is HD 161701, a spectroscopic binary consisting of a B-type primary and an Ap secondary, although it is the only known spectroscopic binary to consist of a star with excess of mercury and manganese and an Ap star.
South of the Eagle Nebula on the border with Sagittarius is the eclipsing binary W Serpentis, whose primary is a white giant that is interacting with the secondary. The system has been found to contain an accretion disk, and was one of the first discovered Serpentids, which are eclipsing binaries containing exceptionally strong far-ultraviolet spectral lines. It is suspected that such Serpentids are in an earlier evolutionary phase, and will evolve first into double periodic variables and then classical Algol variables. Also near the Eagle Nebula is the eclipsing Wolf–Rayet binary CV Serpentis, consisting of a Wolf–Rayet star and a hot O-type subgiant. The system is surrounded by a ring-shaped nebula, likely formed during the Wolf–Rayet phase of the primary. The eclipses of the system vary erratically, and although there are two theories as to why, neither of them is completely consistent with current understanding of stars.
Serpens Cauda contains a few X-ray binaries. One of these, GX 17+2, is a low-mass X-ray binary consisting of a neutron star and, as in all low-mass X-ray binaries, a low-mass star. The system has been classified as a Sco-like Z source, meaning that its accretion is near the Eddington limit. The system has also been found to approximately every 3 days brighten by around 3.5 K-band magnitudes, possibly due to the presence of a synchrotron jet. Another low-mass X-ray binary, Serpens X-1, undergoes occasional X-ray bursts. One in particular lasted nearly four hours, possibly explained by the burning of carbon in "a heavy element ocean".
Deep-sky objects.
Head objects.
As the galactic plane does not pass through this part of Serpens, a view to many galaxies beyond it is possible. However, a few structures of the Milky Way Galaxy are present in Serpens Caput, such as Messier 5, a globular cluster positioned approximately 8° southwest of α Serpentis, next to the star 5 Serpentis. Barely visible to the naked eye under good conditions, and is located approximately 25,000 ly distant. Messier 5 contains a large number of known RR Lyrae variable stars, and is receding from us at over 50 km/s. The cluster contains two millisecond pulsars, one of which is in a binary, allowing the proper motion of the cluster to be measured. The binary could help our understanding of neutron degenerate matter; the current median mass, if confirmed, would exclude any "soft" equation of state for such matter. The cluster has been used to test for magnetic dipole moments in neutrinos, which could shed light on some hypothetical particles such as the axion. Another globular cluster is Palomar 5, found just south of Messier 5. Many stars are leaving this globular cluster due to the Milky Way's gravity, forming a tidal tail over 30000 light-years long.
A remarkable dark nebula complex is the L134/L183 complex. Along with a third cloud, they are likely fragments of a single original cloud located 36 degrees away from the galactic plane, a large distance for dark nebulae. The entire complex is thought to be around 140 parsecs distant. L183, also referred to as L134N, is particularly interesting; there are several infrared sources within, indicating pre-stellar sources thought to present the first known observation of the contraction phase between cloud cores and prestellar cores. The core is split into three regions, with a combined mass of around 25 solar masses.
Outside of the Milky Way, there are no bright deep-sky objects for amateur astronomers in Serpens Caput, with nothing else above 10th magnitude. The brightest is NGC 5962, a spiral galaxy positioned around 28 megaparsecs distant with an apparent magnitude of 11.34. Slightly fainter is NGC 5921, a barred spiral galaxy with a LINER-type active galactic nucleus situated somewhat closer at a distance of 21 megaparsecs. A type II supernova was observed in this galaxy in 2001 and was designated SN 2001X. Fainter still are the spirals NGC 5964 and NGC 6118, with the latter being host to the supernova SN 2004dk.
Hoag's Object, located 600 million light-years from Earth, is one of the most famous of a very rare class of galaxies known as ring galaxies. The outer ring is largely composed of young blue stars while the core is made up of older yellow stars. The predominant theory regarding its formation is that the progenitor galaxy was a barred spiral galaxy whose arms had velocities too great to keep the galaxy's coherence and therefore detached. Arp 220 is another unusual galaxy in Serpens. The prototypical ultraluminous infrared galaxy, Arp 220 is somewhat closer than Hoag's Object at 250 million light-years from Earth. It consists of two large spiral galaxies in the process of colliding with their nuclei orbiting at a distance of 1,200 light-years, causing extensive star formation throughout both components. It possesses a large cluster of more than a billion stars, partially covered by thick dust clouds near one of the galaxies' core. Another interacting galaxy pair, albeit in an earlier stage, consists of the galaxies NGC 5953 and NGC 5954. In this case, both are active galaxies, with the former a Seyfert 2 galaxy and the latter a LINER-type galaxy. Both are undergoing a burst of star formation triggered by the interaction.
Seyfert's Sextet is a group of six galaxies, four of which are interacting gravitationally and two of which simply appear to be a part of the group despite their greater distance. The gravitationally bound cluster lies at a distance of 190 million light-years from Earth and is approximately 100,000 light-years across, making Seyfert's Sextet one of the densest galaxy group known. Astronomers predict that the four interacting galaxies will eventually merge to form a large elliptical galaxy. The radio source 3C 326 was originally though to emanate from a giant elliptical galaxy. However, in 1990, it was shown that the source is instead a brighter, smaller galaxy a few arcseconds north. This object, designated 3C 326 N, has enough gas for star formation, but is being inhibited due to the energy from the radio galaxy nucleus.
A much larger galaxy cluster is the redshift-0.0354 Abell 2063. The cluster is thought to be interacting with the nearby galaxy group MKW 3s, based on radial velocity measurements of galaxies and the positioning of the cD galaxy at the center of Abell 2063. The active galaxy at the center of MKW 3s—NGC 5920—appears to be creating a bubble of hot gas from its radio activity. Near the 5th-magnitude star Pi Serpentis lies AWM 4, a cluster containing an excess of metals in the intracluster medium. The central galaxy, NGC 6051, is a radio galaxy that is probably responsible for this enrichment. Similar to AWM 4, the cluster Abell 2052 has central cD radio galaxy, 3C 317. This radio galaxy is believed to have restarted after a period of inactivity less than 200 years ago. The galaxy has over 40,000 known globular clusters, the highest known total of any galaxy as of 2002.
Consisting of two quasars with a separation of less than 5 arcseconds, the quasar pair 4C 11.50 is one of the visually closest pairs of quasars in the sky. The two have markedly different redshifts, however, and are thus unrelated. The foreground member of the pair (4C 11.50 A) does not have enough mass to refract light from the background component (4C 11.50 B) enough to produce a lensed image, although it does have a true companion of its own. An even stranger galaxy pair is 3C 321. Unlike the previous pair, the two galaxies making up 3C 321 are interacting with each other and are in the process of merging. Both members appear to be active galaxies; the primary radio galaxy may be responsible for the activity in the secondary by means of the former's jet driving material onto the latter's supermassive black hole.
A remarkable example of gravitational lensing is found in the radio galaxy 3C 324. First thought to be a single overluminous radio galaxy with a redshift of "z" = 1.206, it was found in 1987 to actually be two galaxies, with the radio galaxy at the aforementioned redshift being lensed by another galaxy at redshift "z" = 0.845. The first example of a multiply-imaged radio galaxy discovered, the source appears to be an elliptical galaxy with a dust lane obscuring our view of the visual and ultraviolet emission from the nucleus. In even shorter wavelengths, the BL Lac object PG 1553+113 is a heavy emitter of gamma rays. This object is the most distant found to emit photons with energies in the TeV range as of 2007. The spectrum is unique, with hard emission in some ranges of the gamma-ray spectrum in stark contrast to soft emission in others. In 2012, the object flared in the gamma-ray spectrum, tripling in luminosity for two nights, allowing the redshift to be accurately measured as "z" = 0.49.
Several gamma-ray bursts (GRBs) have been observed in Serpens Caput, such as GRB 970111, one of the brightest GRBs observed. An optical transient event associated with this GRB has not been found, despite its intensity. The host galaxy initially also proved elusive, however it now appears that the host is a Seyfert I galaxy located at redshift "z" = 0.657. The X-ray afterglow of the GRB has also been much fainter than for other dimmer GRBs. More distant is GRB 060526 (redshift "z" = 3.221), from which X-ray and optical afterglows were detected. This GRB was surprisingly faint for a long-duration GRB.
Tail objects.
Part of the galactic plane passes through the tail, and thus Serpens Cauda is rich in deep-sky objects within our own galaxy. The Eagle Nebula and its associated star cluster, Messier 16 lie 7,000 light-years from Earth in the direction of the galactic center. The nebula measures 70 light-years by 50 light-years and contains the Pillars of Creation, three dust clouds that became famous for the image taken by the Hubble Space Telescope. The stars being born in the Eagle Nebula, added to those with an approximate age of 5 million years have an average temperature of 45,000 kelvins and produce prodigious amounts of radiation that will eventually destroy the dust pillars. Despite its fame, the Eagle Nebula is fairly dim, with an integrated magnitude of approximately 6.0. The star-forming regions in the nebula are often evaporating gaseous globules; unlike Bok globules they only hold one protostar.
North of Messier 16, at a distance of approximately 2000 parsecs, is the OB association Serpens OB2, containing over 100 OB stars. Around 5 million years old, the association appears to still contain star-forming regions, and the light from its stars is illuminating the HII region S 54. Within this HII region is the open cluster NGC 6604, which is the same age as the surrounding OB association, and the cluster is now thought to simply be the densest part of it. The cluster appears to be producing a thermal chimney of ionized gas, caused by the interaction of the gas from the galactic disk with the galactic halo.
Another open cluster in Serpens Cauda is IC 4756, containing at least one naked-eye star, HD 172365 (another naked-eye star in the vicinity, HD 171586, is most likely unrelated). Positioned approximately 440 parsecs distant, the cluster is estimated to be around 800 million years old, quite old for an open cluster. Despite the presence of the Milky Way in Serpens Cauda, one globular cluster can be found: NGC 6535, although invisible to the naked eye, can be made out in small telescopes just north of Zeta Serpentis. Rather small and sparse for a globular cluster, this cluster contains no known RR Lyrae variables, which is unusual for a globular cluster.
MWC 922 is a star surrounded by a planetary nebula. Dubbed the Red Square Nebula due to its similarities to the Red Rectangle Nebula, the planetary nebula appears to be a nearly perfect square with a dark band around the equatorial regions. The nebula contains concentric rings, which are similar to those seen in the supernova SN 1987A. MWC 922 itself is an FS Canis Majoris variable, meaning that it is a Be star containing exceptionally bright hydrogen emission lines as well as select forbidden lines, likely due to the presence of a close binary. East of Xi Serpentis is another planetary nebula, Abell 41, containing the binary star MT Serpentis at its center. The nebula appears to have a bipolar structure, and the axis of symmetry of the nebula has been found to be within 5° of the line perpendicular to the orbital plane of the stars, strengthening the link between binary stars and bipolar planetary nebulae. On the other end of the stellar age spectrum is L483, a dark nebula which contains the protostar IRAS 18418-0440. Although classified as a class 0 protostar, it has some unusual features for such an object, such as a lack of high-velocity stellar winds, and it has been proposed that this object is in transition between class 0 and class I. A variable nebula exists around the protostar, although it is only visible in infrared light.
The Serpens cloud is a massive star-forming molecular cloud situated in the southern part of Serpens Cauda. Only two million years old and 420 parecs distant, the cloud is known to contain many protostars such as Serpens FIRS 1 and Serpens SVS 20. The Serpens South protocluster was uncovered by NASA's Spitzer Space Telescope in the southern portion of the cloud, and it appears that star formation is still continuing in the region. Another site of star formation is the Westerhout 40 complex, consisting of a prominent HII region adjacent to a molecular cloud. Located around 500 parsecs distant, it is one of the nearest massive regions of star formation, but as the molecular cloud obscures the HII region, rendering it and its embedded cluster tough to see visibly, it is not as well-studied as others. The embedded cluster likely contains over 600 stars above 0.1 solar masses, with several massive stars, including at least one O-type star, being responsible for lighting the HII region and the production of a bubble.
Despite the presence of the Milky Way, several active galaxies are visible in Serpens Cauda as well, such as PDS 456, found near Xi Serpentis. The most intrinsically luminous nearby active galaxy, this AGN has been found to be extremely variable in the X-ray spectrum. This has allowed light to be shed on the nature of the supermassive black hole at the center, likely a Kerr black hole. It is possible that the quasar is undergoing a transition from an ultraluminous infrared galaxy to a classical radio-quiet quasar, but there are problems with this theory, and the object appears to be an exceptional object that does not completely lie within current classification systems. Nearby is NRAO 530, a blazar that has been known to flare in the X-rays occasionally. One of these flares was for less than 2000 seconds, making it the shortest flare ever observed in a blazar as of 2004. The blazar also appears to show periodic variability in its radio wave output over two different periods of six and ten years.
Meteor showers.
There are two daytime meteor showers that radiate from Serpens, the Omega Serpentids and the Sigma Serpentids. Both showers peak between December 18 and December 25.

</doc>
<doc id="28150" url="https://en.wikipedia.org/wiki?curid=28150" title="Sculptor Group">
Sculptor Group

The Sculptor Group is a loose group of galaxies near the south galactic pole. The group is one of the closest groups of galaxies to the Local Group; the distance to the center of the group from the Milky Way is approximately .
The Sculptor Galaxy (NGC 253) and a few other galaxies form a gravitationally-bound core in the center of this group. A few other galaxies at the periphery may be associated with the group but may not be gravitationally bound. Because most of the galaxies in this group are actually weakly gravitationally bound, the group may also be described as a filament.
Members.
The table below lists galaxies that have been identified as associated with the Sculptor Galaxy (and hence associated with the group) by I. D. Karachentsev and collaborators.
Note that the object names used in the above table differ from the names used by Karachentsev and collaborators. NGC, IC, UGC, and PGC numbers have been used when possible to allow for easier referencing.
Foreground galaxies.
The irregular galaxy NGC 55, the spiral galaxy NGC 300, and their companion galaxies have been considered by many researchers to be part of this group. However, recent distance measurements to these and other galaxies in the same region of the sky show that NGC 55, NGC 300, and their companions may simply be foreground galaxies that are physically unassociated with the Sculptor Group.

</doc>
<doc id="28151" url="https://en.wikipedia.org/wiki?curid=28151" title="State (polity)">
State (polity)

A state is a type of polity that is an organized political community living under a single system of government. States may or may not be sovereign. For instance, federated states are members of a federal union, and may have only partial sovereignty, but are, nonetheless, states. Some states are subject to external sovereignty or hegemony, in which ultimate sovereignty lies in another state. States that are sovereign are known as sovereign states. 
The term "state" can also refer to the secular branches of government within a state, often as a manner of contrasting them with churches and civilian institutions.
Speakers of American English often use the terms "state" and "government" as , with both words referring to an organized political group that exercises authority over a particular territory. 
Many human societies have been governed by states for millennia, but many have been stateless societies. Over time a variety of different forms developed, employing a variety of justifications of legitimacy for their existence (such as the divine right of kings, the theory of social contract, etc.). In the 21st century, the modern nation-state is the predominant form of state to which people are subjected.
Definition issues.
There is no academic consensus on the most appropriate definition of the state. The term "state" refers to a set of different, but interrelated and often overlapping, theories about a certain range of political phenomena. The act of defining the term can be seen as part of an ideological conflict, because different definitions lead to different theories of state function, and as a result validate different political strategies. According to Jeffrey and Painter, "if we define the 'essence' of the state in one place or era, we are liable to find that in another time or space something which is also understood to be a state has different 'essential' characteristics" 
The most commonly used definition is Max Weber's, which describes the state as a compulsory political organization with a centralized government that maintains a monopoly of the legitimate use of force within a certain territory. General categories of state institutions include administrative bureaucracies, legal systems, and military or religious organizations.
According to the "Oxford English Dictionary", a state is "a. an organized political community under one government; a commonwealth; a nation. b. such a community forming part of a federal republic, esp the United States of America".
Confounding the definition problem is that "state" and "government" are often used as synonyms in common conversation and even some academic discourse. According to this definition schema, the states are nonphysical persons of international law, governments are organizations of people. The relationship between a government and its state is one of representation and authorized agency.
Types of states.
States may be classified as "sovereign" if they are not dependent on, or subject to any other power or state. Other states are subject to external sovereignty or hegemony where ultimate sovereignty lies in another state. Many states are federated states which participate in a federal union. A federated state is a territorial and constitutional community forming part of a federation. Such states differ from sovereign states, in that they have transferred a portion of their sovereign powers to a federal government.
The state and government.
A state can be distinguished from a government. The government is the particular group of people, the administrative bureaucracy that controls the state apparatus at a given time. That is, governments are the means through which state power is employed. States are served by a continuous succession of different governments. States are immaterial and nonphysical social objects, whereas governments are groups of people with certain coercive powers.
Each successive government is composed of a specialized and privileged body of individuals, who monopolize political decision-making, and are separated by status and organization from the population as a whole. Their function is to enforce existing laws, legislate new ones, and arbitrate conflicts. In some societies, this group is often a self-perpetuating or hereditary class. In other societies, such as democracies, the political roles remain, but there is frequent turnover of the people actually filling the positions.
States and nation-states.
States can also be distinguished from the concept of a "nation", where "nation" refers to a cultural-political community of people.
The state and civil society.
In the classical thought, the state was identified with both political society and civil society as a form of political community, while the modern thought distinguished the nation state as a political society from civil society as a form of economic society.
Thus in the modern thought the state is contrasted with civil society.
The man versus the state.
Antonio Gramsci believed that civil society is the primary locus of political activity because it is where all forms of "identity formation, ideological struggle, the activities of intellectuals, and the construction of hegemony take place." and that civil society was the nexus connecting the economic and political sphere. Arising out of the collective actions of civil society is what Gramsci calls "political society", which Gramsci differentiates from the notion of the state as a polity. He stated that politics was not a "one-way process of political management" but, rather, that the activities of civil organizations conditioned the activities of political parties and state institutions, and were conditioned by them in turn. Louis Althusser argued that civil organizations such as church, schools, and the family are part of an "ideological state apparatus" which complements the "repressive state apparatus" (such as police and military) in reproducing social relations.
Jürgen Habermas spoke of a public sphere that was distinct from both the economic and political sphere.
Given the role that many social groups have in the development of public policy, and the extensive connections between state bureaucracies and other institutions, it has become increasingly difficult to identify the boundaries of the state. Privatization, nationalization, and the creation of new regulatory bodies also change the boundaries of the state in relation to society. Often the nature of quasi-autonomous organizations is unclear, generating debate among political scientists on whether they are part of the state or civil society. Some political scientists thus prefer to speak of policy networks and decentralized governance in modern societies rather than of state bureaucracies and direct state control over policy.
Theories of state function.
Most political theories of the state can roughly be classified into two categories. The first are known as "liberal" or "conservative" theories, which treat capitalism as a given, and then concentrate on the function of states in capitalist society. These theories tend to see the state as a neutral entity separated from society and the economy. Marxist theories on the other hand, see politics as intimately tied in with economic relations, and emphasize the relation between economic power and political power. They see the state as a partisan instrument that primarily serves the interests of the upper class.
Anarchist.
Anarchism is a political philosophy which considers the state immoral, unnecessary, and harmful and instead promotes a stateless society, or anarchy.
Anarchists believe that the state is inherently an instrument of domination and repression, no matter who is in control of it. Anarchists note that the state possesses the monopoly on the legal use of violence. Unlike Marxists, anarchists believe that revolutionary seizure of state power should not be a political goal. They believe instead that the state apparatus should be completely dismantled, and an alternative set of social relations created, which are not based on state power at all.
Various Christian anarchists, such as Jacques Ellul, have identified the State and political power as the Beast in the Book of Revelation.
Marxist perspective.
Marx and Engels were clear in that the communist goal was a classless society in which the state would have "withered away". Their views are scattered throughout the Marx/Engels Collected Works and address past or the then extant state forms from an analytical or tactical viewpoint, not future social forms, speculation about which is generally anathema to groups considering themselves Marxist but who, not having conquered the existing state power(s) are not in the situation of supplying the institutional form of an actual society. To the extent that it makes sense, there is no single "Marxist theory of state", but rather many different "Marxist" theories that have been developed by adherents of Marxism.
Marx's early writings portrayed the state as "parasitic", built upon the superstructure of the economy, and working against the public interest. He also wrote that the state mirrors class relations in society in general, acts as a regulator and repressor of class struggle, and acts as a tool of political power and domination for the ruling class. The "Communist Manifesto" claimed that the state is nothing more than "a committee for managing the common affairs of the "bourgeoisie".
For Marxist theorists, the role of the non-socialist state is determined by its function in the global capitalist order. Ralph Miliband argued that the ruling class uses the state as its instrument to dominate society by virtue of the interpersonal ties between state officials and economic elites. For Miliband, the state is dominated by an elite that comes from the same background as the capitalist class. State officials therefore share the same interests as owners of capital and are linked to them through a wide array of social, economic, and political ties.
Gramsci's theories of state emphasized that the state is only one of the institutions in society that helps maintain the hegemony of the ruling class, and that state power is bolstered by the ideological domination of the institutions of civil society, such as churches, schools, and mass media.
Pluralism.
Pluralists view society as a collection of individuals and groups, who are competing for political power. They then view the state as a neutral body that simply enacts the will of whichever groups dominate the electoral process. Within the pluralist tradition, Robert Dahl developed the theory of the state as a neutral arena for contending interests or its agencies as simply another set of interest groups. With power competitively arranged in society, state policy is a product of recurrent bargaining. Although pluralism recognizes the existence of inequality, it asserts that all groups have an opportunity to pressure the state. The pluralist approach suggests that the modern democratic state's actions are the result of pressures applied by a variety of organized interests. Dahl called this kind of state a polyarchy.
Pluralism has been challenged on the ground that it is not supported by empirical evidence. Citing surveys showing that the large majority of people in high leadership positions are members of the wealthy upper class, critics of pluralism claim that the state serves the interests of the upper class rather than equitably serving the interests of all social groups.
Contemporary critical perspectives.
Jürgen Habermas believed that the base-superstructure framework, used by many Marxist theorists to describe the relation between the state and the economy, was overly simplistic. He felt that the modern state plays a large role in structuring the economy, by regulating economic activity and being a large-scale economic consumer/producer, and through its redistributive welfare state activities. Because of the way these activities structure the economic framework, Habermas felt that the state cannot be looked at as passively responding to economic class interests.
Michel Foucault believed that modern political theory was too state-centric, saying "Maybe, after all, the state is no more than a composite reality and a mythologized abstraction, whose importance is a lot more limited than many of us think." He thought that political theory was focusing too much on abstract institutions, and not enough on the actual practices of government. In Foucault's opinion, the state had no essence. He believed that instead of trying to understand the activities of governments by analyzing the properties of the state (a reified abstraction), political theorists should be examining changes in the practice of government to understand changes in the nature of the state.
Heavily influenced by Gramsci, Nicos Poulantzas, a Greek neo-Marxist theorist argued that capitalist states do not always act on behalf of the ruling class, and when they do, it is not necessarily the case because state officials consciously strive to do so, but because the 'structural' position of the state is configured in such a way to ensure that the long-term interests of capital are always dominant. Poulantzas' main contribution to the Marxist literature on the state was the concept of 'relative autonomy' of the state. While Poulantzas' work on 'state autonomy' has served to sharpen and specify a great deal of Marxist literature on the state, his own framework came under criticism for its 'structural functionalism.'
State autonomy (institutionalism).
State autonomy theorists believe that the state is an entity that is impervious to external social and economic influence, and has interests of its own.
"New institutionalist" writings on the state, such as the works of Theda Skocpol, suggest that state actors are to an important degree autonomous. In other words, state personnel have interests of their own, which they can and do pursue independently of (at times in conflict with) actors in society. Since the state controls the means of coercion, and given the dependence of many groups in civil society on the state for achieving any goals they may espouse, state personnel can to some extent impose their own preferences on civil society.
G. William Domhoff claims that "The idea of the American state having any significant degree of autonomy from the owners and managers of banks, corporations, and agribusinesses is a theoretical mistake based in empirical inaccuracies," and cites empirical studies showing a high degree of overlap between upper-level corporate management and high-level positions in government.
Theories of state legitimacy.
States generally rely on a claim to some form of political legitimacy in order to maintain domination over their subjects.
Divine right.
The rise of the modern day state system was closely related to changes in political thought, especially concerning the changing understanding of legitimate state power and control. Early modern defenders of absolutism, such as Thomas Hobbes and Jean Bodin undermined the doctrine of the divine right of kings by arguing that the power of kings should be justified by reference to the people. Hobbes in particular went further to argue that political power should be justified with reference to the individual, not just to the people understood collectively. Both Hobbes and Bodin thought they were defending the power of kings, not advocating for democracy, but their arguments about the nature of sovereignty were fiercely resisted by more traditional defenders of the power of kings, such as Sir Robert Filmer in England, who thought that such defenses ultimately opened the way to more democratic claims.
Rational-legal authority.
Max Weber identified three main sources of political legitimacy in his works. The first, legitimacy based on traditional grounds is derived from a belief that things should be as they have been in the past, and that those who defend these traditions have a legitimate claim to power. The second, legitimacy based on charismatic leadership is devotion to a leader or group that is viewed as exceptionally heroic or virtuous. The third is rational-legal authority, whereby legitimacy is derived from the belief that a certain group has been placed in power in a legal manner, and that their actions are justifiable according to a specific code of written laws. Weber believed that the modern state is characterized primarily by appeals to rational-legal authority.
Etymology.
The word "state" and its cognates in some other European languages ("stato" in Italian, "estado" in Spanish, "état" in French, "Staat" in German) ultimately derive from the Latin word "status", meaning "condition" or "status."
With the revival of the Roman law in 14th-century Europe, this Latin term came to refer to the legal standing of persons (such as the various "estates of the realm" - noble, common, and clerical), and in particular the special status of the king. The word also had associations with Roman ideas (dating back to Cicero) about the ""status rei publicae"", the "condition of public matters". In time, the word lost its reference to particular social groups and became associated with the legal order of the entire society and the apparatus of its enforcement.
In English, "state" came about as a contraction of the word "estate", which is similar to the old French "estat" and the modern French "état", both of which signify that a person has status and therefore estate. The highest estates, generally those with the most wealth and social rank, were those that held power.
The early 16th-century works of Machiavelli (especially "The Prince") played a central role in popularizing the use of the word "state" in something similar to its modern sense.
History.
The earliest forms of the state emerged whenever it became possible to centralize power in a durable way. Agriculture and writing are almost everywhere associated with this process: agriculture because it allowed for the emergence of a class of people who did not have to spend most of their time providing for their own subsistence, and writing (or an equivalent of writing, like Inca quipus) because it made possible the centralization of vital information.
The first known states were created in Ancient Egypt, Mesopotamia, India, China, the Inca civilization, and others, but it is only in relatively modern times that states have almost completely displaced alternative "stateless" forms of political organization of societies all over the planet. Roving bands of hunter-gatherers and even fairly sizable and complex tribal societies based on herding or agriculture have existed without any full-time specialized state organization, and these "stateless" forms of political organization have in fact prevailed for all of the prehistory and much of the history of the human species and civilization.
Initially states emerged over territories built by conquest in which one culture, one set of ideals and one set of laws have been imposed by force or threat over diverse nations by a civilian and military bureaucracy. Currently, that is not always the case and there are multinational states, federated states and autonomous areas within states.
Since the late 19th century, virtually the entirety of the world's inhabitable land has been parcelled up into areas with more or less definite borders claimed by various states. Earlier, quite large land areas had been either unclaimed or uninhabited, or inhabited by nomadic peoples who were not organised as states. However, even within present-day states there are vast areas of wilderness, like the Amazon Rainforest, which are uninhabited or inhabited solely or mostly by indigenous people (and some of them remain uncontacted). Also, there are states which do not hold de facto control over all of their claimed territory or where this control is challenged. Currently the international community comprises around 200 sovereign states, the vast majority of which are represented in the United Nations.
Pre-historic stateless societies.
For most of human history, people have lived in stateless societies, characterized by a lack of concentrated authority, and the absence of large inequalities in economic and political power.
The anthropologist Tim Ingold writes:
The Neolithic period.
During the Neolithic period, human societies underwent major cultural and economic changes, including the development of agriculture, the formation of sedentary societies and fixed settlements, increasing population densities, and the use of pottery and more complex tools.
Sedentary agriculture led to the development of property rights, domestication of plants and animals, and larger family sizes. It also provided the basis for the centralized state form by producing a large surplus of food, which created a more complex division of labor by enabling people to specialize in tasks other than food production. Early states were characterized by highly stratified societies, with a privileged and wealthy ruling class that was subordinate to a monarch. The ruling classes began to differentiate themselves through forms of architecture and other cultural practices that were different from those of the subordinate laboring classes.
In the past, it was suggested that the centralized state was developed to administer large public works systems (such as irrigation systems) and to regulate complex economies. However, modern archaeological and anthropological evidence does not support this thesis, pointing to the existence of several non-stratified and politically decentralized complex societies.
The state in ancient Eurasia.
Mesopotamia is generally considered to be the location of the earliest civilization or complex society, meaning that it contained cities, full-time division of labor, social concentration of wealth into capital, unequal distribution of wealth, ruling classes, community ties based on residency rather than kinship, long distance trade, monumental architecture, standardized forms of art and culture, writing, and mathematics and science. It was the world's first literate civilization, and formed the first sets of written laws.
The state in classical antiquity.
Although state-forms existed before the rise of the Ancient Greek empire, the Greeks were the first people known to have explicitly formulated a political philosophy of the state, and to have rationally analyzed political institutions. Prior to this, states were described and justified in terms of religious myths.
Several important political innovations of classical antiquity came from the Greek city-states and the Roman Republic. The Greek city-states before the 4th century granted citizenship rights to their free population, and in Athens these rights were combined with a directly democratic form of government that was to have a long afterlife in political thought and history.
The Feudal state.
During Medieval times in Europe, the state was organized on the principle of feudalism, and the relationship between lord and vassal became central to social organization. Feudalism led to the development of greater social hierarchies.
The formalization of the struggles over taxation between the monarch and other elements of society (especially the nobility and the cities) gave rise to what is now called the Standestaat, or the state of Estates, characterized by parliaments in which key social groups negotiated with the king about legal and economic matters. These estates of the realm sometimes evolved in the direction of fully-fledged parliaments, but sometimes lost out in their struggles with the monarch, leading to greater centralization of lawmaking and military power in his hands. Beginning in the 15th century, this centralizing process gives rise to the absolutist state.
The modern state.
Cultural and national homogenization figured prominently in the rise of the modern state system. Since the absolutist period, states have largely been organized on a national basis. The concept of a national state, however, is not synonymous with nation state. Even in the most ethnically homogeneous societies there is not always a complete correspondence between state and nation, hence the active role often taken by the state to promote nationalism through emphasis on shared symbols and national identity.

</doc>
<doc id="28152" url="https://en.wikipedia.org/wiki?curid=28152" title="Stevia">
Stevia

Stevia (, or ) is a sweetener and sugar substitute extracted from the leaves of the plant species "Stevia rebaudiana".
The active compounds of stevia are steviol glycosides (mainly stevioside and rebaudioside), which have up to 150 times the sweetness of sugar, are heat-stable, pH-stable, and not fermentable. These steviosides have a negligible effect on blood glucose, which makes stevia attractive to people on carbohydrate-controlled diets. Stevia's taste has a slower onset and longer duration than that of sugar, and some of its extracts may have a bitter or licorice-like aftertaste at high concentrations.
The legal status of stevia extracts as food additives and supplements varies from country to country. In the United States, stevia was banned in 1991 after early studies found that it might be carcinogenic; after additional studies, the FDA approved some specific glycoside extracts for use as food additives in 2008. The European Union approved stevia additives in 2011, and in Japan, stevia has been widely used as a sweetener for decades.
History.
Discovery.
The plant "Stevia rebaudiana" has been used for more than 1,500 years by the Guaraní peoples of South America, who called it "ka'a he'ê" ("sweet herb"). The leaves have been used traditionally for hundreds of years in both Brazil and Paraguay to sweeten local teas and medicines, and as a "sweet treat". The genus was named for Spanish botanist and physician Petrus Jacobus Stevus (Pedro Jaime Esteve 1500–1556) a professor of botany at the University of Valencia.
In 1899, Swiss botanist Moisés Santiago Bertoni, while conducting research in eastern Paraguay, first described the plant and the sweet taste in detail. Only limited research was conducted on the topic until in 1931 two French chemists isolated the glycosides that give stevia its sweet taste.
The exact structure of the aglycone (steviol) and of the glycoside were published in 1955.
Commercial use.
In the early 1970s, sweeteners such as cyclamate and saccharin were gradually decreased or removed from a variant formulation of Coca-Cola. Consequently, use of stevia as an alternative began in Japan, with the aqueous extract of the leaves yielding purified steviosides developed as sweeteners. The first commercial stevia sweetener in Japan was produced by the Japanese firm Morita Kagaku Kogyo Co., Ltd. in 1971. The Japanese have been using stevia in food products and soft drinks, (including Coca Cola), and for table use. Japan currently consumes more stevia than any other country, with stevia accounting for 40% of the sweetener market.
In the mid-1980s, stevia became popular in U.S. natural foods and health food industries, as a noncaloric natural sweetener for teas and weight-loss blends. The makers of the synthetic sweetener NutraSweet asked the FDA to require testing of the herb. In 2007, the Coca-Cola Company announced plans to obtain approval for its stevia-derived sweetener, Rebiana, for use as a food additive within the United States by 2009, as well as plans to market Rebiana-sweetened products in 12 countries that allow stevia's use as a food additive. In May 2008, Coca Cola and Cargill announced the availability of Truvia, a consumer brand stevia sweetener containing erythritol and Rebiana, which the FDA permitted as a food additive in December 2008. Coca-Cola announced intentions to release stevia-sweetened beverages in late December 2008. From 2013 onwards, Coca-Cola Life, containing stevia as a sweetener, was launched in various countries around the world.
Shortly afterward, PepsiCo and Pure Circle announced PureVia, their brand of stevia-based sweetener, but withheld release of beverages sweetened with rebaudioside A until receipt of FDA confirmation. Since the FDA permitted Truvia and PureVia, both Coca Cola and PepsiCo have introduced products that contain their new sweeteners.
As of 2006, China was the world's largest exporter of stevioside products.
Industrial extracts and derivatives.
Stevia extracts and derivatives are produced industrially by many companies, and marketed under many trade names. Some of them are:
Mechanism of action.
Glycosides are molecules that contain glucose and other non-sugar substances called aglycones (molecules with other sugars are polysaccharides). The tongue's taste receptors react to the glucose in the glycosides: those with more glucose (rebaudioside) taste sweeter than those with less (stevioside). Some of the tongue's bitter receptors react to the aglycones.
In the digestive tract, rebaudiosides are metabolised into stevioside. Then stevioside is broken down into glucose and steviol. The glucose released in this process is used by bacteria in the colon and not absorbed into the bloodstream. Steviol cannot be further digested and is excreted.
Safety and regulations.
A 2009 review summarized the basic research in which steviosides and related compounds are being tested for possible antidisease actions, with no effect yet demonstrated in humans. A 2011 review found that the use of stevia sweeteners as replacements for sugar might benefit diabetic patients because it is a noncaloric additive.
Although both steviol and rebaudioside A have been found to be mutagenic in laboratory "in vitro" testing, these effects have not been demonstrated for the doses and routes of administration to which humans are exposed. Two 2010 review studies found no health concerns with stevia or its sweetening extracts. However, experts have noted a "general lack of long-term studies on stevia’s use and effects".
The WHO's Joint Experts Committee on Food Additives has approved, based on long-term studies, an acceptable daily intake of steviol glycoside of up to 4 mg/kg of body weight. In 2010, The European Food Safety Authority established an acceptable daily intake of 4 mg/kg/day of steviol, in the form of steviol glycosides. Meanwhile, the Memorial Sloan Kettering Cancer Center warns that "steviol at high dosages may have weak mutagenic activity."
Availability and legal status by country.
The plant may be grown legally in most countries, although some countries restrict its use as a sweetener. The legally allowed uses and maximum dosage of the extracts and derived products vary widely from country to country.
Extraction.
Rebaudioside A has the least bitterness of all the steviol glycosides in the "Stevia rebaudiana" plant. To produce rebaudioside A commercially, stevia plants are dried and subjected to a water extraction process. This crude extract contains about 50% rebaudioside A. The various glycosides are separated and purified via crystallization techniques, typically using ethanol or methanol as solvent.
Controversy.
In 1991, after receiving an anonymous industry complaint, the United States Food and Drug Administration (FDA) labeled stevia as an "unsafe food additive" and restricted its import. The FDA's stated reason was "toxicological information on stevia is inadequate to demonstrate its safety".
Arizona congressman Jon Kyl called the FDA's action against stevia "a restraint of trade to benefit the artificial sweetener industry". To protect the complainant, the FDA deleted names in the original complaint in its responses to requests filed under the Freedom of Information Act.
Stevia remained banned until after the Dietary Supplement Health and Education Act of 1994 forced the FDA in 1995 to revise its stance and to permit stevia to be used as a dietary supplement, although not as a food additive – a position that stevia proponents regarded as contradictory as they felt it simultaneously labeled stevia as safe and unsafe, depending on how it was sold.
Early studies prompted the European Commission in 1999 to ban stevia's use in food in the European Union pending further research. In 2006, research data compiled in the safety evaluation released by the World Health Organization found no adverse effects.
In December 2008, the FDA gave a "no objection" approval for GRAS status to Truvia (developed by Cargill and the Coca-Cola Company) and PureVia (developed by PepsiCo and the Whole Earth Sweetener Company, a subsidiary of Merisant), both of which use rebaudioside A derived from the stevia plant. However, the FDA said that these products are not stevia, but a highly purified product. 
In 2012, the FDA posted a note on its website regarding crude stevia plants: "FDA has not permitted the use of whole-leaf stevia or crude stevia extracts because these substances have not been approved for use as a food additive. FDA does not consider their use in food to be GRAS in light of reports in the literature that raise concerns about the use of these substances. Among these concerns are control of blood sugar and effects on the reproductive, cardiovascular, and renal systems."

</doc>
<doc id="28153" url="https://en.wikipedia.org/wiki?curid=28153" title="Search for extraterrestrial intelligence">
Search for extraterrestrial intelligence

The search for extraterrestrial intelligence (SETI) is a collective term for the scientific search for intelligent extraterrestrial life. For example, monitoring electromagnetic radiation for signs of transmissions from civilizations on other worlds.
There are great challenges in searching the universe for signs of intelligent life, including their identification and interpretation. As various SETI projects have progressed, some have criticized early claims by researchers as being too "euphoric".
Scientific investigation of the potential phenomenon began shortly after the advent of radio in the early 1900s. Focused international efforts to answer a variety of scientific questions have been going on since the 1980s. In 2015, Stephen Hawking and Russian billionaire Yuri Milner announced a well-funded effort, called the Breakthrough Initiatives to expand efforts to search for extraterrestrial life.
History of SETI.
Early work.
Earlier, a lot of search for extraterrestrial intelligence occurred within the Solar System. In 1896, Nikola Tesla suggested that an extreme version of his wireless electrical transmission system could be used to contact beings on Mars. In 1899 while conducting experiments at his Colorado Springs experimental station, he thought he had detected a signal from the planet since an odd repetitive static signal seemed to cut off when Mars set in the night sky. Analysis of Tesla's research has ranged from suggestions that Tesla detected nothing, he simply was misunderstanding the new technology he was working with, to claims that Tesla may have been observing signals from Marconi's European radio experiments and even that he could have picked up naturally occurring Jovian plasma torus signals. In the early 1900s, Guglielmo Marconi, Lord Kelvin, and David Peck Todd also stated their belief that radio could be used to contact Martians, with Marconi stating that his stations had also picked up potential Martian signals.
On August 21–23, 1924, Mars entered an opposition closer to Earth than any time in a century before or the next 80 years. In the United States, a "National Radio Silence Day" was promoted during a 36-hour period from August 21–23, with all radios quiet for five minutes on the hour, every hour. At the United States Naval Observatory, a radio receiver was lifted above the ground in a dirigible tuned to a wavelength between 8 and , using a "radio-camera" developed by Amherst College and Charles Francis Jenkins. The program was led by David Peck Todd with the military assistance of Admiral Edward W. Eberle (Chief of Naval Operations), with William F. Friedman (chief cryptographer of the United States Army), assigned to translate any potential Martian messages.
A 1959 paper by Philip Morrison and Giuseppe Cocconi first pointed out the possibility of searching the microwave spectrum, and proposed frequencies and a set of initial targets
In 1960, Cornell University astronomer Frank Drake performed the first modern SETI experiment, named "Project Ozma", after the Queen of Oz in L. Frank Baum's fantasy books. Drake used a radio telescope in diameter at Green Bank, West Virginia, to examine the stars Tau Ceti and Epsilon Eridani near the 1.420-gigahertz marker frequency, a region of the radio spectrum dubbed the "water hole" due to its proximity to the hydrogen and hydroxyl radical spectral lines. A 400-kilohertz band was scanned around the marker frequency, using a single-channel receiver with a bandwidth of 100 hertz. He found nothing of interest.
The Soviet scientists took a strong interest in SETI during the 1960s and performed a number of searches with omnidirectional antennas in the hope of picking up powerful radio signals. Soviet astronomer Iosif Shklovsky wrote the pioneering book in the field, "Universe, Life, Intelligence" (1962), which was expanded upon by American astronomer Carl Sagan as the best-selling book "Intelligent Life in the Universe" (1966).
In the March 1955 issue of "Scientific American", John D. Kraus described a concept to scan the cosmos for natural radio signals using a flat-plane radio telescope equipped with a parabolic reflector. Within two years, his concept was approved for construction by Ohio State University. With US$71,000 total in grants from the National Science Foundation, construction began on a plot in Delaware, Ohio. This Ohio State University Radio Observatory telescope was called "Big Ear". Later, it began the world's first continuous SETI program, called the Ohio State University SETI program.
In 1971, NASA funded a SETI study that involved Drake, Bernard M. Oliver of Hewlett-Packard Corporation, and others. The resulting report proposed the construction of an Earth-based radio telescope array with 1,500 dishes known as "Project Cyclops". The price tag for the Cyclops array was US$10 billion. Cyclops was not built, but the report formed the basis of much SETI work that followed.
The OSU SETI program gained fame on August 15, 1977, when Jerry Ehman, a project volunteer, witnessed a startlingly strong signal received by the telescope. He quickly circled the indication on a printout and scribbled the exclamation "Wow!" in the margin. Dubbed the "Wow! signal", it is considered by some to be the best candidate for a radio signal from an artificial, extraterrestrial source ever discovered, but it has not been detected again in several additional searches.
Sentinel, META, and BETA.
In 1980, Carl Sagan, Bruce Murray, and Louis Friedman founded the U.S. Planetary Society, partly as a vehicle for SETI studies.
In the early 1980s, Harvard University physicist Paul Horowitz took the next step and proposed the design of a spectrum analyzer specifically intended to search for SETI transmissions. Traditional desktop spectrum analyzers were of little use for this job, as they sampled frequencies using banks of analog filters and so were restricted in the number of channels they could acquire. However, modern integrated-circuit digital signal processing (DSP) technology could be used to build autocorrelation receivers to check far more channels. This work led in 1981 to a portable spectrum analyzer named "Suitcase SETI" that had a capacity of 131,000 narrow band channels. After field tests that lasted into 1982, Suitcase SETI was put into use in 1983 with the Harvard/Smithsonian radio telescope at Oak Ridge Observatory in Harvard, Massachusetts. This project was named "Sentinel" and continued into 1985.
Even 131,000 channels were not enough to search the sky in detail at a fast rate, so Suitcase SETI was followed in 1985 by Project "META", for "Megachannel Extra-Terrestrial Assay". The META spectrum analyzer had a capacity of 8.4 million channels and a channel resolution of 0.05 hertz. An important feature of META was its use of frequency Doppler shift to distinguish between signals of terrestrial and extraterrestrial origin. The project was led by Horowitz with the help of the Planetary Society, and was partly funded by movie maker Steven Spielberg. A second such effort, META II, was begun in Argentina in 1990, to search the southern sky. META II is still in operation, after an equipment upgrade in 1996.
The follow-on to META was named "BETA", for "Billion-channel Extraterrestrial Assay", and it commenced observation on October 30, 1995. The heart of BETA's processing capability consisted of 63 dedicated fast Fourier transform (FFT) engines, each capable of performing a 222-point complex FFTs in two seconds, and 21 general-purpose personal computers equipped with custom digital signal processing boards. This allowed BETA to receive 250 million simultaneous channels with a resolution of 0.5 hertz per channel. It scanned through the microwave spectrum from 1.400 to 1.720 gigahertz in eight hops, with two seconds of observation per hop. An important capability of the BETA search was rapid and automatic re-observation of candidate signals, achieved by observing the sky with two adjacent beams, one slightly to the east and the other slightly to the west. A successful candidate signal would first transit the east beam, and then the west beam and do so with a speed consistent with Earth's sidereal rotation rate. A third receiver observed the horizon to veto signals of obvious terrestrial origin. On March 23, 1999, the 26-meter radio telescope on which Sentinel, META and BETA were based was blown over by strong winds and seriously damaged. This forced the BETA project to cease operation.
MOP and Project Phoenix.
In 1978, the NASA SETI program had been heavily criticized by Senator William Proxmire, and funding for SETI research was removed from the NASA budget by Congress in 1981; however, funding was restored in 1982, after Carl Sagan talked with Proxmire and convinced him of the program's value. In 1992, the U.S. government funded an operational SETI program, in the form of the NASA Microwave Observing Program (MOP). MOP was planned as a long-term effort to conduct a general survey of the sky and also carry out targeted searches of 800 specific nearby stars. MOP was to be performed by radio antennas associated with the NASA Deep Space Network, as well as the radio telescope of the National Radio Astronomy Observatory at Green Bank, West Virginia and the radio telescope at the Arecibo Observatory in Puerto Rico. The signals were to be analyzed by spectrum analyzers, each with a capacity of 15 million channels. These spectrum analyzers could be grouped together to obtain greater capacity. Those used in the targeted search had a bandwidth of 1 hertz per channel, while those used in the sky survey had a bandwidth of 30 hertz per channel.
MOP drew the attention of the United States Congress, where the program was ridiculed and canceled one year after its start. SETI advocates continued without government funding, and in 1995 the nonprofit SETI Institute of Mountain View, California resurrected the MOP program under the name of Project "Phoenix", backed by private sources of funding. Project Phoenix, under the direction of Jill Tarter, is a continuation of the targeted search program from MOP and studies roughly 1,000 nearby Sun-like stars. From 1995 through March 2004, Phoenix conducted observations at the Parkes radio telescope in Australia, the radio telescope of the National Radio Astronomy Observatory in Green Bank, West Virginia, and the radio telescope at the Arecibo Observatory in Puerto Rico. The project observed the equivalent of 800 stars over the available channels in the frequency range from 1200 to 3000 MHz. The search was sensitive enough to pick up transmitters with 1 GW EIRP to a distance of about 200 light-years. According to Prof. Tarter, in 2012 it costs around "$2 million per year to keep SETI research going at the SETI Institute" and approximately 10 times that to support "all kinds of SETI activity around the world."
Ongoing radio searches.
Many radio frequencies penetrate Earth's atmosphere quite well, and this led to radio telescopes that investigate the cosmos using large radio antennas. Furthermore, human endeavors emit considerable electromagnetic radiation as a byproduct of communications such as television and radio. These signals would be easy to recognize as artificial due to their repetitive nature and narrow bandwidths. If this is typical, one way of discovering an extraterrestrial civilization might be to detect artificial radio emissions from a location outside the Solar System.
Many international radio telescopes are currently being used for radio SETI searches, including the Low Frequency Array (LOFAR) in Europe, the Murchison Widefield Array (MWA) in Australia, and the Lovell Telescope in the United Kingdom.
Allen Telescope Array.
The SETI Institute collaborated with the Radio Astronomy Laboratory at University of California, Berkeley to develop a specialized radio telescope array for SETI studies, something like a mini-cyclops array. Formerly known as the One Hectare Telescope (1HT), the concept was renamed the "Allen Telescope Array" (ATA) after the project's benefactor Paul Allen. Its sensitivity would be equivalent to a single large dish more than 100 meters in diameter if completed. Presently, the array under construction has 42 dishes at the Hat Creek Radio Observatory in rural northern California.
The full array (ATA-350) is planned to consist of 350 or more offset-Gregorian radio dishes, each in diameter. These dishes are the largest producible with commercially available satellite television dish technology. The ATA was planned for a 2007 completion date, at a very modest cost of US$25 million. The SETI Institute provided money for building the ATA while University of California, Berkeley designed the telescope and provided operational funding. The first portion of the array (ATA-42) became operational in October 2007 with 42 antennas. The DSP system planned for ATA-350 is extremely ambitious. Completion of the full 350 element array will depend on funding and the technical results from ATA-42.
ATA-42 (ATA) is designed to allow multiple observers simultaneous access to the interferometer output at the same time. Typically, the ATA snapshot imager (used for astronomical surveys and SETI) is run in parallel with the beam forming system (used primarily for SETI). ATA also supports observations in multiple synthesized pencil beams at once, through a technique known as "multibeaming." Multibeaming provides an effective filter for identifying false positives in SETI, since a very distant transmitter must appear at only one point on the sky.
SETI Institute's Center for SETI Research (CSR) uses ATA in the search for extraterrestrial intelligence, observing 12 hours a day, 7 days a week. From 2007-2015, ATA has identified hundreds of millions of technological signals. So far, all these signals have been assigned the status of noise or radio frequency interference because a) they appear to be generated by satellites or Earth-based transmitters, or b) they disappeared before the threshold time limit of ~1 hour. Researchers in CSR are presently working on ways to reduce the threshold time limit, and to expand ATA's capabilities for detection of signals that may have embedded messages.
Berkeley astronomers used the ATA to pursue several science topics, some of which might have turned up transient SETI signals, until 2011, when the collaboration between the University of California and the SETI Institute was terminated. 
The DSP system planned for the ATA is extremely ambitious. The first portion of the array became operational in October 2007 with 42 antennas. Completion of the full 350 element array will depend on funding and the technical results from the 42-element sub-array.
CNET published an article and pictures about the Allen Telescope Array (ATA) on December 12, 2008.
In April 2011, the ATA was forced to enter an 8-month "hibernation" due to funding shortfalls. Regular operation of the ATA was resumed on December 5, 2011.
In 2012, new life was breathed into the ATA thanks to a $3.6M philanthropic donation by Franklin Antonio, Co-Founder and Chief Scientist of QUALCOMM Incorporated. This gift supports upgrades of all the receivers on the ATA dishes to have dramatically (2x - 10x from 1–8 GHz) greater sensitivity than before and supporting sensitive observations over a wider frequency range from 1–18 GHz, though initially the radio frequency electronics go to only 12 GHz. As of July, 2013 the first of these receivers was installed and proven. Full installation on all 42 antennas is expected in June, 2014. ATA is especially well suited to the search for extraterrestrial intelligence SETI and to discovery of astronomical radio sources, such as heretofore unexplained non-repeating, possibly extragalactic, pulses known as fast radio bursts or FRBs.
SERENDIP.
SERENDIP (Search for Extraterrestrial Radio Emissions from Nearby Developed Intelligent Populations) is a SETI program launched in 1979 by the University of California, Berkeley. SERENDIP takes advantage of ongoing "mainstream" radio telescope observations as a "piggy-back" or "commensal" program, using large radio telescopes including the NRAO 90m telescope at Green Bank and the Arecibo 305m telescope. Rather than having its own observation program, SERENDIP analyzes deep space radio telescope data that it obtains while other astronomers are using the telescopes.
The most recently deployed SERENDIP spectrometer, SERENDIP V.v, was installed at the Arecibo Observatory in June 2009 and is currently operational. The digital back-end instrument is an FPGA-based 128 million-channel digital spectrometer covering 200 MHz of bandwidth. It takes data commensally with the seven-beam Arecibo L-band Feed Array (ALFA). The program has found around 400 suspicious signals, but there is not enough data to prove that they belong to extraterrestrial intelligence.
Breakthrough Listen.
"Breakthrough Listen" is a ten-year initiative with $100 million funding begun in July 2015 to actively search for intelligent extraterrestrial communications in the universe, in a substantially expanded way, using resources that had not previously been extensively used for the purpose. It has been described as the most comprehensive search for alien communications to date.
Announced in July 2015, the project will use thousands of hours every year on two major radiotelescopes, the Green Bank Observatory in West Virginia and the Parkes Observatory in Australia. Previously, only about 24 to 36 hours of telescope per year was used in the search for alien life. Furthermore, the Automated Planet Finder of Lick Observatory will search for optical signals coming from laser transmissions. For processing of the massive data, the experience of SETI and SETI@home will be used. SETI founder Frank Drake is one of the project's scientists.
Community SETI projects.
SETI@home.
SETI@home was conceived by David Gedye along with Craig Kasnoff and is a popular volunteer distributed computing project that was launched by the University of California, Berkeley, in May 1999. It was originally funded by The Planetary Society and Paramount Pictures, and later by the state of California. The project is run by director David P. Anderson and chief scientist Dan Werthimer. Any individual can become involved with SETI research by downloading the Berkeley Open Infrastructure for Network Computing (BOINC) software program, attaching to the SETI@home project, and allowing the program to run as a background process that uses idle computer power. The SETI@home program itself runs signal analysis on a "work unit" of data recorded from the central 2.5 MHz wide band of the SERENDIP IV instrument. After computation on the work unit is complete, the results are then automatically reported back to SETI@home servers at University of California, Berkeley. By June 28, 2009, the SETI@home project had over 180,000 active participants volunteering a total of over 290,000 computers. These computers give SETI@home an average computational power of 617 teraFLOPS. In 2004 radio source SHGb02+14a set off speculation in the media that a signal had been detected but researchers noted the frequency drifted rapidly and the detection on three SETI@home computers fell within random chance.
As of 2010, after 10 years of data collection, SETI@home has listened to that one frequency at every point of over 67 percent of the sky observable from Arecibo with at least three scans (out of the goal of nine scans), which covers about 20 percent of the full celestial sphere.
SETI Net.
SETI Net is a private search system created by a single individual. It is closely affiliated with the SETI League and is one of the project Argus stations (DM12jw).
The SETI Net station consists of off-the-shelf, consumer-grade electronics to minimize cost and to allow this design to be replicated as simply as possible. It has a 3-meter parabolic antenna that can be directed in azimuth and elevation, an LNA that covers the 1420 MHz spectrum, a receiver to reproduce the wideband audio, and a standard personal computer as the control device and for deploying the detection algorithms.
The antenna can be pointed and locked to one sky location, enabling the system to integrate on it for long periods. Currently the Wow! signal area is being monitored when it is above the horizon. All search data are collected and made available on the Internet archive.
SETI Net started operation in the early 1980s as a way to learn about the science of the search, and has developed several software packages for the amateur SETI community. It has provided an astronomical clock, a file manager to keep track of SETI data files, a spectrum analyzer optimized for amateur SETI, remote control of the station from the Internet, and other packages.
The SETI League and Project Argus.
Founded in 1994 in response to the United States Congress cancellation of the NASA SETI program, The SETI League, Inc. is a membership-supported nonprofit organization with 1,500 members in 62 countries. This grass-roots alliance of amateur and professional radio astronomers is headed by executive director emeritus H. Paul Shuch, the engineer credited with developing the world's first commercial home satellite TV receiver. Many SETI League members are licensed radio amateurs and microwave experimenters. Others are digital signal processing experts and computer enthusiasts.
The SETI League pioneered the conversion of backyard satellite TV dishes in diameter into research-grade radio telescopes of modest sensitivity. The organization concentrates on coordinating a global network of small, amateur-built radio telescopes under Project Argus, an all-sky survey seeking to achieve real-time coverage of the entire sky. Project Argus was conceived as a continuation of the all-sky survey component of the late NASA SETI program (the targeted search having been continued by the SETI Institute's Project Phoenix). There are currently 143 Project Argus radio telescopes operating in 27 countries. Project Argus instruments typically exhibit sensitivity on the order of 10−23 Watts/square metre, or roughly equivalent to that achieved by the Ohio State University Big Ear radio telescope in 1977, when it detected the landmark "Wow!" candidate signal.
The name "Argus" derives from the mythical Greek guard-beast who had 100 eyes, and could see in all directions at once. In the SETI context, the name has been used for radio telescopes in fiction (Arthur C. Clarke, ""Imperial Earth""; Carl Sagan, ""Contact""), was the name initially used for the NASA study ultimately known as "Cyclops," and is the name given to an omnidirectional radio telescope design being developed at the Ohio State University.
Optical experiments.
While most SETI sky searches have studied the radio spectrum, some SETI researchers have considered the possibility that alien civilizations might be using powerful lasers for interstellar communications at optical wavelengths. The idea was first suggested by R. N. Schwartz and Charles Hard Townes in a 1961 paper published in the journal "Nature" titled "Interstellar and Interplanetary Communication by Optical Masers". However, the 1971 Cyclops study discounted the possibility of optical SETI, reasoning that construction of a laser system that could outshine the bright central star of a remote star system would be too difficult. In 1983, Townes published a detailed study of the idea in the United States journal "Proceedings of the National Academy of Sciences", which was met with widespread agreement by the SETI community.
There are two problems with optical SETI. The first problem is that lasers are highly "monochromatic", that is, they emit light only on one frequency, making it troublesome to figure out what frequency to look for. However, emitting light in narrow pulses results in a broad spectrum of emission; the spread in frequency becomes higher as the pulse width becomes narrower, making it easier to detect an emission.
The other problem is that while radio transmissions can be broadcast in all directions, lasers are highly directional. This means that a laser beam could be easily blocked by clouds of interstellar dust, and Earth would have to cross its direct line of fire by chance to receive it.
Optical SETI supporters have conducted paper studies of the effectiveness of using contemporary high-energy lasers and a ten-meter diameter mirror as an interstellar beacon. The analysis shows that an infrared pulse from a laser, focused into a narrow beam by such a mirror, would appear thousands of times brighter than the Sun to a distant civilization in the beam's line of fire. The Cyclops study proved incorrect in suggesting a laser beam would be inherently hard to see.
Such a system could be made to automatically steer itself through a target list, sending a pulse to each target at a constant rate. This would allow targeting of all Sun-like stars within a distance of 100 light-years. The studies have also described an automatic laser pulse detector system with a low-cost, two-meter mirror made of carbon composite materials, focusing on an array of light detectors. This automatic detector system could perform sky surveys to detect laser flashes from civilizations attempting contact.
Several optical SETI experiments are now in progress. A Harvard-Smithsonian group that includes Paul Horowitz designed a laser detector and mounted it on Harvard's optical telescope. This telescope is currently being used for a more conventional star survey, and the optical SETI survey is "piggybacking" on that effort. Between October 1998 and November 1999, the survey inspected about 2,500 stars. Nothing that resembled an intentional laser signal was detected, but efforts continue. The Harvard-Smithsonian group is now working with Princeton University to mount a similar detector system on Princeton's 91-centimeter (36-inch) telescope. The Harvard and Princeton telescopes will be "ganged" to track the same targets at the same time, with the intent being to detect the same signal in both locations as a means of reducing errors from detector noise.
The Harvard-Smithsonian group is now building a dedicated all-sky optical survey system along the lines of that described above, featuring a 1.8-meter (72-inch) telescope. The new optical SETI survey telescope is being set up at the Oak Ridge Observatory in Harvard, Massachusetts.
The University of California, Berkeley, home of SERENDIP and SETI@home, is also conducting optical SETI searches. One is being directed by Geoffrey Marcy, an extrasolar planet hunter, and involves examination of records of spectra taken during extrasolar planet hunts for a continuous, rather than pulsed, laser signal. The other Berkeley optical SETI effort is more like that being pursued by the Harvard-Smithsonian group and is being directed by Dan Werthimer of Berkeley, who built the laser detector for the Harvard-Smithsonian group. The Berkeley survey uses a 76-centimeter (30-inch) automated telescope at Leuschner Observatory and an older laser detector built by Werthimer.
Gamma-ray bursts.
Gamma-ray bursts (GRBs) are candidates for extraterrestrial communication. These high-energy bursts are observed about once per day and originate throughout the observable universe. SETI currently omits gamma ray frequencies in their monitoring and analysis because they are absorbed by the Earth's atmosphere and difficult to detect with ground-based receivers. In addition, the wide burst bandwidths pose a serious analysis challenge for modern digital signal processing systems. Still, the continued mysteries surrounding gamma-ray bursts have encouraged hypotheses invoking extraterrestrials. John A. Ball from the MIT Haystack Observatory suggests that an advanced civilization that has reached a technological singularity would be capable of transmitting a two-millisecond pulse encoding bits of information. This is "comparable to the estimated total information content of Earth's biosystem—genes and memes and including all libraries and computer media."
Search for extraterrestrial artifacts.
The possibility of using interstellar messenger probes in the search for extraterrestrial intelligence was first suggested by Ronald N. Bracewell in 1960 (see Bracewell probe), and the technical feasibility of this approach was demonstrated by the British Interplanetary Society's starship study Project Daedalus in 1978. Starting in 1979, Robert Freitas advanced arguments for the proposition that physical space-probes are a superior mode of interstellar communication to radio signals. See Voyager Golden Record.
In recognition that any sufficiently advanced interstellar probe in the vicinity of Earth could easily monitor the terrestrial Internet, Invitation to ETI was established by Prof. Allen Tough in 1996, as a Web-based SETI experiment inviting such spacefaring probes to establish contact with humanity. The project's 100 Signatories includes prominent physical, biological, and social scientists, as well as artists, educators, entertainers, philosophers and futurists. Prof. H. Paul Shuch, executive director emeritus of The SETI League, serves as the project's Principal Investigator.
Inscribing a message in matter and transporting it to an interstellar destination can be enormously more energy efficient than communication using electromagnetic waves if delays larger than light transit time can be tolerated. That said, for simple messages such as "hello," radio SETI could be far more efficient. If energy requirement is used as a proxy for technical difficulty, then a solarcentric Search for Extraterrestrial Artifacts (SETA) may be a useful supplement to traditional radio or optical searches.
Much like the "preferred frequency" concept in SETI radio beacon theory, the Earth-Moon or Sun-Earth libration orbits might therefore constitute the most universally convenient parking places for automated extraterrestrial spacecraft exploring arbitrary stellar systems. A viable long-term SETI program may be founded upon a search for these objects.
In 1979, Freitas and Valdes conducted a photographic search of the vicinity of the Earth-Moon triangular libration points and , and of the solar-synchronized positions in the associated halo orbits, seeking possible orbiting extraterrestrial interstellar probes, but found nothing to a detection limit of about 14th magnitude. The authors conducted a second, more comprehensive photographic search for probes in 1982 that examined the five Earth-Moon Lagrangian positions and included the solar-synchronized positions in the stable L4/L5 libration orbits, the potentially stable nonplanar orbits near L1/L2, Earth-Moon , and also in the Sun-Earth system. Again no extraterrestrial probes were found to limiting magnitudes of 17–19th magnitude near L3/L4/L5, 10–18th magnitude for /, and 14–16th magnitude for Sun-Earth .
In June 1983, Valdes and Freitas used the 26 m radiotelescope at Hat Creek Radio Observatory to search for the tritium hyperfine line at 1516 MHz from 108 assorted astronomical objects, with emphasis on 53 nearby stars including all visible stars within a 20 light-year radius. The tritium frequency was deemed highly attractive for SETI work because (1) the isotope is cosmically rare, (2) the tritium hyperfine line is centered in the SETI waterhole region of the terrestrial microwave window, and (3) in addition to beacon signals, tritium hyperfine emission may occur as a byproduct of extensive nuclear fusion energy production by extraterrestrial civilizations. The wideband- and narrowband-channel observations achieved sensitivities of 5–14 x 10−21 W/m²/channel and 0.7-2 x 10−24 W/m²/channel, respectively, but no detections were made.
Technosignatures.
Technosignatures, including all signs of technology with the exception of the interstellar radio messages that define traditional SETI, are a recent avenue in the search for extraterrestrial intelligence. Technosignatures may originate from various sources, from megastructures such as Dyson spheres and space mirrors or space shaders to the atmospheric contamination created by an industrial civilization, or city lights on extrasolar planets, and may be detectable in the future with large hypertelescopes.
Technosignatures can be divided into three broad categories: astroengineering projects, signals of planetary origin, and spacecraft within and outside the Solar System.
An astroengineering installation such as a Dyson sphere, designed to convert all of the incident radiation of its host star into energy, could be detected through the observation of an infrared excess from a solar analog star. After examining some 100,000 nearby large galaxies, a team of researchers has concluded that none of them contain any obvious signs of highly advanced technological civilizations.
Another theoretical form of astroengineering, the Shkadov thruster, moves its host star by reflecting some of the star's light back on itself, and could be detected by observing if its transits across the star abruptly end with the thruster in front. Asteroid mining within the Solar System is also a detectable technosignature of the first kind.
Individual extrasolar planets can be analyzed for signs of technology. Avi Loeb of the Harvard-Smithsonian Center for Astrophysics has proposed that persistent light signals on the night side of an exoplanet can be an indication of the presence of cities and an advanced civilization. In addition, the excess infrared radiation and chemicals produced by various industrial processes or terraforming efforts may point to intelligence.
Clearly, light and heat detected from planets need to be distinguished from natural sources to conclusively prove the existence of civilization on a planet. However, as argued by the Colossus team,
a civilization heat signature should be within a "comfortable" temperature range, like terrestrial urban heat islands, i.e. only a few degrees warmer than the planet itself. In contrast, such natural sources as wild fires, volcanoes, etc. are significantly hotter, so they will be well distinguished by their maximum flux at a different wavelength.
Extraterrestrial craft are another target in the search for technosignatures. Magnetic sail interstellar spacecraft should be detectable over thousands of light-years of distance through the synchrotron radiation they would produce through interaction with the interstellar medium; other interstellar spacecraft designs may be detectable at more modest distances. In addition, robotic probes within the Solar System are also being sought out with optical and radio searches.
For a sufficiently advanced civilization, hyper energetic neutrinos from Planck scale accelerators should be detectable at a distance of many Mpc.
Fermi paradox.
Italian physicist Enrico Fermi suggested in the 1950s that if technologically advanced civilizations are common in the universe, then they should be detectable in one way or another. (According to those who were there, Fermi either asked "Where are they?" or "Where is everybody?")
The Fermi paradox is commonly understood as asking why extraterrestrials have not visited Earth, but the same reasoning applies to the question of why signals from extraterrestrials have not been heard. The SETI version of the question is sometimes referred to as "the Great Silence".
The Fermi paradox can be stated more completely as follows:
There are multiple explanations proposed for the Fermi paradox, ranging from analyses suggesting that intelligent life is rare (the "Rare Earth hypothesis"), to analyses suggesting that although extraterrestrial civilizations may be common, they would not communicate, or would not travel across interstellar distances.
Science writer Timothy Ferris has posited that since galactic societies are most likely only transitory, an obvious solution is an interstellar communications network, or a type of library consisting mostly of automated systems. They would store the cumulative knowledge of vanished civilizations and communicate that knowledge through the galaxy. Ferris calls this the "Interstellar Internet", with the various automated systems acting as network "servers". If such an Interstellar Internet exists, the hypothesis states, communications between servers are mostly through narrow-band, highly directional radio or laser links. Intercepting such signals is, as discussed earlier, very difficult. However, the network could maintain some broadcast nodes in hopes of making contact with new civilizations.
Although somewhat dated in terms of "information culture" arguments, not to mention the obvious technological problems of a system that could work effectively for billions of years and requires multiple lifeforms agreeing on certain basics of communications technologies, this hypothesis is actually testable (see below).
A significant problem is the vastness of space. Despite piggybacking on the world's most sensitive radio telescope, Charles Stuart Bowyer said, the instrument could not detect random radio noise emanating from a civilization like ours, which has been leaking radio and TV signals for less than 100 years. For SERENDIP and most other SETI projects to detect a signal from an extraterrestrial civilization, the civilization would have to be beaming a powerful signal directly at us. It also means that Earth civilization will only be detectable within a distance of 100 light-years.
Post detection disclosure protocol.
The International Academy of Astronautics (IAA) has a long-standing SETI Permanent Study Group (SPSG, formerly called the IAA SETI Committee), which addresses matters of SETI science, technology, and international policy. The SPSG meets in conjunction with the International Astronautical Congress (IAC) held annually at different locations around the world, and sponsors two SETI Symposia at each IAC. In 2005, the IAA established the SETI: Post-Detection Science and Technology Taskgroup (Chairman, Professor Paul Davies) "to act as a Standing Committee to be available to be called on at any time to advise and consult on questions stemming from the discovery of a putative signal of extraterrestrial intelligent (ETI) origin."
When awarded the 2009 TED Prize, SETI Institute's Jill Tarter outlined the organisation's "post detection protocol". During NASA's funding of the project, an administrator would be first informed with the intention of informing the United States executive government. The current protocol for SETI Institute is to first internally investigate the signal, seeking independent verification and confirmation. During the process, the organisation's private financiers would be secretly informed. Once a signal has been verified, a telegram would be sent via the Central Bureau for Astronomical Telegrams. Following this process, Tarter says that the organisation will hold a press conference with the aim of broadcasting to the public. SETI Institute's Seth Shostak has claimed that knowledge of the discovery would likely leak as early as the verification process.
However, the protocols mentioned apply only to radio SETI rather than for METI (Active SETI). The intention for METI is covered under the SETI charter "Declaration of Principles Concerning Sending Communications with Extraterrestrial Intelligence".
The SETI Institute does not officially recognize the Wow! signal as of extraterrestrial origin (as it was unable to be verified). The SETI Institute has also publicly denied that the candidate signal Radio source SHGb02+14a is of extraterrestrial origin though full details of the signal, such as its exact location have never been disclosed to the public. Although other volunteering projects such as Zooniverse credit users for discoveries, there is currently no crediting or early notification by SETI@Home following the discovery of a signal.
Some people, including Steven M. Greer, have expressed cynicism that the general public might not be informed in the event of a genuine discovery of extraterrestrial intelligence due to significant vested interests. Some, such as Bruce Jakosky have also argued that the official disclosure of extraterrestrial life may have far reaching and as yet undetermined implications for society, particularly for the world's religions.
Active SETI.
Active SETI, also known as messaging to extraterrestrial intelligence (METI), consists of sending signals into space in the hope that they will be picked up by an alien intelligence.
Realized interstellar radio message projects.
In November 1974, a largely symbolic attempt was made at the Arecibo Observatory to send a message to other worlds. Known as the Arecibo Message, it was sent towards the globular cluster M13, which is 25,000 light-years from Earth. Further IRMs Cosmic Call, Teen Age Message, Cosmic Call 2, and A Message From Earth were transmitted in 1999, 2001, 2003 and 2008 from the Evpatoria Planetary Radar.
Debate.
Physicist Stephen Hawking, in his book "A Brief History of Time", suggests that "alerting" extraterrestrial intelligences to our existence is foolhardy, citing mankind's history of treating his fellow man harshly in meetings of civilizations with a significant technology gap. He suggests, in view of this history, that we "lay low".
The concern over METI was raised by the science journal "Nature" in an editorial in October 2006, which commented on a recent meeting of the International Academy of Astronautics SETI study group. The editor said, "It is not obvious that all extraterrestrial civilizations will be benign, or that contact with even a benign one would not have serious repercussions" (Nature Vol 443 12 October 06 p 606). Astronomer and science fiction author David Brin has expressed similar concerns.
Richard Carrigan, a particle physicist at the Fermi National Accelerator Laboratory near Chicago, Illinois, suggested that passive SETI could also be dangerous and that a signal released onto the Internet could act as a computer virus. Computer security expert Bruce Schneier dismissed this possibility as a "bizarre movie-plot threat".
To lend a quantitative basis to discussions of the risks of transmitting deliberate messages from Earth, the SETI Permanent Study Group of the International Academy of Astronautics adopted in 2007 a new analytical tool, the San Marino Scale. Developed by Prof. Ivan Almar and Prof. H. Paul Shuch, the scale evaluates the significance of transmissions from Earth as a function of signal intensity and information content. Its adoption suggests that not all such transmissions are equal, and each must be evaluated separately before establishing blanket international policy regarding active SETI.
However, some scientists consider these fears about the dangers of METI as panic and irrational superstition; see, for example, Alexander L. Zaitsev's papers. Biologist João Pedro de Magalhães also proposed in 2015 transmitting an invitation message to any extraterrestrial intelligences watching us already in the context of the Zoo Hypothesis and inviting them to respond, arguing this would not put us in any more danger than we are already if the Zoo Hypothesis is correct.
On 13 February 2015, scientists (including Geoffrey Marcy, Seth Shostak, Frank Drake, Elon Musk and David Brin) at a convention of the American Association for the Advancement of Science, discussed Active SETI and whether transmitting a message to possible intelligent extraterrestrials in the Cosmos was a good idea; one result was a statement, signed by many, that a "worldwide scientific, political and humanitarian discussion must occur before any message is sent". On 28 March 2015, a related essay was written by Seth Shostak and published in "The New York Times".
Breakthrough Message.
The Breakthrough Message program is an open competition announced in July 2015 to design a digital message that could be transmitted from Earth to an extraterrestrial civilization, with a US$1,000,000 prize pool. The message should be "representative of humanity and planet Earth". The program pledges "not to transmit any message until there has been a wide-ranging debate at high levels of science and politics on the risks and rewards of contacting advanced civilizations".
Criticism.
As various SETI projects have progressed, some have criticized early claims by researchers as being too "euphoric". For example, Peter Schenkel, while remaining a supporter of SETI projects, has written that
Clive Trotman presents some sobering but realistic calculations emphasizing the timeframe dimension.
SETI has also occasionally been the target of criticism by those who suggest that it is a form of pseudoscience. In particular, critics allege that no observed phenomena suggest the existence of extraterrestrial intelligence, and furthermore that the assertion of the existence of extraterrestrial intelligence has no good Popperian criteria for falsifiability.
In response, SETI advocates note, among other things, that the Drake Equation was never a hypothesis, and so never intended to be testable, nor to be "solved"; it was merely a clever representation of the agenda for the world's first scientific SETI meeting in 1961, and it serves as a tool in formulating testable hypotheses. Further, they note that the existence of intelligent life on Earth is a plausible reason to expect it elsewhere, and that individual SETI projects have clearly defined "stop" conditions.

</doc>
<doc id="28154" url="https://en.wikipedia.org/wiki?curid=28154" title="Sextans">
Sextans

Sextans is a minor equatorial constellation which was introduced in 1687 by Johannes Hevelius. Its name is Latin for the astronomical sextant, an instrument that Hevelius made frequent use of in his observations.
Notable features.
Sextans as a constellation covers a rather dim, sparse region of the sky. It has only one star above the fifth magnitude, namely α Sextantis at 4.49m. The constellation contains a few double stars, including γ, 35, and 40 Sextantis. There are a few notable variable stars, including β, 25, 23 Sextantis, and LHS 292. NGC 3115, an edge-on lenticular galaxy, is the only noteworthy deep-sky object. It also lies near the ecliptic, which causes the Moon, and some of the planets to occasionally pass through it for brief periods of time.
The constellation is the location of the field studied by the COSMOS project, undertaken by the Hubble Space Telescope.
Sextans B is a fairly bright dwarf irregular galaxy at magnitude 6.6, 4.3 million light-years from Earth. It is part of the Local Group of galaxies.
In June 2015, astronomers reported evidence for Population III stars in the Cosmos Redshift 7 galaxy (at ) found in the Sextans constellation. Such stars are likely to have existed in the very early universe (i.e., at high redshift), and may have started the production of chemical elements heavier than hydrogen that are needed for the later formation of planets and life as we know it.

</doc>
<doc id="28156" url="https://en.wikipedia.org/wiki?curid=28156" title="Salem al-Hazmi">
Salem al-Hazmi

Salem al-Hazmi (, , also transliterated as Alhazmi) (February 2, 1981 – September 11, 2001) was one of five hijackers of American Airlines Flight 77 as part of the September 11 attacks. 
A Saudi, Hazmi had a relatively long history with al-Qaeda before being selected for the attacks. He obtained a tourist visa through the Visa Express program and arrived in the United States in June 2001 where he would settle in New Jersey with other American 77 hijackers up until the attacks. 
On September 11, 2001, Hazmi boarded American Airlines Flight 77 and helped subdue the passengers and crew for Hani Hanjour, the pilot among the hijackers, to crash the plane into west facade of the Pentagon. His older brother, Nawaf al-Hazmi, was another hijacker aboard the same flight. At the age of 20 years and 221 days, he was the youngest hijacker who participated in the attacks.
History.
Hazmi was born on February 2, 1981 to Muhammad Salim al-Hazmi, a grocer, in Mecca, Saudi Arabia. His father described Salem as a quarrelsome teenager who had problems with alcohol and petty theft. However, he stopped drinking and began to attend the mosque about three months before he left his family.
There are reports that he fought in Afghanistan with his brother, Nawaf al-Hazmi, and other reports say the two fought together in Chechnya. Salem al-Hazmi was an al-Qaeda veteran by the time he was selected for participation in the 9/11 attacks. U.S intelligence learned of Hazmi's involvement with al-Qaeda as early as 1999, but he was not placed on any watchlists. 
Known as "Bilal" during the preparations, both he and Ahmed al-Ghamdi flew to Beirut in November 2000, though on separate flights.
Along with Nawaf al-Hazmi and several other future hijackers, Salem al-Hazmi may have attended the 2000 Al Qaeda Summit in Kuala Lumpur, Malaysia. It was there that the details of the 9/11 attacks were decided upon.
In the United States.
According to the FBI and the 9/11 Commission report, Hazmi first entered the United States on June 29, 2001, although there are numerous unconfirmed reports that he was living in San Antonio, Texas with fellow hijacker Satam al-Suqami much earlier. Hazmi used the controversial Visa Express program to gain entry into the country. 
Hazmi moved to Paterson, New Jersey where he lived with Hani Hanjour. Both were among the five hijackers who applied for Virginia identity cards at the Arlington office of the Virginia Department of Motor Vehicles on August 2, 2001, although Salem already held an NJ identity card.
On August 27, brothers Nawaf and Salem purchased flight tickets through Travelocity.com using Nawaf's visa card.
With the four other Flight 77 hijackers, he worked out at a Gold's Gym in Greenbelt, Maryland from September 2 to September 6 of the same year.
Attacks.
On September 11, 2001, Hazmi boarded American Airlines Flight 77. Airport surveillance video from Washington's Dulles Airport shows two of the five hijackers, including Salem al-Hazmi, being pulled aside to undergo additional scrutiny after setting off metal detectors.
The flight was scheduled to depart at 08:10, but ended up departing 10 minutes late from Gate D26 at Dulles. The last normal radio communications from the aircraft to air traffic control occurred at 08:50:51. At 08:54, Flight 77 began to deviate from its normal, assigned flight path and turned south, and then hijackers set the flight's autopilot heading for Washington, D.C. Passenger Barbara Olson called her husband, United States Solicitor General Theodore Olson, and reported that the plane had been hijacked and that the assailants had box cutters and knives. At 09:37, American Airlines Flight 77 crashed into the west facade of the Pentagon, killing all 64 aboard (including the hijackers), along with 125 on the ground in the Pentagon. In the recovery process at the Pentagon, remains of all five Flight 77 hijackers were identified through a process of elimination, as not matching any DNA samples for the victims, and put into custody of the FBI. Forensics teams confirmed that it seemed two of the hijackers were brothers, based on their DNA similarities.
Mistaken identity.
Shortly after the attacks, several sources reported that Salem al-Hazmi, 26, was alive and working at a petrochemical plant in Yanbu, Saudi Arabia. He claimed that his passport had been stolen by a pickpocket in Cairo three years before, and that the pictures and details such as date of birth released to the public by the FBI were his own. He also stated that he had never visited the United States, but volunteered to fly to the U.S. to prove his innocence. On September 19, "Al-Sharq Al-Awsat" published his photograph alongside Badr Alhazmi's, who they claimed was the actual hijacker who had stolen his identity.
Muhammad Salim al-Hazmi, father of the two suspects, Nawaf and Salim Muhammad al-Hazmi, said that the published photos may be doctored or faked somehow. Hazmi continued, "As a father, I have a feeling that the two of them are still alive and unhurt, and will come back home in the near future when the truth is uncovered and the real culprits are found."
After some confusion and doubt Saudi Arabia admitted that in fact the names of the hijackers were correct. "The names that we got confirmed that," Interior Minister Prince Nayef said in an interview with The Associated Press. "Their families have been notified." Nayef said the Saudi leadership was shocked to learn 15 of the hijackers were from Saudi Arabia and said it was natural that the kingdom had not noticed their involvement beforehand.

</doc>
<doc id="28157" url="https://en.wikipedia.org/wiki?curid=28157" title="Satsuma Province">
Satsuma Province

History.
Satsuma's provincial capital was Satsumasendai. During the Sengoku Period, Satsuma was a fief of the Shimazu daimyo, who ruled much of southern Kyūshū from their castle at Kagoshima city.
In 1871, with the abolition of feudal domains and the establishment of prefectures after the Meiji Restoration, the provinces of Satsuma and Ōsumi were combined to eventually establish Kagoshima Prefecture.
Satsuma was one of the main provinces that rose in opposition to the Tokugawa Shogunate in the mid 19th century. Because of this, the oligarchy that came into power after the "Meiji Restoration" of 1868 had a strong representation from the Satsuma province, with leaders such as Ōkubo Toshimichi and Saigō Takamori taking up key government positions.
Satsuma is well known for its production of sweet potatoes, known in Japan as 薩摩芋 (satsuma-imo or "Satsuma potato"). On the other hand, Satsuma mandarins (known as "mikan" in Japan) do not specifically originate from Satsuma but were imported into the West through this province in the Meiji era.

</doc>
<doc id="28159" url="https://en.wikipedia.org/wiki?curid=28159" title="Scottish">
Scottish

Scottish usually refers to something of, from, or related to Scotland, including:

</doc>
<doc id="28161" url="https://en.wikipedia.org/wiki?curid=28161" title="List of brightest stars">
List of brightest stars

This is a list of the brightest naked eye stars to +2.50 magnitude, as determined by their "maximum", "total" or "combined" apparent visual magnitudes as seen from Earth. Although several of the brightest stars are also known close binary or multiple star systems, they do appear to the naked eye as single stars. The given list below combines/adds the magnitudes of bright individual components.
Measurement.
Apparent visual magnitudes of the brightest star can also be compared to non-stellar objects in our Solar System. Here the maximum visible magnitudes above the brightest star, Sirius (-1.46), are as follows. Excluding the Sun, the brightest objects are the Moon (−12.7), Venus (−4.89), Jupiter (−2.94), Mars (−2.91), Mercury (−2.45), and Saturn (−0.49).
Any exact order of the visual brightness of stars is not perfectly defined for the following reasons:

</doc>
<doc id="28162" url="https://en.wikipedia.org/wiki?curid=28162" title="List of nearest stars and brown dwarfs">
List of nearest stars and brown dwarfs

This list contains all known stars and brown dwarfs at a distance of up to 5 parsecs (16.3 light-years) from the Solar System. In addition to the Solar System, there are another 54 stellar systems currently known lying within this distance. These systems contain a total of 56 hydrogen-fusing stars (of which 46 are red dwarfs), 14 brown dwarfs, and 4 white dwarfs. Despite the relative proximity of these objects to Earth, only nine of them have an apparent magnitude less than 6.5, which means only about 12% of these objects can be observed with the naked eye. Besides the Sun, only three are first-magnitude stars: Alpha Centauri, Sirius, and Procyon. All of these objects are located in the Local Bubble, a region within the Orion–Cygnus Arm of the Milky Way.
List.
Stars visible to the unaided eye have their magnitude shown in light blue below. Brown dwarfs are shown with their designations in brown. The classes of the stars and brown dwarfs are shown in the color of their spectral types (these colors are derived from conventional names for the spectral types and do not represent the star's observed color). Many brown dwarfs are not listed by visual magnitude but are listed by near-IR J band magnitude. Some of the parallax and distance results are preliminary measurements.
Future and past.
Backwards extrapolation of the motion of Gamma Microscopii has shown that approximately 3.8 million years ago, it was only around 6 light-years from the Sun. Though because it is a red giant, it would then have had an apparent magnitude of −3, brighter than Sirius currently is.
It is estimated that Scholz's star and its companion brown dwarf passed about from the Sun about 70,000 years ago.
Ross 248, currently at a distance of 10.3 light-years, has a radial velocity of −81 km/s. In about 31,000 years it may be the closest star to the Sun for several millennia, with a minimum distance of in 36,000 years. Gliese 445, currently at a distance of 17.6 light-years, has a radial velocity of −119 km/s. In about 40,000 years it will be the closest star for a period of several thousand years.
Gliese 710 is currently about from Earth, but its proper motion, distance, and radial velocity indicate that it will approach within a very small distance—perhaps under one light year—from the Sun within 1.4 million years, based on past and current "Hipparcos" data. At closest approach it will be a first-magnitude star about as bright as Antares. The proper motion of Gliese 710 is very small for its distance, meaning it is traveling nearly directly in our line of sight.
In a time interval of ±10 million years from the present, Gliese 710 is the star whose combination of mass and close approach distance will cause the greatest gravitational perturbation of the Solar System.
HIP 85605 is also concerning. Its spectral type and trajectory are not fully understood. More-accurate astrometry is required to determine the distance to the star, and thus if it will pass close to the Sun. It was estimated in 2014 that HIP 85605 could approach to about 0.13 to 0.65 light-years (0.04 to 0.2 pc) from the Sun within 240,000 to 470,000 years.

</doc>
<doc id="28163" url="https://en.wikipedia.org/wiki?curid=28163" title="Sagitta">
Sagitta

Sagitta is a dim but distinctive constellation in the northern sky. Its name is Latin for "arrow", and it should not be confused with the larger constellation Sagittarius, the archer. Although Sagitta is an ancient constellation, it has no star brighter than 3rd magnitude and has the third-smallest area of all constellations (only Equuleus and Crux are smaller). It was included among the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations defined by the International Astronomical Union. Located to the north of the equator, Sagitta can be seen from every location on Earth except within the Antarctic circle.
The red giant Gamma Sagittae is the constellation's brightest star, with an apparent magnitude of 3.47. Two star systems have been found to have planets.
Characteristics.
Covering 79.9 square degrees and hence 0.194% of the sky, Sagitta ranks 86th of the 88 modern constellations by area. Its position in the Northern Celestial Hemisphere means that the whole constellation is visible to observers north of 69°S. It is bordered by Vulpecula to the north, Hercules to the west, Aquila to the south, and Delphinus to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'Sge'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of twelve segments ("illustrated in infobox"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 16.08° and 21.64°.
Notable features.
Stars.
Johann Bayer gave Bayer designations to eight stars, labelling them Alpha to Theta. What was viewed by Bayer, Friedrich Wilhelm Argelander and Heis as a single star Theta was in fact three stars, and is now equated to HR 7705. John Flamsteed added the letters x (mistaken as Chi), y and z to 13, 14 and 15 Sagittae in his Catalogus Britannicus. All three were dropped by Bevis and Baily.
In his "Uranometria", Bayer depicted Alpha, Beta and Epsilon Sagittae as the fins of the arrow. Also known as Sham, Alpha is a yellow bright giant star of spectral class G1 II (with an apparent magnitude of 4.38, which lies at a distance of 430 ± 10 light-years from Earth. Originally 4 times as massive as the Sun, it has swollen and brightened to 20 times its diameter and 340 times its luminosity. Also of magnitude 4.38, Beta is a G-type giant located 440 ± 20 light-years distant from Earth. Epsilon Sagittae is G8 III, 5.66m, multiple star (4 components; component B is optical)
Ptolemy saw the constellation's brightest star Gamma Sagittae as marking the arrow's head, while Bayer saw Gamma, Eta and Theta as depicting the arrow's shaft. Gamma Sagittae is a red giant of spectral type M0III, and magnitude 3.47. It lies at a distance of 258 ± 4 light-years from Earth. Eta Sagittae is a star of spectral class K2 III with a magnitude of 5.1, which belongs to the Hyades Stream. Theta Sagittae is a multiple star system.
Delta and Zeta depicted the spike according to Bayer. Delta Sagittae is a suspected visual double - M2 II+A0 V probably single image, composite spectrum), magnitude 3.82. Zeta Sagittae is a triple system, approximately 326 light-years from Earth, the primary an A-type star.
FG Sagittae is a remote highly luminous star around 8000 light years distant from Earth. WR 124 is a Wolf-Rayet star moving at great speed surrounded by a nebula of ejected gas.
R Sagittae is a member of the rare RV Tauri variable class of star. It ranges in magnitude from 8.2 to 10.4.
S Sagittae is a Classical Cepheid variable that varies from magnitude 5.24 to 6.04 in 8.38 days. It is a yellow-white supergiant that varies between spectral types F6Ib and G5Ib. Around 6 or 7 times as massive and 3500 time as luminous as the Sun, it is located around 2300 light-years away from Earth.
Located near 18 Sagittae is V Sagittae.
WZ Sagittae is a dwarf nova composed of a white dwarf and low mass star companion. The black widow pulsar (B1957+20) is a millisecond pulsar with a brown dwarf companion.
HD 231701 is a yellow-white main sequence star hotter and larger than our Sun, which was found to have a planet in 2007. 15 Sagittae is a solar analog that has a brown dwarf substellar companion.
Deep-sky objects.
Messier 71 is a very loose globular cluster mistaken for quite some time for a dense open cluster. It lies at a distance of about 13,000 light-years from Earth and was first discovered by the French astronomer Philippe Loys de Chéseaux in the year 1745 or 1746.
History.
The Greeks who may have originally identified this constellation called it "Oistos". The Romans named it Sagitta.
Mythology.
Sagitta's shape is reminiscent of an arrow, and many cultures have interpreted it thus, among them the Persians, Hebrews, Greeks and Romans. The Arabs called it "as-Sahm", a name that was transferred "Sham" and now refers to α Sge only.
Ancient Greece.
In ancient Greece, Sagitta was regarded as the weapon that Hercules used to kill the eagle (Aquila) of Jove that perpetually gnawed Prometheus' liver. The Arrow is located beyond the north border of Aquila, the Eagle. According to R.H. Allen, the Arrow could be the one shot by Hercules towards the adjacent Stymphalian birds (6th labor) who had claws, beaks and wings of iron, and who lived on human flesh in the marshes of Arcadia - Aquila the Eagle, Cygnus the Swan, and Lyra (the Vulture) - and still lying between them, whence the title Herculea (although Allen cites no reference to support this assertion). Eratosthenes claimed it as the arrow with which Apollo exterminated the Cyclopes.

</doc>
<doc id="28164" url="https://en.wikipedia.org/wiki?curid=28164" title="Simon Ockley">
Simon Ockley

Simon Ockley (1678 – 9 August 1720) was a British Orientalist.
Biography.
Ockley was born at Exeter. He was educated at Queens' College, Cambridge, and graduated B.A. in 1697, MA. in 1701, and B.D. in 1710. He became fellow of Jesus College and vicar of Swavesey, and in 1711 was chosen Adams Professor of Arabic in the university. He had a large family, and his latter days were embittered by pecuniary embarrassments, which form the subject of a chapter in Isaac D'Israeli's "Calamities of Authors".
The preface to the second volume of his "History of the Saracens" is dated from Cambridge Castle, where he lay a prisoner for debt.
Ockley maintained that a knowledge of Oriental literature was essential to the proper study of theology, and in the preface to his first book, the "Introductio ad linguas orientales" (1706), he urges the importance of the study.
He died at Swavesey.

</doc>
<doc id="28165" url="https://en.wikipedia.org/wiki?curid=28165" title="Sharable Content Object Reference Model">
Sharable Content Object Reference Model

Sharable Content Object Reference Model (SCORM) is a collection of standards and specifications for web-based electronic educational technology (also called e-learning). It defines communications between client side content and a host system (called "the run-time environment"), which is commonly supported by a learning management system. SCORM also defines how content may be packaged into a transferable ZIP file called "Package Interchange Format."
SCORM is a specification of the Advanced Distributed Learning (ADL) Initiative from the Office of the United States Secretary of Defense.
SCORM 2004 introduced a complex idea called sequencing, which is a set of rules that specifies the order in which a learner may experience content objects. In simple terms, they constrain a learner to a fixed set of paths through the training material, permit the learner to "bookmark" their progress when taking breaks, and assure the acceptability of test scores achieved by the learner. The standard uses XML, and it is based on the results of work done by AICC, IMS Global, IEEE, and Ariadne.
SCORM versions.
SCORM 1.1-.
SCORM 1.1 is the first production version. It used a Course Structure Format XML file based on the AICC specifications to describe content structure, but lacked a robust packaging manifest and support for metadata. Quickly abandoned in favor of SCORM 1.2.
SCORM 1.2.
This was the first version that was widely used. It is still widely used and is supported by most Learning Management Systems.
SCORM 2004.
This is the current version. It is based on new standards for API and content object-to-runtime environment communication, with many ambiguities of previous versions resolved. Includes ability to specify adaptive sequencing of activities that use the content objects. Includes ability to share and use information about the success status for multiple learning objectives or competencies across content objects and across courses for the same learner within the same learning management system. A more robust test suite helps ensure good interoperability.
Experience API (Tin Can API).
The Experience API (also known as xAPI or Tin Can API) was finalized to version 1.0 in April 2013. The Experience API solves many of the problems inherent with older versions of SCORM. Just like SCORM, ADL is the steward of the Experience API. AICC with their CMI-5 planned to use xAPI as their transport standard, but AICC membership decided to dissolve the organization and transferred CMI-5 to ADL.
The Experience API (Tin Can API) is a web service that allows software clients to read and write experiential data in the form of “statement” objects. In their simplest form, statements are in the form of “I did this”, or more generally “actor verb object”. More complex statement forms can be used. There is also a built-in query API to help filter recorded statements, and a state API that allows for a sort of “scratch space” for consuming applications. Experience API statements are stored in a data store called a Learning Record Store, which can exist on its own or within a Learning Management System.

</doc>
<doc id="28167" url="https://en.wikipedia.org/wiki?curid=28167" title="Sejm">
Sejm

The Sejm of the Republic of Poland (; ) is the lower house of the Polish parliament. It consists of 460 deputies (posłowie, literally "envoys", in Polish) elected by universal ballot and is presided over by a speaker called the "Marshal of the "Sejm" of the Republic of Poland" ("Marszałek Sejmu Rzeczypospolitej Polskiej"). In the Kingdom of Poland, ""Sejm"" referred to the entire three-chamber parliament of Poland, comprising the lower house (the Chamber of Envoys; ), the upper house (the Senate; Polish: "Senat") and the King. It was thus a three-estate parliament. Since the Second Polish Republic (1918–1939), ""Sejm"" has referred only to the lower house of the parliament; the upper house is called the "Senat Rzeczypospolitej Polskiej" ("Senate of the Republic of Poland").
History.
Partitions.
After the fall of the Duchy of Warsaw, which existed as a Napoleonic client state between 1807 and 1815, and its short-lived "Sejm" of the Duchy of Warsaw, the "Sejm" of Congress Poland was established in the "Kongresówka" (Congress Poland) of Russia; it was composed of the king (the Russian emperor), the upper house (Senate), and the lower house (Chamber of Envoys). Overall, during the period from 1795 until the re-establishment of Poland's sovereignty in 1918, little power was actually held by any Polish legislative body and the occupying powers of Russia, Prussia (later united Germany) and Austria-Hungary propagated legislation for their own respective formerly-Polish territories at a national level.
Congress Poland.
The Chamber of Envoys, despite its name, consisted not only of 77 envoys (sent by local assemblies) from the hereditary nobility, but also of 51 deputies, elected by the non-noble population. All deputies were covered by Parliamentary immunity, with each individual serving for a term of office of six years, with half of the deputies being elected every two years. Candidates for deputy had to be able to read and write, and have a certain amount of wealth. The legal voting age was 21, except for those citizens serving in the military, the personnel of which were not allowed to vote. Parliamentary sessions were initially convened every two years, and lasted for (at least) 30 days. However, after many clashes between liberal deputies and conservative government officials, sessions were later called only four times (1818, 1820, 1826, and 1830, with the last two sessions being secret). The "Sejm" had the right to call for votes on civil and administrative legal issues, and, with permission from the king, it could also vote on matters related to the fiscal policy and the military. It had the right to exercise control over government officials, and to file petitions. The 64-member Senate on the other hand, was composed of "voivodes" and "kasztelans" (both types of provincial governors), Russian "princes of the blood", and nine bishops. It acted as the Parliamentary Court, had the right to control "citizens' books", and had similar legislative rights as did the Chamber of Deputies.
Germany and Austria-Hungary.
In the Free City of Cracow (1815–1846), a unicameral Assembly of Representatives was established, and from 1827, a unicameral provincial "sejm" existed in the Grand Duchy of Poznań. Poles were elected to and represented the majority in both of these legislatures; however, they were largely powerless institutions and exercised only very limited power. After numerous failures in securing legislative sovereignty in the early 19th century, many Poles simply gave up trying to attain a degree of independence from their foreign master-states. In the Austrian partition, a relatively powerless "Sejm" of the Estates operated until the time of the Spring of Nations. After this, in the mid to late 19th century, only in autonomous Galicia (1861–1914) was there a unicameral and functional National "Sejm", the "Sejm" of the Land. It is recognised today as having played a major and overwhelming positive role in the development of Polish national institutions.
In the second half of the 19th century, Poles were able to become members of the parliaments of Austria, Prussia and Russia, where they formed Polish Clubs. Deputies of Polish nationality were elected to the Prussian "Landtag" from 1848, and then to the German Empire's "Reichstag" from 1871. Polish Deputies were members of the Austrian State Council (from 1867), and from 1906 were also elected to the Russian Imperial State "Duma" (lower chamber) and to the State Council (upper chamber).
Second Republic.
After the First World War and re-establishment of Polish independence, the convocation of parliament, under the democratic electoral law of 1918, became an enduring symbol of the new state's wish to demonstrate and establish continuity with the 300-year Polish parliamentary traditions established before the time of the partitions. Maciej Rataj emphatically paid tribute to this with the phrase: "There is Poland there, and so is the "Sejm"".
During the interwar period of Poland's independence, the first Legislative "Sejm" of 1919, a Constituent Assembly, passed the Small Constitution of 1919, which introduced a parliamentary republic and proclaimed the principle of the "Sejm"'s sovereignty. This was then strengthened, in 1921, by the March Constitution, one of the most democratic European constitutions enacted after the end of World War I. The constitution established a political system which was based on Montesquieu's doctrine of separation of powers, and which restored the bicameral "Sejm" consisting of a lower house (to which alone the name of ""Sejm"" was from then on applied) and an upper house, the Senate. In 1919, Roza Pomerantz-Meltzer, a member of the Zionist party, became the first woman ever elected to the "Sejm".
The legal content of the March Constitution allowed for "Sejm" supremacy in the system of state institutions at the expense of the executive powers, thus creating a parliamentary republic out of the Polish state. An attempt to strengthen executive powers in 1926 (through the August Amendment) proved too limited and largely failed in helping avoid legislative grid-lock which had ensued as a result of too-great parliamentary power in a state which had numerous diametrically-opposed political parties sitting in its legislature. In 1935, the parliamentary republic was weakened further when, by way of, Józef Piłsudski's May Coup, the president was forced to sign the April Constitution of 1935, an act through which the head of state assumed the dominant position in legislating for the state and the Senate increased its power at the expense of the "Sejm".
On 2 September 1939, the "Sejm" held its final pre-war session, during which it declared Poland's readiness to defend itself against invading German forces. On 2 November 1939, the President dissolved the "Sejm" and the Senate, which were then, according to plan, to resume their activity within two months after the end of the Second World War; this, however, never happened. During wartime, the National Council (1939–1945) was established to represent the legislature as part of the Polish Government in Exile. Meanwhile, in Nazi-occupied Poland, the Council of National Unity was set up; this body functioned from 1944 to 1945 as the parliament of the Polish Underground State. With the cessation of hostilities in 1945, and subsequent rise to power of the Communist-backed Provisional Government of National Unity, the Second Polish Republic legally ceased to exist.
Polish People's Republic.
The "Sejm" in the Polish People's Republic had 460 deputies throughout most of its history. At first, this number was declared to represent one deputy per 60,000 citizens (425 were elected in 1952), but, in 1960, as the population grew, the declaration was changed: The constitution then stated that the deputies were representative "of" the people and could be recalled "by" the people, but this article was never used, and, instead of the "five-point electoral law", a non-proportional, "four-point" version was used. Legislation was passed with majority voting.
The "Sejm" voted on the budget as well as on the periodic national plans that were a fixture of communist economies. The "Sejm" deliberated in sessions that were ordered to convene by the State Council.
The "Sejm" also chose a "Prezydium" ("presiding body") from among its members; the marshall of which was always a member of the United People's Party. In its preliminary session, the "Sejm" also nominated the Prime Minister, the Council of Ministers of Poland, and members of the State Council. It also chose many other government officials, including the head of the Supreme Chamber of Control and members of the State Tribunal and the Constitutional Tribunal, as well as the Ombudsman (the last three bodies of which were created in the 1980s).
The Senate of Poland was abolished by the Polish people's referendum in 1946, after which the "Sejm" became the sole legislative body in Poland. Even though the "Sejm" was largely subservient to the Communist party, it is worth noting that a single brave deputy, Romuald Bukowski (Independent) voted against the imposition of martial law in 1982.
Today.
After the end of communism in 1989, the Senate was reinstated as the upper house of a bicameral national assembly, while the "Sejm" became the lower house. The "Sejm" is now composed of 460 deputies elected by proportional representation every four years.
Between 7 and 19 deputies are elected from each constituency using the d'Hondt method (with one exception, in 2001, when the Sainte-Laguë method was used), their number being proportional to their constituency's population. Additionally, a threshold is used, so that candidates are chosen only from parties that gained at least 5% of the nationwide vote (candidates from ethnic-minority parties are exempt from this threshold).

</doc>
<doc id="28168" url="https://en.wikipedia.org/wiki?curid=28168" title="Stock exchange">
Stock exchange

A stock exchange or bourse is an exchange where stock brokers and traders can buy and/or sell stocks (also called shares), bonds, and other securities. Stock exchanges may also provide facilities for issue and redemption of securities and other financial instruments, and capital events including the payment of income and dividends. Securities traded on a stock exchange include stock issued by listed companies, unit trusts, derivatives, pooled investment products and bonds. Stock exchanges often function as "continuous auction" markets, with buyers and sellers consummating transactions at a central location, such as the floor of the exchange.
To be able to trade a security on a certain stock exchange, it must be listed there. Usually, there is a central location at least for record keeping, but trade is increasingly less linked to such a physical place, as modern markets use electronic networks, which gives them advantages of increased speed and reduced cost of transactions. Trade on an exchange is restricted to brokers who are members of the exchange. In recent years, various other trading venues, such as electronic communication networks, alternative trading systems and "dark pools" have taken much of the trading activity away from traditional stock exchanges.
The initial public offering of stocks and bonds to investors is by definition done in the primary market and subsequent trading is done in the secondary market. A stock exchange is often the most important component of a stock market. Supply and demand in stock markets are driven by various factors that, as in all free markets, affect the price of stocks (see stock valuation).
There is usually no obligation for stock to be issued via the stock exchange itself, nor must stock be subsequently traded on the exchange. Such trading may be "off exchange" or over-the-counter. This is the usual way that derivatives and bonds are traded. Increasingly, stock exchanges are part of a global securities market.
History.
The idea of debt dates back to the ancient world, as evidenced for example by ancient Mesopotamian clay tablets recording interest-bearing loans. There is little consensus among scholars as to when corporate stock was first traded. Some see the key event as the Dutch East India Company's founding in 1602, while others point to earlier developments. Economist Ulrike Malmendier of the University of California at Berkeley argues that a share market existed as far back as ancient Rome.
In the Roman Republic, which existed for centuries before the Empire was founded, there were "societates publicanorum", organizations of contractors or leaseholders who performed temple-building and other services for the government. One such service was the feeding of geese on the Capitoline Hill as a reward to the birds after their honking warned of a Gallic invasion in 390 B.C. Participants in such organizations had "partes" or shares, a concept mentioned various times by the statesman and orator Cicero. In one speech, Cicero mentions "shares that had a very high price at the time." Such evidence, in Malmendier's view, suggests the instruments were tradable, with fluctuating values based on an organization's success. The "societas" declined into obscurity in the time of the emperors, as most of their services were taken over by direct agents of the state.
Tradable bonds as a commonly used type of security were a more recent innovation, spearheaded by the Italian city-states of the late medieval and early Renaissance periods.
The Dutch East India Company, formed to build up the spice trade, operated as a colonial ruler in what's now Indonesia and beyond, a purview that included conducting military operations against wishes of the exploited natives and competing colonial powers. Control of the company was held tightly by its directors, with ordinary shareholders not having much influence on management or even access to the company's accounting statements.
However, shareholders were rewarded well for their investment. The company paid an average dividend of over 16 percent per year from 1602 to 1650. Financial innovation in Amsterdam took many forms. In 1609, investors led by one Isaac Le Maire formed history's first bear syndicate, but their coordinated trading had only a modest impact in driving down share prices, which tended to be robust throughout the 17th century. By the 1620s, the company was expanding its securities issuance with the first use of corporate bonds.
Joseph de la Vega, also known as Joseph Penso de la Vega and by other variations of his name, was an Amsterdam trader from a Spanish Jewish family and a prolific writer as well as a successful businessman in 17th-century Amsterdam. His 1688 book "Confusion of Confusions" explained the workings of the city's stock market. It was the earliest book about stock trading, taking the form of a dialogue between a merchant, a shareholder and a philosopher, the book described a market that was sophisticated but also prone to excesses, and de la Vega offered advice to his readers on such topics as the unpredictability of market shifts and the importance of patience in investment.
William sought to modernize England's finances to pay for its wars, and thus the kingdom's first government bonds were issued in 1693 and the Bank of England was set up the following year. Soon thereafter, English joint-stock companies began going public.
London's first stockbrokers, however, were barred from the old commercial center known as the Royal Exchange, reportedly because of their rude manners. Instead, the new trade was conducted from coffee houses along Exchange Alley. By 1698, a broker named John Castaing, operating out of Jonathan's Coffee House, was posting regular lists of stock and commodity prices. Those lists mark the beginning of the London Stock Exchange.
One of history's greatest financial bubbles occurred in the next few decades. At the center of it were the South Sea Company, set up in 1711 to conduct English trade with South America, and the Mississippi Company, focused on commerce with France's Louisiana colony and touted by transplanted Scottish financier John Law, who was acting in effect as France's central banker. Investors snapped up shares in both, and whatever else was available. In 1720, at the height of the mania, there was even an offering of "a company for carrying out an undertaking of great advantage, but nobody to know what it is."
By the end of that same year, share prices were collapsing, as it became clear that expectations of imminent wealth from the Americas were overblown. In London, Parliament passed the Bubble Act, which stated that only royally chartered companies could issue public shares. In Paris, Law was stripped of office and fled the country. Stock trading was more limited and subdued in subsequent decades. Yet the market survived, and by the 1790s shares were being traded in the young United States.
Role of stock exchanges.
Stock exchanges have multiple roles in the economy. This may include the following:
Raising capital for businesses.
A stock exchange provides companies with the facility to raise capital for expansion through selling shares to the investing public.
Common forms of capital raising.
Besides the borrowing capacity provided to an individual or firm by the banking system, in the form of credit or a loan, there are four common forms of capital raising used by companies and entrepreneurs. Most of these available options might be achieved, directly or indirectly, through a stock exchange.
Going public.
Capital intensive companies, particularly high tech companies, always need to raise high volumes of capital in their early stages. For this reason, the public market provided by the stock exchanges has been one of the most important funding sources for many capital intensive startups. After the 1990s and early-2000s hi-tech listed companies' boom and bust in the world's major stock exchanges, it has been much more demanding for the high-tech entrepreneur to take his/her company public, unless either the company already has products in the market and is generating sales and earnings, or the company has completed advanced promising clinical trials, earned potentially profitable patents or conducted market research which demonstrated very positive outcomes. This is quite different from the situation of the 1990s to early-2000s period, when a number of companies (particularly Internet boom and biotechnology companies) went public in the most prominent stock exchanges around the world, in the total absence of sales, earnings and any well-documented promising outcome. Anyway, every year a number of companies, including unknown highly speculative and financially unpredictable hi-tech startups, are listed for the first time in all the major stock exchanges – there are even specialized entry markets for these kind of companies or stock indexes tracking their performance (examples include the Alternext, CAC Small, SDAX, TecDAX, or most of the third market good companies).
Limited partnerships.
A number of companies have also raised significant amounts of capital through R&D limited partnerships. Tax law changes that were enacted in 1987 in the United States changed the tax deductibility of investments in R&D limited partnerships. In order for a partnership to be of interest to investors today, the cash on cash return must be high enough to entice investors.
Venture capital.
A third usual source of capital for startup companies has been venture capital. This source remains largely available today, but the maximum statistical amount that the venture company firms in aggregate will invest in any one company is not limitless (it was approximately $15 million in 2001 for a biotechnology company).
Corporate partners.
A fourth alternative source of cash for a private company is a corporate partner, usually an established multinational company, which provides capital for the smaller company in return for marketing rights, patent rights, or equity. Corporate partnerships have been used successfully in a large number of cases.
Mobilizing savings for investment.
When people draw their savings and invest in shares (through an IPO or the issuance of new company shares of an already listed company), it usually leads to rational allocation of resources because funds, which could have been consumed, or kept in idle deposits with banks, are mobilized and redirected to help companies' management boards finance their organizations. This may promote business activity with benefits for several economic sectors such as agriculture, commerce and industry, resulting in stronger economic growth and higher productivity levels of firms.
Facilitating company growth.
Companies view acquisitions as an opportunity to expand product lines, increase distribution channels, hedge against volatility, increase their market share, or acquire other necessary business assets. A takeover bid or a merger agreement through the stock market is one of the simplest and most common ways for a company to grow by acquisition or fusion.
Profit sharing.
Both casual and professional stock investors, as large as institutional investors or as small as an ordinary middle-class family, through dividends and stock price increases that may result in capital gains, share in the wealth of profitable businesses. Unprofitable and troubled businesses may result in capital losses for shareholders.
Corporate governance.
By having a wide and varied scope of owners, companies generally tend to improve management standards and efficiency to satisfy the demands of these shareholders, and the more stringent rules for public corporations imposed by public stock exchanges and the government. Consequently, it is alleged that public companies (companies that are owned by shareholders who are members of the general public and trade shares on public exchanges) tend to have better management records than privately held companies (those companies where shares are not publicly traded, often owned by the company founders and/or their families and heirs, or otherwise by a small group of investors).
Despite this claim, some well-documented cases are known where it is alleged that there has been considerable slippage in corporate governance on the part of some public companies. The dot-com bubble in the late 1990s, and the subprime mortgage crisis in 2007–08, are classical examples of corporate mismanagement. Companies like Pets.com (2000), Enron (2001), One.Tel (2001), Sunbeam (2001), Webvan (2001), Adelphia (2002), MCI WorldCom (2002), Parmalat (2003), American International Group (2008), Bear Stearns (2008), Lehman Brothers (2008), General Motors (2009) and Satyam Computer Services (2009) were among the most widely scrutinized by the media.
To assist in corporate governance many banks and companies worldwide utilize securities identification numbers (ISIN) to identify, uniquely, their stocks, bonds and other securities. Adding an ISIN code helps to distinctly identify securities and the ISIN system is used worldwide by funds, companies, and governments.
However, when poor financial, ethical or managerial records are known by the stock investors, the stock and the company tend to lose value. In the stock exchanges, shareholders of underperforming firms are often penalized by significant share price decline, and they tend as well to dismiss incompetent management teams.
Creating investment opportunities for small investors.
As opposed to other businesses that require huge capital outlay, investing in shares is open to both the large and small stock investors because a person buys the number of shares they can afford. Therefore, the Stock Exchange provides the opportunity for small investors to own shares of the same companies as large investors.
Government capital-raising for development projects.
Governments at various levels may decide to borrow money to finance infrastructure projects such as sewage and water treatment works or housing estates by selling another category of securities known as bonds. These bonds can be raised through the stock exchange whereby members of the public buy them, thus loaning money to the government. The issuance of such bonds can obviate, in the short term, direct taxation of citizens to finance development—though by securing such bonds with the full faith and credit of the government instead of with collateral, the government must eventually tax citizens or otherwise raise additional funds to make any regular coupon payments and refund the principal when the bonds mature.
Barometer of the economy.
At the stock exchange, share prices rise and fall depending, largely, on economic forces. Share prices tend to rise or remain stable when companies and the economy in general show signs of stability and growth. An economic recession, depression, or financial crisis could eventually lead to a stock market crash. Therefore, the movement of share prices and in general of the stock indexes can be an indicator of the general trend in the economy.
Listing requirements.
Listing requirements are the set of conditions imposed by a given stock exchange upon companies that want to be listed on that exchange. Such conditions sometimes include minimum number of shares outstanding, minimum market capitalization, and minimum annual income.
Requirements by stock exchange.
Companies must meet an exchange's requirements to have their stocks and shares listed and traded there, but requirements vary by stock exchange:
Ownership.
Stock exchanges originated as mutual organizations, owned by its member stock brokers. There has been a recent trend for stock exchanges to "demutualize", where the members sell their shares in an initial public offering. In this way the mutual organization becomes a corporation, with shares that are listed on a stock exchange. Examples are Australian Securities Exchange (1998), Euronext (merged with New York Stock Exchange), NASDAQ (2002), Bursa Malaysia (2004), the New York Stock Exchange (2005), Bolsas y Mercados Españoles, and the São Paulo Stock Exchange (2007).
The Shenzhen and Shanghai stock exchanges can been characterized as quasi-state institutions insofar as they were created by government bodies in China and their leading personnel are directly appointed by the China Securities Regulatory Commission. 
Another example is Tashkent republican stock exchange (Uzbekistan) established in 1994, three years after collapse of Soviet Union, mainly state-owned but has a form of a public corporation (joint stock company). According to an Uzbek government decision (March 2012) 25 percent minus one share of Tashkent stock exchange was expected to be sold to Korea Exchange(KRX) in 2014.
Other types of exchanges.
In the 19th century, exchanges were opened to trade forward contracts on commodities. Exchange traded forward contracts are called futures contracts. These "commodity exchanges" later started offering future contracts on other products, such as interest rates and shares, as well as options contracts. They are now generally known as futures exchanges.
See also.
Lists:

</doc>
<doc id="28170" url="https://en.wikipedia.org/wiki?curid=28170" title="Son of God">
Son of God

Historically, many rulers have assumed titles such as son of god, son of a god or son of Heaven.
The term "son of God" is sometimes used in the Old and New Testaments of the Bible to refer to those with special relationships with God. In the Old Testament, angels, just and pious men, the descendants of Seth, and the kings of Israel are all called "sons of God." In the New Testament, Adam, and, most notably, Jesus Christ are called "son of God," while followers of Jesus are called, "sons of God."
In the New Testament, "Son of God" is applied to Jesus on many occasions. Jesus is declared to be the Son of God on two separate occasions by a voice speaking from Heaven. Jesus is also explicitly and implicitly described as the Son of God by himself and by various individuals who appear in the New Testament. As applied to Jesus, the term is a reference to his role as the Messiah, the King chosen by God. The contexts and ways in which Jesus' title, Son of God, means something more than or other than Messiah remain the subject of ongoing scholarly study and discussion.
The term "Son of God" should not be confused with the term "God the Son" (), the second Person of the Trinity in Christian theology. The doctrine of the Trinity identifies Jesus as God the Son, "identical in essence but distinct in person" with regard to God the Father and God the Holy Spirit (the first and third Persons of the Trinity). Nontrinitarian Christians accept the application to Jesus of the term "Son of God", which is found in the New Testament, but not the term "God the Son", which is not found there.
Rulers and Imperial titles.
Throughout history, emperors and rulers ranging from the Western Zhou dynasty (c. 1000 BC) in China to Alexander the Great (c. 360 BC) to the Emperor of Japan (c. 600 AD) have assumed titles that reflect a filial relationship with deities.
The title "Son of Heaven" i.e. 天子 (from 天 meaning sky/heaven/god and 子 meaning child) was first used in the Western Zhou dynasty (c. 1000 BC). It is mentioned in the Shijing book of songs, and reflected the Zhou belief that as Son of Heaven (and as its delegate) the Emperor of China was responsible for the well being of the whole world by the Mandate of Heaven. This title may also be translated as "son of God" given that the word "Ten" or "Tien" in Chinese may either mean sky or god. The Emperor of Japan was also called the Son of Heaven (天子 "tenshi") starting in the early 7th century.
Among the Steppe Peoples, there was also a widespread use of "Son of God/Son of Heaven" for instance, in the Third Century B.C., the ruler was called Chanyü and similar titles were used as late as the 13th Century by Genghis Khan.
Examples of kings being considered the son of god are found throughout the Ancient Near East. Egypt in particular developed a long lasting tradition. Egyptian pharaohs are known to have been referred to as the son of a particular god and their begetting in some cases is even given in sexually explicit detail. Egyptian pharaohs did not have full parity with their divine fathers but rather were subordinate. Nevertheless, in the first four dynasties, the pharaoh was considered to be the embodiment of a god. Thus, Egypt was ruled by direct theocracy, wherein "God himself is recognized as the head" of the state. During the later Amarna Period, Akhenaten reduced the Pharaoh's role to one of coregent, where the Pharaoh and God ruled as father and son. Akhenaten also took on the role of the priest of god, eliminating representation on his behalf by others. Later still, the closest Egypt came to the Jewish variant of theocracy was during the reign of Herihor. He took on the role of ruler not as a god but rather as a high-priest and king.
Jewish kings are also known to have been referred to as "son of the wikt:LORD". The Jewish variant of theocracy can be thought of as a representative theocracy where the king is viewed as God’s surrogate on earth. Jewish kings thus, had less of a direct connection to god than pharaohs. Unlike pharaohs, Jewish kings rarely acted as priests, nor were prayers addressed directly to them. Rather, prayers concerning the king are addressed directly to god. The Jewish philosopher Philo is known to have likened God to a supreme king, rather than likening Jewish kings to gods.
Based on the Bible, several kings of Damascus took the title son of Hadad. From the archaeological record a stela erected by Bar-Rakib for his father Panammuwa II contains similar language. The son of Panammuwa II a king of Sam'al referred to himself as a son of Rakib. Rakib-El is a god who appears in Phoenician and Aramaic inscriptions. Panammuwa II died unexpectedly while in Damascus. However, his son the king Bar-Rakib was not a native of Damascus but rather the ruler of Sam'al it is unknown if other rules of Sam'al used similar language.
In Greek mythology, Heracles (son of Zeus) and many other figures were considered to be sons of gods through union with mortal women. From around 360 BC onwards Alexander the Great may have implied he was a demigod by using the title "Son of Ammon–Zeus".
In 42 BC, Julius Caesar was formally deified as "the divine Julius" ("divus Iulius") after his assassination. His adopted son, Octavian (better known as Augustus, a title given to him 15 years later, in 27 BC) thus became known as "divi Iuli filius" (son of the divine Julius) or simply "divi filius" (son of the god). As a daring and unprecedented move, Augustus used this title to advance his political position in the Second Triumvirate, finally overcoming all rivals for power within the Roman state.
The word applied to Julius Caesar as deified was "divus", not the distinct word "deus". Thus Augustus called himself "Divi filius", and not "Dei filius". The line between been god and god-like was at times less than clear to the population at large, and Augustus seems to have been aware of the necessity of keeping the ambiguity. As a purely semantic mechanism, and to maintain ambiguity, the court of Augustus sustained the concept that any worship given to an emperor was paid to the "position of emperor" rather than the person of the emperor. However, the subtle semantic distinction was lost outside Rome, where Augustus began to be worshiped as a deity. The inscription DF thus came to be used for Augustus, at times unclear which meaning was intended. The assumption of the title "Divi filius" by Augustus meshed with a larger campaign by him to exercise the power of his image. Official portraits of Augustus made even towards the end of his life continued to portray him as a handsome youth, implying that miraculously, he never aged. Given that few people had ever seen the emperor, these images sent a distinct message.
Later, Tiberius (emperor from 14–37 AD) came to be accepted as the son of "divus Augustus" and Hadrian as the son of "divus Trajan". By the end of the 1st century, the emperor Domitian was being called "dominus et deus" (i.e. "master and god").
Outside the Roman Empire, the 2nd century Kushan King Kanishka I used the title "devaputra" meaning "son of God".
Judaism.
Although references to "sons of God", "son of God" and "son of the " are occasionally found in Jewish literature, they never refer to physical descent from God. There are two instances where Jewish kings are figuratively referred to as a god. The king is likened to the supreme king God. These terms are often used in the general sense in which the Jewish people were referred to as "children of the your God".
When used by the rabbis, the term referred to Israel or to human beings in general, and not as a reference to the Jewish mashiach. In Judaism the term "mashiach" has a broader meaning and usage and can refer to a wide range of people and objects, not necessarily related to the Jewish eschaton.
Genesis.
In the introduction to the Genesis flood narrative, refers to "sons of God" who married the daughters of men and is used in a polytheistic context to refer to angels.
Exodus.
In , the Israelites as a people are called "my firstborn son" by God using the singular form.
Psalms.
In , David calls God his father. God in turn tells David that he will make David his first-born and highest king of the earth.
In , the Biblical judges are called gods and the sons of God.
Royal Psalms.
Psalm 2 is thought to be an enthronement text. The rebel nations and the uses of an iron rod are Assyrian motifs. The begetting of the king is an Egyptian one. Israel’s kings are referred to as the son of the . They are reborn or adopted on the day of their enthroning as the "son of the ".
Some scholars think that Psalm 110 is an alternative enthronement text. Psalm 110:1 distinguishes the king from the . The LORD asks the king to sit at his right hand. Psalm 110:3 may or may not have a reference to the begetting of kings. The exact translation of 110:3 is uncertain. In the traditional Hebrew translations his youth is renewed like the morning dew. In some alternative translations the king is begotten by God like the morning dew or by the morning dew. One possible translation of 110:4 is that the king is told that he is a priest like Melchizedek. Another possibility is to translate Melchizedek not as a name but rather as a title "Righteous King". If a reference is made to Melchizedek this could be linked to pre-Israelite Canaanite belief. The invitation to sit at the right hand of the deity and the king’s enemy’s being used as footstools are both classic Egyptian motifs, as is the association of the king with the rising sun. Many scholars now think that Israelite beliefs evolved from Canaanite beliefs. Jews have traditionally believed that Psalm 110 applied only to King David. Being the first Davidic king, he had certain priest-like responsibilities.
Psalm 45 is thought to be a royal wedding text. Psalm 45:7-8 may refer to the king as a god anointed by God, reflecting the king’s special relationship with God.
Some believe that these psalms where not meant to apply to a single king, but rather where used during the enthronement ceremony. The fact that the Royal Psalms were preserved suggests that the influence of Egyptian and other near eastern cultures on pre-exile religion needs to be taken seriously. Ancient Egyptians used similar language to describe pharaohs. Assyrian and Canaanite influences among others are also noted.
Samuel.
In God promises David regarding his offspring that "I will be to him as a father and he will be to me as a son." The promise is one of eternal kingship.
Isaiah.
In Isaiah 9:6 the next king is greeted, similarly to the passages in Psalms. Like Psalm 45:7-8 he is figuratively likened to the supreme king God. Isaiah could also be interpreted as the birth of a royal child, Psalm 2 nevertheless leaves the accession scenario as an attractive possibility. The king in 9:6 is thought to have been Hezekiah by Jews and various academic scholars.
Jeremiah.
In Jeremiah Chapter 31 God refers to himself as the father of Israel and Ephraim as his first born son. Ephraim in Jeremiah refers collectively to the northern kingdom.
Book of Wisdom.
The Book of Wisdom refers to a righteous man as the son of God.
Book of Ecclesiasticus.
In the Book of Ecclesiasticus 4:10 in the Hebrew text God calls a person who acts righteously his son. The Greek reads slightly different here he will be “like a son of the Most High".
Dead Sea Scrolls.
In some versions of Deuteronomy the Dead Sea Scrolls refer to the sons of God rather than the sons of Israel, probably in reference to angels. The Septuagint reads similarly.
4Q174 is a midrashic text in which God refers to the Davidic messiah as his son.
4Q246 refers to a figure who will be called the son of God and son of the Most High. It is debated if this figure represents the royal messiah, a future evil gentile king or something else.
In 11Q13 Melchizedek is referred to as god the divine judge. Melchizedek in the bible was the king of Salem. At least some in the Qumran community seemed to think that at the end of days Melchizedek would reign as their king. The passage is based on Psalm 82.
Gabriel's Revelation.
Gabriel's Revelation, also called the Vision of Gabriel or the Jeselsohn Stone, is a three-foot-tall (one metre) stone tablet with 87 lines of Hebrew text written in ink, containing a collection of short prophecies written in the first person and dated to the late 1st century BCE. One of the stories allegedly tells of a man who was killed by the Romans and resurrected in three days. 
It is a tablet described as a "Dead Sea scroll in stone".
The text seems to talk about a messianic figure from Ephraim who broke evil before righteousness by three days. Later the text talks about a “prince of princes" a leader of Israel who was killed by the evil king and not properly buried. The evil king was then miraculously defeated. The text seems to refer to Jeremiah Chapter 31. The choice of Ephraim as the linage of the messianic figure described in the text seems to draw on passages in Jeremiah, Zechariah and Hosea. This leader was referred to as a son of God.
The text seems to be based on a Jewish revolt recorded by Josephus dating from 4 BCE. Based on its dating the text seems to refer to Simon of Peraea, one of the three leaders of this revolt.
Pseudepigrapha.
In both Joseph and Aseneth and the related text The Story of Asenath, Joseph is referred to as the son of God. In the Prayer of Joseph both Jacob and the angel are referred to as angels and the sons of God.
Talmud.
This style of naming is also used for some rabbis in the Talmud.
Christianity.
Of all the Christological titles used in the New Testament, Son of God has had one of the most lasting impacts in Christian history and has become part of the profession of faith by many Christians. In the mainstream Trinitarian context the title implies the full divinity of Jesus as part of the Holy Trinity of Father, Son and the Spirit.
The New Testament quotes Psalm 110 extensively as applying to Jesus. A new theological understanding of Psalm 110:1 and 110:4, distinct from that of Judaism, evolved. Jesus himself quotes Psalm 110 in Luke 20:41-44, Matthew 22:41-45 and Mark 12:35-37. The meanings and authenticity of these quotations are debated among modern scholars. Various modern critical scholars reject that David wrote this psalm. In the Masoretic Text many Psalm including this one are explicitly attributed to David. The superscription is “of David a psalm." Some have suggested that this indicates that Psalm 110 was not written by David. The superscription as it stands is ambiguous. However, Jewish tradition ascribes Psalm 110 and indeed all Psalms to king David. In Christianity David is consider to be a prophet. The New Testament records several psalms as having been spoken through David by the Holy Spirit. Acts 2:29-30 explicitly calls David a prophet. Jesus himself affirms the authorship of this psalm by David in Mark 12:36 and Matthew 22:43. In the Christian reading, David the king is presented as having a lord other than the Lord God. The second lord is the Messiah, who is greater than David, because David calls him "my lord". In Hebrew, the first "Lord" in Psalm 110 is "Yahweh" (יהוה), while the second is referred to as "adoni" (אדני), (my "adon"), a form of address that in the Old Testament is used generally for humans but also, in , for the theophanic Angel of the Lord. The Greek-speaking Jewish philosopher Philo, a contemporary of Jesus, identified the Angel of the Lord with his version of the logos distinct from the later Christian logos.
It’s debated when exactly Christians came to understand Psalm 110 as introducing a distinction of persons in the Godhead and indicating that Jesus was more than a human or angelic messiah, but also a divine entity who was David’s lord. Hebrews 1:13 again quotes Psalm 110 to prove that the Son is superior to angels. Psalm 110 would play a crucial role in the development of the early Christian understanding of the divinity of Jesus. The final reading of Psalm 110:1 incorporated a Preexistent Son of God greater than both David and the angels. The Apostle Creed, The Nicaea Creed and the Creed of Constantinople would all included references to Psalm 110:1.
Psalm 2 can be seen as referring to a particular king of Judah, but has also been understood to reference the awaited Messiah. References to Psalm 2 in the New Testament are less common than Psalm 110. The passages in Acts, Hebrews and Romans that refer to it give the appearance of being linked with Jesus’ resurrection and/or exaltation. Those in the Gospels associate it with Jesus' baptism and transfiguration. The majority of scholars believe that the earliest Christian use of this Psalm was in relation to his resurrection, suggesting that this was initially thought of as the moment when he became Son, a status that the early Christians later extended back to his earthly life, to the beginning of that earthly life and, later still, to his pre-existence, a view that Aquila Hyung Il Lee questions.
The terms "sons of God" and "son of God" appear frequently in Jewish literature, and leaders of the people, kings and princes were called "sons of God". What Jesus did with the language of divine sonship was first of all to apply it individually (to himself) and to fill it with a meaning that lifted "Son of God" beyond the level of his being merely a human being made like Adam in the image of God, his being perfectly sensitive to the Holy Spirit (), his bringing God's peace (; ) albeit in his own way (, ), or even his being God's designated Messiah.
In the New Testament, the title "Son of God" is applied to Jesus on many occasions. It is often used to refer to his divinity, from the beginning of the New Testament narrative when in the angel Gabriel announces: "the power of the Most High shall overshadow thee: wherefore also the holy thing which is begotten shall be called the Son of God."
The declaration that Jesus is the Son of God is echoed by many sources in the New Testament. On two separate occasions the declarations are by God the Father, when during the Baptism of Jesus and then during the Transfiguration as a voice from Heaven. On several occasions the disciples call Jesus the Son of God and even the Jews scornfully remind Jesus during his crucifixion of his claim to be the Son of God."
However, the concept of God as the father of Jesus, and Jesus as the exclusive divine Son of God is distinct from the concept of God as the Creator and father of all people, as indicated in the Apostle's Creed. The profession begins with expressing belief in the "Father almighty, creator of heaven and earth" and then immediately, but separately, in "Jesus Christ, his only Son, our Lord", thus expressing both senses of fatherhood within the Creed.
Synoptic Gospels.
According to the Synoptic Gospels, Jesus referred to himself obliquely as "the Son" and even more significantly spoke of God as "my Father" (; ; ). He not only spoke like "the Son" but also acted like "the Son" in knowing and revealing the truth about God, in changing the divine law, in forgiving sins, in being the one through whom others could become children of God, and in acting with total obedience as the agent for God's final kingdom. This clarifies the charge of blasphemy brought against him at the end (); he had given the impression of claiming to stand on a par with God. Jesus came across as expressing a unique filial consciousness and as laying claim to a unique filial relationship with the God whom he addressed as "Abba".
Even if historically he never called himself "the only" Son of God (cf. ; ), Jesus presented himself as Son and not just as one who was the divinely appointed Messiah (and therefore "son" of God). He made himself out to be more than only someone chosen and anointed as divine representative to fulfil an eschatological role in and for the kingdom. Implicitly, Jesus claimed an essential, "ontological" relationship of sonship towards God which provided the grounds for his functions as revealer, lawgiver, forgiver of sins, and agent of the final kingdom. Those functions (his "doing") depended on his ontological relationship as Son of God (his "being"). Jesus invited his hearers to accept God as a loving, merciful Father. He worked towards mediating to them a new relationship with God, even to the point that they too could use "Abba" when addressing God in prayer. Yet, Jesus' consistent distinction between "my" Father and "your" Father showed that he was not inviting the disciples to share with him an identical relationship of sonship. He was apparently conscious of a qualitative distinction between his sonship and their sonship which was derived from and depended on his. His way of being son was different from theirs.
Paul.
In their own way, John and Paul maintained this distinction. Paul expressed their new relationship with God as taking place through an "adoption" (; ), which makes them "children of God" () or, alternatively, "sons of God" (; (). John distinguished between the only Son of God (; ) and all those who through faith can become "children of God" (; ; and ). Paul and John likewise maintained and developed the correlative of all this, Jesus' stress on the fatherhood of God. Over 100 times John's Gospel names God as "Father". Paul's typical greeting to his correspondents runs as follows: "Grace to you and peace from "God our Father" and the/our Lord Jesus Christ" (; ; ; ; ; ; ). The greeting names Jesus as "Lord", but the context of "God our Father" implies his sonship.
Paul therefore distinguished between their graced situation as God's adopted children and that of Jesus as Son of God. In understanding the latter's "natural" divine sonship, Paul firstly spoke of God "sending his own Son in the likeness of sinful nature and to deal with sin" (). In a similar passage, Paul says that "when the fullness of time had come God sent his Son, born of a woman, born under the law" (). If one examines these three passages in some detail, it raises the question whether Paul thinks of an eternally pre-existent Son coming into the world from his Father in heaven to set humanity free from sin and death () and make it God's adopted children (). The answer will partly depend, first, on the way one interprets other Pauline passages which do not use the title "Son of God" (; ). These latter passages present a pre-existent Christ taking the initiative, through his "generosity" in "becoming poor" for us and "assuming the form of a slave". The answer will, second, depend on whether one judges and to imply that as a pre-existent being the Son was active at creation. without explicitly naming "the Son" as such, runs:
There is one God, the Father, from whom are all things and for whom we exist, and one Lord, Jesus Christ, through whom are all things and through whom we exist.
Calling God "the Father" clearly moves one toward talk of "the Son". In the case of , the whole hymn () does not give Jesus any title. However, he has just been referred to () as God's "beloved Son".
Third, it should be observed that the language of "sending" (or, for that matter, "coming" with its stress on personal purpose (; ) by itself does not necessarily imply pre-existence. Otherwise one would have to ascribe pre-existence to John the Baptist, "a man sent from God", who "came to bear witness to the light" (; cf. ). In the Old Testament, angelic and human messengers, especially prophets, were "sent" by God, but one should add at once that the prophets sent by God were never called God's sons. It makes a difference that in the cited Pauline passages it was God's Son who was sent. Here being "sent" by God means more than merely receiving a divine commission and includes coming from a heavenly pre-existence and enjoying a divine origin. Fourth, in their context, the three Son of God passages here examined (Rom. 8:3, 32; Gal. 4:4) certainly do not focus on the Son's pre-existence, but on his being sent or given up to free human beings from sin and death, to make them God's adopted children, and to let them live (and pray) with the power of the indwelling Spirit. Nevertheless, the Apostle's soteriology presupposes here a Christology that includes divine pre-existence. It is precisely because Christ is the pre-existent Son who comes from the Father that he can turn human beings into God's adopted sons and daughters.
Gospel of John.
In the Gospel of John, Jesus is the eternally pre-existent Son who was sent from heaven into the world by the Father (e.g., ; ; ). He remains conscious of the divine pre-existence he enjoyed with the Father (, ). He is one with the father (; ) and loved by the Father (; ; ; ). The Son has the divine power to give life and to judge (; ; ; ). Through his death, resurrection, and ascension the Son is glorified by the Father (), but it is not a glory that is thereby essentially enhanced. His glory not only existed from the time of the incarnation to reveal the Father (), but also pre-existed the creation of the world (). Where Paul and the author of Hebrews picture Jesus almost as the elder brother or the first-born of God's new eschatological family (; ), John insists even more on the clear qualitative difference between Jesus' sonship and that of others. Being God's "only Son" (; ), he enjoys a truly unique and exclusive relationship with the Father.
At least four of these themes go back to the earthly Jesus himself. First, although one has no real evidence for holding that he was humanly aware of his eternal pre-existence as Son, his "Abba-consciousness" revealed an intimate loving relationship with the Father. The full Johannine development of the Father-Son relationship rests on an authentic basis in the Jesus-tradition (; ; ; ). Second, Jesus not only thought of himself as God's Son, but also spoke of himself as sent by God. Once again, John develops the theme of the Son's mission, which is already present in sayings that at least partly go back to Jesus (; ; ), especially in , where it is a question of the sending of a "beloved Son". Third, the Johannine theme of the Son with power to judge in the context of eternal life finds its original historical source in the sayings of Jesus about his power to dispose of things in the kingdom assigned to him by "my Father" () and about one's relationship to him deciding one's final destiny before God (). Fourth, albeit less insistently, when inviting his audience to accept a new filial relationship with God, Jesus — as previously seen — distinguished his own relationship to God from theirs. The exclusive Johannine language of God's "only Son" has its real source in Jesus' preaching. All in all, Johannine theology fully deploys Jesus' divine sonship, but does so by building up what one already finds in the Synoptic Gospels and what, at least in part, derives from the earthly Jesus himself.
New Testament narrative.
The Gospel of Mark begins by calling Jesus the Son of God and reaffirms the title twice when a voice from Heaven calls Jesus: "my Son" in and .
In after Jesus walks on water, the disciples tell Jesus: "You really are the Son of God!" In response to the question by Jesus, "But who do you say that I am?", Peter replied: "You are Christ, the Son of the living God". And Jesus answered him, "Blessed are you, Simon Bar-Jonah! For flesh and blood has not revealed this to you, but my Father who is in heaven" (). In , while Jesus hangs on the cross, the Jewish leaders mock him to ask God help, "for he said, I am the Son of God", referring to the claim of Jesus to be the Son of God. and include the exclamation by the Roman commander: "He was surely the Son of God!" after the earthquake following the Crucifixion of Jesus.
In , in the Annunciation, before the birth of Jesus, the angel tells Mary that her child "shall be called the Son of God". In (and ), when Jesus casts out demons, they fall down before him, and declare: "You are the Son of God."
In John the Baptist bears witness that Jesus is the Son of God and in Martha calls him the Messiah and the Son of God. In several passages in the Gospel of John assertions of Jesus being the Son of God are usually also assertions of his unity with the Father, as in : "If you know me, then you will also know my Father" and "Whoever has seen me has seen the Father".
In the Jews cry out to Pontius Pilate "Crucify him" based on the charge that Jesus "made himself the Son of God." The charge that Jesus had declared himself "Son of God" was essential to the argument of the Jews from a religious perspective, as the charge that he had called himself King of the Jews was important to Pilate from a political perspective, for it meant possible rebellion against Rome.
Towards the end of his Gospel (in ) John declares that the purpose for writing it was "that you may believe that Jesus is the Messiah, the Son of God".
In , after the Conversion of Paul the Apostle, and following his recovery, "straightway in the synagogues he proclaimed Jesus, that he is the Son of God."
Jesus' own assertions.
When in Matthew 16:15–16, Saint Peter states: "You are Christ, the Son of the living God", Jesus not only accepts the titles, but calls Peter "blessed" because his declaration had been revealed him by "my Father who is in Heaven". According to John Yieh, in this account the evangelist Matthew is unequivocally stating this as the church's view of Jesus.
In the Sanhedrin trial of Jesus in Mark 14:61 when the high priest asked Jesus: "Are you the Messiah, the Son of the Blessed One?" In the next verse, Jesus responded "I am". Jesus' claim here was emphatic enough to make the high priest tear his robe.
In the new Testament Jesus uses the term "my Father" as a direct and unequivocal assertion of his sonship, and a unique relationship with the Father beyond any attribution of titles by others:
In a number of other episodes Jesus claims sonship by referring to the Father, e.g. in Luke 2:49 when he is found in the temple a young Jesus calls the temple "my Father's house", just as he does later in John 2:16 in the Cleansing of the Temple episode. In Matthew 1:11 and Luke 3:22 Jesus allows himself to be called the Son of God by the voice from above, not objecting to the title.
References to "my Father" by Jesus in the New Testament are distinguished in that he never includes other individuals in them and only refers to "his" Father, however when addressing the disciples he uses "your" Father, excluding himself from the reference.
New Testament references.
Humans, including the New Testament writers, calling Jesus Son of God
Jesus calling himself Son of God
Jesus calling God his father
God the Father referring to Jesus as his son
Angels calling Jesus Son of God
The devil or demons calling Jesus Son of God
Jesus referred to as the Son:
The God and Father of Jesus
Theological development.
Through the centuries, the theological development of the concept of Son of God has interacted with other Christological elements such as Pre-existence of Christ, Son of man, the hypostatic union, etc. For instance, in Johannine "Christology from above" which begins with the Pre-existence of Christ, Jesus did not become Son of God through the Virgin Birth, he always was the Son of God.
By the 2nd century, differences had developed among various Christian groups and to defend the mainstream view in the early Church, St. Irenaeus introduced the confession: "One Christ only, Jesus the Son of God incarnate for our salvation". By referring to incarnation, this professes Jesus as the pre-existing Logos, i.e. The Word. It also professes him as both Christ and the only-begotten Son of God.
To establish a common ground, the Nicene Creed of 325 began with the profession of the Father Almighty and then states the belief:
Saint Augustine wrote at length on the Son of God and its relationship with the Son of man, positioning the two issues in terms of the dual nature of Jesus as both divine and human in terms of the hypostatic union. He wrote:
Christ Jesus, the Son of God, is God and Man: God before all worlds, man in our world...
But since he is the only Son of God, by nature and not by grace, he became also the Son of Man that he might be full of grace as well.
However, unlike Son of God, the proclamation of Jesus as the Son of man has never been an article of faith in Christianity. The interpretation of the use of "the Son of man" and its relationship to Son of God has remained challenging and after 150 years of debate no consensus on the issue has emerged among scholars.
Just as in Romans 10:9–13 Paul emphasized the salvific value of "professing by mouth" that Jesus is Lord (Kyrion Iesoun) Augustine emphasized the value of "professing that Jesus is the Son of God" as a path to salvation.
For Saint Thomas Aquinas (who also taught the Perfection of Christ) the "'Son of God' is God as known to God". Aquinas emphasized the crucial role of the Son of God in bringing forth all of creation and taught that although humans are created in the "image of God" they fall short and only the Son of God is truly like God, and hence divine.
Islam.
In Islam, Jesus () is considered to be the Messiah and a highly respected prophet sent to the Children of Israel, but not the son of God. As in Christianity, Jesus had no earthly father, but is instead seen as born through the breathing of the "Spirit of God" on Mary. The Qur'an compares the nature of his birth to the birth of Adam, who had neither mother nor father. The Qur'an also asserts that God has no begotten son as in the verse "He begets not, nor is He begotten." The birth of Jesus without a father, is stated in the following verse of the Quran:
She (Mary) said, "My Lord, how will I have a child when no man has touched me?" angel said, "Such is Allah ; He creates what He wills. When He decrees a matter, He only says to it, 'Be,' and it is.
The Quran challenges the acceptance of Jesus or other person as the son of God in the following verse:
O People of the Scripture, do not commit excess in your religion or say about Allah except the truth. The Messiah, Jesus, the son of Mary, was but a messenger of Allah and His word which He directed to Mary and a soul at a command from Him. So believe in Allah and His messengers. And do not say, "Three"; desist - it is better for you. Indeed, Allah is but one God. Exalted is He above having a son. To Him belongs whatever is in the heavens and whatever is on the earth. And sufficient is Allah as Disposer of affairs.
Bahá'í Faith.
In the writings of the Bahá'í Faith, the term "Son of God" is applied to Jesus, but does not indicate a literal physical relationship between Jesus and God, but is symbolic and is used to indicate the very strong spiritual relationship between Jesus and God and the source of his authority. Shoghi Effendi, the head of the Bahá'í Faith in the first half of the 20th century, also noted that the term does not indicate that the station of Jesus is superior to other prophets and messengers that Bahá'ís name Manifestations of God, including Buddha, Muhammad and Baha'u'llah among others. Shoghi Effendi notes that, since all Manifestations of God share the same intimate relationship with God and reflect the same light, the term Sonship can in a sense be attributable to all the Manifestations.

</doc>
<doc id="28171" url="https://en.wikipedia.org/wiki?curid=28171" title="SA">
SA

Sa, SA or S.A. may refer to:

</doc>
<doc id="28172" url="https://en.wikipedia.org/wiki?curid=28172" title="Saint Boniface">
Saint Boniface

Saint Boniface () ( 675? – 5 June 754 AD), born Winfrid, Wynfrith, or Wynfryth in the kingdom of Wessex in Anglo-Saxon England, was a leading figure in the Anglo-Saxon mission to the Germanic parts of the Frankish Empire during the 8th century. He established the first organized Christianity in many parts of Germania. He is the patron saint of Germania, the first archbishop of Mainz and the "Apostle of the Germans". He was killed in Frisia in 754, along with 52 others. His remains were returned to Fulda, where they rest in a sarcophagus which became a site of pilgrimage. Facts about Boniface's life and death as well as his work became widely known, since there is a wealth of material available—a number of "vitae", especially the near-contemporary "Vita Bonifatii auctore Willibaldi", and legal documents, possibly some sermons, and above all his correspondence.
Norman F. Cantor notes the three roles Boniface played that made him "one of the truly outstanding creators of the first Europe, as the apostle of Germania, the reformer of the Frankish church, and the chief fomentor of the alliance between the papacy and the Carolingian family." Through his efforts to reorganize and regulate the church of the Franks, he helped shape Western Christianity, and many of the dioceses he proposed remain today. After his martyrdom, he was quickly hailed as a saint in Fulda and other areas in Germania and in England. His cult is still notably strong today. Boniface is celebrated (and criticized) as a missionary; he is regarded as a unifier of Europe, and he is seen (mainly by Catholics) as a Germanic national figure.
Early life and first mission to Frisia.
The earliest Bonifacian "vita", Willibald's, does not mention his place of birth but says that at an early age he attended a monastery ruled by Abbot Wulfhard in "escancastre", or "Examchester", which seems to denote Exeter, and may have been one of many "monasteriola" built by local landowners and churchmen; nothing else is known of it outside the Bonifacian "vitae". Later tradition places his birth at Crediton, but the earliest mention of Crediton in connection to Boniface is from the early fourteenth century, in John Grandisson's "Legenda Sanctorum: The Proper Lessons for Saints' Days according to the use of Exeter". In one of his letters Boniface mentions he was "born and reared... the synod of London", but he may have been speaking metaphorically.
According to the "vitae", Winfrid was of a respected and prosperous family. Against his father's wishes he devoted himself at an early age to the monastic life. He received further theological training in the Benedictine monastery and minster of Nhutscelle (Nursling), not far from Winchester, which under the direction of abbot Winbert had grown into an industrious centre of learning in the tradition of Aldhelm. Winfrid taught in the abbey school and at the age of 30 became a priest; in this time, he wrote a Latin grammar, the "Ars Grammatica", besides a treatise on verse and some Aldhelm-inspired riddles. While little is known about Nursling outside of Boniface's "vitae", it seems clear that the library there was significant. In order to supply Boniface with the materials he needed, it would have contained works by Donatus, Priscian, Isidore, and many others. Around 716, when his abbot Wynberth of Nursling died, he was invited (or expected) to assume his position—it is possible that they were related, and the practice of hereditary right among the early Anglo-Saxons would affirm this. Winfrid, however, declined the position and in 716 set out on a missionary expedition to Frisia.
Early missionary work in Frisia and Germania.
Boniface first left for the continent in 716. He traveled to Utrecht, where Willibrord, the "Apostle of the Frisians," had been working since the 690s. He spent a year with Willibrord, preaching in the countryside, but their efforts were frustrated by the war then being carried on between Charles Martel and Radbod, King of the Frisians. Willibrord fled to the abbey he had founded in Echternach (in modern-day Luxembourg) while Boniface returned to Nursling.
Boniface returned to the continent the next year and went straight to Rome, where Pope Gregory II renamed him "Boniface", after the (legendary) fourth-century martyr Boniface of Tarsus, and appointed him missionary bishop for Germania—he became a bishop without a diocese for an area that lacked any church organization. He would never return to England, though he remained in correspondence with his countrymen and kinfolk throughout his life.
According to the "vitae" Boniface felled the Donar Oak, Latinized by Willibald as "Jupiter's oak," near the present-day town of Fritzlar in northern Hesse. According to his early biographer Willibald, Boniface started to chop the oak down, when suddenly a great wind, as if by miracle, blew the ancient oak over. When the god did not strike him down, the people were amazed and converted to Christianity. He built a chapel dedicated to Saint Peter from its wood at the site—the chapel was the beginning of the monastery in Fritzlar. This account from the "vita" is stylized to portray Boniface as a singular character who alone acts to root out paganism. Lutz von Padberg and others point out that what the "vitae" leave out is that the action was most likely well-prepared and widely publicized in advance for maximum effect, and that Boniface had little reason to fear for his personal safety since the Frankish fortified settlement of Büraburg was nearby. According to Willibald, Boniface later had a church with an attached monastery built in Fritzlar, on the site of the previously built chapel, according to tradition.
Boniface and the Carolingians.
The support of the Frankish mayors of the palace (maior domos), and later the early Pippinid and Carolingian rulers, was essential for Boniface's work. Boniface had been under the protection of Charles Martel from 723 on. The Christian Frankish leaders desired to defeat their rival power, the non-Christian Saxons, and to incorporate the Saxon lands into their own growing empire. Boniface's destruction of indigenous Germanic pagan sites may have benefited the Franks in their campaign against the Saxons.
In 732, Boniface traveled again to Rome to report, and Pope Gregory III conferred upon him the pallium as archbishop with jurisdiction over Germany. Boniface again set out for what is now Germany, baptized thousands, and dealt with the problems of many other Christians who had fallen out of contact with the regular hierarchy of the Roman Catholic Church. During his third visit to Rome in 737–38, he was made papal legate for Germany.
After Boniface's third trip to Rome, Charles Martel erected four dioceses in Bavaria (Salzburg, Regensburg, Freising, and Passau) and gave them to Boniface as archbishop and metropolitan over all Germany east of the Rhine. In 745, he was granted Mainz as metropolitan see. In 742, one of his disciples, Sturm (also known as Sturmi, or Sturmius), founded the abbey of Fulda not far from Boniface's earlier missionary outpost at Fritzlar. Although Sturm was the founding abbot of Fulda, Boniface was very involved in the foundation. The initial grant for the abbey was signed by Carloman, the son of Charles Martel, and a supporter of Boniface's reform efforts in the Frankish church. The saint himself explained to his old friend, Daniel of Winchester, that without the protection of Charles Martel he could "neither administer his church, defend his clergy, nor prevent idolatry."
According to German historian Gunther Wolf, the high point of Boniface's career was the Concilium Germanicum, organized by Carloman in an unknown location in April 743. While Boniface was not able to safeguard the church from property seizures by the local nobility, he did achieve one goal, the adoption of stricter guidelines for the Frankish clergy, which often hailed directly from the nobility. After Carloman's resignation in 747 he maintained a sometimes turbulent relationship with the king of the Franks, Pepin; the claim that he would have crowned Pepin at Soissons in 751 is now generally discredited.
Boniface balanced this support and attempted to maintain some independence, however, by attaining the support of the papacy and of the Agilolfing rulers of Bavaria. In Frankish, Hessian, and Thuringian territory, he established the dioceses of Würzburg, and Erfurt. By appointing his own followers as bishops, he was able to retain some independence from the Carolingians, who most likely were content to give him leeway as long as Christianity was imposed on the Saxons and other Germanic tribes.
Last mission to Frisia.
According to the "vitae", Boniface had never relinquished his hope of converting the Frisians, and in 754 he set out with a retinue for Frisia. He baptized a great number and summoned a general meeting for confirmation at a place not far from Dokkum, between Franeker and Groningen. Instead of his converts, however, a group of armed robbers appeared who slew the aged archbishop. The "vitae" mention that Boniface persuaded his (armed) comrades to lay down their arms: "Cease fighting. Lay down your arms, for we are told in Scripture not to render evil for good but to overcome evil by good."
Having killed Boniface and his company, the Frisian bandits ransacked their possessions but found that the company's luggage did not contain the riches they had hoped for: "they broke open the chests containing the books and found, to their dismay, that they held manuscripts instead of gold vessels, pages of sacred texts instead of silver plates." They attempted to destroy these books, the earliest "vita" already says, and this account underlies the status of the Ragyndrudis Codex, now held as a Bonifacian relic in Fulda, and supposedly one of three books found on the field by the Christians who inspected it afterward. Of those three books, the Ragyndrudis Codex shows incisions that could have been made by sword or axe; its story appears confirmed in the Utrecht hagiography, the "Vita altera", which reports that an eye-witness saw that the saint at the moment of death held up a gospel as spiritual protection. The story was later repeated by Otloh's "vita"; at that time, the Ragyndrudis Codex seems to have been firmly connected to the martyrdom.
Boniface's remains were moved from the Frisian countryside to Utrecht, and then to Mainz, where sources contradict each other regarding the behavior of Lullus, Boniface's successor as archbishop of Mainz. According to Willibald's "vita" Lullus allowed the body to be moved to Fulda, while the (later) "Vita Sturmi", a hagiography of Sturm by Eigil of Fulda, Lullus attempted to block the move and keep the body in Mainz.
His remains were eventually buried in the abbey church of Fulda after resting for some time in Utrecht, and they are entombed within a shrine beneath the high altar of Fulda Cathedral, previously the abbey church.
Veneration.
Fulda.
Veneration of Boniface in Fulda began immediately after his death; his grave was equipped with a decorative tomb around ten years after his burial, and the grave and relics became the center of the abbey and of the cult of the saint. Fulda monks prayed for newly elected abbots at the grave site before greeting them, and every Monday the saint was remembered in prayer, the monks prostrating themselves and reciting Psalm 50. After the abbey church was rebuilt to become the Ratgar Basilica (dedicated 791), Boniface's remains were translated to a new grave: since the church had been enlarged, his grave, originally in the west, was now in the middle; his relics were moved to a new apse in 819. From then on Boniface, as patron of the abbey, was regarded as both spiritual intercessor for the monks and legal owner of the abbey and its possessions, and all donations to the abbey were done in his name. He was honored on the date of his martyrdom, 5 June (with a mass written by Alcuin), and (around the year 1000) with a mass dedicated to his appointment as bishop, on 1 December.
Dokkum.
Willibald's "vita" describes how a visitor on horseback come to the site of the martyrdom, and a hoof of his horse got stuck in the mire. When it was pulled loose, a well sprang up. By the time of the "Vita altera Bonifatii" (9th century), there was a church on the site, and the well had become a "fountain of sweet water" used to sanctify people. The "Vita Liudgeri", a hagiographical account of the work of Ludger, describes how Ludger himself had built the church, sharing duties with two other priests. According to James Palmer, the well was of great importance since the saint's body was hundreds of miles away; the physicality of the well allowed for an ongoing connection with the saint. In addition, Boniface signified Dokkum's and Frisia's "connect to the rest of (Frankish) Christendom".
Memorials.
Saint Boniface's feast day is celebrated on 5 June in the Roman Catholic Church, the Lutheran Church, the Anglican Communion and the Eastern Orthodox Church.
A famous statue of Saint Boniface stands on the grounds of Mainz Cathedral, seat of the archbishop of Mainz. A more modern rendition stands facing St. Peter's Church of Fritzlar.
The UK National Shrine is located at the Catholic church at Crediton, Devon, which has a bas-relief of the felling of Thor's Oak, by sculptor Kenneth Carter. The sculpture was unveiled by Princess Margaret in his native Crediton, located in Newcombes Meadow Park. There is also a series of paintings there by Timothy Moore. There are quite a few churches dedicated to St. Boniface in the United Kingdom: Bunbury, Cheshire; Chandler's Ford and Southampton Hampshire; Adler Street, London; Papa Westray, Orkney; St Budeaux, Plymouth (now demolished); Bonchurch, Isle of Wight; Cullompton, Devon.
Bishop George Errington founded St Boniface's Catholic College, Plymouth in 1856. The school celebrates Saint Boniface on 5 June each year.
In 1818, Father Norbert Provencher founded a mission on the east bank of the Red River in what was then Rupert's Land, building a log church and naming it after St. Boniface. The log church was consecrated as Saint Boniface Cathedral after Provencher was himself consecrated as a bishop and the diocese was formed. The community that grew around the cathedral eventually became the city of Saint Boniface, which merged into the city of Winnipeg in 1971. In 1844, four Grey Nuns arrived by canoe in Manitoba, and in 1871, built Western Canada's first hospital: St. Boniface Hospital, where the Assiniboine and Red Rivers meet. Today, St. Boniface Hospital is the second-largest hospital in Manitoba.
Legends.
Some traditions credit Saint Boniface with the invention of the Christmas tree. The "vitae" mention nothing of the sort. However, it is mentioned on a BBC-Devon website, in an account which places Geismar in Bavaria, and in a number of educational books, including "St. Boniface and the Little Fir Tree", "The Brightest Star of All: Christmas Stories for the Family", "The American normal readers". and a short story by Henry van Dyke, "The First Christmas Tree".
Sources and writings.
"Vitae".
The earliest "Life" of Boniface was written by a certain Willibald, an Anglo-Saxon priest who came to Mainz after Boniface's death, around 765. Willibald's biography was widely dispersed; Levison lists some forty manuscripts. According to his lemma, a group of four manuscripts including Codex Monacensis 1086 are copies directly from the original.
Listed second in Levison's edition is the entry from a late ninth-century Fulda document: Boniface's status as a martyr is attested by his inclusion in the "Fulda Martyrology" which also lists, for instance, the date (1 November) of his translation in 819, when the Fulda Cathedral had been rebuilt.
The next "vita", chronologically, is the "Vita altera Bonifatii auctore Radbodo", which originates in the Bishopric of Utrecht, and was probably revised by Radboud of Utrecht (899–917). Mainly agreeing with Willibald, it adds an eye-witness who presumably saw the martyrdom at Dokkum. The "Vita tertia Bonifatii" likewise originates in Utrecht. It is dated between 917 (Radboud's death) and 1075, the year Adam of Bremen wrote his "Gesta Hammaburgensis ecclesiae pontificum", which used the "Vita tertia".
A later "vita", written by Otloh of St. Emmeram (1062–1066), is based on Willibald's and a number of other "vitae" as well as the correspondence, and also includes information from local traditions.
Correspondence.
Boniface engaged in regular correspondence with fellow churchmen all over Western Europe, including the three popes he worked with, and with some of his kinsmen back in England. Many of these letters contain questions about church reform and liturgical or doctrinal matters. In most cases, what remains is one half of the conversation, either the question or the answer. The correspondence as a whole gives evidence of Boniface's widespread connections; some of the letters also prove an intimate relationship especially with female correspondents.
There are 150 letters in what is generally called the Bonifatian correspondence, though not all them are by Boniface or addressed to him. They were assembled by order of archbishop Lullus, Boniface's successor in Mainz, and were initially organized into two parts, a section containing the papal correspondence and another with his private letters. They were reorganized in the eighth century, in a roughly chronological ordering. Otloh of St. Emmeram, who worked on a new "vita" of Boniface in the eleventh century, is credited with compiling the complete correspondence as we have it.
The correspondence was edited and published already in the seventeenth century, by Nicolaus Serarius. Stephan Alexander Würdtwein's 1789 edition, "Epistolae S. Bonifacii Archiepiscopi Magontini", was the basis for a number of (partial) translations in the nineteenth century. The first version to be published by Monumenta Germaniae Historica (MGH) was the edition by Ernst Dümmler (1892); the most authoritative version until today is Michael Tangl's 1912 "Die Briefe des Heiligen Bonifatius, Nach der Ausgabe in den Monumenta Germaniae Historica", published by MGH in 1916. This edition is the basis of Ephraim Emerton's selection and translation in English, "The Letters of Saint Boniface", first published in New York in 1940; it was republished most recently with a new introduction by Thomas F.X. Noble in 2000.
Sermons.
Some fifteen preserved sermons are traditionally associated with Boniface, but that they were actually his is not generally accepted.
Grammar and poetry.
Early in his career, before he left for the continent, Boniface wrote an "Ars Grammatica", a grammatical treatise presumably for his students in Nursling. Helmut Gneuss reports that one manuscript copy of the treatise originates from (the south of) England, mid-eighth century; it is now held in Marburg, in the Hessisches Staatsarchiv. He also wrote a treatise on verse, the "Caesurae uersuum", and a collection of riddles, the "Enigmata", influenced greatly by Aldhelm and containing many references to works of Vergil (the "Aeneid", the "Georgics", and the "Eclogues"). Three octosyllabic poems written in clearly Aldhelmian fashion (according to Andy Orchard) are preserved in his correspondence, all composed before he left for the continent.
Additional materials.
A letter by Boniface charging Aldebert and Clement with heresy is preserved in the records of the Roman Council of 745 that condemned the two. Boniface had an interest in the Irish canon law collection known as "Collectio canonum Hibernensis", and a late 8th/early 9th-century manuscript in Würzburg contains, besides a selection from the "Hibernensis", a list of rubrics that mention the heresies of Clemens and Aldebert. The relevant folios containing these rubrics were most likely copied in Mainz, Würzburg, or Fulda, all places associated with Boniface. Michael Glatthaar suggested that the rubrics should be seen as Boniface's contribution to the agenda for a synod.
Anniversary and other celebrations.
Boniface's death (and birth) has given rise to a number of noteworthy celebrations. The dates for some of these celebrations have undergone some changes: in 1805, 1855, and 1905 (and in England in 1955) anniversaries were calculated with Boniface's death dated in 755, the "Mainz tradition"; Michael Tangl's dating of the martyrdom in 754 was not accepted until after 1955. Celebrations in Germany centered on Fulda and Mainz, in the Netherlands on Dokkum and Utrecht, and in England on Crediton and Exeter.
Celebrations in Germany: 1805, 1855, 1905.
The first German celebration on a fairly large scale was held in 1805 (the 1150th anniversary of his death), followed by a similar celebration in a number of towns in 1855; both of these were predominantly Catholic affairs, which emphasized the role of Boniface in German history as opposed to Protestant views on the role of Martin Luther, and especially the 1855 celebrations were an expression of German Catholic nationalism. In 1905, when strife between Catholic and Protestant factions had eased (one Protestant church published a celebratory pamphlet, Gerhard Ficker's "Bonifatius, der "Apostel der Deutschen""), there were modest celebrations and a publication for the occasion on historical aspects of Boniface and his work, the 1905 "Festgabe" by Gregor Richter and Carl Scherer. In all, the content of these early celebrations showed evidence of the continuing question about the meaning of Boniface for Germany, though the importance of Boniface in cities associated with him was without question.
1954 celebrations.
In 1954, celebrations were widespread, in England, Germany, and the Netherlands, and a number of these celebrations were international affairs. Especially in Germany, these celebrations had a distinctly political note to them and often stressed Boniface as a kind of founder of Europe, such as when Konrad Adenauer, the (Catholic) German chancellor, addressed a crowd of 60,000 in Fulda, celebrating the feast day of the saint in a European context: "Das, was wir in Europa gemeinsam haben, gemeinsamen Ursprungs" ("What we have in common in Europe comes from the same source").
Papal visit, 1980.
When Pope John Paul II visited Germany in November 1980, he spent two days in Fulda (17 and 18 November). He celebrated mass in Fulda Cathedral with 30,000 gathered on the square in front of the building, and met with the German Bishops' Conference (held in Fulda since 1867). The pope next celebrated mass outside the cathedral, in front of an estimated crowd of 100,000, and hailed the importance of Boniface for German Christianity: "Der heilige Bonifatius, Bischof und Märtyrer, "bedeutet" den 'Anfang' des Evangeliums und der Kirche in Eurem Land" ("The holy Boniface, bishop and martyr, "signifies" the beginning of the gospel and the church in your country"). A photograph of the pope praying at Boniface's grave became the centerpiece of a prayer card distributed from the cathedral.
2004 celebrations.
In 2004, anniversary celebrations were held throughout Northwestern Germany and Utrecht, and Fulda and Mainz—generating a great amount of academic and popular interest. The event occasioned a number of scholarly studies, esp. biographies (for instance, by Auke Jelsma in Dutch, Lutz von Padberg in German, and Klaas Bruinsma in Frisian), and a fictional completion of the Boniface correspondence (Lutterbach, "Mit Axt und Evangelium"). A German musical proved a great commercial success, and in the Netherlands an opera was staged.
Scholarship on Boniface.
The literature on the saint and his work is extensive. At the time of the various anniversaries, edited collections were published containing essays by some of the best-known scholars of the time, such as the 1954 collection "Sankt Bonifatius: Gedenkgabe zum Zwölfhundertsten Todestag" and the 2004 collection "Bonifatius—Vom Angelsächsischen Missionar zum Apostel der Deutschen". In the modern era, Lutz von Padberg published a number of biographies and articles on the saint focusing on his missionary praxis and his relics. The most authoritative biography is still Theodor Schieffer's "Winfrid-Bonifatius und die Christliche Grundlegung Europas" (1954).

</doc>
<doc id="28174" url="https://en.wikipedia.org/wiki?curid=28174" title="Data storage device">
Data storage device

A data storage device is a device for recording (storing) information (data). Recording can be done using virtually any form of energy, spanning from manual muscle power in handwriting, to acoustic vibrations in phonographic recording, to electromagnetic energy modulating magnetic tape and optical discs.
A storage device may hold information, process information, or both. A device that only holds information is a recording medium. Devices that process information (data storage equipment) may either access a separate portable (removable) recording medium or a permanent component to store and retrieve data.
Electronic data storage requires electrical power to store and retrieve that data. Most storage devices that do not require vision and a brain to read data fall into this category. Electromagnetic data may be stored in either an analog data or digital data format on a variety of media. This type of data is considered to be electronically encoded data, whether it is electronically stored in a semiconductor device, for it is certain that a semiconductor device was used to record it on its medium. Most electronically processed data storage media (including some forms of computer data storage) are considered permanent (non-volatile) storage, that is, the data will remain stored when power is removed from the device. In contrast, most electronically stored information within most types of semiconductor (computer chips) microcircuits are volatile memory, for it vanishes if power is removed.
Except for barcodes and OCR data, electronic data storage is easier to revise and may be more cost effective than alternative methods due to smaller physical space requirements and the ease of replacing (rewriting) data on the same medium. However, the durability of methods such as printed data is still superior to that of most electronic storage media. The durability limitations may be overcome with the ease of duplicating (backing-up) electronic data.
Terminology.
Devices that are not used exclusively for recording such as hands, mouths, musical instruments, and devices that are intermediate in the storing/retrieving process, like eyes, ears, cameras, scanners, microphones, speakers, monitors, or video projectors, are generally not considered storage devices. Devices that are exclusively for recording such as printers, exclusively for reading, like barcode readers, or devices that process only one form of information, like phonographs may or may not be considered storage devices. In computing these are known as input/output devices.
All information is data. However, not all data is information.
Many data storage devices are also media players. Any device that can store and playback multimedia may also be considered a media player such as in the case with the HD media player. Designated hard drives are used to play saved or streaming media on home cinemas or home theater PCs.
Global capacity, digitization, and trends.
In a recent study in "Science" it was estimated that the world's technological capacity to store information in analog and digital devices grew from less than 3 (optimally compressed) exabytes in 1986, to 295 (optimally compressed) exabytes in 2007, and doubles roughly every 3 years.
It is estimated that the year 2002 marked the beginning of the digital age for information storage, the year that marked the date when human kind started to store more information on digital than on analog storage devices. In 1986 only 1% of the world's capacity to store information was in digital format, which grew to 3% by 1993, 25% in the year 2000, and exploded to 97% of the world's storage capacity by 2007.
Data storage equipment.
Any input/output equipment may be considered data storage equipment if it writes to and reads from a data storage medium.
Data storage equipment uses either:
The following are examples of those methods:
Recording medium.
A recording medium is a physical material that holds data expressed in any of the existing recording formats. With electronic media, the data and the recording medium is sometimes\s part of the surface of the medium.
Some recording media may be temporary either by design or by nature. Volatile organic compounds may be used to preserve the environment or to purposely make data expire over time. Data such as smoke signals or skywriting are temporary by nature.
Modern examples by shape.
A typical way to classify data storage media is to consider its shape and type of movement (or non-movement) relative to the read/write device(s) of the storage apparatus as listed:
Bekenstein (2003) foresees that miniaturization might lead to the invention of devices that store bits on a single atom.
Weight and volume.
Especially for carrying around data, the weight and volume per MB are relevant. They are quite large for written and printed paper compared with modern electronic media. On the other hand, written and printer paper do not require (the weight and volume of) reading equipment, and handwritten edits only require simple writing equipment, such as a pen.
With mobile data connections the data need not be carried around to be available.

</doc>
