<doc id="27474" url="https://en.wikipedia.org/wiki?curid=27474" title="Demographics of Syria">
Demographics of Syria

In 2011, the Syrian population was estimated at roughly 23 million permanent inhabitants, including people with refugee status from Palestine and Iraq and are an overall indigenous Levantine people. While most modern-day Syrians are commonly described as Arabs by virtue of their modern-day language and bonds to Arab culture and history, they are, in fact, largely a blend of the various Semitic-speaking groups indigenous to the region.
Population.
Religion.
There has been no Syrian census including a question about religion since 1960, these are thus the last official statistics available. In the next census of 1970, the religion statistics were no longer mentioned.: 92.1% Muslims(4,053,349) including 75% Sunnis, 11% Alawis, 3% Druzes; 7.8% Christians (344,621) and 0.1% Jews (4,860). 
Languages.
Arabic is the official, and most widely spoken, language. Arabic speakers make up 85% of the population (this includes some 500,000 Palestinians). Many educated Syrians also speak English and French. The Kurds, a majority of whom speak Kurdish, make up 9% of the population and live mostly in the northeast corner of Syria, as well in pockets all along the northern borders of Syria with Turkey, and demographically dominate the district of Afrin, west of Aleppo, though sizable Kurdish communities live in most major Syrian cities as well. Armenian and Turkmen are spoken among the small Armenian and Turkmen populations respectively. Aramaic is still spoken in two forms, the Syriac used by Assyrians and Western Neo-Aramaic used by a few inhabitants in the villages of Bakh'a, Jubb'adin and Ma'loula. 1,500 people of Greek descent lived in Syria. The majority of them were Syrian citizens.
Disposition.
60% of the population live in the Aleppo Governorate, the Euphrates valley or along the coastal plain; a fertile strip between the coastal mountains and the desert. Overall population density is about . Education is free and compulsory from ages 6 to 11. Schooling consists of 6 years of primary education followed by a 3-year general or vocational training period and a 3-year academic or vocational program. The second 3-year period of academic training is required for university admission. Total enrollment at post-secondary schools is over 150,000. The literacy rate of Syrians aged 15 and older is 86.0% for males and 73.6% for females.
Since 1960, censuses have been conducted in 1960, 1970, 1981, 1994 and 2004.
Civil war's effect on population.
More than four million refugees have left the country during the course of the war. Most of them fled to neighboring Turkey, Lebanon, Jordan, and Iraq,
The war also affected the birth rate. The annual birth rate in Syria has fallen by more than half since the country plunged into turmoil in March 2011, from about 500,000 births per year before 2011, to about 200,000.
Life expectancy.
Prior to the civil war, the life expectancy of a child born in Syria was 75.9 years, but that number has since fallen to an estimated 55.7 years.
CIA World Factbook demographic statistics.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Population.
17,951,639 in 2014, a massive decline due to nearly 4 million Syrian refugees leaving the country because of the Syrian Civil War and furthermore because of the death in the war. This is a drop of 9.7% from the previous year.
Age structure.
"0–14 years:"
35.2% (male 4,066,109/female 3,865,817)
<br>"15–64 years:"
61% (male 6,985,067/female 6,753,619)
<br>"65 years and older:"
3.8% (male 390,802/female 456,336) (2011 est.)
Median age.
"total"
<br>21.9 years
"male"
<br>21.7 years
"female"
<br>22.1 years (2011 est.)
Population decline rate.
0.797% (2012 est.)
Birth rate.
2.35 births/1,000 population (2012 est.)
Death rate.
3.67 deaths/1,000 population (July 2012 est.)
Net migration rate.
-27.82 migrant(s)/1,000 population (2012 est.)
Sex ratio.
"at birth:"
1.06 male(s)/female
<br>"under 15 years:"
1.06 male(s)/female
<br>"15–64 years:"
1.05 male(s)/female
<br>"65 years and older:"
0.89 male(s)/female
<br>"total population:"
1.05 male(s)/female (2009 est.)
Life expectancy at birth.
"total population:"
71.19 years
<br>"male:"
69.8 years
<br>"female:"
72.68 years (2009 est.)
Nationality.
"noun:"
Syrian(s)
<br>"adjective:"
Syrian
Ethnic groups.
Syrian Arabs 90%, other ethnic groups such as Kurds 9%, Syriac-Arameans/Assyrians, Armenians, Circassians, and Syrian Turkmen, Greeks 1%
Religions.
There has been no Syrian census including a question about religion since 1960, these are thus the last official statistics available:
In the next census of 1970, the religion statistics were no longer mentioned.
Languages.
Arabic (official), Kurdish, Turkmen, Armenian, Circassian (Adyghe), and Aramaic
Literacy.
"definition:" age 15 and older can read and write
Major urban areas - population.
As of 2011:

</doc>
<doc id="27475" url="https://en.wikipedia.org/wiki?curid=27475" title="Politics of Syria">
Politics of Syria

Politics in the Syrian Arab Republic takes place in the framework of what is officially a semi-presidential republic, but others disagree with that assessment. The CIA assesses that the power is in the hands of the President of Syria and his family, all members of the ruling Arab Socialist Ba'ath Party which is a cell of the Syrian-dominated Ba'ath Party (established in 1966 when the original Ba'ath Party was dissolved and split into two).
Officially, decrees issued by the president must be approved by the People's Council to become law, except during a state of emergency which was in force until 21 April 2011 when it was lifted during the Syrian uprising, (the end of it being one of the key demands of the protesters). The Ba'ath Party is Syria's ruling party and the previous Syrian constitution of 1973 stated that "the Arab Socialist Ba'ath Party leads society and the state." At least 167 seats of the 250-member parliament were guaranteed for the National Progressive Front, which is a coalition of the Ba'ath Party and several other much smaller allied parties. The new Syrian constitution of 2012 introduced multi-party system based on the principle of political pluralism without guaranteed leadership of any political party. The Syrian army and security services maintained a considerable presence in the neighbouring Lebanese Republic from 1975 until 24 April 2005.
Background.
Hafez al-Assad took power in 1970, and after his death in 2000 his son Bashar al-Assad succeeded him as President. A surge of interest in political reform took place after Bashar al-Assad assumed power in 2000. Human-rights activists and other civil-society advocates, as well as some parliamentarians, became more outspoken during a period referred to as the "Damascus Spring" (July 2000-February 2001). Assad also made a series of appointments of reform-minded advisors to formal and less formal positions, and included a number of similarly oriented individuals in his Cabinet.
Neo-Ba'athism.
The Ba'ath platform is proclaimed succinctly in the party's slogan: "Unity, freedom, and socialism." The party is both socialist, advocating state ownership of the means of industrial production and the redistribution of agricultural land (in practice, Syria's nominally socialist economy is effectively a mixed economy, composed of large state enterprises and private small businesses), and revolutionary, dedicated to carrying a pan-Arab revolution to every part of the Arab world. Founded by Michel Aflaq, a Syrian Christian, Salah al-Din al-Bitar, a Syrian Sunni, and Zaki al-Arsuzi, an alawite, the Arab Socialist Ba'ath Party, which was dissolved in 1966 following the 1966 Syrian coup d'état which led to the establishment of one Iraqi-dominated ba'ath movement and one Syrian-led ba'ath movement. The party embraces secularism and has attracted supporters of all faiths in many Arab countries, especially Iraq, Jordan, and Lebanon.
Since August 1990, however, the party has tended to de-emphasize socialism and to stress pan-Arab unity.
Six smaller political parties are permitted to exist and, along with the Ba'ath Party, make up the National Progressive Front (NPF), a grouping of parties that represents the sole framework of legal political party participation for citizens. While created ostensibly to give the appearance of a multi-party system, the NPF is dominated by the Ba'ath Party and does not change the essentially one-party character of the political system. Non-Ba'ath Party members of the NPF exist as political parties largely in name only and conform strictly to Ba'ath Party and government policies. There were reports in 2000 that the government was considering legislation to expand the NPF to include new parties and several parties previously banned; these changes have not taken place. However, one such party- the Syrian Social Nationalist Party- was legalised in 2005.
Traditionally, the parties of the NPF accepted the socialist and Arab nationalist ideology of the government. However, the SSNP was the first party that is neither socialist nor Arab nationalist in orientation to be legalised and admitted to the NPF. This has given rise to suggestions that broader ideological perspectives may be afforded some degree of toleration in the future, but ethnically-based (Kurdish and Assyrian) parties continue to be repressed and a strict ban on religious parties is still enforced.
Syria's Emergency Law was in force from 1963, when the Ba'ath Party came to power, until 21 April 2011 when it was rescinded by Bashar al-Assad (decree 161). The law, justified on the grounds of the continuing war with Israel and the threats posed by terrorists, suspended most constitutional protections.
Government administration.
Leadership in Damascus:
Leadership of the Syrian opposition in Idlib:
The previous Syrian constitution of 1973 vested the Ba'ath Party (formally the Arab Ba'ath Socialist Party) with leadership functions in the state and society and provided broad powers to the president. The president, approved by referendum for a 7-year term, was also Secretary General of the Ba'ath Party and leader of the National Progressive Front. During the 2011–2012 Syrian uprising, a new constitution was put to a referendum. Amongst other changes, it abolished the old article 8 which entrenched the power of the Ba'ath party. The new article 8 reads: "The political system of the state shall be based on the principle of political pluralism, and exercising power democratically through the ballot box". In a new article 88, it introduced presidential elections and limited the term of office for the president to seven years with a maximum of one re-election. The referendum resulted in the adoption of the new constitution, which came into force on 27 February 2012.
The president has the right to appoint ministers (Council of Ministers), to declare war and states of emergency, to issue laws (which, except in the case of emergency, require ratification by the People's Council), to declare amnesty, to amend the constitution, and to appoint civil servants and military personnel. The late President Hafiz al-Asad was confirmed by unopposed plebiscites five times. His son and current President Bashar al-Asad, was confirmed by an unopposed referendum in July 2000. He was confirmed again on 27 May 2007 (next to be held in May 2014) with 97.6% of the vote
Along with the National Progressive Front, the president decides issues of war and peace and approves the state's 5-year economic plans. The National Progressive Front also acts as a forum in which economic policies are debated and the country's political orientation is determined.
The Syrian constitution of 2012 requires that the president be Muslim but does not make Islam the state religion. The judicial system in Syria is an amalgam of Ottoman, French, and Islamic laws, with three levels of courts: courts of first instance, courts of appeals, and the constitutional court, the highest tribunal. In addition, religious courts handle questions of personal and family law.
The Ba'ath Party emphasizes socialism and secular Pan-Arabism. Despite the Ba'ath Party's doctrine on building national rather than ethnic identity, the issues of ethnic, religious, and regional allegiances still remain important in Syria.
Legislative branch.
The People's Council ("Majlis al-Sha'ab") has 250 members elected for a four-year term in 15 multi-seat constituencies. According to the previous Syrian constitution of 1973 Syria was a one-party state and only one political party, the Arab Socialist Ba'ath Party was legally allowed to hold effective power. Of the 250 seats in the council, 167 were guaranteed for the National Progressive Front (founded in 1972) and 134 of these (as of 2007) were members of the Ba'ath Party. The minor parties in the Progressive Front, were legally required to accept the leadership of the Ba'ath Party. The other parties in the Progressive Front, for example, are not allowed to canvass for supporters in the army or the student body which are "reserved exclusively for the Ba'ath." The new Syrian constitution of 2012 introduced multi-party system without guaranted leadership of any political party.
Political parties and elections.
The last parliamentary election was on 7 May 2012 and the results were announced on 15 May.
The Baath party won an even larger victory than it did in previous elections. They won a majority of around 60% of the 250 parliamentary seats. Previously, the Baath had a majority of just over 50% of the seats in parliament. If one adds in the independent MPs aligned with the Baath Party, the MPs who support the president make up over 90% of the seats in new parliament. The National Unity List, which is dominated by the Syrian Baath Party, won more than 150 seats in the 250 member parliament. Independent individuals won more than 90 seats. Among the newly established opposition parties (established since August 2011), only one single seat was won, namely a seat in Aleppo won by the Syrian Democratic Party, Ahmad Koussa. In addition three representatives of longstanding opposition parties have been elected to Parliament: Qadri Jamil and Ali Haydar from the Front for Change and Liberation, and Amro Osi from the Initiative of Syrian Kurds.
Summary of the 7 May 2012 People's Council of Syria election results
!style="background-color:#E9E9E9" align=left valign=top|Parties
!style="background-color:#E9E9E9" align=right|Votes
!style="background-color:#E9E9E9" align=right|%
!style="background-color:#E9E9E9" align=right|Seats
!style="background-color:#E9E9E9" align=right|Seats inside
International organization participation.
Syria is a member of the Arab Bank for Economic Development in Africa, Arab Fund for Economic and Social Development, Arab Monetary Fund, Council of Arab Economic Unity, Customs Cooperation Council, Economic and Social Commission for Western Asia, Food and Agricultural Organization, Group of 24, Group of 77, International Atomic Energy Agency, International Bank for Reconstruction and Development, International Civil Aviation Organization, International Chamber of Commerce, International Development Association, Islamic Development Bank, International Fund for Agricultural Development, International Finance Corporation, International Labour Organization, International Monetary Fund, International Maritime Organization, INTELSAT, INTERPOL, International Olympic Committee, International Organization for Standardization, International Telecommunication Union, International Federation of Red Cross and Red Crescent Societies, Non-Aligned Movement, Organization of Arab Petroleum Exporting Countries, Organisation of Islamic Cooperation, United Nations, UN Commission on Human Rights, UN Conference on Trade and Development, UN Industrial Development Organization, UN Relief and Works Agency for Palestine Refugees in the Near East, Universal Postal Union, World Federation of Trade Unions, World Health Organization, World Meteorological Organization, and World Tourism Organization.
Syria's diplomats last sat on the UN Security Council, (as a non-permanent member) in December 2003.

</doc>
<doc id="27476" url="https://en.wikipedia.org/wiki?curid=27476" title="Economy of Syria">
Economy of Syria

The economy of Syria is based on agriculture, oil, industry and services. Its GDP per capita expanded 80% in the 1960s reaching a peak of 336% of total growth during the 1970s. This proved unsustainable for Syria and the economy shrank by 33% during the 1980s. However the GDP per capita registered a very modest total growth of 12% (1.1% per year on average) during the 1990s due to successful diversification. More recently, the International Monetary Fund (IMF) projected real GDP growth at 3.9% in 2009 from close to 6% in 2008. The two main pillars of the Syrian economy used to be agriculture and oil, which together accounted for about one-half of GDP. Agriculture, for instance, accounted for about 25% of GDP and employed 25% of the total labor force. However, poor climatic conditions and severe drought badly affected the agricultural sector, thus reducing its share in the economy to about 17% of 2008 GDP, down from 20.4% in 2007, according to preliminary data from the Central Bureau of Statistics. On the other hand, higher crude oil prices countered declining oil production and led to higher budgetary and export receipts.
Since the outbreak of the Syrian civil war, the Syrian economy has been hit by massive economic sanctions restricting trade with the Arab League, Australia, Canada, the European Union, (as well as the European countries of Albania, Iceland, Liechtenstein, Macedonia, Moldova, Montenegro, Norway, Serbia, and Switzerland) Georgia, Japan, Turkey, and the United States. These sanctions and the instability associated with the civil war have reversed previous growth in the Syrian economy to a state of decline for the years 2011 and 2012. According to the UN, total economic damages of the Syrian civil war are estimated at $143 billion as of late 2013.
By July 2013, the Syrian economy had shrunk 45 percent since the start of the Civil War. Unemployment increased fivefold, the value of the Syrian currency decreased to one-sixth its pre-war value, and the public sector lost USD $15 billion. By the end of 2013, the UN estimated total economic damage of the Syrian civil war at $143 billion. The total economic loss from the Syrian Civil War will reach $237 billion by the end of 2015, according to the United Nations Economic and Social Commission for Western Asia, with the Syrian opposition's capture of Nasib border crossing costing the government a further $500–$700 million a year on top of this.
As a result of the war, the six economies of the greater Levant (Turkey, Syria, Lebanon, Jordan, Iraq, and Egypt) taken together have lost close to US$35 billion in output, measured in 2007 prices.
Basic information.
During the 1960s, along socialist lines, the government nationalized most major enterprises and adopted economic policies designed to address regional and class disparities. This legacy of state intervention and price, trade, and foreign exchange controls may have hampered economic growth. Syria also has low investment levels, and relatively low industrial and agricultural productivity. Economic reform has been incremental and gradual. In 2001, Syria legalized private banking. In 2004, four private banks began operations. In August 2004, a committee was formed to supervise the establishment of a stock market. Beyond the financial sector, the Syrian Government has enacted major changes to rental and tax laws, and is reportedly considering similar changes to the commercial code and to other laws, which impact property rights.
Syria has produced heavy-grade oil from fields inside in the northeast since the late 1960s. In the early 1980s, light-grade, low-sulphur oil was discovered near Deir ez-Zor in eastern Syria. This discovery relieved Syria of the need to import light oil to mix with domestic heavy crude in refineries. Recently, Syrian oil production has been about 379,000 barrels per day (bpd). Syria's oil reserves are being gradually depleted and reached 2.5 billion barrels in January 2009. Experts generally agree that Syria will become a net importer of petroleum by the end of the next decade. Recent developments have helped revitalize the energy sector, including new discoveries and the successful development of its hydrocarbon reserves. According to the 2009 Syria Report of the Oxford Business Group, the oil sector accounted for 23% of government revenues, 20% of exports, and 22% of GDP in 2008. Syria exported roughly 150,000 bpd in 2008, and oil accounted for a majority of the country's export income.
Ad hoc economic liberalization continues to add wealth inequality, impoverishing the average population while enriching a few people in Syria's private sector. In 1990, the government established an official parallel exchange rate to provide incentives for remittances and exports through official channels. This action improved the supply of basic commodities and contained inflation by removing risk premiums on smuggled commodities.
Foreign aid to Syria in 1997 totaled an estimated US$199 million. The World Bank reported that in July 2004 that it had committed a total of US$661 million for 20 operations in Syria. One investment project remained active at that time.
External trade and investment.
Despite the mitigation of the severe drought that plagued the region in the late 1990s and the recovery of energy export revenues, Syria's economy faces serious challenges. With almost 60% of its population under the age of 20, unemployment higher than the current 9% is a real possibility unless sustained and strong economic growth takes off.
Commerce has always been important to the Syrian economy, which benefited from the country's location along major east-west trade routes. Syrian cities boast both traditional industries such as weaving and dried-fruit packing and modern heavy industry. Given the policies adopted from the 1960s through the late 1980s, Syria refused to join the "global economy". In late 2001, however, Syria submitted a request to the World Trade Organization (WTO) to begin the accession process. Syria had been an original contracting party of the former General Agreement on Tariffs and Trade but withdrew in 1951 because of Israel's joining. Major elements of current Syrian trade rules would have to change in order to be consistent with the WTO. In March 2007, Syria signed an Association Agreement with the European Union that would encourage both sides to negotiate a free trade agreement before 2010.
The bulk of Syrian imports have been raw materials essential for industry, agriculture, equipment, and machinery. Major exports include crude oil, refined products, raw cotton, clothing, fruits, and cereal grains.
Over time, the government has increased the number of transactions to which the more favorable neighboring country exchange rate applies. The government also introduced a quasi-rate for non-commercial transactions in 2001 broadly in line with prevailing black market rates.
Given the poor development of its own capital markets and Syria's lack of access to international money and capital markets, monetary policy remains captive to the need to cover the fiscal deficit. Although in 2003 Syria lowered interest rates for the first time in 22 years and again in 2004, rates remain fixed by law.
Foreign debt.
Syria has made progress in easing its heavy foreign debt burden through bilateral rescheduling deals with virtually all of its key creditors in Europe.In December 2004, Syria and Poland reached an agreement by which Syria would pay $27 million out of the total $261.7 million debt. In January 2005, Russia and Syria signed a deal that wrote off nearly 80% of Syria's debt to Russia, approximately €10.5 billion ($13 billion). The agreement left Syria with less than €3 billion (just over $3.6 billion) owed to Moscow. Half of it would be repaid over the next 10 years, while the rest would be paid into Russian accounts in Syrian banks and could be used for Russian investment projects in Syria and for buying Syrian products. This agreement was part of a weapons deal between Russia and Syria. And later that year Syria reached an agreement with Slovakia, and the Czech Republic to settle debt estimated at $1.6 billion. Again Syria was forgiven the bulk of its debt, in exchange for a one time payment of $150 million.
Sectors of the economy.
Agriculture.
Agriculture is a high priority in Syria's economic development plans, as the government seeks to achieve food self-sufficiency, increase export earnings, and halt rural out-migration. Thanks to sustained capital investment, infrastructure development, subsidies of inputs, and price supports, Syria has gone from a net importer of many agricultural products to an exporter of cotton, fruits, vegetables, and other foodstuffs. One of the prime reasons for this turnaround has been the government's investment in huge irrigation systems in northern and northeastern Syria. The agriculture sector, as of 2009, employs about 17 percent of the labor force and generates about 21 percent of the gross domestic product, of which livestock accounted for 16 percent and fruit and grains for more than 40 percent.
Most land is privately owned, a crucial factor behind the sector's success. Of Syria's 196,000 km² (72,000 square miles), about 28 percent of it is cultivated, and 21 percent of that total is irrigated. Most irrigated land is designated "strategic", meaning that it encounters significant state intervention in terms of pricing, subsidies, and marketing controls. "Strategic" products such as wheat, barley, and sugar beets, must be sold to state marketing boards at fixed prices, often above world prices in order to support farmers, but at a significant cost to the state budget. The most widely grown arable crop is wheat, but the most important cash crop is cotton; cotton was the largest single export before the development of the oil sector. Nevertheless, the total area planted with cotton has declined because of an increasing problem of water shortage coupled with old and inefficient irrigation techniques. The output of grains like wheat is often underutilized because of poor storage facilities.
Water and energy are among the most pervasive issues facing the agriculture sector. Another difficulty the agricultural sector suffered from is the government's decision to liberalize the prices of fertilizers, which have increased between 100% and 400%. Drought was an alarming problem in 2008; however, the drought situation slightly improved in 2009. Wheat and barley production about doubled in 2009 compared to 2008. In spite of that, the livelihoods of up to 1 million agricultural workers have been threatened. In response, the UN launched an emergency appeal for $20.2 million. Wheat has been one of the crops most affected, and for the first time in 2 decades Syria has moved from being a net exporter of wheat to a net importer. During the civil war which began in 2011, the Syrian government was forced to put out a tender for 100,000 metric tonnes of wheat, one of the few trade products not subject to economic sanctions.
Less than 3 percent of Syria's land area is forested, and only a portion of that is commercially useful. Limited forestry activity is centered in the higher elevations of the mountains just inland from the coast, where rainfall is more abundant.
Energy and mineral resources.
Mining.
Phosphates are the major minerals exploited in Syria. Production dropped sharply in the early 1990s when world demand and prices fell, but output has since increased to more than 2.4 million tons. Syria produced about 1.9% of the world's phosphate rock output and was the world's ninth ranked producer of phosphate rock in 2009. Other major minerals produced in Syria include cement, gypsum, industrial sand (silica), marble, natural crude asphalt, nitrogen fertilizer, phosphate fertilizer, salt, steel, and volcanic tuff, which generally are not produced for export.
Oil and natural gas.
Syria is a relatively small oil producer, accounting for just 0.5 percent of the global production in 2010. Although Syria is not a major oil exporter by Middle Eastern standards, oil is a major pillar of the economy. According to the International Monetary Fund, oil sales for 2010 were projected to generate $3.2 billion for the Syrian government and account for 25.1% of the state's revenue.
Electrical generation.
In 2001 Syria reportedly produced 23.3 billion kilowatt hours (kWh) of electricity and consumed 21.6 billion kWh. As of January 2002, Syria's total installed electric generating capacity was 7.6 gigawatts (GW), with fuel oil and natural gas serving as the primary energy sources and 1.5 GW generated by hydroelectric power. A network totaling 45 GW linking the electric power grids of Syria, Egypt, and Jordan was completed in March 2001. Syria's electric supply capacity is an important national priority, and the government hopes to add 3,000 megawatts of power generating capacity by 2010 at a probable cost of US$2 billion, but progress has been slowed by a lack of investment capital. Power plants in Syria are undergoing intensive maintenance, and four new generating plants have been built. The power distribution network has serious problems, with transmission losses estimated as high as 25 percent of total generated capacity as a result of poor quality wires and transformer stations. A project for the expansion and upgrading of the power transmission network is scheduled for completion in 2005.
As of May 2009 it was reported that the Islamic Development Bank and the Syrian government signed an agreement stating that the bank would provide a €100 million loan for the expansion of Deir Ali power station in Syria.
Nuclear energy.
Syria abandoned its plans to build a VVER-440 reactor after the Chernobyl accident. The plans for a nuclear program were revived at the beginning of the 2000s when Syria negotiated with Russia to build a nuclear facility that would include a nuclear power plant and a seawater atomic desalination plant.
Industry and manufacturing.
The industrial sector, which includes mining, manufacturing, construction, and petroleum, accounted for 27.3 percent of gross domestic product (GDP) in 2010 and employed about 16 percent of the labor force. The main industrial products are petroleum, textiles, food processing, beverages, tobacco, phosphate rock mining, cement, oil seeds crushing, and car assembly. Syria's manufacturing sector was largely state dominated until the 1990s, when economic reforms allowed greater local and foreign private-sector participation. Private participation remains constrained, however, by the lack of investment funds, input/output pricing limits, cumbersome customs and foreign exchange regulations, and poor marketing.
Because land prices are not controlled by the state, real estate is one of the few domestic avenues for investment with realistic and safe returns. Activity in the construction sector tends to mirror changes in the economy. Investment Law No. 10 of 1991, which opened the country to foreign investment in some areas, marked the beginning of a strong revival, with growth in real terms increasing over 2001 and 2002.
Services.
Services accounted for 45.3 percent of gross domestic product (GDP) in 2009 and employed 67 percent of the labor force, including government, in 2008. As of May 2009, it was reported that Damascus office prices are skyrocketing.
Banking and finance.
The Syrian government under Assad started its reform efforts by changing the regulatory environment in the financial sector, including the introduction of private banks and the opening of the Damascus Securities Exchange in March 2009. In 2001, Syria legalized private banking and the sector, while still nascent, has been growing. Foreign banks were given licenses in December 2002, in compliance with Law 28 March 2001, which allows the establishment of private and joint-venture banks. Foreigners are allowed up to 49 percent ownership of a bank, but may not hold a controlling stakes. As of January 2010, 13 private banks had opened, including two Islamic banks.
Syria has taken gradual steps to loosen controls over foreign exchange. In 2003, the government canceled a law that criminalized private sector use of foreign currencies, and in 2005 it issued legislation that allowed licensed private banks to sell specific amounts of foreign currency to Syrian citizens under certain circumstances and to the private sector to finance imports. In October 2009, the Syrian Government further loosened its restrictions on currency transfers by allowing Syrians travelling abroad to withdraw the equivalent of up to U.S. $10,000 from their Syrian pound accounts. In practice, the decision allows local banks to open accounts of a maximum of U.S. $10,000 that their clients can use for their international payment cards. The holders of these accounts will be able to withdraw up to U.S. $10,000 per month while travelling abroad.
To attract investment and to ease access to credit, the government allowed investors in 2007 to receive loans and other credit instruments from foreign banks, and to repay the loans and any accrued interest through local banks using project proceeds. In February 2008, the government permitted investors to receive loans in foreign currencies from local private banks to finance capital investments. Syria's exchange rate is fixed, and the government maintains two official rates—one rate on which the budget and the value of imports, customs, and other official transactions are based, and a second set by the Central Bank on a daily basis that covers all other financial transactions. The government passed a law in 2006 which permits the operation of private money exchange companies. However, a small black market for foreign currency is still active.
Still after the opening of the financial sector, the six specialized state banks, the Central Bank of Syria, Commercial Bank of Syria, Agricultural Co-Operative Bank, Industrial Bank, Popular Credit Bank, and Real Estate Bank, are major financial operators. They each extend funds to, and take deposits from, a particular sector. The Central Bank of Syria controls all foreign exchange and trade transactions and gives priority to lending to the public sector. The Industrial Bank also is directed more toward the public sector, although it is under-capitalized. As a result, the private sector often is forced to bank abroad, a process that is more expensive and therefore a poor solution to industrial financing needs. Many business people travel abroad to deposit or borrow funds. It is estimated that Syrians have deposited US$6 billion in Lebanese banks. The U.S. sanctions of May 2004 may have increased the role of Lebanese and European banks because a ban on transactions between U.S. financial institutions and the Central Bank of Syria created an increase in demand for intermediary sources for U.S. dollar transfers. The US, EU, Arab league and Turkey all imposed Sanctions on the central bank because of the Syrian Civil War.
Tourism.
Non-Arab visitors to Syria reached 1.1 million in 2002, which includes all visitors to the country, not just tourists. The total number of Arab visitors in 2002 was 3.2 million, most from Lebanon, Jordan, Saudi Arabia, and Iraq. Many Iraqi businesspeople set up ventures in Syrian ports to run import operations for Iraq, causing an increased number of Iraqis visiting Syria in 2003–4. Tourism is a potentially large foreign exchange earner and a source of economic growth. Tourism generated more than 6 percent of Syria's gross domestic product in 2000, and more reforms were discussed to increase tourism revenues. As a result of projects derived from Investment Law No. 10 of 1991, hotel bed numbers had increased 51 percent by 1999 and increased further in 2001. A plan was announced in 2002 to develop ecological tourism with visits to desert and nature preserves. Two luxury hotels opened in Damascus at the end of 2004. Since March 2011 tourism in Syria has fallen due to the ongoing civil war.
Labour.
Syria has a population of approximately 21 million people, and Syrian government figures place the population growth rate at 2.37%, with 65% of the population under the age of 35 and more than 40% under the age of 15. Each year more than 200,000 new job seekers enter the Syrian job market, but the economy has not been able to absorb them. In 2010, the Syrian labor force was estimated to total about 5.5 million people. An estimated 67 percent worked in the services sector including government, 17 percent in agriculture, and 16 percent in industry in 2008. Government and public sector employees constitute about 30% of the total labor force and are paid very low salaries and wages.
According to Syrian Government statistics, the unemployment rate in 2009 was 12.6%; however, more accurate independent sources place it closer to 20%. About 70 percent of Syria's workforce earns less than US$100 per month. Anecdotal evidence suggests that many more Syrians are seeking work over the border in Lebanon than official numbers indicate. In 2002 the Unemployment Commission (UC) was established, tasked with creating several hundred thousand jobs over a five-year period. As of June 2009 it was reported that some 700,000 households in Syria - about 3.5 million people - have no income. Government officials acknowledge that the economy is not growing at a pace sufficient to create enough new jobs annually to match population growth. The UN Development Program announced in 2005 that 30% of the Syrian population lives in poverty and 11.4% live below the subsistence level.
Opportunity cost of conflict.
A report by Strategic Foresight Group, an India-based think tank, calculated the opportunity cost of conflict for the Middle East for 1991—2010 at US$12 trillion in 2006 dollars. Syria's share in this was US$152 billion, more than four times the projected 2010 GDP of US$36 billion.
The Syrian Center for Policy Research stated in March 2015 that, by then, nearly three million Syrians had lost their jobs because of the civil war, causing the loss of the primary source of income of more than 12 million people; unemployment levels "surged" from 14.9 percent in 2011 to 57.7 percent at the end of 2014. As a result, 4 in 5 Syrians were by then living in poverty, with 30 percent of the population living in "abject poverty" and frequently unable to meet basic household food needs.

</doc>
<doc id="27477" url="https://en.wikipedia.org/wiki?curid=27477" title="Telecommunications in Syria">
Telecommunications in Syria

The Syrian Ministry of Communications retains governmental authority over the internet in Syria. Prior to the Syrian civil war, telecommunications in Syria were slowly moving towards liberalization, with a number of licenses awarded and services launched in the Internet service provision market. The initiative reflected the government's change in attitude towards liberalization, following its promise to the European Union to liberalize markets by 2010. All other forms of fixed-line communications are provided by the state owned operator, Syrian Telecom (STE).
Telecommunications system.
International dialing code: +963
Landline telephones in use in 2009: 4,069,000.
Mobile phones in use in 2009: 11,696,000. The mobile operators are Syriatel (http://www.syriatel.sy) and MTN (http://www.mtn.com.sy). There is mobile phone coverage in most parts of Syria providing access to 96% of the population. Call quality ranges from acceptable to poor. Many international calls fail or are less clear over the mobile network compared to the landline network.
Radio: 14 AM, 11 FM, and 1 shortwave stations in 1998. The radio operators are the state owned Syrian Arab Republic Radio and Al-Madina FM, the first private radio station, launched in March 2005. Private radio stations cannot transmit news or political content.
Television: There are two television operators: the state owned Syrian Television which operates two domestic networks and a satellite channel, broadcasting in Arabic, English, and French and the private Addounia TV. There are no restrictions on the use of satellite receivers and many viewers watch pan-Arab TV stations. Roughly two-thirds of Syrian homes have a satellite dish providing access to foreign TV broadcasts.
Opposition satellite stations broadcast from abroad; they include London-based Barada TV and Orient TV, which operates from the UAE.
Internet.
Country code: The top level domain for Syria is .sy.
There were 4,469,000 Internet users in Syria as of June 2011 for a 19.8% Internet penetration rate. Syria ranks 12th out of 14 countries in the Middle East region, just behind Jordan (26.8%) and ahead of Yemen (9.7%) and Iraq (2.8%). Growth in the number of Internet users has been fairly steady since 2005:
There were 420 Syrian Internet hosts in 2010, placing Syria 187th out of 231 in the world.
With a measured download speed that averages 768 kbit/s, the speed of the Internet in Syria is relatively slow compared to the world-wide average of 4.6 Mbit/s.
ADSL service in Syria has been available since 2003. However, ADSL is not available in all locations and, where available, the local telco may not have enough ports for immediate activation. Through 2009 broadband Internet access had reached less than 0.2% of the Syrian population.
The 3G wireless Internet is available in all major cities as well as cities with significant tourism. 2.5G EDGE wireless Internet is available through mobile network operators, SyriaTel and MTN. Wireless Internet is accessed using a USB stick purchased from the mobile operators. In addition, 3G SIM cards for use on mobile phones may be purchased with a data plan. However, only WCDMA phones support data at the moment.
High-speed Internet is also available through many Internet cafes.
Internet service providers (ISPs).
ISPs in Syria include:
Internet censorship.
Internet filtering in Syria was found to be pervasive in the political and Internet tools areas, and selective in the social and conflict/security areas by the OpenNet Initiative in August 2009. Syria has been on Reporters Without Borders Enemy of the Internet list since 2006 when the list was established. In 2009, the Committee to Protect Journalists named Syria number three in a list of the ten worst countries in which to be a blogger, given the arrests, harassment, and restrictions which online writers in Syria have faced.
Syria has banned websites for political reasons and arrested people accessing them. In addition to filtering a wide range of Web content, the Syrian government monitors Internet use very closely and has detained citizens "for expressing their opinions or reporting information online." Vague and broadly worded laws invite government abuse and have prompted Internet users to engage in self-censoring and self-monitoring to avoid the state's ambiguous grounds for arrest.
In February 2011 Syria stopped filtering YouTube, Facebook, and Twitter.
Voice over Internet Protocol (VoIP) is blocked completely and requires a proxy or Virtual Private Network (VPN) to work around it. However, VoIP operators that utilize non-standard Session Initiation Protocol (SIP) ports may function behind Syria's proxy.
Internet cafes, which are widespread and accessible to the public for a fee, can be used to access blocked sites. However, more restrictions have been placed on internet cafes, all public internet centers need operating approval from the security services, are required to keep detailed records of their customers' surfing habits, and people have been arrested after accessing blocked content.
Shutdown of Syrian Internet.
In November 2012, it was reported that all Internet connectivity between Syria and the outside world appeared to have ceased, as of 29 November 2012. This coincided with reported intense rebel activity inside Syria. Matthew Prince, CEO of Cloudflare, reported that three undersea cables in Tartous, Syria and a fourth land cable through Turkey were connecting Syria to the internet prior to the event.
However, according to an August 2014 interview with Edward Snowden, the Internet blackout in Syria was related to a failed attempt by the U.S. National Security Agency (NSA) to infiltrate malware on a core router of one of the country's main Internet Service Providers (ISPs).

</doc>
<doc id="27478" url="https://en.wikipedia.org/wiki?curid=27478" title="Transport in Syria">
Transport in Syria

This article deals with the system of transport in Syria, both public and private.
Railways.
"total:"
2,052 km
<br>"standard gauge:"
1,801 km of gauge
<br>"narrow gauge:"
251 km of gauge (2006)
See also Hejaz railway.
Road Transport.
An overland trans-desert bus service between Beirut, Haifa, Damascus and Baghdad was established by the "Nairn Transport Company" of Damascus in 1923.
Roads.
"total:"
68,157 km
<br>"paved:"
61,514 km (including 1,103 km of expressways)
<br>"unpaved:"
6,643 km (2006)
Motorways.
Syria has a well-developed system of motorways in the western half of the country. The eastern part nevertheless has only connection through two lanes roads due to the sparsity of the population. The main motorways in Syria are the following:
Waterways.
900 km; minimal economic importance
Pipelines.
crude oil 1,997 km; petroleum products 3,161 km (2010)
Ports and Harbors.
Main international seaport at Latakia with additional ports at Baniyas, Jablah, and Tartus.
Merchant marine.
"total:"
19 ships ( or over) totaling /
<br>"ships by type:"
bulk carrier 4, cargo ship 14, carrier 1 (2010)
Airports.
As of 2012, Syria had a total of 99 airports. The major airports are: Aleppo International Airport, Bassel Al-Assad International Airport, Damascus International Airport, Deir ez-Zor Airport, Kamishly Airport, and Palmyra Airport.
Airports (with paved runways).
"total:" 29<br>
"over 3,047 meters in length:" 5<br>
"2,438 to 3,047 meters:" 16<br>
"914 to 1,523 meters:" 3<br>
"under 914 meters:" 5
Airports (with unpaved runways).
"total:"
70
<br>"1,524 to 2,437 m:"
1
<br>"914 to 1,523 m:"
14
<br>"under 914 m:"
55 (2012)

</doc>
<doc id="27479" url="https://en.wikipedia.org/wiki?curid=27479" title="Syrian Armed Forces">
Syrian Armed Forces

The Syrian Armed Forces () are the military forces of Syria. They consist of the Syrian Arab Army, Syrian Arab Navy, Syrian Arab Air Force, Syrian Arab Air Defense Force, and several paramilitary forces. According to the Syrian constitution, the President of Syria is the Commander-in-Chief of the Armed Forces.
The military is a conscripted force; males serve in the military upon reaching the age of 18, but there are many women in the armed forces. Since the Syrian Civil War, the enlisted members of the Syrian military have dropped by over half from a pre-civil war figure of 325,000 to 150,000 soldiers in the army in December 2014, due to casualties, desertions and draft dodging, reaching between 178,000 and 220,000 soldiers in the army, in addition to 80,000 to 100,000 irregular forces.
Before the start of the Syrian Civil War, the obligatory military service period was being decreased over time. In 2005, it was reduced from two and a half years to two years, in 2008 to 21 months and in 2011 to year and a half. Since the Syrian Civil War the Syrian government has reportedly engaged in arrest campaigns and enacted new regulations, with even citizens who have completed mandatory conscription being called up for reserve duty.
History.
The French Mandate volunteer force, which would later become the Syrian army, was established in 1920 with the threat of Syrian−Arab nationalism in mind. Although the unit's officers were originally all French, it was, in effect, the first indigenous modern Syrian army. In 1925, this force was expanded and designated as the Special Troops of the Levant (Troupes Spéciales du Levant). In 1941, during World War II, the Army of the Levant participated in a futile resistance to the British and Free French invasion that ousted the Vichy French from Syria during the Syria–Lebanon Campaign. After the Allies takeover, the army came under the control of the Free French and was designated the Levantine Forces (Troupes du Levant).
https://archive.org/stream/syriacountrystud00coll_0/syriacountrystud00coll_0_djvu.txt
French Mandate authorities maintained a gendarmerie to police Syria's vast rural areas. This paramilitary force was used to combat criminals and political foes of the Mandate government. As with the Levantine Special Troops, French officers held the top posts, but as Syrian independence approached, the ranks below major were gradually filled by Syrian officers who had graduated from the Homs Military Academy, which had been established by the French during the 1930s. In 1938, the Troupes Spéciales numbered around 10,000 men and 306 officers (of whom 88 were French, mainly in the higher ranks). A majority of the Syrian troops were of rural background and minority ethnic origin, mainly Alawis, Druzes, Kurds, and Circassians. By the end of 1945, the army numbered about 5,000 and the gendarmerie some 3,500. In April 1946, the last French officers were forced to leave Syria due to sustained resistance offensives; the Levantine Forces then became the regular armed forces of the newly independent state and grew rapidly to about 12,000 by the time of the 1948 Arab−Israeli War, the first of four Arab−Israeli wars between 1948 and 1986.
Post Second World War.
The Syrian Armed Forces fought in the 1948 Arab-Israeli War (against Israel), and were involved in a number of military coups. Between 1948 and 1967, a series of military coups destroyed the stability of the government and any remaining professionalism within the armed forces. In March 1949, the chief of staff, General Husni al-Za'im, installed himself as president. Two more military dictators followed by December 1949. General Adib Shishakli then held power until deposed in the 1954 Syrian coup d'etat. Further coups followed, each attended by a purge of the officer corps to remove supporters of the losers from the force.
In 1963, the Military Committee of the Syrian Regional Command of the Arab Socialist Ba'ath Party spent most of its time planning to take power through a conventional military coup. From the very beginning, the Military Committee knew it had to capture al-Kiswah and Qatana, two military camps, seize control of the 70th Armoured Brigade at al-Kiswah, the Military Academy in the city of Homs and the Damascus radio station. While the conspirators of the Military Committee were all young, their aim was not out of reach; the sitting regime had been slowly disintegrating and the traditional elite had lost effective political power over the country. A small group of military officers, including Hafez al-Assad, soon seized control in the March 1963 Syrian coup d'etat. Following the coup, General Amin al-Hafiz discharged many ranking Sunni officers, thereby, Stratfor says, 'providing openings for hundreds of Alawites to fill top-tier military positions during the 1963-1965 period on the grounds of being opposed to Arab unity. This measure tipped the balance in favor of Alawite officers who staged a coup in 1966 and for the first time placed Damascus in the hands of the Alawites.'
The Armed Forces were involved in the 1967 Six Day War (against Israel). Since 1967, most of the Golan Heights territory of southwestern Syria has been under Israeli occupation. They then fought in the late 1960s War of Attrition (against Israel), and the 1970 Black September invasion of Jordan. During the Yom Kippur War of 1973 the Syrian Army launched an invasion of Israel that was only narrowly repulsed. Since 1973 the cease-fire line has been respected by both sides, with very few incidents until the Syrian uprising of 2011 began.
Syria was invited into Lebanon by that country's president in 1976, to intervene on the side of the Lebanese government against a rebellion of PLO and Lebanese forces. The Arab Deterrent Force originally consisted of a Syrian core with participation by some other Arab League states. However the other states withdrew their forces in the late 1970s.
Occupation of Lebanon.
Syrian forces, still technically known as the Arab Deterrent Force, lingered in Lebanon throughout the Lebanese civil war (1975–1990). Eventually the Syrians brought most of the nation under their control, as part of a power-struggle with Israel, which occupied areas of southern Lebanon in 1978. Following the end of the Lebanese civil war in 1990, the Syrian occupation of Lebanon continued until 2005, when they were forced out by widespread public protest and international pressure, following the murder of Rafiq al-Hariri. About 20,000 Syrian soldiers were deployed in Lebanon until 27 April 2005, when the last of Syria's troops left the country. Syrian forces have been accused of involvement in that murder, as well as continued meddling in Lebanese affairs, and an international investigation into the Hariri killing and several subsequent bomb attacks has been launched by the UN.
Other engagements.
Engagements since 1979 have included the Islamic uprising in Syria (1979–82), notably including the Hama Massacre, the 1982 Lebanon War (against Israel), and the dispatch of the 9th Armoured Division to Saudi Arabia in 1990–91, ahead of the Gulf War against Iraq. The 9th Armoured Division served as the Arab Joint Forces Command North reserve and saw little action. Syria's force numbered ~20,000 in strength (the 6th largest contingent) and their involvement was justified domestically as an effort to defend Saudi Arabia. Syria's initial involvement in Operation Desert Shield also rolled into the Allied Operation Desert Storm as Syrian forces did participate in helping dislodge and drive Iraqi forces out of Kuwait City. Total losses sustained were 2 dead and 1 wounded. There were indications the Syrian government had been prepared to double its force to 40,000.
Modernisation.
In recent years Syria has relied on Russian arms purchases to obtain modern weapons. Purchases have included anti-tank and air defence systems. In early September 2008, the Syrian government ordered MiG-29SMT fighters, Pantsir S1E air-defence systems, Iskander tactical missile systems, Yak-130 aircraft, and two Amur-1650 submarines from Russia. Russia's Foreign Minister Sergei Lavrov asserted that the sale wouldn't upset the balance of power in the Middle East and were "in line with ..international law."
Russia aims to turn the Russian naval base in Tartus into a permanent naval base. Israel and the United States oppose further arms sales to Syria due to fears that the weapons could fall under the control of Iran or Hezbollah fighters in Lebanon.
Syrian civil war.
Since the Syrian civil war began, the Armed Forces have been sent to fight the insurgents. As the uprising progressed into civil war, many soldiers began to defect from the Syrian Armed Forces and came together under the banner of the Free Syrian Army. In March 2012, the Syrian government issued new travel restrictions for military-aged males. Under the new restrictions, reported by local Syrian news outlets, all males between 18 and 42 were banned from traveling outside the country. In a late June 2012 interview given by the FSA's "Asharq Al-Awsat" he claimed Riad al-Asaad said that about 20-30 Syrian officers defected to Turkey each day.
On 18 July 2012 Syrian Defence Minister Dawoud Rajha, former defence minister Hasan Turkmani, and the president's brother-in-law General Assef Shawkat were killed by a bomb attack in Damascus. The Syrian intelligence chief Hisham Bekhityar, and Head of the 4th Army Division Maher Al Assad brother to President Assad were also injured in the same explosion.
Since the start of the Syrian civil war, human rights groups say that the majority of abuses have been committed by the Syrian government's forces, and UN investigations have concluded that the government's abuses are the greatest in both gravity and scale. The branches of the Syrian Armed Forces that have committed war crimes include at least the Syrian Arab Army, Syrian Arab Air Force and the Syrian Military Intelligence. However the Syrian authorities deny these accusations and claim that irregular armed groups with foreign support are behind the atrocities, including Al Qaeda linked Insurgents.
Despite shrinking by nearly half since the beginning of the civil war in 2011, the Armed Forces has become much more flexible and capable, especially in anti-guerilla warfare. Its "modus operandi" switched from a traditional Soviet-modeled conventional military into a force of smaller groups fighting in close-quarters guerrilla combat with an increasing role of junior officers.
Structure.
With its headquarters in Damascus, the Syrian military consists of air, ground, and naval forces. Active personnel were estimated as 295,000 in 2011, with an additional 314,000 reserves. Paramilitary forces were estimated at 108,000 in 2011.
The majority of the Syrian military are Sunni, but most of the military leadership are Alawites. Alawites make up 12 percent of the Syrian population but are estimated to make up 70 percent of the career soldiers in the Syrian Army. Of the 200,000 or so career soldiers in the Syrian Army, 140,000 are Alawites. A similar imbalance is seen in the officer corps where some 80 percent of the officers are Alawites. The military’s most elite divisions, the Republican Guard and the 4th Armoured Division, which are commanded by Bashar al-Assad's brother Maher, are exclusively Alawite. Most of Syria’s 300,000 conscripts were, however, Sunni but that number is speculated to be changing now.
Syrian Army.
In 1987, Joshua Sinai of the Library of Congress wrote that the Syrian Arab Army was the dominant military service, and as such controlled the senior-most posts in the armed forces, and had the most manpower, approximately 80 percent of the combined services. In 1987, Sinai wrote that the major development in force organisation was the establishment of an additional divisional framework based on the special forces and the organisation of ground formations into two corps. In 2010, the International Institute for Strategic Studies estimated army regulars at 220,000, with an additional 280,000 reserves. That figure was unchanged in the 2011 edition of the "Military Balance", but in the 2013 edition, in the midst of the war, the IISS estimated that army strength was 110,000.
The army's active manpower served in three, all-arms army corps, eight armoured divisions (with one independent armoured brigade), three mechanised divisions, one armoured-special forces division, and ten, independent airborne-special forces brigades. The army had eleven divisional formations reported in 2011, with a fall in the number of armoured divisions reported from the 2010 edition, from eight to seven. The independent armoured brigade had been replaced by an independent tank regiment. However, in addition to the 14th Special Forces Division, the 15th Special Forces Division has been identified by Human Rights Watch in 2011.
The former Defense companies were merged into the Syrian Army as the 4th Armoured Division and the Republican Guard. The 4th Armoured Division became one of the Assad government's most trusted security forces.
Syrian Navy.
In 1950, the Syrian Navy was established following the procurement of a few naval craft from France. The initial personnel consisted of soldiers who had been sent to French academies of naval training. In 1985, the navy consisted of approximately 4,000 regular and 2,500 reserve officers and men. The navy is under the army's Latakia regional command. The fleet was based in the ports of Latakia, Baniyas, Minat al Bayda, and Tartus. Among the 41 vessel fleet were 2 frigates, 22 missile attack craft (including 10 advanced Osa II missile boats), 2 submarine chasers, 4 mine warfare vessels, 8 gunboats, 6 patrol craft, 4 missile corvettes (on order), 3 landing craft (on order), 1 torpedo recovery vessel and, as part of its coastal defence system, Sepal shore-based, anti-ship missiles with a range of 300 kilometres.
Syrian Air Force.
The Syrian Arab Air Force is the aviation branch of the Syrian Armed Forces. It was established in 1948, and saw combat in 1948, 1967, 1973 and in 1982 against Israel. It has seen combat against militant groups on Syrian soil from 2011-2012, during the Syrian civil war. Presently, there are at least 15 Syrian air force bases throughout the country.
Syrian Air Defence Force.
In 1987, according to the Library of Congress Country Studies, the Air Defence Command, within the Army Command, but also composed of Air Force personnel, numbered approximately 60,000. In 1987, units included twenty air defence brigades (with approximately ninety-five SAM batteries) and two air defence regiments. The Air Defence Command had command access to interceptor aircraft and radar facilities. Air defences included SA-5 long-range SAM batteries around Damascus and Aleppo, with additional SA-6 and SA-8 mobile SAM units deployed along Syria's side of the Lebanese border and in eastern Lebanon.
At some later point in time, the Air Defence Command was upgraded into a separate, Syrian Air Defense Force.
Paramilitary forces.
"See: List of armed groups in the Syrian Civil War#Syrian government and allies for more information on current paramilitaries due to the ongoing Syrian civil war."
Role of women in the Armed forces.
As the Syrian Civil War progressed and casualties mounted, more and more positions were opened to women. The National Defense Force allows female volunteers into its ranks, mainly in securing checkpoints. The Republican Guard also formed a female section, an all female tank battalion of 800 strong, nicknamed 'Lionesses of Defense', fighting within the limits of Damascus.
Weapons, uniforms and organisation.
Weapons.
The breakup of the Soviet Union — long the principal source of training, material, and credit for the Syrian forces — may have slowed Syria's ability to acquire modern military equipment. It has an arsenal of surface-to-surface missiles. In the early 1990s, Scud-C missiles with a 500-kilometer range were procured from North Korea, and Scud-D, with a range of up to 700 kilometers, is allegedly being developed by Syria with the help of North Korea and Iran, according to Eyal Zisser.
Syria received significant financial aid from Persian Gulf Arab states as a result of its participation in the Persian Gulf War, with a sizable portion of these funds earmarked for military spending. In 2005, Russia forgave Syria of three-fourths, or about $9.8 billion, of its $13.4 billion Soviet-era debt. Russia wrote off the debt in order to renew arms sales with Syria. As of 2011, arms contracts with Russia, Syria's main arms supplier, were worth at least $4 billion. Syria has conducted research and produced weapons of mass destruction.
Uniforms (1987).
In 1987, according to a Library of Congress Country Study on Syria, service uniforms for Syrian military officers generally followed the British Army style, although army combat clothing followed the older British model. Each uniform had two coats: a long one for dress and a short jacket for informal wear. Army officer uniforms were khaki in summer, olive in winter. Certain Army and Air Defense personnel (i.e., commandos and paratroops) may have worn camouflage uniforms. Air force officers had two uniforms for each season: a khaki and a light gray for summer and a dark blue and a light gray in winter. Naval officers wore white in summer and navy blue in winter while lower ranks wear the traditional bell bottoms and white blouse. The uniform for naval chief petty officers was a buttoned jacket, similar to that worn by American chief petty officers. Officers had a variety of headgear, including a service cap, garrison cap, and beret (linen in summer and wool in winter). The color of the beret varied by season and according to the officer's unit.
Syrian Commando and Paratroop uniforms consist of lizard or woodland-patterned camouflage fatigues along with combat boots, helmets and bulletproof vests. Headgear consisted of a red or orange beret.
The Syrian military provides NBC uniforms to soldiers in order to remain effective in an environment effected by biological or chemical agents. This uniform consisted of a Russian-made Model ShMS-41 mask similar to those made in the Desert Storm conflict. Previous models of the ShMS used a hose, while the improved "ShmS-41" used a canister-style Respirator.
Rank Insignia (1987).
In 1987, according to a Library of Congress Country Study on Syria, the rank insignia of Syrian commissioned officers were identical for both the army and air force. These were gold on a bright green shoulder board for the army and gold on a bright blue board for the air force. Officer ranks were standard, although the highest is the equivalent of lieutenant general, a rank held in 1986 only by the commander in chief and the minister of defence. Navy officer rank insignia were gold stripes worn on the lower sleeve. The highest-ranking officer in Syria's navy is the equivalent of lieutenant general. Army and air force rank for warrant officers were indicated by gold stars on an olive green shield worn on the upper left arm. Lower noncommissioned ranks were indicated by upright and inverted chevrons worn on the upper left arm.
Awards and decorations.
Although some twenty-five orders and medals were authorized, generally only senior officers and warrant officers wear medal ribbons. The following were some important Syrian awards: Order of Umayyads, Medal of Military Honor, the War Medal, Medal for Courage, Yarmuk Medal, Wounded in Action Medal, and Medal of 8 March 1963.

</doc>
<doc id="27480" url="https://en.wikipedia.org/wiki?curid=27480" title="Foreign relations of Syria">
Foreign relations of Syria

Ensuring national security, increasing influence among its Arab neighbors, and securing the return of the Golan Heights, have been the primary goals of Syria's foreign policy. At many points in its history, Syria has seen virulent tension with its geographically cultural neighbors, such as Turkey, Israel, Iraq, and Lebanon. Syria enjoyed an improvement in relations with several of the states in its region in the 21st century, prior to the Arab Spring and the Syrian Civil War.
Since the ongoing civil war, Syria has been increasingly isolated from the countries in the region, and the wider international community. Diplomatic relations have been severed with several countries including: Britain, Turkey, Saudi Arabia, Canada, France, Italy, Germany, United States, Belgium, Spain, and the Arab states of the Persian Gulf. Syria was suspended from the Arab League in 2011 and the Organisation of Islamic Cooperation in 2012. Syria continues to foster good relations with its traditional allies, Iran and Russia. Other countries that presently maintain good relations with Syria include China, North Korea, Angola, Cuba, Venezuela, Bolivia, Ecuador, Nicaragua, Brazil, Guyana, India, South Africa, Tanzania, Pakistan, Armenia, Argentina, Belarus, Tajikistan, Philippines, Uganda, Zimbabwe, and others. From among the Arab League states, Syria continues to have good relations with Iraq, Egypt (after 3 July 2013), Algeria, Kuwait, Lebanon and Oman.
Middle East.
Arab nationalism is a fundamental doctrine of Syrian government policy, and as such it doesn't consider inhabitants of other Arab states as 'foreigners'. Rather the Syrian Arab Republic is considered as part of one vast Arab homeland, "al-watan al-arabi".
Syria's relations with the Arab world were strained by its support for Iran during the Iran–Iraq War, which began in 1980. With the end of the war in August 1988, Syria began a slow process of reintegration with the other Arab states. In 1989, it joined with the rest of the Arab world in readmitting Egypt to the 19th Arab League Summit at Casablanca.
This decision, prompted in part by Syria's need for Arab League support of its own position in Lebanon, marked the end of the Syrian-led opposition to Egypt and the 1977–79 Sadat initiatives toward Israel, as well as the Camp David Accords. It coincided with the end of the 10-year Arab subsidy to Syria and other front-line Arab countries pledged at Baghdad in 1978. Syria re-established full diplomatic relations with Egypt in 1989. In the 1990–1991 Gulf War, Syria joined other Arab states in the US-led multinational coalition against Iraq. In 1998, Syria began a slow rapprochement with Iraq, driven primarily by economic needs. Syria continues to play an active pan-Arab role, which has intensified as the peace process collapsed in September 2000 with the start of the second Palestinian uprising (Intifada) against Israel. Though it voted in favor of UNSCR 1441 in 2002, Syria was against coalition military action in Iraq in 2003. However, the Syrian government accepted UNSCR 1483 (after being absent for the actual vote), which lifted sanctions on Iraq and established a framework to assist the Iraqi people in determining their political future and rebuilding their economy. Currently, much of the Middle East has condemned Syria's handling of the civil uprising, with only a few countries in the Middle East supporting Syria, most notably Iran, Iraq and Lebanon.
Arab League.
Syria has been temporarily suspended from the Arab League since the Syrian civil war. On 26 March 2013, at the Arab league summit in Doha, the League recognised the 
National Coalition for Syrian Revolutionary and Opposition Forces, as the legitimate representatives of the Syrian people. The National Coalition was henceforth granted Damascus' seat at the summit. This act of recognition was opposed by Algeria, Iraq & Lebanon.
Iran.
Syria and Iran are strategic allies. Syria is often called Iran's "closest ally", the Arab nationalism ideology of Syria's ruling Baath party notwithstanding. During the Iran–Iraq War, Syria sided with non-Arab Iran against its enemy Iraq and was isolated by Saudi Arabia and some of the Arab countries, with the exceptions of Libya, Lebanon, Algeria, Sudan and Oman. Iran and Syria have had a strategic alliance ever since, partially due to their common animosity towards Saddam Hussein and coordination against the United States and Israel. Syria and Iran cooperate on arms smuggling from Iran to the Hezbollah in Lebanon, which borders Israel.
On 16 June 2006 the defence ministers of Iran and Syria signed an agreement for military cooperation against what they called the "common threats" presented by Israel and the United States. Details of the agreement were not specified, however Syrian defense minister Najjar said "Iran considers Syria's security its own security, and we consider our defense capabilities to be those of Syria." The visit also resulted in the sale of Iranian military hardware to Syria. In addition to receiving military hardware, Iran has consistently invested billions of dollars into the Syrian economy. The Syrian leadership, including President Assad himself, belongs predominantly to the Alawite branch of Shi'a Islam. Currently, Iran is involved in implementing several industrial projects in Syria, including cement factories, car assembly lines, power plants, and silo construction. Iran also plans to set up a joint Iranian–Syrian bank in the future.
Iraq.
The political states of Iraq and Syria were formed by the United Kingdom and France following the defeat of the Ottoman Empire in World War I. Iraq and Syria are united by historical, social, political, cultural and economic relations, but share a long foreign drawn border. The land known as Mesopotamia is Iraq and eastern Syria and is called such by its inhabitants. Political relations between Iraq and Syria have in the past seen difficulties, however, new diplomatic relations described by both sides as "Historic" were established in November 2006, beginning an era of close cooperation and political friendship between Iraq and Syria.
Israel.
Syria has been an active belligerent, with periodic ceasefires and use of proxies, against Israel ever since May 1948, when the Syrian army captured territory from the newly established State of Israel north and south of the Sea of Galilee. Most of this territory was returned to Israel after the signing of the July 1949 Armistice Agreement and declared Demilitarized Zones. However, the exact location of the border between the two states, ownership of portions of territory and the right of Israeli farmers to farm the land in the Demilitarized Zones on the Israeli side of the border remained in dispute and sparked intermittent fighting between Syria and Israel until the 1967 Arab–Israeli War. Through the early 1950s the Syrians gradually retook de facto control of some of the territory ostensibly belonging to Israel (along the foot of part of the western escarpment of the Golan Heights north of the Sea of Galilee, along the north-eastern coast of the Sea of Galilee and the low ground below the southern escarpment of the Golan). In addition to the territorial dispute, small-scale fighting was also sparked by a dispute over Israel's right to pump water from the Jordan River and the Sea of Galilee (actually a fresh-water lake) for use in agricultural irrigation and drinking. From 1964 to 1966 the Syrians attempted to dig a canal that would divert the sources of the Jordan River before they entered Israeli territory—thus drying up that portion of the River and dramatically reducing the water-intake of the Sea of Galilee to prevent Israel from using that water. This led to a period of escalated fighting as the Israelis sought to prevent this diversion project which threatened to severely damage their ability to provide fresh-water to their population and agriculture (attempts to negotiate a solution by UN mediators failed). In fact, escalation of incidents between Israel and Syria in late 1966 and spring 1967 was one of the prime causes leading to the crisis that precipitated the Six Day War.
Syria was an active belligerent in the 1967 Arab–Israeli War, which resulted in Israel's occupation of the Golan Heights and the city of Quneitra. On 19 June, a week after the war ended, Israel offered to return the Golan if Syrian would agree to a full Peace Treaty. However, Syria refused. From 1967 to 1973 there were sporadic bouts of fighting along the new border.
Following the October 1973 Arab–Israeli War, which left Israel in occupation of additional Syrian territory, Syria accepted UN Security Council Resolution 338, which signaled an implicit acceptance of Resolution 242. Resolution 242, which became the basis for the peace process negotiations begun in Madrid, calls for a just and lasting Middle East peace to include withdrawal of Israeli armed forces from territories (note: not all territories) occupied in 1967; termination of the state of belligerency; and acknowledgment of the sovereignty, territorial integrity, and political independence of all regional states and of their right to live in peace within secure and recognized boundaries.
As a result of the mediation efforts of then US Secretary of State Henry Kissinger, Syria and Israel concluded a disengagement agreement in May 1974, enabling Syria to recover territory lost in the October war and part of the Golan Heights occupied by Israel since 1967, including Quneitra. The two sides have effectively implemented the agreement, which is monitored by UN forces.
In December 1981, the Israeli Knesset voted to extend Israeli law to the part of the Golan Heights over which Israel retained control. The UN Security Council subsequently passed a resolution calling on Israel to rescind this measure. Syria participated in the Middle East Peace Conference in Madrid in October 1991. Negotiations were conducted intermittently through the 1990s, and came very close to succeeding. However, the parties were unable to come to an agreement due to President Bill Clinton's failure to consult with the Syrian President, Hafez al-Assad during the negotiating process, Israeli Prime Minister Ehud Barak's backtracking on the issue of the northeastern shore of the Sea of Galilee and Syria's nonnegotiable demand that Israel withdraw to the positions it held on 4 June 1967 (which meant Israel would relinquish its claim to territory occupied by the Syrians in the early 1950s in contravention to the 1949 Armistice Agreement—including the north-eastern shore of the Sea of Galilee). A major stumbling-block was that in response to Israel's demand that the entire Golan from the Jordan River to the outskirts of Damascus be demilitarized the Syrians demanded that Israel demilitarize all its territory to a similar distance from the new border. This was not acceptable to Israel as it would have effectively left all of northern Israel between the Jordan River and the Mediterranean Sea (more than a quarter of Israel), including the entire length of Israel's border with Lebanon, completely defenceless. The peace negotiations collapsed following the outbreak of the second Palestinian (Intifada) uprising in September 2000, though Syria continues to call for a comprehensive settlement based on UN Security Council Resolutions 242 and 338, and the land-for-peace formula adopted at the 1991 Madrid conference.
Tensions between Israel and Syria increased as the Intifada dragged on, primarily as a result of Syria's refusal to stop giving sanctuary to Palestinian militant groups conducting operations against Israel. In October 2003, following a suicide bombing carried out by a member of Palestinian Islamic Jihad in Haifa that killed 20 Israeli citizens, Israeli Defense Forces attacked a suspected Palestinian militant training camp 15 kilometers north of Damascus. This was the first such Israeli attack deep inside Syrian territory since the 1973 war. Syria announced it would respond diplomatically, and asked the UN Security Council to condemn the Israeli action.
In 2004 and 2005 Israel and Syria engaged in private talks discussing an outline peace accord. These were successful at a technical level, but failed to gain adequate political support.
Hostility between Syria and Israel further increased following Israel's execution of Operation Orchard on 6 September 2007. Israel bombed a northern Syrian complex near Dayr az-Zawr which was suspected of holding nuclear materials from North Korea.
In 2008 Syrian President Bashar al-Assad confirmed that talks with Israel have resumed through a third party.
The expatriates minister, Buthaina Shaaban has also confirmed that Israel is ready to give up the Golan Heights 
Jordan.
Jordanian interest in Syria began in 1921, when the founder of the Emirate of Transjordan, Abdallah, sought to advance into Syria, from which his brother had been expelled by the French, and which he regarded as part of the promised Hashemite kingdom. Even as late as 1946, when both countries gained independence, King Abdallah did not abandon his plan to become king of Syria. Syria considered Abdallah's schemes for an expanded Hashimite kingdom as intervention in its domestic affairs and officially complained to the Arab League.
After the first Gulf War relations between Jordan and Syria had improved. After the Treaty of Peace Between the State of Israel and the Hashemite Kingdom of Jordan in which Jordan established diplomatic ties with Israel, Jordan has been an important transit point for Syrian businessmen doing business in the Palestinian territories.
Jordan has been accepting Syrian military defectors since the Syrian civil war.
Lebanon.
Syria plays an important role in Lebanon by virtue of its history, size, power, and economy. Lebanon was part of Ottoman Syria until 1926. The presence of Syrian troops in Lebanon dates to 1976, when President Hafez Al-Assad intervened in the Lebanese civil war on behalf of Maronite Christians. Following the 1982 Israeli invasion of Lebanon, Syrian and Israeli forces clashed in eastern Lebanon. The late U.S. Ambassador Philip Habib negotiated a cease-fire in Lebanon and the subsequent evacuation of PLO fighters from West Beirut. However, Syrian opposition blocked implementation of the 17 May 1983 Lebanese-Israeli accord on the withdrawal of Israeli forces from Lebanon. Following the February 1984 withdrawal of the UN Multinational Force from Beirut and the departure of most of Israel's forces from southern Lebanon a year later, Syria launched an unsuccessful initiative to reconcile warring Lebanese factions and establish a permanent cease-fire. Syria actively participated in the March–September 1989 fighting between the Christian Lebanese Forces and Muslim forces allied with Syria. In 1989, Syria endorsed the Charter of National Reconciliation, or "Taif Accord", a comprehensive plan for ending the Lebanese conflict negotiated under the auspices of Saudi Arabia, Algeria, and Morocco.
At the request of Lebanese President Hrawi, the Syrian military took joint action with the Lebanese Armed Forces on 13 October 1990, to oust rebel Gen. Michel Aoun who had defied efforts at reconciliation with the legitimate Government of Lebanon. The process of disarming and disbanding the many Lebanese militias began in earnest in early 1991. In May 1991, Lebanon and Syria signed the treaty of brotherhood, cooperation, and coordination called for in the Taif Accord, which is intended to provide the basis for many aspects of Syrian-Lebanese relations. The treaty provides the most explicit recognition to date by the Syrian Government of Lebanon's independence and sovereignty.
According to the U.S. interpretation of the Taif Accord, Syria and Lebanon were to have decided on the redeployment of Syrian forces from Beirut and other coastal areas of Lebanon by September 1992. Israeli occupation of Lebanon until May 2000, the breakdown of peace negotiations between Syria and Israel that same year, and intensifying Arab/Israeli tensions since the start of the second Palestinian uprising in September 2000 have helped delay full implementation of the Taif Accords. The UN declared that Israel's withdrawal from southern Lebanon fulfilled the requirements of UN Security Council Resolution 425. However, Syria and Lebanon claimed that UNSCR 425 had not been fully implemented because Israel did not withdraw from an area of the Golan Heights called Shebaa Farms, which had been occupied by Israel in 1967, and which Syria now claimed was part of Lebanon. The United Nations does not recognize this claim. However, Lebanese resistance groups such as Hezbollah use it to justify attacks against Israeli forces in that region, creating a potentially dangerous flashpoint along the Lebanon-Israeli border.
In 2005, Syrian troops withdrew from Lebanon after the assassination of Lebanese Sunni Prime Minister Rafik Hariri on 14 February 2005. In December 2008, The Syrian Embassy was opened in Beirut for the first time in history since both countries gained their Independence during the 1940s. In March 2009, Lebanon followed and opened its Embassy in Damascus. On 19 December 2009, Lebanese Prime Minister Saad Al-Hariri visited Syria, and stayed in Damascus for three days meeting with President Bashar Al-Assad & breaking the ice between the two sides.
Qatar.
Qatar along with Saudi Arabia, UAE, Bahrain, and Kuwait have closed their embassies in Syria.
Saudi Arabia.
Saudi Arabia is a member of the Arab League and Syria is an ex-member. Relations between Syria and Saudi Arabia have become severed due to the Syrian Civil War and Saudi Arabia's support for the rebels and their support for the removal of Bashar al-Assad from power. The Saudi monarchy certainly hopes that a new government will emerge and that any government which emerges afterward will be more appeasing to Saudi interests. Many have criticized Saudi Arabia for its support of the Islamic State behind public eye (since both share in their practice of the extremist Islamic sect of Wahabism, and their punishment methods using beheading are identical in their ideology). further distancing itself from the Syrian government.In August 2008, Saudi Arabian ambassador was called back to Riyadh. Saudi Arabia also closed its embassy in Syria, following the Syrian Civil War.
Turkey.
Syrian–Turkish relations have long been strained even though Turkey shares its longest common border with Syria and various other geographic, cultural, and historical links tie the two neighboring states together.
This friction has been due to disputes including the self annexation of the Hatay Province to Turkey in 1939, water disputes resulting from the Southeastern Anatolia Project, and Syria’s support for the outlawed Kurdistan Worker's Party (PKK) and the Armenian Secret Army for the Liberation of Armenia (ASALA), but relations have improved greatly since October 1998; when PKK leader Abdullah Öcalan was expelled by Syrian authorities.
Syria currently maintains an embassy in Ankara and two consulates–general in Istanbul and Gaziantep. Turkey has closed its embassy in Damascus and it consulate–general in Aleppo. Both countries are full members of the Union for the Mediterranean and the Organisation of Islamic Cooperation (OIC).
Because of the Syrian civil war relations between Syria and Turkey have become increasingly tense. Turkey has been taking in refugees from Syria, although abuse and injustice towards the Syrian refugees has been reported. Relations have further been degraded due to a serious incident that occurred with the Syrian downing of a Turkish military training flight in June 2012. Relations worsened further in May 2013 following a border incident involving two car bombs exploding in the town of Reyhanlı, Hatay Province, Turkey. At least 43 people were killed and 140 more were injured in the attack. The car bombs were left outside Reyhanlı's town hall and post office. The first exploded at around 13:45 local time (10:45 GMT) and the second exploded about 15 minutes later. 
The issue that cemented the crack in the relations was Turkey's reportedly confirmed dealings with the Islamic State (an enemy of the Syrian government) in oil and weapons by various sources. A video surfacing of the Islamic State being unopposed by Turkish security as they traveled across the border between Syria, questions more of Turkey's alleged role of simply fighting terrorism. Although large allies such as the United States refuses to acknowledge these facts (because of Turkey's importance as an ally), evidence suggests that this event will not prompt relations between Turkey and Syria to improve in the future.
Turkey closed its embassy in Damascus on March 26, 2012. 
Europe.
Cyprus.
Syrian president Bashar al-Assad became the first Syrian head of state to visit Cyprus in November 2010, resulting in the signing of five agreements between the two countries and pledges to work closer together on issues of common interest. The two leaders agreed to enhance cooperation in the sectors of tourism, construction, energy, transport, education, services, and telecommunications, as well as other fields in the public and private sector.
The most important agreement signed was on coordinating search and rescue services. In addition, Cyprus and Syria signed agreements on cooperation in Telecommunications and Information Technology Services, Air Services, cultural cooperation for 2009–2011, Social Security and Agriculture. The 7th Protocol for the implementation of the agreement on Tourism Cooperation for the years 2009–2011 was also signed. The two countries also reached an agreement on technical cooperation between the Central Banks of the two countries.
After the talks, Christofias awarded al-Assad the Grand Collar of the Order of Makarios III, while the Syrian leader presented Christofias with the National Order of Ummayya with the Grand Sash.
Russia.
Russia has an embassy in Damascus and a consulate in Aleppo, and Syria has an embassy in Moscow. As with most of the Arab countries, Russia enjoys a historically strong and stable friendly relationship with Syria.
Since 1971, Russia has leased port facilities in Tartus for its naval fleet. Between 1992 and 2008 these facilities were much in disrepair, however, works have commenced concurrent with the 2008 South Ossetia war to improve the port's facilities to support an increased Mediterranean presence of the Russian Navy.
Russia is believed to have sent Syria dozens of Iskander missiles.
Russia has been supporting Syria in the Syrian civil war.
Rest of world.
China.
Diplomatic relations between both countries were established on 1 August 1956. China has an embassy in Damascus and Syria has an embassy in Beijing.
The total volume of import and export between China and Syria in 2001 was US$223,190,000, of which the Chinese export was US$223,180,000, and import US$10,000. China has helped Syria in building some projects such as textile mill and stadium. China currently has contracted to build a hydraulic power station and a rubber tire factory.
See Chinese Ministry of Foreign Affairs about the relations with Syria
India.
India and Syria has historical and cultural links dating back to silk route trade.
North Korea.
In September 2015, Syria government paid tribute to Kim Il-sung in a ceremony for a new park in Damascus named in his honor.
Pakistan.
Both countries were on the silk route through which civilizational exchanges took place for centuries, Islamic missionaries that introduced Islam after 711 AD were from Syria. During the Yom Kippur War of 1973 (usually referred to as the Ramadan war in Pakistan) several Pakistani pilots assisted the Syrian air force. In 2005 Syria and Pakistan agreed on mutual cooperation in the fields of science and technology.
South Korea.
From Syria to the Republic of Korea 1994 April Command Office Communication Ali 1994 September Minister of Information and Communication Radwan 2000 June Economic Mission of Syria 2007 October President of University of Aleppo.
United States.
While relations between the two states have long since been tense, the two have maintained diplomatic exchanges. However, relations took an ominous turn in October 2008 with a cross-border raid during the Iraq war to ostensibly fend off the rise of allegedly foreign militants into the Iraq fighting for the Iraqi resistance. , the embassy of the United States is suspended due to the Syrian civil war.
As of 21 August 2013, the United States has threatened to strike key Syrian chemical and biological weapons installations in response to a chemical attack that was carried out by forces loyal to Assad on a rebel stronghold within the capital Damascus. Assad had denied any involvement, however President Obama claims to have intelligence proving otherwise. No proof has been given to the public other than reports from key United States senators and representatives. As of 4 September 2013, the Committee on Foreign Relations approved an attack with a 10-7 vote.
Membership in international organizations.
Syria is a member of the Arab Bank for Economic Development in Africa, Arab Fund for Economic and Social Development, Arab League, Arab Monetary Fund, Council of Arab Economic Unity, Customs Cooperation Council, Economic and Social Commission for Western Asia, Food and Agricultural Organization, Group of 24, Group of 77, International Atomic Energy Agency, International Bank for Reconstruction and Development, International Civil Aviation Organization, International Chamber of Commerce, International Development Association, Islamic Development Bank, International Fund for Agricultural Development, International Finance Corporation, International Labour Organization, International Monetary Fund, International Maritime Organization, INTELSAT, INTERPOL, International Olympic Committee, International Organization for Standardization, International Telecommunication Union, League of Red Cross and Red Crescent Societies, Non-Aligned Movement, Organization of Arab Petroleum Exporting Countries, Organisation of Islamic Cooperation, UN, UN Commission on Human Rights, UN Conference on Trade and Development, UN Industrial Development Organization, UN Relief and Works Agency for Palestine Refugees in the Near East, Universal Postal Union, World Federation of Trade Unions, World Health Organization, World Meteorological Organization, and World Tourism Organization. Syria is 1 of only 7 U.N. members which is not a member of the Organization for the Prohibition of Chemical Weapons.
Syria's 2-year term as a nonpermanent member of the UN Security Council ended in December 2003.
Disputes – international:
Golan Heights with Israel; dispute with upstream riparian Turkey over Turkish water development plans for the Tigris and Euphrates rivers
Illicit drugs:
a transit point for opiates and hashish bound for regional and Western markets
Sources.
This article is adapted from the United States Department of State "Background note" on Syria, visualised December 2003, the current version of which is available at http://www.state.gov/r/pa/ei/bgn/3580.htm#foreign.

</doc>
<doc id="27481" url="https://en.wikipedia.org/wiki?curid=27481" title="Section 508 Amendment to the Rehabilitation Act of 1973">
Section 508 Amendment to the Rehabilitation Act of 1973

In 1998 the US Congress amended the Rehabilitation Act to require Federal agencies to make their electronic and information technology accessible to people with disabilities. Section 508 was enacted to eliminate barriers in information technology, to make available new opportunities for people with disabilities, and to encourage development of technologies that will help achieve these goals. The law applies to all Federal agencies when they develop, procure, maintain, or use electronic and information technology. Under Section 508 (), agencies must give disabled employees and members of the public access to information that is comparable to the access available to others.
History.
Section 508 was originally added as an amendment to the "Rehabilitation Act of 1973" in 1986. The original section 508 dealt with electronic and information technologies, in recognition of the growth of this field.
In 1997, The Federal Electronic and Information Technology Accessibility and Compliance Act was proposed in the U.S. legislature to correct the shortcomings of the original section 508; the original Section 508 had turned out to be mostly ineffective, in part due to the lack of enforcement mechanisms. In the end, this Federal Electronic and Information Technology Accessibility and Compliance Act, with revisions, was enacted as the "new" Section 508 of the Rehabilitation Act of 1973, in 1998.
Section 508 addresses legal compliance through the process of market research and government procurement and also has technical standards against which products can be evaluated to determine if they meet the technical compliance. Because technology can meet the legal provisions and be legally compliant (e.g., no such product exists at time of purchase) but may not meet the United States Access Board's technical accessibility standards, users are often confused between these two issues. Additionally, evaluation of compliance can be done only when reviewing the procurement process and documentation used when making a purchase or contracting for development, the changes in technologies and standards themselves, it requires a more detailed understanding of the law and technology than at first seems necessary.
There is nothing in section 508 that requires private web sites to comply unless they are receiving federal funds or under contract with a federal agency. Commercial best practices include voluntary standards and guidelines as the World Wide Web Consortium's (W3C) Web Accessibility Initiative (WAI). Automatic accessibility checkers (engines) such as "IBM Rational Policy Tester" and AccVerify, refer to Section 508 guidelines but have difficulty in accurately testing content for accessibility.
In 2006, the United States Access Board organized the Telecommunications and Electronic and Information Technology Advisory Committee (TEITAC) to review and recommend updates to its Section 508 standards and Telecommunications Act Accessibility Guidelines. TEITAC issued its report to the Board in April 2008. The Board released drafts of proposed rules based on the committee’s recommendations in 2010 and 2011 for public comment. In February 2015, the Board released a notice of proposed rulemaking for the Section 508 standards.
The law.
Provisions.
The original legislation mandated that the Architectural and Transportation Barriers Compliance Board, known as the Access Board, establish a draft for their Final Standards for accessibility for such electronic and information technologies in December 2001. The final standards were approved in April 2001 and became enforceable on June 25, 2001.
The latest information about these standards and about support available from the Access Board in implementing them, as well as the results of surveys conducted to assess compliance, is available from the Board's newsletter Access Currents. The Section 508 standards, tools, and resources are available from the Center for Information Technology Accommodation (CITA), in the U.S. General Services Administration's Office of Government-wide Policy.

</doc>
<doc id="27485" url="https://en.wikipedia.org/wiki?curid=27485" title="Slartibartfast">
Slartibartfast

Slartibartfast is a character in "The Hitchhiker's Guide to the Galaxy", a comedy/science fiction series created by Douglas Adams. The character appears in the first and third novels, the first and third radio series (and the LP adaptation of the first radio series), the 1981 television series and the 2005 feature film. The character was modelled after actor John Le Mesurier.
Character overview.
Slartibartfast is a Magrathean, and a designer of planets. His favourite part of the job is creating coastlines, the most notable of which are the fjords found on the coast of Norway on planet Earth, for which he won an award. While trapped on prehistoric Earth, Arthur Dent and Ford Prefect see Slartibartfast's signature deep inside a glacier in ancient Norway.
When "Earth Mk. II" is being made, Slartibartfast is assigned to the continent of Africa. He is unhappy about this because he wants to make more fjords (arguing that they give a continent a baroque feel), and fjords in Africa would be hard for him to explain without natural glacial movement.
In any event, the new Earth is not required and, much to Slartibartfast's disgust, its owners suggested that he take a quick skiing holiday on his glaciers before dismantling them.
In "Life, the Universe and Everything" Slartibartfast has joined the Campaign for Real Time (or "CamTim" as the volunteers casually refer to it, a reference to CAMRA) which tries to preserve events as they happened before time travelling was invented. He picks up Arthur and Ford from Lord's Cricket Ground with his "Starship Bistromath", after which they head out to stop the robots of Krikkit from bringing together the pieces of the Wikkit Gate.
Origin of name.
Douglas Adams writes in the notes accompanying that he wanted Slartibartfast's name to sound very rude, but still actually be broadcastable. He therefore started with the name "Phartiphukborlz", and changed bits of it until it would be acceptable to the BBC. He came closer to achieving this goal in the following episode, with the double-act Lunkwill and Fook. He adds to this statement in "", an analysis by Neil Gaiman:
Portrayals.
Slartibartfast was first portrayed in the 1978 radio serial, in which he was voiced by Richard Vernon, who also portrayed him in the 1981 live-action miniseries. Richard Griffiths voiced him in the 2004 radio series. He was portrayed by Bill Nighy in the 2005 film adaptation of the first novel.

</doc>
<doc id="27487" url="https://en.wikipedia.org/wiki?curid=27487" title="Split screen (video production)">
Split screen (video production)

In film and video production, split screen is the visible division of the screen, traditionally in half, but also in several simultaneous images, rupturing the illusion that the screen's frame is a seamless view of reality, similar to that of the human eye. There may or may not be an explicit borderline. Until the arrival of digital technology in the early 1990s, a split screen was accomplished by using an optical printer to combine two or more actions filmed separately by copying them onto the same negative, called the composite.
In filmmaking split screen is also a technique that allows one actor to appear twice in a scene. The simplest technique is to lock down the camera and shoot the scene twice, with one "version" of the actor appearing on the left side, and the other on the right side. The seam between the two splits is intended to be invisible, making the duplication seem realistic.
Popularisation.
Several studio-made films in the 1960s popularized the use of split screen. They include "Indiscreet" (1958), John Frankenheimer's "Grand Prix" (1966), Richard Fleischer's "The Boston Strangler" (1968), Norman Jewison's "The Thomas Crown Affair" (1968), "Airport" (1970), "Woodstock" (1970), "The Andromeda Strain" (1971), "Carrie" (1976) and "More American Graffiti" (1979).
In "Indiscreet" the technique was famously used to bypass the censors and allow Cary Grant and Ingrid Bergman to be in bed together, and even to appear to pat her on the bottom.
Influences.
An influential arena for the great split screen movies of the 1960s were two world's fairs - the 1964 New York World's Fair, where Ray and Charles Eames had a 17-screen film they created for IBM's "Think" Pavilion (it included sections with race car driving) and the 3-division film "To Be Alive," by Francis Thompson, which won the Academy Award that year for Best Short. John Frankenheimer made "Grand Prix" after his visit to the 1964 New York World's Fair. The success of these pavilions further influenced the 1967 Universal exhibition in Montreal, commonly referred to as Expo 67, where multi-screen highlights included "In the Labyrinth", hailed by "Time" magazine as a "stunning visual display," their review concluding: "such visual delights as Labyrinth ... suggest that cinema—the most typical of 20th century arts—has just begun to explore its boundaries and possibilities," as well as "A Place to Stand", which displayed Christopher Chapman's pioneering "multi-dynamic image technique" of shifting multiple images. Directors Norman Jewison and Richard Fleischer conceived their ambitious split-screen films of 1968 after visiting Expo '67.
It's also common to use this technique to simultaneously portray both participants in a telephone conversation, a long-standing convention which dates back to early silents, as in Lois Weber's triangular frames in her 1913 "Suspense", and culminating in "Pillow Talk", where Doris Day and Rock Hudson share a party line. So linked to this convention are the Doris Day/Rock Hudson movies that "Down With Love", the only slightly tongue-in-cheek homage, used split screen in several phone calls, explicitly parodying this use. In the 1971 Emmy Award winning TV movie "Brian's Song" which portrays the story of former Chicago Bears running backs Brian Piccolo and Hall of Famer Gale Sayers, it’s the night after Piccolo's second surgery and Piccolo (James Caan) is talking to Sayers (Billy Dee Williams) on the phone. There is a diagonal split screen from upper left corner to lower right corner (Piccolo on the right side and Sayers on the left). The BBC series "Coupling" made extensive use of split screen as one of several techniques that are unconventional for TV series, often to a humorous effect. One episode, 'Split', was even named after the use of the effect. The acclaimed Fox TV series "24" used split-screen extensively to depict the many simultaneous events, enhancing the show's real-time element as well as connecting its multiple storylines. 
An unusual and revolutionary use of split screen as an extension to the cinematic vocabulary was invented by film director Roger Avary in "The Rules of Attraction" (2002) where two separate halves of a split screen are folded together into one seamless shot through the use of motion control photography. The much acclaimed shot was examined and detailed in Bravo Television's "Anatomy of a Scene".
Digital technology.
The arrival of digital video technology has made dividing the screen much easier to accomplish, and recent digital films and music videos have explored this possibility in depth. Sometimes the technique is used to show actions occurring simultaneously; "Timecode" (2000), by Mike Figgis, is a recent example where the combination is of four real time digital video cameras shown continuously for the duration of the film. Split-screen can also be used to the extent that it becomes part of the narrative structure of a film, as in "The Boston Strangler".
Usage.
In films.
This technique has been used to portray twins in such films as "Wonder Man" (1945), "The Dark Mirror" (1946), "The Parent Trap" (both the 1961 original and the 1998 remake), and "Adaptation" (2002). In the 1961 version of "The Parent Trap", conversations between the twins were simulated by filming the actress (Hayley Mills) as she stood at the left of the frame facing right, then filming her again, standing at the right and facing left. The negative of the first action was placed into a printer and copied onto another negative, the composite, but this other negative was masked so that only the right part of the original picture is copied. Then the composite was rewound and the negative of the second action was copied onto the right side of each frame. On this second pass, the left side was masked to prevent double exposure. This technique is then carefully hidden by background lines, such as windows, doors, etc. to disguise the split.
Hans Canosa's 2005 film "Conversations with Other Women" made extensive use of split screens. "Conversations" juxtaposed shot and reverse shot of two actors in the same take, captured with two cameras, for the entire movie. The film was designed to enlist the audience as perceptual editors, as they can choose to watch either character act and react in real time. While the shot/reverse shot function of split screen comprises most of the running time of the film, the filmmakers also used split screen for other spatial, temporal and emotional effects. "Conversations"' split screen sometimes showed flashbacks of the recent or distant past juxtaposed with the present; moments imagined or hoped by the characters juxtaposed with present reality; present experience fractured into more than one emotion for a given line or action, showing an actor performing the same moment in different ways; and present and near future actions juxtaposed to accelerate the narrative in temporal overlap.
By filmmakers.
The visionary French director, Abel Gance, used the term "Polyvision" to describe his three-camera, three-projector technique for both widening and dividing the screen in his 1927 silent epic, "Napoléon". The filmmaker Brian De Palma has incorporated split screens into many of his films, most notably in "Sisters" (1973) and they have since become synonymous with his filmmaking style (Specifically 1981's "Blow Out" and 1998's "Snake Eyes").
In technology.
The "Interactive Olaf" bonus feature from the DVD release of "Lemony Snicket's A Series of Unfortunate Events" shows Jim Carrey's makeup tests from the movie in a four-way split-screen. Viewers can split the audio by selecting which one to listen to, then pressing "ENTER" on their DVD remote. The split screen has also been simulated in video games. Most notably "Fahrenheit" where it is used to allow a player to keep track of multiple simultaneous elements relevant to the gameplay.
In music video.
A number of music videos have made creative use of split screen presentations. In Michael Jackson's "Billie Jean" video a number of freeze frames are shown in split screen. Video and film director Michel Gondry has made extensive use of split screen techniques in his videos. One notable example is "Sugar Water" - Cibo Matto (1996), where one side of the screen shows the video played normally, and the other side shows the same video played backwards. Through careful and creative staging the two sides appear to interact directly - passing objects from side to side and visually referencing each other. The music video for "Doo Wop (That Thing)" by Lauryn Hill was filmed using a split screen technique, the video features Hill, performing the song at block parties in two different eras: the mid-1960s (shown on the left of the video) and the late-1990s (shown on the right).
In television.
The split screen has also been used extensively in television programs. Newscasts often show two reporters in a split screen frame. The sitcom "That '70s Show", USA Network's Burn Notice, and Fox's 24 made extensive use of split screens. It is sometimes used in game shows to show two contestants simultaneously, and on cable news shows, when participants in a discussion are in different locations.
Split screens are frequently used in motor racing, especially during safety car pit stops in the IndyCar Series and NASCAR, where four way splits are used, most often with three leading cars or trucks' pit stops shown on the left and a shot of the pit exit (where restart order is determined after pit stops) on the right, with some featuring just four different cars or trucks making pit stops. Often these pit stops can change the entire outcome of a race. In sports, an instant replay, highlights package, or featurette on a specific subject relating to the play may be shown in a corner while the main play is happening.
Also, split screens are used during commercial breaks (ESPN calls this Side-By-Side), where one side of the screen shows race footage and the other shows advertising. This allows commercial breaks at the same time as viewers watch all the race action.
Split screens are also common in advertising, often to show comparison.

</doc>
<doc id="27488" url="https://en.wikipedia.org/wiki?curid=27488" title="Software documentation">
Software documentation

Software documentation is written text or illustration that accompanies computer software. It either explains how it operates or how to use it, and may mean different things to people in different roles.
Documentation is an important part of software engineering. Types of documentation include:
Requirements documentation.
Requirements documentation is the description of what a particular software does or shall do. It is used throughout development to communicate what the software does or how it is intended to operate. It is also used as an agreement or as the foundation for agreement on what the software will do. Requirements are produced and consumed by everyone involved in the production of software: end users, customers, product managers, project managers, sales, marketing, software architects, usability engineers, interaction designers, developers, and testers, to name a few. Thus, requirements documentation has many different purposes.
Requirements come in a variety of styles, notations and formality. Requirements can be goal-like (e.g., "distributed work environment"), close to design (e.g., "builds can be started by right-clicking a configuration file and select the 'build' function"), and anything in between. They can be specified as statements in natural language, as drawn figures, as detailed mathematical formulas, and as a combination of them all.
The variation and complexity of requirements documentation makes it a proven challenge. Requirements may be implicit and hard to uncover. It is difficult to know exactly how much and what kind of documentation is needed and how much can be left to the architecture and design documentation, and it is difficult to know how to document requirements considering the variety of people who shall read and use the documentation. Thus, requirements documentation is often incomplete (or non-existent). Without proper requirements documentation, software changes become more difficult — and therefore more error prone (decreased software quality) and time-consuming (expensive).
The need for requirements documentation is typically related to the complexity of the product, the impact of the product, and the life expectancy of the software. If the software is very complex or developed by many people (e.g., mobile phone software), requirements can help to better communicate what to achieve. If the software is safety-critical and can have negative impact on human life (e.g., nuclear power systems, medical equipment), more formal requirements documentation is often required. If the software is expected to live for only a month or two (e.g., very small mobile phone applications developed specifically for a certain campaign) very little requirements documentation may be needed. If the software is a first release that is later built upon, requirements documentation is very helpful when managing the change of the software and verifying that nothing has been broken in the software when it is modified.
Traditionally, requirements are specified in requirements documents (e.g. using word processing applications and spreadsheet applications). To manage the increased complexity and changing nature of requirements documentation (and software documentation in general), database-centric systems and special-purpose requirements management tools are advocated.
Architecture/Design documentation.
Architecture documentation (also known as software architecture description) is a special breed of design document. In a way, architecture documents are third derivative from the code (design document being second derivative, and code documents being first). Very little in the architecture documents is specific to the code itself. These documents do not describe how to program a particular routine, or even why that particular routine exists in the form that it does, but instead merely lays out the general requirements that would motivate the existence of such a routine. A good architecture document is short on details but thick on explanation. It may suggest approaches for lower level design, but leave the actual exploration trade studies to other documents.
Another breed of design docs is the comparison document, or trade study. This would often take the form of a "whitepaper". It focuses on one specific aspect of the system and suggests alternate approaches. It could be at the user interface, code, design, or even architectural level. It will outline what the situation is, describe one or more alternatives, and enumerate the pros and cons of each. A good trade study document is heavy on research, expresses its idea clearly (without relying heavily on obtuse jargon to dazzle the reader), and most importantly is impartial. It should honestly and clearly explain the costs of whatever solution it offers as best. The objective of a trade study is to devise the best solution, rather than to push a particular point of view. It is perfectly acceptable to state no conclusion, or to conclude that none of the alternatives are sufficiently better than the baseline to warrant a change. It should be approached as a scientific endeavor, not as a marketing technique.
A very important part of the design document in enterprise software development is the Database Design Document (DDD). It contains Conceptual, Logical, and Physical Design Elements. The DDD includes the formal information that the people who interact with the database need. The purpose of preparing it is to create a common source to be used by all players within the scene. The potential users are:
When talking about Relational Database Systems, the document should include following parts:
It is very important to include all information that is to be used by all actors in the scene. It is also very important to update the documents as any change occurs in the database as well.
Technical documentation.
It is important for the code documents associated with the source code (which may include README files and API documentation) to be thorough, but not so verbose that it becomes overly time-consuming or difficult to maintain them. Various how-to and overview documentation guides are commonly found specific to the software application or software product being documented by API writers. This documentation may be used by developers, testers, and also the end-users using the software application. Today, a lot of high-end applications in the field of power, energy, transportation, networks, aerospace, safety, security, industry automation and a variety of other domains are seen. Technical documentation has become important within such organizations as the basic and advanced level of information may change over a period of time with architecture changes.
Code documents are often organized into a "reference guide" style, allowing a programmer to quickly look up an arbitrary function or class.
Technical documentation embedded in source code.
Often, tools such as Doxygen, NDoc, javadoc, EiffelStudio, Sandcastle, ROBODoc, POD, TwinText, or Universal Report can be used to auto-generate the code documents—that is, they extract the comments and software contracts, where available, from the source code and create reference manuals in such forms as text or HTML files.
The idea of auto-generating documentation is attractive to programmers for various reasons. For example, because it is extracted from the source code itself (for example, through comments), the programmer can write it while referring to the code, and use the same tools used to create the source code to make the documentation. This makes it much easier to keep the documentation up-to-date.
Of course, a downside is that only programmers can edit this kind of documentation, and it depends on them to refresh the output (for example, by running a cron job to update the documents nightly). Some would characterize this as a pro rather than a con.
Literate programming.
Respected computer scientist Donald Knuth has noted that documentation can be a very difficult afterthought process and has advocated literate programming, written at the same time and location as the source code and extracted by automatic means. The programming languages Haskell and CoffeeScript have built-in support for a simple form of literate programming, but this support is not widely used.
Elucidative programming.
Elucidative Programming is the result of practical applications of Literate Programming in real programming contexts. The Elucidative paradigm proposes that source code and documentation be stored separately. This paradigm was inspired by the same experimental findings that produced Kelp.
Often, software developers need to be able to create and access information that is not going to be part of the source file itself. Such annotations are usually part of several software development activities, such as code walks and porting, where third party source code is analysed in a functional way. Annotations can therefore help the developer during any stage of software development where a formal documentation system would hinder progress. Kelp stores annotations in separate files, linking the information to the source code dynamically.
User documentation.
Unlike code documents, user documents simply describe how a program is used.
In the case of a software library, the code documents and user documents could in some cases be effectively equivalent and worth conjoining, but for a general application this is not often true.
Typically, the user documentation describes each feature of the program, and assists the user in realizing these features. A good user document can also go so far as to provide thorough troubleshooting assistance. It is very important for user documents to not be confusing, and for them to be up to date. User documents need not be organized in any particular way, but it is very important for them to have a thorough index. Consistency and simplicity are also very valuable. User documentation is considered to constitute a contract specifying what the software will do. API Writers are very well accomplished towards writing good user documents as they would be well aware of the software architecture and programming techniques used. See also technical writing.
User documentation can be produced in a variety of online and print formats. However, there are three broad ways in which user documentation can be organized. 
A common complaint among users regarding software documentation is that only one of these three approaches was taken to the near-exclusion of the other two. It is common to limit provided software documentation for personal computers to online help that give only reference information on commands or menu items. The job of tutoring new users or helping more experienced users get the most out of a program is left to private publishers, who are often given significant assistance by the software developer.
Composing user documentation.
Like other forms of technical documentation, good user documentation benefits from an organized process of development. In the case of user documentation, the process as it commonly occurs in industry consists of five steps:
1. User analysis, the basic research phase of the process.<br>
2. Planning, or the actual documentation phase.<br>
3. Draft review, a self-explanatory phase where feedback is sought on the draft composed in the previous step.<br>
4. Usability testing, whereby the usability of the document is tested empirically.<br>
5. Editing, the final step in which the information collected in steps three and four is used to produce the final draft.
Documentation and agile development controversy.
"The resistance to documentation among developers is well known and needs no emphasis." 
This situation is particularly ambivalent in agile software development because these methodologies try to avoid any unnecessary activities that do not directly bring value.
Specifically, the Agile Manifesto advocates valuing "working software over comprehensive documentation", which could be interpreted cynically as "We want to spend all our time coding. Remember, real programmers don't write documentation."
A survey among software engineering experts revealed, however, that documentation is by no means considered unnecessary in agile development.
Yet it is acknowledged that there are motivational problems in development, and that documentation methods tailored to agile development (e.g. through Reputation systems and Gamification) may be needed.
Marketing documentation.
For many applications it is necessary to have some promotional materials to encourage casual observers to spend more time learning about the product. This form of documentation has three purposes:-

</doc>
<doc id="27490" url="https://en.wikipedia.org/wiki?curid=27490" title="Sense and Sensibility">
Sense and Sensibility

Sense and Sensibility is a novel by Jane Austen, and was her first published work when it appeared in 1811 under the pseudonym "A Lady". A work of romantic fiction, better known as a comedy of manners, "Sense and Sensibility" is set in southwest England, London and Kent between 1792 and 1797, and portrays the life and loves of the Dashwood sisters, Elinor and Marianne. The novel follows the young ladies to their new home, a meagre cottage on a distant relative's property, where they experience love, romance and heartbreak.
Title.
Jane Austen wrote the first draft of the novel in the form of a novel-in-letters (epistolary form) sometime around 1795 when she was about 19 years old, and gave it the title "Elinor and Marianne". She later changed the form to a narrative and the title to "Sense and Sensibility". "Sense" in the book means good judgment or prudence, and "sensibility" means sensitivity or emotionality. "Sense" is identified with the character of Elinor, while "sensibility" is identified with the character of Marianne. By changing the title, Austen added "philosophical depth" to what began as a sketch of two characters. The title of the book, and that of her next published novel, "Pride and Prejudice" (1813), may be suggestive of political conflicts of the 1790s.
Source texts.
Austen also drew inspiration for "Sense and Sensibility" from other novels of the 1790s that treated similar themes, including Adam Stevenson's "Life and Love" (1785) Which he had written about himself and a relationship that wasn't meant to be, Also Jane West's, "A Gossip's Story" (1796), which features two sisters, one full of rational sense and the other of romantic, emotive sensibility. West’s romantic sister-heroine shares a first name with Austen’s: Marianne. There are further textual similarities, described in a modern edition of West's novel. 
Critical views.
Austen biographer Claire Tomalin argues that "Sense and Sensibility" has a "wobble in its approach", which developed because Austen, in the course of writing the novel, gradually became less certain about whether sense or sensibility should triumph. Austen characterises Marianne as a sweet lady with attractive qualities: intelligence, musical talent, frankness, and the capacity to love deeply. She also acknowledges that Willoughby, with all his faults, continues to love and, in some measure, appreciate Marianne. For these reasons, some readers find Marianne's ultimate marriage to Colonel Brandon an unsatisfactory ending.
Other interpretations, however, have argued that Austen's intention was not to debate the superior value of either sense or sensibility in good judgment, but rather to demonstrate that both are equally important but must be applied with good balance to one another.
Plot.
Dashwood extracts a promise from his son, that he will take care of his half-sisters; however, John's selfish and greedy wife, Fanny, soon persuades him to renege. John and Fanny immediately take up their place as the new owners of Norland, while the Dashwood women are reduced to the position of unwelcome guests. Mrs. Dashwood begins looking for somewhere else to live.
In the meantime, Fanny's brother, Edward Ferrars, a pleasant, unassuming, intelligent but reserved young man, visits Norland and soon forms an attachment with Elinor. Fanny disapproves the match and offends Mrs. Dashwood with the implication that Elinor is motivated by money rather than love. Mrs. Dashwood indignantly speeds her search for a new home.
Mrs. Dashwood moves her family to Barton Cottage in Devonshire, near the home of her cousin, Sir John Middleton. Their new home lacks many of the conveniences that they have been used to; however, they are warmly received by Sir John, and welcomed into the local society—meeting his wife, Lady Middleton, his mother-in-law, Mrs. Jennings and his friend, the grave, quiet and gentlemanly Colonel Brandon. It soon becomes apparent that Colonel Brandon is attracted to Marianne, and Mrs. Jennings teases them about it. Marianne is not pleased as she considers the thirty-five-year-old Colonel Brandon an old bachelor, incapable of falling in love or inspiring love in anyone else.
Marianne, out for a walk, gets caught in the rain, slips and sprains her ankle. The dashing, handsome John Willoughby sees the accident and assists her. Marianne quickly comes to admire his good looks and outspoken views on poetry, music, art and love. Mr. Willoughby's attentions are so overt that Elinor and Mrs. Dashwood begin to suspect that the couple are secretly engaged. Elinor cautions Marianne against her unguarded conduct, but Marianne refuses to check her emotions, believing that it is a falsehood. Unexpectedly one day, Mr. Willoughby informs the Dashwoods that his aunt is sending him to London on business, indefinitely. Marianne is distraught and abandons herself to her sorrow.
Edward Ferrars then pays a short visit to Barton Cottage but seems unhappy and out of sorts. Elinor fears that he no longer has feelings for her, but feels compelled, by a sense of duty, to protect her family from knowing her heartache. Soon after Edward departs, Anne and Lucy Steele, the vulgar and uneducated cousins of Lady Middleton, come to stay at Barton Park. Lucy informs Elinor of her secret four-year engagement to Edward Ferrars, displaying proofs of her veracity. Elinor comes to understand the inconsistencies of Edward's behaviour to her and acquits him of blame. She is charitable enough to pity Edward for being held to a loveless engagement by his gentlemanly honour.
As winter approaches, Elinor and Marianne accompany Mrs. Jennings to London. On arriving, Marianne rashly writes a series of personal letters to Willoughby, which go unanswered. When they finally meet, Mr. Willoughby greets Marianne reluctantly and coldly, to her extreme distress. Soon Marianne receives a curt letter enclosing their former correspondence and love tokens, including a lock of her hair and informing her of his engagement to a young lady of large fortune. Marianne is devastated, and admits to Elinor that she and Willoughby were never engaged, but she loved him and he led her to believe he loved her. In sympathy for Marianne, and to illuminate Willoughby's true character, Colonel Brandon reveals to Elinor that Willoughby had seduced Brandon's fifteen-year-old ward, Miss Williams, then abandoned her when she became pregnant. Brandon had been in love with her mother, who was his father's ward and forced into an unhappy marriage to his brother; Marianne strongly reminds him of her.
In the meantime, the Steele sisters have come to London as guests of John and Fanny Dashwood. Lucy sees her invitation to the Dashwoods' as a personal compliment, rather than what it is, a slight to Elinor. In the false confidence of their popularity, Anne Steele betrays Lucy's secret. As a result, the Misses Steele are turned out of the house, and Edward is entreated to break the engagement on pain of disinheritance. Edward, honourably, refuses to comply and is immediately disinherited in favour of his brother, gaining widespread respect for his gentlemanly conduct, and sympathy from Elinor and Marianne who understand how much he has sacrificed. Colonel Brandon shows this admiration by offering him the living of Delaford parsonage.
Mrs. Jennings takes Elinor and Marianne to the country to visit her second daughter who has just given birth to her first child. In her misery over Willoughby's marriage, Marianne neglects her health and becomes dangerously ill. Traumatised by rumours of her impending death, Willoughby arrives to repent and reveals to Elinor that his love for Marianne was genuine. When his aunt learned of his behaviour towards Miss Williams and disinherited him, he felt he had to marry for money rather than love. But he elicits Elinor's pity because his choice has made him unhappy.
When Marianne recovers, Elinor tells her of Willoughby's visit. Marianne comes to assess what has passed with sense rather than emotion, and sees that she could never have been happy with Willoughby's immoral and expansive nature. She comes to value Elinor's conduct in a similar situation and resolves to model herself after Elinor's courage and good sense.
On learning that Lucy has married Mr. Ferrars, Elinor grieves, until Edward arrives and reveals that, after his disinheritance, Lucy jilted him in favour of his now wealthy brother, Robert Ferrars. Edward and Elinor soon marry, and in a very few years Marianne marries Colonel Brandon, having gradually fallen deeply in love with him.
Publication.
In 1811, Thomas Egerton of the Military Library publishing house in London accepted the manuscript for publication in three volumes. Austen paid to have the book published and paid the publisher a commission on sales. The cost of publication was more than a third of Austen's annual household income of £460 (about £15,000 in 2008 currency). She made a profit of £140 (almost £5,000 in 2008 currency) on the first edition, which sold all 750 printed copies by July 1813. A second edition was advertised in October 1813.
Adaptations.
The book has been adapted for film and television a number of times, including a 1981 serial for TV directed by Rodney Bennett; a 1995 movie adapted by Emma Thompson and directed by Ang Lee; a version in Tamil called "Kandukondain Kandukondain", released in 2000, starring Aishwarya Rai Bachchan; and a 2008 TV series on BBC adapted by Andrew Davies and directed by John Alexander.
"Sense & Sensibility, the Musical" (book and lyrics by Jeffrey Haddow and music by Neal Hampton) received its world premiere by the Denver Center Theatre Company in April 2013 staged by Tony-nominated director Marcia Milgrom Dodge. In 2014, the Utah Shakespeare Festival presented Joseph Hanreddy and J.R. Sullivan's adaptation of the novel. In 2016, the Bedlam theatrical troupe mounted a well-received minimalist production, adapted by Kate Hamill and directed by Eric Tucker, from a repertory run in 2014.
In 2013, author Joanna Trollope published her own version of the story, bringing the characters into the present day and providing modern satire.

</doc>
<doc id="27491" url="https://en.wikipedia.org/wiki?curid=27491" title="Sanity">
Sanity

Sanity (from ) refers to the soundness, rationality and healthiness of the human mind, as opposed to insanity. A person is not considered sane anymore just if he/she is irrational. In modern society, the terms have become exclusively synonymous with compos mentis (), in contrast with "non compos mentis", or insane, meaning troubled conscience. A sane mind is nowadays considered healthy both from its analytical -once called "rational"- and emotional aspects. Furthermore, according to Chesterton, sanity involves wholeness, whereas insanity implies narrowness and brokenness.
Psychiatry and psychology.
A theory of sanity was proposed by Alfred Korzybski in his general semantics. He believed sanity was tied to the structural fit or lack of thereof, of what is actually going on in the world. He imposed this notion in a map-territory analogy: "A map "is not" the territory it represents, but, if correct, it has a "similar structure" to the territory, which accounts for its usefulness." Given that science continually seeks to adjust its theories structurally to fit the facts, i.e., adjusts its maps to fit the territory, and thus advances more rapidly than any other field, he believed that the key to understanding sanity would be found in the study of the methods of science (and the study of structure as revealed by science). The adoption of a scientific outlook and attitude of continual adjustment by the individual toward his or her assumptions was the way, so he claimed. In other words, there were "factors of sanity to be found in the physico-mathematical methods of science." And he also stressed that sanity requires the awareness that "whatever you say a thing is, it is not" because anything expressed through language is not the reality it refers to: language is like a map and the map is not the territory. The territory, that is, reality, remains unnamable, un-speakable, mysterious. Hence, the widespread assumption that we can grasp reality through language involves a degree of insanity.
Psychiatrist Philip S. Graven suggested the term "un-sane" to describe a condition that is not exactly "insane", but not quite "sane" either.
In "The Sane Society", published in 1955, psychologist Erich Fromm proposed that, not just individuals, but entire societies "may be lacking in sanity". Fromm argued that one of the most deceptive features of social life involves "consensual validation.":
It is naively assumed that the fact that the majority of people share certain ideas or feelings proves the validity of these ideas and feelings. Nothing is further from the truth... Just as there is a "folie à deux" there is a "folie à millions". The fact that millions of people share the same vices does not make these vices virtues, the fact that they share so many errors does not make the errors to be truths, and the fact that millions of people share the same form of mental pathology does not make these people sane.
Law.
In criminal and mental health law, sanity is a legal term denoting that an individual is of sound mind and therefore can bear legal responsibility for their actions. The official legal term is "compos mentis". It is generally defined in terms of the absence of sanity ("non compos mentis"). It is not a medical term, although the opinions of medical experts are often important in making a legal decision as to whether someone is sane or insane. It is also not the same concept as mental illness. One can be acting under profound mental illness and yet be sane, and one can also be ruled insane without an underlying mental illness.
Legal definitions of sanity have been little explored by science and medicine, as the concentration has been on illness. It remains completely impossible to prove sanity. Furthermore, as Korzybski has pointed out repeatedly, insanity to various degrees is widespread in the general population, which includes many people that are considered mentally fit in medical and laval terms. In this connection Erich Fromm referred to the "pathology of normalcy."

</doc>
<doc id="27495" url="https://en.wikipedia.org/wiki?curid=27495" title="Slavic">
Slavic

Slav, Slavic or Slavonic may refer to:

</doc>
<doc id="27529" url="https://en.wikipedia.org/wiki?curid=27529" title="September">
September

September is the ninth month of the year in the Julian and Gregorian Calendars and one of four months with a length of 30 days.
September in the Northern Hemisphere is the seasonal equivalent of March in the Southern Hemisphere.
In the Northern hemisphere, the beginning of the meteorological autumn is on 1 September. In the Southern hemisphere, the beginning of the meteorological spring is on 1 September.
September (from Latin "septem", "seven") was originally the seventh of ten months on the oldest known Roman calendar, with March (Latin "Martius") the first month of the year until perhaps as late as 153 BC. After the calendar reform that added January and February to the beginning of the year, September became the ninth month, but retained its name. It had 29 days until the Julian reform, which added a day.
September marks the beginning of the ecclesiastical year in the Eastern Orthodox Church.
It is the start of the academic year in many countries, in which children go back to school after the summer break, sometimes on the first day of the month.
The autumnal equinox in the northern hemisphere and the vernal or spring equinox in the southern hemisphere occur on dates varying from 21 September to 24 September (in UTC). In the pagan wheel of the year the spring equinox is the time of Ostara and is celebrated on the first Sunday of September.
September is mostly in the sixth month of the astrological calendar (and the first part of the seventh), which begins at the end of March/Mars/Aries.

</doc>
<doc id="27530" url="https://en.wikipedia.org/wiki?curid=27530" title="September 1">
September 1


</doc>
<doc id="27531" url="https://en.wikipedia.org/wiki?curid=27531" title="September 2">
September 2


</doc>
<doc id="27532" url="https://en.wikipedia.org/wiki?curid=27532" title="September 21">
September 21


</doc>
<doc id="27533" url="https://en.wikipedia.org/wiki?curid=27533" title="September 28">
September 28


</doc>
<doc id="27541" url="https://en.wikipedia.org/wiki?curid=27541" title="Sprouts (game)">
Sprouts (game)

Sprouts is a pencil-and-paper game with significant mathematical properties. It was invented by mathematicians John Horton Conway and Michael S. Paterson at Cambridge University in the early 1960s.
Rules.
The game is played by two players, starting with a few spots drawn on a sheet of paper. Players take turns, where each turn consists of drawing a line between two spots (or from a spot to itself) and adding a new spot somewhere along the line. The players are constrained by the following rules.
In so-called "normal play", the player who makes the last move wins. In "misère play", the player who makes the last move loses. (Misère Sprouts is perhaps the only misère combinatorial game that is played competitively in an organized forum.) 
The diagram on the right shows a 2-spot game of normal-play Sprouts. After the fourth move, most of the spots are "dead"–they have three lines attached to them, so they cannot be used as endpoints for a new line. There are two spots (shown in green) that are still "alive", having fewer than three lines attached. However, it is impossible to make another move, because a line from a live spot to itself would make four attachments, and a line from one live spot to the other would cross lines. Therefore, no fifth move is possible, and the first player loses. Live spots at the end of the game are called "survivors" and play a key role in the analysis of Sprouts.
Number of moves.
It is not evident from the rules of Sprouts that the game always terminates, since the number of spots increase at each move. The correct approach is to consider the number of "lives" (opportunities to connect a line) instead of the number of spots. Then, we can show that if the game starts with "n" spots, it will end in no more than 3"n"−1 moves and no fewer than 2"n" moves.
In the following proofs, we suppose that a game starts with "n" spots and lasts for exactly "m" moves.
Maximum number of moves.
Each spot starts with three "lives" and each move reduces the total number of lives in the game by one (two lives are lost at the ends of the line, but the new spot has one life). So at the end of the game there are 3"n"−"m" remaining lives. Each surviving spot has only one life (otherwise there would be another move joining that spot to itself), so there are exactly 3"n"−"m" survivors. There must be at least one survivor, namely the spot added in the final move. So 3"n"−"m" ≥ 1; hence a game can last no more than 3"n"−1 moves.
This upper bound is actually the maximum, and it can be attained in many ways by ensuring that there is only one survivor at the end of the game. For instance, the game on the right has one survivor and 3"n"−1 moves.
Minimum number of moves.
At the end of the game each survivor has exactly two dead "neighbors", in a technical sense of "neighbor", "different from the ordinary graph notion of adjacency"; see the diagram on the right. No dead spot can be the neighbor of two different survivors, for otherwise there would be a move joining the survivors. All other dead spots (not neighbors of a survivor) are called "pharisees" (from the Hebrew for "separated ones"). Suppose there are "p" pharisees. Then
since initial spots + moves = total spots at end of game = survivors + neighbors + pharisees. Rearranging gives:
So a game lasts for at least 2"n" moves, and the number of pharisees is divisible by 4.
This lower bound on the length of a game is actually the minimum. The diagram on the right shows a completed game of 2"n" moves. It has "n" survivors, 2"n" neighbors and 0 pharisees.
Importance in real games.
Real games seem to turn into a battle over whether the number of moves will be "k" or "k"+1 (for some "k", depending on the early moves in the game) with other possibilities being quite unlikely. One player tries to create enclosed regions containing survivors (thus reducing the total number of moves that will be played) and the other tries to create pharisees (thus increasing the number of moves that will be played).
Winning strategies.
Since Sprouts is a finite game where no draw is possible, a perfect strategy exists either for the first or the second player, depending on the number of initial spots. The main question about a given starting position is then to determine which player can force a win if he plays perfectly.
When the winning strategy is for the first player, it is said that the "outcome" of the position is a "win", and when the winning strategy is for the second player, it is said that the outcome of the position is a "loss" (because it is a loss from the point of view of the first player).
The outcome is determined by developing the game tree of the starting position. This can be done by hand only for a small number of spots, and all the new results since 1990 have been obtained by extensive search with computers.
Normal version.
Winning Ways for your Mathematical Plays reports that the 6-spot normal game was proved to be a win for the second player by Denis Mollison, with a hand-made analysis of 47 pages. It stood as the record for a long time, until the first computer analysis, which was done at Carnegie Mellon University, in 1990, by David Applegate, Guy Jacobson, and Daniel Sleator. They reached up to 11 spots with some of the best hardware available at the time.
Applegate, Jacobson and Sleator observed a pattern in their results, and conjectured that the first player has a winning strategy when the number of spots divided by six leaves a remainder of three, four, or five. This is a mathematical way of saying that the pattern displayed by the outcome in the table below repeats itself indefinitely, with a period of six spots.
In 2001, Riccardo Focardi and Flamina Luccio described a method to prove by hand that the normal 7-spot game is a Loss.
Then, the computation results were extended in 2006 by Josh Jordan up to 14 spots. In 2007, Julien Lemoine and Simon Viennot introduced an algorithm based on the concept of nimbers to accelerate the computation, reaching up to 32 spots. They have extended the computation up to 44 spots in 2011, and three isolated starting positions, with 46, 47 and 53 spots.
The normal-play results so far are all consistent with the conjecture of Applegate, Jacobson and Sleator.
Misère version.
The computation history of the misère version of Sprouts is very similar to that of the normal version, with the same people involved. However, the misère version is more difficult to compute, and progress has been significantly slower.
In 1990, Applegate, Jacobson and Sleator reached up to nine spots. Based on their results, they conjectured that the outcome follows a regular pattern of period five. However, this conjecture was invalidated in 2007 when Josh Jordan and Roman Khorkov extended the misère analysis up to 12 spots : the 12-spot misère game is a win, and not the conjectured loss. The same team reached up to 16 spots in 2009. The same year, Julien Lemoine and Simon Viennot reached 17 spots with complicated algorithms. They were able to extend their analysis up to 20 points in 2011.
The results for misère play are now conjectured to follow a pattern of length six (with some exceptional values): the first player wins in misère Sprouts when the remainder (mod 6) is zero, four, or five, except that the first player wins the one-spot game and loses the four-spot game. The table below shows the pattern, with the two irregular values in bold.
Brussels Sprouts.
A variant of the game, called Brussels Sprouts after the vegetable, starts with a number of crosses, i.e. spots with four free ends. Each move involves joining two free ends with a curve (again not crossing any existing line) and then putting a short stroke across the line to create two new free ends. This game is finite, and the total number of moves is predetermined by the initial number of crosses: the players cannot affect the result by their play.
Each move removes two free ends and introduces two more. With "n" initial crosses, the number of moves will be 5"n"−2, so a game starting with an odd number of crosses will be a first player win, while a game starting with an even number will be a second player win regardless of the moves.
To prove this (assuming that the game ends), let m denote the number of moves and v,e,f denote the number of vertices, edges, and faces of the planar graph obtained at the end of the game, respectively. We have:
The Euler characteristic for planar graphs is 2, so 2 = f-e+v = 4n-2m+n+m = 5n-m, hence m = 5n-2.
References.
Bibliography

</doc>
<doc id="27546" url="https://en.wikipedia.org/wiki?curid=27546" title="Sexual intercourse">
Sexual intercourse

Sexual intercourse, or coitus or copulation, is principally the insertion and thrusting of the penis, usually when erect, into the vagina for sexual pleasure, reproduction, or both. This is also known as vaginal intercourse or vaginal sex. Other forms of penetrative sexual intercourse include anal sex (penetration of the anus by the penis), oral sex (penetration of the mouth by the penis or oral penetration of the female genitalia), fingering (sexual penetration by the fingers), and penetration by use of a dildo (especially a strap-on dildo). These activities involve physical intimacy between two or more individuals and are usually used among humans solely for physical or emotional pleasure and commonly contribute to human bonding.
A variety of views concern what constitutes sexual intercourse or other sexual activity, which can also impact views on sexual health. Although the term "sexual intercourse", particularly the variant "coitus," generally denotes penile-vaginal penetration and the possibility of creating offspring, it also commonly denotes penetrative oral sex and penile-anal sex, particularly the latter. It is usually defined by sexual penetration, while non-penetrative sex acts, such as non-penetrative forms of cunnilingus or mutual masturbation, have been termed "outercourse". Non-penetrative sex acts, however, may additionally be considered sexual intercourse. The term "sex", often a shorthand for "sexual intercourse", can mean any form of sexual activity. Because people can be at risk of contracting sexually transmitted infections during sexual activities, though the transmission risk is significantly reduced during non-penetrative sex, safe sex practices are advised.
Various jurisdictions have placed restrictive laws against certain sexual acts, such as incest, sexual activity with minors, prostitution, rape and zoophilia, as well as sodomy, premarital and extramarital sex. Religious beliefs also play a role in personal decisions about sexual intercourse or other sexual activity, such as decisions about virginity, or legal and public policy matters. Religious views on sexuality vary significantly between different religions and sects of the same religion, though there are common themes, such as prohibition of adultery.
Reproductive sexual intercourse between non-human animals is more often termed "copulation", and sperm may be introduced into the female's reproductive tract in non-vaginal ways among the animals, such as by cloacal copulation. For most non-human mammals, mating and copulation occur at the point of estrus (the most fertile period of time in the female's reproductive cycle), which increases the chances of successful impregnation. However, bonobos, dolphins and chimpanzees are known to engage in sexual intercourse regardless of whether or not the female is in estrus, and to engage in sex acts with same-sex partners. Like humans engaging in sexual activity primarily for pleasure, this behavior in the aforementioned animals is also presumed to be for pleasure, and a contributing factor to strengthening their social bonds.
Behaviors.
Definitions.
"Sexual intercourse" may be defined by different words, including "coitus," "copulation", "coition" or "intercourse" (which is typically shorthand for "sexual intercourse"). The term "coitus" is derived from the Latin word "coitio" or "coire", meaning "a coming together or joining together" or "to go together", and it describes a variety of sexual activities under ancient Latin names, but usually refers exclusively to penile-vaginal penetration. This is often termed "vaginal intercourse" or "vaginal sex." The term "vaginal sex," and less often "vaginal intercourse", may also refer to any vaginal sexual activity, particularly if penetrative, including sexual activity between lesbian couples. "Copulation", by contrast, most often means the mating process of non-human animals; it is generally defined as the sexually reproductive act of transferring sperm from a male to a female or sexual procreation between a man and a woman, but can denote any sexual activity between opposite-sex or same-sex pairings.
Although the prevalent usages of the terms "sexual intercourse" and "sex" denote penile-vaginal intercourse, "sex" and the phrase "have sex" can mean any penetrative or non-penetrative sexual activity between two or more people. The World Health Organization (WHO) states that non-English languages and cultures "use different terms for sexual activity, with slightly different meanings". Various vulgar or slang words and euphemisms are also used to describe sexual intercourse or other sexual activity, such as the term "fuck" and the phrase "sleep together". Penetration of the vagina by the erect penis is additionally known as "intromission", or by the Latin name "immissio penis" (Latin for "insertion of the penis").
Vaginal, anal and oral sex are the sexual behaviors most commonly recognized as sexual intercourse. While non-penetrative and non-penile-vaginal sexual activities may be regarded as sexual intercourse, they might alternatively be considered a means of maintaining "technical virginity" or labeled "outercourse", regardless of any penetrative aspects; this is more often the case for oral sex than for anal sex. Virginity loss is often based on penile-vaginal intercourse partly because heterosexual couples may engage in anal or oral sex not only for sexual pleasure, but as ways of maintaining that they are virgins if they have not engaged in the reproductive act of coitus. Similarly, some gay men consider frotting or oral sex as ways of maintaining their virginities, with penile-anal penetration defined as sexual intercourse and resulting in virginity loss, while other gay men may define frotting or oral sex as their main forms of sexual activity. Lesbians may define oral sex or fingering as sexual intercourse and subsequently an act of virginity loss, or tribadism as a primary form of sexual activity.
Researchers commonly define sexual intercourse as penile-vaginal intercourse while using specific terms, such as "anal sex" or "oral sex", for other sexual behaviors. Scholars Richard M. Lerner and Laurence Steinberg state that researchers also "rarely disclose how they define sex or even whether they resolved potential discrepancies in definitions of sex". Learner and Steinberg attribute researchers' focus on penile-vaginal sex to "the larger culture's preoccupation with this form of sexual activity," and have expressed concern that the "widespread, unquestioned equation of penile-vaginal intercourse with sex reflects a failure to examine systematically 'whether the respondent's understanding of the question sexual activity matches what the researcher had in mind'". This focus can also relegate other forms of mutual sexual activity to foreplay or contribute to them not being regarded as "real sex", and limit how rape is defined. It may also be that conceptually conflating sexual activity with vaginal intercourse and sexual function hinders and limits information about sexual behavior that non-heterosexual people may be engaging in, or information about heterosexuals who may be engaging in non-vaginal sexual activity.
Studies regarding the definition of sexual intercourse sometimes conflict. A 1999 study by the Kinsey Institute examined the definition of sex based on a 1991 random sample of 599 college students from 29 U.S. states; it reported that while "virtually every college student they surveyed considered penile-vaginal intercourse to be sex," and 19–20% said that anal intercourse was not sex, 60% said oral-genital contact (fellatio, cunnilingus) did not constitute having sex. Similarly, a 2003 study published in the "Canadian Journal of Human Sexuality" focusing on definitions of having sex and noting studies concerning university students from the United States, the United Kingdom, and Australia reported that "the vast majority of respondents (more than 97%) in these three studies included penile-vaginal intercourse in their definition of sex, fewer (between 70% and 90%) respondents considered penile-anal intercourse to constitute having sex" and that "oral-genital behaviours were defined as sex by between 32% and 58% of respondents". The Centers for Disease Control and Prevention (CDC) stated in 2009 that "[although there are only limited national data about how often adolescents engage in oral sex, some data suggest that many adolescents who engage in oral sex do not consider it to be 'sex'; therefore they may use oral sex as an option to experience sex while still, in their minds, remaining abstinent".
The specificity of questions concerning sexual activity can additionally affect definitions of sexual intercourse or other sexual behaviors. Another study by the Kinsey Institute sampled 484 people, ranging in ages 18–96. The study reported that nearly 95% of its participants "agreed that penile-vaginal intercourse meant 'had sex.' But the numbers changed as the questions got more specific". 11% of respondents based "had sex" on whether the man had achieved an orgasm, concluding that absence of an orgasm does not constitute "having had" sex; "bout 80 percent of respondents said penile-anal intercourse meant 'had sex.' About 70 percent of people believed oral sex was sex." Condom use is also a factor, with some men stating that sexual activity involving the protection of a condom is not "real sex" or "the real thing". One study reported that older generations of men (65 or older) in particular do not view sexual activity involving the protection of a condom to be sex. This view is common among men in Africa, where sexual activity involving the protection of a condom is often associated with emasculation because condoms prevent direct penile–to–skin genital contact.
Bonding and stimulus variation.
Copulation ranges from a purely reproductive activity to one of emotional bonding. For example, sexual intercourse and sexual activity in general often play a strong role in human bonding. In many societies, it is normal for couples to have sexual intercourse while using some method of birth control (contraception), sharing pleasure and strengthening their emotional bond through sexual activity even though they are deliberately avoiding pregnancy.
In humans and bonobos, the female undergoes relatively concealed ovulation so that male and female partners commonly do not know whether she is fertile at any given moment. One possible reason for this distinct biological feature may be formation of strong emotional bonds between sexual partners important for social interactions and, in the case of humans, long-term partnership rather than immediate sexual reproduction. For humans in particular, cooperative behavior in a community and, by extension, sexual activity reinforce social bonds between individuals and may form larger social structures. The resulting cooperation encourages collective tasks that promote the survival of each member of the group.
Sexual intercourse or other sexual activity can encompass various sexually stimulating factors (physiological stimulation or psychological stimulation), including different sex positions or the use of sex toys. Foreplay may precede particular sexual activities, often leading to sexual arousal of the partners and resulting in the erection of the penis or natural lubrication of the vagina. It is also common for people to be as sexually satisfied by being kissed, touched erotically, or held as they are by sexual intercourse.
During coitus, the partners orient their hips to allow the penis to move back and forth in the vagina to cause friction, typically without fully removing the penis. In this way, they stimulate themselves and each other, often continuing until orgasm in either or both partners is achieved.
For human females, stimulation of the clitoris plays a significant role in sexual activity; 70–80% of women require direct clitoral stimulation to achieve orgasm, though indirect clitoral stimulation (for example, via vaginal intercourse) may also be sufficient (see orgasm in females). Because of this, some couples may engage in the woman on top position or the coital alignment technique, a technique combining the "riding high" variation of the missionary position with pressure-counterpressure movements performed by each partner in rhythm with sexual penetration, to maximize clitoral stimulation.
Anal sex involves stimulation of the anus, anal cavity, sphincter valve or rectum; it most commonly means the insertion of a man's penis into another person's rectum, but may also mean pegging, the use of other sex toys or fingers to penetrate the anus, or anilingus.
Oral sex consists of all the sexual activities that involve the use of the mouth and throat to stimulate genitalia or anus. It is sometimes performed to the exclusion of all other forms of sexual activity, and may include the ingestion or absorption of semen or vaginal fluids.
Fingering (or digital penetration or digital intercourse) involves the manual manipulation of the clitoris, rest of the vulva, vagina or anus for the purpose of sexual arousal and sexual stimulation; it may constitute the entire sexual encounter or it may be part of mutual masturbation, foreplay or other sexual activities.
Reproduction.
Sexual intercourse is perhaps 385 million years old, and it is likely that the oldest jawed fish on Earth was the first animal to reproduce by copulation. Reproduction among humans usually occurs with penile-vaginal penetration. Male orgasm usually includes ejaculation, a series of muscular contractions that deliver semen containing male gametes known as sperm cells or spermatozoa from the penis into the vagina. The subsequent route of the sperm from the vault of the vagina is through the cervix and into the uterus, and then into the fallopian tubes. Millions of sperm are present in each ejaculation, to increase the chances of one fertilizing an egg or ovum (see sperm competition). When a fertile ovum from the female is present in the fallopian tubes, the male gamete joins with the ovum, resulting in fertilization and the formation of a new embryo. When a fertilized ovum reaches the uterus, it becomes implanted in the lining of the uterus (the endometrium) and a pregnancy begins. Unlike most species, human sexual activity is not linked to periods of estrus and can take place at any time during the reproductive cycle, even during pregnancy.
When a sperm donor has sexual intercourse with a woman who is not his partner and for the sole purpose of impregnating the woman, this may be known as natural insemination, as opposed to artificial insemination. Artificial insemination is a form of assisted reproductive technology, which are methods used to achieve pregnancy by artificial or partially artificial means. For artificial insemination, sperm donors may donate their sperm through a sperm bank, and the insemination is performed with the express intention of attempting to impregnate the female; to this extent, its purpose is the medical equivalent of sexual intercourse.
Reproductive methods also extend to gay and lesbian couples. For gay male pairings, there is the option of surrogate pregnancy; for lesbian couples, there is donor insemination in addition to choosing surrogate pregnancy. Surrogacy and donor insemination remain the primary methods. Surrogacy is an arrangement in which a woman carries and delivers a child for another couple or person. The woman may be the child's genetic mother (traditional surrogacy) or she may carry a pregnancy to delivery after having another woman's eggs transferred to her uterus (gestational surrogacy). Gay or lesbian pairings who want the host to have no genetic connection to the child may choose gestational surrogacy and enter into a contract with an egg donor. Gay male couples might decide that they should both contribute semen for an in vitro fertilisation (IVF) process, which further establishes the couple's joint intention to become parents. Lesbian couples often have contracts drafted to extinguish the legal rights of the sperm donor, while creating legal rights for the parent who is not biologically related to the child.
Safe sex and birth control.
There are a variety of safe sex methods that are practiced by heterosexual and same-sex couples, including non-penetrative sex acts, and heterosexual couples may use oral or anal sex (or both) as a means of birth control. However, pregnancy can still occur with anal sex or other forms of sexual activity if the penis is near the vagina (such as during intercrural sex or other genital-genital rubbing) and its sperm is deposited near the vagina's entrance and travels along the vagina's lubricating fluids; the risk of pregnancy can also occur without the penis being near the vagina because sperm may be transported to the vaginal opening by the vagina coming in contact with fingers or other non-genital body parts that have come in contact with semen.
Safe sex is a relevant harm reduction philosophy, and condoms are used as a form of safe sex and contraception. Condoms are widely recommended for the prevention of sexually transmitted infections (STIs). According to reports by the National Institutes of Health (NIH) and World Health Organization (WHO), correct and consistent use of latex condoms reduces the risk of HIV/AIDS transmission by approximately 85–99% relative to risk when unprotected. The most effective way to avoid sexually transmitted infections is to abstain from sexual intercourse, especially vaginal, anal, and oral sexual intercourse.
Decisions and options concerning birth control can be affected by cultural reasons, such as religion, gender roles or folklore. In the predominantly Catholic countries Ireland, Italy and the Philippines, fertility awareness and the rhythm method are emphasized while disapproval is expressed with regard to other contraceptive methods. Worldwide, sterilization is a more common birth control method, and use of the intrauterine device (IUD) is the most common and effective way of reversible contraception. Conception and contraception are additionally a life-and-death situation in developing countries, where one in three women give birth before age 20; however, 90% of unsafe abortions in these countries could be prevented by effective contraception use.
In 2004, the Guttmacher Institute indicated in 2002 that 62% of the 62 million women aged 15–44 are currently using a contraceptive method, that among U.S. women who practice contraception, the birth-control pill is the most popular choice (30.6%), followed by tubal sterilization (27.0%) and the male condom (18.0%), and that 27% of teenage women using contraceptives choose condoms as their primary method. A 2006 Kaiser Family Foundation report stated that among sexually active 15- to 19-year-olds in the U.S., 83% of females and 91% of males reported using at least one method of birth control during last intercourse.
The National Survey of Sexual Health and Behavior (NSSHB) indicated in 2010 that "1 of 4 acts of vaginal intercourse are condom-protected in the U.S. (1 in 3 among singles)," that "condom use is higher among black and Hispanic Americans than among white Americans and those from other racial groups," and that "adults using a condom for intercourse were just as likely to rate the sexual extent positively in terms of arousal, pleasure and orgasm than when having intercourse without one".
Prevalence.
Penile-vaginal penetration is the most common form of sexual intercourse. Studies indicate that most heterosexual couples engage in vaginal intercourse nearly every sexual encounter. The National Survey of Sexual Health and Behavior (NSSHB) reported in 2010 that vaginal intercourse is "the most prevalent sexual behavior among men and women of all ages and ethnicities". In 2013, Clint E. Bruess et al. stated that it "is the most frequently studied behavior" and, besides in many cultures being what is usually meant when people refer to "having sex" or "sexual intercourse", is "often the focus of sexuality education programming for youth."
Regarding oral or anal intercourse, the CDC stated in 2009, "Studies indicate that oral sex is commonly practiced by sexually active male-female and same-gender couples of various ages, including adolescents." The 2010 NSSHB study reported that vaginal intercourse was practiced more than insertive anal intercourse among men, but that 13% to 15% of men aged 25 to 49 practiced insertive anal intercourse. Receptive anal intercourse was infrequent among men, with approximately 7% of men aged 14 to 94 years old having said that they were a receptive partner during anal intercourse. It said that women engage in anal intercourse less commonly than men, but that the practice is not uncommon among women; it was estimated that 10% to 14% of women aged 18 to 39 years old practiced anal sex in the past 90 days, and that most of the women said they practiced it once a month or a few times a year.
The prevalence of sexual intercourse has been compared cross-culturally. In 2003, Michael Bozon of the French Institut national d'études démographiques conducted a cross-cultural study titled "At what age do women and men have their first sexual intercourse?". In the first group of the contemporary cultures he studied, which included sub-Saharan Africa (listing Mali, Senegal and Ethiopia), the data indicated that the age of men at sexual initiation in these societies is at later ages than that of women, but is often extra-marital; the study considered the Indian subcontinent to also fall into this group, though data was only available from Nepal.
In the second group, the data indicated families encouraged daughters to delay marriage, and to abstain from sexual activity before that time. However, sons are encouraged to gain experience with older women or prostitutes before marriage. Age of men at sexual initiation in these societies is at lower ages than that of women; this group includes Latin cultures, both from southern Europe (Portugal, Greece and Romania are noted) and from Latin America (Brazil, Chile, and the Dominican Republic). The study considered many Asian societies to also fall into this group, although matching data was only available from Thailand.
In the third group, age of men and women at sexual initiation was more closely matched; there were two sub-groups, however. In non-Latin, Catholic countries (Poland and Lithuania are mentioned), age at sexual initiation was higher, suggesting later marriage and reciprocal valuing of male and female virginity. The same pattern of late marriage and reciprocal valuing of virginity was reflected in Singapore and Sri Lanka. The study considered China and Vietnam to also fall into this group, though data were not available. In northern and eastern European countries, age at sexual initiation was lower, with both men and women involved in sexual intercourse before any union formation; the study listed Switzerland, Germany and the Czech Republic as members of this group.
Concerning United States data, national surveys in 1995 indicated that at least 3/4 of all men and women in the U.S. engaged in sexual intercourse by their late teenage years, and more than 2/3 of all sexually experienced teens had two or more partners. Based on the 2002 National Survey of Family Growth, published by the U.S. Department of Health and Human Services, the average age of first sexual intercourse in U.S. participants aged 15 to 44 was 17.3 years for females and 17.0 years for males. Special tabulations by the National Center for Health Statistics suggest that this figure changed between 2006 and 2010 to 17.1 years for both males and females. The Centers for Disease Control and Prevention (CDC) stated that 45.5 percent of girls and 45.7 percent of boys had engaged in sexual activity by 19 in 2002; in 2011, reporting their research from 2006–2010, they stated that 43% of American unmarried teenage girls and 42% of American unmarried teenage boys have ever engaged in sexual intercourse. The CDC also reports that American girls will most likely lose their virginity to a boy who is 1 to 3 years older than they are.
The U.S. Department of Health and Human Services reported in 2002 that teenagers are delaying sexual intercourse and other sexual activity until older ages. Between 1988 and 2002, the percentage of people in the U.S. who had sexual intercourse between the ages of 15 to 19 fell from 60 to 46 percent for never-married males, and from 51 to 46 percent for never-married females. Similarly, a 2006 survey conducted by "The Observer" suggested that most adolescents in Britain were waiting longer to have sexual intercourse than they were only a few years earlier. For example, it was reported in 2002 that 32% of British teenagers were having sex before the age of 16; in 2006, however, it was only 20%. The average age a British teenager lost his or her virginity was reportedly 17.13 years in 2002, and 17.44 years in 2006 on average for girls and 18.06 for boys. The most notable drop among teens who reported having sex was 14 and 15-year-olds. A 2008 survey conducted by YouGov for Channel 4 suggested that 40% of all 14 to 17-year-olds are sexually active, 74% of sexually active 14 to 17-year-olds have had a sexual experience under the age of consent, and 6% of teens would wait until marriage before having sex.
Health effects.
Benefits.
In humans, sexual intercourse and sexual activity in general have been reported as having health benefits as varied as increased immunity by increasing the body's production of antibodies and subsequent lower blood pressure, and decreased risk of prostate cancer. Sexual intimacy and orgasms increase levels of the hormone oxytocin (also known as "the love hormone"), which can help people bond and build trust. Oxytocin is believed to have a more significant impact on women than on men, which may be why women associate sexual attraction or sexual activity with romance and love more than men do. A long-term study of 3,500 people between ages 18 and 102 by clinical neuropsychologist David Weeks indicated that, based on impartial ratings of the subjects' photographs, sex on a regular basis helps people look significantly chronologically younger.
Risks.
Sexually transmitted infections (STIs) are bacteria, viruses and parasites, which are passed from person to person during sexual contact, especially penetrative sexual intercourse. Some, in particular HIV and syphilis, can also be passed in other ways, including from mother to child during pregnancy and childbirth, through blood products, and by shared hypodermic needles. Gonococcal or chlamydia infections often produce no symptoms. Untreated chlamydia infection can lead to female infertility and ectopic pregnancy. Human papillomavirus can lead to genital and cervical cancers. Syphilis can result in stillbirths and neonatal deaths. Untreated gonococcal infections result in miscarriages, preterm births and perinatal deaths. Infants born to mothers with untreated gonorrhea or chlamydia can develop neonatal conjunctivitis (a serious eye infection), which can lead to blindness. Hepatitis B can also be transmitted through sexual contact. Globally, there are about 350 million chronic carriers of hepatitis B.
There are 19 million new cases of sexually transmitted infections every year in the U.S., and, in 2005, the World Health Organization estimated that 448 million people aged 15–49 were being infected a year with curable STIs (such as syphilis, gonorrhea and chlamydia). Some STIs can cause a genital ulcer; even if they do not, they increase the risk of both acquiring and passing on HIV up to ten-fold. HIV is one of the world's leading infectious killers; in 2010, approximately 30 million people were estimated to have died because of it since the beginning of the epidemic. Of the 2.7 million new HIV infections estimated to occur worldwide in 2010, 1.9 million (70%) were in Africa. "The estimated 1.2 million Africans who died of HIV-related illnesses in 2010 comprised 69% of the global total of 1.8 million deaths attributable to the epidemic." It is diagnosed by blood tests, and while no cure has been found, it can be controlled by management through antiretroviral drugs for the disease, and patients can enjoy healthy and productive lives.
In cases where infection is suspected, early medical intervention is highly beneficial in all cases. The CDC stated "risk of HIV transmission from an infected partner through oral sex is much less than the risk of HIV transmission from anal or vaginal sex," but that "[measuring the exact risk of HIV transmission as a result of oral sex is very difficult" and that this is "because most sexually active individuals practice oral sex in addition to other forms of sex, such as vaginal and/or anal sex, when transmission occurs, it is difficult to determine whether or not it occurred as a result of oral sex or other more risky sexual activities". They added that "several co-factors may increase the risk of HIV transmission through oral sex"; this includes ulcers, bleeding gums, genital sores, and the presence of other STIs.
In 2005, the World Health Organization (WHO) estimated that 123 million women become pregnant world-wide each year, and around 87 million of those pregnancies or 70.7% are unintentional. Approximately 46 million pregnancies per year reportedly end in induced abortion. Approximately 6 million U.S. women become pregnant per year. Out of known pregnancies, two-thirds result in live births and roughly 25% in abortions; the remainder end in miscarriage. However, many more women become pregnant and miscarry without even realizing it, instead mistaking the miscarriage for an unusually heavy menstruation. The U.S. teenage pregnancy rate fell by 27 percent between 1990 and 2000, from 116.3 pregnancies per 1,000 girls aged 15–19 to 84.5. This data includes live births, abortions, and fetal losses. Almost 1 million American teenage women, 10% of all women aged 15–19 and 19% of those who report having had intercourse, become pregnant each year. Britain has been stated to have a teenage pregnancy rate similar to America's.
Sexual activity can increase the expression of a gene transcription factor called ΔFosB (Delta FosB) in the brain's reward center; consequently excessively frequent engagement in sexual activity on a regular (daily) basis can lead to the overexpression of ΔFosB, inducing an addiction to sexual activity. Sexual addiction or hypersexuality is often considered an impulse control disorder or a behavioral addiction. It has been linked to atypical levels of dopamine, a neurotransmitter. This behavior is characterized by a fixation on sexual intercourse and disinhibition. It was proposed that this 'addictive behavior' be classified in DSM-5 as an impulsive–compulsive behavioral disorder. Addiction to sexual intercourse is thought to be genetically linked. Those having an addiction to sexual intercourse have a higher response to visual sexual cues in the brain. Those seeking treatment will typically see a physician for pharmacological management and therapy. One form of hyper sexuality is Kleine-Levin syndrome. It is manifested by hypersomnia and hypersexuality and remains relatively rare.
Sexual activity can directly cause death, particularly due to coronary circulation complications, which is sometimes termed "coital death," "coital sudden death" or "coital coronary." However, coital deaths are significantly rare. People, especially those who get little or no physical exercise, have a slightly increased risk of triggering a heart attack or sudden cardiac death when they engage in sexual intercourse or any vigorous physical exercise that is engaged in on a sporadic basis. Increased risk is temporary with incidents occurring within a few hours of the activity. Regular exercise reduces, but does not eliminate, the increased risk. In a study in Switzerland of emergency department admissions for conditions related to sexual intercourse, less than 1% had cardiovascular emergencies, 10% had trauma and 12% had neurological emergencies whereof the most frequent were headaches (in 49% of neurological emergencies), followed by subarachnoid hemorrhage (22%) and transient global amnesia (20%).
Duration and genital complications.
Sexual intercourse, when involving a male participant, often ends when the male has ejaculated, and thus the partner might not have time to reach orgasm. In addition, premature ejaculation (PE) is common, and women often require a substantially longer duration of stimulation with a sexual partner than men do before reaching an orgasm. Masters and Johnson found that men took approximately 4 minutes to reach orgasm with their partners; women took approximately 10–20 minutes to reach orgasm with their partners, but 4 minutes to reach orgasm when they masturbated. Scholars, such as Weiten et al., state that "many couples are locked into the idea that orgasms should be achieved only through intercourse sex," that "the word "foreplay" suggests that any other form of sexual stimulation is merely preparation for the 'main event'" and that "ecause women reach orgasm through intercourse less consistently than men," they are likelier than men to fake an orgasm to satisfy their sexual partners. 
In 1991, scholars from the Kinsey Institute stated, "The truth is that the time between penetration and ejaculation varies not only from man to man, but from one time to the next for the same man." They added that the appropriate length for sexual intercourse is the length of time it takes for both partners to be mutually satisfied, emphasizing that Kinsey "found that 75 percent of men ejaculated within two minutes of penetration. But he didn't ask if the men or their partners considered two minutes mutually satisfying" and "more recent research reports slightly longer times for intercourse". A 2008 survey of Canadian and American sex therapists stated that the average time for heterosexual intercourse (coitus) was 7 minutes and that 1 to 2 minutes was too short, 3 to 7 minutes was adequate and 7 to 13 minutes desirable, while 10 to 30 minutes was too long.
Anorgasmia is regular difficulty reaching orgasm after ample sexual stimulation, causing personal distress. This is significantly more common in women than in men, which has been attributed to the lack of sex education with regard to women's bodies, especially in sex-negative cultures, such as clitoral stimulation usually being key for women to orgasm. The physical structure of coitus favors penile stimulation over clitoral stimulation; the location of the clitoris then usually necessitates manual or oral stimulation in order for the woman to achieve orgasm. Approximately 25% of women report difficulties with orgasm, 10% of women have never had an orgasm, and 40% or 40–50% have either complained about sexual dissatisfaction or experienced difficulty becoming sexually aroused at some point in their lives.
Vaginismus is involuntary tensing of the pelvic floor musculature, making coitus, or any form of penetration of the vagina, distressing, painful and sometimes impossible for women. It is a conditioned reflex of the pubococcygeus muscle, and is sometimes referred to as the "PC muscle." Vaginismus can be hard to overcome because if a woman expects to experience pain during sexual intercourse, this can cause a muscle spasm, which results in painful sexual intercourse. Treatment of vaginismus often includes both psychological and behavioral techniques, including the use of vaginal dilators. Additionally, the use of Botox as a medical treatment for vaginismus has been tested and administered. Painful or uncomfortable sexual intercourse may also be categorized as dyspareunia.
Approximately 40% of males reportedly suffer from some form of erectile dysfunction (ED) or impotence, at least occasionally. Premature ejaculation has been reported to be more common than erectile dysfunction, although some estimates suggest otherwise. Due to various definitions of the disorder, estimates for the prevalence of premature ejaculation vary significantly more than for erectile dysfunction. For example, the Mayo Clinic states, "Estimates vary, but as many as 1 out of 3 men may be affected by ejaculation at some time." Further, "Masters and Johnson speculated that premature ejaculation is the most common sexual dysfunction, even though more men seek therapy for erectile difficulties" and that this is because "although an estimated 15 percent to 20 percent of men experience difficulty controlling rapid ejaculation, most do not consider it a problem requiring help, and many women have difficulty expressing their sexual needs". The American Urological Association (AUA) estimates that premature ejaculation could affect 21 percent of men in the United States.
For those whose impotence is caused by medical conditions, prescription drugs such as Viagra, Cialis, and Levitra are available. However, doctors caution against the unnecessary use of these drugs because they are accompanied by serious risks such as increased chance of heart attack. The selective serotonin reuptake inhibitor (SSRI) and antidepressant drug dapoxetine has been used to treat premature ejaculation. In clinical trials, those with PE who took dapoxetine experienced sexual intercourse three to four times longer before orgasm than without the drug. Another ejaculation-related disorder is delayed ejaculation, which can be caused as an unwanted side effect of antidepressant medications such as Fluvoxamine; however, all SSRIs have ejaculation-delaying effects, and Fluvoxamine has the least ejaculation-delaying effects.
Sexual intercourse remains possible after major medical treatment of the reproductive organs and structures. This is especially true for women. Even after extensive gynecological surgical procedures (such as hysterectomy, oophorectomy, salpingectomy, dilation and curettage, hymenotomy, Bartholin gland surgery, abscess removal, vestibulectomy, labia minora reduction, cervical conization, surgical and radiological cancer treatments and chemotherapy), coitus can continue. Reconstructive surgery remains an option for women who have experienced benign and malignant conditions.
Disabilities and other complications.
Obstacles that those with disabilities face with regard to engaging in sexual intercourse include pain, depression, fatigue, negative body image, stiffness, functional impairment, anxiety, reduced libido, hormonal imbalance, and drug treatment or side effects. Sexual functioning has been regularly identified as a neglected area of the quality of life in patients with rheumatoid arthritis. For those that must take opioids for pain control, sexual intercourse can become more difficult. Having a stroke can also largely impact on the ability to engage in sexual intercourse. Although disability-related pain, including as a result of cancer, and mobility impairment can hamper sexual intercourse, in many cases, the most significant impediments to sexual intercourse for individuals with a disability are psychological. In particular, people who have a disability can find sexual intercourse daunting due to issues involving their self-concept as a sexual being, or a partner's discomfort or perceived discomfort. Temporary difficulties can arise with alcohol and sex, as alcohol can initially increase interest through disinhibition but decrease capacity with greater intake; however, disinhibition can vary depending on the culture.
The mentally disabled also are subject to challenges in participating in sexual intercourse. Women with Intellectual disabilities (ID) are often presented with situations that prevent sexual intercourse. This can include the lack of a knowledgeable healthcare provider trained and experienced in counseling those with ID on sexual intercourse. Those with ID may have hesitations regarding the discussion of the topic of sex, a lack of sexual knowledge and limited opportunities for sex education. In addition there are other barriers such as a higher prevalence of sexual abuse and assault. These crimes often remain underreported. There remains a lack of "dialogue around this population's human right to consensual sexual expression, undertreatment of menstrual disorders, and legal and systemic barriers". Women with ID may lack sexual health care and sex education. They may not recognize sexual abuse. Consensual sexual intercourse is not always an option for some. Those with ID may have limited knowledge and access to contraception, screening for sexually transmitted infections and cervical cancer.
Social effects.
Adults.
Some researchers, such as Alex Comfort, posit three potential advantages or social effects of sexual intercourse in humans, which are not mutually exclusive; these are reproductive, relational, and recreational. While the development of the birth control pill and other highly effective forms of contraception in the mid to late 20th century increased people's ability to segregate these three functions, they still significantly overlap and in complex patterns. For example: A fertile couple may have sexual intercourse while contracepting not only to experience sexual pleasure (recreational), but also as a means of emotional intimacy (relational), thus deepening their bonding, making their relationship more stable and more capable of sustaining children in the future (deferred reproductive). This couple may emphasize different aspects of sexual intercourse on different occasions, being playful during one episode of sexual intercourse (recreational), experiencing deep emotional connection on another occasion (relational), and later, after discontinuing contraception, seeking to achieve pregnancy (reproductive, or more likely reproductive and relational).
Sexual dissatisfaction due to the lack of sexual intercourse is associated with increased risk of divorce and relationship dissolution, especially for men. Some research, however, indicates that general dissatisfaction with marriage for men results if their wives flirted with, erotically kissed or became romantically or sexually involved with another man (infidelity), and that this is especially the case for men with a lower emotional and composite marital satisfaction. Other studies report that the lack of sexual intercourse does not significantly result in divorce, though it is commonly one of the various contributors to it. According to the 2010 National Survey of Sexual Health and Behavior (NSSHB), men whose most recent sexual encounter was with a relationship partner reported greater arousal, greater pleasure, fewer problems with erectile function, orgasm, and less pain during the event than men whose last sexual encounter was with a non-relationship partner.
For women, there is often a complaint about the lack of their spouses' sexual spontaneity. Decreased sexual activity among these women may be the result of their perceived failure to maintain ideal physical attractiveness or because their sexual partners' health issues have hindered sexual intercourse. Some women express that their most satisfying sexual experiences entail being connected to someone, rather than solely basing satisfaction on orgasm. With regard to divorce, women are more likely to divorce their spouses for a one-night stand or various infidelities if they are in less cooperative or high-conflict marriages.
Research additionally indicates that non-married couples who are cohabiting engage in sexual intercourse more often than married couples, and are more likely to participate in sexual activity outside of their sexual relationships; this may be due to the "honeymoon" effect (the newness or novelty of sexual intercourse with the partner), since sexual intercourse is usually practiced less the longer a couple is married, with couples engaging in sexual intercourse or other sexual activity once or twice a week, or approximately six to seven times a month. Sexuality in older age also affects the frequency of sexual intercourse, as older people generally engage in sexual intercourse less frequently than younger people do.
Adolescents.
Adolescents commonly use sexual intercourse for relational and recreational purposes, which may negatively or positively impact their lives. For example, while teenage pregnancy may be welcomed in some cultures, it is also commonly disparaged, and research suggests that the earlier onset of puberty for children puts pressure on children and teenagers to act like adults before they are emotionally or cognitively ready. Some studies have concluded that engaging in sexual intercourse leaves adolescents, especially girls, with higher levels of stress and depression, and that girls may be likelier to engage in sexual risk (such as sexual intercourse without the use of a condom), but it may be that further research is needed in these areas. In some countries, such as the United States, sex education and abstinence-only sex education curricula are available to educate adolescents about sexual activity; these programs are controversial, as debate exists as to whether or not teaching children and adolescents about sexual intercourse or other sexual activity should only be left up to parents or other caregivers.
One group of Canadian researchers found a relationship between self-esteem and sexual activity. They found that students, especially girls, who were verbally abused by teachers or rejected by their peers were more likely than other students to engage in sex by the end of Grade 7. The researchers speculate that low self-esteem increases the likelihood of sexual activity: "low self-esteem seemed to explain the link between peer rejection and early sex. Girls with a poor self-image may see sex as a way to become 'popular', according to the researchers".
In India, there is evidence that adolescents are becoming more sexually active outside of marriage, which is feared to lead to an increase in the spread of HIV/AIDS among adolescents, as well as the number of unwanted pregnancies and abortions, and add to the conflict between contemporary social values. In India, adolescents have relatively poor access to health care and education, and with cultural norms opposing extramarital sexual behavior, "these implications may acquire threatening dimensions for the society and the nation".
Psychiatrist Lynn Ponton wrote, "All adolescents have sex lives, whether they are sexually active with others, with themselves, or seemingly not at all", and that viewing adolescent sexuality as a potentially positive experience, rather than as something inherently dangerous, may help young people develop healthier patterns and make more positive choices regarding sexual activity. Similarly, researchers state that long-term romantic relationships allow adolescents to gain the skills necessary for high-quality relationships later in life and develop feelings of self-worth. Overall, positive romantic relationships among adolescents can result in long-term benefits. High-quality romantic relationships are associated with higher commitment in early adulthood and are positively associated with self-esteem, self-confidence, and social competence.
Ethical, religious, and legal views.
While sexual intercourse, as coitus, is the natural mode of reproduction for the human species, humans have intricate moral and ethical guidelines which regulate the practice of sexual intercourse and vary according to religious and governmental laws. Some governments and religions also have strict designations of "appropriate" and "inappropriate" sexual behavior, which include restrictions on the types of sex acts which are permissible. A historically prohibited or regulated sex act is anal sex.
Consent and sexual offenses.
Sexual intercourse with a person against their will, or without their informed legal consent, is rape, but may also be termed "sexual assault"; it is considered a serious crime in most countries. More than 90% of rape victims are female, 99% of rapists male, and only about 5% of rapists are strangers to the victims.
Most developed countries have age of consent laws specifying the minimum legal age a person may engage in sexual intercourse with substantially older persons, usually set at about 16–18, while the legal age of consent ranges from 12–20 years of age or is not a matter of law in other countries. Sex with a person under the age of consent, regardless of their stated consent, is often considered to be sexual assault or statutory rape depending on differences in ages of the participants. Some countries treat any sex with a person of diminished or insufficient mental capacity to give consent, regardless of age, as rape.
Scholars state that "to the 1970s, rape definitions of sex often included only penile-vaginal sexual intercourse" and that if "sex means penile-vaginal intercourse, then rape means forced penile-vaginal intercourse, and other sexual behaviors – such as fondling a person's genitals without her or his consent, forced oral sex, and same-sex coercion – are not considered rape"; they state that "[although some other forms of forced sexual contact are included within the legal category of sodomy (e.g., anal penetration and oral-genital contact), many unwanted sexual contacts have no legal grounding as rape in some states".
While Robert Francoeur et al. state that there is a broad "conceptualization of sex, including many kinds of sexual penetration (e.g., penile-vaginal intercourse, fellatio, cunnilingus, anal intercourse, or penetration of the genitals or rectum by an object)" for most definitions of rape, scholar Ken Plumber argues that "the legal definition of rape in most countries is unlawful sexual intercourse which means the penis must penetrate the vagina" and that "ther forms of sexual violence towards women such as forced oral sex or anal intercourse, or the insertion of other objects into the vagina, constitute the 'less serious' crime of sexual assault".
Another sexual matter concerning consent is zoophilia, a paraphilia involving sexual activity between human and non-human animals, or a fixation on such practice. Human sexual activity with non-human animals is not outlawed in some jurisdictions, but it is illegal in others under animal abuse laws or laws dealing with crimes against nature.
Romantic relationships.
Marriage and relationships.
Sexual intercourse has traditionally been considered an essential part of a marriage, with many religious customs requiring consummation of the marriage and citing marriage as the most appropriate union for sexual reproduction (procreation). In such cases, a failure for any reason to consummate the marriage would be considered a ground for annulment (which does not require a divorce process). Sexual relations between marriage partners have been a "marital right" in various societies and religions, both historically and in modern times, especially with regard to a husband's rights to his wife. Until the late 20th century, there was usually a marital exemption in rape laws which precluded a husband from being prosecuted under the rape law for forced sex with his wife. Author Oshisanya, 'lai Oshitokunbo stated, "As the legal status of women has changed, the concept of a married man's or woman's marital right to sexual intercourse has become less widely held."
Adultery (engaging in sexual intercourse with someone other than one's spouse) has been, and remains, a criminal offense in some jurisdictions. Sexual intercourse between unmarried partners and cohabitation of an unmarried couple are also illegal in some jurisdictions. Conversely, in other countries, marriage is not required, socially or legally, in order to have sexual intercourse or to procreate (for example, the majority of births are outside of marriage in countries such as Iceland, Norway, Sweden, Denmark, Bulgaria, Estonia, Slovenia, France, Belgium).
With regard to divorce laws, the refusal to engage in sexual intercourse with one's spouse may give rise to a grounds for divorce, which may be listed under "grounds of abandonment". Concerning no-fault divorce jurisdictions, author James G. Dwyer stated that no-fault divorce laws "have made it much easier for a woman to exit a marital relationship, and wives have obtained greater control over their bodies while in a marriage" because of legislative and judicial changes regarding the concept of a marital exemption when a man rapes his wife.
There are various legal positions regarding the definition and legality of sexual intercourse between persons of the same sex or gender. For example, in the 2003 New Hampshire Supreme Court case Blanchflower v. Blanchflower, it was held that female same-sex sexual relations, and same-sex sexual practices in general, did not constitute sexual intercourse, based on a 1961 definition from "Webster's Third New International Dictionary" that defines sexual intercourse as coitus; and thereby an accused wife in a divorce case was found not guilty of adultery. Some countries consider same-sex sexual behavior an offense punishable by imprisonment or execution; this is the case, for example, in Islamic countries, including LGBT issues in Iran.
Opposition to same-sex marriage is largely based on the belief that sexual intercourse and sexual orientation should be of a heterosexual nature. The recognition of such marriages is a civil rights, political, social, moral and religious issue in many nations, and the conflicts arise over whether same-sex couples should be allowed to enter into marriage, be required to use a different status (such as a civil union, which either grant equal rights as marriage or limited rights in comparison to marriage), or not have any such rights. A related issue is whether the term "marriage" should be applied.
Religious interpretations.
There are wide differences in religious views with regard to sexual intercourse in or outside of marriage:
In some cases, the sexual intercourse between two people is seen as counter to religious law or doctrine. In many religious communities, including the Catholic Church and Mahayana Buddhists, religious leaders are expected to refrain from sexual intercourse in order to devote their full attention, energy, and loyalty to their religious duties.
Other animals.
With regard to zoology, "copulation" is often termed the process in which a male introduces sperm into the female's body, especially directly into her reproductive tract. Spiders have separate male and female sexes. Before mating and copulation, the male spider spins a small web and ejaculates on to it. He then stores the sperm in reservoirs on his large pedipalps, from which he transfers sperm to the female's genitals. The females can store sperm indefinitely.
Many animals that live in water use external fertilization, whereas internal fertilization may have developed from a need to maintain gametes in a liquid medium in the Late Ordovician epoch. Internal fertilization with many vertebrates (such as reptiles, some fish, and most birds) occur via cloacal copulation (see also hemipenis), while mammals copulate vaginally, and many basal vertebrates reproduce sexually with external fertilization.
For primitive insects, the male deposits spermatozoa on the substrate, sometimes stored within a special structure; courtship involves inducing the female to take up the sperm package into her genital opening, but there is no actual copulation. In groups that have reproduction similar to spiders, such as dragonflies, males extrude sperm into secondary copulatory structures removed from their genital opening, which are then used to inseminate the female. In dragonflies, it is a set of modified sternites on the second abdominal segment. In advanced groups of insects, the male uses its aedeagus, a structure formed from the terminal segments of the abdomen, to deposit sperm directly (though sometimes in a capsule called a "spermatophore") into the female's reproductive tract.
Bonobos, chimpanzees and dolphins are species known to engage in heterosexual behaviors even when the female is not in estrus, which is a point in her reproductive cycle suitable for successful impregnation. These species are also known to engage in same-sex sexual behaviors. In these animals, the use of sexual intercourse has evolved beyond reproduction to apparently serve additional social functions (such as bonding).

</doc>
<doc id="27548" url="https://en.wikipedia.org/wiki?curid=27548" title="Supermarine">
Supermarine

Supermarine was a British aircraft manufacturer that produced, among the others, a range of seaplanes and the Supermarine Spitfire fighter.
History.
Noel Pemberton Billing set up a company, Pemberton-Billing Ltd, in 1913 to produce sea-going aircraft. Its telegraphic address, used for sending telegrams and cables to the company, was; "Supermarine, Southampton". It produced a couple of prototypes using quadruplane designs to shoot down zeppelins, the Supermarine P.B.29 and the Supermarine Nighthawk. The aircraft were fitted with the recoilless Davis gun and the Nighthawk had a separate powerplant to power a searchlight.
Upon election as an MP in 1916 Pemberton-Billing sold the company to his factory manager and longtime associate Hubert Scott-Paine who renamed the company Supermarine Aviation Works Ltd. The company became famous for its successes in the Schneider Trophy for seaplanes, especially the three wins in a row of 1927, 1929 and 1931.
In 1928 Vickers-Armstrongs took over Supermarine as Supermarine Aviation Works (Vickers) Ltd and in 1938 all Vickers-Armstrongs aviation interests were reorganised to become Vickers-Armstrongs (Aircraft) Ltd, although Supermarine continued to design, build and trade under its own name. The phrase Vickers Supermarine was applied to the aircraft.
The first Supermarine landplane design to go into production was the famous and successful Spitfire. The earlier Hawker Hurricane and the Spitfire were the mainstay of RAF Fighter Command fighter aircraft which fought off the "Luftwaffe" bombing raids with fighter escorts during the Battle of Britain in the summer of 1940. While the Hurricane was available in larger numbers and consequently played a larger role, the new Spitfire caught the popular imagination and became the aircraft associated with the battle. It went on to play a major part in the remainder of the war, in a number of variants and marks, and it was the only allied fighter aircraft to be in production through the entirety of World War Two.
Other planes from World War II include the Seafire (a naval version of the Spitfire). Supermarine also developed the Spiteful and Seafang, the successors of the Spitfire and Seafire, respectively, and the Walrus flying boat.
The Supermarine main works was in Woolston, Southampton which led to the city being heavily bombed in 1940. This curtailed work on their first heavy bomber design, the Supermarine B.12/36 which was replaced by the Short Stirling.
After the end of World War Two, the Supermarine division built the Royal Navy's first jet fighter, the Attacker, developed from the final Spitfire type. It served front line squadrons aboard aircraft carriers and RNVR squadrons at shore bases. The Attacker was followed by the more advanced Swift which served in the fighter and photo-reconnaissance roles. 
The last of the Supermarine aircraft was the Scimitar.
In the shakeup of British aircraft manufacturing, Vickers-Armstrongs (Aircraft) became a part of the British Aircraft Corporation and the individual manufacturing heritage names were lost. Northshore Marine Motor Yachts now builds a range of motorboats under the Supermarine name in Chichester, Portsmouth, England. The name is also used for Spitfire replicas made by an Australian company in Cisco, Texas. 
Current company.
The name was revived in 1990 by a company in Burslem called Supermarine Aero Engineering Ltd. that handbuilds parts for Spitfire planes.
Supermarine aircraft.
Designs and submissions only

</doc>
<doc id="27550" url="https://en.wikipedia.org/wiki?curid=27550" title="List of Spanish-language poets">
List of Spanish-language poets

This is a list of notable poets who have written in the Spanish language.
Mexico.
"List of Mexican poets"

</doc>
<doc id="27553" url="https://en.wikipedia.org/wiki?curid=27553" title="Set theory">
Set theory

Set theory is the branch of mathematical logic that studies sets, which informally are collections of objects. Although any type of object can be collected into a set, set theory is applied most often to objects that are relevant to mathematics. The language of set theory can be used in the definitions of nearly all mathematical objects.
The modern study of set theory was initiated by Georg Cantor and Richard Dedekind in the 1870s. After the discovery of paradoxes in naive set theory, numerous axiom systems were proposed in the early twentieth century, of which the Zermelo–Fraenkel axioms, with the axiom of choice, are the best-known.
Set theory is commonly employed as a foundational system for mathematics, particularly in the form of Zermelo–Fraenkel set theory with the axiom of choice. Beyond its foundational role, set theory is a branch of mathematics in its own right, with an active research community. Contemporary research into set theory includes a diverse collection of topics, ranging from the structure of the real number line to the study of the consistency of large cardinals.
History.
Mathematical topics typically emerge and evolve through interactions among many researchers. Set theory, however, was founded by a single paper in 1874 by Georg Cantor: "On a Property of the Collection of All Real Algebraic Numbers".
Since the 5th century BC, beginning with Greek mathematician Zeno of Elea in the West and early Indian mathematicians in the East, mathematicians had struggled with the concept of infinity. Especially notable is the work of Bernard Bolzano in the first half of the 19th century. Modern understanding of infinity began in 1867–71, with Cantor's work on number theory. An 1872 meeting between Cantor and Richard Dedekind influenced Cantor's thinking and culminated in Cantor's 1874 paper.
Cantor's work initially polarized the mathematicians of his day. While Karl Weierstrass and Dedekind supported Cantor, Leopold Kronecker, now seen as a founder of mathematical constructivism, did not. Cantorian set theory eventually became widespread, due to the utility of Cantorian concepts, such as one-to-one correspondence among sets, his proof that there are more real numbers than integers, and the "infinity of infinities" ("Cantor's paradise") resulting from the power set operation. This utility of set theory led to the article "Mengenlehre" contributed in 1898 by Arthur Schoenflies to Klein's encyclopedia.
The next wave of excitement in set theory came around 1900, when it was discovered that Cantorian set theory gave rise to several contradictions, called antinomies or paradoxes. Bertrand Russell and Ernst Zermelo independently found the simplest and best known paradox, now called Russell's paradox: consider "the set of all sets that are not members of themselves", which leads to a contradiction since it must be a member of itself, and not a member of itself. In 1899 Cantor had himself posed the question "What is the cardinal number of the set of all sets?", and obtained a related paradox. Russell used his paradox as a theme in his 1903 review of continental mathematics in his "The Principles of Mathematics".
In 1906 English readers were treated to "Theory of Sets of Points" by William Henry Young and his wife Grace Chisholm Young, published by Cambridge University Press.
The momentum of set theory was such that debate on the paradoxes did not lead to its abandonment. The work of Zermelo in 1908 and Abraham Fraenkel in 1922 resulted in the set of axioms ZFC, which became the most commonly used set of axioms for set theory. The work of analysts such as Henri Lebesgue demonstrated the great mathematical utility of set theory, which has since become woven into the fabric of modern mathematics. Set theory is commonly used as a foundational system, although in some areas category theory is thought to be a preferred foundation.
Basic concepts and notation.
Set theory begins with a fundamental binary relation between an object and a set . If is a member (or element) of , write . Since sets are objects, the membership relation can relate sets as well.
A derived binary relation between two sets is the subset relation, also called set inclusion. If all the members of set are also members of set , then is a subset of , denoted . For example, is a subset of , and so is but is not. From this definition, it is clear that a set is a subset of itself; for cases where one wishes to rule this out, the term proper subset is defined. is called a proper subset of if and only if is a subset of , but is not a subset of . Note also that 1 and 2 and 3 are members (elements) of set , but are "not" subsets, and the subsets in turn are "not" as such members of the set.
Just as arithmetic features binary operations on numbers, set theory features binary operations on sets. The:
Some basic sets of central importance are the empty set (the unique set containing no elements), the set of natural numbers, and the set of real numbers.
Some ontology.
A set is pure if all of its members are sets, all members of its members are sets, and so on. For example, the set containing only the empty set is a nonempty pure set. In modern set theory, it is common to restrict attention to the von Neumann universe of pure sets, and many systems of axiomatic set theory are designed to axiomatize the pure sets only. There are many technical advantages to this restriction, and little generality is lost, because essentially all mathematical concepts can be modeled by pure sets. Sets in the von Neumann universe are organized into a cumulative hierarchy, based on how deeply their members, members of members, etc. are nested. Each set in this hierarchy is assigned (by transfinite recursion) an ordinal number α, known as its rank. The rank of a pure set X is defined to be the least upper bound of all successors of ranks of members of X. For example, the empty set is assigned rank 0, while the set containing only the empty set is assigned rank 1. For each ordinal α, the set "V"α is defined to consist of all pure sets with rank less than α. The entire von Neumann universe is denoted "V".
Axiomatic set theory.
Elementary set theory can be studied informally and intuitively, and so can be taught in primary schools using Venn diagrams. The intuitive approach tacitly assumes that a set may be formed from the class of all objects satisfying any particular defining condition. This assumption gives rise to paradoxes, the simplest and best known of which are Russell's paradox and the Burali-Forti paradox. Axiomatic set theory was originally devised to rid set theory of such paradoxes.
The most widely studied systems of axiomatic set theory imply that all sets form a cumulative hierarchy. Such systems come in two flavors, those whose ontology consists of:
The above systems can be modified to allow urelements, objects that can be members of sets but that are not themselves sets and do not have any members.
The systems of New Foundations NFU (allowing urelements) and NF (lacking them) are not based on a cumulative hierarchy. NF and NFU include a "set of everything, " relative to which every set has a complement. In these systems urelements matter, because NF, but not NFU, produces sets for which the axiom of choice does not hold.
Systems of constructive set theory, such as CST, CZF, and IZF, embed their set axioms in intuitionistic instead of classical logic. Yet other systems accept classical logic but feature a nonstandard membership relation. These include rough set theory and fuzzy set theory, in which the value of an atomic formula embodying the membership relation is not simply True or False. The Boolean-valued models of ZFC are a related subject.
An enrichment of ZFC called Internal Set Theory was proposed by Edward Nelson in 1977.
Applications.
Many mathematical concepts can be defined precisely using only set theoretic concepts. For example, mathematical structures as diverse as graphs, manifolds, rings, and vector spaces can all be defined as sets satisfying various (axiomatic) properties. Equivalence and order relations are ubiquitous in mathematics, and the theory of mathematical relations can be described in set theory.
Set theory is also a promising foundational system for much of mathematics. Since the publication of the first volume of "Principia Mathematica", it has been claimed that most or even all mathematical theorems can be derived using an aptly designed set of axioms for set theory, augmented with many definitions, using first or second order logic. For example, properties of the natural and real numbers can be derived within set theory, as each number system can be identified with a set of equivalence classes under a suitable equivalence relation whose field is some infinite set.
Set theory as a foundation for mathematical analysis, topology, abstract algebra, and discrete mathematics is likewise uncontroversial; mathematicians accept that (in principle) theorems in these areas can be derived from the relevant definitions and the axioms of set theory. Few full derivations of complex mathematical theorems from set theory have been formally verified, however, because such formal derivations are often much longer than the natural language proofs mathematicians commonly present. One verification project, Metamath, includes human-written, computer‐verified derivations of more than 12, 000 theorems starting from ZFC set theory, first order logic and propositional logic.
Areas of study.
Set theory is a major area of research in mathematics, with many interrelated subfields.
Combinatorial set theory.
Combinatorial set theory concerns extensions of finite combinatorics to infinite sets. This includes the study of cardinal arithmetic and the study of extensions of Ramsey's theorem such as the Erdős–Rado theorem.
Descriptive set theory.
Descriptive set theory is the study of subsets of the real line and, more generally, subsets of Polish spaces. It begins with the study of pointclasses in the Borel hierarchy and extends to the study of more complex hierarchies such as the projective hierarchy and the Wadge hierarchy. Many properties of Borel sets can be established in ZFC, but proving these properties hold for more complicated sets requires additional axioms related to determinacy and large cardinals.
The field of effective descriptive set theory is between set theory and recursion theory. It includes the study of lightface pointclasses, and is closely related to hyperarithmetical theory. In many cases, results of classical descriptive set theory have effective versions; in some cases, new results are obtained by proving the effective version first and then extending ("relativizing") it to make it more broadly applicable.
A recent area of research concerns Borel equivalence relations and more complicated definable equivalence relations. This has important applications to the study of invariants in many fields of mathematics.
Fuzzy set theory.
In set theory as Cantor defined and Zermelo and Fraenkel axiomatized, an object is either a member of a set or not. In fuzzy set theory this condition was relaxed by Lotfi A. Zadeh so an object has a "degree of membership" in a set, a number between 0 and 1. For example, the degree of membership of a person in the set of "tall people" is more flexible than a simple yes or no answer and can be a real number such as 0.75.
Inner model theory.
An inner model of Zermelo–Fraenkel set theory (ZF) is a transitive class that includes all the ordinals and satisfies all the axioms of ZF. The canonical example is the constructible universe "L" developed by Gödel.
One reason that the study of inner models is of interest is that it can be used to prove consistency results. For example, it can be shown that regardless of whether a model "V" of ZF satisfies the continuum hypothesis or the axiom of choice, the inner model "L" constructed inside the original model will satisfy both the generalized continuum hypothesis and the axiom of choice. Thus the assumption that ZF is consistent (has at least one model) implies that ZF together with these two principles is consistent.
The study of inner models is common in the study of determinacy and large cardinals, especially when considering axioms such as the axiom of determinacy that contradict the axiom of choice. Even if a fixed model of set theory satisfies the axiom of choice, it is possible for an inner model to fail to satisfy the axiom of choice. For example, the existence of sufficiently large cardinals implies that there is an inner model satisfying the axiom of determinacy (and thus not satisfying the axiom of choice).
Large cardinals.
A large cardinal is a cardinal number with an extra property. Many such properties are studied, including inaccessible cardinals, measurable cardinals, and many more. These properties typically imply the cardinal number must be very large, with the existence of a cardinal with the specified property unprovable in Zermelo-Fraenkel set theory.
Determinacy.
Determinacy refers to the fact that, under appropriate assumptions, certain two-player games of perfect information are determined from the start in the sense that one player must have a winning strategy. The existence of these strategies has important consequences in descriptive set theory, as the assumption that a broader class of games is determined often implies that a broader class of sets will have a topological property. The axiom of determinacy (AD) is an important object of study; although incompatible with the axiom of choice, AD implies that all subsets of the real line are well behaved (in particular, measurable and with the perfect set property). AD can be used to prove that the Wadge degrees have an elegant structure.
Forcing.
Paul Cohen invented the method of forcing while searching for a model of ZFC in which the continuum hypothesis fails, or a model of ZF in which the axiom of choice fails. Forcing adjoins to some given model of set theory additional sets in order to create a larger model with properties determined (i.e. "forced") by the construction and the original model. For example, Cohen's construction adjoins additional subsets of the natural numbers without changing any of the cardinal numbers of the original model. Forcing is also one of two methods for proving relative consistency by finitistic methods, the other method being Boolean-valued models.
Cardinal invariants.
A cardinal invariant is a property of the real line measured by a cardinal number. For example, a well-studied invariant is the smallest cardinality of a collection of meagre sets of reals whose union is the entire real line. These are invariants in the sense that any two isomorphic models of set theory must give the same cardinal for each invariant. Many cardinal invariants have been studied, and the relationships between them are often complex and related to axioms of set theory.
Set-theoretic topology.
Set-theoretic topology studies questions of general topology that are set-theoretic in nature or that require advanced methods of set theory for their solution. Many of these theorems are independent of ZFC, requiring stronger axioms for their proof. A famous problem is the normal Moore space question, a question in general topology that was the subject of intense research. The answer to the normal Moore space question was eventually proved to be independent of ZFC.
Objections to set theory as a foundation for mathematics.
From set theory's inception, some mathematicians have objected to it as a foundation for mathematics. The most common objection to set theory, one Kronecker voiced in set theory's earliest years, starts from the constructivist view that mathematics is loosely related to computation. If this view is granted, then the treatment of infinite sets, both in naive and in axiomatic set theory, introduces into mathematics methods and objects that are not computable even in principle. The feasibility of constructivism as a substitute foundation for mathematics was greatly increased by Errett Bishop's influential book "Foundations of Constructive Analysis".
A different objection put forth by Henri Poincaré is that defining sets using the axiom schemas of specification and replacement, as well as the axiom of power set, introduces impredicativity, a type of circularity, into the definitions of mathematical objects. The scope of predicatively founded mathematics, while less than that of the commonly accepted Zermelo-Fraenkel theory, is much greater than that of constructive mathematics, to the point that Solomon Feferman has said that "all of scientifically applicable analysis can be developed predicative methods".
Ludwig Wittgenstein condemned set theory. He wrote that "set theory is wrong", since it builds on the "nonsense" of fictitious symbolism, has "pernicious idioms", and that it is nonsensical to talk about "all numbers". Wittgenstein's views about the foundations of mathematics were later criticised by Georg Kreisel and Paul Bernays, and investigated by Crispin Wright, among others.
Category theorists have proposed topos theory as an alternative to traditional axiomatic set theory. Topos theory can interpret various alternatives to that theory, such as constructivism, finite set theory, and computable set theory. Topoi also give a natural setting for forcing and discussions of the independence of choice from ZF, as well as providing the framework for pointless topology and Stone spaces.
An active area of research is the univalent foundations arising from homotopy type theory. Here, sets may be defined as certain kinds of types, with universal properties of sets arising from higher inductive types. Principles such as the axiom of choice and the law of the excluded middle appear in a spectrum of different forms, some of which can be proven, others which correspond to the classical notions; this allows for a detailed discussion of the effect of these axioms on mathematics.

</doc>
<doc id="27557" url="https://en.wikipedia.org/wiki?curid=27557" title="Sabine Baring-Gould">
Sabine Baring-Gould

Rev. Sabine Baring-Gould (28 January 1834 – 2 January 1924) of Lew Trenchard in Devon, England, was an Anglican priest, hagiographer, antiquarian, novelist and eclectic scholar. His bibliography consists of more than 1240 publications, though this list continues to grow. His family home, the manor house of Lew Trenchard, near Okehampton, Devon, has been preserved as he had it rebuilt and is now a hotel. He is remembered particularly as a writer of hymns, the best-known being "Onward, Christian Soldiers" and "Now the Day Is Over". He also translated the carol "Gabriel's Message" from the Basque language to English.
Origins.
Sabine Baring-Gould was born in the parish of St Sidwell, Exeter on 28 January 1834. He was the eldest son and heir of Edward Baring-Gould (1804-1872), lord of the manor of Lew Trenchard, a Justice of the Peace and Deputy Lieutenant of Devon, formerly a lieutenant in the Madras Light Cavalry (resigned 1830), by his first wife, Sophia Charlotte Bond, daughter of Admiral Francis Godolphin Bond, Royal Navy.
Sabine's paternal grandfather was William Baring (d.1846), JP, DL, who in 1795 had assumed by royal licence the additional surname and arms of Gould, in accordance with the terms of his inheritance of the manor of Lew Trenchard from his mother Margaret Gould, daughter and eventual heiress in her issue of William Drake Gould (1719–1767) of Lew Trenchard. The Gould family was descended from a certain John Gold, a crusader present at the siege of Damietta in 1217 who for his valour was granted in 1220 by Ralph de Vallibus an estate at Seaborough in Somerset. Margaret Gould was the wife of Charles Baring (1742-1829) of Courtland in the parish of Exmouth, Devon, whose monument survives in Lympstone Church, 4th son of Johann Baring (1697–1748), of Larkbeare House, Exeter, a German immigrant apprenticed to an Exeter wool merchant, and younger brother of Sir Francis Baring, 1st Baronet (1740–1810) and John Baring (1730–1816) of Mount Radford, Exeter, which latter two established the London merchant house of "John and Francis Baring Company", which eventually became Barings Bank.
Sabine was named after the family of his grandmother, Diana Amelia Sabine (d.1858), wife of William Baring-Gould (d.1846), daughter of Joseph Sabine of Tewin, Hertfordshire and sister of the Arctic explorer General Sir Edward Sabine.
Career.
Because the family spent much of his childhood travelling round Europe, most of his education was by private tutors. He only spent about two years in formal schooling, first at King's College School in London (then located in Somerset House) and then, for a few months, at Warwick Grammar School (now Warwick School). Here his time was ended by a bronchial disease of the kind that was to plague him throughout his long life. His father considered his ill-health as a good reason for another European tour.
In 1852 he was admitted to Cambridge University, earning the degrees of Bachelor of Arts in 1857, then Master of Arts in 1860 from Clare College, Cambridge. In September 1853 he informed Nathaniel Woodard of his desire to be ordained. He taught for only ten days at one of Woodard's boys' boarding schools in Sussex, Lancing College, but then moved to another, Hurstpierpoint College, where he stayed from 1857 to 1864. While there he was responsible for several subjects, especially languages and science, and he also designed the ironwork of the bookcases in the boys' library, as well as painting the window jambs with scenes from the "Canterbury Tales" and the "Faery Queen".
He took Holy Orders in 1864, and became the curate at Horbury Bridge, West Riding of Yorkshire. It was while acting as a curate that he met Grace Taylor, the daughter of a mill hand, then aged fourteen. In the next few years they fell in love. His vicar, John Sharp, arranged for Grace to live for two years with relatives in York to learn middle class manners. Baring-Gould, meanwhile, relocated to become perpetual curate at Dalton, near Thirsk. He and Grace were married in 1868 at Wakefield.
Their marriage lasted until her death 48 years later, and the couple had 15 children, all but one of whom lived to adulthood. When he buried his wife in 1916 he had carved on her tombstone the Latin motto "Dimidium Animae Meae" ("Half my Soul").
Baring-Gould became the rector of East Mersea in Essex in 1871 and spent ten years there. In 1872 his father died and he inherited the 3,000 acre (12 km²) family estates of Lew Trenchard in Devon, which included the gift of the living of Lew Trenchard parish. When the living became vacant in 1881, he was able to appoint himself to it, becoming parson as well as squire. He did a great deal of work restoring St Peter's Church, Lew Trenchard, and (from 1883 to 1914) thoroughly remodelled his home, Lew Trenchard Manor.
Folk songs.
He regarded his principal achievement to be the collection of folk songs that he made with the help of the ordinary people of Devon and Cornwall. His first book of songs, "Songs and Ballads of the West" (1889–91), was published in four parts between 1889 and 1891. The musical editor for this collection was Henry Fleetwood Sheppard, though some of the songs included were noted by Baring-Gould's other collaborator Frederick Bussell.
Baring-Gould and Sheppard produced a second collection named "A Garland of Country Songs" during 1895. A new edition of "Songs of the West" was proposed for publication in 1905. Sheppard had died in 1901 and so the folk song collector Cecil Sharp was invited to undertake the musical editorship for the new edition. Sharp and Baring-Gould also collaborated on "English Folk Songs for Schools" during 1907. This collection of 53 songs was widely used in British schools for the next 60 years.
Although he had to modify the words of some songs which were too rude for the time, he left his original manuscripts for future students of folk song, thereby preserving many beautiful pieces of music and their lyrics which might otherwise have been lost.
A Fair Copy of the folk songs he collected, together with the notebooks used for gathering information in the field, were given by Baring-Gould to Plymouth Public Library in 1914 and deposited with the Plymouth and West Devon Record Office in 2006. These, together with the folk-song manuscripts from Baring-Gould's personal library discovered at Killerton in 1998, were published as a microfiche edition in 1998. In 2011 the complete collection of folk song manuscripts (including two notebooks not included in the microfiches edition) were digitised and published online by the Devon Tradition Project managed by Wren Music in association with the English Folk Dance and Song Society as part of the 'Take Six' project undertaken by the Vaughan Williams Memorial Library. It now forms part of the VWML's 'Full English' website. Thirty boxes of additional manuscript material on other topics (the Killerton manuscripts) are kept in the Devon History Centre in Exeter.
Cecil Sharp dedicated his "English Folk Song—Some Conclusions" to Baring-Gould.
Literature.
Baring-Gould wrote many novels including "The Broom-Squire" set in the Devil's Punch Bowl (1896), "Mehalah" and "Guavas, the Tinner" (1897), a collection of ghost stories, a 16-volume "The Lives of the Saints", and the biography of the eccentric poet-vicar of Morwenstow, Robert Stephen Hawker. His folkloric studies resulted in "The Book of Were-Wolves" (1865), one of the most frequently cited studies of lycanthropy. He habitually wrote while standing, and his desk can be seen in the manor.
One of his most enduringly popular works was "Curious Myths of the Middle Ages," first published in two parts during 1866 and 1868, and republished in many other editions since then. "Each of the book's twenty-four chapters deals with a particular medieval superstition and its variants and antecedents," writes critic Steven J. Mariconda. H. P. Lovecraft termed it "that curious body of medieval lore which the late Mr. Baring-Gould so effectively assembled in book form."
He wrote much about the Westcountry: his works of this topic include:
Baring-Gould served as President of the Royal Institution of Cornwall for ten years from 1897.
Dartmoor.
Baring-Gould, along with his friend Robert Burnard, organised the first scientific archaeological excavations of hut-circles on Dartmoor at Grimspound during 1893. This resulted in the formation of the Committee of the Devonshire Association for the exploration of Dartmoor. The committee co-opted R. N. Worth, R. Hansford Worth, the Revd W. A. G. Gray and Dr Prowse. Baring-Gould was the Secretary and author of the first ten annual reports until 1905. The Dartmoor Exploration Committee performed many archaeological digs of prehistoric settlements on Dartmoor and systematically recorded and in some cases restored prehistoric sites. The current state of many prehistoric stone rows and stone circles on Dartmoor owes much to the work of Sabine Baring-Gould and Robert Burnard and the Dartmoor Exploration Committee. Baring-Gould was President of the Devonshire Association for the year 1896.
He wrote much about Dartmoor: his works of this topic include:
Family.
He married Grace Taylor on 25 May 1868 at Horbury. They had 15 children: Mary (b. 1869), Margaret Daisy (b. 1870, an artist who painted part of the screen in Lew Trenchard Church), Edward Sabine (b. 1871), Beatrice Gracieuse (b. 1874, d. 1876, aged 2 years), Veronica (b. 1875), Julian (b. 1877), William Drake (b. 1878), Barbara (b. 1880), Diana Amelia (b. 1881), Felicitas (bpt 1883), Henry (b. 1885), Joan (b. 1887), Cecily Sophia (b. 1889), John Hillary (b. 1890), and Grace (b. 1891).
His wife Grace died in April 1916, and he did not remarry; he died on 2 January 1924 at his home at Lew Trenchard and was buried next to his wife.
He wrote two volumes of reminiscences: "Early Reminiscences, 1834–1864" and "Further Reminiscences, 1864–1894".
One grandson, William Stuart Baring-Gould, was a noted Sherlock Holmes scholar who wrote a fictional biography of the great detective—in which, to make up for the lack of information about Holmes's early life, he based his account on the childhood of Sabine Baring-Gould. Sabine himself is a major character of Laurie R. King's Sherlock Holmes novel "The Moor", a Sherlockian pastiche. In this novel it is revealed that Sabine Baring-Gould is the godfather of Sherlock Holmes.

</doc>
<doc id="27558" url="https://en.wikipedia.org/wiki?curid=27558" title="Salt (chemistry)">
Salt (chemistry)

In chemistry, a salt is an ionic compound that results from the neutralization reaction of an acid and a base. Salts are composed of related numbers of cations (positively charged ions) and anions (negative ions) so that the product is electrically neutral (without a net charge). These component ions can be inorganic, such as chloride (Cl−), or organic, such as acetate (); and can be monatomic, such as fluoride (F−), or polyatomic, such as sulfate ().
There are several varieties of salts. Salts that hydrolyze to produce hydroxide ions when dissolved in water are "basic salts", whilst those that hydrolyze to produce hydronium ions in water are "acidic salts". "Neutral salts" are those that are neither acid nor basic salts. Zwitterions contain an anionic centre and a cationic centre in the same molecule, but are not considered to be salts. Examples of zwitterions include amino acids, many metabolites, peptides, and proteins.
Usually, non-dissolved salts at standard temperature and pressure are solid, but there are exceptions (see Molten salts and ionic liquids).
Molten salts and solutions containing dissolved salts (e.g., sodium chloride in water) are called electrolytes, as they are able to conduct electricity. As observed in the cytoplasm of cells, in blood, urine, plant saps and mineral waters, mixtures of many different ions in solution usually do not form defined salts after evaporation of the water. Therefore, their salt content is given for the respective ions.
Properties.
Color.
Salts can appear to be clear and transparent (sodium chloride), opaque, and even metallic and lustrous (iron disulfide). In many cases, the apparent opacity or transparency are only related to the difference in size of the individual monocrystals. Since light reflects from the grain boundaries (boundaries between crystallites), larger crystals tend to be transparent, while the polycrystalline aggregates look like white powders.
Salts exist in many different colors, for example:
Most minerals and inorganic pigments, as well as many synthetic organic dyes, are salts. The color of the specific salt is due to the electronic structure in the d-orbitals of transition elements or in the conjugated organic dye framework.
Taste.
Different salts can elicit all five basic tastes, e.g., salty (sodium chloride), sweet (lead diacetate, which will cause lead poisoning if ingested), sour (potassium bitartrate), bitter (magnesium sulfate), and umami or savory (monosodium glutamate).
Odor.
Salts of strong acids and strong bases ("strong salts") are non-volatile and odorless, whereas salts of either weak acids or weak bases ("weak salts") may smell after the conjugate acid (e.g., acetates like acetic acid (vinegar) and cyanides like hydrogen cyanide (almonds)) or the conjugate base (e.g., ammonium salts like ammonia) of the component ions. That slow, partial decomposition is usually accelerated by the presence of water, since hydrolysis is the other half of the reversible reaction equation of formation of weak salts.
Solubility.
Many ionic compounds can be dissolved in water or other similar solvents. The exact combination of ions involved makes each compound have a unique solubility in any solvent. The solubility is dependent on how well each ion interacts with the solvent, so there are certain patterns. For example, all salts of sodium, potassium and ammonium are soluble in water, as are all nitrates and many sulfates – barium sulfate, calcium sulfate (sparingly soluble) and lead(II) sulfate are examples of exceptions. However, ions that bind tightly to each other and form highly stable lattices are less soluble, because it is harder for these structures to break apart for the compounds to dissolve. For example, most carbonate salts are not soluble in water, such as lead carbonate and barium carbonate. Some soluble carbonate salts are: sodium carbonate, potassium carbonate and ammonium carbonate.
Conductivity.
Solid salts do not conduct electricity. However, liquid salts do. Moreover, solutions of salts also conduct electricity.
Chemical Compound.
The name of a salt starts with the name of the cation (e.g., "sodium" or "ammonium") followed by the name of the anion (e.g., "chloride" or "acetate"). Salts are often referred to only by the name of the cation (e.g., "sodium salt" or "ammonium salt") or by the name of the anion (e.g., "chloride salt" or "acetate salt").
Common salt-forming cations include:
Common salt-forming anions (parent acids in parentheses where available) include:
Formation.
Salts are formed by a chemical reaction between:

</doc>
<doc id="27560" url="https://en.wikipedia.org/wiki?curid=27560" title="Solar deity">
Solar deity

A solar deity (also sun god or sun goddess) is a sky deity who represents the Sun, or an aspect of it, usually by its perceived power and strength. Solar deities and sun worship can be found throughout most of recorded history in various forms.
Overview.
The Neolithic concept of a "solar barge" (also "solar bark", "solar barque", "solar boat" and "sun boat", a mythological representation of the sun riding in a boat) is found in the later myths of ancient Egypt, with Ra and Horus. Predynasty Egyptian beliefs attribute Atum as the sun-god and Horus as a god of the sky and sun. As the Old Kingdom theocracy gained power, early beliefs were incorporated with the expanding popularity of Ra and the Osiris-Horus mythology. Atum became Ra-Atum, the rays of the setting sun. Osiris became the divine heir to Atum's power on Earth and passes his divine authority to his son Horus. Early Egyptian myths imply the sun is within the lioness, Sekhmet, at night and is reflected in her eyes; or that it is within the cow, Hathor, during the night, being reborn each morning as her son ("bull").
Mesopotamian Shamash plays an important role during the Bronze Age, and "my Sun" is eventually used as an address to royalty. Similarly, South American cultures have a tradition of Sun worship, as with the Incan Inti. Svarog is the Slavic god sun and spirit of fire.
Proto-Indo-European religion has a solar chariot, the sun as traversing the sky in a chariot. In Germanic mythology this is "Sol", in Vedic Surya, and in Greek Helios (occasionally referred to as Titan) and (sometimes) as Apollo.
During the Roman Empire, a festival of the birth of the "Unconquered Sun" (or "Dies Natalis Solis Invicti") was celebrated on the winter solstice—the "rebirth" of the sun—which occurred on December 25 of the Julian calendar. In late antiquity, the theological centrality of the sun in some Imperial religious systems suggest a form of a "solar monotheism". The religious commemorations on December 25 were replaced under Christian domination of the Empire with the birthday of Christ.
Africa.
The Tiv people consider the Sun to be the son of the supreme being Awondo and the Moon Awondo's daughter. The Barotse tribe believes that the Sun is inhabited by the sky god Nyambi and the Moon is his wife.
Some Sara people also worship the sun.
Even where the sun god is equated with the supreme being, in some African mythologies he or she does not have any special functions or privileges as compared to other deities. The Ancient Egyptian god of creation, Amun is also believed to reside inside the sun. So is the Akan creator deity, Nyame and the Dogon deity of creation, Nommo. Also in Egypt, there was a religion that worshiped the sun directly, and was among the first monotheistic religions: Atenism.
Sun worship was prevalent in ancient Egyptian religion. The earliest deities associated with the sun are all goddesses: Wadjet, Sekhmet, Hathor, Nut, Bast, Bat, and Menhit. First Hathor, and then Isis, give birth to and nurse Horus and Ra. Hathor the horned-cow is one of the 12 daughters of Ra, gifted with joy and is a wet-nurse to Horus.
From at least the 4th Dynasty of Ancient Egypt, the sun was worshipped as the god Re (pronounced probably as Riya, meaning simply 'the sun'), and portrayed as a falcon headed god surmounted by the solar disk, and surrounded by a serpent. Re supposedly gave warmth to the living body, symbolised as an ankh: a "T" shaped amulet with a looped upper half. The ankh, it was believed, was surrendered with death, but could be preserved in the corpse with appropriate mummification and funerary rites. The supremacy of Re in the Egyptian pantheon was at its highest with the 5th Dynasty, when open air solar temples became common. In the Middle Kingdom of Egypt, Re lost some of his preeminence to Osiris, lord of the West, and judge of the dead. In the New Empire period, the sun became identified with the dung beetle, whose spherical ball of dung was identified with the sun. In the form of the sun disc Aten, the sun had a brief resurgence during the Amarna Period when it again became the preeminent, if not only, divinity for the Pharaoh Akhenaton.
The Sun's movement across the sky represents a struggle between the Pharaoh's soul and an avatar of Osiris. Ra travels across the sky in his solar-boat; at dawn he drives away the demon king Apep. The "solarisation" of several local gods (Hnum-Re, Min-Re, Amon-Re) reaches its peak in the period of the fifth dynasty.
Rituals to the god Amun who became identified with the sun god Ra were often carried out on the top of temple pylons. A Pylon mirrored the hieroglyph for 'horizon' or "akhet", which was a depiction of two hills "between which the sun rose and set", associated with recreation and rebirth. On the first Pylon of the temple of Isis at Philae, the pharaoh is shown slaying his enemies in the presence of Isis, Horus and Hathor.
In the eighteenth dynasty, the earliest-known monotheistic head of state, Akhenaten changed the polytheistic religion of Egypt to a monotheistic one, Atenism of the solar-disk and is the first recorded state monotheism. All other deities were replaced by the Aten, including Amun-Ra, the reigning sun god of Akhenaten's own region. Unlike other deities, the Aten did not have multiple forms. His only image was a disk—a symbol of the sun.
Soon after Akhenaten's death, worship of the traditional deities was reestablished by the religious leaders (Ay the High-Priest of Amen-Ra, mentor of Tutankhaten/Tutankhamen) who had adopted the Aten during the reign of Akhenaten.
Aztec mythology.
In Aztec mythology, "Tonatiuh" (, "Movement of the Sun") was the sun god. The Aztec people considered him the leader of "Tollan" (heaven). He was also known as the fifth sun, because the Aztecs believed that he was the sun that took over when the fourth sun was expelled from the sky. According to their cosmology, each sun was a god with its own cosmic era. According to the Aztecs, they were still in Tonatiuh's era. According to the Aztec creation myth, the god demanded human sacrifice as tribute and without it would refuse to move through the sky. The Aztecs were fascinated by the sun and carefully observed it, and had a solar calendar similar to that of the Maya. Many of today's remaining Aztec monuments have structures aligned with the sun.
In the Aztec calendar, Tonatiuh is the lord of the thirteen days from 1 Death to 13 Flint. The preceding thirteen days are ruled over by Chalchiuhtlicue, and the following thirteen by Tlaloc.
Buddhism.
In Buddhist cosmology, the bodhisattva of the Sun is known as "Sūryaprabha" ("having the light of the sun"); in Chinese he is called "Rigong Riguang Pusa" (The Bright Solar Bodhisattva of the Solar Palace), "Rigong Riguang Tianzi" (The Bright Solar Prince of the Solar Palace), or "Rigong Riguang Zuntian Pusa" (The Greatly Revered Bright Solar Prince of the Solar Palace), one of the 20 or 24 guardian "devas".
Sūryaprabha is often depicted with "Candraprabha" ("having the light of the moon"), called in Chinese "Yuegong Yueguang Pusa" (The Bright Lunar Bodhisattva of the Lunar Palace), "Yuegong Yueguang Tianzi" ( The Bright Lunar Prince of the Lunar Palace), or "Yuegong Yueguang Zuntian Pusa" (The Greatly Revered Bright Lunar Prince of the Lunar Palace). Together with Bhaiṣajyaguru Buddha (Chinese: "Yaoshi Fo") these two bodhisattvas constitute the "Dongfang San Sheng" (Three Holy Sages of the Eastern Quarter). 
Chinese mythology.
In Chinese mythology (cosmology), there were originally ten suns in the sky, who were all brothers. They were supposed to emerge one at a time as commanded by the Jade Emperor. They were all very young and loved to fool around. Once they decided to all go into the sky to play, all at once. This made the world too hot for anything to grow. A hero named Hou Yi shot down nine of them with a bow and arrow to save the people of the earth. He is still honored this very day. In another myth, the solar eclipse was caused by the magical dog of heaven biting off a piece of the sun. The referenced event is said to have occurred around 2,160BCE. There was a tradition in China to make lots of loud celebratory sounds during a solar eclipse to scare the sacred "dog" away.
The Deity of the Sun in Chinese mythology is Ri Gong Tai Yang Xing Jun (Tai Yang Gong / Grandfather Sun) or Star Lord of the Solar Palace, Lord of the Sun. In some mythologies, Tai Yang Xing Jun is believed to be Hou Yi. 
Tai Yang Xing Jun is usually depicted with the Star Lord of the Lunar Palace, Lord of the Moon, Yue Gong Tai Yin Xing Jun (Tai Yin Niang Niang / Lady Tai Yin). Worship of the moon goddess Chang'e and her festivals are very popular among followers of Chinese folk religion and Taoism. Similar to Santa Claus and Christmas in the West, the goddess and her holy days are ingrained in Chinese popular culture.
Baltic mythology.
Those whom practice Dievturība, beliefs of traditional Latvian culture, celebrate the Sun goddess, Saulė and known in traditional Lithuanian beliefs as Saulé. Saule/Saulé is among the most important deities in Baltic mythology/traditions.
Celtic.
Though traditionally gods like Lugh and Belenos have been considered to be male sun gods, this assessment is derived from their identification with the Roman Apollo, and as such this assessment is controversial. The sun in Celtic culture is nowadays assumed to have been feminine, and several goddesses have been proposed as possibly solar in character.
In Irish, the name of the sun, "Grian", is feminine. The figure known as Áine is generally assumed to have been either synonymous with her, or her sister, assuming the role of Summer Sun while Grian was the Winter Sun. Similarly, Étaín has at times been considered to be another theonym associated with the sun; if this is the case, then the pan-Celtic Epona might also have been originally solar in nature, though Roman syncretism pushed her towards a lunar role.
The British Sulis has a name cognate with that of other Indo-European solar deities such as the Greek Helios and Indic Surya, and bears some solar traits like the association with the eye as well as epithets associated with light. The theonym Sulevia, which is more widespread and probably unrelated to Sulis, is sometimes taken to have suggested a pan-Celtic role as a solar goddess. She indeed might have been the "de facto" solar deity of the Celts.
The Welsh Olwen has at times been considered a vestige of the local sun goddess, in part due to the possible etymological association with the wheel and the colours gold, white and red.
Brighid has at times been argued as having had a solar nature, fitting her role as a goddess of fire and light.
Hinduism.
The Ādityas are one of the principal deities of the Vedic classical Hinduism belonging to Solar class. In the Vedas, numerous hymns are dedicated to Mitra, Varuna, Savitr etc.
Even the Gayatri mantra, which is regarded as one of the most sacred of the Vedic hymns is dedicated to Savitr, one of the principal Ādityas. The Adityas are a group of solar deities, from the Brahmana period numbering twelve. The ritual of "sandhyavandanam", performed by Hindus, is an elaborate set of hand gestures and body movements, designed to greet and revere the Sun.
The sun god in Hinduism is an ancient and revered deity. In later Hindu usage, all the Vedic Ādityas lost identity and metamorphosed into one composite deity, Surya, the Sun. The attributes of all other Ādityas merged into that of Surya and the names of all other Ādityas became synonymous with, or epithets of, Surya.
The Ramayana has Rama as a descendant of the Surya, thus belonging to the Suryavansha or the clan of the Sun. The Mahabharata describes one of its warrior heroes, Karna, as being the son of the Pandava mother Kunti and Surya.
The sun god is said to be married to the goddess Ranaadeh, also known as Sanjnya. She is depicted in dual form, being both sunlight and shadow, personified. The goddess is revered in Gujarat and Rajasthan.
The charioteer of Surya is Aruna, who is also personified as the redness that accompanies the sunlight in dawn and dusk. The sun god is driven by a seven-horsed Chariot depicting the seven days of the week.
In India, at Konark, in the state of Odisha, a temple is dedicated to Surya. The Konark Sun Temple has been declared a UNESCO World Heritage Site. Surya is the most prominent of the "navagrahas" or nine celestial objects of the Hindus. "Navagrahas" can be found in almost all Hindu temples. There are further temples dedicated to Surya, one in Arasavilli, Srikakulam District in AndhraPradesh, one in Gujarat at Modhera and another in Rajasthan. The temple at Arasavilli was constructed in such a way that on the day of Radhasaptami, the sun's rays directly fall on the feet of the Sri Suryanarayana Swami, the deity at the temple.
Chhath (Hindi: छठ, also called "Dala Chhath") is an ancient Hindu festival dedicated to Surya, the chief solar deity, unique to Bihar, Jharkhand and the Terai. This major festival is also celebrated in the northeast region of India, Madhya Pradesh, Uttar Pradesh, and parts of Chhattisgarh. Hymns to the sun can be found in the Vedas, the oldest sacred texts of Hinduism. Practiced in different parts of India, the worship of the sun has been described in the Rigveda. There is another festival called Sambha-Dasami, which is celebrated in the state of Odisha for the "surya".
The Gurjars (or Gujjars), were Sun-worshipers and are described as devoted to the feet of the sun god Surya. Their copper-plate grants bear an emblem of the Sun and on their seals too, this symbol is depicted.
Indonesian mythology.
Solar gods have a strong presence in Indonesian mythology. In some cases the Sun is revered as a "father" or "founder" of the tribe. This may apply for the whole tribe or only for the royal and ruling families. This practise is more common in Australia and on the island of Timor, where the tribal leaders are seen as direct heirs to the sun god.
Some of the initiation rites include the second reincarnation of the rite's subject as a "son of the Sun", through a symbolic death and a rebirth in the form of a Sun. These rituals hint that the Sun may have an important role in the sphere of funerary beliefs. Watching the Sun's path has given birth to the idea in some societies that the deity of the Sun descends in to the underworld without dying and is capable of returning afterward. This is the reason for the Sun being associated with functions such as guide of the deceased tribe members to the underworld, as well as with revival of perished. The Sun is a mediator between the planes of the living and the dead.
Theosophy.
The primary local deity in Theosophy is the Solar Logos, "the consciousness of the sun".
Solar myth.
Three theories exercised great influence on nineteenth and early twentieth century mythography, beside the Tree worship of Mannhardt and the Totemism of J. F. McLennan, the "Sun myth" of Alvin Boyd Kuhn and Max Müller.
R. F. Littledale criticized the Sun myth theory when he illustrated that Max Müller on his own principles was himself only a Solar myth, whilst Alfred Lyall delivered a still stronger attack on the same theory and its assumption that tribal gods and heroes, such as those of Homer, were mere reflections of the Sun myth by proving that the gods of certain Rajput clans were really warriors who founded the clans not many centuries ago, and were the ancestors of the present chieftains.
Solar barge and sun chariot.
A "solar barge" (also "solar bark", "solar barque", "solar boat" and "sun boat") is a mythological representation of the sun riding in a boat. The "Khufu ship", a 43.6-meter-long vessel that was sealed into a pit in the Giza pyramid complex at the foot of the Great Pyramid of Giza around 2500 BC, is a full-size surviving example which may have fulfilled the symbolic function of a solar barque. This boat was rediscovered in May 1954 when archeologist Kamal el-Mallakh and inspector Zaki Nur found two ditches sealed off by about 40 blocks weighing 17 to 20 tonnes each. This boat was disassembled into 1,224 pieces and took over 10 years to reassemble. A nearby museum was built to house this boat.
Other sun boats were found in Egypt dating to different pharonic dynasties.
Examples include:
A "sun chariot" is a mythological representation of the sun riding in a chariot. The concept is younger than that of the solar barge, and typically Indo-European, corresponding with the Indo-European expansion after the invention of the chariot in the 2nd millennium BC.
Examples include these:
The sun itself also was compared to a wheel, possibly in Proto-Indo-European, Greek "hēliou kuklos", Sanskrit "suryasya cakram", Anglo-Saxon "sunnan hweogul" (PIE ).
Male and female.
Among modern English speakers, solar deities are popularly thought of as male while the lunar deity is usually female; however sometimes the opposite is seen. The cobra (of Pharaoh Son of Ra), the lioness (daughter of Ra), the cow (daughter of Ra), the dominant symbols of the most ancient Egyptian deities, carried their relationship to the sun atop their heads; they were female and their cults remained active throughout the history of the culture. Later a "sun god" (Aten) was established in the eighteenth dynasty on top of the other solar deities, before the "aberration" was stamped out and the old pantheon re-established. When male deities became associated with the sun in that culture, they began as the offspring of a mother (except Ra, King of the Gods who gave birth to himself).
In Germanic mythology the Sun is female and the Moon is male. The corresponding Old English name is Siȝel , continuing Proto-Germanic *Sôwilô or *Saewelô. The Old High German Sun goddess is Sunna. In the Norse traditions, every day, Sól rode through the sky on her chariot, pulled by two horses named Arvak and Alsvid. Sól also was called Sunna and Frau Sunne, from which are derived the words "sun" and "Sunday".
Other cultures that have sun goddesses include: The Lithuanians and Latvians (Saule), the Finns (Päivätär, Beiwe) and the related Hungarians. Sun goddesses are found around the world; Australia (Bila, Walo), India (Bisal-Mariamna, Bomong, Kn Sgni); among the Hittites (Wurusemu), and Egyptians (Sekhmet). In Native America, among the Cherokee (Unelanuhi), Natchez (Wal Sil), Inuit (Malina) and Miwok (Hekoolas).

</doc>
<doc id="27561" url="https://en.wikipedia.org/wiki?curid=27561" title="Stendhal syndrome">
Stendhal syndrome

Stendhal syndrome, Stendhal's syndrome, hyperkulturemia, or Florence syndrome is a psychosomatic disorder that causes rapid heartbeat, dizziness, fainting, confusion and even hallucinations when an individual is exposed to an experience of great personal significance, particularly viewing art.
History.
The illness is named after the 19th-century French author Stendhal (pseudonym of Marie-Henri Beyle), who described his experience with the phenomenon during his 1817 visit to Florence in his book "Naples and Florence: A Journey from Milan to Reggio".
When he visited the Basilica of Santa Croce, where Niccolò Machiavelli, Michelangelo and Galileo Galilei are buried, he saw Giotto's frescoes for the first time and was overcome with emotion. He wrote:
Although psychiatrists have long debated whether it really exists, its effects on some sufferers are serious enough for them to require treatment in hospital and even antidepressants. The staff at Florence's Santa Maria Nuova hospital are accustomed to dealing with tourists suffering from dizzy spells and disorientation after admiring the statue of David, the masterpieces of the Uffizi Gallery and other treasures of the Tuscan city.
Even though there are many descriptions of people becoming dizzy and fainting while taking in Florentine art, especially at the aforementioned Uffizi in Florence, dating from the early 19th century on, the syndrome was only named in 1979, when it was described by Italian psychiatrist Graziella Magherini, who observed and described more than 100 similar cases among tourists and visitors in Florence. There is no scientific evidence to define the Stendhal syndrome as a specific psychiatric disorder; on the other hand there is evidence that the same cerebral areas involved in emotional reactions are activated during the exposure to artworks.

</doc>
<doc id="27562" url="https://en.wikipedia.org/wiki?curid=27562" title="Spanish proverbs">
Spanish proverbs

Spanish proverbs are a subset of proverbs that are used in Western cultures in general; there are many that have essentially the same form and content as their counterparts in other Western languages. Proverbs that have their origin in Spanish have migrated to and from English, French, Flemish, German and other languages.
Origins.
Many Spanish proverbs have a long history of cultural diffusion; there are proverbs, for example, that have their origin traced to Babylon and that have come down to us through Greece and Rome; equivalents of the Spanish proverb "“En boca cerrada no entran moscas”" (Silence is golden) belong to the cultural tradition of many north-African countries as far as Ethiopia; having gone through multiple languages and millennia, this proverb can be traced back to an ancient Babylonian proverb.
The written evidence of the use of Spanish proverbs goes far back in Spanish literature. "El Cantar de Mio Cid", written at the end of the 11th or the beginning of the 12th century, is the first instance. Examples of other early works that use Spanish proverbs are the "Libro de Buen Amor" by Juan Ruiz (14th century) and "El Corbacho" by Alfonso Martínez de Toledo (15th century). The first anthology of Spanish proverbs, "Proverbios que dicen las viejas tras el fuego", was written by Íñigo López de Mendoza, Marques of Santillana (15th century). Also in the 15th century was written the "Seniloquium", an erudite and anonymous work containing a compendium of Spanish sayings and proverbs with commentaries. The language of the characters in Fernando de Rojas’ "La Celestina" (15th – 16th century) is enlivened with the use of proverbs. And then, of course, in the 17th century there is the incomparable "Don Quijote de la Mancha" by Cervantes.
Sancho Panza, Cervantes’ wonderful, earthy, character, is the essential common man. His thinking habitually relies on the authority he vests in the wealth of popular cultural wisdom expressed in proverbs, which he continually quotes. In almost all his utterances there is reference to one and sometimes to more proverbs. "Don Quijote" is a veritable treasure trove of Spanish proverbs.
There are Spanish proverbs that contradict others; the “wisdom” that they encapsulate is not, of course, absolute. People will use those proverbs that best conform to their own particular way of approaching life. Taken together, however, they reveal the deep wellsprings of Spanish culture and of human nature in general.
References.
Cervantes Virtual Centre

</doc>
<doc id="27563" url="https://en.wikipedia.org/wiki?curid=27563" title="Soad Hosny">
Soad Hosny

Soad Hosny (Egyptian Arabic:سعاد حسني January 26, 1942/1943/1944 – June 21, 2001) was an Egyptian actress and singer from Cairo. She was known as the "Cinderella of Egyptian cinema" and one of the most influential actresses in the Middle East. She ascended to stardom at the end of the 1950s, performing in more than 83 films between 1959 and 1991. A majority of her films were shot in the 1960s and 1970s. Her final screen appearance was in the 1991 film, "The Shepherd and the Women", directed by her ex-husband, Ali Badrakhan.
Early life and career.
Soad Muhammad Kamal Hosny was born in Ataba, Cairo, one of three sisters born to Mohammad Hosni and his wife, Jawahara. She also had eight half-siblings. Her parents divorced and her mother remarried, to Abdul Monem Hafedh, with whom she had six more children, thus giving Soad and her two sisters, no fewer than 14 half-siblings. Her father, a Syrian of Kurdish descent, was a calligrapher. Najat Al Saghira, one of Hosny's half-siblings, was an actress and singer.
Hosny's final screen appearance was in 1991 in "Al Ra'i We El Nissa".
Personal life.
Soad Hosny was married four times. Around 1968, she was married to cinematographer Salah Kurayyem; the marriage lasted for approximately one year. In 1970, Hosny was married to the Egyptian film director Ali Badrakhan; this marriage lasted for approximately eleven years. She was then married to Zaki Fateen Abdel-Wahab, son of Fateen Abdel Wahab and Leila Mourad in 1981. This marriage lasted only five months.
Death.
Hosny died after falling from the balcony of her home at Stuart Tower in London on June 21, 2001. Her funeral in Cairo was attended by some 10,000 people. She had no children and was survived by her widower, her last husband, writer Maher Awad, whom she married in 1987.
Latest.
In 2013, Lebanese filmmaker Rania Stephan used snippets from Hosny's films to re-tell Hosny's story and the history of Egyptian cinema in "The Three Disappearances of Soad Hosny". It was featured in Berlin's Art Week.

</doc>
<doc id="27566" url="https://en.wikipedia.org/wiki?curid=27566" title="Summer Olympic Games">
Summer Olympic Games

The Summer Olympic Games or the Games of the Olympiad (), first held in 1896, are an international multi-sport event, occurring every four years, organized by the International Olympic Committee. Medals are awarded in each event, with gold medals for first place, silver for second and bronze for third, a tradition that started in 1904. The Winter Olympic Games were also created due to the success of the Summer Olympics.
The Olympics have increased from a 42-event competition with fewer than 250 male competitors from 14 nations to a 300-event sporting celebration with over 10,000 competitors from 205 nations. Organizers for the 2008 Summer Olympics in Beijing expected approximately 10,500 competitors to take part in the 302 events on the program for the games.
Eighteen countries have hosted the Summer Olympics, with Great Britain 2012 being the most recent. The United States has hosted four Summer Olympics (1904, 1932, 1984, and 1996), more than any other nation, and Great Britain has hosted three Summer Olympics (1908, 1948, and 2012), all in London. Three cities have hosted two Summer Olympics: Los Angeles (1932 and 1984), Paris (1900 and 1924), and Athens (1896 and 2004).
The only Olympics held in the Southern Hemisphere so far have both been in Australia (Melbourne 1956 and Sydney 2000). In 2016, Rio de Janeiro will host the first Summer Games in South America.
Five countries – Greece, Australia, France, Great Britain and Switzerland – have been represented at all Summer Olympic Games. The only country to have won at least one gold medal at every Summer Olympic Games is Great Britain. The United States leads the all-time medal table.
Qualification.
Qualification rules for each of the Olympic sports are set by the International Sports Federations (IFs) that governs that sport's international competition.
For individual sports, competitors typically qualify through attaining a certain place in a major international event or on the IF's ranking list. There is a general rule that maximum three individual athletes may represent each nation per competition. National Olympic committees may enter a limited number of qualified competitors in each event, and the NOC decides which qualified competitors to select as representatives in each event if more have attained the benchmark than can be entered.
Nations most often qualify teams for team sports through continental qualifying tournaments, in which each continental association is given a certain number of sports in the Olympic tournament. Each nation may be represented by no more than one team per competition .
Hosting.
The United States has hosted four Summer Olympic Games, more than any other nation. The United Kingdom hosted the 2012 Olympic games, its third Summer Olympic Games, in its capital London, making London the first city to host the Summer Olympic Games three times. Australia, France, Germany and Greece have all hosted the Summer Olympic Games twice. Other countries that have hosted the Summer Olympics are Belgium, China, Canada, Finland, Italy, Japan, Mexico, Netherlands, South Korea, Spain, the Soviet Union and Sweden. In 2016, Rio de Janeiro will host the first Summer Games in South America. Three cities have hosted two Summer Olympic Games: Los Angeles, Paris and Athens. Stockholm, Sweden, has hosted events at two Summer Olympic Games, having hosted the games in 1912 and the equestrian events at the 1956 Summer Olympics—which they are usually listed as jointly hosting. Events at the Summer Olympics have also been held in Hong Kong and the Netherlands, with the equestrian events at the 2008 Summer Olympics being held in Sha Tin and Kwu Tung, Hong Kong and two sailing races at the 1920 Summer Olympics being held in Amsterdam, the Netherlands. For the 2020 Summer Olympics, Tokyo, Japan will be the host city, hosting for the second time, the first being the 1964 Summer Games. The hosting of Summer Olympic Games through history have predominantly occurred in Anglosphere and European nations.
History.
Early years.
The modern Olympic Games were founded in 1894 when Pierre de Coubertin sought to promote international understanding through sporting competition. He based his Olympics on the Wenlock Olympian Society Annual Games, which had been contested in Much Wenlock since 1850. The first edition of de Coubertin's games, held in Athens in 1896, attracted just 245 competitors, of whom more than 200 were Greek, and only 14 countries were represented. Nevertheless, no international events of this magnitude had been organized before. Female athletes were not allowed to compete, though one woman, Stamata Revithi, ran the marathon course on her own, saying "f the committee doesn't let me compete I will go after them regardless".
The 1896 Summer Olympics, officially known as the Games of the I Olympiad, was an international multi-sport event which was celebrated in Athens, Greece, from 6 to 15 April 1896. It was the first Olympic Games held in the Modern era. About 100,000 people attended for the opening of the games. The athletes came from 14 different nations, with most coming from Greece. Although that Greece had the most athletes, the U.S. finished with the most champions. 11 Americans placed first in their events vs. the 10 from Greece. Ancient Greece was the birthplace of the Olympic Games, consequently Athens was perceived to be an appropriate choice to stage the inaugural modern Games. It was unanimously chosen as the host city during a congress organized by Pierre de Coubertin, a French pedagogue and historian, in Paris, on 23 June 1894. The International Olympic Committee (IOC) was also established during this congress.
Despite many obstacles and setbacks, the 1896 Olympics were regarded as a great success. The Games had the largest international participation of any sporting event to that date. Panathinaiko Stadium, the first big stadium in the modern world, overflowed with the largest crowd ever to watch a sporting event. The highlight for the Greeks was the marathon victory by their compatriot Spiridon Louis, a water carrier. He won at the Olympics in 2 hours 58 minutes and 50 seconds, setting off wild celebrations at the stadium. The most successful competitor was German wrestler and gymnast Carl Schuhmann, who won four gold medals.
After the Games, Coubertin and the IOC were petitioned by several prominent figures including Greece's King George and some of the American competitors in Athens, to hold all the following Games in Athens. However, the 1900 Summer Olympics were already planned for Paris and, except for the 1906 Intercalated Games, the Olympics did not return to Greece until the 2004 Summer Olympics.
Four years later the 1900 Summer Olympics in Paris attracted more than four times as many athletes, including 20 women, who were allowed to officially compete for the first time, in croquet, golf, sailing, and tennis. The Games were integrated with the Paris World's Fair and lasted over 5 months. It is still disputed which events exactly were "Olympic", since few or maybe even none of the events were advertised as such at the time.
Numbers declined for the 1904 Games in St. Louis, Missouri, United States, due in part to the lengthy transatlantic boat trip required of the European competitors, and the integration with the Louisiana Purchase Exposition World's Fair, which again spread the event out over an extended period. In contrast with Paris 1900, the word "Olympic" was used for practically every contest, including those exclusively for school boys or for Irish-Americans.
A series of smaller games were held in Athens in 1906. The IOC does not currently recognize these games as being official Olympic Games, although many historians do. The 1906 Athens games were the first of an alternating series of games to be held in Athens, but the series failed to materialize. The games were more successful than the 1900 and 1904 games, with over 900 athletes competing, and contributed positively to the success of future games.
The 1908 London Games saw numbers rise again, as well as the first running of the marathon over its now-standard distance of 42.195 km (26 miles 385 yards). The first Olympic Marathon in 1896 (a male-only race) was raced at a distance of 40 km (24 miles 85 yards). The new marathon distance was chosen to ensure that the race finished in front of the box occupied by the British royal family. Thus the marathon had been for the first games in 1896, but was subsequently varied by up to due to local conditions such as street and stadium layout. At the six Olympic games between 1900 and 1920, the marathon was raced over six different distances.
At the end of the 1908 marathon the Italian runner Dorando Pietri was first to enter the stadium, but he was clearly in distress, and collapsed of exhaustion before he could complete the event. He was helped over the finish line by concerned race officials, but later he was disqualified and the gold medal was awarded to John Hayes, who had trailed him by around 30 seconds.
The Games continued to grow, attracting 2,504 competitors, to Stockholm in 1912, including the great all-rounder Jim Thorpe, who won both the decathlon and pentathlon. Thorpe had previously played a few games of baseball for a fee, and saw his medals stripped for this breach of amateurism after complaints from Avery Brundage. They were reinstated in 1983, 30 years after his death. The Games at Stockholm were the first to fulfill Pierre de Coubertin's original idea. For the first time since the Games started in 1896 were all five inhabited continents represented with athletes competing in the same stadium.
The scheduled 1916 Summer Olympics were cancelled following the onset of World War I.
Interwar era.
The 1920 Antwerp games in war-ravaged Belgium were a subdued affair, but again drew a record number of competitors. This record only stood until 1924, when the Paris Games involved 3,000 competitors, the greatest of whom was Finnish runner Paavo Nurmi. The "Flying Finn" won three team gold medals and the individual 1,500 and 5,000 meter runs, the latter two on the same day.
The 1928 Amsterdam games were notable for being the first games which allowed females to compete at track & field athletics, and benefited greatly from the general prosperity of the times alongside the first appearance of sponsorship of the games, from Coca-Cola. The 1928 games saw the introduction of a standard medal design with the IOC choosing Giuseppe Cassioli's depiction of Greek goddess Nike and a winner being carried by a crowd of people. This design was used up until 1972.
The 1932 Los Angeles games were affected by the Great Depression, which contributed to the low number of competitors (the fewest since the St. Louis games). The 1936 Berlin Games were seen by the German government as a golden opportunity to promote their ideology. The ruling Nazi Party commissioned film-maker Leni Riefenstahl to film the games. The result, "Olympia", was a masterpiece, despite Hitler's theories of Aryan racial superiority being repeatedly shown up by "non-Aryan" athletes. In particular, African-American sprinter and long jumper Jesse Owens won four gold medals. The tale of Hitler snubbing Owens at the ensuing medal ceremony is a myth. The 1936 Berlin Games also saw the reintroduction of the Torch Relay.
Due to World War II, the Games of 1940 (due to be held in Tokyo and temporarily relocated to Helsinki upon the outbreak of war) were cancelled. The Games of 1944 were due to be held in London but were also cancelled; instead, London hosted the first games after the end of the war, in 1948.
After World War II.
The first post-war Games were held in 1948 in London, with both Germany and Japan excluded. Dutch sprinter Fanny Blankers-Koen won four gold medals on the track, emulating Owens' achievement in Berlin.
At the 1952 Games in Helsinki the USSR team competed for the first time and immediately became one of the dominant teams. Finland made a legend of an amiable Czechoslovak army lieutenant named Emil Zátopek, who was intent on improving on his single gold and silver medals from 1948. Having first won both the 10,000 and 5,000 meter races, he also entered the marathon, despite having never previously raced at that distance. Pacing himself by chatting with the other leaders, Zátopek led from about half way, slowly dropping the remaining contenders to win by two and a half minutes, and completed a trio of wins.
The 1956 Melbourne Games were largely successful, barring a water polo match between Hungary and the Soviet Union, which political tensions caused to end as a pitched battle between the teams. Due to a foot-and-mouth disease outbreak in Britain at the time and the strict quarantine laws of Australia, the equestrian events were held in Stockholm.
At the 1960 Rome Games a young light-heavyweight boxer named Cassius Clay, later known as Muhammad Ali, arrived on the scene. Ali would later throw his gold medal away in disgust after being refused service in a whites-only restaurant in his home town of Louisville, Kentucky. Soviet women's artistic gymnastics team members won 15 of 16 possible medals. Other performers of note in 1960 included Wilma Rudolph, a gold medalist in the 100 meters, 200 meters and 4 × 100 meters relay events.
The 1964 Games held in Tokyo are notable for heralding the modern age of telecommunications. These games were the first to be broadcast worldwide on television, enabled by the recent advent of communication satellites. The 1964 Games were thus a turning point in the global visibility and popularity of the Olympics. Judo debuted as an official sport, and Dutch judoka Anton Geesink created quite a stir when he won the final of the open weight division, defeating Akio Kaminaga in front of his home crowd.
Performances at the 1968 Mexico City games were affected by the altitude of the host city, specifically the long jump, in which American athlete Bob Beamon jumped 8.90 meters. Beamon's world record would stand for 23 years. The 1968 Games also introduced the now-universal Fosbury flop, a technique which won American high jumper Dick Fosbury the gold medal. Politics took center stage in the medal ceremony for the men's 200 meter dash, where Tommie Smith and John Carlos made a protest gesture on the podium against the segregation in the United States; their political act was condemned within the Olympic Movement, but was praised in the Black Power movement.
Politics again intervened at Munich in 1972, with lethal consequences. A Palestinian terrorist group named Black September invaded the Olympic village and broke into the apartment of the Israeli delegation. They killed two Israelis and held 9 others as hostages. The terrorists demanded that Israel release numerous prisoners. When the Israeli government refused their demand, a tense stand-off ensued while negotiations continued. Eventually the captors, still holding their hostages, were offered safe passage and taken to an airport, where they were ambushed by German security forces. In the firefight that followed, 15 people, including the nine Israeli athletes and five of the terrorists, were killed. After much debate, it was decided that the Games would continue, but proceedings were obviously dominated by these events. Some memorable athletic achievements did occur during these Games, notably the winning of a then-record seven gold medals by United States swimmer Mark Spitz, Lasse Virén (of Finland)'s back-to-back gold in the 5,000 meters and 10,000 meters (defeating American distance running great Steve Prefontaine in the former), and the winning of three gold medals by 16-year-old Soviet gymnastic sensation Olga Korbut - who thrilled the world with an historic backflip off the high bar. Korbut, however, failed to win the all-around, losing to her teammate Ludmilla Tourischeva.
There was no such tragedy in Montreal in 1976, but bad planning and fraud led to the Games' cost far exceeding the budget. The Montreal Games were the most expensive in Olympic history, until the 2008 Summer Olympics, costing over $5 billion (equivalent to $20 billion in 2006). For a time, it seemed that the Olympics might no longer be a viable financial proposition. In retrospect, the belief that contractors (suspected of being members of the Montreal Mafia) skimmed large sums of money from all levels of contracts while also profiting from the substitution of cheaper building materials of lesser quality, may have contributed to the delays, poor construction and excessive costs. In 1988, one such contractor, Giuseppe Zappia "was cleared of fraud charges that resulted from his work on Olympic facilities after two key witnesses died before testifying at his trial." There was also a boycott by African nations to protest against a recent tour of apartheid-run South Africa by the New Zealand national rugby union team. The Romanian gymnast Nadia Comăneci won the women's individual all around gold medal with two of four possible perfect scores, thus giving birth to a gymnastics dynasty in Romania. Another female gymnast to earn the perfect score and three gold medals there was Nellie Kim of the USSR. Lasse Virén repeated his double gold in the 5,000 meters and 10,000 meters, making him the only athlete to ever win the distance double twice.
End of the 20th century.
Following the Soviet Union's 1979 invasion of Afghanistan, 66 nations, including the United States, Canada, West Germany, and Japan, boycotted the 1980 games held in Moscow. The boycott contributed to the 1980 Games being a less publicised and less competitive affair, which was dominated by the host country.
In 1984 the Soviet Union and 13 Soviet allies reciprocated by boycotting the 1984 Summer Olympics in Los Angeles. Romania, notably, was one of the nations in the Eastern Bloc that did attend the 1984 Olympics. These games were perhaps the first games of a new era to make a profit. The games were again viable, but had become more commercial. Again, without the participation of the Eastern European countries, the 1984 Games were dominated by their host country. The Games were also the first time mainland China (People's Republic) participated.
The 1988 games, in Seoul, were very well planned but the games were tainted when many of the athletes, most notably men's 100 metres winner Ben Johnson, failed mandatory drug tests. Despite splendid drug-free performances by many individuals, the number of people who failed screenings for performance-enhancing chemicals overshadowed the games.
The 1992 Barcelona Games featured increased professionalism among Olympic athletes, exemplified by US basketball's "Dream Team". The 1992 games also saw the reintroduction to the Games of several smaller European states which had been incorporated into the Soviet Union since World War II. These games also saw gymnast Vitaly Scherbo equal the record for most individual gold medals at a single Games set by Eric Heiden in the 1980 Winter Games, with five.
By then the process of choosing a location for the Games had itself become a commercial concern; allegations of corruption rocked the International Olympic Committee. In the Atlanta games in 1996, the highlight was 200 meters runner Michael Johnson annihilating the world record in front of a home crowd. Canadians savored Donovan Bailey's record-breaking gold medal run in the 100-meter dash. This was popularly felt to be an appropriate recompense for the previous national disgrace involving Ben Johnson. There were also emotional scenes, such as when Muhammad Ali, clearly affected by Parkinson's disease, lit the Olympic torch and received a replacement medal for the one he had discarded in 1960. The latter event took place not at the boxing ring but in the basketball arena, at the demand of US television. The atmosphere at the Games was marred, however, when a bomb exploded during the celebration in Centennial Olympic Park. In June 2003, the principal suspect in this bombing, Eric Robert Rudolph, was arrested.
New millennium.
The 2000 Games were held in Sydney, Australia, and showcased individual performances by local favorite Ian Thorpe in the pool, Briton Steve Redgrave who won a rowing gold medal in an unprecedented fifth consecutive Olympics, and Cathy Freeman, an Indigenous Australian whose triumph in the 400 meters united a packed stadium. Eric "the Eel" Moussambani, a swimmer from Equatorial Guinea, had a memorably slow 100 meter freestyle swim that showed that, even in the commercial world of the twentieth century, some of de Coubertin's original vision still remained. The Sydney Games were also memorable for the first appearance of a joint North and South Korean contingent (to a standing ovation) at the opening ceremonies, even if they competed as different countries. Controversy did not escape the 2000 Games in Women's Artistic Gymnastics, in which the vaulting horse was set to the wrong height during the All Around Competition. Several athletes faltered, including Russian Svetlana Khorkina, who had been favored to win gold after qualifying for the competition in first place.
In 2004 the Games returned to their birthplace in Athens, Greece. Greece spent at least $7.2 billion on the Games, including $1.5 billion on security alone. Nonetheless, the Men's Gymnastics events were mired in controversy when it was discovered that Korean gymnast Yang Tae Young had been incorrectly credited with a lower start value, which placed him third behind American Paul Hamm, who won the competition. Later in the event finals, fans halted the Men's High Bar competition with chants of disapproval following the release of the score for Russian Alexei Nemov. Allegations of corrupt judging also marred the event finals in men's still rings. Although unfounded and wildly sensationalized reports of potential terrorism drove crowds away from the preliminary competitions of the first weekend of the games (14–15 August), attendance picked up as the games progressed. Still, a third of the tickets failed to sell. The Athens Games witnessed all 202 NOCs participate with over 11,000 participants.
The 2008 Summer Olympics were held in Beijing, People's Republic of China. This Olympics was the subject of much controversy, especially following the March Tibetan riots. Human rights activists unsuccessfully called for a boycott, and some even compared the 2008 Olympics to the 1936 ones held in Nazi Germany. Several new events were held, including the new discipline of BMX for both men and women. For the first time, women competed in the steeplechase. The fencing program was expanded to include all six events for both men and women. Women had not previously been able to compete in team foil or saber events (although women's team épée and men's team foil were dropped for these Games). Marathon swimming events, over the distance of , were added. In addition, the doubles events in table tennis were replaced by team events. American swimmer Michael Phelps set a record for gold medals at a single Games with eight, and tied the record of most gold medals by a single competitor previously held by both Heiden and Scherbo. Another major star of the Games was Jamaican sprinter Usain Bolt, who became the first male athlete ever to set world records in the finals of both the 100 and 200 metres in the same Games. Equestrian events were held in Hong Kong.
London held the 2012 Summer Olympics, becoming the first city to host the Games three times. In his closing address the IOC President, Jacques Rogge described the Games as "Happy and Glorious". They certainly were for the host nation who won 29 Gold Medals, the best haul for Great Britain since the 1908 Games in London. It was also notable that the United States returned to the top of the medal table after China dominated in 2008. The International Olympic Committee had removed baseball and softball from the 2012 program. On a commercial level the Games were successful as they were the first in history to completely sell out every ticket with as many as 1 million applications for 40,000 tickets for both the Opening Ceremony and the 100m Men's Sprint Final. Such was the demand for tickets to all levels of each event, there was controversy when seats set aside for sponsors and National Delegations went unused in the early days. A system of reallocation was put in place so the empty seats were filled throughout the Games.
Rio de Janeiro, Brazil, will host the 2016 Summer Olympics, becoming the third city in the Southern Hemisphere to host the Olympic Games (after Melbourne, Australia, in 1956 and Sydney, Australia, in 2000), and the first South American city to host the Olympics. In October 2009, the IOC included golf and rugby sevens as part of the Olympic program for Rio de Janeiro. Tokyo, Japan, will host the 2020 Summer Olympics.
All-time medal table.
With reference to the top ten nations and according to official data of the International Olympic Committee.
List of Olympic sports.
Forty-two different sports, spanning 55 different disciplines, have been part of the Olympic program at one point or another. Twenty-eight sports have comprised the schedule for three of the recent games, 2000, 2004, and 2008 Summer Olympics. Due to the removal of baseball and softball, there was a total of 26 sports in the 2012 Games.
The various Olympic Sports federations are grouped under a common umbrella association, called the Association of Summer Olympic International Federations (ASOIF).
Popularity of Olympic sports.
Summer Olympic sports are divided into categories based on popularity, gauged by six categories: television viewing figures (40%), internet popularity (20%), public surveys (15%), ticket requests (10%), press coverage (10%), and number of national federations (5%). The category determines the share the sport's International Federation receives of Olympic revenue. Sports that are new to the 2016 Olympics (rugby and golf) have been placed in Category E.
The current categories are:
List of modern Summer Olympic Games.
"Note: Although the Games of 1916, 1940, and 1944 had been cancelled, the Roman numerals for those Games were still used because the Summer Games' official titles count Olympiads, not the Games themselves, per the Olympic Charter. This contrasts with the Winter Olympic Games, which ignore the cancelled Winter Games of 1940 & 1944 in their numeric count."

</doc>
<doc id="27567" url="https://en.wikipedia.org/wiki?curid=27567" title="Shareware">
Shareware

Shareware is a type of proprietary software which is provided (initially) free of charge to users, who are allowed and encouraged to make and share copies of the program, which helps to distribute it. Shareware is often offered as a download from an Internet website or as a compact disc included with a magazine.
There are many types of shareware, and while they may not require an initial up-front payment, all are intended to generate revenue in one way or another. Some limit use to personal non-commercial purposes only, with purchase of a license required for use in a business enterprise. The software itself may be limited in functionality or be time-limited. Or it may remind you that payment would be appreciated.
Shareware is available on all major personal computer platforms. Titles cover a very wide range of categories including: business, software development, education, home, multimedia, design, drivers, games, and utilities. Because of its minimal overhead and low cost, the shareware model is often the only one practical for distributing non-free software for abandoned or orphaned platforms such as the Atari ST and Amiga.
The term shareware is used in contrast to open-source software, in which the source code is available for anyone to inspect and alter, and freeware, which is software distributed at no cost to the user but without source code being made available. Note that two types of shareware, donationware and freemiums, are also types of freeware.
Types of shareware.
Adware.
Adware, short for "advertising-supported software", is any software package which automatically renders advertisements in order to generate revenue for its author. The advertisements may be in the user interface of the software or on a screen presented to the user during the installation process. The functions may be designed to analyze which Internet sites the user visits and to present advertising pertinent to the types of goods or services featured there. The term is sometimes used to refer to software that displays unwanted advertisements.
On Microsoft Windows, shareware is often packaged with adware. During the install of the intended software, the user is presented with a requirement to agree to the terms of click through licensing or similar licensing which governs the installation of the software.
Demoware.
Demoware is a demonstration version of software. There are generally two types demoware: that which is crippled, and that which has a trial period.
Crippleware.
In software, crippleware means that "vital features of the program such as printing or the ability to save files are disabled until the user purchases a registration key". This allows users to take a close look at the features of a program without being able to use it to generate output.
Trialware.
Trialware is software with a built-in time limit. The user can try out the program until the trial period is up, and then the program automatically stops working, unless the user pays the license fee and receive a code to enter into the program to turn it into a registered version. Trialware has become the norm for online, Software as a Service (SaaS).
The rationale behind trialware is to give potential users the opportunity to try out the program to judge its usefulness before purchasing a license. According to industry research firm Softletter—66% of online companies surveyed had free-trial-to-paying-customer conversion rates of 25% or less. Converting free trials to paid customers is one of the key challenges software providers face. SaaS providers employ a wide range of strategies to nurture leads, and convert them into paid customers.
Donationware.
Donationware is a licensing model that supplies fully operational unrestricted software to the user and requests an optional donation be paid to the programmer or a third-party beneficiary (usually a non-profit). The amount of the donation may also be stipulated by the author, or it may be left to the discretion of the user, based on individual perceptions of the software's value. Since donationware comes fully operational (i.e. not crippleware) with payment optional, it is a type of freeware.
Nagware.
Nagware is a type of shareware that persistently reminds (nags) the user to register it by paying a fee. It usually does this by popping up a message when the user starts the program, or intermittently while the user is using the application. These messages can appear as windows obscuring part of the screen, or as message boxes that can quickly be closed. Some nagware keeps the message up for a certain time period, forcing the user to wait to continue to use the program.
Some titles display a dialog box with payment information and a message that paying will remove the notice, which is usually displayed either upon startup or after an interval while the application is running. These notices are designed to annoy the user into paying.
Freemium.
Freemium works by offering a product or service free of charge (typically digital offerings such as software, content, games, web services or other) while charging a premium for advanced features, functionality, or related products and services. For example, a fully functional feature-limited ("lite") version may be given away for free, with advanced features disabled until a license fee is paid. The word "freemium" is a portmanteau combining the two aspects of the business model: "free" and "premium". It has become a highly popular model, with notable success.
History.
In 1982, Andrew Fluegelman created a program for the IBM PC called PC-Talk, a telecommunications program, and used the term "freeware"; he described it "as an experiment in economics more than altruism". About the same time, Jim "Button" Knopf released PC-File, a database program, calling it "user-supported software". Not much later, Bob Wallace produced PC-Write, a word processor, and called it "shareware". Appearing in an episode of "Horizon" titled "Psychedelic Science" originally broadcast 5 April 1998, Bob Wallace said the idea for shareware came to him "to some extent as a result of my psychedelic experience".
In 1984, "Softalk-PC" magazine had a column, "The Public Library", about such software. "Public domain" is a misnomer for shareware, and "Freeware" was trademarked by Fluegelman and could not be used legally by others, and "User-Supported Software" was too cumbersome. So columnist Nelson Ford had a contest to come up with a better name.
The most popular name submitted was "Shareware", which was being used by Wallace. However, Wallace acknowledged that he got the term from an InfoWorld magazine column by that name in the 1970s, and that he considered the name to be generic, so its use became established over "freeware" and "user-supported software".
Fluegelman, Knopf, and Wallace clearly established shareware as a viable software marketing method. Via the shareware model, Button, Fluegelman and Wallace became millionaires.
Prior to the popularity of the World Wide Web and widespread Internet access, Shareware was often the only economical way for independent software authors to get their product onto users' desktops. Those with Internet or BBS access could download software and distribute it amongst their friends or user groups, who would then be encouraged to send the registration fee to the author, usually via postal mail. During the late 1980s and early 1990s, shareware software was widely distributed over online services, bulletin board systems and on diskettes. Contrary to commercial developers who spent millions of dollars urging users "Don't Copy that Floppy", shareware developers encouraged users to upload the software and share it on disks.
Commercial shareware distributors such as Educorp and Public Domain Inc printed catalogs describing thousands of public domain and shareware programs that were available for a small charge on floppy disk. These companies later made their entire catalog available on CD-ROM. One such distributor, "Public Software Library" (PSL), began an order-taking service for programmers who otherwise had no means of accepting credit card orders. Later, services like Kagi started offering applications that authors could distribute along with their products that would present the user with an onscreen form to fill out, print, and mail along with their payment. Once telecommunications became more widespread, this service also expanded online. Toward the beginning of the Internet era, books compiling reviews of available shareware were published, sometimes targeting specific niches such as small business. These books would typically come with one or more floppy disks or CD-ROMs containing software from the book.
As Internet use grew, users turned to downloading shareware programs from FTP or web sites. This spelled the end of bulletin board systems and shareware disk distributors. At first, disk space on a server was hard to come by, so networks like Info-Mac were developed, consisting of non-profit mirror sites hosting large shareware libraries accessible via the web or ftp. With the advent of the commercial web hosting industry, the authors of shareware programs started their own sites where the public could learn about their programs and download the latest versions, and even pay for the software online. This erased one of the chief distinctions of shareware, as it was now most often downloaded from a central "official" location instead of being shared samizdat-style by its users. To ensure users would get the latest bug-fixes as well as an install untainted by viruses or other malware, some authors discouraged users from giving the software to their friends, encouraging them to send a link instead.
Major download sites such as VersionTracker and CNet's Download.com began to rank titles based on quality, feedback, and downloads. Popular software was sorted to the top of the list, along with products whose authors paid for preferred placement. Blogs and online forums further enabled individuals to spread news about titles they like. The popularity of app stores expanded the audience for shareware, as well as providing features for authors to accept payments and provide updates. App stores will typically enforce content guidelines for applications listed on their store.
Registration.
Paying will provide the user with a licence key or pass code they can enter into the software to disable the notices and enable full functionality.
Some pirate web sites publish license codes for popular shareware, leading to a kind of arms race between the developer and the pirates where the developer disables pirated codes and the pirates attempt to find or generate new ones. Some software publishers have started accepting known pirated codes, using the opportunity to educate users on the economics of the shareware model.
Some shareware relies entirely on the user's honesty and requires no password - simply checking an "I have paid" checkbox in the application is all that is required to disable the registration notices.
Sometimes a more elaborate action is required, such as clicking an obscure area of a window while holding down a modifier key. These tricks were more easily kept secret before the popularity of the Internet. This category of shareware presupposes an educated, involved userbase that is aware of the software development process, and interested in supporting it. A mass audience is more likely to ask the question "Why should I pay for something I already have?" and disable the shareware notice without paying. Some shareware items require no payment; just an email address, so that the supplier can use this address for their own purposes.
Games.
In the early 1990s, shareware distribution was a popular method of publishing games for smaller developers, including then-fledgling companies Apogee Software (also known as 3D Realms), Epic Megagames (now Epic Games), Ambrosia Software and id Software. It gave consumers the chance to play the game before investing money in it, and gave them exposure that some products would be unable to get in the retail space.
With the Kroz series, Apogee introduced the "episodic" shareware model that became the most popular incentive for "registering" (or buying) a game. While the shareware game would be a truly complete game, there would be additional "episodes" of the game that were not shareware, and could only be legally obtained by paying for the shareware episode. In some cases these episodes were neatly integrated and would feel like a longer version of the game, and in other cases the later episode(s) would be stand-alone games. Sometimes the additional content was completely integrated with the unregistered game, such as in Ambrosia's Escape Velocity series, in which a character representing the developer's pet parrot, equipped with an undefeatable ship, would periodically harass and destroy the player after they reached a certain level representing the end of the trial period.
Racks of games on single 5 1/4 inch and later 3.5 inch floppy disks were common in retail stores. However, computer shows and bulletin board systems (BBS) such as Software Creations BBS were the primary distributors of low-cost software. Free software from a BBS was the motive force for consumers to purchase a computer equipped with a modem, so as to acquire software at no cost.
The important distinguishing feature between a shareware game and a game demo is that the shareware game is, at least in theory, a complete game. Where modern demos are often a single level or less, shareware games usually had many hours of play with a beginning, middle, and end. Shareware episodes most commonly offered 1/3 or 1/2 of the entire registered version, and many even offered the entire product as shareware with no additional content for registered users.
Criticism.
Shareware has been characterized as being both less stable and less secure than "officially developed" software.
In the 1980s and early-to-mid 1990s, shareware was a means of distribution enabling small developers to have their product widely disseminated among computer users, some of whom would purchase the product. After the internet became popular, the shareware model began to degrade as the term was used by commercial startups offering (sometimes substandard) commercial software and labeling non-functional or limited demo versions (termed crippleware) as shareware. As a result, in the early 21st century, the term shareware was being used less, replaced by either demo or trial software.
Derivatives.
Other types of software distribution, taking the suffix "-ware" have followed shareware's lead. They usually do not require the user to make a specific payment to the author. Examples include:
Another type of shareware software distribution very popular in the mobile domain are app store markets (e.g., see List of mobile software distribution platforms). There, users can often obtain applications that are free and advert banner supported, and often a paid version with no ads and maybe more features.
Industry standards and technologies.
There are several widely accepted standards and technologies that are used in the development and promotion of shareware.

</doc>
<doc id="27568" url="https://en.wikipedia.org/wiki?curid=27568" title="Substance theory">
Substance theory

Substance theory, or substance attribute theory, is an ontological theory about objecthood, positing that a "substance" is distinct from its properties. A "thing-in-itself" is a property-bearer that must be distinguished from the properties it bears.
"Substance" is a key concept in ontology and metaphysics, which may be classified into monist, dualist, or pluralist varieties according to how many substances or individuals are said to populate, furnish, or exist in the world. According to monistic views, such as those of stoicism and Spinoza, there is only one substance, pneuma or God, respectively. These modes of thinking are sometimes associated with the idea of immanence. Dualism sees the world as being composed of two fundamental substances, for example, the Cartesian substance dualism of mind and matter. Pluralist philosophies include Plato's Theory of Forms and Aristotle's hylomorphic categories.
Ancient Greek philosophy.
Aristotle used the term in a secondary sense for genera and species understood as hylomorphic forms. Primarily, however, he used it with regard to his category of substance, the specimen ("this person" or "this horse") or individual, "qua" individual, who survives accidental change and in whom the essential properties inhere that define those universals. In contrast, Plato and later Neoplatonism, spoke of the objective reality of a thing or its inner reality (as opposed to outer appearance or illusion).
In chapter 6 of the "Physics" Aristotle argues that any change must be analysed in reference to the property of an invariant subject as it was before the change and thereafter. Thus, in his hylomorphic account of change, "matter" serves as a relative substratum of transformation, i.e., of changing form. In the "Categories", properties are predicated only of substance, but in chapter 7 of the "Physics", Aristotle discusses substances coming to be and passing away in the "unqualified sense" wherein a primary substance is generated from (or perishes into) a material substratum by having gained (or lost) the essential property that formally defines a substance of that kind (in the secondary sense). However, because an essential property remains invariant during an accidental change in form, by identifying the substance with its formal essence, substance may thereby serve as the relative subject matter or property-bearer of change in a qualified sense (i.e., barring matters of life or death).
Neither the "bare particulars" nor "property bundles" of modern theory have their antecedent in Aristotle, according to whom, all matter exists in some form. There is no "prime matter" or pure elements, there is always a mixture: a ratio weighing the four potential combinations of primary and secondary properties and analysed into discrete one-step and two-step abstract transmutations between the elements.
However, according to Aristotle's theology, a form of invariant form exists without matter, beyond the cosmos, powerless and oblivious, in the eternal substance of the unmoved movers.
Early Modern Philosophy.
Descartes means by "substance" an entity which exists in such a way that it needs no other entity in order to exist. Therefore, only God is a substance in this strict sense. But he extends the term to created things, which need only the concurrence of God to exist. Of these there are two and only two: mind and matter, each being distinct from the other in their attributes and therefore in their essence, and neither needing the other in order to exist. This is Descartes' dualism. Spinoza denied Descartes' 'real distinction' between mind and matter. Substance, according to Spinoza, is one and indivisible, but has multiple 'attributes'. But an 'attribute' is 'what we conceive as constituting the essence of substance'. We may conceive of the single essence of the one substance as material and also, consistently, as mental. What we ordinarily call the natural world, together with all the individuals in it, is immanent in God: hence the famous phrase "deus sive natura" ("God or Nature").
Locke defined substance as follows: 
Criticisms of the concept of substance.
The idea of substance was famously critiqued by David Hume, who held that since substance cannot be perceived, it should not be assumed to exist. But the claim that substance cannot be perceived is neither clear nor obvious, and neither is the implication obvious.
Friedrich Nietzsche and, after him, Martin Heidegger, Michel Foucault and Gilles Deleuze also rejected the notion of "substance", and in the same movement the concept of subject contained with the framework of Platonic idealism. For this reason, Althusser's "anti-humanism" and Foucault's statements were criticized, by Jürgen Habermas and others, for misunderstanding that this led to a fatalist conception of social determinism. For Habermas, only a subjective form of liberty could be conceived, to the contrary of Deleuze who talks about ""a" life", as an impersonal and immanent form of liberty.
For Heidegger, Descartes means by "substance" that by which "we can understand nothing else than an entity which "is" in such a way that it need no other entity in order to "be"." Therefore, only God is a substance as "ens perfectissimus" (most perfect being). Heidegger showed the inextricable relationship between the concept of substance and of subject, which explains why, instead of talking about "man" or "humankind", he speaks about the "Dasein", which is not a simple subject, nor a substance.
Alfred North Whitehead has argued that the concept of substance has only a limited applicability in everyday life and that metaphysics should rely upon the concept of process.
Roman Catholic theologian Karl Rahner, as part of his critique of transubstantiation, rejected substance theory and instead proposed the doctrine of "transfinalization", which he felt was more attuned to modern philosophy. However, this doctrine was rejected by Pope Paul VI in his encyclical "Mysterium fidei".
Irreducible concepts.
Two irreducible concepts encountered in substance theory are the "bare particular" and "inherence".
Bare particular.
In substance theory, a bare particular of an object is the element without which the object would not exist, that is, its substance, which exists independently from its properties, even if it is impossible for it to lack properties entirely. It is "bare" because it is considered without its properties and "particular" because it is not abstract. The properties that the substance has are said to inhere in the substance.
Inherence.
Another primitive concept in substance theory is the inherence of properties within a substance. For example, in the sentence, "The apple is red" substance theory says that red inheres in the apple. Substance theory takes the meaning of an apple having the property of redness to be understood, and likewise that of a property's inherence in substance, which is similar to, but not identical with, being part of the substance.
The inverse relation is participation. Thus in the example above, just as red inheres in the apple, so the apple participates in red.
Arguments supporting the theory.
Two common arguments supporting substance theory are the argument from grammar and the argument from conception.
Argument from grammar.
The argument from grammar uses traditional grammar to support substance theory. For example, the sentence "Snow is white" contains a grammatical subject "snow" and the predicate "is white", thereby asserting "snow is white". The argument holds that it makes no grammatical sense to speak of "whiteness" disembodied, without asserting that snow or something else "is" white. Meaningful assertions are formed by virtue of a grammatical subject, of which properties may be predicated, and in substance theory, such assertions are made with regard to a substance.
Bundle theory rejects the argument from grammar on the basis that a grammatical subject does not necessarily refer to a metaphysical subject. Bundle theory, for example, maintains that the grammatical subject of statement refers to its properties. For example, a bundle theorist understands the grammatical subject of the sentence, "Snow is white", to be a bundle of properties such as white. Accordingly, one can make meaningful statements about bodies without referring to substances.
Argument from conception.
Another argument for the substance theory is the argument from conception. The argument claims that in order to conceive of an object's properties, like the redness of an apple, one must conceive of the object that has those properties. According to the argument, one cannot conceive of redness, or any other property, distinct from the substance that has that property.
Bundle theory.
In direct opposition to substance theory is bundle theory, whose most basic premise is that all concrete particulars are merely constructions or 'bundles' of attributes or qualitative properties:
The bundle theorist's principal objections to substance theory concern the bare particulars of a substance, which substance theory considers independently of the substance's properties. The bundle theorist objects to the notion of a thing with no properties, claiming that such a thing is inconceivable and citing John Locke, who described a substance as "a something, I know not what." To the bundle theorist, as soon as one has any notion of a substance in mind, a property accompanies that notion.
Identity of indiscernibles.
The indiscernibility argument from the substance theorist targets those bundle theorists who are also metaphysical realists. Metaphysical realism uses the identity of "universals" to compare and identify particulars. Substance theorists say that bundle theory is incompatible with metaphysical realism due to the identity of indiscernibles: particulars may differ from one another only with respect to their attributes or relations.
The substance theorist's indiscernibility argument against the metaphysically realistic bundle theorist states that numerically different concrete particulars are discernible from the self-same concrete particular only by virtue of qualitatively different attributes.
The indiscernibility argument points out that if bundle theory and discernible concrete particulars theory explain the relationship between attributes, then the identity of indiscernibles theory must also be true:
The indiscernibles argument then asserts that the identity of indiscernibles is violated, for example, by identical sheets of paper. All of their qualitative properties are the same (e.g. white, rectangular, 9 x 11 inches...) and thus, the argument claims, bundle theory and metaphysical realism cannot both be correct.
However, bundle theory combined with trope theory (as opposed to metaphysical realism) avoids the indiscernibles argument because each attribute is a trope if can only be held by only one concrete particular.
The argument does not consider whether "position" should be considered an attribute or relation. It is after all through the differing positions that we in practice differentiate between otherwise identical pieces of paper.
Stoicism.
The Stoics rejected the idea that incorporeal beings inhere in matter, as taught by Plato. They believed that all being is corporeal infused with a creative fire called pneuma. Thus they developed a scheme of categories different from Aristotle's based on the ideas of Anaxagoras and Timaeus.

</doc>
<doc id="27571" url="https://en.wikipedia.org/wiki?curid=27571" title="Siebold">
Siebold

von Siebold is a German surname: 

</doc>
<doc id="27573" url="https://en.wikipedia.org/wiki?curid=27573" title="Superfluid helium-4">
Superfluid helium-4

Superfluid helium-4 is the superfluid form of helium-4, an isotope of the element helium. A superfluid is a state of matter in which the matter behaves like a fluid with zero viscosity. The substance, which looks like a normal liquid, flows without friction past any surface, which allows it to continue to circulate over obstructions and through pores in containers which hold it, subject only to its own inertia.
Known as a major facet in the study of quantum hydrodynamics and macroscopic quantum phenomena, the superfluidity effect was discovered by Pyotr Kapitsa and John F. Allen, and Don Misener in 1937. It has since been described through phenomenological and microscopic theories. The formation of the superfluid is known to be related to the formation of a Bose–Einstein condensate. This is made obvious by the fact that superfluidity occurs in liquid helium-4 at far higher temperatures than it does in helium-3. Each atom of helium-4 is a boson particle, by virtue of its zero spin. Helium-3, however, is a fermion particle, which can form bosons only by pairing with itself at much lower temperatures, in a process similar to the electron pairing in superconductivity.
In the 1950s, Hall and Vinen performed experiments establishing the existence of quantized vortex lines in superfluid helium. In the 1960s, Rayfield and Reif established the existence of quantized vortex rings. Packard has observed the intersection of vortex lines with the free surface of the fluid, and Avenel and Varoquaux have studied the Josephson effect in superfluid helium-4. In 2006 a group at the University of Maryland visualized quantized vortices by using small tracer particles of solid hydrogen.
Properties.
Figure 1 is the phase diagram of 4He. It is a p-T diagram indicating the solid and liquid regions separated by the melting curve (between the liquid and solid state) and the liquid and gas region, separated by the vapor-pressure line. This latter ends in the critical point where the difference between gas and liquid disappears. The diagram shows the remarkable property that 4He is liquid even at absolute zero. Helium four is only solid at pressures above 25 bar.
Figure 1 also shows the λ-line. This is the line that separates two fluid regions in the phase diagram indicated by He-I and He-II. In the He-I region the helium behaves like a normal fluid; in the He-II region the helium is superfluid.
The name lambda-line comes from the specific heat – temperature plot which has the shape of the Greek letter λ. See figure 2, which shows a peak at 2.172 K, the so-called λ-point of 4He.
Below the lambda line the liquid can be described by the so-called two-fluid model. It behaves as if it consists of two components: a normal component, which behaves like a normal fluid, and a superfluid component with zero viscosity and zero entropy. The ratios of the respective densities ρn/ρ and ρs/ρ, with ρn (ρs) the density of the normal (superfluid) component, and ρ (the total density), depends on temperature and is represented in figure 3. By lowering the temperature, the fraction of the superfluid density increases from zero at "T"λ to one at zero kelvin. Below 1 K the helium is almost completely superfluid.
It is possible to create density waves of the normal component (and hence of the superfluid component since ρn + ρs = constant) which are similar to ordinary sound waves. This effect is called second sound. Due to the temperature dependence of ρn (figure 3) these waves in ρn are also temperature waves.
Film flow.
Many ordinary liquids, like alcohol or petroleum, creep up solid walls, driven by their surface tension. Liquid helium also has this property, but, in the case of He-II, the flow of the liquid in the layer is not restricted by its viscosity but by a critical velocity which is about 20 cm/s. This is a fairly high velocity so superfluid helium can flow relatively easily up the wall of containers, over the top, and down to the same level as the surface of the liquid inside the container, in a siphon effect as illustrated in figure 4. In a container, lifted above the liquid level, it forms visible droplets as seen in figure 5.
Superfluid hydrodynamics.
The equation of motion for the superfluid component, in a somewhat simplified form, is given by Newton's law
The mass "M"4 is the molar mass of 4He and formula_2 is the velocity of the superfluid component. The time derivative is the so-called hydrodynamic derivative, i.e. the rate of increase of the velocity when moving with the fluid. In the case of superfluid 4He in the gravitational field the force is given by
In this expression μ is the molar chemical potential, "g" the gravitational acceleration, and "z" the vertical coordinate. Thus we get
Eq. only holds if "v"s is below a certain critical value which usually is determined by the diameter of the flow channel.
In classical mechanics the force is often the gradient of a potential energy. Eq. shows that, in the case of the superfluid component, the force contains a term due to the gradient of the chemical potential. This is the origin of the remarkable properties of He-II such as the fountain effect.
Fountain pressure.
In order to rewrite Eq. in more familiar form we use the general formula
Here "S"m is the molar entropy and "V"m the molar volume. With Eq. μ("p","T") can be found by a line integration in the p-T plane. First we integrate from the origin (0,0) to ("p",0), so at "T" =0. Next we integrate from ("p",0) to ("p","T"), so with constant pressure (see figure 6). In the first integral d"T"=0 and in the second d"p"=0. With Eq. we obtain
We are interested only in cases where "p" is small so that "V"m is practically constant. So
where "V"m0 is the molar volume of the liquid at "T" =0 and "p" =0. The other term in Eq. is also written as a product of "V"m0 and a quantity "p"f which has the dimension of pressure
The pressure "p"f is called the fountain pressure. It can be calculated from the entropy of 4He which, in turn, can be calculated from the heat capacity. For "T" ="T"λ the fountain pressure is equal to 0.692 bar. With a density of liquid helium of 125 kg/m3 and "g" = 9.8 m/s2 this corresponds with a liquid-helium column of 56 meter height. So, in many experiments, the fountain pressure has a bigger effect on the motion of the superfluid helium than gravity.
With Eqs. and , Eq. obtains the form
Substitution of Eq. in gives
with ρ₀ = "M"4/"V"m0 the density of liquid 4He at zero pressure and temperature.
Eq. shows that the superfluid component is accelerated by gradients in the pressure and in the gravitational field, as usual, but also by a gradient in the fountain pressure.
So far Eq. has only mathematical meaning, but in special experimental arrangements "p"f can show up as a real pressure. Figure 7 shows two vessels both containing He-II. The left vessel is supposed to be at zero kelvin ("T"l=0) and zero pressure ("p"l = 0). The vessels are connected by a so-called superleak. This is a tube, filled with a very fine powder, so the flow of the normal component is blocked. However, the superfluid component can flow through this superleak without any problem (below a critical velocity of about 20 cm/s). In the steady state "v"s=0 so Eq. implies
where the index l (r) applies to the left (right) side of the superleak. In this particular case "p"l = 0, "z"l = "z"r, and "p"fl = 0 (since "T"l = 0). Consequently,
This means that the pressure in the right vessel is equal to the fountain pressure at "T"r.
In an experiment, arranged as in figure 8, a fountain can be created. The fountain effect is used to drive the circulation of 3He in dilution refrigerators.
Heat transport.
Figure 9 depicts a heat-conduction experiment between two temperatures "T"H and "T"L connected by a tube filled with He-II. When heat is applied to the hot end a pressure builds up at the hot end according to Eq.. This pressure drives the normal component from the hot end to the cold end according to
Here ηn is the viscosity of the normal component, "Z" some geometrical factor, and formula_5 the volume flow. The normal flow is balanced by a flow of the superfluid component from the cold to the hot end. At the end sections a normal to superfluid conversion takes place and vice versa. So heat is transported, not by heat conduction, but by convection. This kind of heat transport is very effective, so the thermal conductivity of He-II is very much better than the best materials. The situation is comparable with heat pipes where heat is transported via gas–liquid conversion. The high thermal conductivity of He-II is applied for stabilizing superconducting magnets such as in the Large Hadron Collider at CERN.
Theory.
Landau two-fluid approach.
L. D. Landau's phenomenological and semi-microscopic theory of superfluidity of helium-4 earned him the Nobel Prize in physics, in 1962. Assuming that sound waves are the most important excitations in helium-4 at low temperatures, he showed that helium-4 flowing past a wall would not spontaneously create excitations if the flow velocity was less than the sound velocity. In this model, the sound velocity is the "critical velocity" above which superfluidity is destroyed. (Helium-4 actually has a lower flow velocity than the sound velocity, but this model is useful to illustrate the concept.) Landau also showed that the sound wave and other excitations could equilibrate with one another and flow separately from the rest of the helium-4, which is known as the "condensate".
From the momentum and flow velocity of the excitations he could then define a "normal fluid" density, which is zero at zero temperature and increases with temperature. At the so-called Lambda temperature, where the normal fluid density equals the total density, the helium-4 is no longer superfluid.
To explain the early specific heat data on superfluid helium-4, Landau posited the existence of a type of excitation he called a "roton", but as better data became available he considered that the "roton" was the same as a high momentum version of sound.
The Landau theory does not elaborate on the microscopic structure of the superfluid component of liquid helium. The first attempt to create the microscopic theory of the superfluid component itself was done by London. and Tisza
Subsequently, other microscopical models were proposed by different authors. Their main objective is to derive the form of the inter-particle potential between helium atoms in superfluid state from first principles of quantum mechanics. 
To date, a number of models of this kind have been proposed: models with vortex rings, hard-sphere models, Gaussian cluster theories, "etc".
Vortex ring model.
Landau thought that vorticity entered superfluid helium-4 by vortex sheets, but such sheets have since been shown to be unstable.
Lars Onsager and, later independently, Feynman showed that vorticity enters by quantized vortex lines. They also developed the idea of quantum vortex rings.
Arie Bijl in the 1940s,
and Richard Feynman around 1955, developed microscopic theories for the roton, which was shortly observed with inelastic neutron experiments by Palevsky. Later on, Feynman admitted that his model gives only qualitative agreement with experiment.
Hard-sphere models.
The models are based on the simplified form of the inter-particle potential between helium-4 atoms in the superfluid phase. Namely, the potential is assumed to be of the hard-sphere type.
In these models the famous Landau (roton) spectrum of excitations is qualitatively reproduced.
Gaussian cluster approach.
This is a two-scale approach which describes the superfluid component of liquid helium-4. It
consists of two nested models linked via parametric space. The short-wavelength part describes the interior structure of the fluid element using a non-perturbative approach based on the Logarithmic Schrödinger equation; it suggests the Gaussian-like behaviour of the element's interior density and interparticle interaction potential. The long-wavelength part is the quantum many-body theory of such elements which deals with their dynamics and interactions. The approach provides a unified description of the phonon, maxon and roton excitations, and has noteworthy agreement with experiment: with one essential parameter to fit one reproduces at high accuracy the Landau roton spectrum, sound velocity and structure factor of superfluid helium-4.
This model utilizes the general theory of quantum Bose liquids with logarithmic nonlinearities which is based on introducing a dissipative-type contribution to energy related to the quantum Everett-Hirschman entropy function.
Background.
Although the phenomenologies of the superfluid states of helium-4 and helium-3 are very similar, the microscopic details of the transitions are very different. Helium-4 atoms are bosons, and their superfluidity can be understood in terms of the Bose–Einstein statistics that they obey. Specifically, the superfluidity of helium-4 can be regarded as a consequence of Bose-Einstein condensation in an interacting system. On the other hand, helium-3 atoms are fermions, and the superfluid transition in this system is described by a generalization of the BCS theory of superconductivity. In it, Cooper pairing takes place between atoms rather than electrons, and the attractive interaction between them is mediated by spin fluctuations rather than phonons. (See fermion condensate.) A unified description of superconductivity and superfluidity is possible in terms of gauge symmetry breaking.
Superfluids, such as helium-4 below the lambda point, exhibit many unusual properties. (See Helium#Helium II state). A superfluid acts as if it were a mixture of a normal component, with all the properties of a normal fluid, and a superfluid component. The superfluid component has zero viscosity and zero entropy. Application of heat to a spot in superfluid helium results in a flow of the normal component which takes care of the heat transport at relatively high velocity (up to 20 cm/s) which leads to a very high effective thermal conductivity.
Another fundamental property becomes visible if a superfluid is placed in a rotating container. Instead of rotating uniformly with the container, the rotating state consists of quantized vortices. That is, when the container is rotated at speeds below the first critical angular velocity, the liquid remains perfectly stationary. Once the first critical angular velocity is reached, the superfluid will form a vortex. The vortex strength is quantized, that is, a superfluid can only spin at certain "allowed" values. Rotation in a normal fluid, like water, is not quantized. If the rotation speed is increased more and more quantized vortices will be formed which arrange in nice patterns similar to the Abrikosov lattice in a superconductor.
Practical application.
Recently in the field of chemistry, superfluid helium-4 has been successfully used in spectroscopic techniques as a quantum solvent. Referred to as superfluid helium droplet spectroscopy (SHeDS), it is of great interest in studies of gas molecules, as a single molecule solvated in a superfluid medium allows a molecule to have effective rotational freedom, allowing it to behave similarly to how it would in the "gas" phase. Droplets of superfluid helium also have a characteristic temperature of about 0.4 K which cools the solvated molecule(s) to its ground or nearly ground rovibronic state.
Superfluids are also used in high-precision devices such as gyroscopes, which allow the measurement of some theoretically predicted gravitational effects (for an example, see Gravity Probe B).
In 1999, one type of superfluid was used to trap light and greatly reduce its speed. In an experiment performed by Lene Hau, light was passed through a Bose-Einstein condensed gas of sodium (analogous to a superfluid) and found to be slowed to from its normal speed of 299,792,458 metres per second in vacuum. This does not change the absolute value of "c", nor is it completely new: any medium other than vacuum, such as water or glass, also slows down the propagation of light to "c"/"n" where "n" is the material's refractive index. The very slow speed of light and high refractive index observed in this particular experiment, moreover, is not a general property of all superfluids.
The Infrared Astronomical Satellite IRAS, launched in January 1983 to gather infrared data was cooled by 73 kilograms of superfluid helium, maintaining a temperature of . Furthermore, when used in conjunction with helium-3, temperatures as low as 40 mK are routinely achieved in extreme low temperature experiments. The helium-3, in liquid state at 3.2 K, can be evaporated into the superfluid helium-4, where it acts as a gas due to the latter's properties as a Bose-Einstein condensate. This evaporation pulls energy from the overall system, which can be pumped out in a way completely analogous to normal refrigeration techniques.
Superfluid-helium technology is used to extend the temperature range of cryocoolers to lower temperatures. So far the limit is 1.19 K, but there is a potential to reach 0.7 K.
21st-century developments.
In the early 2000s, physicists created a Fermionic condensate from pairs of ultra-cold fermionic atoms. Under certain conditions, fermion pairs form diatomic molecules and undergo Bose–Einstein condensation. At the other limit, the fermions (most notably superconducting electrons) form Cooper pairs which also exhibit superfluidity. This work with ultra-cold atomic gases has allowed scientists to study the region in between these two extremes, known as the BEC-BCS crossover.
Supersolids may also have been discovered in 2004 by physicists at Penn State University. When helium-4 is cooled below about 200 mK under high pressures, a fraction (~1%) of the solid appears to become superfluid. By quench cooling or lengthening the annealing time, thus increasing or decreasing the defect density respectively, it was shown, via torsional oscillator experiment, that the supersolid fraction could be made to range from 20% to completely non-existent. This suggested that the supersolid nature of helium-4 is not intrinsic to helium-4 but a property of helium-4 and disorder. Some emerging theories posit that the supersolid signal observed in helium-4 was actually an observation of either a superglass state
or intrinsically superfluid grain boundaries in the helium-4 crystal.

</doc>
<doc id="27574" url="https://en.wikipedia.org/wiki?curid=27574" title="Simon Flexner">
Simon Flexner

Simon Flexner, M.D. (March 25, 1863 in Louisville, Kentucky – May 2, 1946) was a physician, scientist, administrator, and professor of experimental pathology at the University of Pennsylvania (1899–1903). He served as the first director of the Rockefeller Institute for Medical Research (1901–1935) (later developed as Rockefeller University) and a trustee of the Rockefeller Foundation. He was also a friend and adviser to John D. Rockefeller, Jr..
Among Flexner's most important achievements are studies into poliomyelitis and the development of serum treatment for meningitis. Among his lab assistants were Hideyo Noguchi and Cornelius Rhoads, later directors of Memorial Hospital and the Sloan-Kettering Institute, respectively.
The bacteria species "Shigella flexneri" was named in recognition of Flexner. In addition, Flexner was the first to describe Flexner-Wintersteiner rosettes, a characteristic finding in retinoblastoma, a type of cancer.
Early life and career.
Simon was born in Louisville, Kentucky, to Moritz (Morris) Flexner, an immigrant from Neumark, Bohemia, via several years in Strasbourg, France; and Esther from Roden, Germany. He was the fourth son of seven in a large family of nine children: Jacob Flexner, Henry, and Isadore; then Simon, followed by Bernard Flexner, Abraham Flexner, and Washington. The two sisters Mary and Gertrude were the youngest. Jacob became a pharmacist and physician; Bernard became a Zionist leader, and Abraham became an educator, eventually influencing the direction of medical education in the United States.
Simon first gained a degree from the Louisville College of Pharmacy and worked with his brother Jacob for eight years.
Medical school and career.
He returned to college, getting his medical degree from Louisville Medical College in 1889. He did postgraduate work in pathology at Johns Hopkins University Medical School, and started teaching there. By 1899, he was a professor of pathology at the University of Pennsylvania.
He taught at Penn until 1903, but was called to the Rockefeller Institute for Medical Research (later Rockefeller University), where he started serving as its first director in 1901. He managed the research institute until 1935. Through this affiliation and related work, he came to know the philanthropist John D. Rockefeller, who supported research and basic medical care.
In December 1907 Flexner declared in a reading of his paper on "Tendencies in Pathology" in the University of Chicago that it would be possible in the then-future for diseased human organs substitution for healthy ones by surgery — including arteries, stomach, kidneys and heart. These previsions became reality in the second half of the 20th century.
The institute had a long relationship with the government of Puerto Rico, conducting research and working on health issues there, such as anemia (caused by hookworm and tropical sprue), as well as polio and a variety of diseases.
Marriage and family.
Simon Flexner married Helen Thomas (later professor of English) and had a family. His son James Thomas Flexner became a prolific writer; one of his works was an extensive biography of George Washington.
Dr. Flexner died in May 1946 in New York City, from a myocardial infarction (heart attack). He was 83 years old. His papers are currently housed at the American Philosophical Society and the Becker Medical Library at the Washington University School of Medicine.

</doc>
<doc id="27575" url="https://en.wikipedia.org/wiki?curid=27575" title="Statistical regularity">
Statistical regularity

Statistical regularity is a notion in statistics and probability theory that random events exhibit regularity when repeated enough times or that enough sufficiently similar random events exhibit regularity. It is an umbrella term that covers the law of large numbers, all central limit theorems and ergodic theorems.
If one throws a die once, it is difficult to predict the outcome, but if we repeat this experiment many times, we will see that the number of times each result occurs divided by the number of throws will eventually stabilize towards a specific value.
Repeating a series of trials will produce similar, but not identical, results for each series: the average, the standard deviation and other distributional characteristics will be around the same for each series of trials.
The notion is used in games of chance, demographic statistics, quality control of a manufacturing process, and in many other parts of our lives.
Observations of this phenomenon provided the initial motivation for the concept of what is now known as frequency probability.
This phenomenon should not be confused with the Gambler's fallacy, it only concerns regularity in the (possibly very) long run. Gambler's fallacy does not apply to statistical regularity because the latter considers the whole rather than individual cases.

</doc>
<doc id="27576" url="https://en.wikipedia.org/wiki?curid=27576" title="Statistical model">
Statistical model

A statistical model embodies a set of assumptions concerning the generation of the observed data, and similar data from a larger population. A model represents, often in considerably idealized form, the data-generating process. The model assumptions describe a set of probability distributions, some of which are assumed to adequately approximate the distribution from which a particular data set is sampled.
A model is usually specified by mathematical equations that relate one or more random variables and possibly other non-random variables. As such, "a model is a formal representation of a theory" (Herman Adèr quoting Kenneth Bollen).
All statistical hypothesis tests and all statistical estimators are derived from statistical models. More generally, statistical models are part of the foundation of statistical inference.
Formal definition.
In mathematical terms, a statistical model is usually thought of as a pair (formula_1), where formula_2 is the set of possible observations, i.e. the sample space, and formula_3 is a set of probability distributions on formula_2.
The intuition behind this definition is as follows. It is assumed that there is a "true" probability distribution that generates the observed data. We choose formula_3 to represent a set (of distributions) which contains a distribution that adequately approximates the true distribution. Note that we do not require that formula_3 contains the true distribution, and in practice that is rarely the case. Indeed, as Burnham & Anderson state, "A model is a simplification or approximation of reality and hence will not reflect all of reality"—whence the saying "all models are wrong".
The set formula_3 is almost always parameterized: formula_8. The set formula_9 defines the "parameters" of the model. A parameterization is generally required to have distinct parameter values give rise to distinct distributions, i.e., formula_10 must hold (resembling injections). A parameterization that meets the condition is said to be "identifiable".
An example.
Height and age are each probabilistically distributed over humans. They are stochastically related: when we know that a person is of age 10, this influences the chance of the person being 6 feet tall. We could formalize that relationship in a linear regression model with the following form: 
height"i" = "b"0 + "b"1age"i" + ε"i", where "b"0 is the intercept, "b"1 is a parameter that age is multiplied by to get a prediction of height, ε is the error term, and "i" identifies the person. This implies that height is predicted by age, with some error.
An admissible model must be consistent with all the data points. Thus, the straight line (height"i" = "b"0 + "b"1age"i") is "not" a model of the data. The line cannot be a model, unless it exactly fits all the data points—i.e. all the data points lie perfectly on a straight line. The error term, ε"i", must be included in the model, so that the model is consistent with all the data points.
To do statistical inference, we would first need to assume some probability distributions for the ε"i". For instance, we might assume that the ε"i" distributions are i.i.d. Gaussian, with zero mean. In this instance, the model would have 3 parameters: "b"0, "b"1, and the variance of the Gaussian distribution.
We can formally specify the model in the form (formula_1) as follows. The sample space, formula_2, of our model comprises the set of all possible pairs (age, height). Each possible value of formula_13 = ("b"0, "b"1, "σ"2) determines a distribution on formula_2; denote that distribution by formula_15. If formula_9 is the set of all possible values of formula_13, then formula_8. (The parameterization is identifiable, and this is easy to check.)
In this example, the model is determined by (1) specifying formula_2 and (2) making some assumptions relevant to formula_3. There are two assumptions: that height can be approximated by a linear function of age; that errors in the approximation are distributed as i.i.d. Gaussian. The assumptions are sufficient to specify formula_3—as they are required to do.
General remarks.
A statistical model is a special type of mathematical model. What distinguishes a statistical model from other mathematical models is that a statistical model is non-deterministic. Thus, in a statistical model specified via mathematical equations, some of the variables do not have specific values, but instead have probability distributions; i.e. some of the variables are stochastic. In the example above, ε is a stochastic variable; without that variable, the model would be deterministic.
Statistical models are often used even when the physical process being modeled is deterministic. For instance, coin tossing is, in principle, a deterministic process; yet it is commonly modeled as stochastic (via a Bernoulli process).
There are three purposes for a statistical model, according to Konishi & Kitagawa.
Dimension of a model.
Suppose that we have a statistical model (formula_1) with formula_8. The model is said to be parametric if formula_9 has a finite dimension. In notation, we write that formula_25 where "d" is a positive integer (formula_26 denotes the real numbers; other sets can be used, in principle). Here, "d" is called the dimension of the model.
As an example, if we assume that data arise from a univariate Gaussian distribution, then we are assuming that 
In this example, the dimension, "d", equals 2.
As another example, suppose that the data consists of points ("x", "y") that we assume are distributed according to a straight line with i.i.d. Gaussian residuals (with zero mean). Then the dimension of the statistical model is 3: the intercept of the line, the slope of the line, and the variance of the distribution of the residuals. (Note that in geometry, a straight line has dimension 1.)
A statistical model is nonparametric if the parameter set formula_9 is infinite dimensional. A statistical model is semiparametric if it has both finite-dimensional and infinite-dimensional parameters. Formally, if "d" is the dimension of formula_9 and "n" is the number of samples, both semiparametric and nonparemtric models have formula_30 as formula_31. If formula_32 as formula_31, then the model is semiparametric; otherwise, the model is nonparametric.
Parametric models are by far the most commonly-used statistical models. Regarding semiparametric and nonparametric models, Sir David Cox has said, "These typically involve fewer assumptions of structure and distributional form but usually contain strong assumptions about independencies".
Nested models.
Two statistical models are nested if the first model can be transformed into the second model by imposing constraints on the parameters of the first model. For example, the set of all Gaussian distributions has, nested within it, the set of zero-mean Gaussian distributions: we constrain the mean in the set of all Gaussian distributions to get the zero-mean distributions.
In that example, the first model has a higher dimension than the second model (the zero-mean model has dimension 1). Such is usually, but not always, the case. As a different example, the set of positive-mean Gaussian distributions, which has dimension 2, is nested within the set of all Gaussian distributions.
Comparing models.
It is assumed that there is a "true" probability distribution that generates the observed data. The main goal of model selection is to make statements about which elements of formula_3 are most likely to adequately approximate the true distribution.
Models can be compared to each other by exploratory data analysis or confirmatory data analysis. In exploratory analysis, a variety of models are formulated and an assessment is performed of how well each one describes the data. In confirmatory analysis, a previously formulated model or models are compared to the data. Common criteria for comparing models include "R"2, Bayes factor, and the likelihood-ratio test together with its generalization relative likelihood.
Konishi & Kitagawa state: "The majority of the problems in statistical inference can be considered to be problems related to statistical modeling. They are typically formulated as comparisons of several statistical models." Relatedly, Sir David Cox has said, "How translation from subject-matter problem to statistical model is done is often the most critical part of an analysis".

</doc>
<doc id="27577" url="https://en.wikipedia.org/wiki?curid=27577" title="Statistical inference">
Statistical inference

Statistical inference is the process of deducing properties of an underlying distribution by analysis of data. Inferential statistical analysis infers properties about a population: this includes testing hypotheses and deriving estimates. The population is assumed to be larger than the observed data set; in other words, the observed data is assumed to be sampled from a larger population.
Inferential statistics can be contrasted with descriptive statistics. Descriptive statistics is solely concerned with properties of the observed data, and does not assume that the data came from a larger population.
Introduction.
Statistical inference makes propositions about a population, using data drawn from the population with some form of sampling. Given a hypothesis about a population, for which we wish to draw inferences, statistical inference consists of (firstly) selecting a statistical model of the process that generates the data and (secondly) deducing propositions from the model.
Konishi & Kitagawa state, "The majority of the problems in statistical inference can be considered to be problems related to statistical modeling". Relatedly, Sir David Cox has said, "How translation from subject-matter problem to statistical model is done is often the most critical part of an analysis".
The conclusion of a statistical inference is a statistical proposition. Some common forms of statistical proposition are the following:
Models and assumptions.
Any statistical inference requires some assumptions. A statistical model is a set of assumptions concerning the generation of the observed data and similar data. Descriptions of statistical models usually emphasize the role of population quantities of interest, about which we wish to draw inference. Descriptive statistics are typically used as a preliminary step before more formal inferences are drawn.
Degree of models/assumptions.
Statisticians distinguish between three levels of modeling assumptions;
Importance of valid models/assumptions.
Whatever level of assumption is made, correctly calibrated inference in general requires these assumptions to be correct; i.e. that the data-generating mechanisms really have been correctly specified.
Incorrect assumptions of 'simple' random sampling can invalidate statistical inference. More complex semi- and fully parametric assumptions are also cause for concern. For example, incorrectly assuming the Cox model can in some cases lead to faulty conclusions. Incorrect assumptions of Normality in the population also invalidates some forms of regression-based inference. The use of any parametric model is viewed skeptically by most experts in sampling human populations: "most sampling statisticians, when they deal with confidence intervals at all, limit themselves to statements about based on very large samples, where the central limit theorem ensures that these [estimators will have distributions that are nearly normal." In particular, a normal distribution "would be a totally unrealistic and catastrophically unwise assumption to make if we were dealing with any kind of economic population." Here, the central limit theorem states that the distribution of the sample mean "for very large samples" is approximately normally distributed, if the distribution is not heavy tailed.
Approximate distributions.
Given the difficulty in specifying exact distributions of sample statistics, many methods have been developed for approximating these.
With finite samples, approximation results measure how close a limiting distribution approaches the statistic's sample distribution: For example, with 10,000 independent samples the normal distribution approximates (to two digits of accuracy) the distribution of the sample mean for many population distributions, by the Berry–Esseen theorem.
Yet for many practical purposes, the normal approximation provides a good approximation to the sample-mean's distribution when there are 10 (or more) independent samples, according to simulation studies and statisticians' experience. Following Kolmogorov's work in the 1950s, advanced statistics uses approximation theory and functional analysis to quantify the error of approximation. In this approach, the metric geometry of probability distributions is studied; this approach quantifies approximation error with, for example, the Kullback–Leibler divergence, Bregman divergence, and the Hellinger distance.
With indefinitely large samples, limiting results like the central limit theorem describe the sample statistic's limiting distribution, if one exists. Limiting results are not statements about finite samples, and indeed are irrelevant to finite samples. However, the asymptotic theory of limiting distributions is often invoked for work with finite samples. For example, limiting results are often invoked to justify the generalized method of moments and the use of generalized estimating equations, which are popular in econometrics and biostatistics. The magnitude of the difference between the limiting distribution and the true distribution (formally, the 'error' of the approximation) can be assessed using simulation. The heuristic application of limiting results to finite samples is common practice in many applications, especially with low-dimensional models with log-concave likelihoods (such as with one-parameter exponential families).
Randomization-based models.
For a given dataset that was produced by a randomization design, the randomization distribution of a statistic (under the null-hypothesis) is defined by evaluating the test statistic for all of the plans that could have been generated by the randomization design. In frequentist inference, randomization allows inferences to be based on the randomization distribution rather than a subjective model, and this is important especially in survey sampling and design of experiments. Statistical inference from randomized studies is also more straightforward than many other situations. In Bayesian inference, randomization is also of importance: in survey sampling, use of sampling without replacement ensures the exchangeability of the sample with the population; in randomized experiments, randomization warrants a missing at random assumption for covariate information.
Objective randomization allows properly inductive procedures.
Many statisticians prefer randomization-based analysis of data that was generated by well-defined randomization procedures. (However, it is true that in fields of science with developed theoretical knowledge and experimental control, randomized experiments may increase the costs of experimentation without improving the quality of inferences.)
Similarly, results from randomized experiments are recommended by leading statistical authorities as allowing inferences with greater reliability than do observational studies of the same phenomena.
However, a good observational study may be better than a bad randomized experiment.
The statistical analysis of a randomized experiment may be based on the randomization scheme stated in the experimental protocol and does not need a subjective model.
However, at any time, some hypotheses cannot be tested using objective statistical models, which accurately describe randomized experiments or random samples. In some cases, such randomized studies are uneconomical or unethical.
Model-based analysis of randomized experiments.
It is standard practice to refer to a statistical model, often a linear model, when analyzing data from randomized experiments. However, the randomization scheme guides the choice of a statistical model. It is not possible to choose an appropriate model without knowing the randomization scheme. Seriously misleading results can be obtained analyzing data from randomized experiments while ignoring the experimental protocol; common mistakes include forgetting the blocking used in an experiment and confusing repeated measurements on the same experimental unit with independent replicates of the treatment applied to different experimental units.
Paradigms for inference.
Different schools of statistical inference have become established. These schools—or "paradigms"—are not mutually exclusive, and methods that work well under one paradigm often have attractive interpretations under other paradigms.
Bandyopadhyay & Forster describe four paradigms: "(i) classical statistics or error statistics, (ii) Bayesian statistics, (iii) likelihood-based statistics, and (iv) the Akaikean-Information Criterion-based statistics". The classical (or frequentist) paradigm, the Bayesian paradigm, and the AIC-based paradigm are summarized below. The likelihood-based paradigm is essentially a sub-paradigm of the AIC-based paradigm.
Frequentist inference.
This paradigm calibrates the plausibility of propositions by considering (notional) repeated sampling of a population distribution to produce datasets similar to the one at hand. By considering the dataset's characteristics under repeated sampling, the frequentist properties of a statistical proposition can be quantified—although in practice this quantification may be challenging.
Frequentist inference, objectivity, and decision theory.
One interpretation of frequentist inference (or classical inference) is that it is applicable only in terms of frequency probability; that is, in terms of repeated sampling from a population. However, the approach of Neyman develops these procedures in terms of pre-experiment probabilities. That is, before undertaking an experiment, one decides on a rule for coming to a conclusion such that the probability of being correct is controlled in a suitable way: such a probability need not have a frequentist or repeated sampling interpretation. In contrast, Bayesian inference works in terms of conditional probabilities (i.e. probabilities conditional on the observed data), compared to the marginal (but conditioned on unknown parameters) probabilities used in the frequentist approach.
The frequentist procedures of significance testing and confidence intervals can be constructed without regard to utility functions. However, some elements of frequentist statistics, such as statistical decision theory, do incorporate utility functions. In particular, frequentist developments of optimal inference (such as minimum-variance unbiased estimators, or uniformly most powerful testing) make use of loss functions, which play the role of (negative) utility functions. Loss functions need not be explicitly stated for statistical theorists to prove that a statistical procedure has an optimality property. However, loss-functions are often useful for stating optimality properties: for example, median-unbiased estimators are optimal under absolute value loss functions, in that they minimize expected loss, and least squares estimators are optimal under squared error loss functions, in that they minimize expected loss.
While statisticians using frequentist inference must choose for themselves the parameters of interest, and the estimators/test statistic to be used, the absence of obviously explicit utilities and prior distributions has helped frequentist procedures to become widely viewed as 'objective'.
Bayesian inference.
The Bayesian calculus describes degrees of belief using the 'language' of probability; beliefs are positive, integrate to one, and obey probability axioms. Bayesian inference uses the available posterior beliefs as the basis for making statistical propositions. There are several different justifications for using the Bayesian approach.
Bayesian inference, subjectivity and decision theory.
Many informal Bayesian inferences are based on "intuitively reasonable" summaries of the posterior. For example, the posterior mean, median and mode, highest posterior density intervals, and Bayes Factors can all be motivated in this way. While a user's utility function need not be stated for this sort of inference, these summaries do all depend (to some extent) on stated prior beliefs, and are generally viewed as subjective conclusions. (Methods of prior construction which do not require external input have been proposed but not yet fully developed.)
Formally, Bayesian inference is calibrated with reference to an explicitly stated utility, or loss function; the 'Bayes rule' is the one which maximizes expected utility, averaged over the posterior uncertainty. Formal Bayesian inference therefore automatically provides optimal decisions in a decision theoretic sense. Given assumptions, data and utility, Bayesian inference can be made for essentially any problem, although not every statistical inference need have a Bayesian interpretation. Analyses which are not formally Bayesian can be (logically) incoherent; a feature of Bayesian procedures which use proper priors (i.e. those integrable to one) is that they are guaranteed to be coherent. Some advocates of Bayesian inference assert that inference "must" take place in this decision-theoretic framework, and that Bayesian inference should not conclude with the evaluation and summarization of posterior beliefs.
Other paradigms for inference.
Minimum description length.
The minimum description length (MDL) principle has been developed from ideas in information theory and the theory of Kolmogorov complexity. The (MDL) principle selects statistical models that maximally compress the data; inference proceeds without assuming counterfactual or non-falsifiable "data-generating mechanisms" or probability models for the data, as might be done in frequentist or Bayesian approaches.
However, if a "data generating mechanism" does exist in reality, then according to Shannon's source coding theorem it provides the MDL description of the data, on average and asymptotically. In minimizing description length (or descriptive complexity), MDL estimation is similar to maximum likelihood estimation and maximum a posteriori estimation (using maximum-entropy Bayesian priors). However, MDL avoids assuming that the underlying probability model is known; the MDL principle can also be applied without assumptions that e.g. the data arose from independent sampling.
The MDL principle has been applied in communication-coding theory in information theory, in linear regression, and in data mining.
The evaluation of MDL-based inferential procedures often uses techniques or criteria from computational complexity theory.
Fiducial inference.
Fiducial inference was an approach to statistical inference based on fiducial probability, also known as a "fiducial distribution". In subsequent work, this approach has been called ill-defined, extremely limited in applicability, and even fallacious. However this argument is the same as that which shows that a so-called confidence distribution is not a valid probability distribution and, since this has not invalidated the application of confidence intervals, it does not necessarily invalidate conclusions drawn from fiducial arguments. An attempt was made to reinterpret the early work of Fisher's fiducial argument as a special case of an inference theory using Upper and lower probabilities.
Structural inference.
Developing ideas of Fisher and of Pitman from 1938 to 1939, George A. Barnard developed "structural inference" or "pivotal inference", an approach using invariant probabilities on group families. Barnard reformulated the arguments behind fiducial inference on a restricted class of models on which "fiducial" procedures would be well-defined and useful.
Inference topics.
The topics below are usually included in the area of statistical inference.

</doc>
<doc id="27578" url="https://en.wikipedia.org/wiki?curid=27578" title="Survey sampling">
Survey sampling

In statistics, survey sampling describes the process of selecting a sample of elements from a target population to conduct a survey. 
The term "survey" may refer to many different types or techniques of observation. In survey sampling it most often involves a questionnaire used to measure the characteristics and/or attitudes of people. Different ways of contacting members of a sample once they have been selected is the subject of survey data collection. The purpose of sampling is to reduce the cost and/or the amount of work that it would take to survey the entire target population. A survey that measures the entire target population is called a census.
Survey samples can be broadly divided into two types: probability samples and non-probability samples. Probability-based samples implement a sampling plan with specified probabilities (perhaps adapted probabilities specified by an adaptive procedure). Probability-based sampling allows design-based inference about the target population. The inferences are based on a known objective probability distribution that was specified in the study protocol. Inferences from probability-based surveys may still suffer from many types of bias.
Surveys that are not based on probability sampling have greater difficulty measuring their bias or sampling error. Surveys based on non-probability samples often fail to represent the people in the target population.
In academic and government survey research, probability sampling is a standard procedure. In the USA, the Office of Management and Budget's "List of Standards for Statistical Surveys" states that federally funded surveys must be performed:
selecting samples using generally accepted statistical methods (e.g., probabilistic methods that can provide estimates of sampling error). Any use of nonprobability sampling methods (e.g., cut-off or model-based samples) must be justified statistically and be able to measure estimation error.
Besides, random sampling and design-based inference are supplemented by other statistical methods, such as model-assisted sampling and model-based sampling.
For example, many surveys have substantial amounts of nonresponse. Even though the units are initially chosen with known probabilities, the nonresponse mechanisms are unknown. For surveys with substantial nonresponse, statisticians have proposed statistical models, with which data sets are analyzed.
Issues related to survey sampling are discussed in several sources including Salant and Dillman (1994).
Probability sampling.
In a probability sample (also called "scientific" or "random" sample) each member of the target population has a known and non-zero probability of inclusion in the sample. A survey based on a probability sample can in theory produce statistical measurements of the target population that are: 
A probability-based survey sample is created by constructing a list of the target population, called the sample frame, a randomized process for selecting units from the sample frame, called a selection procedure, and a method of contacting selected units to and enabling them complete the survey, called a data collection method or mode. For some target populations this process may be easy, for example, sampling the employees of a company by using payroll list. However, in large, disorganized populations simply constructing a suitable sample frame is often a complex and expensive task.
Common methods of conducting a probability sample of the household population in the United States are Area Probability Sampling, Random Digit Dial telephone sampling, and more recently, Address-Based Sampling.
Within probability sampling, there are specialized techniques such as stratified sampling and cluster sampling that improve the precision or efficiency of the sampling process without altering the fundamental principles of probability sampling.
Stratification is the process of dividing members of the population into homogeneous subgroups before sampling. The strata should be mutually exclusive: every element in the population must be assigned to only one stratum. The strata should also be collectively exhaustive: no population element can be excluded. Then methods such as simple random sampling or systematic sampling can be applied within each stratum. This often improves the representativeness of the sample by reducing sampling error.
Bias in probability sampling.
Bias in surveys is undesirable, but often unavoidable. The major types of bias that may occur in the sampling process are:
Non-probability sampling.
Many surveys are not based on probability samples, but rather on finding a suitable collection of respondents to complete the survey. Some common examples of non-probability sampling are:
In non-probability samples the relationship between the target population and the survey sample is immeasurable and potential bias is unknowable. Sophisticated users of non-probability survey samples tend to view the survey as an experimental condition, rather than a tool for population measurement, and examine the results for internally consistent relationships.
Further reading.
The textbook by Groves et alia provides an overview of survey methodology, including recent literature on questionnaire development (informed by cognitive psychology) : 
The other books focus on the statistical theory of survey sampling and require some knowledge of basic statistics, as discussed in the following textbooks:
The elementary book by Scheaffer et alia uses quadratic equations from high-school algebra: 
More mathematical statistics is required for Lohr, for Särndal et alia, and for Cochran (classic):
The historically important books by Deming and Kish remain valuable for insights for social scientists (particularly about the U.S. census and the Institute for Social Research at the University of Michigan): 

</doc>
<doc id="27579" url="https://en.wikipedia.org/wiki?curid=27579" title="Statistical theory">
Statistical theory

The theory of statistics provides a basis for the whole range of techniques, in both study design and data analysis, that are used within applications of statistics. The theory covers approaches to statistical-decision problems and to statistical inference, and the actions and deductions that satisfy the basic principles stated for these different approaches. Within a given approach, statistical theory gives ways of comparing statistical procedures; it can find a best possible procedure within a given context for given statistical problems, or can provide guidance on the choice between alternative procedures.
Apart from philosophical considerations about how to make statistical inferences and decisions, much of statistical theory consists of mathematical statistics, and is closely linked to probability theory, to utility theory, and to optimization.
Scope.
Statistical theory provides an underlying rationale and provides a consistent basis for the choice of methodology used in applied statistics.
Modelling.
Statistical models describe the sources of data and can have different types of formulation corresponding to these sources and to the problem being studied. Such problems can be of various kinds:
Statistical models, once specified, can be tested to see whether they provide useful inferences for new data sets. Testing a hypothesis using the data that was used to specify the model is a fallacy, according to the natural science of Bacon and the scientific method of Peirce.
Data collection.
Statistical theory provides a guide to comparing methods of data collection, where the problem is to generate informative data using optimization and randomization while measuring and controlling for observational error. Optimization of data collection reduces the cost of data while satisfying statistical goals, while randomization allows reliable inferences. Statistical theory provides a basis for good data collection and the structuring of investigations in the topics of:
Summarising data.
The task of summarising statistical data in conventional forms (also known as descriptive statistics) is considered in theoretical statistics as a problem of defining what aspects of statistical samples need to be described and how well they can be described from a typically limited sample of data. Thus the problems theoretical statistics considers include:
Interpreting data.
Besides the philosophy underlying statistical inference, statistical theory has the task of considering the types of questions that data analysts might want to ask about the problems they are studying and of providing data analytic techniques for answering them. Some of these tasks are:
When a statistical procedure has been specified in the study protocol, then statistical theory provides well-defined probability statements for the method when applied to all populations that could have arisen from the randomization used to generate the data. This provides an objective way of estimating parameters, estimating confidence intervals, testing hypotheses, and selecting the best. Even for observational data, statistical theory provides a way of calculating a value that can be used to interpret a sample of data from a population, it can provide a means of indicating how well that value is determined by the sample, and thus a means of saying corresponding values derived for different populations are as different as they might seem; however, the reliability of inferences from post-hoc observational data is often worse than for planned randomized generation of data.
Applied statistical inference.
Statistical theory provides the basis for a number of data analytic methods that are common across scientific and social research. Some of these are: 
Interpreting data is an important objective of statistical research:
Many of the standard methods for these tasks rely on certain statistical assumptions (made in the derivation of the methodology) actually holding in practice. Statistical theory studies the consequences of departures from these assumptions. In addition it provides a range of robust statistical techniques that are less dependent on assumptions, and it provides methods checking whether particular assumptions are reasonable for a give data-set.

</doc>
<doc id="27580" url="https://en.wikipedia.org/wiki?curid=27580" title="Statistical unit">
Statistical unit

A unit in a statistical analysis refers to one member of a set of entities being studied. It is the material source for the mathematical abstraction of a "random variable". Common examples of a unit would be a single person, animal, plant, or manufactured item that belongs to a larger collection of such entities being studied.
Units are often referred to as being either experimental units, sampling units or, more generally, units of observation:
In most statistical studies, the goal is to generalize from the observed units to a larger set consisting of all comparable units that exist but are not directly observed. For example, if we randomly sample 100 people and ask them which candidate they intend to vote for in an election, our main interest is in the voting behavior of all eligible voters, not exclusively on the 100 observed units.
In some cases, the observed units may not form a sample from any meaningful population, but rather constitute a convenience sample, or may represent the entire population of interest. In this situation, we may study the units descriptively, or we may study their dynamics over time. But it typically does not make sense to talk about generalizing to a larger population of such units. Studies involving countries or business firms are often of this type. Clinical trials also typically use convenience samples, however the aim is often to make inferences about the efficacy of treatments in other patients, and given the inclusion and exclusion criteria for some clinical trials, the sample may not be representative of the majority of patients with the condition or disease.
In simple data sets, the units are in one-to-one correspondence with the data values. In more complex data sets, multiple measurements are made for each unit. For example, if blood pressure measurements are made daily for a week on each subject in a study, there would be seven data values for each statistical unit. Multiple measurements taken on an individual are not independent (they will be more alike compared to measurements taken on different individuals). Ignoring these dependencies during the analysis can lead to an inflated sample size or pseudoreplication.
While a "unit" is often the lowest level at which observations are made, in some cases, a "unit" can be further decomposed as a statistical assembly.
Many statistical analyses use quantitative data that have units of measurement. This is a distinct and non-overlapping use of the term "unit."

</doc>
<doc id="27581" url="https://en.wikipedia.org/wiki?curid=27581" title="Statistical assembly">
Statistical assembly

In statistics, for example in statistical quality control, a statistical assembly is a collection of parts or components which makes up a statistical unit. Thus a statistical unit, which would be the prime item of concern, is made of discrete components like organs or machine parts. The reliability of the statistical unit is, in part, determined by the reliability of the components in the statistical assembly, and by their interactions.
Much of the observation of a statistical assembly requires special preparation of the unit, which demands that the intervention must not prejudice the observations. A simple version of this kind of research uses the stimulus-response model.
In other contexts, statistical assembly refers to the process of constructing a manufactured item which must be carefully specified to contain given amounts of nonuniformity within it.
External links.
http://adcats.et.byu.edu/ADCATS/Theory/AutoCAD_Analyzer/1_2D_Overview/1_2D_Overview-.html

</doc>
<doc id="27582" url="https://en.wikipedia.org/wiki?curid=27582" title="Stimulus–response model">
Stimulus–response model

The stimulus–response model is a characterization of a statistical unit (such as a neuron) as a black box model, predicting a quantitative response to a quantitative stimulus, for example one administered by a researcher.
Fields of application.
Stimulus–response models are applied in international relations, 
psychology, 
risk assessment, 
neuroscience,
neurally-inspired system design,
and many other fields.
Mathematical formulation.
The object of a stimulus–response model is to establish a mathematical function that describes the relation "f" between the stimulus "x" and the expected value (or other measure of location) of the response "Y":
A common simplification assumed for such functions is linear, thus we expect to see a relationship like
Statistical theory for linear models has been well developed for more than fifty years, and a standard form of analysis called linear regression has been developed.

</doc>
<doc id="27585" url="https://en.wikipedia.org/wiki?curid=27585" title="Statistical population">
Statistical population

In statistics, a population is a set of similar items or events which is of interest for some question or experiment. A statistical population can be a group of actually existing objects (e.g. the set of all stars within the Milky Way galaxy) or a hypothetical and potentially infinite group of objects conceived as a generalization from experience (e.g. the set of all possible hands in a game of poker). A common aim of statistical analysis is to produce information about some chosen population.
In statistical inference, a subset of the population (a statistical sample) is chosen to represent the population in a statistical analysis. If a sample is chosen properly, characteristics of the entire population that the sample is drawn from can be estimated from corresponding characteristics of the sample.
Subpopulation.
A subset of a population that shares one or more additional properties is called a subpopulation. For example, if the population is all Egyptian people, a subpopulation is all Egyptian males; if the population is all pharmacies in the world, a subpopulation is all pharmacies in Egypt. By contrast, a sample is a subset of a population that is not chosen to share any additional property.
Descriptive statistics may yield different results for different subpopulations. For instance, a particular medicine may have different effects on different subpopulations, and these effects may be obscured or dismissed if such special subpopulations are not identified and examined in isolation.
Similarly, one can often estimate parameters more accurately if one separates out subpopulations: the distribution of heights among people is better modeled by considering men and women as separate subpopulations, for instance.
Populations consisting of subpopulations can be modeled by mixture models, which combine the distributions within subpopulations into an overall population distribution. Even if subpopulations are well-modeled by given simple models, the overall population may be poorly fit by a given simple model – poor fit may be evidence for existence of subpopulations. For example, given two equal subpopulations, both normally distributed, if they have the same standard deviation and different means, the overall distribution will exhibit low kurtosis relative to a single normal distribution – the means of the subpopulations fall on the shoulders of the overall distribution. If sufficiently separated, these form a bimodal distribution, otherwise it simply has a wide peak. Further, it will exhibit overdispersion relative to a single normal distribution with the given variation. Alternatively, given two subpopulations with the same mean and different standard deviations, the overall population will exhibit high kurtosis, with a sharper peak and heavier tails (and correspondingly shallower shoulders) than a single distribution.

</doc>
<doc id="27586" url="https://en.wikipedia.org/wiki?curid=27586" title="Sample (statistics)">
Sample (statistics)

In statistics and quantitative research methodology, a data sample is a set of data collected and/or selected from a statistical population by a defined procedure. The elements of a sample are known as sample points, sampling units or observations.
Typically, the population is very large, making a census or a complete enumeration of all the values in the population impractical or impossible. The sample usually represents a subset of manageable size. Samples are collected and statistics are calculated from the samples so that one can make inferences or extrapolations from the sample to the population. The data sample may be drawn from a population without replacement, in which case it is a subset of a population; or with replacement, in which case it is a multisubset.
Kinds of samples.
A complete sample is a set of objects from a parent population that includes ALL such objects that satisfy a set of well-defined selection criteria. For example, a complete sample of Australian men taller than 2m would consist of a list of every Australian male taller than 2m. But it wouldn't include German males, or tall Australian females, or people shorter than 2m. So to compile such a complete sample requires a complete list of the parent population, including data on height, gender, and nationality for each member of that parent population. In the case of human populations, such a complete list is unlikely to exist (the human population being in the billions). But, such complete samples are often available in other disciplines such as the set of players in a major sports league, the birth dates of the members of a parliament, or a complete magnitude-limited list of astronomical objects.
An unbiased (representative) sample is a set of objects chosen from a complete sample using a selection process that does not depend on the properties of the objects. For example, an unbiased sample of Australian men taller than 2m might consist of a randomly sampled subset of 1% of Australian males taller than 2m. But one chosen from the electoral register might not be unbiased since, for example, males aged under 18 will not be on the electoral register. In an astronomical context, an unbiased sample might consist of that fraction of a complete sample for which data are available, provided the data availability is not biased by individual source properties.
The best way to avoid a biased or unrepresentative sample is to select a random sample, also known as a probability sample. A random sample is defined as a sample where each individual member of the population has a known, non-zero chance of being selected as part of the sample. Several types of random samples are simple random samples, systematic samples, stratified random samples, and cluster random samples.
A sample that is not random is called a non-random sample or a non-probability sampling. Some examples of nonrandom samples are convenience samples, judgment samples, purposive samples, quota samples, snowball samples, and quadrature nodes in quasi-Monte Carlo methods.
Statistic samples have multiple uses. They can be used in many situations.
Mathematical description of random sample.
In mathematical terms, given a random variable "X" with distribution "F", a random sample of length "n" (where "n" may be any of 1,2,3...) is a set of "n" independent, identically distributed (iid) random variables with distribution "F".
A sample concretely represents "n" experiments in which the same quantity is measured. For example, if "X" represents the height of an individual and "n" individuals are measured, formula_1 will be the height of the "i"-th individual. Note that a sample of random variables (i.e. a set of measurable functions) must not be confused with the realizations of these variables (which are the values that these random variables take, formally called random variates). In other words, formula_1 is a function representing the measurement at the i-th experiment and formula_3 is the value actually obtained when making the measurement.
The concept of a sample thus includes the "process" of how the data are obtained (that is, the random variables). This is necessary so that mathematical statements can be made about the sample and statistics computed from it, such as the sample mean and covariance.

</doc>
<doc id="27587" url="https://en.wikipedia.org/wiki?curid=27587" title="Summary statistics">
Summary statistics

In descriptive statistics, summary statistics are used to summarize a set of observations, in order to communicate the largest amount of information as simply as possible. Statisticians commonly try to describe the observations in
A common collection of order statistics used as summary statistics are the five-number summary, sometimes extended to a seven-number summary, and the associated box plot.
Entries in an analysis of variance table can also be regarded as summary statistics.
Examples of summary statistics.
Location.
Common measures of location, or central tendency, are the arithmetic mean, median, mode, and interquartile mean.
Spread.
Common measures of statistical dispersion are the standard deviation, variance, range, interquartile range, absolute deviation and the distance standard deviation. Measures that assess spread in comparison to the typical size of data values include the coefficient of variation.
The Gini coefficient was originally developed to measure income inequality and is equivalent to one of the L-moments.
A simple summary of a dataset is sometimes given by quoting particular order statistics as approximations to selected percentiles of a distribution.
Shape.
Common measures of the shape of a distribution are skewness or kurtosis, while alternatives can be based on L-moments. A different measure is the distance skewness, for which a value of zero implies central symmetry.
Dependence.
The common measure of dependence between paired random variables is the Pearson product-moment correlation coefficient, while a common alternative summary statistic is Spearman's rank correlation coefficient. A value of zero for the distance correlation implies independence.

</doc>
<doc id="27588" url="https://en.wikipedia.org/wiki?curid=27588" title="Range (statistics)">
Range (statistics)

In arithmetic, the range of a set of data is the difference between the largest and smallest values.
However, in descriptive statistics, this concept of range has a more complex meaning. The range is the size of the smallest interval which contains all the data and provides an indication of statistical dispersion. It is measured in the same units as the data. Since it only depends on two of the observations, it is most useful in representing the dispersion of small data sets.
Independent identically distributed continuous random variables.
For "n" independent and identically distributed continuous random variables "X"1, "X"2, ..., "X""n" with cumulative distribution function G("x") and probability density function g("x") the range of the "X""i" is the range of a sample of size "n" from a population with distribution function "G"("x").
Distribution.
The range has cumulative distribution function
Gumbel notes that the "beauty of this formula is completely marred by the facts that, in general, we cannot express "G"("x" + "t") by "G"("x"), and that the numerical integration is lengthy and tiresome."
If the distribution of each "X""i" is limited to the right (or left) then the asymptotic distribution of the range is equal to the asymptotic distribution of the largest (smallest) value. For more general distributions the asymptotic distribution can be expressed as a Bessel function.
Moments.
The mean range is given by
where "x"("G") is the inverse function. In the case where each of the "X""i" has a standard normal distribution, the mean range is given by
Independent nonidentically distributed continuous random variables.
For "n" nonidentically distributed independent continuous random variables "X"1, "X"2, ..., "X""n" with cumulative distribution functions G1("x"), G2("x"), ..., G"n"("x") and probability density functions g1("x"), g2("x"), ..., g"n"("x"), the range has cumulative distribution function 
Independent identically distributed discrete random variables.
For "n" independent and identically distributed discrete random variables "X"1, "X"2, ..., "X""n" with cumulative distribution function G("x") and probability mass function g("x") the range of the "X""i" is the range of a sample of size "n" from a population with distribution function "G"("x"). We can assume without loss of generality that the support of each "X""i" is {1,2,3...,"N"} where "N" is a positive integer or infinity.
Distribution.
The range has probability mass function
Example.
If we suppose that g("x")=1/"N", the discrete uniform distribution for all "x", then we find
Related quantities.
The range is a simple function of the sample maximum and minimum and these are specific examples of order statistics. In particular, the range is a linear function of order statistics, which brings it into the scope of L-estimation.

</doc>
<doc id="27590" url="https://en.wikipedia.org/wiki?curid=27590" title="Standard deviation">
Standard deviation

In statistics, the standard deviation (SD, also represented by the Greek letter sigma σ or s) is a measure that is used to quantify the amount of variation or dispersion of a set of data values. A low standard deviation indicates that the data points tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the data points are spread out over a wider range of values.
The standard deviation of a random variable, statistical population, data set, or probability distribution is the square root of its variance. It is algebraically simpler, though in practice less robust, than the average absolute deviation.
A useful property of the standard deviation is that, unlike the variance, it is expressed in the same units as the data. There are also other measures of deviation from the norm, including mean absolute deviation, which provide different mathematical properties from standard deviation.
In addition to expressing the variability of a population, the standard deviation is commonly used to measure confidence in statistical conclusions. For example, the margin of error in polling data is determined by calculating the expected standard deviation in the results if the same poll were to be conducted multiple times. This derivation of a standard deviation is often called the "standard error" of the estimate or "standard error of the mean" when referring to a mean. It is computed as the standard deviation of all the means that would be computed from that population if an infinite number of samples were drawn and a mean for each sample were computed. It is very important to note that the standard deviation of a population and the standard error of a statistic derived from that population (such as the mean) are quite different but related (related by the inverse of the square root of the number of observations). The reported margin of error of a poll is computed from the standard error of the mean (or alternatively from the product of the standard deviation of the population and the inverse of the square root of the sample size, which is the same thing) and is typically about twice the standard deviation—the half-width of a 95 percent confidence interval. In science, researchers commonly report the standard deviation of experimental data, and only effects that fall much farther than two standard deviations away from what would have been expected are considered statistically significant—normal random error or variation in the measurements is in this way distinguished from causal variation. The standard deviation is also important in finance, where the standard deviation on the rate of return on an investment is a measure of the volatility of the investment.
When only a sample of data from a population is available, the term standard deviation of the sample or sample standard deviation can refer to either the above-mentioned quantity as applied to those data or to a modified quantity that is a better estimate of the population standard deviation (the standard deviation of the entire population).
Basic examples.
For a finite set of numbers, the standard deviation is found by taking the square root of the average of the squared deviations of the values from their average value. For example, the marks of a class of eight students (that is, a population) are the following eight values:
These eight data points have the mean (average) of 5:
First, calculate the deviations of each data point from the mean, and square the result of each:
The variance is the mean of these values:
and the "population" standard deviation is equal to the square root of the variance:
This formula is valid only if the eight values with which we began form the complete population. If the values instead were a random sample drawn from some larger parent population (for example, they were 8 marks randomly chosen from a class of 20), then we would have divided by instead of in the denominator of the last formula, and then the quantity thus obtained would be called the "sample" standard deviation. Dividing by "n"−1 gives a better estimate of the population standard deviation for the larger parent population than dividing by "n", which gives a result which is correct for the sample only. This is known as "Bessel's correction".
As a slightly more complicated real-life example, the average height for adult men in the United States is about 70 inches, with a standard deviation of around 3 inches. This means that most men (about 68%, assuming a normal distribution) have a height within 3 inches of the mean (67–73 inches)  – one standard deviation – and almost all men (about 95%) have a height within 6 inches of the mean (64–76 inches) – two standard deviations. If the standard deviation were zero, then all men would be exactly 70 inches tall. If the standard deviation were 20 inches, then men would have much more variable heights, with a typical range of about 50–90 inches. Three standard deviations account for 99.7% of the sample population being studied, assuming the distribution is normal (bell-shaped).
Definition of population values.
Let "X" be a random variable with mean value "μ":
Here the operator "E" denotes the average or expected value of "X". Then the standard deviation of "X" is the quantity
(derived using the properties of expected value).
In other words, the standard deviation "σ" (sigma) is the square root of the variance of "X"; i.e., it is the square root of the average value of ("X" − "μ")2.
The standard deviation of a (univariate) probability distribution is the same as that of a random variable having that distribution. Not all random variables have a standard deviation, since these expected values need not exist. For example, the standard deviation of a random variable that follows a Cauchy distribution is undefined because its expected value "μ" is undefined.
Discrete random variable.
In the case where "X" takes random values from a finite data set "x"1, "x"2, ..., "xN", with each value having the same probability, the standard deviation is
or, using summation notation,
If, instead of having equal probabilities, the values have different probabilities, let "x"1 have probability "p"1, "x"2 have probability "p"2, ..., "x""N" have probability "p"N. In this case, the standard deviation will be
Continuous random variable.
The standard deviation of a continuous real-valued random variable "X" with probability density function "p"("x") is
and where the integrals are definite integrals taken for "x" ranging over the set of possible values of the random variable "X".
In the case of a parametric family of distributions, the standard deviation can be expressed in terms of the parameters. For example, in the case of the log-normal distribution with parameters "μ" and "σ"2, the standard deviation is [(exp("σ"2) − 1)exp(2"μ" + "σ"2)]1/2.
Estimation.
One can find the standard deviation of an entire population in cases (such as standardized testing) where every member of a population is sampled. In cases where that cannot be done, the standard deviation "σ" is estimated by examining a random sample taken from the population and computing a statistic of the sample, which is used as an estimate of the population standard deviation. Such a statistic is called an estimator, and the estimator (or the value of the estimator, namely the estimate) is called a sample standard deviation, and is denoted by "s" (possibly with modifiers). However, unlike in the case of estimating the population mean, for which the sample mean is a simple estimator with many desirable properties (unbiased, efficient, maximum likelihood), there is no single estimator for the standard deviation with all these properties, and unbiased estimation of standard deviation is a very technically involved problem. Most often, the standard deviation is estimated using the "corrected sample standard deviation" (using "N" − 1), defined below, and this is often referred to as the "sample standard deviation", without qualifiers. However, other estimators are better in other respects: the uncorrected estimator (using "N") yields lower mean squared error, while using "N" − 1.5 (for the normal distribution) almost completely eliminates bias.
Uncorrected sample standard deviation.
Firstly, the formula for the "population" standard deviation (of a finite population) can be applied to the sample, using the size of the sample as the size of the population (though the actual population size from which the sample is drawn may be much larger). This estimator, denoted by "s""N", is known as the uncorrected sample standard deviation, or sometimes the standard deviation of the sample (considered as the entire population), and is defined as follows:
where formula_13 are the observed values of the sample items and formula_14 is the mean value of these observations, while the denominator "N" stands for the size of the sample: this is the square root of the sample variance, which is the average of the squared deviations about the sample mean.
This is a consistent estimator (it converges in probability to the population value as the number of samples goes to infinity), and is the maximum-likelihood estimate when the population is normally distributed. However, this is a biased estimator, as the estimates are generally too low. The bias decreases as sample size grows, dropping off as 1/"n", and thus is most significant for small or moderate sample sizes; for formula_15 the bias is below 1%. Thus for very large sample sizes, the uncorrected sample standard deviation is generally acceptable. This estimator also has a uniformly smaller mean squared error than the corrected sample standard deviation.
Corrected sample standard deviation.
If the "biased sample variance" (the second central moment of the sample, which is a downward-biased estimate of the population variance) is used to compute an estimate of the population's standard deviation, the result is
Here taking the square root introduces further downward bias, by Jensen's inequality, due to the square root being a concave function. The bias in the variance is easily corrected, but the bias from the square root is more difficult to correct, and depends on the distribution in question.
An unbiased estimator for the "variance" is given by applying Bessel's correction, using "N" − 1 instead of "N" to yield the "unbiased sample variance," denoted "s"2:
This estimator is unbiased if the variance exists and the sample values are drawn independently with replacement. "N" − 1 corresponds to the number of degrees of freedom in the vector of deviations from the mean, formula_18
Taking square roots reintroduces bias (because the square root is a nonlinear function, which does not commute with the expectation), yielding the corrected sample standard deviation, denoted by "s:"
As explained above, while "s"2 is an unbiased estimator for the population variance, "s" is still a biased estimator for the population standard deviation, though markedly less biased than the uncorrected sample standard deviation. The bias is still significant for small samples ("N" less than 10), and also drops off as 1/"N" as sample size increases. This estimator is commonly used and generally known simply as the "sample standard deviation".
Unbiased sample standard deviation.
For unbiased estimation of standard deviation, there is no formula that works across all distributions, unlike for mean and variance. Instead, "s" is used as a basis, and is scaled by a correction factor to produce an unbiased estimate. For the normal distribution, an unbiased estimator is given by "s"/"c"4, where the correction factor (which depends on "N") is given in terms of the Gamma function, and equals:
This arises because the sampling distribution of the sample standard deviation follows a (scaled) chi distribution, and the correction factor is the mean of the chi distribution.
An approximation can be given by replacing "N" − 1 with "N" − 1.5, yielding:
The error in this approximation decays quadratically (as 1/"N"2), and it is suited for all but the smallest samples or highest precision: for n = 3 the bias is equal to 1.3%, and for n = 9 the bias is already less than 0.1%.
For other distributions, the correct formula depends on the distribution, but a rule of thumb is to use the further refinement of the approximation:
where "γ"2 denotes the population excess kurtosis. The excess kurtosis may be either known beforehand for certain distributions, or estimated from the data.
Confidence interval of a sampled standard deviation.
The standard deviation we obtain by sampling a distribution is itself not absolutely accurate, both for mathematical reasons (explained here by the confidence interval) and for practical reasons of measurement (measurement error). The mathematical effect can be described by the confidence interval or CI. 
To show how a larger sample will make the confidence interval more narrow, consider the following examples: 
For a small population of N=2, the 95% CI of the SD is from 0.45*SD to 31.9*SD. In other words, the standard deviation of the distribution in 95% of the cases can be larger by a factor of 31 or smaller by a factor of 2. For a larger population of N=10, the CI is 0.69*SD to 1.83*SD. So even with a sample population of 10, the actual SD can still be almost a factor 2 higher than the sampled SD. For a sample population N=100, this is down to 0.88*SD to 1.16*SD. To be more certain that the sampled SD is close to the actual SD we need to sample a large number of points.
Identities and mathematical properties.
The standard deviation is invariant under changes in location, and scales directly with the scale of the random variable. Thus, for a constant "c" and random variables "X" and "Y":
The standard deviation of the sum of two random variables can be related to their individual standard deviations and the covariance between them:
where formula_27 and formula_28 stand for variance and covariance, respectively.
The calculation of the sum of squared deviations can be related to moments calculated directly from the data. In the following formula, the letter E is interpreted to mean expected value, i.e., mean.
The sample standard deviation can be computed as:
For a finite population with equal probabilities at all points, we have
This means that the standard deviation is equal to the square root of the difference between the average of the squares of the values and the square of the average value.
See computational formula for the variance for proof, and for an analogous result for the sample standard deviation.
Interpretation and application.
A large standard deviation indicates that the data points can spread far from the mean and a small standard deviation indicates that they are clustered closely around the mean.
For example, each of the three populations {0, 0, 14, 14}, {0, 6, 8, 14} and {6, 6, 8, 8} has a mean of 7. Their standard deviations are 7, 5, and 1, respectively. The third population has a much smaller standard deviation than the other two because its values are all close to 7. It will have the same units as the data points themselves. If, for instance, the data set {0, 6, 8, 14} represents the ages of a population of four siblings in years, the standard deviation is 5 years. As another example, the population {1000, 1006, 1008, 1014} may represent the distances traveled by four athletes, measured in meters. It has a mean of 1007 meters, and a standard deviation of 5 meters.
Standard deviation may serve as a measure of uncertainty. In physical science, for example, the reported standard deviation of a group of repeated measurements gives the precision of those measurements. When deciding whether measurements agree with a theoretical prediction, the standard deviation of those measurements is of crucial importance: if the mean of the measurements is too far away from the prediction (with the distance measured in standard deviations), then the theory being tested probably needs to be revised. This makes sense since they fall outside the range of values that could reasonably be expected to occur, if the prediction were correct and the standard deviation appropriately quantified. See prediction interval.
While the standard deviation does measure how far typical values tend to be from the mean, other measures are available. An example is the mean absolute deviation, which might be considered a more direct measure of average distance, compared to the root mean square distance inherent in the standard deviation.
Application examples.
The practical value of understanding the standard deviation of a set of values is in appreciating how much variation there is from the average (mean).
Experiment, industrial and hypothesis testing.
Standard deviation is often used to compare real-world data against a model to test the model.
For example, in industrial applications the weight of products coming off a production line may need to legally be some value. By weighing some fraction of the products an average weight can be found, which will always be slightly different to the long term average. By using standard deviations a minimum and maximum value can be calculated that the averaged weight will be within some very high percentage of the time (99.9% or more). If it falls outside the range then the production process may need to be corrected. Statistical tests such as these are particularly important when the testing is relatively expensive. For example, if the product needs to be opened and drained and weighed, or if the product was otherwise used up by the test.
In experimental science a theoretical model of reality is used. Particle physics conventionally uses a standard of "5 sigma" for the declaration of a discovery. A five-sigma level translates to one chance in 3.5 million that a random fluctuation would yield the result. This level of certainty was required in order to assert that a particle consistent with the Higgs boson had been discovered in two independent experiments at CERN, and this was also the significance level leading to the declaration of the first detection of gravitational waves.
Weather.
As a simple example, consider the average daily maximum temperatures for two cities, one inland and one on the coast. It is helpful to understand that the range of daily maximum temperatures for cities near the coast is smaller than for cities inland. Thus, while these two cities may each have the same average maximum temperature, the standard deviation of the daily maximum temperature for the coastal city will be less than that of the inland city as, on any particular day, the actual maximum temperature is more likely to be farther from the average maximum temperature for the inland city than for the coastal one.
Finance.
In finance, standard deviation is often used as a measure of the risk associated with price-fluctuations of a given asset (stocks, bonds, property, etc.), or the risk of a portfolio of assets (actively managed mutual funds, index mutual funds, or ETFs). Risk is an important factor in determining how to efficiently manage a portfolio of investments because it determines the variation in returns on the asset and/or portfolio and gives investors a mathematical basis for investment decisions (known as mean-variance optimization). The fundamental concept of risk is that as it increases, the expected return on an investment should increase as well, an increase known as the risk premium. In other words, investors should expect a higher return on an investment when that investment carries a higher level of risk or uncertainty. When evaluating investments, investors should estimate both the expected return and the uncertainty of future returns. Standard deviation provides a quantified estimate of the uncertainty of future returns.
For example, let's assume an investor had to choose between two stocks. Stock A over the past 20 years had an average return of 10 percent, with a standard deviation of 20 percentage points (pp) and Stock B, over the same period, had average returns of 12 percent but a higher standard deviation of 30 pp. On the basis of risk and return, an investor may decide that Stock A is the safer choice, because Stock B's additional two percentage points of return is not worth the additional 10 pp standard deviation (greater risk or uncertainty of the expected return). Stock B is likely to fall short of the initial investment (but also to exceed the initial investment) more often than Stock A under the same circumstances, and is estimated to return only two percent more on average. In this example, Stock A is expected to earn about 10 percent, plus or minus 20 pp (a range of 30 percent to −10 percent), about two-thirds of the future year returns. When considering more extreme possible returns or outcomes in future, an investor should expect results of as much as 10 percent plus or minus 60 pp, or a range from 70 percent to −50 percent, which includes outcomes for three standard deviations from the average return (about 99.7 percent of probable returns).
Calculating the average (or arithmetic mean) of the return of a security over a given period will generate the expected return of the asset. For each period, subtracting the expected return from the actual return results in the difference from the mean. Squaring the difference in each period and taking the average gives the overall variance of the return of the asset. The larger the variance, the greater risk the security carries. Finding the square root of this variance will give the standard deviation of the investment tool in question.
Population standard deviation is used to set the width of Bollinger Bands, a widely adopted technical analysis tool. For example, the upper Bollinger Band is given as The most commonly used value for "n" is 2; there is about a five percent chance of going outside, assuming a normal distribution of returns.
Financial time series are known to be non-stationary series, whereas the statistical calculations above, such as standard deviation, apply only to stationary series. To apply the above statistical tools to non-stationary series, the series first must be transformed to a stationary series, enabling use of statistical tools that now have a valid basis from which to work.
Geometric interpretation.
To gain some geometric insights and clarification, we will start with a population of three values, "x"1, "x"2, "x"3. This defines a point "P" = ("x"1, "x"2, "x"3) in R3. Consider the line "L" = {("r", "r", "r") : "r" ∈ R}. This is the "main diagonal" going through the origin. If our three given values were all equal, then the standard deviation would be zero and "P" would lie on "L". So it is not unreasonable to assume that the standard deviation is related to the "distance" of "P" to "L". And that is indeed the case. To move orthogonally from "L" to the point "P", one begins at the point:
whose coordinates are the mean of the values we started out with. 
formula_33 is on formula_34 therefore formula_35 with formula_36
The line formula_34 is to be orthogonal to the vector from formula_33 to formula_39. Therefore:
formula_40
A little algebra shows that the distance between "P" and "M" (which is the same as the orthogonal distance between "P" and the line "L") formula_41 is equal to the standard deviation of the vector "x"1, "x"2, "x"3, multiplied by the square root of the number of dimensions of the vector (3 in this case.)
Chebyshev's inequality.
An observation is rarely more than a few standard deviations away from the mean. Chebyshev's inequality ensures that, for all distributions for which the standard deviation is defined, the amount of data within a number of standard deviations of the mean is at least as much as given in the following table.
Rules for normally distributed data.
The central limit theorem says that the distribution of an average of many independent, identically distributed random variables tends toward the famous bell-shaped normal distribution with a probability density function of:
where "μ" is the expected value of the random variables, "σ" equals their distribution's standard deviation divided by "n"1/2, and "n" is the number of random variables. The standard deviation therefore is simply a scaling variable that adjusts how broad the curve will be, though it also appears in the normalizing constant.
If a data distribution is approximately normal, then the proportion of data values within "z" standard deviations of the mean is defined by:
where formula_44 is the error function. The proportion that is less than or equal to a number, x, is given by the cumulative distribution function:
If a data distribution is approximately normal then about 68 percent of the data values are within one standard deviation of the mean (mathematically, μ ± σ, where μ is the arithmetic mean), about 95 percent are within two standard deviations (μ ± 2σ), and about 99.7 percent lie within three standard deviations (μ ± 3σ). This is known as the "68-95-99.7 rule", or "the empirical rule".
For various values of "z", the percentage of values expected to lie in and outside the symmetric interval, CI = (−"zσ", "zσ"), are as follows:
Relationship between standard deviation and mean.
The mean and the standard deviation of a set of data are descriptive statistics usually reported together. In a certain sense, the standard deviation is a "natural" measure of statistical dispersion if the center of the data is measured about the mean. This is because the standard deviation from the mean is smaller than from any other point. The precise statement is the following: suppose "x"1, ..., "x""n" are real numbers and define the function:
Using calculus or by completing the square, it is possible to show that σ("r") has a unique minimum at the mean:
Variability can also be measured by the coefficient of variation, which is the ratio of the standard deviation to the mean. It is a dimensionless number.
Standard deviation of the mean.
Often, we want some information about the precision of the mean we obtained. We can obtain this by determining the standard deviation of the sampled mean.
Assuming statistical independence of the values in the sample, the standard deviation of the mean is related to the standard deviation of the distribution by:
where "N" is the number of observations in the sample used to estimate the mean. This can easily be proven with (see basic properties of the variance):
hence
Resulting in:
It should be emphasized that in order to estimate standard deviation of the mean formula_52 it is necessary to know standard deviation of the entire population formula_53 beforehand. However, in most applications this parameter is unknown. For example, if series of 10 measurements of previously unknown quantity is performed in laboratory, it is possible to calculate resulting sample mean and sample standard deviation, but it is impossible to calculate standard deviation of the mean.
Rapid calculation methods.
The following two formulas can represent a running (repeatedly updated) standard deviation. A set of two power sums "s"1 and "s"2 are computed over a set of "N" values of "x", denoted as "x"1, ..., "x""N":
Given the results of these running summations, the values "N", "s"1, "s"2 can be used at any time to compute the "current" value of the running standard deviation:
Where N, as mentioned above, is the size of the set of values.
Similarly for sample standard deviation,
In a computer implementation, as the three "s""j" sums become large, we need to consider round-off error, arithmetic overflow, and arithmetic underflow. The method below calculates the running sums method with reduced rounding errors. This is a "one pass" algorithm for calculating variance of "n" samples without the need to store prior data during the calculation. Applying this method to a time series will result in successive values of standard deviation corresponding to "n" data points as "n" grows larger with each new sample, rather than a constant-width sliding window calculation.
For "k" = 1, ..., "n":
where A is the mean value.
Note: formula_59 since formula_60 or formula_61
Sample variance:
Population variance:
Weighted calculation.
When the values "xi" are weighted with unequal weights "wi", the power sums "s"0, "s"1, "s"2 are each computed as:
And the standard deviation equations remain unchanged. Note that "s"0 is now the sum of the weights and not the number of samples "N".
The incremental method with reduced rounding errors can also be applied, with some additional complexity.
A running sum of weights must be computed for each "k" from 1 to "n":
and places where 1/"n" is used above must be replaced by "wi"/"Wn":
In the final division,
and
where n is the total number of elements, and n' is the number of elements with non-zero weights.
The above formulas become equal to the simpler formulas given above if weights are taken as equal to one.
Combining standard deviations.
Population-based statistics.
The populations of sets, which may overlap, can be calculated simply as follows:
Standard deviations of non-overlapping () sub-populations can be aggregated as follows if the size (actual or relative to one another) and means of each are known:
For example, suppose it is known that the average American man has a mean height of 70 inches with a standard deviation of three inches and that the average American woman has a mean height of 65 inches with a standard deviation of two inches. Also assume that the number of men, "N", is equal to the number of women. Then the mean and standard deviation of heights of American adults could be calculated as:
For the more general case of "M" non-overlapping populations, "X"1 through "X""M", and the aggregate population formula_72:
where
If the size (actual or relative to one another), mean, and standard deviation of two overlapping populations are known for the populations as well as their intersection, then the standard deviation of the overall population can still be calculated as follows:
If two or more sets of data are being added together datapoint by datapoint, the standard deviation of the result can be calculated if the standard deviation of each data set and the covariance between each pair of data sets is known:
For the special case where no correlation exists between any pair of data sets, then the relation reduces to the root-mean-square:
Sample-based statistics.
Standard deviations of non-overlapping () sub-samples can be aggregated as follows if the actual size and means of each are known:
For the more general case of "M" non-overlapping data sets, "X"1 through "X""M", and the aggregate data set formula_72:
where:
If the size, mean, and standard deviation of two overlapping samples are known for the samples as well as their intersection, then the standard deviation of the aggregated sample can still be calculated. In general:
History.
The term "standard deviation" was first used in writing by Karl Pearson in 1894, following his use of it in lectures. This was as a replacement for earlier alternative names for the same idea: for example, Gauss used "mean error". It may be worth noting in passing that the mean error is mathematically distinct from the standard deviation.

</doc>
<doc id="27592" url="https://en.wikipedia.org/wiki?curid=27592" title="Statistical assumption">
Statistical assumption

Statistics, like all mathematical disciplines, does not infer valid conclusions from nothing. Inferring interesting conclusions about real statistical populations almost always requires some background assumptions. Those assumptions must be made carefully, because incorrect assumptions can generate wildly inaccurate conclusions.
Here are some examples of statistical assumptions.
Classes of assumptions.
There are two approaches to statistical inference: "model-based inference" and "design-based inference". Both approaches rely on some statistical model to represent the data-generating process. In the model-based approach, the model is taken to be initially unknown, and one of the goals is to select an appropriate model for inference. In the design-based approach, the model is taken to be known, and one of the goals is to ensure that the sample data are selected randomly enough for inference.
Statistical assumptions can be put into two classes, depending upon which approach to inference is used.
The model-based approach is much the most commonly used in statistical inference; the design-based approach is used mainly with survey sampling. With the model-based approach, all the assumptions are effectively encoded in the model.
Checking assumptions.
Given that the validity of any conclusion drawn from a statistical inference depends on the validity of the assumptions made, it is clearly important that those assumptions should be reviewed at some stage. Some instances—for example where data are lacking—may require that researchers judge whether an assumption is reasonable. Researchers can expand this somewhat to consider what effect a departure from the assumptions might produce. Where more extensive data are available, various types of procedures for statistical model validation are available—e.g. for regression model validation.

</doc>
<doc id="27593" url="https://en.wikipedia.org/wiki?curid=27593" title="Independence (probability theory)">
Independence (probability theory)

In probability theory, two events are independent, statistically independent, or stochastically independent if the occurrence of one does not affect the probability of the other. Similarly, two random variables are independent if the realization of one does not affect the probability distribution of the other.
The concept of independence extends to dealing with collections of more than two events or random variables, in which case the events are pairwise independent if each pair are independent of each other, and the events are mutually independent if each event is independent of each other combination of events.
Definition.
For events.
Two events.
Two events "A" and "B" are independent (often written as formula_1 or formula_2) if and only if their joint probability equals the product of their probabilities:
Why this defines independence is made clear by rewriting with conditional probabilities:
and similarly
Thus, the occurrence of "B" does not affect the probability of "A", and vice versa. Although the derived expressions may seem more intuitive, they are not the preferred definition, as the conditional probabilities may be undefined if "P"("A") or "P"("B") are 0. Furthermore, the preferred definition makes clear by symmetry that when "A" is independent of "B", "B" is also independent of "A".
More than two events.
A finite set of events {"Ai"} is pairwise independent if and only if every pair of events is independent—that is, if and only if for all distinct pairs of indices "m", "k",
A finite set of events is mutually independent if and only if every event is independent of any intersection of the other events—that is, if and only if for every "n"-element subset {"Ai"},
This is called the "multiplication rule" for independent events. Note that it is not a single condition involving only the product of all the probabilities of all single events (see below for a counterexample); it must hold true for all subset of events.
For more than two events, a mutually independent set of events is (by definition) pairwise independent; but the converse is not necessarily true (see below for a counterexample).
For random variables.
Two random variables.
Two random variables "X" and "Y" are independent if and only if (iff) the elements of the π-system generated by them are independent; that is to say, for every "a" and "b", the events {"X" ≤ "a"} and {"Y" ≤ "b"} are independent events (as defined above). That is, "X" and "Y" with cumulative distribution functions formula_8 and formula_9, and probability densities formula_10 and formula_11, are independent iff the combined random variable ("X", "Y") has a joint cumulative distribution function
or equivalently, if the joint density exists, 
More than two random variables.
A set of random variables is pairwise independent if and only if every pair of random variables is independent.
A set of random variables is mutually independent if and only if for any finite subset formula_14 and any finite sequence of numbers formula_15, the events formula_16 are mutually independent events (as defined above).
The measure-theoretically inclined may prefer to substitute events {"X" ∈ "A"} for events {"X" ≤ "a"} in the above definition, where "A" is any Borel set. That definition is exactly equivalent to the one above when the values of the random variables are real numbers. It has the advantage of working also for complex-valued random variables or for random variables taking values in any measurable space (which includes topological spaces endowed by appropriate σ-algebras).
Conditional independence.
Intuitively, two random variables "X" and "Y" are conditionally independent given "Z" if, once "Z" is known, the value of "Y" does not add any additional information about "X". For instance, two measurements "X" and "Y" of the same underlying quantity "Z" are not independent, but they are conditionally independent given "Z" (unless the errors in the two measurements are somehow connected).
The formal definition of conditional independence is based on the idea of conditional distributions. If "X", "Y", and "Z" are discrete random variables, then we define "X" and "Y" to be "conditionally independent given" "Z" if
for all "x", "y" and "z" such that P("Z" = "z") > 0. On the other hand, if the random variables are continuous and have a joint probability density function "p", then "X" and "Y" are conditionally independent given "Z" if
for all real numbers "x", "y" and "z" such that "p""Z"("z") > 0.
If "X" and "Y" are conditionally independent given "Z", then
for any "x", "y" and "z" with P("Z" = "z") > 0. That is, the conditional distribution for "X" given "Y" and "Z" is the same as that given "Z" alone. A similar equation holds for the conditional probability density functions in the continuous case.
Independence can be seen as a special kind of conditional independence, since probability can be seen as a kind of conditional probability given no events.
Independent σ-algebras.
The definitions above are both generalized by the following definition of independence for σ-algebras. Let (Ω, Σ, Pr) be a probability space and let A and B be two sub-σ-algebras of Σ. A and B are said to be independent if, whenever "A" ∈ A and "B" ∈ B,
Likewise, a finite family of σ-algebras formula_21 is said to be independent if and only if
and an infinite family of σ-algebras is said to be independent if all its finite subfamilies are independent.
The new definition relates to the previous ones very directly:
Using this definition, it is easy to show that if "X" and "Y" are random variables and "Y" is constant, then "X" and "Y" are independent, since the σ-algebra generated by a constant random variable is the trivial σ-algebra {∅, Ω}. Probability zero events cannot affect independence so independence also holds if "Y" is only Pr-almost surely constant.
Properties.
Self-independence.
Note that an event is independent of itself if and only if
Thus an event is independent of itself if and only if it almost surely occurs or its complement almost surely occurs.
Expectation and covariance.
If "X" and "Y" are independent, then the expectation operator "E" has the property
and the covariance cov("X", "Y") is zero, since we have
Characteristic function.
Two random variables "X" and "Y" are independent if and only if the characteristic function of the random vector
("X", "Y") satisfies
In particular the characteristic function of their sum is the product of their marginal characteristic functions:
though the reverse implication is not true. Random variables that satisfy the latter condition are called subindependent.
Examples.
Rolling a die.
The event of getting a 6 the first time a die is rolled and the event of getting a 6 the second time are "independent". By contrast, the event of getting a 6 the first time a die is rolled and the event that the sum of the numbers seen on the first and second trials is 8 are "not" independent.
Drawing cards.
If two cards are drawn "with" replacement from a deck of cards, the event of drawing a red card on the first trial and that of drawing a red card on the second trial are "independent". By contrast, if two cards are drawn "without" replacement from a deck of cards, the event of drawing a red card on the first trial and that of drawing a red card on the second trial are again "not" independent.
Pairwise and mutual independence.
Consider the two probability spaces shown. In both cases, "P"("A") = "P"("B") = 1/2 and "P"("C") = 1/4 The first space is pairwise independent but not mutually independent. The second space is both pairwise independent and mutually independent. To illustrate the difference, consider conditioning on two events. In the pairwise independent case, although any one event is independent of each of the other two individually, it is not independent of the intersection of the other two:
In the mutually independent case however:
Mutual independence.
It is possible to create a three-event example in which
and yet no two of the three events are pairwise independent (and hence the set of events are not mutually independent). This example shows that mutual independence involves requirements on the products of probabilities of all combinations of events, not just the single events as in this example.

</doc>
<doc id="27595" url="https://en.wikipedia.org/wiki?curid=27595" title="Sherrié Austin">
Sherrié Austin

Sherrie Veronica Krenn (born 28 August 1970), known professionally as Sherrié Austin, is an Australian actress and singer. Active as a singer since her teenage years, Austin initially recorded as one half of the duo Colourhaus, which also featured Phil Radford. After leaving Colourhaus, she recorded one album in her native Australia before moving to the United States in pursuit of a singing career.
There, she recorded four studio albums, and charted several singles on the "Billboard" Hot Country Songs charts. Her highest-charting single was the No. 18 "Streets of Heaven" in 2003. She has sold over 430,000 albums and 288,000 singles in her career, according to Nielsen SoundScan. Her fifth album was released on 15 November 2011.
Career.
Early career.
Austin got her start in music opening for Johnny Cash in Australia at the age of 14. She later moved to the United States where she took up acting. She is most known in the United States for playing the role of Pippa McKenna on "The Facts of Life" in 1987–88. In 1991 she appeared as "Lady Penelope" on episode No. 20 of the first season of the TV comedy series "Fresh Prince of Bel Air" starring Will Smith. In the 1990s, she started a singing career, teaming up with Phil Radford in 1992 to form a duo called Colourhaus, which released one album, "Water to the Soul".
The Colorhaus song "Color Me You" was on the soundtrack of the "Rookie of the Year" episode of the TV series, Baywatch on Oct. 05, 1992.
Nashville move.
Afterward, Austin moved to Nashville, Tennessee, to pursue a career in country music. Her first solo contract was with Arista Nashville, with the album "Words" being released in 1997. It produced singles in "Lucky in Love", "One Solitary Tear", "Put Your Heart into It", and "Innocent Man". "Lucky in Love" and "Put Your Heart into It" both reached Top 40 on the country charts with a peak of No. 34 each.
Her second and final album for Arista was 1999's "Love in the Real World", led off by the No. 29 "Never Been Kissed", which was followed by "Little Bird." After RCA acquired Arista Records, Austin's publishing company, Reynsong Publishing, formed Wrensong Entertainment and signed to Madacy Entertainment for her next album, "Followin' a Feelin, which produced another single in its lead-off single, a cover of Dolly Parton's "Jolene".
Later, she switched to the independent Broken Bow Records label. Her fourth album of country music, titled "Streets of Heaven", produced her biggest country hit in its title track. Following this single was "Son of a Preacher Man", a cover of the Dusty Springfield song, which was never included on an album.
Broadway years.
Austin moved to New York City in 2005 and appeared in the New York Musical Theater Festival's production of "Bonnie & Clyde". The New York Times commented that she was "a sultry young country music singer who plays the notorious criminal Bonnie Parker and does for this musical what Reba McEntire did for the 1999 revival of "Annie Get Your Gun." That twang in her voice provides some much-needed authenticity in excellent pop-country numbers like "Ain't Goin' Back." And it's easy to tell by her hip-swiveling poses that this is a woman who knows how to hold a stage."
The following year, Austin performed in "Ring Of Fire- The Johnny Cash Musical Show" at the Ethel Barrymore Theatre. She also performed in the production of "Warrior", a musical about the American-Indian athlete Jim Thorpe, where CurtainUp.com described her as "outstanding." She returned to Nashville in 2006.
Return to Nashville.
Austin co-wrote Danielle Peck's 2007 single "Bad for Me", the title track to Blake Shelton's 2008 album "Startin' Fires", George Strait's "Where Have I Been All My Life" off his 2009 album "Twang", and Tim McGraw's duet, with wife Faith Hill, "Shotgun Rider" off his "Let It Go" album in 2007. Austin left Broken Bow in 2008.
She was named one of 2011's "25 Most Beautiful People" by "Nashville Lifestyles Magazine".
In the summer of 2011, The Sundance Channel announced that Austin and her friend Shane Stevens would be on the second season of "Girls Who Like Boys Who Like Boys", which was filmed in Nashville and features women and their gay best friends. The season started 18 November 2011.
Latest release.
Austin's most recent album, "Circus Girl", her first in eight years, is described as a series of stories interpreted by a strong woman, about women, and for women, and Sherrié feels it’s something her female fans have been clamouring for, for quite some time.
"The last few years I had been complaining about that fact that there weren’t any females speaking to women above the age of 30, so I started thinking about how I was writing my songs and came up with the idea for “Friday Night Girls" ...I wanted to write a three-minute song with every Sex and the City episode that had ever existed, so I did. I quickly noticed that the women in my audiences loved it and so I switched my songwriting focus for a while to concentrate on that audience, who are my peers, to speak to them,” says Austin.
"Circus Girl" was released independently on 15 November 2011.

</doc>
<doc id="27596" url="https://en.wikipedia.org/wiki?curid=27596" title="Stratified sampling">
Stratified sampling

In statistics, stratified sampling is a method of sampling from a population.
In statistical surveys, when subpopulations within an overall population vary, it is advantageous to sample each subpopulation (stratum) independently. Stratification is the process of dividing members of the population into homogeneous subgroups before sampling. The strata should be mutually exclusive: every element in the population must be assigned to only one stratum. The strata should also be collectively exhaustive: no population element can be excluded. Then simple random sampling or systematic sampling is applied within each stratum. This often improves the representativeness of the sample by reducing sampling error. It can produce a weighted mean that has less variability than the arithmetic mean of a simple random sample of the population.
In computational statistics, stratified sampling is a method of variance reduction when Monte Carlo methods are used to estimate population statistics from a known population.
Example.
Assume that we need to estimate average number of votes for each candidate in an election. Assume that country has 3 towns: Town A has 1 million factory workers, Town B has 2 million office workers and Town C has 3 million retirees. We can choose to get a random sample of size 60 over entire population but there is some chance that the random sample turns out to be not well balanced across these towns and hence is biased causing a significant error in estimation. Instead if we choose to take a random sample of 10, 20 and 30 from Town A, B and C respectively then we can produce a smaller error in estimation for the same total size of sample.
Stratified sampling strategies.
Stratified sampling ensures that at least one observation is picked from each of the strata, even if probability of it being selected is close to 0. Hence the statistical properties of the population may not be preserved if there are thin strata. A rule of thumb that is used to ensure this is that the population should consist of no more than six strata, but depending on special cases the rule can change - for example if there are 100 strata each with 1 million observations, it is perfectly fine to do a 10% stratified sampling on them.
A real-world example of using stratified sampling would be for a political survey. If the respondents needed to reflect the diversity of the population, the researcher would specifically seek to include participants of various minority groups such as race or religion, based on their proportionality to the total population as mentioned above. A stratified survey could thus claim to be more representative of the population than a survey of simple random sampling or systematic sampling.
Advantages.
The reasons to use stratified sampling rather than simple random sampling include
If the population density varies greatly within a region, stratified sampling will ensure that estimates can be made with equal accuracy in different parts of the region, and that comparisons of sub-regions can be made with equal statistical power. For example, in Ontario a survey taken throughout the province might use a larger sampling fraction in the less populated north, since the disparity in population between north and south is so great that a sampling fraction based on the provincial sample as a whole might result in the collection of only a handful of data from the north.
Randomized stratification can also be used to improve population representativeness in a study.
Disadvantages.
Stratified sampling is not useful when the population cannot be exhaustively partitioned into disjoint subgroups.
It would be a misapplication of the technique to make subgroups' sample sizes proportional to the amount of data available from the subgroups, rather than scaling sample sizes to subgroup sizes (or to their variances, if known to vary significantly e.g. by means of an F Test). Data representing each subgroup are taken to be of equal importance if suspected variation among them warrants stratified sampling. If subgroups' variances differ significantly and the data need to be stratified by variance, then there is no way to make the subgroup sample sizes proportional (at the same time) to the subgroups' sizes within the total population. For an efficient way to partition sampling resources among groups that vary in their means, their variances, and their costs, see "optimum allocation".
The problem of stratified sampling in the case of unknown class priors (ratio of subpopulations in the entire population) can have deleterious effect on the performance of any analysis on the dataset, e.g. classification. In that regard, minimax sampling ratio can be used to make the dataset robust with respect to uncertainty in the underlying data generating process.
Mean and Variance.
The mean and variance of stratified random sampling is given by,
formula_1
formula_2
where,
formula_3 Size of entire population, should equal to sum of all stratum sizes
formula_4 Size of each stratum
formula_5 Number of observations in each stratum
formula_6 Count of strata
formula_7 sample standard deviation of stratum formula_8
formula_9 sample mean of stratum formula_8
Strata Size Calculation.
In general the size of the sample in each stratum is taken in proportion to the size of the stratum. This is called proportional allocation. Suppose that in a company there are the following staff:
and we are asked to take a sample of 40 staff, stratified according to the above categories.
The first step is to find the total number of staff (180) and calculate the percentage in each group.
This tells us that of our sample of 40,
Another easy way without having to calculate the percentage is to multiply each group size by the sample size and divide by the total population size (size of entire staff):

</doc>
<doc id="27600" url="https://en.wikipedia.org/wiki?curid=27600" title="Science Fiction and Fantasy Writers of America">
Science Fiction and Fantasy Writers of America

Science Fiction and Fantasy Writers of America, or SFWA ( or ) is a nonprofit 501(c)3 organization of professional science fiction and fantasy writers in the United States. It was founded in 1965 by Damon Knight under the name Science Fiction Writers of America, Inc. The president of SFWA as of 2015 is Cat Rambo.
SFWA has about 1,800 professionally published writer members worldwide.
SFWA members vote for the Nebula Awards, one of the principal English-language science fiction awards.
Mission.
SFWA informs, supports, promotes, defends and advocates for its members.
SFWA activities include informing science fiction and fantasy writers on professional matters, protecting their interests, and helping them deal effectively with agents, editors, anthologists, and producers in print and non-print media; encouraging public interest in and appreciation for science fiction and fantasy literature; sponsoring, editing, and disseminating writings, papers, books, pamphlets, and other publications which exemplify science fiction and fantasy literature of high quality; conducting conferences, public discussion groups, forums, lectures, and seminar programs; and furnishing services connected with this stated purpose.
History.
Science Fiction Writers of America, Inc. was founded in 1965 by a group of writers associated with the Milford Conference and headed by Damon Knight. According to Todd McCaffrey, the organization immediately "acquired great status in its efforts to help J.R.R. Tolkien get fair recompense in America for pirated sales of "The Lord of the Rings"." Later, the name of the organization was changed to Science Fiction and Fantasy Writers of America, although the acronym SFWA was retained.
In 1982, Lisa Tuttle withdrew her short story "The Bone Flute" from the final Nebula ballot, to protest what she saw as excessive campaigning for awards and that voters did not receive copies of nominated works. Her withdrawal was sent after voting had been completed. When informed she had won, she contacted SFWA and told them she refused to accept it. She was told that her reasons for doing so would be announced. Her publisher accepted the award in her place, apparently with no knowledge of her withdrawal, and there was no mention of her objection.
In September 2009, SFWA joined the Open Book Alliance to oppose the Google Book Settlement. As a party to the class action suit, SFWA had recently explained its reservations about the settlement and declared its intention to file an objection. 
In 2013, the "SFWA Bulletin" was the subject of a controversy about sexism. This led to a brief hiatus, followed by a reboot of the magazine in a modern, updated format.
In 2014, the original Massachusetts corporation was dissolved and SFWA reincorporated as a California nonprofit 501(c)3 organization with new bylaws.
Activities.
SFWA participates in various trade shows and publishing industry events in the United States and abroad, including BookExpo America, the American Library Association Midwinter Conference, the USA Science & Engineering Festival, and several major (and minor) science fiction, fantasy and media conventions. SFWA holds a semi-annual business meeting at the World Science Fiction Convention (Worldcon) when it's held in North America, and at the North American Science Fiction Convention (NASFiC) otherwise. For logistical reasons, in 2014 SFWA's fall business meeting will be held at the World Fantasy Convention in Washington, DC.
SFWA also hosts its own events, which include:
Advocacy and support.
As an organization, SFWA acts as an advocate to effect important changes within the publishing industry, especially among publishers of science fiction and fantasy, by promoting author-friendly copyright legislation, equitable treatment of authors, and fair contract terms.
Writer Beware.
SFWA sponsors Writer Beware, whose mission is to track, expose, and raise awareness of the prevalence of fraud and other questionable activities in and around the publishing industry. Writer Beware consists of the Writer Beware website, which provides the latest information on literary schemes, scams, and pitfalls; the Writer Beware blog, which provides up-to-the-minute information on specific scams and schemes, along with advice for writers and industry news and commentary; and the Writer Beware Facebook page, which posts links to articles, news items, and warnings of interest to writers, and provides a forum for discussion. Writer Beware receives additional support from the Mystery Writers of America and the Horror Writers Association.
Writer Beware maintains an extensive database of complaints on questionable literary agents, publishers, independent editors, writers’ services, contests, publicity services, and others, and offers a free research and information service for writers. Writer Beware staff assist law enforcement agencies with investigations of literary fraud, and have been instrumental in the convictions of several literary scammers.
Griefcom.
Greifcom, or the Grievance Committee, is formed of member volunteers who undertake to mediate writer disputes and grievances between member writers and their publishers.
Emergency Medical Fund.
SFWA's Emergency Medical Fund was established to assist eligible member writers who have unexpected medical expenses.
Legal Fund.
SFWA's Legal Fund was established to create loans for eligible member writers who have writing-related court costs and other related legal expenses.
Estates Project.
Headed by longtime SFWA member Bud Webster, the Estates Project maintains a list of the estates of deceased SFWA member writers and coordinates with living member writers to make arrangements for their future estates. The Estates Project also accumulates information about authors' archives for member writers, living or dead.29.
Publications.
"The SFWA Bulletin".
"The SFWA Bulletin" is a quarterly magazine that SFWA members receive as part of their membership, but it is also available (by subscription) to non-members. The Bulletin carries nonfiction articles of general interest to writers, especially science fiction and fantasy writers. It accepts submissions, for which the pay rate is 8 cents a word. The current Bulletin editor is John Klima.
A special issue (no. 203) published in March 2014 was edited by Tansy Rayner Roberts and Jaym Gates and "was specially created to be used as an outreach tool for conventions and other events." The issue's contents and cover were welcomed by some as an antidote to the perceived sexism of past issues though Sue Granquist felt that something looked "suspiciously like a woman in a burka". 
In 2013, a controversy about sexism in the "Bulletin" led to the resignation of editor Jean Rabe on June 5, 2013. More than 50 authors wrote blog posts in objection to comments by longtime contributors Mike Resnick and Barry N. Malzberg that included references to "lady editors" and "lady writers" who were "beauty pageant beautiful" or a "knock out", an article by C. J. Henderson praising Barbie for maintaining "quiet dignity the way a woman should", and the "exploitative" cover image of no. 200 of the "Bulletin" depicting a woman in a chain-mail bikini. Several authors used the occasion to speak out against sexism in science fiction genre circles more broadly. The controversy continued through Bulletin no. 202, which contained another column by Resnick and Malzberg, discussing the response to their earlier column. Their column framed that response as censorship, referring to their critics as "liberal fascists".
As a result of the controversy, SFWA president John Scalzi apologized to members, and the "Bulletin" was put on hiatus for six months. It reappeared with the Winter 2014 Special Issue, #203.
The Forum.
The Forum is a quarterly publication that functions as SFWA's internal newsletter for members. As such, it is not available to non-members.
The SFWA Blog.
SFWA also publishes short essays and other content relevant to writers on the SFWA Blog.
Membership.
Most members live in the United States. Authors, regardless of nationality or residence, must be professionally published in a qualifying market as listed by SFWA in order to become SFWA members. At present, all listed qualifying markets publish only in the English language.
Dues range from $70 for Affiliate membership up to $110 for Institutional membership.
Board and administrative staff.
As of July 2015, the board consists of the current president, vice president, secretary, treasurer, and five directors at large.

</doc>
<doc id="27606" url="https://en.wikipedia.org/wiki?curid=27606" title="Soul Coughing">
Soul Coughing

Soul Coughing was an American alternative rock band. Based in New York City, the band found modest mainstream success during the mid-to-late 1990s. Soul Coughing developed a devout fanbase and have garnered largely positive response from critics. Steve Huey in AllMusic describes the band as "one of the most unusual cult bands of the 1990s...driven by frontman Mike Doughty's stream-of-consciousness poetry, Soul Coughing's sound was a willfully idiosyncratic mix of improvisational jazz grooves, oddball samples, hip-hop, electronics, and noisy experimentalism (described by Doughty as 'deep slacker jazz')." The inventive sampling and keyboard artistry of Mark Degli Antoni undergirded the band's distinct sound.
Recording career.
The band was signed within a year to Warner Bros. subsidiary Slash Records, and released three albums: "Ruby Vroom" (1994), "Irresistible Bliss" (1996), and "El Oso" (1998). In 1996, the band contributed to the AIDS benefit album ' produced by the Red Hot Organization. They enjoyed minor hit singles with "Circles", "Super Bon Bon", and "Screenwriter's Blues." They also had songs featured in the movies 'The X-Files" film ("Fight the Future")", "Batman and Robin" ("The Bug"), "Tommy Boy" and "Spawn" ("A Plane Scraped Its Belly on a Sooty Yellow Moon" featuring drum and bass artist Roni Size). Their song "Super Bon Bon" was included on the soundtrack for the 2K Sports video game "The Bigs 2" released in 2009 and on the soundtrack for the PlayStation game "Gran Turismo 2" released in 1999. Following their breakup they released "Lust in Phaze" (2002), a greatest hits compilation including a few B-sides
Rhino Records has reissued their three studio albums to 180 gram black vinyl on August 24, 2015 in the US and September 4 in the UK. This marks the first time "Ruby Vroom" has ever been pressed to vinyl. 

</doc>
<doc id="27608" url="https://en.wikipedia.org/wiki?curid=27608" title="Science fiction on television">
Science fiction on television

Science fiction first appeared in television programming in the 1940s, during what is called the Golden Age of Science Fiction. Special effects and other production techniques allow creators to present a living visual image of an imaginary world not limited by the constraints of reality.
Science fiction television production process and methods.
The need to portray imaginary settings or characters with properties and abilities beyond the reach of current reality obliges producers to make extensive use of specialized techniques of television production.
Through most of the 20th century, many of these techniques were expensive and involved a small number of dedicated craft practitioners, while the reusability of props, models, effects, or animation techniques made it easier to keep using them. The combination of high initial cost and lower maintenance cost pushed producers into building these techniques into the basic concept of a series, influencing all the artistic choices. 
By the late 1990s, improved technology and more training and cross-training within the industry made all of these techniques easier to use, so that directors of individual episodes could make decisions to use one or more methods, so such artistic choices no longer needed to be baked into the series concept.
Special effects.
Special effects (or "SPFX") have been an essential tool throughout the history of science fiction on television: small explosives to simulate the effects of various rayguns, squibs of blood and gruesome prosthetics to simulate the monsters and victims in horror series, and the wire-flying entrances and exits of George Reeves as Superman.
The broad term "special effects" includes all the techniques here, but more commonly there are two categories of effects. Visual effects ("VFX") involve photographic or digital manipulation of the onscreen image, usually done in post-production. Mechanical or physical effects involve props, pyrotechnics, and other physical methods used during principal photography itself. Some effects involved a combination of techniques; a ray gun might require a pyrotechnic during filming, and then an optical glowing line added to the film image in post-production. Stunts are another important category of physical effects. In general, all kinds of special effects must be carefully planned during pre-production.
Computer-generated imagery.
"Babylon 5" was the first series to use computer-generated imagery, or "CGI", for all exterior space scenes, even those with characters in space suits. The technology has made this more practical, so that today models are rarely used. In the 1990s, CGI required expensive processors and customized applications, but by the 2000s (decade), computing power has pushed capabilities down to personal laptops running a wide array of software.
Models and puppets.
Models have been an essential tool in science fiction television since the beginning, when Buck Rogers took flight in spark-scattering spaceships wheeling across a matte backdrop sky. The original "" required a staggering array of models; the USS "Enterprise" had to be built in several different scales for different needs. Models fell out of use in filming in the 1990s as CGI became more affordable and practical, but even today, designers sometimes construct scale models which are then digitized for use in animation software.
Models of characters are puppets. Gerry Anderson created a series of shows using puppets living in a universe of models and miniature sets, notably "Thunderbirds". "ALF" depicted an alien living in a family, while "Farscape" included two puppets as regular characters. In "Stargate SG-1", the Asgard characters are puppets in scenes where they are sitting, standing, or lying down.
Animation.
As animation is completely free of the constraints of gravity, momentum, and physical reality, it is an ideal technique for science fiction and fantasy on television. In a sense, virtually all animated series allow characters and objects to perform in unrealistic ways, so they are almost all considered to fit within the broadest category of speculative fiction (in the context of awards, criticism, marketing, etc.) The artistic affinity of animation to comic books has led to a large amount of superhero-themed animation, much of this adapted from comics series, while the impossible characters and settings allowed in animation made this a preferred medium for both fantasy and for series aimed at young audiences.
Originally, animation was all hand-drawn by artists, though in the 1980s, beginning with "Captain Power", computers began to automate the task of creating repeated images; by the 1990s, hand-drawn animation became defunct.
Animation in live-action.
In recent years as technology has improved, this has become more common, notably since the development of the Massive software application permits producers to include hordes of non-human characters to storm a city or space station. The robotic Cylons in the new version of "Battlestar Galactica" are usually animated characters, while the Asgard in "Stargate SG-1" are animated when they are shown walking around or more than one is on screen at once.
Science fiction television economics and distribution.
In general, science fiction series are subject to the same financial constraints as other television shows. However, high production costs increase the financial risk, while limited audiences further complicate the business case for continuing production. ' was the first television series to cost more than $100,000 per episode, while ' was the first to cost more than $1 million per episode.
The innovative nature of science fiction means that new shows cannot rely on predictable market-tested formulas like legal dramas or sitcoms; the involvement of creative talent outside the Hollywood mainstream introduces more variables to the budget forecasts.
In the past, science fiction television shows have maintained a family friendly format that rendered them suitable for all ages, especially children, as the majority of them were of the action-adventure format. This enabled merchandising such as toy lines, animated cartoon adaptations, and other licensing. However, many modern shows include a significant amount of adult themes (such as sexual situations, nudity, profanity and graphic violence) rendering them unsuitable for young audiences, and severely limiting the remaining audience demographic and the potential for merchandising.
The perception, more than the reality, of science fiction series being cancelled unreasonably is greatly increased by the attachment of fans to their favorite series, which is much stronger in science fiction fandom than it is in the general population. While mainstream shows are often more strictly episodic, where ending shows can allow viewers to imagine that characters live happily, or at least normally, ever after, science fiction series generate questions and loose ends that, when unresolved, cause dissatisfaction among devoted viewers. Creative settings also often call for broader story arcs than is often found in mainstream television, requiring science fiction series many episodes to resolve an ongoing major conflict. Science fiction television producers will sometimes end a season with a dramatic cliffhanger episode to attract viewer interest, but the short-term effect rarely influences financial partners. "Dark Angel" is one of many shows ending with a cliffhanger scene that left critical questions open when the series was cancelled.
Media fandom.
One of the earliest forms of media fandom was Star Trek fandom. Fans of the series became known to each other through the science fiction fandom. In 1968, NBC decided to cancel '. Bjo Trimble wrote letters to contacts in the National Fantasy Fan Foundation, asking people to organize their local friends to write to the network to demand the show remain on the air. Network executives were overwhelmed by an unprecedented wave of correspondence, and they kept the show on the air. Although the series continued to receive low ratings and was canceled a year later, the enduring popularity of the series resulted in Paramount creating a set of movies, and then a new series ', which by the early 1990s had become one of the most popular dramas on American television.
Although somewhat smaller, "Doctor Who" fandom considerably predates "Star Trek" fandom. Meanwhile, "Star Trek" fans continued to grow in numbers, and began organizing conventions in the 1970s. No other show attracted a large organized following until the 1990s, when "Babylon 5" attracted both "Star Trek" fans and a large number of literary SF fans who previously had not been involved in media fandom. Other series began to attract a growing number of followers.
In the late 1990s, "Buffy the Vampire Slayer" drew a large mainstream audience into fandom; greater demand allowed (even obliged, for the sake of time management) "Buffy" actors to charge much higher appearance fees than the "Star Trek" actors had. This pushed appearances out of the reach of some volunteer non-profit fan groups towards commercial event promoters. At the same time, a market for celebrity autographs emerged on eBay, which created a new source of income for actors, who began to charge money for autographs that they had previously been doing for free. This became significant enough that lesser-known actors would come to conventions without requesting any appearance fee, simply to be allowed to sell their own autographs (commonly on publicity photos). Today most events with actor appearances are organized by commercial promoters, though a number of fan-run conventions still exist, such as Toronto Trek and Shore Leave.
The 1985 series "Robotech" is most often credited as the catalyst for the Western interest in anime. The series inspired a few fanzines such as "Protoculture Addicts" and "Animag" both of which in turn promoted interest in the wide world of anime in general. Anime's first notable appearance at SF or comic book conventions was in the form of video showings of popular anime, untranslated and often low quality VHS bootlegs. Starting in the 1990s, anime fans began organizing conventions. These quickly grew to sizes much larger than other science fiction and media conventions in the same communities; many cities now have anime conventions attracting five to ten thousand attendees. Many anime conventions are a hybrid between non-profit and commercial events, with volunteer organizers handling large revenue streams and dealing with commercial suppliers and professional marketing campaigns.
For decades, the majority of science fiction media fandom has been represented by males of all ages and for most of its modern existence, a fairly diverse racial demographic. The most highly publicized demographic for science fiction fans is the male adolescent; roughly the same demographic for American comic books. Female fans, while always present, were far fewer in number and less conspicuously present in fandom. With the rising popularity of fanzines, female fans became increasingly vocal. Starting in the 2000s (decade), genre series began to offer more prominent female characters. Many series featured women as the main characters with males as supporting characters. "True Blood" is an example. Also, such shows premises moved away from heroic action-adventure and focused more on characters and their relationships. This has caused the rising popularity of fanfiction, a large majority of which is categorized as slash fanfiction. Female fans comprise the majority of fanfiction writers.
Science fiction television history and culture.
U.S. television science fiction.
U.S. television science fiction has produced "" and its various spin-off shows of the Star Trek franchise, "The Twilight Zone," "The X-Files," and many others.
British television science fiction.
British television science fiction began when the broadcast medium was in its infancy. Despite an occasionally chequered history, popular programmes in the genre have been produced by both the BBC and the largest commercial channel, ITV. "Doctor Who" is listed in the "Guinness World Records" as the longest-running science fiction television show in the world and as the "most successful" science fiction series of all time.
Canadian science fiction television.
Science fiction in Canada was produced by the CBC as early as the 1950s. In the 1970s, CTV produced "The Starlost". In the 1980s, Canadian animation studios including Nelvana, began producing a growing proportion of the world market in animation.
In the 1990s, Canada became an important player in live action speculative fiction on television, with dozens of series like "Forever Knight", "", and most notably "The X-Files" and "Stargate SG-1". Many series have been produced for youth and children's markets, including "Deepwater Black" and "MythQuest".
In the first decade of the 21st century, changes in provincial tax legislation prompted many production companies to move from Toronto to Vancouver. Recent popular series produced in Vancouver include "The Dead Zone", "Smallville", "Andromeda", "Stargate Atlantis", "Stargate Universe", "The 4400", "Sanctuary" and the reimagined "Battlestar Galactica".
Because of the small size of the domestic television market, most Canadian productions involve partnerships with production studios based in the United States and Europe. However, in recent years, new partnership arrangements are allowing Canadian investors a growing share of control of projects produced in Canada and elsewhere.
Australian science fiction television.
Australia's best known Science Fiction series was "Farscape"; made with American co-production, it ran from 1999 to 2003. Early series made in the 1960s included "The Interparis" (1968) "Vega 4" (1967), and "Phoenix Five" (1970). A significant proportion of Australian produced Science Fiction programmes are made for the teens/young Adults market, including "The Girl from Tomorrow", the long-running "Mr. Squiggle", "Halfway Across the Galaxy and Turn Left", "Ocean Girl", "Crash Zone", "Watch This Space" and "Spellbinder".
Other series like "Time Trax", "Roar" and "" were filmed in Australia, but used mostly US crew and actors.
Japanese television science fiction.
Japan has a long history of producing science fiction series for television. Some of the most famous are anime such as Osamu Tezuka's "Astro Boy", the Super Robots such as Mitsuteru Yokoyama's "Tetsujin 28-go" ("Gigantor") and Go Nagai's "Mazinger Z", and the Real Robots such as Yoshiyuki Tomino's "Gundam" series and Shōji Kawamori's "Macross" series.
Other primary aspects of Japanese science fiction television are the superhero "tokusatsu" (a term literally meaning special effects) series, pioneered by programs such as "Moonlight Mask" and "Planet Prince". The suitmation technique has been used in long running franchises include Eiji Tsuburaya's Ultra Series, Shotaro Ishinomori's Kamen Rider Series, and the Super Sentai Series.
In addition, several dramas utilize science fiction elements as framing devices, but are not labeled as "tokusatsu" as they do not utilize actors in full body suits and other special effects.
Continental European science fiction series.
Northern European series.
Among the notable German language productions is "Lexx" and , a German series first broadcast in 1966. Mmovies by Rainer Erler, include the miniseries .<br>
"Star Maidens" (1975, aka "Medusa" or "Die Mädchen aus dem Weltraum") was a British-German coproduction of pure SF. Danish television broadcast the children's TV-series "Crash" in 1984 about a boy who finds out that his room is a space ship.
Early Dutch television series were "Morgen gebeurt het" (tomorrow it will happen), broadcast from 1957 to 1959, about a group of Dutch space explorers and their adventures, "De duivelsgrot" (the devil's cave), broadcast from 1963 to 1964, about a scientist who finds the map of a cave that leads to the center of the earth and "Treinreis naar de Toekomst" (train journey to the future) about two young children who are taken to the future by robots who try to recreate humanity, but are unable to give the cloned humans a soul. All three of these television series where aimed mostly at children.
Later television series were "Professor Vreemdeling" (1977) about a strange professor who wants to make plants speak and "Zeeuws Meisje" (1997) a nationalistic post-apocalyptic series where the Netherlands has been built full of housing and the highways are filled with traffic jams. The protagonist, a female superhero, wears traditional folkloric clothes and tries to save traditional elements of Dutch society against the factory owners.
Italian series.
Italian TV shows include "A come Andromeda" (1972) which was a remake of 1962 BBC miniseries "A for Andromeda" (from the novels of Hoyle and Elliott), "Geminus" (1968), "Il segno del comando" (1971), "Gamma" (1974) and "La traccia verde" (1975).
French series.
French series are "" French science-fiction/fantasy television series (both co-produced with Canada) and a number of smaller fiction/fantasy television series, including "Tang" in 1971, about a secret organization that attempts to control the world with a new super weapon, "Les atomistes" and 1970 miniseries "La brigade des maléfices".
Another French-produced science fiction series was the new age animated series (). Anime-influenced animation includes a series of French-Japanese cartoons/anime, including such titles as "Ulysses 31" (1981), "The Mysterious Cities of Gold" (1982), and "Ōban Star-Racers" (2006).
Eastern European series.
Serbia produced "The Collector" (), a science fiction television series based upon Zoran Živković's story, winner of a World Fantasy Award. Several science-fiction series were also produced in various European countries, and never translated into English.
Significant creative influences.
For a list of notable science fiction series and programs on television, see: List of science fiction television programs.
People who have influenced science fiction on television include:

</doc>
<doc id="27609" url="https://en.wikipedia.org/wiki?curid=27609" title="Skeleton">
Skeleton

The skeleton (from Greek σκελετός, "skeletós" "dried up") is the body part that forms the supporting structure of an organism. There are several different skeletal types: the exoskeleton, which is the stable outer shell of an organism, the endoskeleton, which forms the support structure inside the body, the hydroskeleton, and the cytoskeleton.
Types of skeletons.
Exoskeleton.
Exoskeletons are external, and are found in many invertebrates; they enclose and protect the soft tissues and organs of the body. Some kinds of exoskeletons undergo periodic moulting as the animal grows, as is the case in many arthropods including insects and crustaceans.
Exoskeletons are made of different materials including chitin (in arthropods), calcium compounds (in stony corals and mollusks) and silicate (for diatoms and radiolarians.) 
The exoskeleton of insects is not only a protection but also serves as a surface for muscle attachment, as a watertight protection against drying and as a sense organ to interact with their environments. The shell of mollusks also performs all of the same functions, except that in most cases it does not contain sense organs.
An external skeleton can be quite heavy in relation to the overall mass of an animal, so on land, organisms that have an exoskeleton are mostly relatively small. Somewhat larger aquatic animals can support an exoskeleton because weight is less of a consideration underwater. The southern giant clam, a species of extremely large saltwater clam in the Pacific Ocean, has a shell that is massive in both size and weight. "Syrinx aruanus" is a species of sea snail with a very large shell.
Endoskeleton.
The endoskeleton is the internal support structure of an animal, composed of mineralized tissue and is typical of vertebrates. Endoskeletons vary in complexity from functioning purely for support (as in the case of sponges), to serving as an attachment site for muscles and a mechanism for transmitting muscular forces. A true endoskeleton is derived from mesodermal tissue. Such a skeleton is present in echinoderms and chordates.
Hydrostatic skeleton (hydroskeleton).
A hydrostatic skeleton is a semi-rigid, soft tissue structure filled with liquid under pressure, surrounded by muscles. Longitudinal and circular muscles around their body sectors allow movement by alternate lengthening and contractions along their lengths. A common example of this is earthworm. 
Cytoskeleton.
The cytoskeleton (gr. "kytos" = cell) is used to stabilize and preserve the form of the cells. It is a dynamic structure that maintains cell shape, protects the cell, enables cellular motion (using structures such as flagella, cilia and lamellipodia), and plays important roles in both intracellular transport (the movement of vesicles and organelles, for example) and cellular division.
Invertebrates.
The endoskeletons of echinoderms and some other soft-bodied invertebrates such as jellyfish and earthworms are also termed hydrostatic; a body cavity the coelom is filled with coelomic fluid and the pressure from this fluid acts together with the surrounding muscles to change the organism's shape and produce movement.
Sponges.
The skeleton of sponges consists of microscopic calcareous or silicious spicules. The demosponges include 90% of all species of sponges. Their "skeletons" are made of spicules consisting of fibers of the protein spongin, the mineral silica, or both. Where spicules of silica are present, they have a different shape from those in the otherwise similar glass sponges.
Echinoderms.
The skeleton of the echinoderms, which include, among other things, the starfish, is composed of calcite and a small amount of magnesium oxide. It lies below the epidermis in the mesoderm and is within cell clusters of frame-forming cells. This structure formed is porous and therefore firm and at the same time light. It coalesces into small calcareous ossicles (bony plates), which can grow in all directions and thus can replace the loss of a body part. Connected by joints, the individual skeletal parts can be moved by the muscles. 
Vertebrates.
In most vertebrates, the main skeletal component is referred to as bone. Another important component is cartilage which in mammals is found mainly in the joint areas. In other animals, such as the cartilaginous fishes, which include the sharks, the skeleton is composed entirely of cartilage. The segmental pattern of the skeleton is present in all vertebrates (mammals, birds, fish, reptiles and amphibians) with basic units being repeated. This segmental pattern is particularly evident in the vertebral column and the ribcage.
Bones in addition to supporting the body also serve, at the cellular level, as calcium and phosphate storage.
Fish.
The skeleton, which forms the support structure inside the fish is either made of cartilage as in the (Chondrichthyes), or bones as in the (Osteichthyes). The main skeletal element is the vertebral column, composed of articulating vertebrae which are lightweight yet strong. The ribs attach to the spine and there are no limbs or limb girdles. They are supported only by the muscles. The main external features of the fish, the fins, are composed of either bony or soft spines called rays, which with the exception of the caudal fin (tail fin), have no direct connection with the spine. They are supported by the muscles which compose the main part of the trunk.
Birds.
The bird skeleton is highly adapted for flight. It is extremely lightweight, yet still strong enough to withstand the stresses of taking off, flying, and landing. One key adaptation is the fusing of bones into single ossifications, such as the pygostyle. Because of this, birds usually have a smaller number of bones than other terrestrial vertebrates. Birds also lack teeth or even a true jaw, instead having evolved a beak, which is far more lightweight. The beaks of many baby birds have a projection called an egg tooth, which facilitates their exit from the amniotic egg.
Marine mammals.
To facilitate the movement of marine mammals in water, the hind legs were either lost altogether, as in the whales and manatees, or united in a single tail fin as in the pinnipeds (seals). In the whale, the cervical vertebrae are typically fused, an adaptation trading flexibility for stability during swimming.
Human.
The human skeleton consists of both fused and individual bones supported and supplemented by ligaments, tendons, muscles and cartilage. It serves as a scaffold which supports organs, anchors muscles, and protects organs such as the brain, lungs, heart and spinal cord. Although the teeth do not consist of tissue commonly found in bones, the teeth are usually considered as members of the skeletal system.
The biggest bone in the body is the femur in the upper leg, and the smallest is the stapes bone in the middle ear. In an adult, the skeleton comprises around 14% of the total body weight, and half of this weight is water.
Fused bones include those of the pelvis and the cranium. Not all bones are interconnected directly: There are three bones in each middle ear called the ossicles that articulate only with each other. The hyoid bone, which is located in the neck and serves as the point of attachment for the tongue, does not articulate with any other bones in the body, being supported by muscles and ligaments.
There are 206 bones in the adult human skeleton, although this number depends on whether the pelvic bones (the hip bones on each side) are counted as one or three bones on each side (ilium, ischium, and pubis), whether the coccyx or tail bone is counted as one or four separate bones, and does not count the variable wormian bones between skull sutures. Similarly, the sacrum is usually counted as a single bone, rather than five fused vertebrae. There is also a variable number of small sesamoid bones, commonly found in tendons. The patella or kneecap on each side is an example of a larger sesamoid bone. The patellae are counted in the total, as they are constant. The number of bones varies between individuals and with age - newborn babies have over 270 bones some of which fuse together. These bones are organized into a longitudinal axis, the axial skeleton, to which the appendicular skeleton is attached.
The human skeleton takes 20 years before it is fully developed. In many animals, the skeleton bones contain marrow, which produces blood cells.
There exist several general differences between the male and female skeletons. The male skeleton, for example, is generally larger and heavier than the female skeleton. In the female skeleton, the bones of the skull are generally less angular. The female skeleton also has wider and shorter breastbone and slimmer wrists. There exist significant differences between the male and female pelvis which are related to the female's pregnancy and childbirth capabilities. The female pelvis is wider and shallower than the male pelvis. Female pelvises also have an enlarged pelvic outlet and a wider and more circular pelvic inlet. The angle between the pubic bones is known to be sharper in males, which results in a more circular, narrower, and near heart-shaped pelvis.
Bones and cartilage.
Bone.
Bones are rigid organs that form part of the endoskeleton of vertebrates. They function to move, support, and protect the various organs of the body, produce red and white blood cells and store minerals. Bone tissue is a type of dense connective tissue. Bones have a variety of shapes with a complex internal and external structure they are also lightweight, yet strong and hard. One of the types of tissue that makes up bone tissue is mineralized tissue and this 
gives it rigidity and a honeycomb-like three-dimensional internal structure. Other types of tissue found in bones include marrow, endosteum and periosteum, nerves, blood vessels and cartilage. There are 206 bones in the adult human body and 270 in an infant.
Cartilage.
During embryogenesis the precursor to bone development is cartilage. Much of this substance is then replaced by bone during the second and third trimester, after the flesh such as muscle has formed around it; forming the skeleton. Cartilage is a stiff and inflexible connective tissue found in many areas in the bodies of humans and other animals, including the joints between bones, the rib cage, the ear, the nose, the elbow, the knee, the ankle, the bronchial tubes and the intervertebral discs. It is not as hard and rigid as bone but is stiffer and less flexible than muscle.
Cartilage is composed of specialized cells called chondrocytes that produce a large amount of extracellular matrix composed of Type II collagen (except Fibrocartilage which also contains type I collagen) fibers, abundant ground substance rich in proteoglycan, and elastin fibers. Cartilage is classified in three types, elastic cartilage, hyaline cartilage and fibrocartilage, which differ in the relative amounts of these three main components.
Unlike other connective tissues, cartilage does not contain blood vessels. The chondrocytes are supplied by diffusion, helped by the pumping action generated by compression of the articular cartilage or flexion of the elastic cartilage. Thus, compared to other connective tissues, cartilage grows and repairs more slowly.
In popular culture.
In Western culture, the skeleton is oftentimes seen as a fearful symbol of death and the paranormal. It is a popular motif in the holiday Halloween, as well as Day of the Dead.

</doc>
