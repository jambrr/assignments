<doc id="24864" url="https://en.wikipedia.org/wiki?curid=24864" title="Professional wrestling">
Professional wrestling

Professional wrestling (colloquially abbreviated to pro wrestling or wrestling) is an athletic form of entertainment based on a portrayal of a combat sport. Taking the form of live events held by touring promotions, it portrays a unique style of combat based on a combination of adopted styles, which include classical wrestling, catch wrestling and various forms of martial arts, as well as an innovative style based on grappling (holds/throws), striking, and aerialism. Various forms of weaponry are sometimes used.
The content including match outcomes is choreographed and the combative actions and reactions are executed in special manners designed to both protect from, yet simulate, pain. These facts were once kept highly secret, but they are now openly declared as the truth. By and large, the true nature of the content is ignored by the performing promotion in official media in order to sustain and promote the willing suspension of disbelief for the audience by maintaining an aura of verisimilitude. Fan communications by individual wrestlers and promotions through outside media (i.e., interviews) will often directly acknowledge the fictional nature of the spectacle.
Although the combative content is staged and communicated between the wrestlers, there are legitimate physical hazards resulting in serious injury and death in limited cases, due to the realism and contact involved in the performance.
History.
Originating as a popular form of entertainment in 19th-century Europe and later as a sideshow exhibition in North American traveling carnivals and vaudeville halls, professional wrestling grew into a standalone genre of entertainment with many diverse variations in cultures around the globe, and is now considered a multimillion-dollar entertainment industry. While it has greatly declined in Europe, in North America it has experienced several different periods of prominent cultural popularity during its century and a half of existence. The advent of television gave professional wrestling a new outlet, and wrestling (along with boxing) was instrumental in making pay-per-view a viable method of content delivery.
Scope and influence.
Unlike in Europe, show wrestling has become especially prominent in Japan, in Mexico and in North America. In Brazil, there was a very popular wrestling television program from the 1960s to the early 1980s called "Telecatch". High-profile figures in the sport have become celebrities or cultural icons in their native or adopted home countries.
Although professional wrestling started out as petty acts in sideshows, traveling circuses and carnivals, today it is a billion-dollar industry. Revenue is drawn from live event ticket sales, network television broadcasts, pay-per-view broadcasts, personal appearances by performers, branded merchandise and home video. Particularly since the 1950s, pro wrestling events have frequently been responsible for sellout crowds at large arenas, including Madison Square Garden, as well as football stadiums, by promotions including the WWE, the NWA territory system, WCW, and AWA. Pro wrestling was also instrumental in making pay-per-view a viable method of content delivery. Annual shows such as WrestleMania, SummerSlam, Royal Rumble, and formerly Bash at the Beach, Halloween Havoc and Starrcade are among the highest-selling pay-per-view programming each year. In modern day, internet programming has been utilized by a number of companies to air web shows, internet pay-per-views (iPPVs) or on-demand content, helping to generate internet-related revenue earnings from the evolving World Wide Web.
Home video sales dominate the Billboard charts Recreational Sports DVD sales, with wrestling holding anywhere from 3 to 9 of the top 10 spots every week.
Due to its persistent cultural presence and to its novelty within the performing arts, wrestling constitutes a recurring topic in both academia and the media. Several documentaries have been produced looking at professional wrestling, most notably, "Beyond the Mat" directed by Barry W. Blaustein, and "" featuring wrestler Bret Hart and directed by Paul Jay. There have also been many fictional depictions of wrestling; the 2008 film "The Wrestler" received several Oscar nominations and began a career revival for star Mickey Rourke.
Currently, the largest professional wrestling company worldwide is the United States-based WWE, which bought out many smaller regional companies in the late 20th century, as well as its primary US competitors WCW and Extreme Championship Wrestling (ECW) in early 2001. Other prominent professional wrestling companies worldwide include the US-based Total Nonstop Action Wrestling (TNA) and Ring of Honor (ROH), Consejo Mundial de Lucha Libre (CMLL) and Asistencia Asesoría y Administración (AAA) in Mexico, and the Japanese New Japan Pro Wrestling (NJPW), All Japan Pro Wrestling (AJPW), and Pro Wrestling Noah (NOAH) leagues.
Genre conventions.
When talking about professional wrestling, there are two levels: the "in-show" happenings that are presented through the shows, and happenings which are outside the scope of performance (in other words, are real life). but have implications on the performance, such as performer contracts, legitimate injuries, etc. Because actual events are often co-opted by writers for incorporation into storylines for the performers, the lines are often blurred and become confused.
Special care must be taken when talking about people who perform under their own name. The actions of the character should be considered fictional events, wholly separate from the life of the performer. This is similar to other entertainers who perform with a persona that shares their own name (such as Stephen Colbert and his fictional persona).
Some wrestlers will incorporate elements of their real-life personalities into their characters, even if they and their in-ring persona have different names.
Kayfabe.
Historians are unsure at what point wrestling changed from competitive catch wrestling into worked entertainment. Those who participated felt that maintenance of a constant and complete illusion for all who were not involved was necessary to keep audience interest. For decades, wrestlers lived their public lives as though they were their characters.
The practice of keeping the illusion, and the various methods used to do so, came to be known as "kayfabe" within wrestling circles, or "working the marks". An entire lexicon of slang jargon and euphemism developed to allow performers to communicate without outsiders' knowledge of what was being said.
Occasionally a performer will deviate from the intended sequence of events. This is known as a shoot. Sometimes shoot-like elements are included in wrestling stories to blur the line between performance and reality. These are known as "worked shoots". However, the vast majority of events in professional wrestling are preplanned and improvised within accepted boundaries.
Gradually, the predetermined nature of professional wrestling became an open secret, as prominent figures in the wrestling business (including WWE owner Vince McMahon) began to publicly admit that wrestling was entertainment, not competition. This public reveal has garnered mixed reactions from the wrestling community, as some feel that exposure ruins the experience to the spectators as does exposure in illusionism. Despite the public admission of the theatrical nature of professional wrestling, many U.S. states still regulate professional wrestling as they do other professional competitive sports. For example, New York State still regulates "professional wrestling" through the New York State Athletic Commission (SAC).
Aspects of performing art.
Professional wrestling shows can be considered a form of theatre in the round, with the ring, ringside area, and entryway comprising a thrust stage. However, there is a much more limited concept of a fourth wall than in most theatric performances. The audience is recognized and acknowledged by the performers as spectators to the sporting event being portrayed, and are encouraged to interact as such. This leads to a high level of audience participation; in fact, their reactions can dictate how the performance unfolds. Often, individual matches will be part of a longer storyline conflict between "babyfaces" (often shortened to just "faces") and "heels". "Faces" (the "good guys") are those whose actions are intended to encourage the audience to cheer, while "heels" (the "bad guys") act to draw the spectators' ire.
Rules.
There is no governing authority for professional wrestling rules, although there is a general standard which has developed. Each promotion has their own variation, but all are similar enough to avoid confusion most of the time. Any rule described here is simply a standard, and may or may not correspond exactly with any given promotion's ruleset.
It should be noted that, due to the staged nature of wrestling, these are not actual "rules" in the sense that they would be considered in similar articles about actual sports like freestyle wrestling. Instead, the "rules" in this article are implemented and supposedly enforced for the sake of suspension of disbelief (known as kayfabe in the jargon of the business).
General structure.
Matches are held between two or more sides ("corners"). Each corner may consist of one wrestler, or a team of two or more. Most team matches are governed by tag team rules (see below). Other matches are free-for-alls, with multiple combatants but no teams. In all variants, there can be only one winning team or wrestler.
The standard method of scoring is the "fall", which is accomplished by:
These are each explained in greater detail below. Typically, pinfalls and submissions must occur within the ring area, however there are times where it may be stipulated otherwise.
Most wrestling matches last for a set number of falls, with the first side to achieve the majority number of pinfalls, submissions, or countouts being the winner. Historically, matches were wrestled to 3 falls ("best 2 out of 3") or 5 falls ("best 3 out of 5"). The standard for modern matches is one fall. However, even though it is now standard, many announcers will explicitly state this (e.g. "The following contest is set for one fall with a 20-minute time limit"). These matches are given a time limit; if not enough falls are scored by the end of the time limit, the match is declared a draw. Modern matches are generally given a 10- to 30-minute time limit for standard matches; title matches can go for up to one hour. British wrestling matches held under Admiral-Lord Mountevans rules are 2 out of 3 falls.
An alternative is a match set for a prescribed length of time, with a running tally of falls. The entrant with the most falls at the end of the time limit is declared the winner. This is usually for 20, 30 or 60 minutes, and is commonly called an Iron Man match. This type of match can be modified so that fewer types of falls are allowed.
In matches with multiple competitors, an elimination system may be used. Any wrestler who has a fall scored against them is forced out of the match, and the match continues until only one remains. However, it is much more common when more than two wrestlers are involved to simply go one fall, with the one scoring the fall, regardless of who they scored it against, being the winner. In championship matches, this means that, unlike one-on-one matches (where the champion can simply disqualify themselves or get themselves counted out to retain the title via the "champion's advantag"), the champion does not have to be pinned or involved in the decision to lose the championship. However, heel champions often find advantages, not in champion's advantage, but in the use of weapons and outside interference, as these poly-sided matches tend to involve no holds barred rules.
Many modern specialty matches have been devised, with unique winning conditions. The most common of these is the ladder match. In the basic ladder match, the wrestlers or teams of wrestlers must climb a ladder to obtain a prize that is hoisted above the ring. The key to winning this match is that the wrestler or team of wrestlers must try to incapacitate each other long enough for one wrestler to climb the ladder and secure that prize for their team. As a result, the ladder can be used as a weapon. The prizes include – but are not limited to any given championship belt (the traditional prize), a document granting the winner the right to a future title shot, or any document that matters to the wrestlers involved in the match (such as one granting the winner a cash prize). Another common specialty match is known as the battle royal. In a battle royal, all the wrestlers enter the ring to the point that there are 20-30 wrestlers in the ring at one time. When the match begins, the simple objective is to throw the opponent over the top rope and out of the ring with both feet on the floor in order to eliminate that opponent. The last wrestler standing is declared the winner. A variant on this type of match is the WWE's Royal Rumble where two wrestlers enter the ring to start the match and other wrestlers follow in 90 second intervals (previously 2 minutes) until 30-40 wrestlers have entered the ring. All other rules stay the same. For more match types, see Professional wrestling match types.
Every match must be assigned a rule keeper known as a referee, who is the final arbitrator. In multi-man "lucha libre" matches, two referees are used, one inside the ring and one outside.
Due to the legitimate role that referees play in wrestling of serving as liaison between the bookers backstage and the wrestlers in the ring (the role of being a final arbitrator is merely kayfabe), the referee is present, even in matches that do not at first glance appear to require a referee (such as a ladder match, as it is no holds barred, and the criteria for victory could theoretically be assessed from afar). Although their actions are also frequently scripted for dramatic effect, referees are subject to certain general rules and requirements in order to maintain the theatrical appearance of unbiased authority. The most basic rule is that an action must be seen by a referee to be declared for a fall or disqualification. This allows for heel characters to gain a scripted advantage by distracting or disabling the referee in order to perform some ostensibly illegal maneuver on their opponent. Most referees are unnamed and essentially anonymous, though the WWE has let their officials reveal their names.
Special guest referees may be used from time to time; by virtue of their celebrity status, they are often scripted to dispense with the appearance of neutrality and use their influence to unfairly influence the outcome of the match for added dramatic impact. Face special referees will often fight back against hostile heel wrestlers, particularly if the special referee is either a wrestler themselves or a famous martial artist (such as Tito Ortiz in the main event at TNA's THard Justice in 2005). They also have the power to eject from ringside any of the heel wrestler's entourage/stable, who may otherwise interfere with the match. 
For heel special referees, common ways of assisting the heel wrestler to obtain victory include, but are not limited to, the following:
It is worth noting that the special referee may enter the match appearing to be a heel, but often they ultimately perform a "face-turn" during the climax of the match, and also vice-versa. This is most often the case if the referee is a wrestler, as it can setup a further storyline feud between the special referee and the wrestler that he or she "betrayed".
Matches are held within a wrestling ring, an elevated square canvas mat with posts on each corner. A cloth apron hangs over the edges of the ring. Three horizontal ropes or cables surround the ring, suspended with turnbuckles which are connected to the posts. For safety, the ropes are padded at the turnbuckles and cushioned mats surround the floor outside the ring. Guardrails or a similar barrier enclose this area from the audience. Wrestlers are generally expected to stay within the confines of the ring, though matches sometimes end up outside the ring, and even in the audience, to add excitement.
Tag rules.
In some team matches, only one entrant from each team may be designated as the "legal" or "active" wrestler at any given moment. Two wrestlers must make physical contact (typically palm-to-palm) in order to transfer this legal status. This is known as a "tag", with the participants "tagging out" and "tagging in". Typically the wrestler who is tagging out has a 5-second count to leave the ring, whereas the one tagging in can enter the ring at any time, resulting in heels legally double-teaming a face.
The non-legal wrestlers must remain outside the ring or other legal area at all times (and avoid purposeful contact with the opposing wrestlers) or face reprimand from the referee. In most promotions, the wrestler to be tagged in must be touching the turnbuckle on their corner, or a cloth strap attached to the turnbuckle.
Some multi-wrestler matches allow for a set number of legal wrestlers, and a legal wrestler may tag out to any other wrestler, regardless of team. In these matches, the tag need not be a mutual effort, and this results in active wrestlers being tagged out against their will, or non-legal wrestlers forced to enter the battle.
Sometimes, poly-sided matches that pit every one for themselves will incorporate tagging rules. Outside of kayfabe, this is done to give wrestlers a break from the action (as these matches tend to go on for long periods of time), and to make the action in the ring easier to choreograph. One of the most mainstream examples of this is the four-corner match, the most common type of match in the WWE before it was replaced with its equivalent fatal four-way; four wrestlers, each for themselves, fight in a match, but only two wrestlers can be in the match at any given time. The other two are positioned in the corner, and tags can be made between any two wrestlers.
In a Texas tornado tag team match, all the competitors are legal in the match, and tagging in and out is not necessary. All matches fought under hardcore rules (such as no disqualification, no holds barred, ladder match, etc.) are all contested under "de facto" Texas tornado tag team rules, since the lack of ability of a referee to issue a disqualification renders any tagging requirements moot.
Regardless of rules of tagging, a wrestler cannot pin their own tag team partner, even if it is technically possible from the rules of the match (e.g. Texas tornado tag team rules, or a three-way tag team match). This is called the "Outlaw Rule" because the first team to attempt to use that (in an attempt to unfairly retain their tag team titles) was The New Age Outlaws.
Decisions.
Pinfall.
In order to score by pinfall, a wrestler must pin both their opponent's shoulders against the mat while the referee slaps the mat three times (referred to as a "three count"). This is the most common form of defeat. The pinned wrestler must also be on their back; if they are lying on their belly, it usually does not count.
A count may be started at any time that a wrestler's shoulders are down (both shoulders touching the mat), back-first and any part of the opponent's body is lying over the wrestler. This often results in pins that can easily be kicked out of, if the defensive wrestler is even slightly conscious. For example, an attacking wrestler who is half-conscious may simply drape an arm over an opponent, or a cocky wrestler may place their foot gently on the opponent's body, prompting a three-count from the referee.
However, although almost any scenario where one wrestler is covering another prone, back-first wrestler can be considered a pin attempt, there is one important exception to that rule: Pin attempts broken up by other wrestlers. In matches involving multiple wrestlers (such as triple threat matches or tag team matches), wrestlers who see a pin attempt that, if successful, would result in them losing the match are expected to run in and break the pin attempt by performing some sort of offensive maneuver on the wrestler attempting the pin. The most common attacks for breaking pins are a stomp to the back and an elbow to the back of the head, as they are simple to pull off in the spur of the moment. However, these moves, simple as they are, still leave the pinning wrestler on top of the pinned wrestler. Despite the pinning wrestler still technically being on top of the pinned wrestler, the referee will still consider the pin attempt to be broken.
Illegal pinning methods include using the ropes for leverage and hooking the opponent's clothing, which are therefore popular cheating methods for heels, unless certain stipulations make such an advantage legal. Such pins as these are rarely seen by the referee (as they have to see if their shoulders are down) and are subsequently often used by heels and on occasion by cheating faces to win matches. Even if it is noticed, it is rare for such an attempt to result in a disqualification (see below), and instead it simply results in nullification of the pin attempt, so the heel wrestler rarely has anything to lose for trying it, anyway.
Occasionally, there are instances where a pinfall is made where both wrestlers' shoulders were on the mat for the three-count. This situation will most likely lead to a draw, and in some cases a continuation of the match or a future match to determine the winner.
Submission.
To score by submission, the wrestler must make their opponent give up or pass out, usually, but not necessarily, by putting them in a submission hold (e.g. figure-four leglock, armlock, sleeper hold).
A wrestler may voluntarily submit by verbally informing the referee (usually used in moves such as the Mexican Surfboard, where all four limbs are incapacitated, making tapping impossible). Also, since Ken Shamrock (a legitimate UFC competitor in its early days) popularized it in 1997, a wrestler can indicate a voluntary submission by "tapping out", that is, tapping a free hand against the mat or against an opponent. Occasionally, a wrestler will reach for a rope (see rope breaks below), only to put their hand back on the mat so they can crawl towards the rope some more; this is not a submission, and the referee decides what their intent is.
Passing out in a submission hold also technically constitutes a loss by submission. To determine if a wrestler has passed out in WWE, the referee usually picks up and drops their hand. If it drops to the mat or floor three consecutive times without the wrestler having the strength to hold it up, the wrestler is considered to have passed out.
Submission was initially a large factor in professional wrestling, but following the decline of the submission-oriented catch-as-catch-can style from mainstream professional wrestling, the submission largely faded until the rise of the legitimate sport of mixed martial arts. Despite this, some wrestlers, such as Chris Jericho, The Undertaker, Ric Flair, Bret Hart, Kurt Angle, Ken Shamrock, Dean Malenko, Chris Benoit, and Tazz, became famous for winning matches via submission. A wrestler with a signature submission technique is portrayed as better at applying the hold, making it more painful or more difficult to get out of than others who use it, or can be falsely credited as inventing the hold (such as when Tazz popularized the kata ha jime judo choke in pro wrestling as the "Tazzmission").
Since all contact between the wrestlers must cease if any part of the body is touching, or underneath, the ropes, many wrestlers will attempt to break submission holds by deliberately grabbing the bottom ropes. This is called a "rope break", and it is one of the most common ways to break a submission hold. Most holds leave an arm or leg free, so that the person can tap out if they want. Instead, they use these free limbs to either grab one of the ring ropes (the bottom one is the most common, as it is nearest the wrestlers, though other ropes sometimes are used for standing holds such as Chris Masters' "Master Lock") or drape their foot across, or underneath one. Once this has been accomplished, and the accomplishment is witnessed by the referee, the referee will demand that the offending wrestler break the hold, and start counting to five if the wrestler does not. If the referee reaches the count of five, and the wrestler still does not break the hold, they are disqualified.
If a manager decides that their client wrestler should tap out, but cannot convince the wrestler themselves to do so, they may "throw in the towel" (by literally taking a gym towel and hurling it into the ring where the referee can see it); this is the same as a submission, as the manager is, in kayfabe, considered the wrestler's agent, and therefore, authorized to make formal decisions (such as forfeiting a match) on the client's behalf.
Knockout.
A wrestler can win by knockout (sometimes referred to as a referee stoppage) if they do not resort to submission holds, but stills pummels their opponent to the point that they are unconscious or are unable to intelligently defend themselves. To check for a knockout in this manner, a referee will wave their hand in front of the wrestler's face; if the wrestler does not react in any way, the referee will award the victory to the other wrestler. If all the active wrestlers in a match are down inside the ring at the same time, the referee will begin a count (usually ten seconds, twenty in Japan). If nobody rises to their feet by the end of the count, the match is ruled a draw. Any participant who stands up in time will end the count for everyone else. In a Last Man Standing match, this form of a knockout is the only way that the match can end, so the referee will count when one or more wrestlers are down, and one wrestler standing up before the 10-count doesn't stop the count for another wrestler who is still down.
A referee may stop the match when they or official ring physician decides that a wrestler cannot safely continue the match. This may be decided if the wrestler cannot continue the match due to an injury. At the Great American Bash in 2008, Chris Jericho was declared the winner of a match against Shawn Michaels when Michaels could not defend himself due to excessive blood loss and impaired vision. At in 2015, the referee stopped the match when Sami Zayn could not defend himself due to an injury sustained against Kevin Owens for the NXT Championship.
Countout.
A countout (alternatively "count-out" or "count out") happens when a wrestler is out of the ring long enough for the referee to count to ten (twenty in some promotions) and thus disqualified. The count is broken and restarted when a wrestler in the ring exits the ring. Playing into this, some wrestlers will "milk" the count by sliding in the ring, and immediately sliding back out. As they were technically inside the ring for a split second before exiting again, it is sufficient to restart the count. This is often referred to by commentators as "breaking the count." Heels often use this tactic in order to buy themselves more time to catch their breath, or to attempt to frustrate their babyface opponents.
In some promotions (and most major modern ones), championships cannot change hands via a countout, unless the on-screen authority declares it for at least one match, although in others, championships may change hands via countout. Heels are known to take advantage of this and will intentionally get counted out when facing difficult opponents, especially when defending championships.
Disqualification.
Disqualification (sometimes abbreviated as "DQ") occurs when a wrestler violates the match's rules, thus losing automatically. Although a countout can technically be considered a disqualification (as it is, for all intents and purposes, an automatic loss suffered as a result of violating a match rule), the two concepts are often distinct in wrestling. A no disqualification match can still end by countout (although this is rare); typically, a match must be declared a "no holds barred" match, a "street fight" or some other term, in order for both disqualifications and countouts to be waived.
Disqualification from a match is called for a number of reasons:
In practice, not all rule violations will result in a disqualification as the referee may use their own judgement and is not obligated to stop the match. Usually, the only offenses that the referee will see and immediately disqualify the match on (as opposed to having multiple offenses) are low blows, weapon usage, interference, or assaulting the referee. In WWE, a referee must see the violation with their own eyes to rule that the match end in a disqualification (simply watching the video tape is not usually enough) and the referee's ruling is almost always final, although Dusty finishes (named after, and made famous by, Dusty Rhodes) will often result in the referee's decision being overturned. It is not uncommon for the referees themselves to get knocked out during a match, which is commonly referred to by the term "ref bump". While the referee remains "unconscious", wrestlers are free to violate rules until the referee is revived or replaced. In some cases, a referee might disqualify a person under the presumption that it was that wrestler who knocked them out; most referee knockouts are arranged to allow a wrestler, usually a heel, to gain an advantage. For example, a wrestler may get whipped into a referee at a slower speed, knocking the ref down for short amount of time; during that interim period, one wrestler may pin their opponent for a three-count and would have won the match but for the referee being down (sometimes, another referee will sprint to the ring from backstage to attempt to make the count, but by then, the other wrestler has had enough time to kick-out on their own accord).
If all participants in a match continue to breach the referee's instructions, the match may end in a double disqualification, where both wrestlers or teams (in a tag team match) have been disqualified. The match is essentially nullified, and called a draw or in some cases a restart or the same match being held at a pay-per-view or next night's show.
Draw.
A professional wrestling match can end in a draw. A draw occurs if both opponents are simultaneously disqualified (as via countout or if the referee loses complete control of the match and both opponents attack each other with no regard to being in a match, like Brock Lesnar vs. Undertaker at Unforgiven in 2002), neither opponent is able to answer a ten-count, or both opponents simultaneously win the match. The latter can occur if, for example, one opponent's shoulders touch the mat while maintaining a submission hold against another opponent. If the opponent in the hold begins to tap out at the same time a referee counts to three for pinning the opponent delivering the hold, both opponents have legally achieved scoring conditions simultaneously. Traditionally, a championship may not change hands in the event of a draw (though it may become vacant), though some promotions such as TNA have endorsed rules where the champion may lose a title by disqualification. A variant of the draw is the time-limit draw, where the match does not have a winner by a specified time period (a one-hour draw, which was once common, is known in wrestling circles as a "Broadway").
Also if two wrestlers have been given DQ by either the referee or the chairman, this is a no contest. If there is a championship belt on the line, the champion keeps the title.
No contest.
A wrestling match may be declared a no contest if the winning conditions are unable to occur. This can be due to excessive interference, loss of referee's control over the match, one or more participants sustaining debilitating injury not caused by the opponent, or the inability of a scheduled match to even begin. A no contest is a state separate and distinct from a draw — a draw indicates winning conditions were met. Although the terms are sometimes used interchangeably in practice, this usage is technically incorrect.
Dramatic elements.
While each wrestling match is ostensibly a competition of athletics and strategy, the goal of each match from a business standpoint is to excite and entertain the audience. Although the competition is staged, dramatic emphasis can be utilized to draw out the most intense reaction from the audience. Heightened interest results in higher attendance rates, increased ticket sales, higher ratings on television broadcasts (which result in greater ad revenue), higher pay-per-view buyrates, and sales of branded merchandise and recorded video footage. All of these contribute to the profit of the promotion company.
Character/gimmick.
In Latin America and English-speaking countries, most wrestlers (and other on-stage performers) portray character roles, sometimes with personalities wildly different from their own. These personalities are a gimmick intended to heighten interest in a wrestler without regard to athletic ability. Some can be unrealistic and cartoon-like (such as Doink the Clown), while others carry more verisimilitude and can be seen as exaggerated versions of the performer's real life personality (such as Chris Jericho, The Rock, John Cena, Stone Cold Steve Austin, and CM Punk). In "lucha libre", many characters wear masks, adopting a secret identity akin to a superhero, a near-sacred tradition.
An individual wrestler may sometimes use their real name, or a minor variation of it, for much of their career, such as Angelo Poffo, Ernie Ladd, Verne Gagne, Bret Hart, and Randy Orton. Others can keep one ring name for their entire career (cases in point include Chris Jericho, Shawn Michaels, CM Punk and Ricky Steamboat), or may change from time to time to better suit the demands of the audience or company. Sometimes a character is owned and trademarked by the company, forcing the wrestler to find a new one when they leave (although a simple typeset change, such as changing Rhyno to Rhino, can usually get around this), and sometimes a character is owned by the wrestler. Sometimes, a wrestler may change their legal name in order to obtain ownership of their ring name (examples include Andrew Martin and Warrior). Many wrestlers (such as The Rock and The Undertaker) are strongly identified with their character, even responding to the name in public or between friends. It's actually considered proper decorum for fellow wrestlers to refer to each other by their stage names/characters rather than their birth/legal names, unless otherwise introduced. A professional wrestling character's popularity can grow to the point that it makes appearances in other media (see Hulk Hogan and El Santo) or even give the performer enough visibility to enter politics (Antonio Inoki and Jesse Ventura, among others).
Typically, matches are staged between a protagonist (historically an audience favorite, known as a babyface, or "the good guy") and an antagonist (historically a villain with arrogance, a tendency to break rules, or other unlikable qualities, called a heel). In recent years, however, antiheroes have also become prominent in professional wrestling. There is also a less common role of a "tweener", who is neither fully face nor fully heel yet able to play either role effectively (case in point, Samoa Joe during his first run in TNA from June 2005 to November 2006).
At times a character may "turn", altering their face/heel alignment. This may be an abrupt, surprising event, or it may slowly build up over time. It almost always is accomplished with a markable change in behavior on the part of the character. Some turns become defining points in a wrestler's career, as was the case when Hulk Hogan turned heel after being a top face for over a decade. Others may have no noticeable effect on the character's status. If a character repeatedly switches between being a face and heel, this lessens the effect of such turns, and may result in apathy from the audience. Vince McMahon is a good example of having more heel and face turns than anyone in WWE history.
As with personae in general, a character's face or heel alignment may change with time, or remain constant over its lifetime (the most famous example of the latter is Ricky Steamboat, a WWE Hall of Famer who remained a babyface throughout his entire career). Sometimes a character's heel turn will become so popular that eventually the audience response will alter the character's heel-face cycle to the point where the heel persona will, in practice, become a face persona, and what was previously the face persona, will turn into the heel persona, such as when Dwayne Johnson first began using "The Rock" persona as a heel character, as opposed to his original "Rocky Maivia" babyface persona. Another legendary example is Stone Cold Steve Austin, who was originally booked as a heel, with such mannerisms as drinking on the job, using profanity, breaking company property, and even breaking into people's private homes. However, much to WWF's surprise, the fans enjoyed Austin's antics so much that he became one of the greatest antiheroes in the history of the business. He, along with the stable of D-Generation X, is generally credited with ushering in the Attitude Era of WWF programming.
In some cases a wrestler may possess admirable physical traits but perceived mediocre public speaking abilities (such as Brock Lesnar), or their gimmick may be that of a "wild savage" needing a handler (such as Kamala). Such performers have historically employed a manager, who speaks on their behalf and adds to the performance. Managers have sometimes become major personalities, including Bobby Heenan, Paul Heyman, Ernie Roth, and Paul Bearer. A manager role may also be filled by a "valet", typically an appealing female who may participate in love triangle storylines, "damsel in distress" situations, and scripted fights with female wrestlers. Some of these have also gone on to become recognized stars, such as Tammy Lynn Sytch, Stacy Keibler, and Miss Elizabeth.
Story.
While true exhibition matches are not uncommon, most matches tell a story analogous to a scene in a play or film, or an episode of a serial drama: The face will sometimes win (triumph) or sometimes lose (tragedy). Longer story arcs can result from multiple matches over the course of time. Since most promotions have a championship title, competition for the championship is a common impetus for stories. Also, anything from a character's own hair to their job with the promotion can be wagered in a match. The same type of good vs. evil storylines were also once popular in roller derby.
Some matches are designed to further a story of only one participant. It could be intended to portray him or her as a strong unstoppable force, a lucky underdog, a sore loser, or any other characterization. Sometimes non-wrestling vignettes are shown in order to enhance a character's image without the need for matches.
Other stories result from a natural rivalry between two or more characters. Outside of performance, these are referred to as feuds. A feud can exist between any number of participants and can last for a few days up to multiple decades. The feud between Ric Flair and Ricky Steamboat lasted from the late 1970s into the early 1990s and allegedly spanned over two thousand matches (although most of those matches were mere dark matches). The career-spanning history between characters Mike Awesome and Masato Tanaka is another example of a long-running feud, as is the case of Stone Cold Steve Austin vs. Mr. McMahon, one of the most lucrative feuds in the World Wrestling Federation (WWF) during 1998 and 1999.
In theory, the longer a feud is built up, the more audience interest (aka heat) will exist. The main event of a wrestling show is generally the one with the most heat behind it. Commonly, a heel will hold the upper hand over a face until a final showdown, heightening dramatic tension as the face's fans desire to see them win.
Throughout the history of professional wrestling, many other elements and forms of media have been utilized in professional wrestling storytelling: pre- and post-match interviews, "backstage" skits, positions of authority and worked behind-the-scenes feuds, division rankings (typically the #1-contendership spot), contracts, lotteries, news stories on websites, and in recent years social media.
Also, anything that can be used as an element of drama can exist in professional wrestling stories: romantic relationships (including love triangles and marriage), racism, classism, nepotism, favoritism, corporate corruption, family bonds, personal histories, grudges, theft, cheating, assault, betrayal, bribery, seduction, stalking, confidence tricks, extortion, blackmail, substance abuse, self-doubt, self-sacrifice; even kidnapping, sexual fetishism, necrophilia, misogyny, rape and death have been portrayed in wrestling. Some promotions have included supernatural elements such as magic, curses, the undead and Satanic imagery (most notably The Undertaker and his Ministry of Darkness, a stable that regularly performed evil rituals and human sacrifice in Satanic-like worship of a hidden power figure). Celebrities would also be involved in storylines.
Commentators have become important in communicating the relevance of the characters' actions to the story at hand, filling in past details and pointing out subtle actions that may otherwise go unnoticed.
Promos.
A main part of the story-telling part of wrestling is a promo, promotional interview. Promos are performed, or "cut", in wrestling jargon, for a variety of reasons, including to heighten interest in a wrestler, or to hype an upcoming match.
Since the crowd is often too loud or the venue too large for promos to be heard naturally, wrestlers will use amplification when speaking in the ring. Unlike most Hollywood acting, large and highly visible handheld microphones are typically used and wrestlers often speak directly to the audience.
Championships.
Professional wrestling mimics the structure of title match combat sports. Participants compete for a championship, and must defend it after winning it. These titles are represented physically by a belt that can be worn by the champion. In the case of team wrestling, there is a belt for each member of the team.
Almost all professional wrestling promotions have one major title, and some have more. Championships are designated by divisions of weight, height, gender, wrestling style and other qualifications.
Typically, each promotion only recognizes the "legitimacy" of their own titles, although cross-promotion does happen. When one promotion absorbs or purchases another, the titles from the defunct promotion may continue to be defended in the new promotion or be decommissioned.
Behind the scenes, the bookers in a company will place the title on the most accomplished performer, or those the bookers believe will generate fan interest in terms of event attendance and television viewership. Lower ranked titles may also be used on the performers who show potential, thus allowing them greater exposure to the audience. However other circumstances may also determine the use of a championship. A combination of a championship's lineage, the caliber of performers as champion, and the frequency and manner of title changes, dictates the audience's perception of the title's quality, significance and reputation.
A wrestler's championship accomplishments can be central to their career, becoming a measure of their performance ability and drawing power. In general, a wrestler with multiple title reigns or an extended title reign is indicative of a wrestler's ability to maintain audience interest and/or a wrestler's ability to perform in the ring. As such, the most accomplished or decorated wrestlers tend to be revered as legends despite the predetermined nature of title reigns. American wrestler Ric Flair has had multiple world heavyweight championship reigns spanning over three decades. Japanese wrestler Último Dragón once held and defended a record 10 titles simultaneously.
Non-standard matches.
Often a match will take place under additional rules, usually serving as a special attraction or a climactic point in a feud or storyline. Sometimes this will be the culmination of an entire feud, ending it for the immediate future (known as a blowoff match).
Perhaps the most well-known non-standard match is the cage match, in which the ring is surrounded by a fence or similar metal structure, with the express intention of preventing escape or outside interference—and with the added bonus of the cage being a potentially brutal weapon or platform for launching attacks. The WWE has another provision where a standard cage match can end with one wrestler or wrestling team escaping the cage through the door or over the top.
Another example is the WWE's Royal Rumble match, which involves thirty participants in a random and unknown order. The Rumble match is itself a spectacle in that it is a once-yearly event with multiple participants, including individuals who might not interact otherwise. It also serves as a catalyst for the company's ongoing feuds, as well as a springboard for new storylines. It is common for legendary wrestlers to make one-time cameo appearances during the Royal Rumble match.
Other non standard matches include Hell in a Cell, Elimination Chamber, Beat the Clock, ladder, tables, chairs, stairs, falls count anywhere, "I quit", Russian chain, no holds barred, battle royals, no disqualification, last man standing, and many others as well.
Ring entrance.
While the wrestling matches themselves are the primary focus of professional wrestling, a key dramatic element of the business can be entrances of the wrestlers to the arena and ring. It is typical for a wrestler to get their biggest crowd reaction (or "pop") for their ring entrance, rather than for anything they do in the wrestling match itself, especially if former main event stars are returning to a promotion after a long absence.
All notable wrestlers now enter the ring accompanied by music, and regularly add other elements to their entrance. The music played during the ring entrance will usually mirror the wrestler's personality. Many wrestlers, particularly in America, have music and lyrics specially written for their ring entrance. While invented long before, the practice of including music with the entrance gained rapid popularity during the 1980s, largely as a result of the huge success of Hulk Hogan and the WWF, and their Rock 'n' Wrestling Connection. When a match is won, the victor's theme music is usually also played in celebration.
With the introduction of the "TitanTron" entrance screen in 1997, WWF/E wrestlers also had entrance videos made that would play along with their entrance music.
Other dramatic elements of a ring entrance can include:
Another method of entry involves descending from the ceiling with a Zip-line or rappel line and stunt harness. This has been done by Shawn Michaels at WrestleMania XII, by Sting many times in WCW and TNA, and has gained major controversy over its role in the death of wrestler Owen Hart at Over the Edge.
Special ring entrances are also developed for big occasions, most notably the WrestleMania event. For example, WrestleMania III and VI both saw all wrestlers enter the arena on motorized miniature wrestling rings. Live bands are sometimes hired to perform live entrance music at special events. John Cena and Triple H are particularly notable in recent years for their highly theatrical entrances at WrestleMania.
Wrestlers.
Wrestlers can be represented by nearly anyone, regardless of size, age, or gender. While most are typically muscular, athletic males or females, they may also be very small (Lord Littlebrook), very large (Happy Humphrey), former powerlifters (Ken Patera), former sumo wrestlers (John Tenta and Yokozuna), elderly (Mae Young), or even missing limbs (Zach Gowen).
Women's wrestling.
The women's division of professional wrestling has maintained a recognized world champion since 1937, when Mildred Burke won the original World Women's title. She then formed the World Women's Wrestling Association in the early 1950s and recognized herself as the first champion, although the championship would be vacated upon her retirement in 1956. The NWA, however, ceased to acknowledge Burke as their Women's World champion in 1954, and instead acknowledged June Byers as champion after a controversial finish to a high-profile match between Burke and Byers that year. Upon Byers' retirement in 1964, The Fabulous Moolah, who won a junior heavyweight version of the NWA World Women's Championship (the predecessor to the WWE's Women's Championship) in a tournament back in 1958, was recognized by most NWA promoters as champion by default.
In Japan, professional wrestling done by female wrestlers is called joshi puroresu (女子プロレス) or joshi puro for short. Female wrestling is usually handled by promotions that specialize in joshi puroresu rather than divisions of otherwise male-dominated promotions, as is the case in the United States. However, joshi puroresu promotions usually have agreements with male puroresu promotions such that they recognize each other's titles as legitimate, and may share cards. All Japan Women's Pro-Wrestling was the dominant joshi organization from the 1970s to the 1990s.
Intergender wrestling.
For most of its history, men and women would rarely compete against each other in professional wrestling, as it was deemed to be unfair and unchivalrous. Andy Kaufman used this to gain notoriety when he created an Intergender Championship and declared it open to any female challenger. This led to a long (worked) feud with Jerry Lawler.
In the 1980s, mixed tag team matches began to take place, with a male and female on each team and a rule stating that each wrestler could only attack the opponent of the same gender. If a tag was made, the other team had to automatically switch their legal wrestler as well. Despite these restrictions, many mixed tag matches do feature some physical interaction between participants of different genders. For example, a heel may take a cheap shot at the female wrestler of the opposing team to draw a negative crowd reaction. In "lucha libre", cheap-shots and male-female attacks are not uncommon.
Intergender singles bouts were first fought on a national level in the 1990s. This began with Luna Vachon, who faced men in ECW and WWF. Later, Chyna became the first female to hold a belt that was not exclusive to women when she won the Intercontinental Championship. While it is a rare feat in WWE, in TNA, ODB participates in singles intergender matches. Also, ODB's kayfabe husband and tag team partner Eric Young held the Knockouts Tag Team Championship for a record 478 days before it was stripped by Brooke Hogan because Young was a male.
Midget wrestling.
Midget wrestling can be traced to professional wrestling's carnival and vaudeville origins. In recent years, the popularity and prevalence of midgets in wrestling has greatly decreased due to wrestling companies depriving midget divisions of storyline and/or feud. However, WWE has made a few attempts to enter this market with their "minis" in the 1990s and the "junior's league" as recent as 2006. It is still a popular form of entertainment in Mexican wrestling, mostly as a "sideshow".
Some wrestlers may have their own specific "mini me", like Mascarita Sagrada, Alebrije has Quije, etc. There are also cases in which midgets can become valets for a wrestler, and even get physically involved in matches, like Alushe, who often accompanies Tinieblas, or KeMonito, who is portrayed as Consejo Mundial de Lucha Libre's mascot and is also a valet for Mistico. Dave Finlay was often aided in his matches by a midget known mainly as Hornswoggle while in WWE, who hid under the ring and gave a shillelagh to Finlay to use on his opponent. Finlay also occasionally threw him at his opponent(s). Hornswoggle has also been given a run with the Cruiserweight Championship and feuded with D-Generation X in 2009.
Bear wrestling.
Though they have not had the level of exposure as other wrestlers, bears have long been a part of professional wrestling. Usually declawed and muzzled, they often wrestled shoot matches against audience members, offered a cash reward if they could pin the bear. They also wrestled professionals in worked, often battle royal or handicap, matches (usually booked so the bear won). Though they have wrestled around the world and continue to do so, wrestling bears enjoyed their greatest popularity in the Southern United States, during the 1960s and 1970s. The practice of bear wrestling has met strong opposition from animal rights activists in recent decades, contributing to its lack of mainstream acceptance. As of 2006, it is banned in 20 U.S. states. Perhaps the most famous wrestling bears are Ginger, Victor, Hercules and Terrible Ted.
Styles and characteristics in different countries.
The U.S., Japan and Mexico are three countries where there is a huge market and high popularity for professional wrestling. However, the styles of professional wrestling are different, given their independent development for a long period.
Professional wrestling in the U.S. tends to have a heavy focus on story building and the establishment of characters (and their personalities). There is a story for each match, and even a longer story for successive matches. The stories usually contain characters like faces and heels, and less often antiheroes and tweeners. It is a "triumph" if the face wins, while it is a "tragedy" if the heel wins. The characters usually have strong and sharp personalities, with examples like Doink the Clown, whose personality is melodramatic, slapstick and fantastical. The opposition between faces and heels is very intense in the story, and the heels may even attack the faces during TV interviews. The relationship between different characters can also be very complex.
Although professional wrestling in Mexico ("lucha libre") also has stories and characters, they are less emphasized. Wrestlers in Mexico are traditionally more agile and perform more aerial maneuvers than professional wrestlers in the U.S. who, more often, rely on power moves and strikes to subdue their opponents. The difference in styles is due to the independent evolution of the sport in Mexico beginning in the 1930s and the fact that wrestlers in the cruiserweight division ("peso semicompleto") are often the most popular wrestlers in Mexican lucha libre. Wrestlers often execute high flying moves characteristic of "lucha libre" by utilizing the wrestling ring's ropes to catapult themselves towards their opponents, using intricate combinations in rapid-fire succession, and applying complex submission holds. "Lucha libre" is also known for its tag team wrestling matches, in which the teams are often made up of three members, instead of two as is common in the U.S.
The style of Japanese professional wrestling ("puroresu") is again different. With its origins in traditional American style of wrestling and still being under the same genre, it has become an entity in itself. Despite the similarity to its American counterpart in that the outcome of the matches remains predetermined, the phenomena are different in the form of the psychology and presentation of the sport; it is treated as a full contact combat sport as it mixes hard hitting martial arts strikes with shoot style submission holds, while in the U.S. it is rather more regarded as an entertainment show. Wrestlers incorporate kicks and strikes from martial arts disciplines, and a strong emphasis is placed on submission wrestling, and unlike the use of involved storylines in the U.S., they are not as intricate in Japan, more emphasis is placed on the concept of Fighting Spirit, meaning the Wrestlers display of physical and mental stamina are valued a lot more than theatrics. Many of Japan's wrestlers including top stars such as Shinya Hashimoto, Riki Choshu and Keiji Mutoh came from a legitimate martial arts background and many Japanese wrestlers in the 1990s began to pursue careers in mixed martial arts organizations such as Pancrase and Shooto which at the time retained the original look of "puroresu", but were actual competitions.
Culture.
Professional wrestling has developed its own cultures, both internal and external.
Those involved in producing professional wrestling have developed a kind of global fraternity, with familial bonds, shared language and passed-down traditions. New performers are expected to "pay their dues" for a few years by working in lower-profile promotions and working as ring crew before working their way upward. The permanent rosters of most promotions develop a backstage pecking order, with veterans mediating conflicts and mentoring younger wrestlers. For many decades (and still to a lesser extent today), performers were expected to keep the illusions of wrestling's legitimacy alive even while not performing, essentially acting in character any time they were in public. Some veterans speak of a "sickness" among wrestling performers, an inexplicable pull to remain active in the wrestling world despite the devastating effects the job can have on one's life and health.
Fans of professional wrestling have their own subculture, comparable to those of science fiction, video games, or comic books (in some cases, the "fandoms" overlap; in recent years, some professional wrestlers, particularly those who nurture an anti-establishment rebel persona, such as CM Punk, have made guest appearances at comic book conventions). Those who are interested in the backstage occurrences, future storylines, and reasonings behind company decisions read newsletters written by journalists with inside ties to the wrestling industry. These "rags" or "dirt sheets" have expanded into the Internet, where their information can be dispensed on an up-to-the-minute basis. Some have expanded into radio shows.
Some fans enjoy a pastime of collecting tapes of wrestling shows from specific companies, of certain wrestlers, or of specific genres. The Internet has given fans exposure to worldwide variations of wrestling they would be unable to see otherwise. Since the 1990s, many companies have been founded which deal primarily in wrestling footage. When the WWF purchased both WCW and ECW in 2001, they also obtained the entire past video libraries of both productions and have released many past matches online and on home video.
Like some other sports, fantasy leagues have developed around professional wrestling. Some take this concept further by creating E-feds (electronic federations), where a user can create their own fictional wrestling character, and role-playing storylines with other users, leading to scheduled "shows" where match results are determined by the organizers, usually based on a combination of the characters' statistics and the players' roleplaying aptitude, sometimes with audience voting.
Professional wrestling in mainstream culture.
From the first established world championship, the top professional wrestlers have garnered fame within mainstream society. Each successive generation has produced a number of wrestlers who extend their careers into the realms of music, acting, writing, business, politics or public speaking, and are known to those who are unfamiliar with wrestling in general. Conversely, celebrities from other sports or general pop culture also become involved with wrestling for brief periods of time. A prime example of this is The Rock 'n' Wrestling Connection of the 1980s, which combined wrestling with MTV.
Professional wrestling is often portrayed within other works using parody, and its general elements have become familiar tropes and memes in American culture.
Some terminology originating in professional wrestling has found its way into the common vernacular. Phrases such as "body slam", "sleeper hold" and "tag team" are used by those who do not follow professional wrestling. The term "smackdown", popularized by The Rock and WWF's "SmackDown!" in the 1990s, has been included in Merriam-Webster dictionaries since 2007.
Many television shows and films have been produced which portray in-character professional wrestlers as protagonists, such as "Ready to Rumble", "¡Mucha Lucha!", "Nacho Libre", and the Santo film series. In the wildly popular "Rocky" series of films about the fictional boxer Rocky Balboa, "Rocky III" saw its hero fighting a "boxer vs. wrestler" exhibition match against the enormous and villainous wrestler "Thunderlips", portrayed by real-life soon-to-be wrestling icon Hulk Hogan. At least two stage plays set in the world of pro wrestling have been produced: "The Baron" is a comedy that retells the life of an actual performer known as Baron von Raschke. "From Parts Unknown..." is an award-nominated Canadian drama about the rise and fall of a fictional wrestler. The 2009 "South Park" episode "W.T.F." played on the soap operatic elements of professional wrestling. One of the lead characters on the Disney Channel series "Kim Possible" was a huge fan of pro wrestling and actually featured it on an episode (with two former WWE wrestlers voicing the two fictitious wrestlers featured in the episode). The 2008 film "The Wrestler", about a washed-up professional wrestler, garnered several Oscar nominations.
The 1950 film noir "Night and the City", directed by Jules Dassin and starring Richard Widmark and Gene Tierney, told the story of a promoter in London trying to make it big, and featured a match involving real professional wrestler Stanislaus Zbyszko.
Study and analysis of professional wrestling.
With its growing popularity, professional wrestling has attracted attention as a subject of serious academic study and journalistic criticism. Many courses, theses, essays, and dissertations have analyzed wrestling's conventions, content, and its role in modern society. It is often included as part of studies on theatre, sociology, performance, and media. The Massachusetts Institute of Technology developed a course of study on the cultural significance of professional wrestling, and anthropologist Heather Levi has written an ethnography about the culture of lucha libre in Mexico.
However, this was not always the case; in the early 20th century, once it became apparent that the "sport" was worked, pro wrestling was looked down on as a cheap entertainment for the uneducated working class — an attitude that still exists to varying degrees today. The French theorist Roland Barthes was among the first to propose that wrestling was worthy of deeper analysis, in his essay "The World of Wrestling" from his book "Mythologies", first published in 1957. Barthes argued that it should be looked at not as a scamming of the ignorant, but as spectacle; a mode of theatric performance for a willing, if bloodthirsty, audience. Wrestling is described as performed art which demands an immediate reading of the juxtaposed meanings. The logical conclusion is given least importance over the theatrical performers of the wrestlers and the referee. According to Barthes, the function of a wrestler is not to win: it is to go exactly through the motions which are expected of them and to give the audience a theatrical spectacle. This work is considered a foundation of all later study.
While pro wrestling is often described simplistically as a "soap opera for males", it has also been cited as filling the role of past forms of literature and theatre; a of classical heroics, commedia dell'arte, revenge tragedies, morality plays, and burlesque. The characters and storylines portrayed by a successful promotion are seen to reflect the current mood, attitudes, and concerns of that promotion's society (and can, in turn, influence those same things). Wrestling's high levels of violence and masculinity make it a vicarious outlet for aggression during peacetime.
Documentary filmmakers have studied the lives of wrestlers and the effects the profession has on them and their families. The 1999 theatrical documentary "Beyond the Mat" focused on Terry Funk, a wrestler nearing retirement; Mick Foley, a wrestler within his prime; Jake Roberts, a former star fallen from grace; and a school of wrestling student trying to break into the business. The 2005 release ' chronicled the development of women's wrestling throughout the 20th century. Pro wrestling has been featured several times on HBO's "Real Sports with Bryant Gumbel". MTV's documentary series "True Life" featured two episodes titled "I'm a Professional Wrestler" and "I Want to Be a Professional Wrestler". Other documentaries have been produced by The Learning Channel ("The Secret World of Professional Wrestling") and A&E ('). Bloodstained Memoirs explored the careers of several pro wrestlers, including Chris Jericho, Rob Van Dam and Roddy Piper.
Injury and fatality.
Although professional wrestling is worked, there is a high chance of injury, and even death. Strikes are often stiff, especially in Japan and in independent wrestling promotions such as Combat Zone Wrestling (CZW) and Ring of Honor (ROH). The ring is often made out of 2 by 8 timber planks. Many of the injuries that occur in pro wrestling are shoulders, knee, back, neck, and rib injuries. Chronic traumatic encephalopathy and traumatic brain injuries have also been linked to pro wrestling, including in the double-murder suicide case involving Chris Benoit. Professional wrestler Davey Richards said in 2015, "We train to take damage, we know we are going to take damage and we accept that".
Less than 25 years after the 1990 WrestleMania VI, one third of its 36 competitors had died, including André the Giant and main event winner The Ultimate Warrior; all of these deaths had occurred before the age of 64.

</doc>
<doc id="24868" url="https://en.wikipedia.org/wiki?curid=24868" title="Pauli matrices">
Pauli matrices

In mathematical physics and mathematics, the Pauli matrices are a set of three complex matrices which are Hermitian and unitary. Usually indicated by the Greek letter sigma (), they are occasionally denoted by tau () when used in connection with isospin symmetries. They are
These matrices are named after the physicist Wolfgang Pauli. In quantum mechanics, they occur in the Pauli equation which takes into account the interaction of the spin of a particle with an external electromagnetic field.
Each Pauli matrix is Hermitian, and together with the identity matrix (sometimes considered as the zeroth Pauli matrix ), the Pauli matrices (multiplied by "real" coefficients) form a basis for the vector space of Hermitian matrices.
Hermitian operators represent observables, so the Pauli matrices span the space of observables of the -dimensional complex Hilbert space. In the context of Pauli's work, represents the observable corresponding to spin along the th coordinate axis in three-dimensional Euclidean space .
The Pauli matrices (after multiplication by to make them anti-Hermitian), also generate transformations in the sense of Lie algebras: the matrices form a basis for , which exponentiates to the special unitary group SU(2). The algebra generated by the three matrices is isomorphic to the Clifford algebra of , called the algebra of physical space.
Algebraic properties.
All three of the Pauli matrices can be compacted into a single expression:
where is the imaginary unit, and is the Kronecker delta, which equals +1 if and 0 otherwise. This expression is useful for "selecting" any one of the matrices numerically by substituting values of , in turn useful when any of the matrices (but no particular one) is to be used in algebraic manipulations.
The matrices are involutory:
where is the identity matrix.
From above we can deduce that the eigenvalues of each are .
Eigenvectors and eigenvalues.
Each of the (Hermitian) Pauli matrices has two eigenvalues, and . The corresponding normalized eigenvectors are:
Pauli vector.
The Pauli vector is defined by
and provides a mapping mechanism from a vector basis to a Pauli matrix basis as follows,
using the summation convention. Further,
and also (see completeness, below) 
Its (unnormalized) eigenvectors are 
formula_10
Commutation relations.
The Pauli matrices obey the following commutation relations:
and anticommutation relations:
where is the Levi-Civita symbol, Einstein summation notation is used, is the Kronecker delta, and is the identity matrix.
For example,
Relation to dot and cross product.
Pauli vectors elegantly map these commutation and anticommutation relations to corresponding vector products. Adding the commutator to the anticommutator gives
so that, 
Contracting each side of the equation with components of two -vectors and (which commute with the Pauli matrices, i.e., for each matrix and vector component (and likewise with ), and relabeling indices , to prevent notational conflicts, yields
Finally, translating the index notation for the dot product and cross product results in 
Exponential of a Pauli vector.
For 
one has, for even powers,
which can be shown first for the case using the anticommutation relations.
Thus, for odd powers,
Matrix exponentiating, and using the Taylor series for sine and cosine,
and, in the last line, the first sum is the cosine, while the second sum is the sine; so, finally,
which is analogous to Euler's formula. Note 
while the determinant of the exponential itself is just , which makes it the generic group element of SU(2).
A more abstract version of formula for a general matrix can be found in the article on matrix exponentials. A general version of for an analytic (at "a" and −"a") function is provided by application of Sylvester's formula,
The group composition law of.
A straightforward application of formula provides a parameterization of the composition law of the group . One may directly solve for in 
which specifies the generic group multiplication, where, manifestly, 
the spherical law of cosines. Given , then, 
Consequently, the composite rotation parameters in this group element (a closed form of the respective BCH expansion in this case) simply amount to 
The fact that any complex Hermitian matrices can be expressed in terms of the identity matrix and the Pauli matrices also leads to the Bloch sphere representation of mixed states' density matrix, ( positive semidefinite matrices with trace ). This can be seen by simply first writing an arbitrary Hermitian matrix as a real linear combination of as above, and then imposing the positive-semidefinite and trace conditions.
Completeness relation.
An alternative notation that is commonly used for the Pauli matrices is to write the vector index in the superscript, and the matrix indices as subscripts, so that the element in row and column of the -th Pauli matrix is .
In this notation, the completeness relation for the Pauli matrices can be written
As noted above, it is common to denote the 2 × 2 unit matrix by "σ"0, so "σ"0"αβ" = "δ""αβ". 
The completeness relation can alternatively be expressed as
Relation with the permutation operator.
Let be the transposition (also known as a permutation) between two spins and living in the tensor product space ,
This operator can also be written more explicitly as Dirac's spin exchange operator,
Its eigenvalues are therefore 1 or −1. It may thus be utilized as an interaction term in a Hamiltonian, splitting the energy eigenvalues of its symmetric versus antisymmetric eigenstates.
SU(2).
The group SU(2) is the Lie group of unitary 2×2 matrices with unit determinant; its Lie algebra is the set of all 2×2 anti-Hermitian matrices with trace 0. Direct calculation, as above, shows that the Lie algebra formula_36 is the 3-dimensional real algebra spanned by the set }. In compact notation,
As a result, each can be seen as an infinitesimal generator of SU(2). The elements of SU(2) are exponentials of linear combinations of these three generators, and multiply as indicated above in discussing the Pauli vector. Although this suffices to generate SU(2), it is not a proper representation of , as the Pauli eigenvalues are scaled unconventionally. The conventional normalization is  , so that
As SU(2) is a compact group, its Cartan decomposition is trivial.
SO(3).
The Lie algebra is isomorphic to the Lie algebra , which corresponds to the Lie group SO(3), the group of rotations in three-dimensional space. In other words, one can say that the are a realization (and, in fact, the lowest-dimensional realization) of "infinitesimal" rotations in three-dimensional space. However, even though and are isomorphic as Lie algebras, and are not isomorphic as Lie groups. is actually a double cover of , meaning that there is a two-to-one group homomorphism from to , see relationship between SO(3) and SU(2).
Quaternions.
The real linear span of is isomorphic to the real algebra of quaternions . The isomorphism from to this set is given by the following map (notice the reversed signs for the Pauli matrices):
Alternatively, the isomorphism can be achieved by a map using the Pauli matrices in reversed order,
As the quaternions of unit norm is group-isomorphic to , this gives yet another way of describing via the Pauli matrices. The two-to-one homomorphism from to can also be explicitly given in terms of the Pauli matrices in this formulation.
Quaternions form a division algebra—every non-zero element has an inverse—whereas Pauli matrices do not. For a quaternionic version of the algebra generated by Pauli matrices see biquaternions, which is a venerable algebra of eight real dimensions.
Physics.
Quantum mechanics.
In quantum mechanics, each Pauli matrix is related to an angular momentum operator that corresponds to an observable describing the spin of a spin ½ particle, in each of the three spatial directions. As an immediate consequence of the Cartan decomposition mentioned above, are the generators of a projective representation (spin representation) of the rotation group SO(3) acting on non-relativistic particles with spin ½. The states of the particles are represented as two-component spinors. In the same way, the Pauli matrices are related to the isospin operator.
An interesting property of spin ½ particles is that they must be rotated by an angle of 4 in order to return to their original configuration. This is due to the two-to-one correspondence between SU(2) and SO(3) mentioned above, and the fact that, although one visualizes spin up/down as the north/south pole on the 2-sphere 2, they are actually represented by orthogonal vectors in the two dimensional complex Hilbert space.
For a spin ½ particle, the spin operator is given by , the fundamental representation of "SU(2)". By taking Kronecker products of this representation with itself repeatedly, one may construct all higher irreducible representations. That is, the resulting spin operators for higher spin systems in three spatial dimensions, for arbitrarily large "j", can be calculated using this spin operator and ladder operators. They can be found in Rotation group SO(3)#A note on representations. The analog formula to the above generalization of Euler's formula for Pauli matrices, the group element in terms of spin matrices, is tractable, but less simple.
Also useful in the quantum mechanics of multiparticle systems, the general Pauli group is defined to consist of all -fold tensor products of Pauli matrices.

</doc>
<doc id="24869" url="https://en.wikipedia.org/wiki?curid=24869" title="Pie menu">
Pie menu

In computer interface design, a pie menu (also known as a radial menu) is a circular context menu where selection depends on direction. It is a graphical control element. A pie menu is made of several "pie slices" around an inactive center and works best with stylus input, and well with a mouse. Pie slices are drawn with a hole in the middle for an easy way to exit the menu.
Pie menus work well with keyboard acceleration, particularly four and eight item menus, on the cursor keys and the number pad. A goal of pie menus is to provide a smooth, reliable gestural style of interaction for novices and experts. A slice can lead to another pie menu; selecting this may center the pointer in the new menu.
A marking menu is a variant of this technique that makes the menu less sensitive to variance in gesture size.
As a kind of context menu, pie menus are often context-sensitive, showing different options depending on what the pointer was pointing at when the menu was requested.
History.
The first documented radial menu is attributed to a system called PIXIE in 1969. Some universities explored alternative visual layouts.
In 1986, Mike Gallaher and Don Hopkins together independently arrived at the concept of a context menu based on the angle to the origin where the exact angle and radius could be passed as parameters to a command, or the radius could be used to trigger a submenu.
The first performance comparison to linear menus was performed in 1988 showing an increase in performance of 15% less time and a reduction of selection errors.
Usage.
For novice users, pie menus are easy because they are a self-revealing gestural interface: They show what you can do and direct you how to do it. By clicking and popping up a pie menu, looking at the labels, moving the pointer in the desired direction, then clicking to make a selection, users learn the menu and practice the gesture to "mark ahead" ("mouse ahead" in the case of a mouse, "wave ahead" in the case of a dataglove). With a little practice, it becomes quite easy to mark ahead even through nested pie menus.
For the expert, the pie menus are more efficient. Because they might have built up the muscle memory for certain menu actions, and able to select the option they want without looking the pop up selections. In some cases, only when used more slowly like a traditional menu, does a pie menu pop up on the screen, to reveal the available selections. Moreover, novices can gradually become experts when they practice the same pie menu selection for many times and start to remember the menu and the motion. As Jaron Lanier of VPL Research has remarked, "The mind may forget, but the body remembers." Pie menus take advantage of the body's ability to remember muscle motion and direction, even when the mind has forgotten the corresponding symbolic labels.
Comparison with other interaction techniques.
Pie menus are faster and more reliable to select from than linear menus, because selection depends on direction instead of distance. The circular menu slices are large in size and near the pointer for fast interaction (see Fitts's law). Experienced users use muscle memory without looking at the menu while selecting from it. Nested pie menus can efficiently offer many options, and some pie menus can pop up linear menus, and combine linear and radial items in the same menu. Pie menus just like any popup menu are shown only when requested, resulting in less visual distraction and cognitive load than toolbars and menu bars that are always shown.
Pie menus show available options, in contrast to invisible mouse gestures. Pie menus, which delay appearance until the pointer is not moving, reduce intrusiveness to the same level as mouse gestures for experienced users. Pie menus take up more screen space than linear menus, and the number of slices in an individual menu must be kept low for effectiveness by using submenus. When using pie menus, submenus may overlap with the parent menu, but the parent menu may become translucent or hidden.
Pie menus are most suited for actions that have been laid out by humans, and have logical grouping choices. Linear menus are most suited for dynamic, large menus that have many possible options, without any logical grouping, since pie menus can only show a limited number of menu items. Around 3-12 items can be reasonably accommodated in a radial layout, but additional items past that tend to counteract the benefits of using pie menus in the first place. This can be overcome with related techniques that allow chaining commands in one single gesture through submenus.
However, using interaction techniques that are not pointer-based have proven problematic with both pie and linear menus for cluttered digital tabletop, where physical objects might occlude menu items.
Pie menus are unavailable as standard graphical control element in common commercial toolkits. Video games often require custom widget development, so pie menu cost is lower in that particular scenario.

</doc>
<doc id="24872" url="https://en.wikipedia.org/wiki?curid=24872" title="Pollution">
Pollution

Pollution is the introduction of contaminants into the natural environment that cause adverse change. Pollution can take the form of chemical substances or energy, such as noise, heat or light. Pollutants, the components of pollution, can be either foreign substances/energies or naturally occurring contaminants. Pollution is often classed as point source or nonpoint source pollution.
Ancient cultures.
Air pollution has always accompanied civilizations. Pollution started from prehistoric times when man created the first fires. According to a 1983 article in the journal "Science," "soot found on ceilings of prehistoric caves provides ample evidence of the high levels of pollution that was associated with inadequate ventilation of open fires." Metal forging appears to be a key turning point in the creation of significant air pollution levels outside the home. Core samples of glaciers in Greenland indicate increases in pollution associated with Greek, Roman and Chinese metal production, but at that time the pollution was comparatively small and could be handled by nature.
Urban pollution.
The burning of coal and wood, and the presence of many horses in concentrated areas made the cities the cesspools of pollution. The Industrial Revolution brought an infusion of untreated chemicals and wastes into local streams that served as the water supply. King Edward I of England banned the burning of sea-coal by proclamation in London in 1272, after its smoke became a problem. But the fuel was so common in England that this earliest of names for it was acquired because it could be carted away from some shores by the wheelbarrow.
It was the industrial revolution that gave birth to environmental pollution as we know it today. London also recorded one of the earlier extreme cases of water quality problems with the Great Stink on the Thames of 1858, which led to construction of the London sewerage system soon afterward. Pollution issues escalated as population growth far exceeded view ability of neighborhoods to handle their waste problem. Reformers began to demand sewer systems, and clean water.
In 1870, the sanitary conditions in Berlin were among the worst in Europe. August Bebel recalled conditions before a modern sewer system was built in the late 1870s:
The primitive conditions were intolerable for a world national capital, and the Imperial German government brought in its scientists, engineers and urban planners to not only solve the deficiencies but to forge Berlin as the world's model city. A British expert in 1906 concluded that Berlin represented "the most complete application of science, order and method of public life," adding "it is a marvel of civic administration, the most modern and most perfectly organized city that there is."
The emergence of great factories and consumption of immense quantities of coal gave rise to unprecedented air pollution and the large volume of industrial chemical discharges added to the growing load of untreated human waste. Chicago and Cincinnati were the first two American cities to enact laws ensuring cleaner air in 1881. Pollution became a major issue in the United States in the early twentieth century, as progressive reformers took issue with air pollution caused by coal burning, water pollution caused by bad sanitation, and street pollution caused by the 3 million horses who worked in American cities in 1900, generating large quantities of urine and manure. As historian Martin Melosi notes, The generation that first saw automobiles replacing the horses saw cars as "miracles of cleanliness.". By the 1940s, however, automobile-caused smog was a major issue in Los Angeles.
Other cities followed around the country until early in the 20th century, when the short lived Office of Air Pollution was created under the Department of the Interior. Extreme smog events were experienced by the cities of Los Angeles and Donora, Pennsylvania in the late 1940s, serving as another public reminder.
Air pollution would continue to be a problem in England, especially later during the industrial revolution, and extending into the recent past with the Great Smog of 1952.
Awareness of atmospheric pollution spread widely after World War II, with fears triggered by reports of radioactive fallout from atomic warfare and testing. Then a non-nuclear event, The Great Smog of 1952 in London, killed at least 4000 people. This prompted some of the first major modern environmental legislation, The Clean Air Act of 1956.
Pollution began to draw major public attention in the United States between the mid-1950s and early 1970s, when Congress passed the Noise Control Act, the Clean Air Act, the Clean Water Act and the National Environmental Policy Act.
Severe incidents of pollution helped increase consciousness. PCB dumping in the Hudson River resulted in a ban by the EPA on consumption of its fish in 1974. Long-term dioxin contamination at Love Canal starting in 1947 became a national news story in 1978 and led to the Superfund legislation of 1980. The pollution of industrial land gave rise to the name brownfield, a term now common in city planning.
The development of nuclear science introduced radioactive contamination, which can remain lethally radioactive for hundreds of thousands of years. Lake Karachay, named by the Worldwatch Institute as the "most polluted spot" on earth, served as a disposal site for the Soviet Union throughout the 1950s and 1960s. Second place may go to the area of Chelyabinsk Russian as the "Most polluted place on the planet".
Nuclear weapons continued to be tested in the Cold War, especially in the earlier stages of their development. The toll on the worst-affected populations and the growth since then in understanding about the critical threat to human health posed by radioactivity has also been a prohibitive complication associated with nuclear power. Though extreme care is practiced in that industry, the potential for disaster suggested by incidents such as those at Three Mile Island and Chernobyl pose a lingering specter of public mistrust. Worldwide publicity has been intense on those disasters. Widespread support for test ban treaties has ended almost all nuclear testing in the atmosphere.
International catastrophes such as the wreck of the Amoco Cadiz oil tanker off the coast of Brittany in 1978 and the Bhopal disaster in 1984 have demonstrated the universality of such events and the scale on which efforts to address them needed to engage. The borderless nature of atmosphere and oceans inevitably resulted in the implication of pollution on a planetary level with the issue of global warming. Most recently the term persistent organic pollutant (POP) has come to describe a group of chemicals such as PBDEs and PFCs among others. Though their effects remain somewhat less well understood owing to a lack of experimental data, they have been detected in various ecological habitats far removed from industrial activity such as the Arctic, demonstrating diffusion and bioaccumulation after only a relatively brief period of widespread use.
A much more recently discovered problem is the Great Pacific Garbage Patch, a huge concentration of plastics, chemical sludge and other debris which has been collected into a large area of the Pacific Ocean by the North Pacific Gyre. This is a less well known pollution problem than the others described above, but nonetheless has multiple and serious consequences such as increasing wildlife mortality, the spread of invasive species and human ingestion of toxic chemicals. Organizations such as 5 Gyres have researched the pollution and, along with artists like Marina DeBris, are working toward publicizing the issue.
Growing evidence of local and global pollution and an increasingly informed public over time have given rise to environmentalism and the environmental movement, which generally seek to limit human impact on the environment.
Forms of pollution.
The major forms of pollution are listed below along with the particular contaminant relevant to each of them:
Pollutants.
A pollutant is a waste material that pollutes air, water or soil. Three factors determine the severity of a pollutant: its chemical nature, the concentration and the persistence.
Cost of pollution.
Pollution has cost. Manufacturing activities that cause air pollution impose health and clean-up costs on the whole society, whereas the neighbors of an individual who chooses to fire-proof his home may benefit from a reduced risk of a fire spreading to their own houses. If external costs exist, such as pollution, the producer may choose to produce more of the product than would be produced if the producer were required to pay all associated environmental costs. Because responsibility or consequence for self-directed action lies partly outside the self, an element of externalization is involved. If there are external benefits, such as in public safety, less of the good may be produced than would be the case if the producer were to receive payment for the external benefits to others.
Sources and causes.
Air pollution comes from both natural and human-made (anthropogenic) sources. However, globally human-made pollutants from combustion, construction, mining, agriculture and warfare are increasingly significant in the air pollution equation.
Motor vehicle emissions are one of the leading causes of air pollution. China, United States, Russia, India Mexico, and Japan are the world leaders in air pollution emissions. Principal stationary pollution sources include chemical plants, coal-fired power plants, oil refineries, petrochemical plants, nuclear waste disposal activity, incinerators, large livestock farms (dairy cows, pigs, poultry, etc.), PVC factories, metals production factories, plastics factories, and other heavy industry. Agricultural air pollution comes from contemporary practices which include clear felling and burning of natural vegetation as well as spraying of pesticides and herbicides
About 400 million metric tons of hazardous wastes are generated each year. The United States alone produces about 250 million metric tons. Americans constitute less than 5% of the world's population, but produce roughly 25% of the world’s carbon dioxide, and generate approximately 30% of world’s waste. In 2007, China has overtaken the United States as the world's biggest producer of , while still far behind based on per capita pollution - ranked 78th among the world's nations.
In February 2007, a report by the Intergovernmental Panel on Climate Change (IPCC), representing the work of 2,500 scientists, economists, and policymakers from more than 120 countries, said that humans have been the primary cause of global warming since 1950. Humans have ways to cut greenhouse gas emissions and avoid the consequences of global warming, a major climate report concluded. But to change the climate, the transition from fossil fuels like coal and oil needs to occur within decades, according to the final report this year from the UN's Intergovernmental Panel on Climate Change (IPCC).
Some of the more common soil contaminants are chlorinated hydrocarbons (CFH), heavy metals (such as chromium, cadmium–found in rechargeable batteries, and lead–found in lead paint, aviation fuel and still in some countries, gasoline), MTBE, zinc, arsenic and benzene. In 2001 a series of press reports culminating in a book called "Fateful Harvest" unveiled a widespread practice of recycling industrial byproducts into fertilizer, resulting in the contamination of the soil with various metals. Ordinary municipal landfills are the source of many chemical substances entering the soil environment (and often groundwater), emanating from the wide variety of refuse accepted, especially substances illegally discarded there, or from pre-1970 landfills that may have been subject to little control in the U.S. or EU. There have also been some unusual releases of polychlorinated dibenzodioxins, commonly called "dioxins" for simplicity, such as TCDD.
Pollution can also be the consequence of a natural disaster. For example, hurricanes often involve water contamination from sewage, and petrochemical spills from ruptured boats or automobiles. Larger scale and environmental damage is not uncommon when coastal oil rigs or refineries are involved. Some sources of pollution, such as nuclear power plants or oil tankers, can produce widespread and potentially hazardous releases when accidents occur.
In the case of noise pollution the dominant source class is the motor vehicle, producing about ninety percent of all unwanted noise worldwide.
Effects.
Human health.
Adverse air quality can kill many organisms including humans. Ozone pollution can cause respiratory disease, cardiovascular disease, throat inflammation, chest pain, and congestion. Water pollution causes approximately 14,000 deaths per day, mostly due to contamination of drinking water by untreated sewage in developing countries. An estimated 500 million Indians have no access to a proper toilet, Over ten million people in India fell ill with waterborne illnesses in 2013, and 1,535 people died, most of them children. Nearly 500 million Chinese lack access to safe drinking water. A 2010 analysis estimated that 1.2 million people died prematurely each year in China because of air pollution. The WHO estimated in 2007 that air pollution causes half a million deaths per year in India. Studies have estimated that the number of people killed annually in the United States could be over 50,000.
Oil spills can cause skin irritations and rashes. Noise pollution induces hearing loss, high blood pressure, stress, and sleep disturbance. Mercury has been linked to developmental deficits in children and neurologic symptoms. Older people are majorly exposed to diseases induced by air pollution. Those with heart or lung disorders are at additional risk. Children and infants are also at serious risk. Lead and other heavy metals have been shown to cause neurological problems. Chemical and radioactive substances can cause cancer and as well as birth defects.
Environment.
Pollution has been found to be present widely in the environment. There are a number of effects of this:
Environmental health information.
The Toxicology and Environmental Health Information Program (TEHIP) at the United States National Library of Medicine (NLM) maintains a comprehensive toxicology and environmental health web site that includes access to resources produced by TEHIP and by other government agencies and organizations. This web site includes links to databases, bibliographies, tutorials, and other scientific and consumer-oriented resources. TEHIP also is responsible for the Toxicology Data Network (TOXNET) an integrated system of toxicology and environmental health databases that are available free of charge on the web.
TOXMAP is a Geographic Information System (GIS) that is part of TOXNET. TOXMAP uses maps of the United States to help users visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs.
Regulation and monitoring.
To protect the environment from the adverse effects of pollution, many nations worldwide have enacted legislation to regulate various types of pollution as well as to mitigate the adverse effects of pollution.
Pollution control.
Pollution control is a term used in environmental management. It means the control of emissions and effluents into air, water or soil. Without pollution control, the waste products from overconsumption, heating, agriculture, mining, manufacturing, transportation and other human activities, whether they accumulate or disperse, will degrade the environment. In the hierarchy of controls, pollution prevention and waste minimization are more desirable than pollution control. In the field of land development, low impact development is a similar technique for the prevention of urban runoff.
Perspectives.
The earliest precursor of pollution generated by life forms would have been a natural function of their existence. The attendant consequences on viability and population levels fell within the sphere of natural selection. These would have included the demise of a population locally or ultimately, species extinction. Processes that were untenable would have resulted in a new balance brought about by changes and adaptations. At the extremes, for any form of life, consideration of pollution is superseded by that of survival.
For humankind, the factor of technology is a distinguishing and critical consideration, both as an enabler and an additional source of byproducts. Short of survival, human concerns include the range from quality of life to health hazards. Since science holds experimental demonstration to be definitive, modern treatment of toxicity or environmental harm involves defining a level at which an effect is observable. Common examples of fields where practical measurement is crucial include automobile emissions control, industrial exposure (e.g. Occupational Safety and Health Administration (OSHA) PELs), toxicology (e.g. ), and medicine (e.g. medication and radiation doses).
"The solution to pollution is dilution", is a dictum which summarizes a traditional approach to pollution management whereby sufficiently diluted pollution is not harmful. It is well-suited to some other modern, locally scoped applications such as laboratory safety procedure and hazardous material release emergency management. But it assumes that the dilutant is in virtually unlimited supply for the application or that resulting dilutions are acceptable in all cases.
Such simple treatment for environmental pollution on a wider scale might have had greater merit in earlier centuries when physical survival was often the highest imperative, human population and densities were lower, technologies were simpler and their byproducts more benign. But these are often no longer the case. Furthermore, advances have enabled measurement of concentrations not possible before. The use of statistical methods in evaluating outcomes has given currency to the principle of probable harm in cases where assessment is warranted but resorting to deterministic models is impractical or infeasible. In addition, consideration of the environment beyond direct impact on human beings has gained prominence.
Yet in the absence of a superseding principle, this older approach predominates practices throughout the world. It is the basis by which to gauge concentrations of effluent for legal release, exceeding which penalties are assessed or restrictions applied. One such superseding principle is contained in modern hazardous waste laws in developed countries, as the process of diluting hazardous waste to make it non-hazardous is usually a regulated treatment process. Migration from pollution dilution to elimination in many cases can be confronted by challenging economical and technological barriers.
Greenhouse gases and global warming.
[[Image:CO2-by-country--1990-2025.png|thumb|300px|Historical and projected CO2 emissions by country (as of 2005).
Source: Energy Information Administration.]]
Carbon dioxide, while vital for photosynthesis, is sometimes referred to as pollution, because raised levels of the gas in the atmosphere are affecting the Earth's climate. Disruption of the environment can also highlight the connection between areas of pollution that would normally be classified separately, such as those of water and air. Recent studies have investigated the potential for long-term rising levels of atmospheric carbon dioxide to cause slight but critical increases in the acidity of ocean waters, and the possible effects of this on marine ecosystems.
Most polluted places in the developing world.
The Blacksmith Institute, an international non-for-profit organization dedicated to eliminating life-threatening pollution in the developing world, issues an annual list of some of the world's worst polluted places..

</doc>
<doc id="24873" url="https://en.wikipedia.org/wiki?curid=24873" title="Pole weapon">
Pole weapon

A pole weapon or polearm is a close combat weapon in which the main fighting part of the weapon is fitted to the end of a long shaft, typically of wood, thereby extending the user's effective range. Glaives, poleaxes, halberds, and naginata are all varieties of polearms.
The purpose of using pole weapons is either to extend reach or to increase angular momentum—and thus striking power—when the weapon is swung. Because they contain relatively little metal, polearms are cheap to make. This has made them the favored weapon of peasant levies and peasants in rebellion the world over. Many are adapted from farm implements, or other tools.
Polearms were common weapons on medieval European battlefields. Their range and impact force made them effective weapons against armored warriors on horseback, because they could penetrate armor. The Renaissance saw a plethora of different varieties. Polearms in modern times are largely constrained to ceremonial military units such as the Papal Swiss Guard or Yeomen of the Guard or traditional martial arts. Chinese Martial Arts in particular have preserved a wide variety of weapons and techniques.
Classification difficulties.
The classification of pole weapons can be difficult, and European weapon classifications in particular can be confusing. This can be due to a number of factors, including uncertainty in original descriptions, changes in weapons or nomenclature through time, mistranslation of terms, and the well-meaning inventiveness of later experts. For example, the word 'halberd' is also used to translate the Chinese ji and also a range of medieval Scandinavian weapons as described in sagas, such as the atgeir.
In the words of the arms expert Ewart Oakeshott,
While men-at-arms may have been armed with custom designed military weapons, militias were often armed with whatever was available. These may or may not have been mounted on poles and described by one of more names. The problems with precise definitions can be inferred by a contemporary description of Royalist infantry which were engaged in the Battle of Birmingham (1643) during the first year of English Civil War (in the early modern period). The infantry regiment that accompanied Prince Rupert's cavalry were armed:
List of pole weapons.
Dark Ages/Medieval Europe.
Danish axe.
The Danish Axe (also Broad Axe, Dane-axe) is a weapon with a heavy crescent-shaped head mounted on a haft 4 ft. to 6 ft. (1.2-1.8 m.) in length. Originally a Viking weapon, it was adopted by the Anglo-Saxons and Normans in the 11th century, spreading through Europe in the 12th and 13th centuries. Variants of this basic weapon continued in use in Scotland and Ireland into the 16th century. A form of 'Long Axe'.
Sparth axe.
In the 13th century, variants on the Danish axe are seen. Described in English as a "sparth" (from the Old Norse "sparðr") or "pale-axe", the weapon featured a larger head with broader blade, the rearward part of the crescent sweeping up to contact (or even be attached to) the haft.
In Ireland, this axe was known as a "Sparr Axe". Originating in either Western Scotland or Ireland, the "sparr" was widely used by the galloglass. Although sometimes said to derive from the Irish for a joist or beam, a more likely definition is as a variant of sparth. Although attempts have been made to suggest that the sparr had a distinctive shaped head, illustrations and surviving weapons show there was considerable variation and the distinctive feature of the weapon was its long haft.
Fauchard.
A fauchard is a type of polearm which was used in medieval Europe from the 11th through the 14th centuries. The design consisted of a curved blade put atop a pole. The blade bore a moderate to strong curve along its length; however, unlike a glaive, the cutting edge was on the concave side (similar to a scythe or sickle). Later variants had one or more spear points attached to the back or top of the blade for stabbing. The later variant can easily be confused with the guisarme or bill-guisarme, since it superficially appears to have a "hook".
Guisarme.
A guisarme (sometimes gisarme, giserne or bisarme) was a pole weapon used in Europe primarily between 1000–1400. It was used primarily to dismount knights and horsemen. Like most polearms it was developed by peasants by combining hand tools with long poles, in this case by putting a pruning hook onto a spear shaft. While hooks are fine for dismounting horsemen from mounts, they lack the stopping power of a spear especially when dealing with static opponents. While early designs were simply a hook on the end of a long pole, later designs implemented a small reverse spike on the back of the blade. Eventually weapon makers incorporated the usefulness of the hook in a variety of different polearms and "guisarme" became a catch-all for any weapon that included a hook on the blade. Ewart Oakeshott has proposed an alternative description of the weapon as a crescent shaped socketed axe.
Glaive.
A glaive is a polearm consisting of a single-edged tapering blade similar in shape to a modern kitchen knife on the end of a pole. The blade was around 18 inches (55 cm) long, on the end of a pole 6 or 7 feet (180–210 cm) long However, instead of having a tang like a sword or naginata, the blade is affixed in a socket-shaft configuration similar to an axe head, both the blade and shaft varying in length. Illustrations in the 13th century Maciejowski Bible show a short staffed weapon with a long blade used by both infantry and cavalry. Occasionally glaive blades were created with a small hook or spike on the reverse side. Such glaives are named glaive-guisarme.
Voulge.
A voulge (occasionally called a pole cleaver) is a curved blade attached to a pole by binding the lower 2/3 of the blade to the side of the pole, to form a sort of axe. Looks very similar to a glaive.
Svärdstav.
A svärdstav (literally sword-staff) is a Swedish medieval polearm that consists of a two-edged sword blade attached to a 2-metre staff. The illustrations often show the weapon being equipped with sword-like quillons. The illustrations sometimes show a socket mount and reinforcing langets being used, but sometimes they are missing; it is possible this weapon was sometimes manufactured by simply attaching an old sword blade onto a long pole on its tang, not unlike the naginata.
Renaissance Europe.
Corseque.
A corseque has a three-bladed head on a 6–8 ft. (1.8m-2.5m.) haft which, like the partisan, similar to the winged spear or spetum in the later Middle Ages. It was popular in Europe in the 16th and 17th centuries. Surviving examples have a variety of head forms but there are two main variants, one with the side blades (known as flukes or wings) branching from the neck of the central blade at 45 degrees, the other with hooked blades curving back towards the haft. The corseque is usually associated with the rawcon, ranseur and runka. Another possible association is with the "three-grayned staff" listed as being in the armoury of Henry VIII in 1547 (though the same list also features 84 rawcons, suggesting the weapons were not identical in 16th century English eyes). Another modern term used for particularly ornate-bladed corseques is the "chauve-souris".
Halberd.
A halberd (or Swiss voulge) is a two-handed pole weapon that came to prominent use during the 14th and 15th centuries but has continued in use as a ceremonial weapon to the present day. First recorded as "hellembart" in 1279, the word "halberd" possibly comes from the German words "Halm" (staff) or "Helm" (helmet), and "Barte" (axe). The halberd consists of an axe blade topped with a spike mounted on a long shaft. It always has a hook or thorn on the back side of the axe blade for grappling mounted combatants. Early forms are very similar in many ways to certain forms of voulge, while 16th century and later forms are similar to the pollaxe. The Swiss were famous users of the halberd in the medieval and renaissance eras, with various cantons evolving regional variations of the basic form.
Poleaxe.
In the 14th century, the basic long axe gained an armour piercing spike on the back and another on the end of the haft for thrusting. This is similar to the pollaxe of 15th century. The poleaxe emerged in response to the need for a weapon that could penetrate plate armour and featured various combinations of an axe-blade, a back-spike and a hammer. It was the favoured weapon for men-at-arms fighting on foot into the sixteenth century.
See also Bec de corbin, lucerne hammer
Asia.
Dagger-axe.
The dagger-axe, or "gee" (Chinese: 戈; pinyin: gē; Wade–Giles: ko; sometimes confusingly translated "halberd") is a type of weapon that was in use from Shang dynasty until at least Han dynasty China. It consists of a dagger-shaped blade made of bronze (or later iron) mounted by the tang perpendicular wooden shaft. A common Bronze Age infantry weapon. Also used by charioteers. Some dagger axes include a spear-point. There is a (rare) variant type with a divided two-part head, consisting of the usual straight blade and a scythe-like blade. Other rarities include archaeology findings with 2 or sometimes 3 blades stacked in line on top of a pole, but were generally thought as ceremonial polearms. Though the weapon saw frequent use in ancient China, the use of the dagger-axe decreased dramatically after the Qin and Han dynasties. By the medieval Chinese dynasties, with the decline of chariot warfare, the use of the dagger-axe was almost nonexistent.
Guan dao.
A Guan dao or Kwan tou is a type of Chinese pole weapon. In Chinese it is properly called a Yanyue dao (偃月刀) which translates as "reclining moon blade". Some believed it comes from the late Han Era and supposedly used by the late Eastern Han Dynasty general Guan Yu, but archaeological findings so far showed that Han dynasty armies were generally using straight single-edged blades, as curved blades came several centuries later. There is no reason to believe their polearms had curved-blades on them. Besides, historical accounts of the Three Kingdoms era had several specific records of Guan Yu thrusting his opponents down (probably with a spear-like polearm) in battles, instead of cutting them down with a curved-blade. Alternatively the guan dao is also known as "Chun Qiu Da Dao" ("Spring Autumn Great Knife"), again probably related to Guan Yu's loyal image depicted in the Ming dynasty novel "Romance of the Three Kingdoms", but possibly a Ming author's invention. It consists of a heavy blade mounted atop a wooden or metal pole with a pointed metal counter weight used for striking and stabbing on the opposite end.
The blade is very deep and curved on its face; this resembles a Chinese Sabre or Dao. Used by cavalry. Supposed to take great physical prowess to wield in combat due to great weight. Variants include having rings along the length of the straight back edge as found in the nine-ring guan dao for use as distractions or entanglements for incoming enemy weapons, having the tip curl into a rounded spiral as in the elephant guan dao, or featuring a more ornate design as exemplified by the dragon head guan dao.
Podao.
Chinese polearm, a 'long-handled sabre', also known as the zhan ma dao (horsecutter sabre) which has a lighter blade and a ring at the end in that it. A pu dao is an infantryman's weapon mainly used for cutting the legs off oncoming charging horses to bring down the riders.
Ji.
Ji (Chinese: 戟), the Chinese halberd, was used as a military weapon in one form or another from at least as early as the Shang dynasty until the end of the Qing dynasty. The ji resembles a Chinese spear with a crescent blade attached to the head, as sort of an axe blade. Sometimes double-bladed with 2 crescent blades on opposing sides of the spearhead.(refer to the right most weapons in the 2 Chinese polearm pictures)
Naginata.
A naginata (なぎなた or 薙刀) is a Japanese polearm that was traditionally used by members of the samurai class. A naginata consists of a wood shaft with a curved blade on the end; it is descended from the Chinese guan dao. Usually it also had a sword-like guard (tsuba) between the blade and shaft. It was mounted with a tang and held in place with a pin or pins, rather than going over the shaft using a socket.
Nagamaki.
A nagamaki is a pole weapon that was traditionally used in Japan by members of the samurai class, typically against mounted opponents. It had a much shorter grip and longer blade than the naginata, and was developed later. Unlike most Japanese weapons, there were no specific rules about exact measurements and proportions for nagamaki. It varies from typical European construction of polearms in that, like most Japanese weapons, it was mounted with a tang and held in place with a pin or pins, rather than going over the shaft using a socket. It may have been manufactured using a remounted sword blade.
Woldo.
The Korean woldo was a variation of the Chinese guan dao. It was originally used by the medieval Shilla warriors. Wielding the woldo took time due to its weight, but in the hands of a trained soldier, the woldo was a fearsome, agile weapon famous for enabling a single soldier to cut down ranks of infantrymen. The woldo was continually in use for the military in Korea with various modifications made over the decades. Unlike the Chinese with the guan dao, the Koreans found the woldo unwieldy on horseback, and thus, it was specifically tailored to the needs of infantrymen. The Joseon government implemented rigorous training regimens requiring soldiers to be proficient with swordsmanship, and the use of the woldo. Though it was never widely used as a standard weapon, the woldo saw action on many fronts and was considered by many Korean troops to be a versatile weapon. Recently, a contemporary revival in various martial arts in Korea has brought interest into the application of the woldo and its history.
Ngao.
The ngao or ngau (ง้าว,ของ้าว) is a Thai polearm that was traditionally used by elephant-riding infantry and is still used by practitioners of krabi krabong. Known in Malay as a "dap", it consists of a wooden shaft with a curved blade fashioned onto the end, and is similar in design to the Korean woldo. Usually, it also had a hook (ขอ) between the blade and shaft used for commanding the elephant. The elephant warrior used the ngao like a blade from atop an elephant or horse during battle.

</doc>
<doc id="24874" url="https://en.wikipedia.org/wiki?curid=24874" title="PHD">
PHD

PHD or PhD may refer to:

</doc>
<doc id="24875" url="https://en.wikipedia.org/wiki?curid=24875" title="Personal jurisdiction">
Personal jurisdiction

Personal jurisdiction is a court's jurisdiction over the "parties" to a lawsuit, as opposed to subject-matter jurisdiction, which is jurisdiction over the "law and facts" involved in the suit. If a court does not have "personal" jurisdiction over a party, its rulings or decrees cannot be enforced upon that party, except by comity; i.e., to the extent that the sovereign having jurisdiction over the party allows the court to enforce them upon that party. A court that has "personal" jurisdiction has both the authority to rule on the law and facts of a suit and the power to enforce its decision upon a party to the suit. In some cases, territorial jurisdiction may also constrain a court's reach, such as preventing hearing of a case concerning events occurring on foreign territory between two citizens of the home jurisdiction.
International principles.
Since there is no world government which all countries recognize to arbitrate disputes over jurisdiction, sovereign powers can find themselves in conflict over which is the more appropriate venue to hear a case, or which country's laws should apply. These conflicts are sometimes resolved de facto by physical factors, such as which country has physical possession of a defendant or property, or sometimes by use of physical police or military force to seize people or property. A country with loose rule of law - for example an absolute monarchy with no independent judiciary - may arbitrarily choose to assert jurisdiction over a case without citing any particular justification. Such assertion can cause problems, such as encouraging other countries to take arbitrary actions over foreign citizens and property, or even provoking skirmishes or armed conflict.
In practice, many countries operate by one or another principles, either in written law or in practice, which communicate when the country will and will not assert jurisdiction:
Different principles are applied by different countries, and different principles may be applied by the same country in different circumstances. Determination of whether or not a court has jurisdiction to hear a case is the first stage of a conflict of laws proceeding, potentially followed by choice of law to determine which jurisdiction's laws apply. Executive prosecutorial authority and foreign policy also play a role in scope and practical impact of jurisdiction choices.
Any assertion of jurisdiction based on anything other than the territorial principle is known as extraterritorial jurisdiction. Prosecution of a case against an out-of-territory defendant is known as assertion of long arm jurisdiction.
When a person commits a crime in a foreign country against the laws of that country, usually the host country is responsible for prosecution. The Vienna Convention on Consular Relations requires that the host country notify the foreign embassy, potentially allowing the foreign country to assist in legal defense and monitor conditions of detention. (Most countries protect their citizens against foreign powers in general.)
Foreign diplomats enjoy diplomatic immunity in many countries based on the Vienna Convention on Diplomatic Relations or bilateral agreement, and foreign military personnel may be subject to the jurisdiction of their home country based on a status of forces agreement or Visiting Forces Agreement.
If a person is not physically present in the country which wishes to prosecute a case, that country may either wait until the person enters the national territory, or pursue extradition by legal or extralegal means, and with or without a general extradition treaty. Some countries (like China) prefer to prosecute their own citizens for crimes committed abroad rather than extradite them. Other countries defer to the host country.
When a crime is committed outside the territory of any country, such as in Antarctica, on watercraft in international waters, on aircraft in international airspace, and on spacecraft, jurisdiction is usually determined by the nationality of defendants or victims, or by the flag state of the vessel. This is determined by the admiralty law of the countries involved and in international agreements.
History in English and U.S. law.
The concept of personal jurisdiction in English law has its origin in the idea that a monarch could not exercise power over persons or property located outside of his or her kingdom. To some degree, this was a de facto rule; the monarch's men could not arrest people or seize property outside the kingdom without risking physical conflict with the soldiers and police of other kingdoms. Slowly this principle was incorporated into written law, but problems arose in cases where property owners could not be sued because they had left the kingdom or had died and therefore were not present within the kingdom at the time they were being sued. To solve this problem, the courts created another type of jurisdiction, called "quasi in rem", that is, jurisdiction over the land itself, even if the person who owned the land was not in the country. However, this jurisdiction was limited to the settlement of debts owed by the owner of the land.
In the United States, the exercise of personal jurisdiction by a court must both comply with Constitutional limitations, and be authorized by a statute. In the United Kingdom, the exercise of personal jurisdiction does not need a statutory basis, since the United Kingdom does not have a written constitution.
United States.
The intersection of American federalism and the rules and theories of jurisdiction inherited from the common law of England has resulted in a highly complex body of law respecting personal jurisdiction in the United States. These rules limit both state and federal courts in their ability to hear cases.
Principles of personal jurisdiction.
Three fundamentals of personal jurisdiction constrain the ability of courts in the United States to bind individuals or property to its decisions: consent, power, and notice.
Consent.
The United States legal system is an adversarial system. Civil suits cannot be initiated by third parties, but must be filed by the aggrieved party who seeks redress. Generally, the action is initiated in the jurisdiction where the event occurred, where the defendant can be served or where the parties have agreed to have the case located. The filing of a complaint or "prayer for relief" is a voluntary action by the person aggrieved, and as a necessity of this request, the person seeking relief consents to be bound by the judgment of the court. The doctrine of consent is also extended to defendants who attend and litigate actions without challenging the court's personal jurisdiction. Consent may also derive from a pre-litigation agreement by the parties, such as a forum selection clause in a contract (not to be confused with a choice of law clause). Doctrines such as claim preclusion prevent re-litigation of failed complaints in alternative forums. Claim preclusion does not, however, prevent the refiling of a claim that was filed in a court that did not have personal jurisdiction over the defendant.
Power.
In cases where a defendant challenges personal jurisdiction, a court may still exercise personal jurisdiction if it has independent power to do so. This power is founded in the inherent nature of the State: sovereignty over affairs within its territory.
Notice.
The Fifth and Fourteenth Amendment to the United States Constitution preserve the right of the individual to "due process". Due process requires that notice be given in a manner "reasonably calculated" to inform a party of the action affecting him. Originally, "Notice" (and the power of the State) was often exercised more forcefully, the defendant in a civil case sometimes being seized and brought before the court under a writ of "capias ad respondendum". Notice in such a case is inferred from consent of the defendant to go with the officer. Nowadays, when exercising power over an individual without consent, notice is usually given by formal delivery of suitable papers to the defendant (service of process).
Historical background: territorial jurisdiction.
Originally, jurisdiction over parties in the United States was determined by strict interpretation of the geographic boundaries of each state's sovereign power. In "Pennoyer v. Neff", the Supreme Court discussed that though each state ceded certain powers (e.g. foreign relations) to the Federal Government or to no entity at all (e.g. the powers that are eliminated by the protections of the bill of rights), the states retained all the other powers of sovereignty, including the exclusive power to regulate the affairs of individuals and property within its territory. Necessarily following from this, one state's exercise of power could not infringe upon the sovereignty of another state. Thus, Constitutional limitations applied to the validity of state court judgments.
Three types of jurisdiction developed, collectively termed territorial jurisdiction because of their reliance upon territorial control: "in personam" jurisdiction, "in rem" jurisdiction, and "quasi in rem" jurisdiction. Some sources refer to all three types of territorial jurisdiction as personal jurisdiction, since most actions against property (in rem jurisdiction) bear, in the end, upon the rights and obligations of persons. Others continue to recognize the traditional distinction between personal jurisdiction and jurisdiction over property, even after "Shaffer v. Heitner" (discussed below).
In personam jurisdiction referred to jurisdiction over a particular person (or entity, such as a company). "In personam" jurisdiction, if held by a state court, permitted that court to rule upon any case over which it otherwise held jurisdiction. Under territorial jurisdiction, pure "in personam" jurisdiction could only be established by serving notice upon the individual while that individual was within the territory of the state.
In rem jurisdiction referred to jurisdiction over a particular piece of property, most commonly real estate or land. Certain cases, notably government suits for unpaid property taxes, proceed not against an individual but against their property directly. Under territorial jurisdiction, "in rem" jurisdiction could be exercised by the courts of a state by seizing the property in question. Since an actual tract of land could not literally be brought into a courtroom as a person could, this was effected by giving notice upon the real property itself. "In rem" jurisdiction was thus supported by the assumption that the owner of that property, having a concrete economic interest in the property, had a duty to look after the affairs of their property, and would be notified of the pending case by such seizure. "In rem" jurisdiction was limited to deciding issues regarding the specific property in question.
Quasi in rem jurisdiction involved the seizure of property held by the individual against whom the suit was brought, and attachment of that property to the case in question. This form of territorial jurisdiction developed from the rationale of "in rem" jurisdiction, namely that seizure of the property was reasonably calculated to inform an individual of the proceedings against them.
Once a valid judgment was obtained against an individual, however, the plaintiff could pursue recovery against the assets of the defendant regardless of their location, as other states were obligated by the Full Faith and Credit Clause of the Constitution to recognize such a judgment (i.e. had ceded their power to refuse comity to fellow states of the Union). Violations by a rogue state could be checked via collateral attack: when a plaintiff sought recovery against a defendant's assets in another state, that state could refuse judgment on the grounds that the original judgment was invalid.
Difficulties in applying "Pennoyer" territorial jurisdiction.
Following "Pennoyer", extreme applications of territorial jurisdiction revealed imperfections in the doctrine, and societal changes began to present new problems as the United States' national economy became more integrated by increasingly efficient multi-state transportation technology and business practices.
While determining the physical location of an individual for the purposes of "in personam" jurisdiction was easy enough, applying the same principle to non-physical entities became difficult. Courts were presented with the question of where a company was present and amenable to service for the purpose of "in personam" jurisdiction over the company.
Extension of "quasi in rem" jurisdiction led to extreme results that threatened the justification for the jurisdiction. Bearing in mind that territorial jurisdiction existed in a pre-industrial society where transportation across the country was difficult, long, and potentially treacherous, and consider the hypothetical wherein A owes B money, and B owes C, a resident of New York, money. C seeks to recover on B's debt to C, however cannot do so because B avoids C by travelling to California. A, however, happens to travel through New York. C serves notice upon A, and attaches A's debt to B (considered to be property within the state) to the proceeding. A can no more certainly provide notice to B in California than C could provide, and the transient and involuntary exposure of B to being hauled into court in New York by this attachment seems to erode the original rationale of "quasi in rem" jurisdiction.
The US Supreme Court largely abolished the exercise of jurisdiction on the basis of "quasi in rem" in "Shaffer v. Heitner", except in exceptional circumstances, which sometimes would arise while dealing with real property such as land, and when the owner of the land cannot be found.
Modern Constitutional doctrine: "International Shoe" doctrine.
In the modern era, the reach of personal jurisdiction has been expanded by judicial re-interpretation and legislative enactments. Under the new and current doctrine, a state court may only exert personal jurisdiction over an individual or entity with "sufficient minimal contacts" with the forum state such that the particular suit "does not offend 'traditional notions of fair play and justice.'" The "minimum contacts" must be purposefully directed towards the state by the defendant. This jurisdiction was initially limited to the particulars of the "International Shoe Co. v. Washington" holding, that is to jurisdictional inquiries regarding companies, but was soon extended to apply to all questions of personal jurisdiction. When an individual, or entity, has no "minimum contacts" with a forum State, the Due Process Clause of the Fourteenth Amendment prohibits that State from acting against that individual, or entity. The lack of "minimum contacts" with the owner of property also constitutionally prohibits action against that property (in rem jurisdiction) even when the property is located within the forum state.
What constitutes sufficient "minimum contacts" has been delineated in numerous cases which followed the International Shoe decision. For example, in "Hanson v. Denckla", the Court proclaimed the "unilateral activity of those who claim some relationship with a nonresident cannot satisfy the requirement of contact with the forum State. The application of that rule will vary with the nature and quality of the defendant's activity, but it is essential in each case that there be some act by which the defendant purposefully avails itself of the privilege of conducting activities within the forum State, thus invoking the benefits and protection of its laws."
The additional requirement of "'purposeful availment' ensures that a defendant will not be hauled into a jurisdiction solely as a result of 'random,' 'fortuitous,' or 'attenuated' contacts, or of the unilateral activity of another party or a third person". Jurisdiction may, however, be exercised, under some circumstances, even though the defendant never physically entered the forum State.
In addition, the claim must arise from the those contacts to which the defendant had with the forum state. In addition to the minimum contacts test asserted in International Shoe, the assertion of specific personal jurisdiction must be reasonable. The court in "World-Wide Volkswagen Corp. v. Woodson" asserted a five part test for determining if the assertion of personal jurisdiction in a forum state was reasonable. This test considers: the burden on the defendant from litigating the forum state; the interest of the forum state to have the case adjudicated there; the interests of the plaintiff in adjudicating in the forum state; the interests of the inter-state judiciary—that is, that a court's assertion of personal jurisdiction over an out-of state defendant would not overreach and preempt the interests and judicial sovereignty of another state and; the interests in preserving the judicial integrity of the several states—that is, ensuring one court's assertion of personal jurisdiction over an out of state defendant does not violate the Due Process Clause of the Fourteenth Amendment.
In another recent case of "Goodyear Dunlop Tires Operations, S. A. v. Brown", Justice Ginsburg held that for the exercise of general jurisdiction in personam, the defendant must be "essentially at home". This applies when the defendant has contacts with the forum state, but the claim that arises is not related to those contacts. For example, if Harrods (a British store) sets up an office in California to export and sell goods there, and because of that someone gets injured, it would be amenable to suit in California for that injury. On the other hand, if someone is injured in Harrods in London and for some reason finds that California law is more favorable and decides to sue in California, the suit would not be maintainable since the contacts that Harrods have is not continuous and systematic, and they are not 'essentially at home' in California.
This holding was reaffirmed in 2014 by the Supreme Court in "Daimler AG v. Bauman".
Statutory authorization.
While the "Pennoyer" and later "Shoe" doctrines limit the maximum power of a sovereign state, courts must also have authorization to exercise the state's power; an individual state may choose to not grant its courts the full power that the state is Constitutionally permitted to exercise. Similarly, the jurisdiction of Federal courts (other than the Supreme Court) are statutorily-defined. Thus, a particular exercise of personal jurisdiction must not only be permitted by Constitutional doctrine, but be statutorily authorized as well. Under "Pennoyer", personal jurisdiction was authorized by statutes authorizing service of process, but these methods of service often lacked because they required such service to be effected by officers of the state, such as sheriffs – an untenable method for defendants located outside of the state but still subject to jurisdiction due to their contacts with the state. Subsequent to the development of the "Shoe" Doctrine, states have enacted so-called long-arm statutes, by which courts in a state can serve process and thus exercise jurisdiction over a party located outside the state. The doctrine of International shoe applies only in cases where there is no presence in the forum state. For example, if A committed a tort in State X. He is sued by B and B serves him with process just before he leaves State X before the flight was took off, the service would be valid and State X would have jurisdiction over A. If A did not comply with the final judgement passed by the courts of State X, B could enforce that judgement in the state where A resides under the full faith and credit clause of the US Constitution. There was one case where a defendant was served while the airplane was in the air over the forum State, and the federal district court held that this was valid service, since at law the territory of a state includes the airspace above the State. 
Relationship to venue.
Venue and personal jurisdiction are closely related for practical purposes. A lawyer should usually perform joint analysis of personal jurisdiction and venue issues. Personal jurisdiction is largely a constitutional requirement, though also shaped by state long-arm statutes and Rule 4 of the Federal Rules of Civil Procedure, while venue is purely statutory.
It is possible for either venue or personal jurisdiction to preclude a court from hearing a case. Consider these examples:
External links.
[ Official Website of the Supreme Court of the United States]

</doc>
<doc id="24877" url="https://en.wikipedia.org/wiki?curid=24877" title="Pell's equation">
Pell's equation

Pell's equation (also called the Pell–Fermat equation) is any Diophantine equation of the form
where "n" is a given positive nonsquare integer and integer solutions are sought for "x" and "y". In Cartesian coordinates, the equation has the form of a hyperbola; solutions occur wherever the curve passes through a point whose "x" and "y" coordinates are both integers, such as the trivial solution with "x" = 1 and "y" = 0. Joseph Louis Lagrange proved that, as long as "n" is not a perfect square, Pell's equation has infinitely many distinct integer solutions. These solutions may be used to accurately approximate the square root of "n" by rational numbers of the form "x/y".
This equation was first studied extensively in India, starting with Brahmagupta, who developed the "chakravala" method to solve Pell's equation and other quadratic indeterminate equations in his "Brahma Sphuta Siddhanta" in 628, about a thousand years before Pell's time. His "Brahma Sphuta Siddhanta" was translated into Arabic in 773 and was subsequently translated into Latin in 1126. Bhaskara II in the 12th century and Narayana Pandit in the 14th century both found general solutions to Pell's equation and other quadratic indeterminate equations. Solutions to specific examples of the Pell equation, such as the Pell numbers arising from the equation with "n" = 2, had been known for much longer, since the time of Pythagoras in Greece and to a similar date in India. The name of Pell's equation arose from Leonhard Euler's mistakenly attributing Lord Brouncker's solution of the equation to John Pell.
For a more detailed discussion of much of the material here, see Lenstra (2002) and Barbeau (2003).
History.
As early as 400 BC in India and Greece, mathematicians studied the numbers arising from the "n" = 2 case of Pell's equation,
and from the closely related equation
because of the connection of these equations to the square root of two. Indeed, if "x" and "y" are positive integers satisfying this equation, then "x"/"y" is an approximation of √2. The numbers "x" and "y" appearing in these approximations, called side and diameter numbers, were known to the Pythagoreans, and Proclus observed that in the opposite direction these numbers obeyed one of these two equations. Similarly, Baudhayana discovered that "x" = 17, "y" = 12 and "x" = 577, "y" = 408 are two solutions to the Pell equation, and that 17/12 and 577/408 are very close approximations to the square root of two.
Later, Archimedes approximated the square root of 3 by the rational number 1351/780. Although he did not explain his methods, this approximation may be obtained in the same way, as a solution to Pell's equation.
Archimedes' cattle problem involves solving a Pellian equation, though it is unclear whether this problem is really due to Archimedes.
Around AD 250, Diophantus considered the equation
where "a" and "c" are fixed numbers and "x" and "y" are the variables to be solved for.
This equation is different in form from Pell's equation but equivalent to it.
Diophantus solved the equation for ("a","c") equal to (1,1), (1,−1), (1,12), and (3,9). Al-Karaji, a 10th-century Persian mathematician, worked on similar problems to Diophantus.
In Indian mathematics, Brahmagupta discovered that
(see Brahmagupta's identity). Using this, he was able to "compose" triples formula_6 and formula_7 that were solutions of formula_8, to generate the new triple
Not only did this give a way to generate infinitely many solutions to formula_11 starting with one solution, but also, by dividing such a composition by formula_12, integer or "nearly integer" solutions could often be obtained. For instance, for formula_13, Brahmagupta composed the triple formula_14 (since formula_15) with itself to get the new triple formula_16. Dividing throughout by 64 ('8' for formula_17 and formula_18, being squared) gave the triple formula_19, which when composed with itself gave the desired integer solution formula_20. Brahmagupta solved many Pell equations with this method; in particular he showed how to obtain solutions starting from an integer solution of formula_8 for formula_22 = ±1, ±2, or ±4.
The first general method for solving the Pell equation (for all "N") was given by Bhaskara II in 1150, extending the methods of Brahmagupta. Called the chakravala (cyclic) method, it starts by composing any triple formula_23 (that is, one which satisfies formula_24) with the trivial triple formula_25 to get the triple formula_26, which can be scaled down to
When formula_28 is chosen so that formula_29 is an integer, so are the other two numbers in the triple. Among such formula_28, the method chooses one that minimizes formula_31, and repeats the process. This method always terminates with a solution (proved by Lagrange in 1768). Bhaskara used it to give the solution formula_17 =1766319049, formula_18 =226153980 to the notorious formula_34 = 61 case.
Several European mathematicians rediscovered how to solve Pell's equation in the 17th century, apparently unaware that it had been solved almost a thousand years earlier in India. Fermat found how to solve the equation and in a 1657 letter issued it as a challenge to English mathematicians. In a letter to Digby, Bernard Frénicle de Bessy said that Fermat found the smallest solution for formula_34 up to 150, and challenged John Wallis to solve the cases formula_34 = 151 or 313. Both Wallis and Lord Brouncker gave solutions to these problems, though Wallis suggests in a letter that the solution was due to Brouncker.
Pell's connection with the equation is that he revised Thomas Branker's translation of Johann Rahn's 1659 book "Teutsche Algebra" into English, with a discussion of Brouncker's solution of the equation. Euler mistakenly thought that this solution was due to Pell, as a result of which he named the equation after Pell.
The general theory of Pell's equation, based on continued fractions and algebraic manipulations with numbers of the form formula_37 was developed by Lagrange in 1766–1769.
Solutions.
Fundamental solution via continued fractions.
Let formula_38 denote the sequence of convergents to the regular continued fraction for formula_39. This sequence is unique. Then the pair ("x"1,"y"1) solving Pell's equation and minimizing "x" satisfies "x"1 = "hi" and "y"1 = "ki" for some "i". This pair is called the "fundamental solution". Thus, the fundamental solution may be found by performing the continued fraction expansion and testing each successive convergent until a solution to Pell's equation is found.
As describes, the time for finding the fundamental solution using the continued fraction method, with the aid of the Schönhage–Strassen algorithm for fast integer multiplication, is within a logarithmic factor of the solution size, the number of digits in the pair ("x"1,"y"1). However, this is not a polynomial time algorithm because the number of digits in the solution may be as large as √"n", far larger than a polynomial in the number of digits in the input value "n" .
Additional solutions from the fundamental solution.
Once the fundamental solution is found, all remaining solutions may be calculated algebraically from
expanding the right side, equating coefficients of formula_39 on both sides, and equating the other terms on both sides. This yields the recurrence relations
Concise representation and faster algorithms.
Although writing out the fundamental solution ("x"1,"y"1) as a pair of binary numbers may require a large number of bits, it may in many cases be represented more compactly in the form
using much smaller coefficients "a""i", "b""i", and "c""i".
For instance, Archimedes' cattle problem may be solved using a Pell equation, the fundamental solution of which has 206545 digits if written out explicitly, the value is 776027140648...719455081800. However, instead of writing the solution as a pair of numbers, it may be written using the formula
where
and formula_47 and formula_48 only have 45 and 41 decimal digits, respectively. Alternatively, one may write even more concisely
In fact, it is equivalent to solving the Pell equation formula_50. (formula_51)
Methods related to the quadratic sieve approach for integer factorization may be used to collect relations between prime numbers in the number field generated by √"n", and to combine these relations to find a product representation of this type. The resulting algorithm for solving Pell's equation is more efficient than the continued fraction method, though it still does not take polynomial time. Under the assumption of the generalized Riemann hypothesis, it can be shown to take time
where "N" = log "n" is the input size, similarly to the quadratic sieve .
Example.
As an example, consider the instance of Pell's equation for "n" = 7; that is,
The sequence of convergents for the square root of seven are
Therefore, the fundamental solution is formed by the pair (8, 3). Applying the recurrence formula to this solution generates the infinite sequence of solutions
The smallest solution can be very large. For example, the smallest solution to formula_54 is (32188120829134849, 1819380158564160), and this is the equation which Frenicle challenged Wallis to solve. Values of "n" such that the smallest solution of formula_55 is greater than the smallest solution for any smaller value of "n" are
(For these records, see ("x"), and ("y")).
The smallest solution of Pell equations.
The following is a list of the smallest solution to formula_56 with "n" ≤ 128. For square "n", there are no solutions except (1, 0). (sequence ("x") and ("y") in OEIS, or ("x") and ("y") (for nonsquare "n"))
Connections.
Pell's equation has connections to several other important subjects in mathematics.
Algebraic number theory.
Pell's equation is closely related to the theory of algebraic numbers, as the formula
is the norm for the ring formula_58 and for the closely related quadratic field formula_59. Thus, a pair of integers formula_60 solves Pell's equation if and only if formula_61 is a unit with norm 1 in formula_58. Dirichlet's unit theorem, that all units of formula_58 can be expressed as powers of a single fundamental unit (and multiplication by a sign), is an algebraic restatement of the fact that all solutions to the Pell equation can be generated from the fundamental solution. The fundamental unit can in general be found by solving a Pell-like equation but it does not always correspond directly to the fundamental solution of Pell's equation itself, because the fundamental unit may have norm −1 rather than 1 and its coefficients may be half integers rather than integers.
Chebyshev polynomials.
Demeyer (2007) mentions a connection between Pell's equation and the Chebyshev polynomials:
If "Ti" ("x") and "Ui" ("x") are the Chebyshev polynomials of the first and second kind, respectively, then these polynomials satisfy a form of Pell's equation in any polynomial ring "R"["x"], with "n" = "x"2 − 1:
Thus, these polynomials can be generated by the standard technique for Pell equations of taking powers of a fundamental solution:
It may further be observed that, if ("xi","yi") are the solutions to any integer Pell equation, then "xi" = "Ti" ("x"1) and "yi" = "y"1"U""i" − 1("x"1) (Barbeau, chapter 3).
Continued fractions.
A general development of solutions of Pell's equation formula_55 in terms of continued fractions of formula_39 can be presented, as the solutions "x" and "y" are approximates to the square root of "n" and thus are a special case of continued fraction approximations for quadratic irrationals.
The relationship to the continued fractions implies that the solutions to Pell's equation form a semigroup subset of the modular group. Thus, for example, if "p" and "q" satisfy Pell's equation, then
is a matrix of unit determinant. Products of such matrices take exactly the same form, and thus all such products yield solutions to Pell's equation. This can be understood in part to arise from the fact that successive convergents of a continued fraction share the same property: If "p""k"−1/"q""k"−1 and "p""k"/"q""k" are two successive convergents of a continued fraction, then the matrix
has determinant (−1)"k".
Størmer's theorem applies Pell equations to find pairs of consecutive smooth numbers. As part of this theory, Størmer also investigated divisibility relations among solutions to Pell's equation; in particular, he showed that each solution other than the fundamental solution has a prime factor that does not divide "n".
As Lenstra (2002) describes, Pell's equation can also be used to solve Archimedes' cattle problem.
The negative Pell equation.
The negative Pell equation is given by
It has also been extensively studied; it can be solved by the same method of using continued fractions and will have solutions when the period of the continued fraction has odd length. However we do not know which roots have odd period lengths so we do not know when the negative Pell equation is solvable. But we can eliminate certain "n" since a necessary but not sufficient condition for solvability is that "n" is not divisible by a prime of form 4"m" + 3. Thus, for example, "x"2 − 3"py"2 = −1 is never solvable, but "x"2 − 5"py"2 = −1 may be, such as when "p" = 13 or 17 (of course, "p" needs to be with the form 4"m" + 1), though not when "p" = 41.
Numbers "n" for which "x"2 − "ny"2 = −1 is solvable are
The solutions of "x" (for values of "n" in this sequence) are listed in .
These "n" values are divisible neither by 4 nor by a prime of the form 4"m" + 3, but these conditions are not sufficient --- the counterexamples are listed in , the first few such "n"s are 34, 146, 178, 194, 205, 221, 305, 377, 386, 410, 466, 482, ... In fact, if and only if the period length of the continued fraction for formula_39 () is odd, then "x"2 − "ny"2 = −1 is solvable.
to get,
Or, since ny2 = x2 + 1 from eq.1, then,
showing that fundamental solutions to the positive case are bigger than those for the negative case.
Transformations.
I. The related equation,
can be used to find solutions to the positive Pell equation for certain "d". Legendre proved that all primes of form "d" = 4"m" + 3 solve one case of eq.2, with the form 8"m" + 3 solving the negative, and 8"m" + 7 for the positive. Their fundamental solution then leads to the one for "x"2−"dy"2 = 1. This can be shown by squaring both sides of eq. 2,
to get,
Since formula_78 from eq.2, then,
or simply,
showing that fundamental solutions to eq.2 are smaller than eq.1. For example, u2-3v2 = -2 is {"u","v"} = {1,1}, so "x"2 − 3"y"2 = 1 has {"x","y"} = {2,1}. On the other hand, "u"2 − 7"v"2 = 2 is {"u","v"} = {3,1}, so "x"2 − 7y2 = 1 has {"x","y"} = {8,3}.
II. Another related equation,
can also be used to find solutions to Pell equations for certain "d", this time for the positive and negative case. For the following transformations, if fundamental {"u","v"} are both odd, then it leads to fundamental {x,y}.
1. If u2 − dv2 = −4, and {x,y} = {("u"2 + 3)"u"/2, ("u"2 + 1)"v"/2}, then "x"2 − "dy"2 = −1.
Ex. Let "d" = 13, then {"u","v"} = {3, 1} and {"x","y"} = {18, 5}.
2. If "u"2 − "dv"2 = 4, and {"x","y"} = {("u"2 − 3)"u"/2, ("u"2 − 1)"v"/2}, then "x"2 − "dy"2 = 1.
Ex. Let "d" = 13, then {u,v} = {11, 3} and {x,y} = {649, 180}.
3. If "u"2 − "dv"2 = −4, and {"x","y"} = {("u"4 + 4"u"2 + 1)("u"2 + 2)/2, ("u"2 + 3)("u"2 + 1)"uv"/2}, then "x"2 − "dy"2 = 1.
Ex. Let "d" = 61, then {"u","v"} = {39, 5} and {"x","y"} = {1766319049, 226153980}.
Especially for the last transformation, it can be seen how solutions to {"u","v"} are "much" smaller than {"x","y"}, since the latter are sextic and quintic polynomials in terms of "u".

</doc>
<doc id="24879" url="https://en.wikipedia.org/wiki?curid=24879" title="Telephone card">
Telephone card

A telephone card, calling card or phonecard for short, is a credit card size plastic card, used to pay for telephone services. It is not necessary to have the physical card except with a stored-value system; knowledge of the access telephone number to dial and the PIN is sufficient. Standard cards which can be purchased and used without any sort of account facility give a fixed amount of credit and are discarded when used up; rechargeable cards can be topped up, or collect payment in arrears. The system for payment and the way in which the card is used to place a telephone call vary from card to card.
Calling cards usually come equipped with PIN for user protection and security. Most companies require user to enter the PIN before granting access to the calling card’s funds. PINs often are printed on a piece of paper found inside the calling card’s packaging. Once the users makes their first call, some companies offer the option of eliminating the PIN altogether to speed up the calling process. Companies that sell virtual calling cards online typically PIN via email.
Stored-value phone cards.
A stored-value phonecard contains the balance available on the card. This balance can be read by a public payphone machine when the card is inserted into the payphone's card reader. This is superficially similar to a bank automated teller machine, but a stored-value card is more closely analogous to a change purse. While ATMs (as well as the remote memory systems discussed below) use the card merely to identify the associated account and record changes in a central database, stored-value systems make a physical alteration to the card to reflect the new balance after a call. Used primarily for payphones, stored-value systems avoid the time lag and expense of communication with a central database, which would have been prohibitive before the 1990s. There are several ways in which the value can be encoded on the card.
The earliest system used a magnetic stripe as information carrier, similar to the technology of ATMs and key cards. The first magnetic strip phonecard, manufactured by SIDA, was issued in 1976 in Italy.
The next technology used optical storage. Optical phonecards get their name from optical structure embossed inside the cards. This optical structure is heated and destroyed after use of the units. Visible marks are left on the top of the cards, so that the user can see the balance of remaining units. Optical cards were produced by Landis+Gyr and Sodeco from Switzerland and were popular early phonecards in many countries with first optical phonecards successfully introduced in 1977 in Belgium. Such technology was very secure and not easily hackable but chip cards phased out the optical phone cards around the world and the last Landis+Gyr factory closed in May 2006 when optical phonecards were still in use in few countries like Austria, Israel and Egypt.
The third system of stored-value phonecards is chip cards, first launched on a large scale in 1986 in Germany by Deutsche Bundespost after three years of testing, and in France by France Télécom. Many other countries followed suit, including Ireland in 1990 and the UK circa 1994-1995, which phased out the old green Landis+Gyr cards in favor of the chip (smart) cards. The initial microchips were easy to hack, typically by scratching off the programming-voltage contact on the card, which rendered the phone unable to reduce the card's value after a call. But by the mid-to-late 1990s, highly secure technology aided the spread of chip phonecards worldwide.
Making a prepaid or calling card call requires the user to make two calls. Regardless of the type of card it is necessary to dial an access telephone number to connect to the calling card system. There are several methods. One is via a toll-free number, with larger companies offering this internationally. Access through a local number has become increasingly popular in recent years. Toll-free calls are paid for by the recipient (the calling card company), which passes on the cost through higher call charges; total cost of a call to the user is often lower using a local number. When travelling through several local areas a toll-free service may be preferable.
Once connected to the access number, the account is identified by keying in a PIN (the most popular method) or by swiping a card with embedded chip or magnetic stripe. After validation the balance remaining on the card may be announced, and the desired number may be keyed in. The available minutes may be announced, and the call is connected. Many cards make a verbal announcement if credit is running out.
Prepaid or calling cards are usually much cheaper than other telephone services, particularly for travelers who do not have easy access to other services. Hotel telephones can be very expensive, particularly for long-distance calls. Cellular services are flexible, but may attract high roaming charges away from the home area.
Remote memory systems.
Telephone accounts symbolized by a card.
The second main technology of phonecards is remote memory, which uses a toll or toll-free access number to reach the database and check for balance on product. As the United States never had a single nationalized telephone service (or even the same firm for every part of a state), and with the deregulation of its major telecommunications providers, there was no incentive to be consistent with the rest of the world. The ease of use of sliding a card into a machine just as in a teller machine was countered by fears of vandalism of the machines.
The first public prepaid remote memory phonecard was issued in the United States in December 1980 by Phone Line. As telecom industries around the world became deregulated, remote memory cards were issued in various countries. Remote memory phonecards can be used from any tone-mode phone and do not require special card readers. Since remote memory cards are more accessible and have lower costs, remote memory phone cards have proliferated. However, the utility of these cards is reduced by the large number of digits that need to be entered during usage. To call a long distance number, the user first dials the local access number, then keys in the secret code, followed by the actual long distance number. Based on the long distance number entered, the time remaining on the card is announced, and the call is finally processed through.
Remote memory phonecards are in essence text; requiring an access number, a unique PIN and instructions. Therefore the instructions can be printed on virtually anything, or can be delivered via e-mail or the Internet. Currently many websites post phone card details through e-mail.
Phone cards are available in most countries in retail stores, retail chains and commonly post offices or corner stores. In general, remote memory phonecards can be issued by any company and come in countless varieties. They can focus on calling to certain countries or regions and have specific features such as rechargeability, pinless dial, speed dial and more. Phone cards may have connection fees, taxes and maintenance fees, all influencing the rates.
Accounts without a card (Virtual phonecards).
Since the early 2000s calling card service providers have introduced calling accounts not associated with a physical card. Calling accounts can be purchased over the Internet using credit cards and are instantly delivered to the customer via e-mail. This e-mail contains the PIN and instructions for using the service. The service may be prepaid, or may take payment from a credit card or by direct debit. Some prepaid card companies allow accounts to be recharged online manually or automatically via a method called auto-top-up.
Some virtual cards offer PINless Dialing, either by dialling a number unique to the customer, or by recognising the telephone number which originated the call by Caller ID and relating it to the appropriate account. Some virtual phone cards allow customers to view their call detail reports (CDRs) online by logging into their account.
The virtual phonecard has become a multi-billion US dollar industry as of 2009, with a number of large corporations and smaller Dot Com companies. While long-distance inland calls have been offered by calling cards, by the mid-2000s conventional carriers reduced their rates to be competitive; however in many countries calling-card type indirect services can be much cheaper than normal calls.
Phonecard as an artifact or collectible.
Telecom companies have placed advertising on phonecards, or featured celebrity portraits, artwork, or attractive photography. As the supply of any one design is limited, this has led some people to collect disposable phonecards.
The hobby is sometimes called "fusilately" in the UK and a collector is known as a "fusilatelist"; In the USA it is called "telegery". Phonecards have been collected worldwide since the mid-1970s and peaked in the mid-1990s, when over 2 million people collected phonecards.
There are many web sites dedicated to this hobby, some of which offer catalogs and show the stories behind the cards. Colnect is a site providing the world's most extensive online phonecards catalog.
Support in telephones.
Most modern telephones, both mobile and fixed, have memory locations in which telephone numbers can be stored. Some telephones have facilities to make calls through a calling card service whose access details and PIN are also stored in the telephone's memory. This may be implemented in different ways, often by pressing one button before making a call; some telephones support "chain dialing", allowing additional numbers to be dialed when on a call (e.g., dial a PIN and a second number after connecting to an access number). So long as long enough sequences can be stored it is possible to store an access number, pause, PIN, and ultimate telephone number in a single normal phone memory location. Software applications which add calling card support are available for a small charge or free for some smartphones.

</doc>
<doc id="24883" url="https://en.wikipedia.org/wiki?curid=24883" title="Philips CD-i">
Philips CD-i

The Philips CD-i ("Compact Disc Interactive") is an interactive multimedia CD player developed and marketed by the Dutch electronics manufacturer Royal Philips Electronics N.V. This category of device was created to provide more functionality than an audio CD player or game console, but at a lower price than a personal computer with a CD-ROM drive at the time. The cost savings were due to the lack of a hard drive, floppy drive, keyboard, mouse, monitor (a standard television is used), and less operating system software.
In addition to games, educational and multimedia reference titles were produced, such as interactive encyclopedias, museum tours, etc., which were popular before public Internet access was widespread. Competitors included the Tandy VIS and Commodore CDTV.
CD-i also refers to the multimedia Compact Disc standard used by the CD-i console, also known as Green Book, which was developed by Philips and Sony (not to be confused with MMCD, the pre-DVD format also co-developed by Philips and Sony). Work on the CD-i began in 1984 and it was first publicly announced in 1986. The first Philips CD-i player, released in 1991 and initially priced around US$700, was capable of playing interactive CD-i discs, Audio CDs, CD+G (CD+Graphics), Karaoke CDs, Photo CDs and Video CDs (VCDs), though the latter required an optional "Digital Video Card" to provide MPEG-1 decoding.
Seen as a game console, the CD-i format proved to be a commercial failure. The device was sold until 1998, aside claims that Philips had planned a discontinuation in 1996. The company lost nearly one billion dollars on the entire project. The failure of the CD-i caused Philips to leave the video game industry after it was discontinued.
The CD-i is also one of the earliest consoles to implement internet features, including subscriptions, web browsing, downloading, e-mail, and online play. This was facilitated by the use of an additional hardware modem that Philips released in 1996 for $150.
While video game consoles have been made by Japanese companies (and to lesser extent American companies), the CD-i is one of the very few created by a European company.
Applications.
Early software releases in the CD-i format focused heavily on educational, music, and self-improvement titles, with only a handful of video games, many of them adaptations of board games such as "Connect Four". Later attempts to develop a foothold in the games market were rendered irrelevant by the arrival of cheaper and more powerful consoles, such as the Nintendo 64 and PlayStation. Earlier CD-i games included entries in popular Nintendo franchises, although those games were not developed by Nintendo. Specifically, a "Mario" game (titled "Hotel Mario"), and three "Legend of Zelda" games were released: ', ' and "Zelda's Adventure". Nintendo and Philips had established an agreement to co-develop a CD-ROM enhancement for the Super Nintendo Entertainment System due to licensing disagreements with Nintendo's previous partner Sony (an agreement that produced a prototype console called the Play Station). While Philips and Nintendo never released such a CD-ROM add-on, Philips was still contractually allowed to continue using Nintendo characters.
Applications were developed using authoring software produced by OptImage. This included OptImage's Balboa Runtime Libraries and MediaMogul. The second company that produced authoring software was Script Systems; they produced ABCD-I.
Philips also released several versions of popular TV game shows for the CD-i, including versions of "Jeopardy!" (hosted by Alex Trebek), "Name That Tune" (hosted by Bob Goen), and two versions of "The Joker's Wild" (one for adults hosted by Wink Martindale and one for kids hosted by Marc Summers). All CD-i games in North America (with the exception of "Name That Tune") had Charlie O'Donnell as announcer. The Netherlands also released its version of "Lingo" on the CD-i in 1994.
In 1993, American musician Todd Rundgren created the first music-only fully interactive CD, "No World Order", for the CD-i. This application allows the user to completely arrange the whole album in their own personal way with over 15,000 points of customization.
CD-i has a series of learning games ("edutainment") targeted at children from infancy to adolescence. Those intended for a younger audience included "Busytown", "The Berenstain Bears" and various others which usually had vivid cartoon-like settings accompanied by music and logic puzzles.
Although extensively marketed by Philips, notably via infomercial, consumer interest in CD-i titles remained low. By 1994, sales of CD-i systems had begun to slow, and in 1998 the product line was dropped.
A large number of full motion video titles such as "Dragon's Lair" and "Mad Dog McCree" appeared on the system. One of these, "", is considered one of the stronger CD-i titles and was later ported to PC. The February 1994 issue of "Electronic Gaming Monthly" remarked that the CD-i's full motion video capabilities were its strongest point, and that nearly all of its best software required the MPEG upgrade card.
With the home market exhausted, Philips tried with some success to position the technology as a solution for kiosk applications and industrial multimedia.
Player models.
Philips models.
In addition to consumer models, professional and development players were sold by Philips Interactive Media Systems and their VARs. Philips marketed several CD-i player models.
There also exist a number of hard-to-categorize models, such as the FW380i, an integrated mini-stereo and CD-i player; the 21TCDi30, a television with a built-in CD-i device; and the CD-i 180/181/182 modular system, the first CD-i system produced.
Other manufacturers.
In addition to Philips, several manufacturers produced CD-i players, including Magnavox, GoldStar / LG Electronics, Digital Video Systems, Memorex, Grundig, Saab Electric, Sony (Intelligent Discman, a portable CD-i player), Kyocera, NBS, Highscreen, and Bang & Olufsen, who produced a television with a built-in CD-i device (Beocenter AV5).
TeleCD-i and CD-MATICS.
Recognizing the growing need among marketers for networked multimedia, Philips partnered in 1992 with Amsterdam-based CDMATICS to develop TeleCD-i (also TeleCD). In this concept, the CD-i player is connected to a network such as PSTN or Internet, enabling data-communication and rich media presentation. Dutch grocery chain Albert Heijn and mail-order company Neckermann were early adopters and introduced award-winning TeleCD-i applications for their home-shopping and home-delivery services. CDMATICS also developed the special Philips TeleCD-i Assistant and a set of software tools to help the worldwide multimedia industry to develop and implement TeleCD-i. TeleCD-i is the world's first networked multimedia application at the time of its introduction. In 1996, Philips acquired source code rights from CDMATICS.
Market competition.
Panasonic M2 is an interactive kiosk. Multimedia/video game systems include Commodore CDTV, Pioneer LaserActive, 3DO Interactive Multiplayer, and Tandy Video Information System. Dedicated video game consoles based on CD-ROM media include Sega Mega Drive/Genesis with Sega Mega-CD/Sega CD expansion, 3DO Interactive Multiplayer, and NEC TurboDuo.
Reception.
Although Philips had aggressively promoted CD-i, by 1993 "Computer Gaming World" reported that "skepticism persists about its long-term prospects" compared to other platforms like IBM PC compatibles, Apple Macintosh, and Sega Genesis. An early 1995 review of the system in "GamePro" stated that "inconsistent game quality puts the CD-i at a disadvantage against other high-powered game producers."
After its discontinuation, the CD-i was overwhelmingly panned by critics about its price, graphics, games and controls. The CD-i's various controllers were ranked the fifth worst video game controller by IGN editor Craig Harris. "PC World" ranked it as fourth on their list of "The 10 Worst Video Game Systems of All Time". Gamepro.com listed it as number four on their list of "The 10 Worst-Selling Consoles of All Time." In 2008, CNET listed the system on its list of "The worst game console(s) ever." In 2007, GameTrailers ranked the Philips CD-i as the fourth worst console of all time in its Top 10 Worst Console lineup.
Games that were most heavily criticized include "Hotel Mario", ', ', and "Zelda's Adventure". EGM's Seanbaby rated "The Wand of Gamelon" as one of the worst games of all time. However, "" was positively received by critics, and has often been held up as the standout title for the CD-i.

</doc>
<doc id="24884" url="https://en.wikipedia.org/wiki?curid=24884" title="Peppered moth">
Peppered moth

The peppered moth ("Biston betularia") is a temperate species of night-flying moth. Peppered moth evolution is an example of population genetics and natural selection.
Description.
The wingspan is 55mm. median (45–62 mm.) It is relatively stout-bodied, with forewings relatively narrow-elongate. The wings are white, "peppered" with black, and with more or less distinct cross lines, also black. The black speckling varies in amount, in some examples it is almost absent, whilst in others it is so dense that the wings appear to be black sprinkled with white. The antennae of males are strongly bipectinate.
Distribution.
"Biston betularia" is found in China (Heilongjiang, Jilin, Inner Mongolia, Beijing, Hebei, Shanxi, Shandong, Henan, Shaanxi, Ningxia, Gansu, Qinghai, Xinjiang, Fujian, Sichuan, Yunnan,
Tibet), Russia, Mongolia, Japan, North Korea, South Korea, Nepal, Kazakhstan, Kirghizstan, Turkmenistan, Georgia, Azerbaijan, Armenia, Europe and North America.
Ecology and life cycle.
In Britain and Ireland, the peppered moth is univoltine ("i.e.", it has one generation per year), whilst in south-eastern North America it is bivoltine (two generations per year). The lepidopteran life cycle consists of four stages: ova (eggs), several larval instars (caterpillars), pupae, which overwinter live in the soil, and imagines (adults). During the day, the moths typically rest on trees, where they are preyed on by birds.
The caterpillar is a twig mimic, varying in colour between green and brown. On a historical note, it was one of the first animals to be identified as being camouflaged with countershading to make it appear flat (shading being the main visual cue that makes things appear solid), in a paper by Edward Bagnall Poulton in 1887.
It goes into the soil late in the season, where it pupates in order to spend the winter. The imagines emerge from the pupae between late May and August, the males slightly before the females (this is common and expected from sexual selection). They emerge late in the day and dry their wings before flying that night.
The males fly every night of their lives in search of females, whereas the females only fly on the first night. Thereafter, the females release pheromones to attract males. Since the pheromone is carried by the wind, males tend to travel up the concentration gradient, i.e., toward the source. During flight, they are subject to predation by bats. The males guard the female from other males until she lays the eggs. The female lays about 2,000 pale-green ovoid eggs about 1 mm in length into crevices in bark with her ovipositor.
Resting behaviour.
A mating pair or a lone individual will spend the day hiding from predators, particularly birds. In the case of the former, the male stays with the female to ensure paternity. The best evidence for resting positions is given by data collected by the peppered moth researcher Michael Majerus, and it is given in the accompanying charts. These data were originally published in Howlett and Majerus (1987), and an updated version published in Majerus (1998), who concluded that the moths rest in the upper part of the trees. Majerus notes:
Creationist critics of the peppered moth have often pointed to a statement made by Clarke "et al". (1985): "... In 25 years we have only found two "betularia" on the tree trunks or walls adjacent to our traps, and none elsewhere". The reason now seems obvious. Few people spend their time looking for moths up in the trees. That is where peppered moths rest by day.
From their original data, Howlett and Majerus (1987) concluded that peppered moths generally rest in unexposed positions, using three main types of site. Firstly, a few inches below a branch-trunk joint on a tree trunk where the moth is in shadow; secondly, on the underside of branches and thirdly on foliate twigs. The above data would appear to support this.
Further support for these resting positions is given from experiments watching captive moths taking up resting positions in both males (Mikkola, 1979; 1984) and females (Liebert and Brakefield, 1987).
Majerus, "et al.", (2000) have shown that peppered moths are cryptically camouflaged against their backgrounds when they rest in the boughs of trees. It is clear that in human visible wavelengths, "typica" are camouflaged against lichens and "carbonaria" against plain bark. However, birds are capable of seeing ultraviolet light that humans cannot see. Using an ultraviolet-sensitive video camera, Majerus et al. showed that "typica" reflect ultraviolet light in a speckled fashion and are camouflaged against crustose lichens common on branches, both in ultraviolet and human-visible wavelengths. However, "typica" are not as well camouflaged against foliose lichens common on tree trunks; though they are camouflaged in human wavelengths, in ultraviolet wavelengths, foliose lichens do not reflect ultraviolet light.
During an experiment in Cambridge over the seven years 2001–2007 Majerus noted the natural resting positions of peppered moths, and of the 135 moths examined over half were on tree branches, mostly on the lower half of the branch, 37% were on tree trunks, mostly on the north side, and only 12.6% were resting on or under twigs.
Polymorphism.
Introduction on Forms.
There are several melanic and non-melanic morphs of the peppered moth. These are controlled genetically. A particular colour morph can be indicated in a standard way by following the species name in the form "morpha "morph name"". The use of "form" in the method of "Biston betularia" f. "formname" in detailing these variations is also a widespread practice.
These forms are often accidentally elevated to subspecies status when they appear in literature. Not adding the "f." (form) or morpha infers that the taxon is a subspecies instead of a form, as in "Biston betularia carbonaria" instead of "Biston betularia f. carbonaria". Rarely forms have been elevated to species status as in "Biston carbonaria". Either of these two circumstances might lead to the erroneous belief that speciation was involved in the observed evolution of the peppered moth. This is not the case; individuals of each morph interbreed and produce fertile offspring with individuals of all other morphs; hence there is only one peppered moth species.
By contrast, different subspecies of the same species can theoretically interbreed with one another and will produce fully fertile and healthy offspring but in practice do not, as they live in different regions or reproduce in different seasons. Full-fledged species are either unable to produce fertile and healthy offspring, or do not recognize each other's courtship signals, or both.
European breeding experiments have shown that in "Biston betularia betularia", the allele for melanism producing morpha "carbonaria" is controlled by a single locus. The melanic allele is dominant to the non-melanic allele. This situation is, however, somewhat complicated by the presence of three other alleles that produce indistinguishable morphs of morpha "medionigra". These are of intermediate dominance, but this is not complete (Majerus, 1998).
Form Names.
In continental Europe, there are three morphs: the white morph typica (syn. morpha/f. "betularia"), the dark melanistic morph carbonaria (syn. "doubledayaria"), and an intermediate form medionigra.
In Britain, the typical white morph is known as typica, the melanic morph is carbonaria, and the intermediate phenotype is named insularia.
In North America, the melanic black morph is morpha swettaria. In "Biston betularia cognataria", the melanic allele (producing morpha "swettaria") is similarly dominant to the non-melanic allele. There are also some intermediate morphs. In Japan, no melanic morphs have been recorded; they are all morpha "typica".
At present, the precise molecular genetics and biochemistry of the melanism in this species remains unknown. True (2003) has reviewed this and suggests work based on candidate genes from other insects such as the fruit fly "Drosophila melanogaster". In any case, it is rather likely that the underlying mechanism is not overly complex and, as indicated above, does not involve very many genes and alleles: Unlike for example the variation seen in human skin color, Peppered Moth morphs are not clinal and can generally be readily distinguished from another.
Evolution.
The evolution of the peppered moth over the last two hundred years has been studied in detail.
At the start of this period, the vast majority of peppered moths had light coloured wing patterns which effectively camouflaged them against the light-coloured trees and lichens upon which they rested. However, due to widespread pollution during the Industrial Revolution in England, many of the lichens died out, and the trees which peppered moths rested on became blackened by soot, causing most of the light-coloured moths, or "typica", to die off due to predation. At the same time, the dark-coloured, or melanic, moths, "carbonaria", flourished because they could hide on the darkened trees.
Since then, with improved environmental standards, light-coloured peppered moths have again become common, and the dramatic change in the peppered moth's population has remained a subject of much interest and study. This has led to the coining of the term "industrial melanism" to refer to the genetic darkening of species in response to pollutants. As a result of the relatively simple and easy-to-understand circumstances of the adaptation, the peppered moth has become a common example used in explaining or demonstrating natural selection to laypeople and classroom students through simulations.
The first "carbonaria" morph was recorded by Edleston in Manchester in 1848, and over the subsequent years it increased in frequency. Predation experiments, particularly by Bernard Kettlewell, established that the agent of selection was birds who preyed on the "carbonaria" morph.
Jonathan Wells is one of a number of creationists who have criticized the use of peppered moth melanism as an example of evolution in action. In his book "Icons of Evolution", Wells alleges that peppered moth studies, and in particular Kettlewell's experiments, were erroneous. Similarly, in 2002 Judith Hooper repeatedly implied fraud and error in Kettlewell's experiments in her book titled "Of moths and men". Despite some valid criticisms of the early experiments, there has been no evidence of fraud. Subsequent experiments and observations have supported the initial evolutionary explanation of the phenomenon.

</doc>
<doc id="24886" url="https://en.wikipedia.org/wiki?curid=24886" title="Power Macintosh">
Power Macintosh

Power Macintosh, later Power Mac, is a line of Apple Macintosh workstation-class personal computers based on various models of PowerPC microprocessors that were developed, marketed, and supported by Apple Inc. from March 1994 until August 2006. The first models were the Power Macintosh 6100, 7100, and 8100, which offered speeds ranging from 60 to 110 MHz. These machines replaced Apple's Quadra series of personal computers, and were housed in cases very similar to systems sold by Apple up to that point. The Power Mac went on to become the mainstay of Apple's top-end offerings for twelve years, through a succession of case designs, four major generations of PowerPC chips, and a great deal of press coverage, design accolades, and technical controversy. In August 2006, the Power Mac's retirement was announced at Apple's Worldwide Developers Conference by Steve Jobs and Phil Schiller, making way for its Intel-based replacement, the Mac Pro.
Models.
New World ROM.
The following are recent Power Mac lines based on the New World ROM.
Processor and software.
The ROM and Mac OS operating system released with the new Power Mac machines included an Mac 68K emulator to enable programs written for Motorola 68k series CPUs, including nearly all prior Mac software, to run without changes. (A similar scheme is employed to run 68K software on modern x86 Alpha Microsystems machines.) As the Power Mac was originally intended to be a part of the high end of Apple's product line, for a number of years the company continued to offer less expensive 68k-based computers alongside the more expensive Power Mac lineup. However, for many of these so-called 68K transition Macs, Apple offered an upgrade path in the form of a PowerPC Macintosh Processor Upgrade Card and aggressively marketed it to assure a wary consumer of their investment. In April 1996, Apple discontinued the Macintosh LC 580 (released in 1995), the last remaining desktop model of the 68k-based Macintosh line. The PowerBook 190cs, the last 68k-based PowerBook, was discontinued in October 1996. All subsequent Macintosh computers would be based on PowerPC processors until January 2006, when Apple switched to Intel processors. (In 2005, Apple released an Intel-based Power Mac development system to Apple developers at WWDC.)
Naming.
All Power Macs prior to 1997 used PowerPC 60x-series processors, and 4-digit model numbers (e.g. Power Mac 8600). In 1997 the first third-generation ("G3") Power Macintosh was introduced, using the PowerPC 750 processor. From this model onward, Apple no longer used a numbering scheme to identify their Power Mac models, but instead referred to them by their PowerPC processor generation number (i.e. G3, G4, and G5). Later models based on the same generation of PowerPC processor relied on descriptive characteristics to differentiate them, e.g. the color scheme ("Power Macintosh G3 – Blue and White") or a technical feature of a particular model ("Power Mac G4 – Gigabit Ethernet"). This same identification scheme was used in the iMac, PowerBook, and iBook lines of Macintosh computers.
The marketing name was changed from "Power Macintosh" to "Power Mac" with the introduction of the G4 models, meaning all G3 and earlier models are referred to as "Power Macintosh", while all G4 and G5 models are "Power Mac's". Not all Apple documentation follows this rule, but the vast majority does.
Usage.
The Power Mac brand name was used for Apple's high-end tower style computers, targeted primarily at businesses and creative professionals, in differentiation to their more compact "iMac" line (intended for home use) and the "eMac" line (for the education markets). They were usually equipped with Apple's newest technologies, and commanded the highest prices among Apple desktop models. Some Power Mac G4 and G5 models were offered in dual-processor configurations. 
Prior to the "Power Mac" name change, certain "Power Macintosh" models were otherwise identical to their lower-cost re-branded siblings sold as the Macintosh LC and Macintosh Performa, as well as the dedicated Apple Workgroup Server and Macintosh Server G3 & G4 lines. Other past Macintosh lines which used PowerPC processors include the PowerBook 5300 and later models, iMac, iBook and Xserve as well as the Apple Network Server, which was not technically a Macintosh.
Successor.
The Intel-based successor of the Power Mac is the Mac Pro, in line with the renaming of Apple's professional notebooks from PowerBook to MacBook Pro.
The successor to the All-In-One Power Macintosh models (5x00 series), the last of which was the Power Macintosh G3 "All-In-One", was succeeded by the iMac, which kicked off Apple's renaissance in the early 21st century and has persisted through the Intel transition to the present.
Advertising and marketing.
Apple introduced the Power Mac series of high-end personal computers aimed at businesses and creative professionals in 1994 with an advertising campaign consisting of several television commercials and print ads. The television commercials used the slogan ""The Future Is Better Than You Expected"", featuring the first three Power Macintosh computers to showcase special features such as networking and MS-DOS compatibility.
See also.
<br>

</doc>
<doc id="24888" url="https://en.wikipedia.org/wiki?curid=24888" title="Promoter (genetics)">
Promoter (genetics)

[[File:Lac Operon.svg|thumb|250px|Lac Operon|""'1": RNA Polymerase, "2": Repressor, "3": Promoter, "4": Operator, "5": Lactose, "6": lacZ, "7": lacY, "8": lacA.
Bottom: The gene is turned on. Lactose is inhibiting the repressor, allowing the RNA polymerase to bind with the promoter, and express the genes, which synthesize lactase. Eventually, the lactase will digest all of the lactose, until there is none to bind to the repressor. The repressor will then bind to the operator, stopping the manufacture of lactase.]]
In genetics, a promoter is a region of DNA that initiates transcription of a particular gene. Promoters are located near the transcription start sites of genes, on the same strand and upstream on the DNA (towards the 5' region of the sense strand).
Promoters can be about 100–1000 base pairs long.
Overview.
For transcription to take place, the enzyme that synthesizes RNA, known as RNA polymerase, must attach to the DNA near a gene. Promoters contain specific DNA sequences such as response elements that provide a secure initial binding site for RNA polymerase and for proteins called transcription factors that recruit RNA polymerase. These transcription factors have specific activator or repressor sequences of corresponding nucleotides that attach to specific promoters and regulate gene expression.
Promoters represent critical elements that can work in concert with other regulatory regions (enhancers, silencers, boundary elements/insulators) to direct the level of transcription of a given gene.
Identification of relative location.
As promoters are typically immediately adjacent to the gene in question, positions in the promoter are designated relative to the transcriptional start site, where transcription of DNA begins for a particular gene (i.e., positions upstream are negative numbers counting back from -1, for example -100 is a position 100 base pairs upstream).
Relative location in the cell nucleus.
In the cell nucleus, it seems that promoters are distributed preferentially at the edge of the chromosomal territories, likely for the co-expression of genes on different chromosomes. Furthermore, in humans, promoters show certain structural features characteristic for each chromosome.
Promoter elements.
Bacterial promoters.
In bacteria, the promoter contains two short sequence elements approximately -10 and -35 nucleotides "upstream" from the transcription start site.
It should be noted that the above promoter sequences are recognized only by RNA polymerase holoenzyme containing sigma-70. RNA polymerase holoenzymes containing other sigma factors recognize different core promoter sequences.
Eukaryotic promoters.
Eukaryotic promoters are diverse and can be difficult to characterize, however, recent studies show that they are divided in more than 10 classes.
Gene promoters are typically located upstream of the gene and can have regulatory elements several kilobases away from the transcriptional start site (enhancers). In eukaryotes, the transcriptional complex can cause the DNA to bend back on itself, which allows for placement of regulatory sequences far from the actual site of transcription. Eukaryotic RNA-polymerase-II-dependent promoters can contain a TATA element (consensus sequence TATAAA), which is recognized by the general transcription factor TATA-binding protein (TBP); and a B recognition element (BRE), which is recognized by the general transcription factor TFIIB. The TATA element and BRE typically are located close to the transcriptional start site (typically within 30 to 40 base pairs).
Eukaryotic promoter regulatory sequences typically bind proteins called transcription factors that are involved in the formation of the transcriptional complex. An example is the E-box (sequence CACGTG), which binds transcription factors in the basic helix-loop-helix (bHLH) family (e.g. BMAL1-Clock, cMyc). Some promoters that are targeted by multiple transcription factors might achieve a hyperactive state, leading to increased transcriptional activity.
Bidirectional promoters (mammalian).
Bidirectional promoters are short (<1 kbp) intergenic regions of DNA between the 5' ends of the genes in a bidirectional gene pair. A “bidirectional gene pair” refers to two adjacent genes coded on opposite strands, with their 5' ends oriented toward one another. The two genes are often functionally related, and modification of their shared promoter region allows them to be co-regulated and thus co-expressed. Bidirectional promoters are a common feature of mammalian genomes. About 11% of human genes are bidirectionally paired.
Bidirectionally paired genes in the Gene Ontology database shared at least one database-assigned functional category with their partners 47% of the time. Microarray analysis has shown bidirectionally paired genes to be co-expressed to a higher degree than random genes or neighboring unidirectional genes. Although co-expression does not necessarily indicate co-regulation, methylation of bidirectional promoter regions has been shown to downregulate both genes, and demethylation to upregulate both genes. There are exceptions to this, however. In some cases (about 11%), only one gene of a bidirectional pair is expressed. In these cases, the promoter is implicated in suppression of the non-expressed gene. The mechanism behind this could be competition for the same polymerases, or chromatin modification. Divergent transcription could shift nucleosomes to upregulate transcription of one gene, or remove bound transcription factors to downregulate transcription of one gene.
Some functional classes of genes are more likely to be bidirectionally paired than others. Genes implicated in DNA repair are five times more likely to be regulated by bidirectional promoters than by unidirectional promoters. Chaperone proteins are three times more likely, and mitochondrial genes are more than twice as likely. Many basic housekeeping and cellular metabolic genes are regulated by bidirectional promoters.
The overrepresentation of bidirectionally paired DNA repair genes associates these promoters with cancer. Forty-five percent of human somatic oncogenes seem to be regulated by bidirectional promoters - significantly more than non-cancer causing genes. Hypermethylation of the promoters between gene pairs WNT9A/CD558500, CTDSPL/BC040563, and KCNK15/BF195580 has been associated with tumors.
Certain sequence characteristics have been observed in bidirectional promoters, including a lack of TATA boxes, an abundance of CpG islands, and a symmetry around the midpoint of dominant Cs and As on one side and Gs and Ts on the other. CCAAT boxes are common, as they are in many promoters that lack TATA boxes. In addition, the motifs NRF-1, GABPA, YY1,and ACTACAnnTCCC are represented in bidirectional promoters at significantly higher rates than in unidirectional promoters. The absence of TATA boxes in bidirectional promotors suggests that TATA boxes play a role in determining the directionality of promoters, but counterexamples of bidirectional promoters do possess TATA boxes and unidirectional promoters without them indicates that they cannot be the only factor.
Although the term "bidirectional promoter" refers specifically to promoter regions of mRNA-encoding genes, luciferase assays have shown that over half of human genes do not have a strong directional bias. Research suggests that non-coding RNAs are frequently associated with the promoter regions of mRNA-encoding genes. It has been hypothesized that the recruitment and initiation of RNA Polymerase II usually begins bidirectionally, but divergent transcription is halted at a checkpoint later during elongation. Possible mechanisms behind this regulation include sequences in the promoter region, chromatin modification, and the spatial orientation of the DNA.
Subgenomic promoters.
A subgenomic promoter is a promoter added to a virus for a specific heterologous gene, resulting in the formation of mRNA for that gene alone.
Detection of promoters.
A wide variety of algorithms have been developed to facilitate detection of promoters in genomic sequence, and promoter prediction is a common element of many gene prediction methods. A promoter region is located before the -35 and -10 Consensus sequences. The closer the promoter region is to the consensus sequences the more often transcription of that gene will take place. There is not a set pattern for promoter regions as there are for consensus sequences.
Evolutionary change.
Gene promoters have been responsible for the integration of different mutations favorable for the environmental conditions. Recent studies based on DNA patterns show that gene promoters are directly subjected to an immediate selection pressure. A superposition of eukaryotic gene promoters from four different species shows that promoters of genes reflect the selection pressure of a species and less the phylogenetic relations between distant species.
A major question in evolutionary biology is how important tinkering with promoter sequences is to evolutionary change, for example, the changes that have occurred in the human lineage after separating from other primates.
Some evolutionary biologists, for example Allan Wilson, have proposed that evolution in promoter or regulatory regions may be more important than changes in coding sequences over such time frames.
A key reason for the importance of promoters is the potential to incorporate endocrine and environmental signals into changes in gene expression:
A great variety of changes in the extracellular or intracellular environment may have impacts on gene expression, depending on the exact configuration of a given promoter; the combination and arrangement of specific DNA sequences that constitute the promoter defines the exact groups of proteins that can be bound to the promoter, at a given timepoint. Once the cell receives a physiological, pathological, or pharmacological stimulus, a number of cellular proteins are modified biochemically by signal cascades. By changes in structure, specific proteins acquire the capability to enter the nucleus of the cell and bind to promoter DNA, or to other proteins that themselves are already bound to a given promoter. The multi-protein complexes that are formed have the potential to change levels of gene expression. As a result, the gene product may increase or decrease inside the cell.
Gene promoters and diabetes.
Other recent studies suggest that promoters of genes may be the primary cause of diabetes. Promoters of genes associated with diabetes by Genome-wide association studies (GWAS) show specific DNA patterns for each phenotype. This observation indicates that the promoters of these genes use specific transcription factors for each diabetes phenotype.
Binding.
The promoter binding process is crucial in the understanding of the process of gene expression.
Promoter Location.
Although RNA polymerase holoenzyme shows high affinity to non-specific sites of the DNA, this characteristic does not allow us to clarify the process of promoter location. This process of promoter location has been attributed to the structure of the holoenzyme to DNA and sigma 4 to DNA complexes.
Diseases associated with aberrant promoter function.
Although OMIM is a major resource for gathering information on the relationship between mutations and natural variation in gene sequence and susceptibility to hundreds of diseases, a sophisticated search strategy is required to extract diseases associated with defects in transcriptional control where the promoter is believed to have direct involvement.
This is a list of diseases where evidence suggests some promoter malfunction, through either direct mutation of a promoter sequence or mutation in a transcription factor or transcriptional co-activator.
Most diseases are heterogeneous in etiology, meaning that one "disease" is often many different diseases at the molecular level, though symptoms exhibited and response to treatment may be identical. How diseases of different molecular origin respond to treatments is partially addressed in the discipline of pharmacogenomics.
Not listed here are the many kinds of cancers involving aberrant transcriptional regulation owing to creation of chimeric genes through pathological chromosomal translocation. Importantly, intervention in the number or structure of promoter-bound proteins is one key to treating a disease without affecting expression of unrelated genes sharing elements with the target gene. Genes where change is not desirable are capable of influencing the potential of a cell to become cancerous and form a tumor.
Canonical sequences and wild-type.
The usage of the term canonical sequence to refer to a promoter is often problematic, and can lead to misunderstandings about promoter sequences. Canonical implies perfect, in some sense.
In the case of a transcription factor binding site, there may be a single sequence that binds the protein most strongly under specified cellular conditions. This might be called canonical.
However, natural selection may favor less energetic binding as a way of regulating transcriptional output. In this case, we may call the most common sequence in a population the wild-type sequence. It may not even be the most advantageous sequence to have under prevailing conditions.
Recent evidence also indicates that several genes (including the proto-oncogene c-myc) have G-quadruplex motifs as potential regulatory signals.
Diseases that may be associated with promoter variations.
Some cases of many genetic diseases are associated with variations in promoters or transcription factors.
Examples include:
Constitutive vs regulated promoters.
Some promoters are called constitutive as they are active in all circumstances in the cell, while others are regulated, becoming active in the cell only in response to specific stimuli.
Use of the word promoter.
When referring to a promoter some authors actually mean promoter + operator; i.e., the lac promoter is IPTG inducible, meaning that besides the lac promoter, the lac operator is also present. If the lac operator were not present the IPTG would not have an inducible effect.
Another example is the Tac-Promoter system (Ptac). Notice how tac is written as a tac promoter, while in fact tac is actually both a promoter and an operator.

</doc>
<doc id="24893" url="https://en.wikipedia.org/wiki?curid=24893" title="Adobe Photoshop">
Adobe Photoshop

Adobe Photoshop is a raster graphics editor developed and published by Adobe Systems for Windows and OS X.
Photoshop was created in 1988 by Thomas and John Knoll. Since then, it has become the "de facto" industry standard in raster graphics editing, such that the word "photoshop" has become a verb as in "to Photoshop an image," "photo shopping" and "photoshop contest", though Adobe discourages such use. It can edit and compose raster images in multiple layers and supports masks, alpha compositing and several color models including RGB, CMYK, Lab color space, spot color and duotone. Photoshop has vast support for graphic file formats but also uses its own codice_1 and codice_2 file formats which support all the aforementioned features. In addition to raster graphics, it has limited abilities to edit or render text, vector graphics (especially through clipping path), 3D graphics and video. Photoshop's featureset can be expanded by Photoshop plug-ins, programs developed and distributed independently of Photoshop that can run inside it and offer new or enhanced features.
Photoshop's naming scheme was initially based on version numbers. However, in October 2002, following the introduction of Creative Suite branding, each new version of Photoshop was designated with "CS" plus a number; e.g., the eighth major version of Photoshop was Photoshop CS and the ninth major version was Photoshop CS2. Photoshop CS3 through CS6 were also distributed in two different editions: Standard and Extended. In June 2013, with the introduction of Creative Cloud branding, Photoshop's licensing scheme was changed to that of software as a service and the "CS" suffixes were replaced with "CC". Historically, Photoshop was bundled with additional software such as Adobe ImageReady, Adobe Fireworks, Adobe Bridge, Adobe Device Central and Adobe Camera RAW.
Alongside Photoshop, Adobe also develops and publishes Photoshop Elements, Photoshop Lightroom, Photoshop Express and Photoshop Touch. Collectively, they are branded as "The Adobe Photoshop Family". It is currently a licensed software.
Early history.
Photoshop was developed in 1987 by the American brothers Thomas and John Knoll, who sold the distribution license to Adobe Systems Incorporated in 1988. Thomas Knoll, a PhD student at the University of Michigan, began writing a program on his Macintosh Plus to display grayscale images on a monochrome display. This program, called Display, caught the attention of his brother John Knoll, an Industrial Light & Magic employee, who recommended that Thomas turn it into a full-fledged image editing program. Thomas took a six-month break from his studies in 1988 to collaborate with his brother on the program. Thomas renamed the program ImagePro, but the name was already taken. Later that year, Thomas renamed his program Photoshop and worked out a short-term deal with scanner manufacturer Barneyscan to distribute copies of the program with a slide scanner; a "total of about 200 copies of Photoshop were shipped" this way.
During this time, John traveled to Silicon Valley and gave a demonstration of the program to engineers at Apple and Russell Brown, art director at Adobe. Both showings were successful, and Adobe decided to purchase the license to distribute in September 1988. While John worked on plug-ins in California, Thomas remained in Ann Arbor writing code. "Photoshop" 1.0 was released on 19 February 1990 for Macintosh exclusively. The Barneyscan version included advanced color editing features that were stripped from the first Adobe shipped version. The handling of color slowly improved with each release from Adobe and Photoshop quickly became the industry standard in digital color editing. At the time Photoshop 1.0 was released, digital retouching on dedicated high end systems, such as the SciTex, cost around $300 an hour for basic photo retouching.
File format.
Photoshop files have default file extension as .PSD, which stands for "Photoshop Document." A PSD file stores an image with support for most imaging options available in Photoshop. These include layers with masks, transparency, text, alpha channels and spot colors, clipping paths, and duotone settings. This is in contrast to many other file formats (e.g., .JPG or .GIF) that restrict content to provide streamlined, predictable functionality. A PSD file has a maximum height and width of 30,000 pixels, and a length limit of 2 Gigabytes.
Photoshop files sometimes have the file extension .PSB, which stands for "Photoshop Big" (also known as "large document format"). A PSB file extends the PSD file format, increasing the maximum height and width to 300,000 pixels and the length limit to around 4 Exabytes. The dimension limit was apparently chosen arbitrarily by Adobe, not based on computer arithmetic constraints (it is not close to a power of two, as is 30,000) but for ease of software testing. PSD and PSB formats are documented.
Because of Photoshop's popularity, PSD files are widely used and supported to some extent by most competing software. The .PSD file format can be exported to and from Adobe's other apps like Adobe Illustrator, Adobe Premiere Pro, and After Effects, to make professional standard DVDs and provide non-linear editing and special effects services, such as backgrounds, textures, and so on, for television, film, and the Internet. Photoshop's primary strength is as a pixel-based image editor, unlike vector-based image editors. Photoshop also enables vector graphics editing through its Paths, Pen tools, Shape tools, Shape Layers, Type tools, Import command, and Smart Object functions. These tools and commands are convenient to combine pixel-based and vector-based images in one Photoshop document, because it may not be necessary to use more than one program. To create very complex vector graphics with numerous shapes and colors, it may be easier to use software that was created primarily for that purpose, such as Adobe Illustrator or CorelDRAW. Photoshop's non-destructive Smart Objects can also import complex vector shapes.
Plugins.
Photoshop functionality can be extended by add-on programs called Photoshop plugins (or plug-ins). Adobe creates some plugins, such as Adobe Camera Raw, but third-party companies develop most plugins, according to Adobe's specifications. Some are free and some are commercial software.
Most plugins work with only Photoshop or Photoshop-compatible hosts, but a few can also be run as standalone applications.
There are various types of plugins, such as filter, export, import, selection, color correction, and automation. The most popular plugins are the filter plugins (also known as a 8bf plugins), available under the Filter menu in Photoshop.
Filter plugins can either modify the current image or create content. Below are some popular types of plugins, and some well-known companies associated with them:
Adobe Camera Raw (also known as ACR and Camera Raw) is a special plugin, supplied free by Adobe, used primarily to read and process raw image files so that the resultant images can be processed by Photoshop. It can also be used from within Adobe Bridge.
Photoshop tools.
Upon loading Photoshop, a sidebar with a variety of tools with multiple image-editing functions appears to the left of the screen. These tools typically fall under the categories of drawing; painting; measuring and navigation; selection; typing; and retouching. Some tools contain a small triangle in the bottom right of the toolbox icon. These can be expanded to reveal similar tools. While newer versions of Photoshop are updated to include new tools and features, several recurring tools that exist in most versions are discussed below.
Pen tool.
Photoshop includes a few versions of the "pen" tool. The pen tool creates precise paths that can be manipulated using anchor points. The "free form pen" tool allows the user to draw paths freehand, and with the "magnetic pen" tool, the drawn path attaches closely to outlines of objects in an image, which is useful for isolating them from a background.
Shape tools.
Photoshop provides an array of shape tools including rectangles, rounded rectangles, ellipses, polygons and lines. These shapes can be manipulated by the pen tool, direct selection tool etc. to make vector graphics.
Measuring and navigation.
The "eyedropper" tool selects a color from an area of the image that is clicked, and samples it for future use. The "hand" tool navigates an image by moving it in any direction, and the "zoom" tool enlarges the part of an image that is clicked on, allowing for a closer view.
Selection tools.
Selection tools are used to select all or any part of a picture to perform cut, copy, edit, or retouching operations.
Cropping.
The "crop" tool can be used to select a particular area of an image and discard the portions outside the chosen section. This tool assists in creating a focus point on an image and excluding unnecessary or excess space. Cropping allows enhancement of a photo’s composition while decreasing the file size. The "crop" tool is in the tools palette, which is located on the right side of the document. By placing the cursor over the image, the user can drag the cursor to the desired area. Once the Enter key is pressed, the area outside the rectangle will be cropped. The area outside the rectangle is the discarded data, which allows for the file size to be decreased. The "crop" tool can alternatively be used to extend the canvas size by clicking and dragging outside the existing image borders.
Slicing.
The ""slice"" and "slice select" tools, like the crop tool, are used in isolating parts of images. The slice tool can be used to divide an image into different sections, and these separate parts can be used as pieces of a web page design once HTML and CSS are applied. The slice select tool allows sliced sections of an image to be adjusted and shifted.
Moving.
The move tool can be used to drag the entirety of a single layer or more if they are selected. Alternatively, once an area of an image is highlighted, the "move" tool can be used to manually relocate the selected piece to anywhere on the canvas.
Marquee.
The "marquee" is a tool that can make selections that are single row, single column, rectangular and elliptical. An area that has been selected can be edited without affecting the rest of the image. This tool can also crop an image; it allows for better control. In contrast to the "crop" tool, the "marquee" tool allows for more adjustments to the selected area before cropping. The only "marquee" tool that does not allow cropping is the elliptical. Although the single row and column "marquee" tools allow for cropping, they are not ideal, because they only crop a line. The "rectangular marquee" tool is the preferred option. Once the tool has been selected, dragging the tool across the desired area will select it. The selected area will be outlined by dotted lines, referred to as "marching ants". These dotted lines are called "marching ants", because the dashes look like ants marching around the selected area. To set a specific size or ratio, the tool option bar provides these settings. Before selecting an area, the desired size or ratio must be set by adjusting the width and height. Any changes such as color, filters, location, etc. should be made before cropping. To crop the selection, the user must go to image tab and select crop.
Lasso.
The "lasso" tool is similar to the "marquee" tool, however, the user can make a custom selection by drawing it freehand. There are three options for the "lasso" tool – regular, polygonal, and magnetic. The regular "lasso" tool allows the user to have drawing capabilities. Photoshop will complete the selection once the mouse button is released. The user may also complete the selection by connecting the end point to the starting point. The "marching ants" will indicate if a selection has been made. The "polygonal lasso" tool will draw only straight lines, which makes it an ideal choice for images with many straight lines. Unlike the regular "lasso" tool, the user must continually click around the image to outline the shape. To complete the selection, the user must connect the end point to the starting point just like the regular lasso tool. "Magnetic lasso" tool is considered the smart tool. It can do the same as the other two, but it can also detect the edges of an image once the user selects a starting point. It detects by examining the color pixels as the cursor move over the desired area. A pixel is the smallest element in an image. Closing the selection is the same as the other two, which should also should display the "marching ants" once the selection has been closed.
The "quick selection" tool selects areas based on edges, similarly to the "magnetic lasso" tool. The difference between this tool and the "lasso" tool is that there is no starting and ending point. Since there isn’t a starting and ending point, the selected area can be added onto as much as possible without starting over. By dragging the cursor over the desired area, the "quick selection" tool detects the edges of the image. The "marching ants" allow the user to know what is currently being selected. Once the user is done, the selected area can be edited without affecting the rest of the image. One of the features that makes this tool especially user friendly is that the SHIFT key is not needed to add more to the selection; by default, extra mouse clicks will be added to the selection rather than creating a new selection.
Magic wand.
The "magic wand" tool selects areas based on pixels of similar values. One click will select all neighboring pixels of similar value within a tolerance level set by the user. If the "eyedropper" tool is selected in the options bar, then the magic wand can determine the value needed to evaluate the pixels; this is based on the sample size setting in the "eyedropper" tool. This tool is inferior to the quick selection tool which works much the same but with much better results and more intuitive controls. The user must decide what settings to use or if the image is right for this tool.
Eraser.
The "Eraser" tool erases content based on the active layer. If the user is on the text layer, then any text across which the tool is dragged will be erased. The eraser will convert the pixels to transparent, unless the background layer is selected. The size and style of the eraser can be selected in the options bar. This tool is unique in that it can take the form of the paintbrush and pencil tools. In addition to the straight eraser tool, there are two more available options – background eraser and magic eraser. The "background eraser" deletes any part of the image that is on the edge of an object. This tool is often used to extract objects from the background. The "magic eraser" tool deletes based on similar colored pixels. It is very similar to the "magic wand" tool. This tool is ideal for deleting areas with the same color or tone that contrasts with the rest of the image.
Video editing.
In Adobe CS5 Extended edition, video editing is comprehensive and efficient with a broad compatibility of video file formats such as "MOV", "AVI", "MPEG-4", and "FLV" formats and easy workflow. Using simple combination of keys video layers can easily be modified, with other features such as adding text and the creation of animations using single images.
3D extrusion.
With the Extended version of Photoshop CS5, 2D elements of an artwork can easily become three-dimensional with the click of a button. Extrusions of texts, an available library of materials for three-dimensional, and even wrapping two-dimensional images around 3D geometry.
Mobile integration.
Third-party plugins have also been added to the most recent version of Photoshop where technologies such as the iPad have integrated the software with different types of applications. Applications like the Adobe Eazel painting app allows the user to easily create paintings with their fingertips and use an array of different paint from dry to wet in order to create rich color blending.
Camera Raw.
With the Camera Raw plug-in, raw images can be processed without the use of Adobe Photoshop Lightroom, along with other image file formats such as "JPEGs", "TIFFs", or "PNGs". The plug-in allows users to remove noise without the side-effect of over-sharpening, add grain, and even perform "post-crop vignetting".
3D printing tools.
Requiring Photoshop version 14.1 or later, users can create and edit designs for 3D printing. After downloading 3D photo models from numerous online services, users can add color, adjust the shape or rotate the angles. Artists can also design 3D models from scratch.
Color replacement tool.
The Color Replacement Tool allows you to change the color, while maintaining the highlights and shadows of the original image, of pieces of the image. By selecting Brushs and right clicking, the Color Replacement Tool is the third option down. What is important to note with this tool is the foreground color. The foreground color is what will be applied when painting along the chosen part of the image with the Color Replacement Tool.
Cultural impact.
"Photoshop" and derivatives such as "Photoshopped" (or just "Shopped") have become verbs that are sometimes used to refer to images edited by Photoshop, or any image manipulating program. Such derivatives are discouraged by Adobe because, in order to maintain validity and protect the trademark from becoming generic, trademarks must be used as proper nouns.
Magazines.
Before any type of print media is published, whether it is a magazine, newspaper, or even novel, it is likely the case that Photoshop has been used to enhance and clean up the imagery on many if not all of the pages. Magazines use Photoshop and many of its tools in order to enhance the imagery and text in their publications. Many Health and Beauty Magazines employ in-house designers to retouch photos of models to enhance their beauty. They add finishing touches to the imagery by using tools that balance color and add drop shadows, among other edits.
Photoshop disasters.
For comedic effect, some websites publish so-called "Photoshop disasters", that is, pictures that contain obvious Photoshop mistakes. Those mistakes range from missing limbs to overdone photo retouching on fashion models.
Photoshop contest.
A Photoshop contest (or "Photoshop contest") is an online game in which someone posts an image, and other people manipulate the image using a raster graphics editor such as Photoshop.
Version history.
Older versions.
Photoshop's naming scheme was initially based on version numbers. Adobe published thirteen versions (major and minor changes) before the October 2003 introduction of Creative Suite branding. In February 2013 Adobe donated the source code of the 1990 1.0.1 version of Photoshop to the Computer History Museum.
CS.
The first Photoshop CS was commercially released in October 2003 as the eighth major version of Photoshop. Photoshop CS increased user control with a reworked file browser augmenting search versatility, sorting and sharing capabilities and the Histogram Palette which monitors changes in the image as they are made to the document. Match Color was also introduced in CS, which reads color data to achieve a uniform expression throughout a series of pictures.
CS2.
Photoshop CS2, released in May 2005, expanded on its predecessor with a new set of tools and features. It included an upgraded Spot Healing Brush, which is mainly used for handling common photographic problems such as blemishes, red-eye, noise, blurring and lens distortion. One of the most significant inclusions in CS2 was the implementation of Smart Objects, which allows users to scale and transform images and vector illustrations without losing image quality, as well as create linked duplicates of embedded graphics so that a single edit updates across multiple iterations.
Adobe responded to feedback from the professional media industry by implementing non-destructive editing as well as the producing and modifying of 32-Bit High Dynamic Range (HDR) images, which are optimal for 3D rendering and advanced compositing. FireWire Previews could also be viewed on a monitor via a direct export feature.
Photoshop CS2 brought the Vanishing Point and Image Warping tools. Vanishing Point makes tedious graphic and photo retouching endeavors much simpler by letting users clone, paint and transform image objects while maintaining visual perspective. Image Warping makes it easy to digitally distort an image into a shape by choosing on-demand presets or by dragging control points.
The File Browser was upgraded to Adobe Bridge, which functioned as a hub for productivity, imagery and creativity, providing multi-view file browsing and smooth cross-product integration across Adobe Creative Suite 2 software. Adobe Bridge also provided access to Adobe Stock Photos, a new stock photography service that offered users one-stop shopping across five elite stock image providers to deliver high-quality, royalty-free images for layout and design.
Camera Raw version 3.0 was a new addition in CS2, and it allowed settings for multiple raw files to be modified simultaneously. In addition, processing multiple raw files to other formats including JPEG, TIFF, DNG or PSD, could be done in the background without executing Photoshop itself.
Photoshop CS2 brought a streamlined interface, making it easier to access features for specific instances. In CS2 users were also given the ability to create their own custom presets, which was meant to save time and increase productivity.
CS2 activation servers' shutdown: In January 2013, Adobe Photoshop CS2 (9.0), with some other CS2 products, was released with an official serial number, due to the technical glitch in Adobe's CS2 activation servers (see Creative Suite 1 and 2).
CS3.
CS3 improves on features from previous versions of Photoshop and introduces new tools. One of the most significant is the streamline interface which allows increased performance, speed, and efficiency. There is also improved support for Camera RAW files which allow users to process images with higher speed and conversion quality. CS3 supports over 150 RAW formats as well as JPEG, TIFF and PDF. Enhancements were made to the Black and White Conversion, Brightness and Contrast Adjustment and Vanishing Point Module tools. The Black and White adjustment option improves control over manual grayscale conversions with a dialog box similar to that of Channel Mixer. There is more control over print options and better management with Adobe Bridge. The Clone Source palette is introduced, adding more options to the clone stamp tool. Other features include the nondestructive Smart Filters, optimizing graphics for mobile devices, Fill Light and Dust Busting tools. Compositing is assisted with Photoshop's new Quick Selection and Refine Edge tools and improved image stitching technology.
CS3 Extended includes everything in CS3 and additional features. There are tools for 3D graphic file formats, video enhancement and animation, and comprehensive image measurement and analysis tools with DICOM file support. The 3D graphic formats allow 3D content to be incorporated into 2D compositions. As for video editing, CS3 supports layers and video formatting so users can edit video files per frame.
CS3 and CS3 Extended were released in April 2007 to the United States and Canada. They were also made available through Adobe’s online store and Adobe Authorized Resellers. Both CS3 and CS3 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. The price for CS3 is US$649 and the extended version is US$999. Both products are compatible with Intel-based Macs and PowerPCs, supporting Windows XP and Windows Vista. CS3 is the first release of Photoshop that will run natively on Macs with Intel processors: previous versions can only run through the translation layer Rosetta, and will not run at all on Macs running OS X 10.7 or later.
CS4.
CS4 features smoother panning and zooming, allowing faster image editing at a high magnification. The interface is more simplified with its tab-based interface making it cleaner to work with. Photoshop CS4 features a new 3D engine allowing the conversion of gradient maps to 3D objects, adding depth to layers and text, and getting print-quality output with the new ray-tracing rendering engine. It supports common 3D formats; the new Adjustment and Mask Panels; Content-aware scaling (seam carving); Fluid Canvas Rotation and File display options. The Content-aware scaling allows users to intelligently size and scale images, and the Canvas Rotation tool makes it easier to rotate and edit images from any angle.
Adobe released Photoshop CS4 Extended, which has the features of Adobe Photoshop CS4, plus capabilities for scientific imaging, 3D, motion graphics, accurate image analysis and high-end film and video users. The faster 3D engine allows users to paint directly on 3D models, wrap 2D images around 3D shapes and animate 3D objects. As the successor to Photoshop CS3, Photoshop CS4 is the first x64 edition of Photoshop on consumer computers for Windows. The color correction tool has also been improved significantly.
CS4 and CS4 Extended were released on 15 October 2008. They were also made available through Adobe’s online store and Adobe Authorized Resellers. Both CS4 and CS4 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. The price for CS4 is US$699 and the extended version is US$999. Both products are compatible with Intel-based Mac OS X and PowerPCs, supporting Windows XP and Windows Vista.
CS5.
Photoshop CS5 was launched on 12 April 2010. In a video posted on its official Facebook page, the development team revealed the new technologies under development, including three-dimensional brushes and warping tools.
In May 2011, Adobe Creative Suite 5.5 (CS5.5) was released, with new versions of some of the applications. Its version of Photoshop, 12.1, is identical to the concurrently released update for Photoshop CS5, version 12.0.4, except for support for the new subscription pricing that was introduced with CS5.5.
CS5 introduces new tools such as the Content-Aware Fill, Refine Edge, Mixer Brush, Bristle Tips and Puppet Warp. The community also had a hand in the additions made to CS5 as 30 new features and improvements were included by request. These include automatic image straightening, the Rule-of-Thirds cropping tool, color pickup, and saving a 16-bit image as a JPEG. Another feature includes the Adobe Mini Bridge, which allows for efficient file browsing and management.
CS5 Extended includes everything in CS5 plus features in 3D and video editing. A new materials library was added, providing more options such as Chrome, Glass, and Cork. The new Shadow Catcher tool can be used to further enhance 3D objects. For motion graphics, the tools can be applied to over more than one frame in a video sequence.
CS5 and CS5 Extended were made available through Adobe's online store, Adobe Authorized Resellers and Adobe direct sales. Both CS5 and CS5 Extended are offered as either a stand-alone application or a feature of Adobe Creative Suite 5. The price for CS5 is US$699 and the extended version is US$999. Both products are compatible with Intel-based Mac OS and Windows XP, Windows Vista, and Windows 7.
CS6.
Photoshop CS6, released in May 2012, added new creative design tools and provided a redesigned interface with a focus on enhanced performance. New features have been added to the Content-Aware tool such as the Content-Aware Patch and Content-Aware Move.
Adobe Photoshop CS6 brought a suite of tools for video editing. Color and exposure adjustments, as well as layers, are among a few things that are featured in this new editor. Upon completion of editing, the user is presented with a handful of options of exporting into a few popular formats.
CS6 brings the "straighten" tool to Photoshop, where a user simply draws a line anywhere on an image, and the canvas will reorient itself so that the line drawn becomes horizontal, and adjusts the media accordingly. This was created with the intention that users will draw a line parallel to a plane in the image, and reorient the image to that plane to more easily achieve certain perspectives.
CS6 allows background saving, which means that while another document is compiling and archiving itself, it is possible to simultaneously edit an image. CS6 also features a customizable auto-save feature, preventing any work from being lost.
The price for CS6 is US$699 and the extended version is US$999. Students, however, even those who are homeschooled, can receive a significant discount on Photoshop.
With the newest Photoshop version 13.1.3, Adobe has dropped support for Windows XP (even on native x64 for Windows XP x64); thus, the last version that works on Windows XP is 13.0.1. Adobe also announced that CS6 will be the last suite sold with perpetual licenses in favor of the new Creative Cloud subscriptions, but will continue to support Photoshop CS6 for OS compatibility and will provide bug fixes and security updates as necessary.
CC.
Photoshop CC (14.0) was launched on 18 June 2013. As the next major version after CS6, it is only available as part of a Creative Cloud subscription, the full version of which costs $49 every month. Major features in this version include All-new Smart Sharpen, Intelligent Upsampling, and Camera Shake Reduction for reducing blur caused by camera shake. Editable Rounded Rectangles and an update to Adobe Camera Raw (8.0) were also included.
Since the initial launch, Adobe has released two additional feature-bearing updates. The first, version 14.1, was launched on 9 September 2013. The major features in this version were Adobe Generator, a Node.js-based platform for creating plug-ins for Photoshop. Photoshop 14.1 shipped with two plug-ins, one to automatically generate image assets based on an extension in the layer name, and another to automatically generate assets for Adobe Edge Reflow.
Version 14.2 was released on 15 January 2014. Major features include Perspective Warp, Linked Smart Objects, and 3D Printing support.
CC 2014.
Photoshop CC 2014 (15.0) was released on 18 June 2014. CC 2014 features improvements to content-aware tools, two new blur tools (spin blur and path blur) and a new focus mask feature that enables the user to select parts of an image based on whether they are in focus or not. Other minor improvements have been made, including speed increases for certain tasks.
CC 2015.
Photoshop CC 2015 was released on 15 June 2015. Adobe added several features including Adobe Stock, which is a library of custom stock images. They also added the ability to have more than one layer style, for example in the older versions of Photoshop, only one shadow could be used for a layer but in CC 2015, up to ten are available. Other minor features like Export As, which is a form of the Save For Web in CC 2014 were also added. CC 2015 also marks the 25th anniversary of Photoshop.
Photoshop Touch.
Photoshop Touch was an application designed specifically for tablets and touchscreen devices. It included many of the features of the personal computer version, including layers, selection tools, adjustments, and filters. Edited files could be synced with Adobe Creative Cloud. Photoshop touch was available on iOS and Android. There were two iOS versions—one designed for iPad and the other for iPhone and iPod touch; both required iOS 5.0 or later. Android versions could be installed on any Android handset (4.0 and up) and tablets (3.1 and up). It has since been discontinued.

</doc>
<doc id="24894" url="https://en.wikipedia.org/wiki?curid=24894" title="PaintShop Pro">
PaintShop Pro

PaintShop Pro (PSP) is a raster and vector graphics editor for Microsoft Windows. It was originally published by Jasc Software. In October 2004, Corel purchased Jasc Software and the distribution rights to Paint Shop Pro. PSP functionality can be extended by Photoshop-compatible plugins.
The X-numbered editions have been sold in two versions: PaintShop Pro, which is the basic editing program, and PaintShop Pro Ultimate, which bundles in other standalone programs, additional artistic tools and/or plugins. The particular bundled programs have varied with each numbered version and have not been sold by Corel as separate products.
PSP comes with an interface for automating tasks with scripts written in the Python programming language.
History.
Originally called simply Paint Shop, the first version, 1.0, was a basic picture converter between BMP, GIF and PCX formats, released by Robert Voit in August 1990. Paint Shop was originally distributed as shareware and is still available at many download sites (4.12 being a popular version). Most newer versions are only commercially available although some have been distributed in the United Kingdom in computer magazine CDs after they became obsolete.
On November 28, 2007, Corel announced that the office in Eden Prairie, Minnesota, where Paint Shop Pro was created, would be shut down, with development moving to offices in California and China.
From 2006 to 2011 (versions XI to X3), PaintShop Pro was marketed as "Corel Paint Shop Pro Photo". Having dropped the "Photo" part of the name in version X4, Paintshop Pro X5 was derived from Ulead Photo Explorer after Corel's acquisition of Ulead.
Paint Shop Pro 5 added support for layers as well as CMYK and HSL colour modes, included JASC Animation Shop for creating animations and in fact was marketed as "Paint Shop Pro 5.0 with Animation Shop". PaintShop Pro X6 was the first to be available as a native 64 bit version (purchase includes both versions). PaintShop Pro X7 includes content-aware features such as "Magic Fill" and "Smart Edge" as well as support for XMP sidecar files that preserve edit settings for raw formats.
Picture tubes.
Picture tubes are graphic images with no background. They are often used as a starting point for complex images; that is, they are combined with other image elements to produce a final work. Tubes can also be regarded as graphic brushes based on a pre-created image; this was their original use. Instead of leaving a trace of color on the canvas, they would leave a trail of images. Popular tube subjects include alphabets, humans (also known as dollz), animal and toy figures, flowers, love messages and seasonal symbols.
The tube system originated with PSP Pro version 5. Native tube files may be in .tub, .psp, .pspimage, and .psptube formats. XnView, IrfanView, and TubeEx are separate graphics programs that can convert tube files (.tub) to .png.
Ultimate edition.
PaintShop Pro Photo X2 Ultimate was released towards the end of life of PaintShop Pro Photo X2, in September 2008. It included 150 additional picture frames and Picture Tubes, the programs Background Remover, Corel Painter Photo Essentials 4, and Photorecovery, as well as RAW support for 250 cameras and a 2GB flash drive.
Subsequent Ultimate editions were released contemporaneously with the basic version. PaintShop Pro X4 Ultimate included Nik Color Efex Pro 3.0, a voucher for 21 images from Fotolia at high quality, and additional Picture Tubes. X5 Ultimate included Reallusion FaceFilter Studio 2.0, NIK Color Efex Pro 3.0, and "over 100 unique brushes, textures and royalty-free backgrounds". PaintShop Pro X6 Ultimate includes Athentech Imaging's Perfectly Clear and Reallusion's FaceFilter3 Standard. PaintShop Pro X7 Ultimate includes those same two items.
The bundled extras cannot be installed unless that version of the PaintShop program is already installed. However, once a bundled extra such as a plugin has been installed, the installed files can be copied to other versions, e.g., a plugin installed under X5 can be copied to X6 and even if X5 is then uninstalled, the plugin will continue to work under X6. Corel releases a new X version roughly annually, so this ability to copy means PSP users do not have to choose between updating or continued use of Ultimate add-ons from previous versions.
License management software.
Versions XI, X2, X3 and X4 install a third party program named PSIService.exe, a Windows service called ProtexisLicensing. Written by Protexis, this runs in the background and collects licensing information. This program communicates with a remote host. Manually disabling the Protexis Licensing service may cause Corel Paint Shop Pro Photo to cease functioning.
Criticism of pricing policy.
There have been criticisms of Corel's pricing policy that pitches international versions at higher prices than those charged in the US.

</doc>
<doc id="24897" url="https://en.wikipedia.org/wiki?curid=24897" title="Persuasion">
Persuasion

Persuasion is an umbrella term of influence. Persuasion can attempt to influence a person's beliefs, attitudes, intentions, motivations, or behaviors. In business,
persuasion is a process aimed at changing a person's (or a group's) attitude or behavior toward some event, idea, object, or other person(s), by using written or spoken words to convey information, feelings, or reasoning, or a combination thereof. Persuasion is also an often used tool in the pursuit of personal gain, such as election campaigning, giving a sales pitch, or in trial advocacy. Persuasion can also be interpreted as using one's personal or positional resources to change people's behaviors or attitudes.
Systematic persuasion is the process through which attitudes or beliefs are leveraged by appeals to logic and reason. Heuristic persuasion on the other hand is the process through which attitudes or beliefs are leveraged by appeals to habit or emotion.
Brief history.
Persuasion began with the Greeks, who emphasized rhetoric and elocution as the highest standard for a successful politician. All trials were held in front of the Assembly, and both the prosecution and the defense rested, as they often do today, on the persuasiveness of the speaker. Rhetoric was the ability to find the available means of persuasion in any instance.
The Greek philosopher Aristotle listed four reasons why one should learn the art of persuasion:
Aristotle's rhetorical proofs:
Theories.
Attribution theory.
Humans attempt to explain the actions of others through either dispositional attribution or situational attribution.
Dispositional attribution, also referred to as internal attribution, attempts to point to a person’s traits, abilities, motives, or dispositions as a cause or explanation for their actions. A citizen criticizing a president by saying the nation is lacking economic progress and health because the president is either lazy or lacking in economic intuition is utilizing a dispositional attribution.
Situational attribution, also referred to as external attribution, attempts to point to the context around the person and factors of his surroundings, particularly things that are completely out of his control. A citizen claiming that a lack of economic progress is not a fault of the president but rather the fact that he inherited a poor economy from the previous president is situational attribution.
Fundamental attribution error occurs when people wrongly attribute either a shortcoming or accomplishment to internal factors, and disregarding any external factors. In general, people tend to make dispositional attributions more often than situational attributions when trying to explain or understand a person’s behavior. This happens when we are much more focused on the individual because we do not know much about their situation or context. When trying to persuade others to like us or another person, we tend to explain positive behaviors and accomplishments with dispositional attribution, but our own negative behaviors and shortcomings with situational attributions.
Conditioning theories.
Conditioning plays a huge part in the concept of persuasion. It is more often about leading someone into taking certain actions of their own, rather than giving direct commands. In advertisements for example, this is done by attempting to connect a positive emotion to a brand/product logo. This is often done by creating commercials that make people laugh, using a sexual undertone, inserting uplifting images and/or music etc. and then ending the commercial with a brand/product logo. Great examples of this are professional athletes. They are paid to connect themselves to things that can be directly related to their roles; sport shoes, tennis rackets, golf balls, or completely irrelevant things like soft drinks, popcorn poppers and panty hose. The important thing for the advertiser is to establish a connection to the consumer.
This conditioning is thought to affect how people view certain products, knowing that most purchases are made on the basis of emotion. Just like you sometimes recall a memory from a certain smell or sound, the objective of some ads is solely to bring back certain emotions when you see their logo in your local store. The hope is that by repeating the message several times it will cause the consumer to be more likely to purchase the product because he/she already connects it with a good emotion and a positive experience.
Stefano DellaVigna and Matthew Gentzkow did a comprehensive study on the effects of persuasion in different domains. They discovered that persuasion has little or no effect on advertisement; however, there was a substantial effect of persuasion on voting if there was face-to-face contact.
Cognitive dissonance theory.
Leon Festinger originally proposed the theory of cognitive dissonance in 1956. He theorized that human beings constantly strive for mental consistency. Our cognition (thoughts, beliefs, or attitudes) can be in agreement, unrelated, or in disagreement with each other. Our cognition can also be in agreement or disagreement with our behaviors. When we detect conflicting cognition, or dissonance, it gives us a sense of incompleteness and discomfort. For example, a person who is addicted to smoking cigarettes but also suspects it could be detrimental to his health suffers from cognitive dissonance.
Festinger suggests that we are motivated to reduce this dissonance until our cognition is in harmony with itself. We strive for mental consistency. There are four main ways we go about reducing or eliminating our dissonance:
Revisiting the example of the smoker, he can either quit smoking, reduce the importance of his health, convince himself he is not at risk, or evaluate the reward of his smoking to be worth the cost of his health.
Cognitive dissonance is powerful when it relates to competition and self-concept. The most famous example of how cognitive dissonance can be used for persuasion comes from Festinger and Carlsmith’s 1959 experiment in which participants were asked to complete a very dull task for an hour. Some were paid $20, while others were paid $1, and afterwards they were instructed to tell the next waiting participants that the experiment was fun and exciting. Those who were paid $20 were much more likely to convince the next participants that the experiment really was enjoyable than those who received $1. This is because $20 is enough reason to participate in a dull task for an hour, so there is no dissonance. Those who received $1 experienced great dissonance, so they had to truly convince themselves that the task actually was enjoyable in order to avoid feeling like they were taken advantage of, and therefore reduce their dissonance.
Elaboration likelihood model.
Persuasion has traditionally been associated with two routes.
The Elaboration likelihood model (ELM) forms a new facet of the route theory. It holds that the probability of effective persuasion depends on how successful the communication is at bringing to mind a relevant mental representation, which is the elaboration likelihood. Thus if the target of the communication is personally relevant, this increases the elaboration likelihood of the intended outcome and would be more persuasive if it were through the central route. Communication which does not require careful thought would be better suited to the peripheral route.
Functional theories.
Functional theorists attempt to understand the divergent attitudes individuals have towards people, objects or issues in different situations. There are four main functional attitudes:
When communication is targeted at an underlying function its degree of persuasiveness will influence whether the individual will change their attitude, after determining that another attitude will be more effective in fulfilling that function.
Inoculation theory.
A vaccine introduces a weak form of a virus that can easily be defeated to prepare the immune system should it need to fight off a stronger form of the same virus. In much the same way, the theory of inoculation suggests a certain party can introduce a weak form of an argument that can easily be thwarted in order to prepare the audience to disregard a stronger, full-fledged form of the argument from an opposing party.
This is often practiced in negative advertisements and comparative advertisements, both for products and political causes. An example would be a manufacturer of a product displaying an ad that refutes one particular claim made about a rival’s product, so that when the audience sees an ad for said rival product, they will refute all the claims of the product without a second thought.
Narrative transportation theory.
Narrative transportation theory proposes that when people lose themselves in a story, their attitudes and intentions change to reflect that story. The mental state of narrative transportation can explain the persuasive effect of stories on people, who may experience narrative transportation when certain contextual and personal preconditions are met, as Green and Brock postulate for the transportation-imagery model. Narrative transportation occurs whenever the story receiver experiences a feeling of entering a world evoked by the narrative because of empathy for the story characters and imagination of the story plot.
Social judgment theory.
Social judgment theory suggests that when people are presented with an idea or any kind of persuasive proposal, their natural reaction is to immediately seek a way to sort the information subconsciously and react to it. We evaluate the information and compare it with the attitude we already have, which is called the initial attitude or anchor point.
When attempting to sort the incoming persuasive information, an audience will evaluate whether it lands in their latitude of acceptance, latitude of non-commitment or indifference, or the latitude of rejection. The size of these latitudes will vary from topic to topic. Our "ego-involvement" generally plays one of the largest roles in determining the size of these latitudes. When a topic is closely connected to how we define and perceive ourselves, or deals with anything we care passionately about, our latitudes of acceptance and non-commitment are likely to be much smaller and our attitude of rejection much larger. A person’s anchor point is considered to be the center of his latitude of acceptance, the position that is most acceptable to him.
An audience is likely to distort incoming information to fit into their unique latitudes. If something falls within the latitude of acceptance, the subject tends to assimilate the information and consider it closer to his anchor point than it really is. Inversely, if something falls within the latitude of rejection, the subject tends to contrast the information and convince himself the information is farther away from his anchor point than it really is.
When trying to persuade an individual target or an entire audience, it is vital to first learn the average latitudes of acceptance, non-commitment, and rejection of your audience. It is ideal to use persuasive information that lands near the boundary of the latitude of acceptance if the goal is to change the audience’s anchor point. Repeatedly suggesting ideas on the fringe of the acceptance latitude will cause people to gradually adjust their anchor points, while suggesting ideas in the rejection latitude or even the non-commitment latitude will not result in any change to the audience’s anchor point.
Methods.
Persuasion methods are also sometimes referred to as "persuasion tactics" or "persuasion strategies".
Usage of force.
There is the usage of force in persuasion, which does not have any scientific theories, except for its use to make demands. The use of force is then a precedent to the failure of less direct means of persuasion. Application of this strategy can be interpreted as a threat since the persuader does not give options to his or her request.
Weapons of influence.
Robert Cialdini, in "Influence", his book on persuasion, defined six "influence cues or weapons of influence": Influence is the process of changing.
Reciprocity.
The principle of reciprocity states that when a person provides us with something, we attempt to repay him or her in kind. Reciprocation produces a sense of obligation, which can be a powerful tool in persuasion. The reciprocity rule is effective because it can be overpowering and instill in us a sense of obligation. Generally, we have a dislike for individuals who neglect to return a favor or provide payment when offered a free service or gift. As a result, reciprocation is a widely held principle. This societal standard makes reciprocity extremely powerful persuasive technique, as it can result in unequal exchanges and can even apply to an uninvited first favor.
Commitment and consistency.
Consistency is an important aspect of persuasion because it:
Consistency allows us to more effectively make decisions and process information. The concept of consistency states that if a person commits, either orally or in writing, he or she is more likely to honor that particular commitment. This is especially true for written commitments, as they appear psychologically more concrete and can be backed up with hard proof. Once a person commits to a stance, he or she has a tendency to behave according to that commitment. Commitment is an effective persuasive technique because once you get someone to make a commitment, they are more likely to engage in self-persuasion, providing themselves and others with reasons and justifications to support his or her commitment in order to avoid dissonance.
Social proof.
We are influenced by others around us; we want to be doing what everyone else is doing. People often base their actions and beliefs on what others around them are doing, how others act or what others believe.
"The power of the crowd" is very effective. We all want to know what others are doing around us. We are so obsessed with what others do and how others act, that we then try to be just like other people. Cialdini gives an example that is somewhat like this: in a phone–a–thon, the host will say something along the line of, "Operators are waiting, please call now." The only context that you have from that statement is that the operators are waiting and they are not busy. Rather the host may say: "If operators are busy, please call again." This is proving the technique of social proof. Just by changing three words, it sounds like the lines are busy and other people are calling; so it must be a good, legitimate organization.
Social proof is most effective when people are uncertain or when there are similarities in a situation. In uncertain or ambiguous situations, when there are multiple possibilities or choices that need to be made, people are likely to conform to what others do/are doing. We become more influenced by the people around us, in situations that cause us to make a decision. The other effective situation for social proofing is when there are similarities. We are more prone to change/conform around people who are similar to us. If someone who is similar to you is being controlling and a leader, you are more likely to listen and follow what it is they are saying.
Likeness.
This principle is simple and concise. People say "yes" to people that they like. Two major factors contribute to overall likeness. The first is physical attractiveness. People who are physically attractive seem to be more persuasive; they get what they want and they can easily change others' attitudes. This attractiveness is proven to send favorable messages/impressions of other traits that a person may have, such as talent, kindness, and intelligence. The second factor is similarity. We are more likely to be persuaded by people we see as similar to ourselves.
Authority.
We have the tendency to believe that if an expert says something, then it must be true. People like to listen to those who are knowledgeable and trustworthy, so if you can be those two things, then you are already on your way to getting people to believe and listen to you.
In the Milgram study, a series of experiments begun in 1961, a "teacher" and a "learner" were placed in two different rooms. The "learner" was attached to an electric harness that could administer shock. The "teacher" was told by a supervisor, dressed in a white scientist's coat, to ask the learner questions and punish him when he got a question wrong. The teacher was instructed by the study supervisor to deliver an electric shock from a panel under the teacher's control. After delivery, the teacher had to up the voltage to the next notch. The voltage went up to 450 volts. The catch to this experiment was that the teacher did not know that the learner was an actor faking the pain sounds he heard and was not actually being harmed. The experiment was being done to see how obedient we are to authority. "When an authority tells ordinary people it is their job to deliver harm, how much suffering will each subject be willing to inflict on an entirely innocent other person if the instructions come 'from above'?". In this study the results show that most teachers were willing to give as much pain as was available to them. The conclusion was that people are willing to bring pain upon others when they are directed to do so by some authority figure.
Scarcity.
Scarcity is a principle that people underestimate. When something has limited availability, people assign it more value. According to Cialdini, "people want more of what they cannot have." When scarcity is an issue, the context matters. This means that within certain contexts, scarcity "works" better. To get people to believe that something is scarcer, you need to explain what about that certain product will give them what no other product will. You have to work the audience in the correct way. Something else, that you can do to get people to believe that something is scarce, is to tell them what they will lose, not what they will gain. Saying things like "you will lose $5", rather than saying "you could save $5". You are making something sound more scarce.
There are two major reasons why the scarcity principle works:
When this happens, we assign the scarce item or service more value simply because it is harder to acquire.
This principle is that we all want things that are out of our reach. If we see something is easily available, we do not want it as much as something that is very rare.
Machiavellianism.
Machiavellianism employs the tools of manipulation and deceit to gain wealth and power.
Relationship-based persuasion of Shell and Moussa.
In their book "The Art of Woo", G. Richard Shell and Mario Moussa present a four-step approach to strategic persuasion. They explain that persuasion means to win others over, not to defeat them. Thus it is important to be able to see the topic from different angles in order to anticipate the reaction others have to a proposal.
List of methods.
By appeal to reason:
By appeal to emotion:
Aids to persuasion:
Other techniques:
Coercive techniques, some of which are highly controversial and/or not scientifically proven to be effective:
In culture.
It is through a basic cultural personal definition of persuasion that everyday people understand how others are attempting to influence them and then how they influence others. The dialogue surrounding persuasion is constantly evolving because of the necessity to use persuasion in everyday life. Persuasion tactics traded in society have influences from researchers, which may sometimes be misinterpreted.
To keep evolutionary advantage, in the sense of wealth and survival, you must persuade and not be persuaded. In order to understand cultural persuasion, researchers will gather knowledge from domains such as "buying, selling, advertising, and shopping, as well as parenting and courting."
Methods of persuasion vary by culture, both in prevalence and effectiveness. For example, advertisements tend to appeal to different values according to whether they are used in collectivistic or individualistic cultures.
Persuasion Knowledge Model (PKM).
The Persuasion Knowledge Model (PKM) was created by Friestad and Wright in 1994. This framework allows the researchers to analyze the process of gaining and using everyday persuasion knowledge. The researchers suggest the necessity of including "the relationship and interplay between everyday folk knowledge and scientific knowledge on persuasion, advertising, selling, and marketing in general."
In order to educate the general population about research findings and new knowledge about persuasion, a teacher must draw on their pre-existing beliefs from folk persuasion in order to make the research relevant and informative to lay people, which creates "mingling of their scientific insights and commonsense beliefs."
As a result of this constant mingling, the issue of persuasion expertise becomes messy. Expertise status can be interpreted from a variety of sources like job titles, celebrity, or published scholarship.
It is through this multimodal process that we create concepts like "stay away from car salesmen, they will try to trick you." The kind of persuasion techniques blatantly employed by car salesmen creates an innate distrust of them in popular culture. According to Psychology Today, they employ tactics ranging from making personal life ties with the customer to altering reality by handing the customer the new car keys before the purchase.
Neurobiology.
Attitudes and persuasion are among the central issues of social behavior. One of the classic questions is when are attitudes a predictor of behavior. Previous research suggested that selective activation of left prefrontal cortex might increase the likelihood that an attitude would predict a relevant behavior. Using lateral attentional manipulation, this was supported.
An earlier article showed that EEG measures of anterior prefrontal asymmetry might be a predictor of persuasion. Research participants were presented with arguments that favored and arguments that opposed the attitudes they already held. Those whose brain was more active in left prefrontal areas said that they paid the most attention to statements with which they agreed while those with a more active right prefrontal area said that they paid attention to statements that disagreed. This is an example of defensive repression, the avoidance or forgetting of unpleasant information. Research has shown that the trait of defensive repression is related to relative left prefrontal activation. In addition, when pleasant or unpleasant words, probably analogous to agreement or disagreement, were seen incidental to the main task, an fMRI scan showed preferential left prefrontal activation to the pleasant words.
One way therefore to increase persuasion would seem to be to selectively activate the right prefrontal cortex. This is easily done by monaural stimulation to the contralateral ear. The effect apparently depends on selective attention rather than merely the source of stimulation. This manipulation had the expected outcome: more persuasion for messages coming from the left.

</doc>
<doc id="24898" url="https://en.wikipedia.org/wiki?curid=24898" title="Prime Minister of Israel">
Prime Minister of Israel

The Prime Minister of Israel (, "Rosh HaMemshala", "lit." Head of the Government, Hebrew acronym: ) is the head of the Israeli government and the most powerful figure in Israeli politics. Although the President of Israel is the country's head of state, his powers are largely ceremonial; the prime minister holds most of the real power. The official residence of the prime minister, "Beit Rosh Hamemshala" is in Jerusalem. The current prime minister is Benjamin Netanyahu of Likud, the ninth person to hold the position (excluding caretakers).
Following an election, the president nominates a member of the Knesset to become prime minister after asking party leaders whom they support for the position. The nominee then presents a government platform and must receive a vote of confidence in order to become prime minister. In practice, the prime minister is usually the leader of the largest party in the governing coalition.
Between 1996 and 2001, the prime minister was directly elected, separately from the Knesset.
History.
The office of prime minister came into existence on 14 May 1948, the date of the Declaration of the Establishment of the State of Israel, when the provisional government was created. David Ben-Gurion, leader of Mapai and head of the Jewish Agency became Israel's first prime minister. The position became permanent on 8 March 1949, when the first government was formed. Ben-Gurion retained his role until late 1953, when he resigned in order to settle in the Kibbutz of Sde Boker. He was replaced by Moshe Sharett. However, Ben-Gurion returned in a little under two years to reclaim his position. He resigned for a second time in 1963, breaking away from Mapai to form Rafi. Levi Eshkol took over as head of Mapai and prime minister. He became the first prime minister to head the country under the banner of two parties when Mapai formed the Alignment with Ahdut HaAvoda in 1965. In 1968 he also became the only party leader to command an absolute majority in the Knesset, after Mapam and Rafi merged into the Alignment, giving it 63 seats in the 120-seat Knesset.
On 26 February 1969, Eshkol became the first prime minister to die in office, and was temporarily replaced by Yigal Allon. However, Allon's stint lasted less than a month, as the party persuaded Golda Meir to return to political life and become prime minister in March 1969. Meir was Israel's first woman prime minister, and the third in the world (after Sirimavo Bandaranaike and Indira Gandhi).
Meir resigned in 1974 after the Agranat Commission published its findings on the Yom Kippur War, even though it had absolved her of blame. Yitzhak Rabin took over, though he also resigned towards the end of the eighth Knesset's term following a series of scandals. Those included the suicide of Housing Minister Avraham Ofer after police began investigating allegations that he had used party funds illegally, and the affair involving Asher Yadlin (the governor-designate of the Bank of Israel), who was sentenced to five years in prison for having accepted bribes. Rabin's wife, Leah, was also found to have had an overseas bank account, which was illegal in Israel at the time.
Menachem Begin became the first right-wing prime minister when his Likud won the 1977 elections, and retained the post in the 1981 elections. He resigned in 1983 for health reasons, passing the reins of power to Yitzhak Shamir.
After the 1984 elections had proved inconclusive with neither the Alignment nor Likud able to form a government, a national unity government was formed with a rotating prime ministership – Shimon Peres took the first two years, and was replaced by Shamir midway through the Knesset term.
Although the 1988 elections produced another national unity government, Shamir was able to take the role alone. Peres made an abortive bid to form a left-wing government in 1990, but failed, leaving Shamir in power until 1992.
Rabin became prime minister for the second time when he led Labour to victory in the 1992 elections. After his assassination on 4 November 1995, Peres took over as prime minister.
Direct election.
During the thirteenth Knesset (1992–1996) it was decided to hold a separate ballot for prime minister modeled after American presidential elections. This system was instituted in part because the Israeli electoral system makes it all but impossible for one party to win a majority. While only two parties—Mapai/Labour and Likud—had ever led governments, the large number of parties or factions in a typical Knesset usually prevents one party from winning the 61 seats needed for a majority.
In 1996, when the first such election took place, the outcome was a surprise win for Benjamin Netanyahu after election polls predicted that Peres was the winner. However, in the Knesset election held at the same time, Labour won more votes than any other party (27%). Thus Netanyahu, despite his theoretical position of power, needed the support of the religious parties to form a viable government.
Ultimately Netanyahu failed to hold the government together, and early elections for both prime minister and the Knesset were called in 1999. Although five candidates announced their intention to run, the three representing minor parties (Benny Begin of Herut – The National Movement, Azmi Bishara of Balad and Yitzhak Mordechai of the Centre Party) dropped out before election day, and Ehud Barak beat Netanyahu in the election. However, the new system again appeared to have failed, as although Barak's One Israel party (an alliance of Labour, Gesher and Meimad) won more votes than any other party in the Knesset election, they garnered only 26 seats, the lowest ever by a winning party, meaning that a coalition with six smaller parties was once again necessary.
In early 2001, Barak resigned following the outbreak of the al-Aqsa Intifada. However, the government was not brought down, and only elections for prime minister were necessary. In the election itself, Ariel Sharon comfortably beat Barak, taking 62.4% of the vote. However, because Likud only had 21 seats in the Knesset, Sharon had to form a national unity government. Following Sharon's victory, it was decided to do away with separate elections for prime minister and return to the previous system.
2003 onwards.
The 2003 elections were carried out in the same manner as prior to 1996. Likud won 38 seats, the highest by a party for over a decade, and as party leader Sharon was duly appointed PM. However, towards the end of his term and largely as a result of the deep divisions within Likud over Israel's unilateral disengagement plan, Sharon broke away from his party to form Kadima, managing to maintain his position as prime minister and also becoming the first prime minister not to be a member of either Labour or Likud (or their predecessors). However, he suffered a stroke in January 2006, in the midst of election season, leading Ehud Olmert to become acting prime minister in the weeks leading to the elections. He was voted by the cabinet to be interim prime minister just after the 2006 elections, when Sharon had reached 100 days of incapacitation. He thus became Israel's third interim prime minister, only days before forming his own new government as the official Prime Minister of Israel.
In 2008, amid accusations of corruption and challenges from his own party, Olmert announced that he would resign. However his successor Tzipi Livni was unable to form a coalition government. In the election in the following year, while Kadima won the most seats, it was the Likud leader Benjamin Netanyahu who was given the task of forming a government. He was able to do so, thus beginning his second term as Prime Minister of Israel.
In the 2013 election, the Likud Yisrael Beiteinu alliance emerged as the largest faction. After forming a coalition, Netanyahu secured his third prime ministership.
Order of succession.
If the prime minister dies in office, the cabinet chooses an interim prime minister, to run the government until a new government is placed in power. Yigal Allon served as interim prime minister following Levi Eshkol's death, as did Shimon Peres following the assassination of Yitzhak Rabin.
According to Israeli law, if a prime minister is temporarily incapacitated rather than dies (as was the case following Ariel Sharon's stroke in early 2006), power is transferred to the acting prime minister, until the prime minister recovers (Ehud Olmert took over from Sharon), for up to 100 days. If the prime minister is declared permanently incapacitated, or that period expires, the President of Israel oversees the process of assembling a new governing coalition, and in the meantime the acting prime minister or other incumbent minister is appointed by the cabinet to serve as interim prime minister.
In the case of Sharon, elections were already due to occur within 100 days of the beginning of his coma thus the post-election coalition building process pre-empted the emergency provisions for the selection of a new prime minister. Nevertheless, Olmert was appointed interim prime minister on 16 April 2006, after the elections, just days before he had formed a government on 4 May 2006, to become the official prime minister.
Acting, vice and deputy prime minister.
Aside from the position of acting prime minister, there are also vice prime ministers and deputy prime ministers.
Prime minister's residence.
During his term of office, the prime minister lives in Jerusalem. Since 1974, the official residence of the prime minister is Beit Aghion, at the corner of Balfour and Smolenskin streets in Rehavia.

</doc>
<doc id="24899" url="https://en.wikipedia.org/wiki?curid=24899" title="President of France">
President of France

The President of the French Republic (, ), is the executive head of state of the French Fifth Republic. The powers, functions and duties of prior presidential offices, and their relation with the first minister and cabinets has over time differed with the various French constitutions.
The President of France is also the "ex officio" Co-Prince of Andorra, Grand Master of the Légion d'honneur and the Ordre national du Mérite and honorary proto-canon of the Basilica of St. John Lateran in Rome.
The current President of France is François Hollande, who took office on 15 May 2012.
Election.
Since the Referendum on the Direct Election of the President of the French Republic in 1962, the President has been directly elected by universal suffrage; he or she was previously elected by an electoral college.
After the Referendum on the Reduction of the Mandate of the President of the French Republic, 2000, the length of the term was reduced to five years from the previous seven; the first election to a shorter term was held in 2002. President Chirac was first elected in 1995 and again in 2002. At that time, there was no limit on the number of terms, so Chirac could have run again, but chose not to. He was succeeded by Nicolas Sarkozy on 16 May 2007.
Following a further change, the Constitutional law on the Modernisation of the Institutions of the Fifth Republic, 2008, a president cannot serve more than two consecutive terms. François Mitterrand and Jacques Chirac are the only Presidents to date who have served a full two terms (14 years for the former, 12 years for the latter).
In order to be admitted as an official candidate, potential candidates must receive signed nominations (informally known as "parrainages", for "godfathering") from more than 500 elected officials, mostly mayors. These officials must be from at least 30 "départements" or overseas collectivities, and no more than 10% of them should be from the same "département" or collectivity. Furthermore, each official may nominate only one candidate. There are exactly 45,543 elected officials, including 33,872 mayors.
Spending and financing of campaigns and political parties are highly regulated. There is a cap on spending, at approximately 20 million euros, and government public financing of 50% of spending if the candidate scores more than 5%. If the candidate receives less than 5% of the vote, the government funds €8,000,000 to the party (€4,000,000 paid in advance). Advertising on TV is forbidden but official time is given to candidates on public TV. An independent agency regulates election and party financing.
French presidential elections are conducted via run-off voting which ensures that the elected President always obtains a majority: if no candidate receives a majority of votes in the first round of voting, the two highest-scoring candidates arrive at a run-off. After the president is elected, he goes through a solemn investiture ceremony called a ""passation des pouvoirs"" ("handing over of powers").
Powers.
The French Fifth Republic is a semi-presidential system. Unlike many other European presidents, the French President is quite powerful. Although it is the Prime Minister of France and parliament that oversee much of the nation's actual day-to-day affairs, the French President wields significant influence and authority, especially in the fields of national security and foreign policy. The president holds the nation's most senior office, and outranks all other politicians.
The president's greatest power is his/her ability to choose the prime minister. However, since the French National Assembly has the sole power to dismiss the Prime Minister's government, the president is forced to name a prime minister who can command the support of a majority in the assembly.
Since 2002, the mandate of the president and the Assembly are both 5 years and the two elections are close to each other. Therefore, the likelihood of a "cohabitation" is lower. Among the powers of the government:
All decisions of the president must be countersigned by the prime minister, except dissolving the French National Assembly, choice of prime minister, dispositions of Article 19.
Detailed constitutional powers.
The constitutional attributions of the president are defined in Title II of the Constitution of France.
Article 5
The President of the Republic shall see that the Constitution is observed. He shall ensure, by his arbitration, the proper functioning of the public authorities and the continuity of the State.
He shall be the guarantor of national independence, territorial integrity and observance of treaties.
Article 8
The President of the Republic shall appoint the Prime Minister. He shall terminate the appointment of the Prime Minister when the latter tenders the resignation of the Government.
On the proposal of the Prime Minister, he shall appoint the other members of the Government and terminate their appointments.
Article 9
The President of the Republic shall preside over the Council of Ministers.
Article 10
The President of the Republic shall promulgate Acts of Parliament within fifteen days following the final adoption of an Act and its transmission to the Government.
He may, before the expiry of this time limit, ask Parliament to reconsider the Act or sections of the Act. Reconsideration shall not be refused.
"While the president has to sign all acts adopted by parliament into law, he cannot refuse to do so and exercise a kind of right of veto; his only power in that matter is to ask for a single reconsideration of the law by parliament and this power is subject to countersigning by the Prime minister."
Article 11 The president could submit laws to the people in a referendum with advice and consent of the cabinet.
Article 12
The President of the Republic may, after consulting the Prime Minister and the Presidents of the assemblies, declare the National Assembly dissolved.
A general election shall take place not less than twenty days and not more than forty days after the dissolution.
The National Assembly shall convene as of right on the second Thursday following its election. Should it so convene outside the period prescribed for the ordinary session, a session shall be called by right for a fifteen-day period.
No further dissolution shall take place within a year following this election.
Article 13
The President of the Republic shall sign the ordinances and decrees deliberated upon in the Council of Ministers.
He shall make appointments to the civil and military posts of the State. [...]
Article 14
The President of the Republic shall accredit ambassadors and envoys extraordinary to foreign powers ; foreign ambassadors and envoys extraordinary shall be accredited to him.
Article 15
The President of the Republic shall be commander-in-chief of the armed forces. He shall preside over the higher national defence councils and committees.
Article 16
Where the institutions of the Republic, the independence of the Nation, the integrity of its territory or the fulfilment of its international commitments are under serious and immediate threat, and where the proper functioning of the constitutional public authorities is interrupted, the President of the Republic shall take the measures required by these circumstances, after formally consulting the Prime Minister, the Presidents of the assemblies and the Constitutional Council. He shall inform the Nation of these measures in a message.
The measures must stem from the desire to provide the constitutional public authorities, in the shortest possible time, with the means to carry out their duties. The Constitutional Council shall be consulted with regard to such measures. Parliament shall convene as of right. The National Assembly shall not be dissolved during the exercise of the emergency powers.
"Article 16, allowing the president a limited form of rule by decree for a limited period of time in exceptional circumstance, has been used only once, by Charles de Gaulle during the Algerian War, from 23 April to 29 September 1961."
Article 17
The President of the Republic has the right to grant pardon.
Article 18
The President of the Republic shall communicate with the two assemblies of Parliament by means of messages, which he shall cause to be read and which shall not be the occasion for any debate. He can also give an address in front of the Congress of France in Versailles.
Outside sessions, Parliament shall be convened especially for this purpose.
"From 1875 to 2008, the President was prohibited from entering the houses of Parliament."
Article 19
Acts of the President of the Republic, other than those provided for under articles 8 (first paragraph), 11, 12, 16, 18, 54, 56 and 61, shall be countersigned by the Prime Minister and, where required, by the appropriate ministers.
Article 49 Para 3 allows the president to adopt a law on his authority. To this end, the prime minister goes before the lower and upper houses, reads out the bill to the legislators and closes with "the administration engages its responsibility" on the foregoing. Deprived of Gaullist party support halfway into his seven-year term spanning 1974 to 1981, Pres. Valéry Giscard d'Estaing relied heavily on this provision to stalemate Paris Mayor Jacques Chirac's attempt to bring him back under Gaullist control.
Presidential amnesties.
There is a tradition of so-called "presidential amnesties", which are something of a misnomer: after the election of a president, and of a National Assembly of the same party, parliament traditionally votes a law granting amnesty for some petty crimes. This practice has been increasingly criticized, particularly because it is believed to incite people to commit traffic offences in the months preceding the election. Such an amnesty law may also authorize the president to designate individuals who have committed certain categories of crimes to be offered amnesty, if certain conditions are met. Such individual measures have been criticized for the political patronage that they allow. Still, it is argued that such amnesty laws help reduce prison overpopulation. An amnesty law was passed in 2002; none have yet been passed as of January 2008.
The difference between an amnesty and a presidential pardon is that the former clears all subsequent effects of the sentencing, as though the crime had not been committed, while pardon simply relieves the sentenced individual from part or all of the remainder of the sentence.
Criminal responsibility and impeachment.
Articles 67 and 68 organize the regime of criminal responsibility of the President. They were reformed by a 2007 constitutional act, in order to clarify a situation that previously resulted in legal controversies.
The President of the Republic enjoys immunity during his term: he cannot be requested to testify before any jurisdiction, he cannot be prosecuted, etc. However, the statute of limitation is suspended during his term, and enquiries and prosecutions can be restarted, at the latest one month after he leaves office.
The President is not deemed personally responsible for his actions in his official capacity, except where his actions are indicted before the International Criminal Court or where impeachment is moved against him. Impeachment can be pronounced by the High Court, a special court convened from both houses of Parliament on the proposal of either House, should the president have failed to discharge his duties in a way that evidently precludes the continuation of his term.
Succession and incapacity.
Upon the death, removal, or resignation of the President, the President of the Senate takes over as acting president. Alain Poher is the only person to have served in this temporary position twice. The first time was in 1969 after Charles de Gaulle's resignation and a second time in 1974 after Georges Pompidou's death. It is important to note that, in this situation, the President of the Senate becomes an Acting President of the Republic; He or she does not become the new President of the Republic as elected and therefore does not have to resign from his or her position as President of the Senate. In spite of his title as Acting President of the Republic, Poher is regarded in France as a former President and is listed in the presidents' gallery on the official presidential website. This is in contrast to acting presidents from the Third Republic.
The first round of a new presidential election must be organized no sooner than twenty days and no later than thirty-five days following the vacancy of the presidency. Because fifteen days can separate the first and second rounds of a presidential election, this means that the President of the Senate can only act as President of the Republic for a maximum period of fifty days. During this period of Interim president is not allowed to dismiss the national assembly nor are they allowed to call for a referendum or initiate any constitutional changes.
If there is no acting president of the senate, the powers of the president of the republic are exercised by the "Gouvernement", meaning the Cabinet. This has been interpreted by some constitutional academics as meaning first the Prime Minister and, if he is himself not able to act, the members of the cabinet in the order of the list of the decree that nominated them. This is in fact unlikely to happen, because if the president of the Senate is not able to act, the Senate will normally name a new president of the Senate, that will act as President of the Republic.
During the Third French Republic the President of the Council of Ministers acted as President whenever office was vacant. According to article 7 of the Constitution, if the presidency becomes vacant for any reason, or if the president becomes incapacitated, upon the request of the "gouvernement", the Constitutional Council may rule, by a majority vote, that the presidency is to be temporarily assumed by the President of the Senate. If the Council rules that the incapacity is permanent, the same procedure as for the resignation is applied, as described above.
If the President cannot attend meetings, including meetings of the Council of Ministers, he can ask the Prime Minister to attend in his stead (Constitution, article 21). This clause has been applied by presidents travelling abroad, ill, or undergoing surgery.
Pay and official residences.
The President of the Republic is paid a salary according to a pay grade defined in comparison to the pay grades of the most seniors members of the French Civil Service ("out of scale", "hors échelle", those whose pay grades are known as letters and not as numeric indices). In addition he is paid a residence stipend of 3%, and a function stipend of 25% on top of the salary and residence indemnity. This gross salary and these indemnities are the same as those of the Prime Minister, and are 50% higher than the highest paid to other members of the government, which is itself defined as twice the average of the highest (pay grade G) and the lowest (pay grade A1) salaries in the "out of scale" pay grades. Using the 2008 "out of scale" pay grades this amounts to a monthly pay of 20,963 €, which fits the 19,000 € quoted to the press in early 2008. Using the pay grades starting from 1 July 2009, this amounts to a gross monthly pay of 21,131 €.
The salary and the residence stipend are taxable for income tax.
The official residence and office of the president is the Élysée Palace in Paris. Other presidential residences include:
Former Presidents.
As of , there are three living former Presidents:
According to French law, Former Presidents have guaranteed lifetime pension defined according to the pay grade of the Councillors of State, a courtesy diplomatic passport, and, according to the French Constitution (Article 56), membership of the Constitutional Council.
They also get personnel, an apartment and/or office, and other amenities, though the legal basis for these is disputed. In 2008, according to an answer by the services of the Prime Minister to a question from member of the National Assembly René Dosière, these facilities comprised: a security detail, a car with a chauffeur, office or housing space, maintained by the State. Two people service this space. In addition, the State funds 7 permanent collaborators.
History.
Under the Third and Fourth Republic, which were parliamentary systems, the office of President of the Republic was a largely ceremonial and powerless one.
The constitution of the Fifth Republic greatly increased the President's powers. A 1962 referendum changed the constitution, so that the President would be directly elected by universal suffrage and not by the Parliament.
In 2000, a referendum shortened the presidential term from seven years to five years.
A maximum of two consecutive terms was imposed after the 2008 constitutional reform.

</doc>
<doc id="24900" url="https://en.wikipedia.org/wiki?curid=24900" title="Plastic explosive">
Plastic explosive

Plastic explosive is a soft and hand-moldable solid form of explosive material. Within the field of explosives engineering, plastic explosives are also known as putty explosives.
Plastic explosives are especially suited for explosive demolition. Common plastic explosives include Semtex and C-4.
Usage.
Plastic explosives are especially suited for explosive demolition of obstacles and fortifications by engineers and combat engineers as they can be easily formed into the best shapes for cutting structural members and have a high enough velocity of detonation and density for metal cutting work.
An early use of plastic explosives was in the warhead of the British Armoured Vehicle Royal Engineers's (AVRE)'s Petard demolition mortar, used to destroy concrete fortifications encountered during Operation Overlord (D-Day). The original use of Nobel 808 supplied by the SOE was for sabotage of German installations and railways in Occupied Europe.
They are generally not used for ordinary blasting as they tend to be significantly more expensive than other materials that perform just as well in this application. A common commercial use of plastic explosives is for shock hardening high manganese percentage steel, a material typically used for train rail components and earth digging implements.
Some terrorist groups have used plastic explosives. In October 2000, al-Qa'ida used C-4 to attack the USS "Cole", killing 17 sailors In 1996, terrorists used C-4 to blow up the Khobar Towers U.S. military housing complex in Saudi Arabia.
History.
The first plastic explosive was gelignite, invented by Alfred Nobel in 1875.
Prior to World War I, the British explosives chemist Oswald Silberrad obtained British and U.S. patents for a series of plastic explosives called "Nitrols", composed of nitrated aromatics, collodion, and oxidising inorganic salts. The language of the patents indicate that at this time, Silberrad saw no need to explain to "those versed in the art" either what he meant by plasticity nor why it may be advantageous, as he only explains why his plastic explosive is superior to others of that type.
One of the simplest plastic explosives was Nobel's Explosive No. 808, also known as "Nobel 808" (often just called "Explosive 808" in the British Armed Forces during the Second World War), developed by the British company Nobel Chemicals Ltd well before World War II. It had the appearance of green plasticine with a distinctive smell of almonds. During World War II it was extensively used by the British Special Operations Executive (SOE) for sabotage missions. It is also the explosive used in HESH anti-tank shells and was an essential factor in the devising of the Gammon grenade. Captured SOE-supplied Nobel 808 was the explosive used in the failed 20 July plot assassination attempt on Adolf Hitler in 1944.
During and after World War II a number of new RDX-based explosives were developed, including Compositions C, C2, and eventually C3. Together with RDX these incorporate various plasticisers to decrease sensitivity and make the composition plastic. The origin of the obsolete term "plastique" dates back to the Nobel 808 explosive introduced to the U.S. by the British in 1940. The samples of explosive brought to the U.S. by the Tizard Mission had already been packaged by the SOE ready for dropping via parachute container to the French Resistance and were therefore labelled in French, as "Explosif Plastique". It is still referred to by this name in France and also by some Americans.
C3 was effective but proved to be too brittle in cold weather. In the 1960s it was replaced by C-4, also using RDX but with polyisobutylene and di(2-ethylhexyl)sebacate as the binder and plasticizer. 

</doc>
<doc id="24902" url="https://en.wikipedia.org/wiki?curid=24902" title="Post-structuralism">
Post-structuralism

Post-structuralism is a label formulated by American academics to denote the heterogeneous works of a series of mid-20th-century French and continental philosophers and critical theorists who came to international prominence in the 1960s and 1970s.
Post-structuralism is defined by its relationship to its predecessor, structuralism, an intellectual movement developed in Europe from the early to mid-20th century which argued that human culture may be understood by means of a structure—modeled on language (i.e., structural linguistics)—that differs from concrete reality and from abstract ideas—a "third order" that mediates between the two. Post-structuralist authors all present different critiques of structuralism, but common themes include the rejection of the self-sufficiency of the structures that structuralism posits and an interrogation of the binary oppositions that constitute those structures. Writers whose work is often characterised as post-structuralist include Jacques Derrida, Michel Foucault, Gilles Deleuze, Judith Butler, Jacques Lacan, Jean Baudrillard, and Julia Kristeva, although many theorists who have been called "post-structuralist" have rejected the label.
Existential phenomenology is a significant influence; Colin Davis has argued that post-structuralists might just as accurately be called "post-phenomenologists".
Theory.
Destabilized meaning.
In the post-structuralist approach to textual analysis, the reader replaces the author as the primary subject of inquiry. This displacement is often referred to as the "destabilizing" or "decentering" of the author, though it has its greatest effect on the text itself. Without a central fixation on the author, post-structuralists examine other sources for meaning (e.g., readers, cultural norms, other literature, etc.). These alternative sources are never authoritative, and promise no consistency.
In his essay "Signification and Sense", Emmanuel Levinas remarked on this new field of semantic inquiry:
Deconstruction.
A major theory associated with Structuralism was binary opposition. This theory proposed that there are certain theoretical and conceptual opposites, often arranged in a hierarchy, which human logic has given to text. Such binary pairs could include Enlightenment/Romantic, male/female, speech/writing, rational/emotional, signifier/signified, symbolic/imaginary.
Post-structuralism rejects the notion of the essential quality of the dominant relation in the hierarchy, choosing rather to expose these relations and the dependency of the dominant term on its apparently subservient counterpart. The only way to properly understand these meanings is to deconstruct the assumptions and knowledge systems that produce multiplicity, the illusion of singular meaning.
Post-structuralism and structuralism.
Structuralism was an intellectual movement in France in the 1950s and 1960s that studied the underlying structures in cultural products (such as texts) and used analytical concepts from linguistics, psychology, anthropology, and other fields to interpret those structures. It emphasized the logical and scientific nature of its results.
Post-structuralism offers a way of studying how knowledge is produced and critiques structuralist premises. It argues that because history and culture condition the study of underlying structures, both are subject to biases and misinterpretations. A post-structuralist approach argues that to understand an object (e.g., a text), it is necessary to study both the object itself and the systems of knowledge that produced the object.
Historical vs. descriptive view.
Post-structuralists generally assert that post-structuralism is historical, and they classify structuralism as descriptive. This terminology relates to Ferdinand de Saussure's distinction between the views of historical (diachronic) and descriptive (synchronic) reading. From this basic distinction, post-structuralist studies often emphasize history to analyze descriptive concepts. By studying how cultural concepts have changed over time, post-structuralists seek to understand how those same concepts are understood by readers in the present. For example, Michel Foucault's "Madness and Civilization" is both a history and an inspection of cultural attitudes about madness. The theme of history in modern Continental thought can be linked to such influences as Georg Wilhelm Friedrich Hegel, Friedrich Nietzsche's "On the Genealogy of Morals" and Martin Heidegger's "Being and time.
Scholars between both movements.
The uncertain distance between structuralism and post-structuralism is further blurred by the fact that scholars rarely label themselves as post-structuralists. Some scholars associated with structuralism, such as Roland Barthes, also became noteworthy in post-structuralism. Lévi-Strauss, Lacan, Barthes, and Foucault were the so-called "Gang of Four" of structuralism. All but Lévi-Strauss became prominent post-structuralists. The works of Jacques Derrida, Gilles Deleuze, Michel Foucault and Julia Kristeva are also counted as prominent examples of post-structuralism.
These thinkers sought contradictions in texts that are supposedly inevitable. Those inconsistencies are used to show that the interpretation and criticism of any literature is in the hands of the reader and includes that reader's own cultural biases and assumptions. While many structuralists first thought that they could tease out an author's intention by close scrutiny, they soon argued that textual analysis discovered so many disconnections that it was obvious that their own experiences lent a view that was unique to them.
Some observers from outside the post-structuralist camp have questioned the rigor and legitimacy of the field. American philosopher John Searle argued in 1990 that "The spread of 'poststructuralist' literary theory is perhaps the best known example of a silly but noncatastrophic phenomenon." Similarly, physicist Alan Sokal in 1997 criticized "the postmodernist/poststructuralist gibberish that is now hegemonic in some sectors of the American academy." Literature scholar Norman Holland argued that post-structuralism was flawed due to reliance on Saussure's linguistic model, which was seriously challenged by the 1950s and was soon abandoned by linguists: "Saussure's views are not held, so far as I know, by modern linguists, only by literary critics and the occasional philosopher. adherence to Saussure has elicited wrong film and literary theory on a grand scale. One can find dozens of books of literary theory bogged down in signifiers and signifieds, but only a handful that refer to Chomsky."
History.
Post-structuralism emerged in France during the 1960s as a movement critiquing structuralism. According to J.G. Merquior a love–hate relationship with structuralism developed among many leading French thinkers in the 1960s.
The period was marked by political anxiety, as students and workers alike rebelled against the state in May 1968, nearly causing the downfall of the French government. At the same time, however, the support by the French Communist Party (FCP) for the oppressive policies of the USSR contributed to popular disillusionment with orthodox Marxism. Post-structuralism offered a means to justify these criticisms, by exposing the underlying assumptions of many Western norms.
Two key figures in the early post-structuralist movement were Jacques Derrida and Roland Barthes. In a 1966 lecture "Structure, Sign, and Play in the Discourse of the Human Sciences", Jacques Derrida presented a thesis on an apparent rupture in intellectual life. Derrida interpreted this event as a "decentering" of the former intellectual cosmos. Instead of progress or divergence from an identified centre, Derrida described this "event" as a kind of "play."
Although Barthes was originally a structuralist, during the 1960s he increasingly favored post-structuralist views. In 1967, Barthes published "The Death of the Author" in which he announced a metaphorical event: the "death" of the author as an authentic source of meaning for a given text. Barthes argued that any literary text has multiple meanings, and that the author was not the prime source of the work's semantic content. The "Death of the Author," Barthes maintained, was the "Birth of the Reader," as the source of the proliferation of meanings of the text.
Post-structuralist philosophers like Derrida and Foucault did not form a self-conscious group, but each responded to the traditions of phenomenology and structuralism. Phenomenology, often associated with two German philosophers Edmund Husserl and Martin Heidegger, rejected previous systems of knowledge and attempted to examine life "just as it appears" (as phenomena). Both movements rejected the idea that knowledge could be centred on the human knower, and sought what they considered a more secure foundation for knowledge. In phenomenology, this foundation is experience itself; in structuralism, knowledge is founded on the "structures" that make experience possible: concepts, and language or signs. By contrast, post-structuralism argues that founding knowledge either on pure experience (phenomenology) or systematic structures (structuralism) is impossible. This impossibility was not meant as a failure or loss, but rather as a cause for "celebration and liberation."
Major works.
Barthes and the need for metalanguage.
Although many may have felt the necessity to move beyond structuralism, there was clearly no consensus on how this ought to occur. Much of the study of post-structuralism is based on the common critiques of structuralism. Roland Barthes is of great significance with respect to post-structuralist theory. In his work, "Elements of Semiology" (1967), he advanced the concept of the "metalanguage". A metalanguage is a systematized way of talking about concepts like meaning and grammar beyond the constraints of a traditional (first-order) language; in a metalanguage, symbols replace words and phrases. Insofar as one metalanguage is required for one explanation of first-order language, another may be required, so metalanguages may actually replace first-order languages. Barthes exposes how this structuralist system is regressive; orders of language rely upon a metalanguage by which it is explained, and therefore deconstruction itself is in danger of becoming a metalanguage, thus exposing all languages and discourse to scrutiny. Barthes' other works contributed deconstructive theories about texts.
Derrida's lecture at Johns Hopkins.
The occasional designation of post-structuralism as a movement can be tied to the fact that mounting criticism of structuralism became evident at approximately the same time that structuralism became a topic of interest in universities in the United States. This interest led to a colloquium being held at Johns Hopkins University in 1966 titled "The Languages of Criticism and the Sciences of Man" which saw such French scholars such as Derrida, Barthes, and Lacan invited to speak.
Derrida's lecture at that conference, "Structure, Sign, and Play in the Human Sciences," often appears in collections as a manifesto against structuralism. Derrida's essay was one of the earliest to propose some theoretical limitations to structuralism, and to attempt to theorize on terms that were clearly no longer structuralist.
The element of "play" in the title of Derrida's essay is often erroneously interpreted in a linguistic sense, based on a general tendency towards puns and humour, while social constructionism as developed in the later work of Michel Foucault is said to create a sense of strategic agency by laying bare the levers of historical change. Many see the importance of Foucault's work as in its synthesis of this social/historical account of the operations of power (see governmentality).
See also.
Authors.
The following are often said to be post-structuralists, or to have had a post-structuralist period:

</doc>
<doc id="24903" url="https://en.wikipedia.org/wiki?curid=24903" title="Peace process">
Peace process

Peace process may refer to:

</doc>
<doc id="24905" url="https://en.wikipedia.org/wiki?curid=24905" title="Peyton Randolph">
Peyton Randolph

Peyton Randolph (September 10, 1721 – October 22, 1775) was a planter and public official from the Colony of Virginia. He served as Speaker of the Virginia House of Burgesses, President of Virginia Conventions, and the first President of the Continental Congress.
Early life.
Randolph was born in Tazewell Hall Williamsburg, Virginia to a prominent family. His parents were Sir John Randolph, the son of William Randolph, and Susanna Beverley, the daughter of Peter Beverley; his brother was John Randolph. His father died when he was 16.
Randolph attended the College of William & Mary, and later studied law at Middle Temple at the Inns of Court in London, becoming a member of the bar in 1743.
Political career.
Randolph returned to Williamsburg and was appointed Attorney General of the Colony of Virginia the next year.
He served several terms in the Virginia House of Burgesses, beginning in 1748. It was Randolph's dual roles as attorney general and as burgess that would lead to an extraordinary conflict of interest in 1751.
The new governor, Robert Dinwiddie, had imposed a fee for the certification of land patents, which the House of Burgesses strongly objected to. The House selected Peyton Randolph to represent their cause to Crown authorities in London. In his role as attorney general, though, he was responsible for defending actions taken by the governor. Randolph left for London, over the objections of Governor Dinwiddie, and was replaced for a short time as attorney general by George Wythe. Randolph resumed his post on his return at the behest of Wythe as well as officials in London, who also recommended the Governor drop the new fee.
In 1765 Randolph found himself at odds with a freshman burgess, Patrick Henry, over the matter of a response to the Stamp Act. The House appointed Randolph to draft objections to the act, but his more conservative plan was trumped when Henry obtained passage of five of his seven Virginia Stamp Act Resolutions. This was accomplished at a meeting of the House in which most of the members were absent, and over which Randolph was presiding in the absence of the Speaker.
Randolph resigned as king's attorney (attorney general) in 1766, as fellow Burgesses elected him as their Speaker upon the death of his relative, the powerful Speaker John Robinson. Sitting as the General Court, they also appointed Randolph one of the executors (with George Wythe and Edmund Pendleton) of the former speaker's estate, which was a major financial scandal. As friction between Britain and the colonies progressed, Randolph grew to favor independence. In 1769 the House of Burgesses was dissolved by the Governor, Norborne Berkeley, 4th Baron Botetourt, in response to its actions against the Townshend Acts. In 1773, Randolph chaired the Virginia committee of correspondence. The next Governor, John Murray, 4th Earl of Dunmore, also dissolved the House of Burgesses in 1774 when it showed solidarity with Boston, Massachusetts, following the Boston Port Act. Afterwards, Randolph chaired meetings of the first of five Virginia Conventions of former House members, principally at a Williamsburg tavern, which worked toward responses to the unwelcome tax measures imposed by the British government. On March 21, 1775 he was President of the Second Virginia Convention in Richmond that debated independence (the site of Patrick Henry's famous "give me liberty" speech). In April, Randolph negotiated with Lord Dunmore for gunpowder removed from the Williamsburg arsenal during the Gunpowder Incident, which was a confrontation between the Governor's forces and Virginia militia, led by Patrick Henry. The House of Burgesses was called back by Lord Dunmore one last time in June 1775 to address British Prime Minister Lord North's Conciliatory Resolution. Randolph, who was a delegate to the Continental Congress, returned to Williamsburg to take his place as Speaker. Randolph indicated that the resolution had not been sent to the Congress (it had instead been sent to each colony individually in an attempt to divide them and bypass the Continental Congress). The House of Burgesses rejected the proposal, which was also later rejected by the Continental Congress. Randolph was thus the last Speaker of the House of Burgesses (their role was replaced by the Virginia Conventions and later the House of Delegates in 1776). Randolph also served as the President of the Third Virginia Convention in July 1775, which as a legislative body elected a Committee of Safety to act as the colony's executive since Lord Dunmore had abandoned the capital and took refuge on a British warship. Edmund Pendleton would succeed Randolph as president of the later conventions.
Virginia selected Randolph as one of its delegates to the Continental Congress in Philadelphia in 1774 and 1775. Fellow delegates elected him their President (Speaker) of both the First Continental Congress (which requested that King George III repeal the Coercive Acts) as well as Second Continental Congress (which extended the Olive Branch Petition as a final attempt at reconciliation). However, Randolph fell ill during each term. Henry Middleton of South Carolina succeeded him as President from his resignation on October 22, 1774 until his return on May 10, 1775. Randolph suffered a fit of apoplexy and died in Philadelphia on October 22, eventually succeeded by John Hancock of Massachusetts as President of the Continental Congress.
Death and legacy.
His remains were returned to Williamsburg and were interred at the chapel of the College of William and Mary. Because the Continental Congress assumed governmental duties for the American colonies as a whole, such as appointing ambassadors, some consider Randolph to have been the first President of the United States, even though he died before the Declaration of Independence.
The Continental Congress honored Randolph by naming one of the first naval frigates as the USS "Randolph", as well by naming a fort at the junction of the Ohio and Kanawha Rivers as Fort Randolph.
Randolph County, North Carolina, and Randolph County, Indiana, were named to honor the colonial statesman.
During World War II, the early "Essex"-class aircraft carrier USS "Randolph" (CV-15) was named for him. Furthermore, the Peyton Randolph House in Colonial Williamsburg was declared a National Historic Landmark in 1970.

</doc>
<doc id="24910" url="https://en.wikipedia.org/wiki?curid=24910" title="Product topology">
Product topology

In topology and related areas of mathematics, a product space is the cartesian product of a family of topological spaces equipped with a natural topology called the product topology. This topology differs from another, perhaps more obvious, topology called the box topology, which can also be given to a product space and which agrees with the product topology when the product is over only finitely many spaces. However, the product topology is "correct" in that it makes the product space a categorical product of its factors, whereas the box topology is too fine; this is the sense in which the product topology is "natural".
Definition.
Given "X" such that
is the Cartesian product of the topological spaces "Xi", indexed by formula_2, and the canonical projections "pi" : "X" → "Xi", the product topology on "X" is defined to be the coarsest topology (i.e. the topology with the fewest open sets) for which all the projections "pi" are continuous. The product topology is sometimes called the Tychonoff topology.
The open sets in the product topology are unions (finite or infinite) of sets of the form formula_3, where each "Ui" is open in "Xi" and "U""i" ≠ "X""i" for only finitely many "i". In particular, for a finite product (in particular, for the product of two topological spaces), the products of base elements of the "Xi" gives a basis for the product formula_4.
The product topology on "X" is the topology generated by sets of the form "pi"−1("U"), where "i" is in "I " and "U" is an open subset of "Xi". In other words, the sets {"pi"−1("U")} form a subbase for the topology on "X". A subset of "X" is open if and only if it is a (possibly infinite) union of intersections of finitely many sets of the form "pi"−1("U"). The "pi"−1("U") are sometimes called open cylinders, and their intersections are cylinder sets.
In general, the product of the topologies of each "Xi" forms a basis for what is called the box topology on "X". In general, the box topology is finer than the product topology, but for finite products they coincide.
Examples.
If one starts with the standard topology on the real line R and defines a topology on the product of "n" copies of R in this fashion, one obtains the ordinary Euclidean topology on R"n".
The Cantor set is homeomorphic to the product of countably many copies of the discrete space {0,1} and the space of irrational numbers is homeomorphic to the product of countably many copies of the natural numbers, where again each copy carries the discrete topology.
Several additional examples are given in the article on the initial topology.
Properties.
The product space "X", together with the canonical projections, can be characterized by the following universal property: If "Y" is a topological space, and for every "i" in "I", "fi" : "Y" → "Xi" is a continuous map, then there exists "precisely one" continuous map "f" : "Y" → "X" such that for each "i" in "I" the following diagram commutes:
This shows that the product space is a product in the category of topological spaces. It follows from the above universal property that a map "f" : "Y" → "X" is continuous if and only if "fi" = "pi" o "f" is continuous for all "i" in "I". In many cases it is easier to check that the component functions "fi" are continuous. Checking whether a map "f" : "Y" → "X" is continuous is usually more difficult; one tries to use the fact that the "pi" are continuous in some way.
In addition to being continuous, the canonical projections "pi" : "X" → "Xi" are open maps. This means that any open subset of the product space remains open when projected down to the "Xi". The converse is not true: if "W" is a subspace of the product space whose projections down to all the "Xi" are open, then "W" need not be open in "X". (Consider for instance "W" = R2 \ (0,1)2.) The canonical projections are not generally closed maps (consider for example the closed set formula_5 whose projections onto both axes are R \ {0}).
The product topology is also called the "topology of pointwise convergence" because of the following fact: a sequence (or net) in "X" converges if and only if all its projections to the spaces "X""i" converge. In particular, if one considers the space "X" = R"I" of all real valued functions on "I", convergence in the product topology is the same as pointwise convergence of functions.
Any product of closed subsets of "Xi" is a closed set in "X".
An important theorem about the product topology is Tychonoff's theorem: any product of compact spaces is compact. This is easy to show for finite products, while the general statement is equivalent to the axiom of choice.
Axiom of choice.
The axiom of choice is equivalent to the statement that the product of a collection of non-empty sets is non-empty. The proof is easy enough: one needs only to pick an element from each set to find a representative in the product. Conversely, a representative of the product is a set which contains exactly one element from each component.
The axiom of choice occurs again in the study of (topological) product spaces; for example, Tychonoff's theorem on compact sets is a more complex and subtle example of a statement that is equivalent to the axiom of choice.

</doc>
<doc id="24913" url="https://en.wikipedia.org/wiki?curid=24913" title="Playdia">
Playdia

The (developed under the codename "BA-X") is a home video game console released exclusively in Japan in 1994 at the initial price of ¥24,800. It was intended for a young audience and, like many consoles of the era (e.g. the LaserActive and the 3DO Interactive Multiplayer), was marketed more as a multimedia home entertainment system than as a dedicated gaming console, with anime quiz software and edutainment making up most of the game library. The Playdia uses a single infrared joypad with simple controls. Bandai, the Playdia's manufacturer, was the only software publisher to support this console.

</doc>
<doc id="24915" url="https://en.wikipedia.org/wiki?curid=24915" title="Pidgin">
Pidgin

A pidgin , or pidgin language, is a grammatically simplified means of communication that develops between two or more groups that do not have a language in common: typically, a mixture of simplified languages or a simplified primary language with other languages' elements included. It is most commonly employed in situations such as trade, or where both groups speak languages different from the language of the country in which they reside (but where there is no common language between the groups). Fundamentally, a pidgin is a simplified means of linguistic communication, as it is constructed impromptu, or by convention, between individuals or groups of people. A pidgin is not the native language of any speech community, but is instead learned as a second language. A pidgin may be built from words, sounds, or body language from multiple other languages and cultures. They allow people who have no common language to communicate with each other. Pidgins usually have low prestige with respect to other languages.
Not all simplified or "broken" forms of a language are pidgins. Each pidgin has its own norms of usage which must be learned for proficiency in the pidgin.
Etymology.
The origin of the word is uncertain. "Pidgin" first appeared in print in 1850. The most widely accepted etymology is from a Chinese pronunciation of the English word "business".
Another etymology that has been proposed is English "pigeon", a bird sometimes used for carrying brief written messages, especially in times prior to modern telecommunications.
Terminology.
The word "pidgin", formerly also spelled "pigion", used to refer originally to Chinese Pidgin English, but was later generalized to refer to any pidgin. "Pidgin" may also be used as the specific name for local pidgins or creoles, in places where they are spoken. For example, the name of the creole language Tok Pisin derives from the English words "talk pidgin". Its speakers usually refer to it simply as "pidgin" when speaking English. Likewise, Hawaiian Creole English is commonly referred to by its speakers as "Pidgin".
The term "jargon" has also been used to refer to pidgins, and is found in the names of some pidgins, such as Chinook Jargon. In this context, linguists today use "jargon" to denote a particularly rudimentary type of pidgin; however, this usage is rather rare, and the term "jargon" most often refers to the words particular to a given profession.
Pidgins may start out as or become trade languages, such as Tok Pisin. Trade languages can eventually evolve into fully developed languages in their own right such as Swahili, distinct from the languages they were originally influenced by. Trade languages and pidgins can also influence an established language's vernacular, especially amongst people who are directly involved in a trade where that pidgin is commonly used, which can alternatively result in a regional dialect being developed.
Common traits among pidgin languages.
Pidgins are usually less morphologically complex but more syntactically rigid than other languages, usually have less morphosyntactic irregularities than other languages, and often consist of:
Pidgin development.
The initial development of a pidgin usually requires:
Keith Whinnom (in ) suggests that pidgins need three languages to form, with one (the superstrate) being clearly dominant over the others.
Linguists sometimes posit that pidgins can become creole languages when a generation of children learn a pidgin as their first language,
a process that regularizes speaker-dependent variation in grammar. Creoles can then replace the existing mix of languages to become the native language of a community (such as the Chavacano language in the Philippines, Krio in Sierra Leone, and Tok Pisin in Papua New Guinea). However, not all pidgins become creole languages; a pidgin may die out before this phase would occur (e.g. the Mediterranean Lingua Franca).
Other scholars, such as Salikoko Mufwene, argue that pidgins and creoles arise independently under different circumstances, and that a pidgin need not always precede a creole nor a creole evolve from a pidgin. Pidgins, according to Mufwene, emerged among trade colonies among "users who preserved their native vernaculars for their day-to-day interactions". Creoles, meanwhile, developed in settlement colonies in which speakers of a European language, often indentured servants whose language would be far from the standard in the first place, interacted extensively with non-European slaves, absorbing certain words and features from the slaves' non-European native languages, resulting in a heavily basilectalized version of the original language. These servants and slaves would come to use the creole as an everyday vernacular, rather than merely in situations in which contact with a speaker of the superstrate was necessary.
List of pidgins.
The following pidgins have Wikipedia articles or sections in articles. They are only a fraction of the pidgins of the world. 

</doc>
<doc id="24916" url="https://en.wikipedia.org/wiki?curid=24916" title="Polish">
Polish

Polish may refer to:
Polish may refer to:

</doc>
<doc id="24918" url="https://en.wikipedia.org/wiki?curid=24918" title="People's Liberation Army Navy">
People's Liberation Army Navy

The People's Liberation Army Navy (PLAN), also known as the PLA Navy, is the naval warfare branch of the People's Liberation Army, the armed wing of the Communist Party of China and by default, the national armed force of the People's Republic of China. The PLAN can trace its lineage to naval units fighting during the Chinese Civil War and was established in September 1950. Throughout the 1950s and early 1960s the Soviet Union provided assistance to the PLAN in the form of naval advisers and export of equipment and technology. Until the late 1980s, the PLAN was largely a riverine and littoral force (brown-water navy). However, by the 1990s, following the fall of the Soviet Union and a shift towards a more forward-oriented foreign and security policy, the leaders of the Chinese military were freed from worrying over land border disputes, and instead turned their attention towards the seas. This led to the development of the People's Liberation Army Navy into a green-water navy by 2009. Before the 1990s the PLAN had traditionally played a subordinate role to the People's Liberation Army Ground Force.
In 2008, General Qian Lihua confirmed that China plans to operate a small fleet of aircraft carriers in the near future, but for the purpose of regional defence as opposed to "global reach". As of 2013 PLA officials have also outlined plans to operate in the first and second island chains. Chinese strategists term the development of the PLAN from a green-water navy into "a regional blue-water defensive and offensive navy."
The People's Liberation Army Navy is composed of five branches; the People's Liberation Army Navy Submarine Force, the People's Liberation Army Navy Surface Force, the People's Liberation Army Navy Coastal Defense Force, the People's Liberation Army Marine Corps and the People's Liberation Army Naval Air Force. With a personnel strength of 255,000 servicemen and women, including 10,000 marines and 26,000 naval air force personnel, it is the second largest navy in the world in terms of tonnage, behind only the United States Navy, and has the largest number of major combatants of any navy.
History.
The PLAN traces its lineage to units of the Republic of China Navy who defected to the People's Liberation Army towards the end of the Chinese Civil War. In 1949, Mao Zedong asserted that "to oppose imperialist aggression, we must build a powerful navy". During the Landing Operation on Hainan Island, the communists used wooden junks fitted with mountain guns as both transport and warships against the Republic of China Navy. The Naval Academy was set up at Dalian on 22 November 1949, mostly with Soviet instructors. The navy was established in September 1950 by consolidating regional naval forces under General Staff Department command in Jiangyan, now in Taizhou, Jiangsu province. It then consisted of a motley collection of ships and boats acquired from the Kuomintang forces. The Naval Air Force was added two years later. By 1954 an estimated 2,500 Soviet naval advisers were in China—possibly one adviser to every thirty Chinese naval personnel—and the Soviet Union began providing modern ships. With Soviet assistance, the navy reorganized in 1954 and 1955 into the North Sea Fleet, East Sea Fleet, and South Sea Fleet, and a corps of admirals and other naval officers was established from the ranks of the ground forces. In shipbuilding the Soviets first assisted the Chinese, then the Chinese copied Soviet designs without assistance, and finally the Chinese produced vessels of their own design. Eventually Soviet assistance progressed to the point that a joint Sino-Soviet Pacific Ocean fleet was under discussion.
1950s and 1960s.
Through the upheavals of the late 1950s and 1960s the Navy remained relatively undisturbed. Under the leadership of Minister of National Defense Lin Biao, large investments were made in naval construction during the frugal years immediately after the Great Leap Forward. During the Cultural Revolution, a number of top naval commissars and commanders were purged, and naval forces were used to suppress a revolt in Wuhan in July 1967, but the service largely avoided the turmoil affecting the country. Although it paid lip service to Mao and assigned political commissars aboard ships, the Navy continued to train, build, and maintain the fleets as well the coastal defense and aviation arms, as well as in the performance of its mission.
1970s and 1980s.
In the 1970s, when approximately 20 percent of the defense budget was allocated to naval forces, the Navy grew dramatically. The conventional submarine force increased from 35 to 100 boats, the number of missile-carrying ships grew from 20 to 200, and the production of larger surface ships, including support ships for oceangoing operations, increased. The Navy also began development of nuclear attack submarines (SSN) and nuclear-powered ballistic missile submarines (SSBN).
In the 1980s, under the leadership of Chief Naval Commander Liu Huaqing, the navy developed into a regional naval power, though naval construction continued at a level somewhat below the 1970s rate. Liu Huaqing was an Army Officer who spent most of his career in administrative positions involving science and technology. It was not until 1988 that the People's Liberation Army Navy was led by a Naval Officer. Liu was also very close to Deng Xiaoping as his modernization efforts were very much in keeping with Deng's national policies. While under his leadership Naval construction yards produced fewer ships than the 1970s, greater emphasis was placed on technology and qualitative improvement. Modernization efforts also encompassed higher educational and technical standards for personnel; reformulation of the traditional coastal defense doctrine and force structure in favor of more green-water operations; and training in naval combined-arms operations involving submarine, surface, naval aviation, and coastal defense forces. Examples of the expansion of China's capabilities were the 1980 recovery of an intercontinental ballistic missile (ICBM) in the Western Pacific by a twenty-ship fleet, extended naval operations in the South China Sea in 1984 and 1985, and the visit of two naval ships to three South Asian nations in 1985. In 1982 the navy conducted a successful test of an underwater-launched ballistic missile. The navy also had some success in developing a variety of surface-to-surface and air-to-surface missiles, improving basic capabilities.
In 1986 the Navy's order of battle included two "Xia"-class SSBNs armed with twelve CSS-N-3 missiles and three Han-class SSNs armed with six SY-2 cruise missiles. In the late 1980s, major deficiencies reportedly remained in antisubmarine warfare, mine warfare, naval electronics (including electronic countermeasures equipment), and naval aviation capabilities.
The PLA Navy was ranked in 1987 as the third largest navy in the world, although naval personnel had comprised only 12 percent of PLA strength. In 1987 the Navy consisted (as it does now) of the naval headquarters in Beijing; three fleet commands – the North Sea Fleet, based at Qingdao, Shandong; the East Sea Fleet, based at Ningbo; and the South Sea Fleet, based at Zhanjiang, Guangdong – and about 2,000 ships. The 350,000-person Navy included Naval Air Force units of 34,000 men, the Coastal Defense Forces of 38,000, and the Marine Corps of 56,500. Navy Headquarters, which controlled the three fleet commands, was subordinate to the PLA General Staff Department. In 1987, China's 1,500 km coastline was protected by more than 100 diesel-powered Romeo- and Whiskey-class submarines, which could remain at sea only a limited time. Inside this protective ring and within range of shore-based aircraft were destroyers and frigates mounting Styx anti-ship missiles, depth-charge projectors, and guns up to 130 mm. Any invader penetrating the destroyer and frigate protection would have been swarmed by almost 900 fast-attack craft. Stormy weather limited the range of these small boats, however, and curtailed air support. Behind the inner ring were Coastal Defense Force personnel operating naval shore batteries of Styx missiles and guns, backed by ground force units deployed in depth.
Into the 21st century.
As the 21st century approached, the PLAN began to transition to an off-shore defensive strategy that entailed more out-of-area operations away from its traditional territorial waters. Between 1989 and 1993, the training ship "Zhenghe" paid ports visits to Hawaii, Thailand, Bangladesh, Pakistan, and India. PLAN vessels visited Vladivostok in 1993, 1994, 1995, and 1996. PLAN task groups also paid visits to Indonesia in 1995; North Korea in 1997; New Zealand, Australia, and the Philippines in 1998; Malaysia, Tanzania, South Africa, the United States, and Canada in 2000; and India, Pakistan, France, Italy, Germany, Britain, Hong Kong, Australia, and New Zealand in 2001. In March 1997, the "Luhu"-class guided missile destroyer "Harbin", the "Luda"-class guided missile destroyer "Zhuhai", and the replenishment oiler "Nancang" began the PLA Navy's first circumnavigation of the Pacific Ocean, a 98-day voyage with port visits to Mexico, Peru, Chile, and the United States, including Pearl Harbor and San Diego. The flotilla was under the command of Vice Admiral Wang Yongguo, the commander-in-chief of the South Sea Fleet.
The "Luhu"-class guided missile destroyer "Qingdao" and the replenishment oiler "Taicang" completed the PLA Navy's first circumnavigation of the world "(pictured)", a 123-day voyage covering between 15 May – 23 September 2002. Port visits included Changi, Singapore; Alexandria, Egypt; Aksis, Turkey; Sevastopol, Ukraine; Piraeus, Greece; Lisbon, Portugal; Fortaleza, Brazil; Guayaquil, Ecuador; Callao, Peru; and Papeete in French Polynesia. The PLA naval vessels participated in naval exercises with the French frigates "Nivôse" and "Prairial", as well as exercises with the Peruvian Navy. The flotilla was under the command of Vice Admiral Ding Yiping, the commander-in-chief of the North Sea Fleet, and Captain Li Yujie was the commanding officer of the "Qingdao". Overall, between 1985 and 2006, PLAN naval vessels visited 18 Asian-Pacific nations, 4 South American nations, 8 European nations, 3 African nations, and 3 North American nations. In 2003, the PLAN conducted its first joint naval exercises during separate visits to Pakistan and India. Bi-lateral naval exercises were also carried out with exercises with the French, British, Australian, Canadian, Philippine, and United States navies.
On 26 December 2008, the PLAN dispatched a task group consisting of the guided missile destroyer "Haikou" (flagship), the guided missile destroyer "Wuhan", and the supply ship "Weishanhu" to the Gulf of Aden to participate in anti-piracy operations off the coast of Somalia. A team of 16 Chinese Special Forces members from its Marine Corps armed with attack helicopters were on board. Since then, China has maintained a three-ship flotilla of two warships and one supply ship in the Gulf of Aden by assigning ships to the Gulf of Aden on a three monthly basis. Other recent PLAN incidents include the 2001 Hainan Island incident, a major submarine accident in 2003, and naval incidents involving the U.S. MSC-operated ocean surveillance ships and during 2009. At the occasion of the 60th anniversary of the PLAN, 52 to 56 vessels were shown in manoeuvres off Qingdao in April 2009 including previously unseen nuclear submarines. The demonstration was seen as a sign of the growing status of China, while the CMC Chairman, Hu Jintao, indicated that China is neither seeking regional hegemony nor entering an arms race. Predictions by Western analysts that the PLAN would outnumber the USN submarine force as early as 2011 have failed to come true because the PRC curtailed both imports and domestic production of submarines.
Between 5–12 July 2013, a seven-ship task force from the Northern Fleet joined warships from the Russian Pacific Fleet to participate in Joint Sea 2013, bilateral naval maneuvers held in the Peter the Great Bay of the Sea of Japan. To date, Joint Sea 2013 was the largest naval drills yet undertaken by the People's Liberation Army Navy with a foreign navy.
On 2 April 2015, during the violent aftermath of a coup d'état in Yemen and amid an international bombing campaign, the PLAN helped 10 countries get their citizens out of Yemen safely, evacuating them aboard a missile frigate from the besieged port city of Aden. The operation was described by Reuters as "the first time that China's military has helped other countries evacuate their people during an international crisis".
PRC military expert Yin Zhuo has said that due to present weaknesses in the PLAN's ability to replenish their ships at sea, their future aircraft carriers will be forced to operate in pairs.
Beginning in 2009, China orders 4 Zubr-class LCAC from Ukraine and bought 4 more from the Hellenic Navy (Greece). These hovercrafts/LCACs were viewed to be a direct threat to Taiwan's pro-independence movement as well as the conflict over Diaoyu Islands. China is continually shifting the power balance in Asia by building up its military. These machines are built to send troops and armored vehicles (tanks, etc.) onto beaches in a fast manner, acting as a landing craft.
Organization.
The PLAN is organized into several departments for purposes of command, control and coordination. Main operating forces are organized into fleets, each with its own headquarters, a commander (a Rear Admiral or Vice Admiral) and a Political Commisar. All PLAN headquarters are subordinate to the PLA General Staff Department and the Chairman of the Central Military Committee.
Fleets.
The People's Liberation Army Navy is divided into three fleets:
Each fleet consists of surface forces (destroyers, frigates, amphibious vessels etc.), submarine forces, coastal defence units, and aircraft.
Branches.
PLAN Submarine Force.
The People's Liberation Army Navy Submarine Force is one of five branches in the navy and consists of all submarines both nuclear-powered and conventionally-powered in service with the PLAN. They are organised into flotillas spread across the three main fleets.
The PRC plans to be the last of the permanent members of the United Nations Security Council to conduct an operational ballistic missile submarine patrol.
PLAN Surface Force.
The People's Liberation Army Surface Force is one of five branches in the navy and consists of all surface warfare ships in service with the PLAN. They are organised into flotillas spread across the three main fleets.
PLAN Coastal Defence Force.
The PLAN Coastal Defence Force is a land-based fighting force and branch of the PLAN with a strength of around 25,000 personnel. Also known as the coastal defense troops, they serve to defend China's coastal areas from invasion via amphibious landings or air-attack. Throughout the 1960s to 1980s, the Coastal Defense Force was focused on defending China's coast from a possible Soviet sea-borne invasion. With the fall of the Soviet Union, the threat of an amphibious invasion of China has diminished and therefore the branch is often considered to no-longer to be a vital component of the PLAN. Especially as the surface warships of the PLAN continue to improve in terms of anti-ship and air-defence capabilities.
Today the primary weapons of the coastal defense troops are the HY-2, YJ-82, and C-602 anti-ship missiles.
PLA Marine Corps.
The PLA Marine Corps was originally established in the 1950s and then re-established in 1979 under PLAN organisation. It consists of around 12,000 marines organised into two 6000-man brigades and is based in the South China Sea with the South Sea Fleet. The Marine Corps are considered elite troops, and are rapid mobilization forces trained primarily in amphibious warfare and as Paratroopers to establish a beachhead or act as a fighting spearhead during operations against enemy targets. The marines are equipped with the standard Type 95 Assault Rifle as well as other small arms and personnel equipment, and a blue/littoral camouflage uniform as standard. The marines are also equipped with armoured fighting vehicles (including amphibious light tanks such as the Type 63), artillery, and anti-aircraft artillery systems and short range surface-to-air missiles.
With the PLAN's accelerating efforts to expand its capabilities beyond territorial waters, it would be likely for the Marine Corps to play a greater role in terms of being an offshore expeditionary force similar to the USMC and Royal Marines.
PLA Naval Air Force.
The People's Liberation Army Naval Air Force is the "air force" of the PLAN and has a strength of around 25,000 personnel and 690 aircraft. It operates similar aircraft to the People's Liberation Army Air Force, including fighter aircraft, bombers, strike aircraft, tankers, reconnaissance aircraft, electronic warfare aircraft, maritime patrol aircraft, transport aircraft, and helicopters of various roles. The PLA Naval Air Force has traditionally received older aircraft than the PLAAF and has taken less ambitious steps towards mass modernization. Advancements in new technologies, weaponry and aircraft acquisition were made after 2000. With the introduction of China's first aircraft carrier, Liaoning the Naval Air Force is for the first time conducting aircraft carrier operations. Naval Air Bases includes:
Relationship with other maritime organisations of China.
The PLAN is complemented by paramilitary maritime services such as the China Coast Guard. The Chinese Coast Guard was previously not under an independent command, considered part of the armed police, under the local (provincial) border defense force command, prior to its reorganization and consolidation as an unified service. It was formed from the integration of several formerly separate services (such as China Marine Surveillance (CMS), Hai Guang, People's Armed Police and sea militia). The CMS performed mostly coastal and ocean search and rescue or patrols. The CMS received quite a few large patrol ships that significantly enhanced their operations, while Hai Guang, militia, police and other services operated hundreds of small patrol craft. For maritime patrol services, these craft are usually quite well armed with machine guns and 37mm antiaircraft guns. In addition, these services operated their own small aviation units to assist their maritime patrol capabilities, with Hai Guang and CMS operating a handful of Harbin Z-9 helicopters, and a maritime patrol aircraft based on the Harbin Y-12 STOL transport.
Every coastal province has 1 to 3 Coast Guard squadrons:
Ranks.
The ranks in the People's Liberation Army Navy are similar to those of the People's Liberation Army Ground Force. The current system of officer ranks and insignia dates from 1988 and is a revision of the ranks and insignia used from 1955 to 1965. The rank of Hai Jun Yi Ji Shang Jiang (First Class Admiral) was never held and was abolished in 1994. With the official introduction of the Type 07 uniforms all officer insignia are on either shoulders or sleeves depending on the type of uniform used. The current system of enlisted ranks and insignia dates from 1998.
Today.
Strategy, plans, priorities.
The People's Liberation Army Navy has become more prominent in recent years owing to a change in Chinese strategic priorities. The new strategic threats include possible conflict with the United States and/or a resurgent Japan in areas such as the Taiwan Strait or the South China Sea. As part of its overall program of naval modernization, the PLAN has a long-term plan of developing a blue water navy. Robert D. Kaplan has said that it was the collapse of the Soviet Union that allowed China to transfer resources from its army to its navy and other force projection assets. China is constructing a major underground nuclear submarine base near Sanya, Hainan. In December 2007 the first Type 094 submarine was moved to Sanya.
The Daily Telegraph on 1 May 2008 reported that tunnels were being built into hillsides which could be capable of hiding up to 20 nuclear submarines from spy satellites. According to the Western news media the base is reportedly to help China project seapower well into the Pacific Ocean area, including challenging United States naval power.
During a 2008 interview with the BBC, Major General Qian Lihua, a senior Chinese defense official, stated that the PLAN aspired to possess a small number of aircraft carriers to allow it to expand China's air defense perimeter. According to Qian the important issue was not whether China had an aircraft carrier, but what it did with it. On 13 January 2009, Adm. Robert F. Willard, head of the U.S. Pacific Command, called the PLAN's modernization "aggressive," and that it raised concerns in the region. On 15 July 2009, Senator Jim Webb of the Senate Foreign Relations Committee declared that only the "United States has both the stature and the national power to confront the obvious imbalance of power that China brings" to situations such as the claims to the Spratly and Paracel islands.
Ronald O'Rourke of the Congressional Research Service wrote that the PLAN "continues to exhibit limitations or weaknesses in several areas, including capabilities for sustained operations by larger formations in distant waters, joint operations with other parts of China’s military, C4ISR systems, anti-air warfare (AAW), antisubmarine warfare (ASW), MCM, and a dependence on foreign suppliers for certain key ship components." In 1998 China purchased the discarded Ukrainian ship Varyag and began retrofitting it for naval deployment. On 25 September 2012, the People's Liberation Army Navy took delivery of China's first aircraft carrier, the Liaoning. The 60,000 ton ship can accommodate 33 fixed wing aircraft. It is widely speculated that these aircraft will be the J15 fighter (the Chinese version of Russia's SU-33).
In September 2015, satellite images showed that China may have started constructing its first indigenous carrier, At the time, the layout suggested a hull to have a length of about 240 m and a beam of about 35 m. The incomplete bow suggests a length of at least 270 m for the completed hull.
Japan has raised concerns about the PLAN's growing capability and the lack of transparency as its naval strength keeps on expanding. China has reportedly entered into service the world's first anti-ship ballistic missile called DF-21D. The potential threat from the DF-21D against U.S. aircraft carriers has reportedly caused major changes in U.S. strategy.
Territorial disputes.
Spratly Islands dispute.
The Spratly Islands dispute is a territorial dispute over the ownership of the Spratly Islands, a group of islands located in the South China Sea. States staking claims to various islands are Brunei, Malaysia, the Philippines, Taiwan, Vietnam, and People's Republic of China. All except Brunei occupy some of the islands in dispute. The People's Republic of China conducted naval patrols in the Spratly Islands and established a permanent base.
On 14 March 1988, Chinese and Vietnamese naval forces clashed over Johnson South Reef in the Spratly Islands, which involved three PLAN frigates/
In February 2011, the Chinese frigate "Dongguan" fired three shots at Philippine fishing boats in the vicinity of Jackson atoll. The shots were fired after the frigate instructed the fishing boats to leave, and one of those boats experienced trouble removing its anchor. In May 2011, the Chinese patrol boats attacked and cut the cable of Vietnamese oil exploration ships near Spratly islands. The incidence sparked several anti-China protests in Vietnam. In June, the Chinese navy conducted three days of exercises, including live fire drills, in the disputed waters. This was widely seen as a warning to Vietnam, which had also conducted live fire drills near the Spratly Islands. Chinese patrol boats fired repeated rounds at a target on an apparently uninhabited island, as twin fighter jets streaked in tandem overhead. 14 vessels participated in the maneuvers, staging antisubmarine and beach landing drills aimed at "defending atolls and protecting sea lanes."
In May 2013, the Chinese navy's three operational fleets deployed together for the first time since 2010. This combined naval maneuvers in the South China Sea coincided with the ongoing Spratly Islands dispute between China and the Philippines as well as deployment of the U.S. Navy's Carrier Strike Group Eleven to the U.S. Seventh Fleet.
Senkaku Islands (Diaoyu) dispute.
The Senkaku Islands dispute concerns a territorial dispute over a group of uninhabited islands known as the Diaoyu Islands in China, the Senkaku Islands in Japan, and Tiaoyutai Islands in Taiwan. Aside from a 1945 to 1972 period of administration by the United States, the archipelago has been controlled by Japan since 1895. The People's Republic of China disputed the proposed U.S. handover of authority to Japan in 1971. and has asserted its claims to the islands since that time. Taiwan also has claimed these islands. The disputed territory is close to key shipping lanes and rich fishing grounds, and it may have major oil reserves in the area.
On some occasions, ships and planes from various Mainland Chinese and Taiwanese government and military agencies have entered the disputed area. In addition to the cases where they escorted fishing and activist vessels, there have been other incursions. In an eight-month period in 2012, over forty maritime incursions and 160 aerial incursions occurred. For example, in July 2012, three Chinese patrol vessels entered the disputed waters around the islands.
Military escalation continued in 2013. In February, Japanese Defense Minister Itsunori Onodera claimed that a Chinese frigate had locked weapons-targeting radar onto a Japanese destroyer and helicopter on two occasions in January. A Chinese Jiangwei II class frigate and a Japanese destroyer were three kilometers apart, and the crew of the latter vessel went to battle stations. The Chinese state media responded that their frigates had been engaged in routine training at the time.</ref> In late February 2013, U.S. intelligence detected China moving road-mobile ballistic missiles closer to the coast near the disputed islands, including medium-range DF-16 anti-ship ballistic missiles. In May, a flotilla of Chinese warships from its North Sea Fleet deployed from Qingdao for training exercises western North Pacific Ocean. It is not known if this deployment is related to the ongoing islands dispute between China and Japan.
Other incidents.
On 22 July 2011, following its Vietnam port-call, the Indian amphibious assault vessel was reportedly contacted 45 nautical miles from the Vietnamese coast in the disputed South China Sea by a party identifying itself as the Chinese Navy and stating that the Indian warship was entering Chinese waters. According to a spokesperson for the Indian Navy, since there were no Chinese ships or aircraft were visible, the INS "Airavat" proceeded on her onward journey as scheduled. The Indian Navy further clarified that "here was no confrontation involving the INS "Airavat". India supports freedom of navigation in international waters, including in the South China Sea, and the right of passage in accordance with accepted principles of international law. These principles should be respected by all."
On 11 July 2012, the Chinese frigate "Dongguan" ran aground on Hasa Hasa Shoal ("pictured") located 60 nmi west of Rizal, which was within the Philippines' 200 nmi-EEZ. By 15 July, the frigate had been refloated and was returning to port with no injuries and only minor damage. During this incident, the 2012 ASEAN summit took place in Phnom Penh, Cambodia, amid the rising regional tensions.
Support for North Korea.
In July 2010, all three operational fleets of the Chinese Navy operated together in the South China Sea. This combined fleet deployment was in response to the bi-lateral naval maneuvers of the United States Seventh Fleet and the South Korean Navy following the sinking of a South Korean frigate by North Korea in March 2010.
2008 anti-piracy operations.
On 18 December 2008, Chinese authorities deployed People's Liberation Army Navy vessels to escort Chinese shipping in the Gulf of Aden. This deployment came after a series of attacks and attempted hijackings on Chinese vessels by Somali pirates. Reports suggest two destroyers (Type 052C 171 Haikou and Type 052B 169 Wuhan) and a supply ship are the ones being used. This move was welcomed by the international community as the warships complement a multinational fleet already operating along the coast of Africa. Since this operation PLAN has sought the leadership of the ‘Shared Awareness and Deconfliction (SHADE)' body, which would require an increase in the number of ships contributing to the anti-piracy fleet. This is the first time Chinese warships have deployed outside the Asia-Pacific region for a military operation since Zheng He's expeditions in the 15th century.
Since then more than 30 People's Liberation Army Navy ships has deployed to the Gulf of Aden in 18 Escort Task Groups.
Libyan civil war.
In the lead-up to the Libyan Civil War, the "Xuzhou" (530) was deployed from anti-piracy operations in the Gulf of Aden to help evacuate Chinese nationals from Libya.
Yemen Conflict.
In the current Yemen conflict, the Chinese Navy diverted their anti-piracy frigates from Somalia to evacuate at least over 600 Chinese and 225 foreign citizen working in Yemen, the non-Chinese evacuees are 176 Pakistani citizen and smaller numbers from other countries, including Ethiopia, Singapore, the UK, Italy and Germany. The Chinese embassy in Yemen is still in operation.
Equipment.
Naval Weaponry.
The unique QBS-06 is an underwater assault rifle with 5.8x42 DBS-06, and is used by Naval frogmen. It is based off of the Soviet APS.
Future of the People's Liberation Army Navy.
The PLAN's ambitions include operating out to the first and second island chains, as far as the South Pacific near Australia, and spanning to the Aleutian islands, and operations extending to the Straits of Malacca near the Indian Ocean. The future PLAN fleet will be composed of a balance of combatant assets aimed at maximising the PLAN's fighting effectiveness. On the high end, there would be modern destroyers equipped with long-range air defense missiles (Type 052B, Type 052C, Type 052D, Type 051C and Type 055); destroyers armed with supersonic anti-ship missiles ("Sovremenny" class); advanced nuclear-powered attack and ballistic missile submarines (Type 093, Type 095, Type 094, Type 096); advanced conventional attack submarines ("Kilo" and "Yuan" classes); aircraft carriers and large amphibious warfare vessels capable of mobilizing troops at long distances. On the medium and low end, there would be more economical multi-role capable frigates and destroyers ("Luhu", "Jiangwei II" and "Jiangkai" classes); corvettes ("Jiangdao" class); fast littoral missile attack craft ("Houjian", "Houxin" and "Houbei" classes); various landing ships and light craft; and conventionally powered coastal patrol submarines ("Song" class). The obsolete combat ships (based on 1960s designs) will be phased out in the coming decades as more modern designs enter full production. It may take a decade for the bulk of these older ships to be retired. Until then, they will serve principally on the low end, as multi-role patrol/escort platforms. Their use could be further enhanced in the future by being used as fast transports or fire support platforms. This system of phasing out would see a reversal in the decline in quantity of PLAN vessels by 2015, and cuts in inventory after the end of the Cold War could be made up for by 2020.
During 2001–2006 there has been a rapid building and acquisition program. There were more than a dozen new classes of ships built in these last five years, totaling some 60 brand new ships (including landing ships and auxiliaries). Simultaneously, dozens of other ships have been either phased out of service or refitted with new equipment. Submarines play a significant role in the development of the PLAN's future fleet. This is made evident by the construction of a new type of nuclear ballistic missile submarine, the Type 094 and the Type 093 nuclear attack submarine. This will provide the PLAN with a more modern response for the need of a seaborne nuclear deterrent. The new submarines will also be capable of performing conventional strike and other special warfare requirements.
The European Union has provided much of the propulsion technology for the PLAN's modernization.
Ronald O'Rourke of the Congressional Research Service reported that the long-term goals of PLAN planning include:
During the military parade on the 60th anniversary of the People's Republic of China, the YJ-62 naval cruise missile made its first public appearance; the YJ-62 represents the next generation in naval weapons technology in the PLA.
A Chinese website stated that the PLAN is going to build a 110,000 ton aircraft carrier, essentially a larger version of the "Liaoning".
The PLA Navy plans to establish three aircraft carrier battle groups by 2020. The Liaoning and China's first domestically built carrier, currently under construction, will be part of the battle groups. One of the battle groups is to be deployed in the East China Sea, while the other two are to be deployed to the South China Sea.
The PLAN may also operate from Gwadar or Seychelles for anti-piracy missions and to protect vital trade routes which may endanger China's energy security in the case of a conflict.

</doc>
<doc id="24921" url="https://en.wikipedia.org/wiki?curid=24921" title="Patrick Macnee">
Patrick Macnee

Daniel Patrick Macnee (6 February 1922 – 25 June 2015), known professionally as Patrick Macnee, was a British-American actor. He was best known for his role as the secret agent John Steed in the British television series "The Avengers."
Early life and career.
The elder of two sons, Macnee was born in Paddington, London in 1922 to Daniel Macnee (1877-1952) and Dorothea Mary Hastings (1896-1984). His father trained race horses in Lambourn, and was known for his dress sense; he had served as an officer in the Yorkshire Dragoons in the First World War. His maternal grandmother was Frances Alice Hastings (1870-1945), who was the daughter of Vice-Admiral George Fowler Hastings and granddaughter of Hans Francis Hastings, 12th Earl of Huntingdon. His younger brother James, known as Jimmy, was born five years later.
Macnee's parents divorced after his mother began to identify as a lesbian. His father later moved to India, and his mother began to live with her wealthy partner, Evelyn Spottswood, whose money came from the Dewar's whisky business. Macnee referred to her in his autobiography as "Uncle Evelyn", and she helped pay for his schooling. He was educated at Summer Fields School and Eton College, where he was a member of the Officer Training Corps and was one of the guard of honour for King George V at St George's Chapel in 1936. He was later expelled from Eton for selling pornography and being a bookmaker for his fellow students.
Macnee studied acting at the Webber Douglas Academy of Dramatic Art, but shortly before he was to perform in his first West End leading role, which would have had him acting alongside Vivien Leigh, he was called up for the United Kingdom Armed Forces. He joined the Royal Navy as an ordinary seaman in October 1942 and was commissioned a sub-lieutenant in June 1943, becoming a navigator on Motor Torpedo Boats in the English Channel and North Sea. Reassigned as first lieutenant on a second MTB, Macnee caught bronchitis just before D-Day; while he was recuperating in hospital, his boat and crew were lost in action. Two of the crew received the Distinguished Service Medal. He left the Navy in 1946 as a lieutenant.
Macnee nurtured his acting career in Canada early on, but he also appeared as an uncredited extra in the British films "Pygmalion" (1938), "The Life and Death of Colonel Blimp" (1943) and Laurence Olivier's "Hamlet" (1948), as well as some live TV dramas for the BBC, before graduating to credited parts in such films as "Scrooge" (US: "A Christmas Carol", 1951), as the young Jacob Marley, the Gene Kelly vehicle "Les Girls" (1957), as an Old Bailey barrister, and the war film "The Battle of the River Plate" (1956). Between these occasional movie roles, Macnee spent the better part of the 1950s working in dozens of small parts in American and Canadian television and theatre, including an appearance in an episode of "The Twilight Zone" in 1959 ("Judgment Night"). Disappointed in his limited career development, in the late 1950s Macnee was daily smoking 80 cigarettes and drinking a bottle of whisky.
Not long before his career-making role in "The Avengers", Macnee took a break from acting and served as one of the London-based producers for the classic documentary series "The Valiant Years", based on the Second World War memoirs of Winston Churchill.
"The Avengers".
While working in London on the Churchill series, Macnee was offered the part in "The Avengers" (1961−69), (originally intended to be known as Jonathan Steed), for which he became best known. The series was originally conceived as a vehicle for Ian Hendry, who played the lead role of Dr. David Keel in a sequel to an earlier series, "Police Surgeon" (1960), while John Steed was his assistant. Macnee, though, became the lead after Hendry's departure at the end of the first season. Macnee played opposite a succession of glamorous female partners; Honor Blackman, Diana Rigg, and Linda Thorson.
Although Macnee evolved in the role as the series progressed, the key elements of Steed's persona and appearance were there from very early on: the slightly mysterious demeanour and, increasingly, the light, suave, flirting tone with ladies (and always with his female assistants). Finally, from the episodes with Blackman onwards, the trademark bowler hat and umbrella completed the image. Though it was traditionally associated with London "city gents", the ensemble of suit, umbrella and bowler had developed in the post-war years as mufti for ex-servicemen attending Armistice Day ceremonies. Steed's sartorial style may also have been drawn from Macnee's father. Macnee, alongside designer Pierre Cardin, adapted the look into a style all his own, and he went on to design several outfits himself for Steed based on the same basic theme. Steed was also the central character of "The New Avengers" (1976–77), in which he was teamed with agents named Purdey (Joanna Lumley) and Mike Gambit (Gareth Hunt).
Macnee insisted on, and was proud of, never carrying a gun in the original series; when asked why, he explained, "I'd just come out of a World War in which I'd seen most of my friends blown to bits." Lumley later said she did all the gun-slinging in "The New Avengers" for the same reason. However, the Internet Movie Firearms Database lists seven instances where Steed uses a firearm, all in the original series.
When asked in June 1982 which "Avengers" female lead was his favourite, Macnee declined to give a specific answer. "Well, I'd rather not say. To do so would invite trouble," he told "TV Week" magazine. Macnee did provide his evaluation of the female leads. Of Honor Blackman he said, "She was wonderful, presenting the concept of a strong-willed, independent and liberated woman just as that sort of woman was beginning to emerge in society." Diana Rigg was "One of the world's great actresses. A superb comedienne. I'm convinced that one day she'll be Dame Diana." (His prediction came true in 1994.) Linda Thorson was "one of the sexiest women alive" while Joanna Lumley was "superb in the role of Purdey. An actress who is only now realising her immense potential."
Macnee co-wrote two original novels based upon "The Avengers" during the 1960s, titled "Dead Duck" and "Deadline." He hosted a documentary, "The Avengers: The Journey Back" (1998), directed by Clyde Lucas.
For the critically lambasted film version of "The Avengers" (1998), he lent his voice in a cameo as "Invisible Jones". The character of Steed was taken over by Ralph Fiennes.
Later roles.
Macnee's other significant roles have included playing Sir Godfrey Tibbett opposite Roger Moore in the James Bond film "A View to a Kill" (1985), as Major Crossley in "The Sea Wolves" (again with Moore), guest roles in "Encounter," "Alias Smith and Jones" (for Glen Larson), "Hart to Hart," "Murder, She Wrote," and "The Love Boat." Although his best known part was heroic, many of his television appearances were as villains; among them were his roles of both the demonic Count Iblis and his provision of the character voice of the Cylons' Imperious Leader in "Battlestar Galactica," also for Glen Larson, for which he also supplied the show's introductory voiceover. He also presented the American paranormal series "Mysteries, Magic and Miracles." Macnee made his Broadway debut as the star of Anthony Shaffer's mystery "Sleuth" in 1972 and subsequently headlined the national tour of that play.
Macnee reunited with Diana Rigg in her short-lived NBC sitcom, "Diana" (1973) in a single episode. Other television appearances include a guest appearance on "Columbo" in the episode "Troubled Waters" (1975); and playing Major Vickers in "For the Term of His Natural Life" (1983). He had recurring roles in the crime series "Gavilan" with Robert Urich and in the short-lived satire on big business, "Empire" (1984), as Dr. Calvin Cromwell. Macnee also narrated the documentary "Ian Fleming: 007's Creator" (2000).
He also appeared in several cult films: in "The Howling" (1981), as 'Dr George Waggner' (named whimsically after the director of "The Wolf Man", 1941) and as Sir Denis Eton-Hogg in the rockumentary comedy "This Is Spinal Tap" (1984). He played Dr. Stark in "The Creature Wasn't Nice" (1981), also called "Spaceship" and "Naked Space". Macnee played the role of actor David Mathews in the made-for-television movie "Rehearsal for Murder" (1982), which starred Robert Preston and Lynn Redgrave. The movie was from a script written by "Columbo" co-creators Richard Levinson and William Link. He took over Leo G. Carroll's role as Alexander Waverly, the head of U.N.C.L.E. in ' (1983), produced by Michael Sloan. He was featured in the science fiction television movie "Super Force" (1990) as E. B. Hungerford (the series which followed did not feature Macnee), as a supporting character in the parody film "Lobster Man From Mars" (1989) as Prof. Plocostomos and in "The Return of Sam McCloud" (1989), a TV film, as Tom Jamison. He made an appearance in "Frasier" (2001), and several episodes of the American science-fiction series "Nightman" as Dr. Walton, a psychiatrist who would advise Johnny/Nightman. Macnee appeared in two episodes of the series ' (1993–94) and was a retired agent in a handful of instalments of "Spy Game" (1997–98).
Macnee made numerous TV commercials including one around 1990 for Swiss Chalet, the Canadian restaurant chain, and a year or so before, a commercial for the Sterling Motor Car Company. Over the James Bond theme, the car duels with a motorcycle assailant at high speed through mountainous territory, ultimately eludes the foe, and reaches its destination. Macnee steps out of the car and greets viewers with a smile, saying, "I suppose you were expecting someone else". Macnee was the narrator for several "behind-the-scenes" featurettes for the James Bond series of DVDs and recorded numerous audio books, including the releases of many novels by Jack Higgins. He also recorded the children's books "The Musical Life of Gustav Mole" and its sequel, "The Lost Music (Gustav Mole's War on Noise)," both written by Michael Twinn.
Macnee featured in two pop videos: as Steed in original "Avengers" footage in The Pretenders' video for their song "Don't Get Me Wrong" (1986) and in the promotion for Oasis's "Don't Look Back in Anger" (1996), as the band's driver, a role similar to that which he played in the James Bond film "A View To A Kill" (1985). In 1990 his recording with his "Avengers" co-star Honor Blackman, called "Kinky Boots" (1964), reached the UK Singles Chart after being played on Simon Mayo's BBC Radio One breakfast show.
Sherlock Holmes and Doctor Watson.
Macnee appeared in "Magnum, P.I." (1984) as a retired, but delusional, British agent, who believed he was Sherlock Holmes, in a season four episode titled "Holmes Is Where the Heart Is". He played both Holmes and Dr. Watson on several occasions. He played Watson three times: once alongside Roger Moore's Sherlock Holmes in a TV film, "Sherlock Holmes in New York" (1976), and twice with Christopher Lee, first in "Incident at Victoria Falls" (1991), and then in "Sherlock Holmes and the Leading Lady" (1992). He played Holmes in another TV film, "The Hound of London" (1993), along with the 1996 TV film "". He is thus one of only a very small number of actors to have portrayed both Sherlock Holmes and Dr. Watson on screen.
Personal life.
Macnee married his first wife, Barbara Douglas, in 1942. They had two children, Rupert and Jenny, and a grandson, Christopher ("Kit"). After they were divorced in 1956, his second marriage (1965−1969) was to actress Katherine Woodville. His third marriage was to Baba Majos de Nagyzsenye, daughter of opera singer Ella Némethy, and it lasted from 1988 until her death in 2007.
Macnee became a U.S. citizen in 1982. He dictated his autobiography, which he entitled "Blind in One Ear: The Avenger Returns" (1988), to Marie Cameron.
Later in life, Macnee was an enthusiastic nudist.
Death.
On 25 June 2015, Macnee died at Rancho Mirage, California, his home for the past four decades, at the age of 93.

</doc>
<doc id="24922" url="https://en.wikipedia.org/wiki?curid=24922" title="List of Polish proverbs">
List of Polish proverbs


</doc>
<doc id="24927" url="https://en.wikipedia.org/wiki?curid=24927" title="Pembroke College, Cambridge">
Pembroke College, Cambridge

Pembroke College is a constituent college of the University of Cambridge, England. The college is the third-oldest college of the university and has over seven hundred students and fellows. Physically, it is one of the university's larger colleges, with buildings from almost every century since its founding, as well as extensive gardens.
Pembroke is home to the first chapel designed by Sir Christopher Wren and is one of the six Cambridge colleges to have educated a British prime minister, in Pembroke's case William Pitt the Younger. The college library, with a Victorian neo-gothic clock tower, is endowed with an original copy of the first encyclopaedia to contain printed diagrams.
The college's current master is Chris Smith, Baron Smith of Finsbury.
History.
On Christmas Eve 1347, Edward III granted Marie de St Pol, widow of the Earl of Pembroke, the licence for the foundation of a new educational establishment in the young university at Cambridge. The "Hall of Valence Mary" ("Custos & Scolares Aule Valence Marie in Cantebrigg'"), as it was originally known, was thus founded to house a body of students and fellows. The statutes were notable in that they both gave preference to students born in France who had already studied elsewhere in England, and that they required students to report fellow students if they indulged in excessive drinking or visited disreputable houses.
The college was later renamed Pembroke Hall, and finally became Pembroke College in 1856.
In 2015, the college received a bequest of £34 million from the estate of American inventor and Pembroke alumnus Ray Dolby, thought to be the largest single donation to a college in the history of Cambridge University.
Buildings.
Old Court.
The first buildings comprised a single court (now called Old Court) containing all the component parts of a college – chapel, hall, kitchen and buttery, master's lodgings, students' rooms – and the statutes provided for a manciple, a cook, a barber and a laundress. Both the founding of the college and the building of the city's first college Chapel (1355) required the grant of a papal bull.
The original court was the university's smallest at only by , but was enlarged to its current size in the nineteenth century by demolishing the south range.
The college's gatehouse is the oldest in Cambridge.
Chapel.
The original Chapel now forms the Old Library and has a striking seventeenth-century plaster ceiling, designed by Henry Doogood, showing birds flying overhead. Around the Civil War, one of Pembroke's fellows and Chaplain to the future Charles I, Matthew Wren, was imprisoned by Oliver Cromwell. On his release after eighteen years, he fulfilled a promise by hiring his nephew Christopher Wren to build a great Chapel in his former college. The resulting Chapel was consecrated on St Matthew's Day, 1665, and the eastern end was extended by George Gilbert Scott in 1880, when it was consecrated on the Feast of the Annunciation.
Expansion.
An increase in membership over the last 150 years saw a corresponding increase in building activity. The Hall was rebuilt in 1875–6 by Alfred Waterhouse after he had declared the medieval Hall unsafe. As well as the Hall, Waterhouse built a new range of rooms, Red Buildings (1871–72), in French Renaissance style, designed a new Master's Lodge on the site of Paschal Yard (1873, later to become N staircase), pulled down the old Lodge and the south range of Old Court to open a vista to the Chapel, and finally built a new Library (1877–78) in the continental Gothic style.
Waterhouse was dismissed as architect in 1878 and succeeded by George Gilbert Scott, who, after extending the Chapel, provided additional accommodation with the construction of New Court in 1881, with letters on a series of shields along the string course above the first floor spelling out the Psalm text ("Except the Lord build the house, their labour is but vain that build it").
Building work continued into the 20th century with W. D. Caröe as architect. He added Pitt Building (M staircase) between Ivy Court and Waterhouse's Lodge, and extended New Court with the construction of O staircase on the other side of the Lodge. He linked his two buildings with an arched stone screen, Caröe Bridge, along Pembroke Street in a late Baroque style, the principal function of which was to act as a bridge by which undergraduates might cross the Master's forecourt at first-floor level from Pitt Building to New Court without leaving the College or trespassing in what was then the Fellows' Garden.
In 1926, as the Fellows had become increasingly disenchanted with Waterhouse's Hall, Maurice Webb was brought in to remove the open roof, put in a flat ceiling and add two storeys of sets above. The wall between the Hall and the Fellows' Parlour was taken down, and the latter made into a High Table dais. A new Senior Parlour was then created on the ground floor of Hitcham Building. The remodelling work was completed in 1949 when Murrary Easton replaced the Gothic tracery of the windows with a simpler design in the style of the medieval Hall.
In 1933 Maurice Webb built a new Master's Lodge in the south-east corner of the College gardens, on land acquired from Peterhouse in 1861. Following the war, further accommodation was created with the construction in 1957 of Orchard Building, so called because it stands on part of the Foundress's orchard. Finally, in a move to accommodate the majority of junior members on the College site rather than in hostels in the town, in the 1990s Eric Parry designed a new range of buildings on the site of the Master's Lodge, with a new Lodge at the west end. "Foundress Court" was opened in 1997 in celebration of the College's 650th Anniversary. In 2001 the Library was extended to the east and modified internally.
Gardens.
Pembroke's enclosed grounds also house some gardens, sporting vegetation. Highlights include "The Orchard" (a patch of semi-wild ground in the centre of the college), an impressive row of Plane Trees and a bowling green, re-turfed in 1996, which is reputed to be among the oldest in continual use in Europe.
Student life.
Pembroke College has both graduate and undergraduate students, termed Valencians, after the College's original name, and its recreational rooms named as "parlours" rather than the more standard "combination room". The undergraduate student body is represented by the Junior Parlour Committee (JPC). The graduate community is represented by the Graduate Parlour Committee (GPC). In March 2016, the Junior Parlour Committee was featured in national newspapers after it cancelled the theme of an "Around The World In 80 Days" dance party.
There are many clubs and societies organised by the students of the college, such as the boat club Pembroke College Boat Club and the college's dramatic society the Pembroke Players, which has been made famous by alumni such as Peter Cook, Eric Idle, Tim Brooke-Taylor, Clive James and Bill Oddie and is now in its 60th year.
International programmes.
Pembroke is the only Cambridge college to have an International Programmes Department, providing opportunities for international students to spend a semester (mid-January to mid-June), or part of the summer, in Cambridge. The Spring Semester Programme is a competitive programme for academically outstanding students who wish to follow a regular Cambridge degree course as fully matriculated members of the University. There are around thirty places each year.
In the summer the College offers the eight-week Pembroke-King's Programme (PKP). As well as the academic content, trips are made to locales such as London, and the programme has a series of formal halls, which are described as "three-course candlelit meals" serving "interesting" fare in Pembroke's historic dining hall. The Pembroke-King's Programme is also the programme for which the prestigious Thouron Prize is awarded, fully supporting nine American undergraduates from Harvard, Yale, and UPenn.
Institutions named after the college.
Pembroke College, the former women's college at Brown University in the United States, was named for the principal building on the women's campus, Pembroke Hall, which was itself named in honour of the Pembroke College (Cambridge) alumnus Roger Williams, a co-founder of Rhode Island.
In 1865 Pembroke College donated land for the formation of the Suffolk memorial to Prince Albert. The land at Framlingham in the county of Suffolk was used to build a school, The Albert Memorial College. The school today is known as Framlingham College and one of its seven houses is named Pembroke House in recognition of the contribution Pembroke College has made to the School.
In 1981, a decade after the merger of Pembroke College into Brown University, the Pembroke Center for Teaching and Research on Women was named in honour of Pembroke College and the history of women's efforts to gain access to higher education.

</doc>
<doc id="24928" url="https://en.wikipedia.org/wiki?curid=24928" title="Prime ideal">
Prime ideal

Primitive ideals are prime, and prime ideals are both primary and semiprime.
Prime ideals for commutative rings.
An ideal of a commutative ring is prime if it has the following two properties:
This generalizes the following property of prime numbers: if is a prime number and if divides a product of two integers, then divides or divides . We can therefore say
Uses.
One use of prime ideals occurs in algebraic geometry, where varieties are defined as the zero sets of ideals in polynomial rings. It turns out that the irreducible varieties correspond to prime ideals. In the modern abstract approach, one starts with an arbitrary commutative ring and turns the set of its prime ideals, also called its spectrum, into a topological space and can thus define generalizations of varieties called schemes, which find applications not only in geometry, but also in number theory.
The introduction of prime ideals in algebraic number theory was a major step forward: it was realized that the important property of unique factorisation expressed in the fundamental theorem of arithmetic does not hold in every ring of algebraic integers, but a substitute was found when Richard Dedekind replaced elements by ideals and prime elements by prime ideals; see Dedekind domain.
Prime ideals for noncommutative rings.
The notion of a prime ideal can be generalized to noncommutative rings by using the commutative definition "ideal-wise". Wolfgang Krull advanced this idea in 1928. The following content can be found in texts such as and . If is a (possibly noncommutative) ring and is an ideal in other than itself, we say that is prime if for any two ideals and of :
It can be shown that this definition is equivalent to the commutative one in commutative rings. It is readily verified that if an ideal of a noncommutative ring satisfies the commutative definition of prime, then it also satisfies the noncommutative version. An ideal satisfying the commutative definition of prime is sometimes called a completely prime ideal to distinguish it from other merely prime ideals in the ring. Completely prime ideals are prime ideals, but the converse is not true. For example, the zero ideal in the ring of matrices over a field is a prime ideal, but it is not completely prime.
This is close to the historical point of view of ideals as ideal numbers, as for the ring " is contained in " is another way of saying " divides ", and the unit ideal represents unity.
Equivalent formulations of the ideal being prime include the following properties:
Prime ideals in commutative rings are characterized by having multiplicatively closed complements in , and with slight modification, a similar characterization can be formulated for prime ideals in noncommutative rings. A nonempty subset is called an m-system if for any and in , there exists in such that "arb" is in . The following item can then be added to the list of equivalent conditions above:
Connection to maximality.
Prime ideals can frequently be produced as maximal elements of certain collections of ideals. For example:

</doc>
<doc id="24929" url="https://en.wikipedia.org/wiki?curid=24929" title="PC-FX">
PC-FX

The is a 32-bit home video game console made by NEC Corporation. It was released in Japan on December 23, 1994, just weeks after Sony's PlayStation and a month after the Sega Saturn. It is the successor to NEC's PC Engine, known as TurboGrafx-16 in North America.
Unlike its predecessor, the PC-FX was only released in Japan. The console is shaped just like a tower PC and was meant to be similarly upgradeable. However the PC-FX was using an outdated graphics chip that rendered the system underpowered in comparison to its competitors, which caused it to be a commercial failure. A lack of developers' support also meant inadequate games and as a result it was unable to compete effectively with its fifth generation peers. The PC-FX was NEC's last home video game console, and was discontinued in February 1998.
History.
NEC launched the PC-FX's predecessor, the PC Engine in 1987, which although had been warmly accepted in Japan, was unable to match the technical specifications put forward by Nintendo and Sega with their consoles, the Super Famicom and the Sega Mega Drive. Plans were therefore drawn up by NEC for a successor in order to reclaim lost ground.
The PC-FX was based on a 32-bit system architecture named "Iron Man", developed in-house by NEC. NEC demonstrated Iron Man at a number of trade shows and events during 1992, and by the middle of the year were discussing an imminent release of an Iron Man-based video game system with many third party developers. At the time, the earlier PC Engine was still quite popular in Japan, and opinions on the Iron Man technology were mixed. Many were uninterested in switching to more powerful hardware while the PC Engine market was still growing, and as a result NEC halted work on the Iron Man project, instead opting for more modifications to the PC Engine technology.
When NEC decided to release the PC-FX, the specs were relatively unchanged from the originally unveiled Iron Man architecture. The most significant difference was the addition of a new 32-bit V-810 RISC CPU.
The console was announced in late 1993. In a special Game Machine Cross Review in May 1995, "Famicom Tsūshin" would score the PC-FX console an 18 out of 40.
Unusual for a fifth generation console, the PC-FX does not have a polygon graphics processor. NEC's reasoning for this was that polygon processors of the time were relatively low-powered, resulting in figures having a blocky appearance, and that it would be better for games to use pre-rendered polygon graphics instead. The shining quality of the PC-FX was the ability to decompress 30 JPEG pictures per second while playing digitally recorded audio (essentially a form of Motion JPEG). This resulted in the PC-FX having superior full motion video quality over all other fifth generation consoles.
The system's target audience was roughly five years older than that of the PC Engine, in hopes that PC Engine fans would be brought over to the successor console. In an interview roughly a year before the system launch, a representative stated that though NEC had not entirely ruled out the possibility of a release outside Japan, they had concluded that unless additional non-gaming uses were developed for the PC-FX, it would sell poorly in the USA due to its high price. According to NEC of Japan, as of August 1995 the PC-FX had sold just under 100,000 units.
Unlike nearly any other console (except for the 3DO and CD-i), the PC-FX was also available as an internal PC card for NEC PC-98 and AT/IBM PC compatibles. This PC card came with two CDs of software to help the user program games for the PC-FX. However, compatibility issues prevented games developed with this software from actually running on the console.
The PC-FX was discontinued in early 1998.
Hardware.
The PC-FX uses CD-ROMs as its storage medium, following on from the expansion released for its predecessor, which originally used HuCards. The game controller is virtually identical to a DUO-RX controller, but the rapid fire switches have been replaced with mode A/B switches. Peripherals include a PC-FX mouse, which is supported by strategy games like "Farland Story FX" and "Power DoLLS FX".
The PC-FX's computer-like design was unusual for consoles at the time. It stands upright like a tower computer while other contemporary consoles lay flat. Another interesting feature is its three expansion ports. Also, similar to the 3DO, it featured a built in power supply.
The PC-FX includes an HU 62 series 32-bit system board, an LSI chip, and a 32-bit V-810 RISC CPU. The system can display 16.77 million colors (the same amount as the PlayStation).
Software.
There were 62 games released for the system. The launch titles were "", "Battle Heat" and "Team Innocent" on December 23, 1994 and the final game released was "First Kiss Story" on April 24, 1998. The system and all titles were only released in Japan. A number of demo discs were also released with publications which allowed the user to play the disc in a CD equipped PC-Engine or the PC-FX.
There was no copy protection on any of the PC-FX games, because at the time the system was released, the high price of CD-R drives made piracy expensive.

</doc>
<doc id="24931" url="https://en.wikipedia.org/wiki?curid=24931" title="Psychotherapy">
Psychotherapy

Psychotherapy is the use of psychological methods, particularly when based on regular personal interaction, to help a person change and overcome problems in desired ways. Psychotherapy aims to increase each individual's well-being and mental health, to resolve or mitigate troublesome behaviors, beliefs, compulsions, thoughts, or emotions, and to improve relationships and social functioning. Certain psychotherapies are considered evidence-based for treating some diagnosed mental disorders.
There are over a thousand different named psychotherapies, some being minor variations while others are based on very different conceptions of psychology, ethics (how to live) or techniques. Most involve one-to-one sessions between client and therapist but some are conducted with groups, including families. Psychotherapists may be mental health professionals or come from a variety of other backgrounds, and depending on the jurisdiction may be legally regulated, voluntarily regulated or unregulated (and the term itself may be protected or not).
Definitions.
The term ' is derived from Ancient Greek ' ( meaning "breath; spirit; soul") and "therapeia" ( "healing; medical treatment"). The "Oxford English Dictionary" defines it now as "The treatment of disorders of the mind or personality by psychological methods..."
The American Psychological Association adopted a resolution on the effectiveness of psychotherapy in 2012 based on a definition developed by John C. Norcross: "Psychotherapy is the informed and intentional application of clinical methods and interpersonal stances derived from established psychological principles for the purpose of assisting people to modify their behaviors, cognitions, emotions, and/or other personal characteristics in directions that the participants deem desirable". Influential editions of a work by psychiatrist Jerome Frank defined psychotherapy as a healing relationship using socially authorized methods in a series of contacts primarily involving words, acts and rituals—regarded as forms of persuasion and rhetoric.
Some definitions of counseling overlap with psychotherapy (particularly non-directive client-centered approaches), or counseling may refer to guidance for everyday problems in specific areas, typically for shorter durations with a less medical focus. Somatotherapy refers to the use of physical methods as treatments, and sociotherapy to the use of a person's social environment to effect therapeutic change. Psychotherapy may address spirituality as part of mental life, and some forms are derived from spiritual philosophies, but practices based on treating the spiritual as a separate dimension would not necessarily be considered psychotherapy.
Historically psychotherapy has sometimes meant "interpretative" (i.e. Freudian) methods, by contrast with other methods to treat psychiatric disorders such as behavior modification.
Psychotherapy is often dubbed "talking therapy", particularly for a general audience, though not all forms of psychotherapy rely on verbal communication. Children or adults who do not engage in verbal communication (or not in the usual way) are not excluded from psychotherapy; indeed some types are designed for such cases.
Regulation.
Psychotherapists may be mental health professionals, professionals from other backgrounds trained in a specific therapy, or in some cases non-professionals. Psychiatrists are first trained as physicians. As such, they may prescribe prescription medication. Specialist psychiatric training begins after medical school in psychiatric residencies. Clinical psychologists have a specialist doctoral degrees in psychology with clinical and research components. Clinical social workers may have specialized training and practical experience in psychotherapy. Many of the wide variety of training programs and institutional settings are multi-professional. In most countries professionals doing specialized psychotherapeutic work also require a program of continuing education after the basic degree.
As sensitive and deeply personal topics are often discussed during psychotherapy, therapists are expected, and usually legally bound, to respect client or patient confidentiality. The critical importance of client confidentiality—and the limited circumstances in which it may need to be broken for the protection of clients or others—is enshrined in the regulatory psychotherapeutic organizations' codes of ethical practice.
Europe.
As of 2015 there is still much variation between European countries. A few have no regulation of the practice or no protection of the title. Some have a system of voluntary registration with independent professional organisations, while others attempt to restrict it to mental health professionals with years of additional state-certified training. Which titles are "protected" also varies. The European Association for Psychotherapy set up after the 1990 Strasbourg Declaration on Psychotherapy attempts to set independent pan-European standards.
In Germany, the practice of psychotherapy for adults is restricted to qualified psychologists and physicians (including psychiatrists) who have completed five years of specialist practical training and certification in psychotherapy. Social workers may complete the specialist training for child and teenage clients. Similarly in Italy, the practice of psychotherapy is restricted to graduates in psychology or medicine who have completed four years of recognised specialist training. 
Sweden has a similar restriction on the title "psychotherapist", which may only be used by professionals who have gone through a post-graduate training in psychotherapy and then applied for a licence, issued by the National Board of Health and Welfare.
French legislation restricts the use of the title "psychotherapist" to professionals on the National Register of Psychotherapists, which requires a training in clinical psychopathology and a period of internship which is only open to physicians or titulars of a master's degree in psychology or psychoanalysis.
Austria and Switzerland (2011) have laws that recognize multidifunctional-disciplinary approaches.
In the United Kingdom, psychotherapy is voluntarily regulated. National registers for psychotherapists and counsellors are maintained by three main umbrella bodies: The United Kingdom Council for Psychotherapy (UKCP), The British Association for Counselling and Psychotherapy (BACP) and The British Psychoanalytic Council. There are many smaller professional bodies and associations such as the Association of Child Psychotherapists (ACP) and the British Association of Psychotherapists (BAP). The government and Health and Care Professions Council considered mandatory legal registration but decided that it was best left to professional bodies to regulate themselves, so the Professional Standards Authority for Health and Social Care (PSA) launched an Accredited Voluntary Registers scheme.
United States.
In some states, counselors or therapists must be licensed to use certain words and titles on self-identification or advertising: in some other states, the restrictions on practice are more closely associated with the charging of fees. Licensing and regulation are performed by the various states. Presentation of practice as licensed, but without such a license, is generally illegal. Without a license, for example a practitioner cannot bill insurance companies. Information about state licensure is provided by the American Psychological Association [http://www.apapracticecentral.org/ce/state/index.aspx]
In addition to state laws, the American Psychological Association enacts “Ethical Principles” for its members. The American Board of Professional Psychology examines and certifies “psychologists who demonstrate competence in approved specialty areas in professional psychology.”
History.
Psychotherapy can be said to have been practiced through the ages, as medics, philosophers, spiritual practitioners and people in general used psychological methods to heal others.
In the Western tradition, by the 19th century a moral treatment movement (then meaning morale or mental) developed based on non-invasive non-restraint therapeutic methods. Another influential movement was started by Franz Mesmer (1734–1815) and his student Armand-Marie-Jacques de Chastenet, Marquis of Puységur (1751–1825). Called Mesmerism or animal magnetism, it would have a strong influence on the rise of dynamic psychology and psychiatry as well as theories about hypnosis. In 1853 Walter Cooper Dendy introduced the term "psycho-therapeia" regarding how physicians might influence the mental states of sufferers and thus their bodily ailments, for example by creating opposing emotions to promote mental balance. Daniel Hack Tuke cited the term and wrote about "psycho-therapeutics" in 1872, in which he also proposed making a science of animal magnetism. Hippolyte Bernheim and colleagues in the "Nancy School" developed the concept of "psychotherapy" in the sense of using the mind to heal the body through hypnotism, yet further. Charles Lloyd Tuckey's 1889 work, "Psycho-therapeutics, or Treatment by Hypnotism and Suggestion" popularized the work of the Nancy School in English. Also in 1889 a clinic used the word in its title for the first time, when Frederik van Eeden and Albert Willem in Amsterdam renamed theirs "Clinique de Psycho-thérapeutique Suggestive" after visiting Nancy. During this time, travelling stage hypnosis became popular, and such activities added to the scientific controversies around the use of hypnosis in medicine. Also in 1892, at the second congress of experimental psychology, van Eeden attempted to take the credit for the term psychotherapy and to distance the term from hypnosis. In 1896, the German journal Zeitschrift für Hypnotismus, Suggestionstherapie, Suggestionslehre und verwandte psychologische Forschungen changed its name to Zeitschrift für Hypnotismus, Psychotherapie sowie andere psychophysiologische und psychopathologische Forschungen, which is probably the first journal to use the term. Thus psychotherapy initially meant "the treatment of disease by psychic or hypnotic influence, or by suggestion"
Sigmund Freud visited the Nancy School and his early neurological practice involved the use of hypnotism. However following the work of his mentor Josef Breuer—in particular a case where symptoms appeared partially resolved by what the patient, Bertha Pappenheim, dubbed a "talking cure"—Freud began focusing on conditions that appeared to have psychological causes originating in childhood experiences and the unconscious mind. He went on to develop techniques such as free association, dream interpretation, transference and analysis of the id, ego and superego. His popular reputation as father of psychotherapy was established by his use of the distinct term "psychoanalysis", tied to an overarching system of theories and methods, and by the effective work of his followers in rewriting history. Many theorists, including Alfred Adler, Carl Jung, Karen Horney, Anna Freud, Otto Rank, Erik Erikson, Melanie Klein and Heinz Kohut, built upon Freud's fundamental ideas and often developed their own systems of psychotherapy. These were all later categorized as "psychodynamic", meaning anything that involved the psyche's conscious/unconscious influence on external relationships and the self. Sessions tended to number into the hundreds over several years.
Behaviorism developed in the 1920s, and behavior modification as a therapy became popularized in the 1950s and 1960s. Notable contributors were Joseph Wolpe in South Africa, M.B. Shipiro and Hans Eysenck in Britain, and John B. Watson and B.F. Skinner in the United States. Behavioral therapy approaches relied on principles of operant conditioning, classical conditioning and social learning theory to bring about therapeutic change in observable symptoms. The approach became commonly used for phobias, as well as other disorders.
Some therapeutic approaches developed out of the European school of existential philosophy. Concerned mainly with the individual's ability to develop and preserve a sense of meaning and purpose throughout life, major contributors to the field (e.g., Irvin Yalom, Rollo May) and Europe (Viktor Frankl, Ludwig Binswanger, Medard Boss, R.D.Laing, Emmy van Deurzen) attempted to create therapies sensitive to common "life crises" springing from the essential bleakness of human self-awareness, previously accessible only through the complex writings of existential philosophers (e.g., Søren Kierkegaard, Jean-Paul Sartre, Gabriel Marcel, Martin Heidegger, Friedrich Nietzsche). The uniqueness of the patient-therapist relationship thus also forms a vehicle for therapeutic inquiry. A related body of thought in psychotherapy started in the 1950s with Carl Rogers. Based also on the works of Abraham Maslow and his hierarchy of human needs, Rogers brought person-centered psychotherapy into mainstream focus. The primary requirement was that the client be in receipt of three core "conditions" from his counselor or therapist: unconditional positive regard, sometimes described as "prizing" the client's humanity; congruence [authenticity/genuineness/transparency]; and empathic understanding. This type of interaction was thought to enable clients to fully experience and express themselves, and thus develop according to their innate potential. Others developed the approach, like Fritz and Laura Perls in the creation of Gestalt therapy, as well as Marshall Rosenberg, founder of Nonviolent Communication, and Eric Berne, founder of transactional analysis. Later these fields of psychotherapy would become what is known as humanistic psychotherapy today. Self-help groups and books became widespread.
During the 1950s, Albert Ellis originated rational emotive behavior therapy (REBT). Independently a few years later, psychiatrist Aaron T. Beck developed a form of psychotherapy known as cognitive therapy. Both of these included relatively short, structured and present-focused techniques aimed at identifying and changing a person's beliefs, appraisals and reaction-patterns, by contrast with the more long-lasting insight-based approach of psychodynamic or humanistic therapies. Beck's approach used primarily the socratic method, and links have been drawn between ancient stoic philosophy and these cognitive therapies.
Cognitive and behavioral therapy approaches were increasingly combined and grouped under the umbrella term cognitive behavioral therapy (CBT) in the 1970s. Many approaches within CBT are oriented towards active/directive yet collaborative empiricism (a form of reality-testing), assessing and modifying core beliefs and dysfunctional schemas. These approaches gained widespread acceptance as a primary treatment for numerous disorders. A "third wave" of cognitive and behavioral therapies developed, including acceptance and commitment therapy and dialectical behavior therapy, which expanded the concepts to other disorders and/or added novel components and mindfulness exercises. Counseling methods developed, including solution-focused therapy and systemic coaching.
Postmodern psychotherapies such as narrative therapy and coherence therapy did not impose definitions of mental health and illness, but rather saw the goal of therapy as something constructed by the client and therapist in a social context. Systemic therapy also developed, which focuses on family and group dynamics—and transpersonal psychology, which focuses on the spiritual facet of human experience. Other orientations developed in the last three decades include feminist therapy, brief therapy, somatic psychology, expressive therapy, applied positive psychology and the human givens approach. A survey of over 2,500 US therapists in 2006 revealed the most utilized models of therapy and the ten most influential therapists of the previous quarter-century.
Types.
Overview.
There are hundreds of psychotherapy approaches or schools of thought. By 1980 there were more than 250; by 1996 more than 450; and at the start of the 21st century there were over a thousand different named psychotherapies - some being minor variations while others are based on very different conceptions of psychology, ethics (how to live) or technique. In practice therapy is often not of one pure type but draws from a number of perspectives and schools - known as an integrative or eclectic approach. The importance of the therapeutic relationship, also known as therapeutic alliance, between client and therapist is often regarded as crucial to psychotherapy. Common factors theory addresses this and other core aspects thought to be responsible for effective psychotherapy.
Therapy may address specific forms of diagnosable mental illness, or everyday problems in managing or maintaining interpersonal relationships or meeting personal goals. A course of therapy may happen before, during or after pharmacotherapy (e.g. taking psychiatric medication).
Psychotherapies are categorized in several different ways. A distinction can be made between those based on a medical model and those based on a humanistic model. In the medical model the client is seen as unwell and the therapist employs their skill to help the client back to health. The extensive use of the DSM-IV, the diagnostic and statistical manual of mental disorders in the United States, is an example of a medically exclusive model. The humanistic or non-medical model in contrast strives to depathologise the human condition. The therapist attempts to create a relational environment conducive to experiential learning and help build the client's confidence in their own natural process resulting in a deeper understanding of themselves. The therapist may see themselves as a facilitator/helper.
Another distinction is between individual one-to-one therapy sessions, and group psychotherapy, including couples therapy and family therapy.
Therapies are sometimes classified according to their duration; a small number of sessions over a few weeks or months may be classed as Brief therapy (or short-term therapy), others where regular sessions take place for years may be classed as long-term.
Some practitioners distinguish between more "uncovering" (or "depth") approaches and more "supportive" psychotherapy. Uncovering psychotherapy emphasizes facilitating the client's insight into the roots of their difficulties. The best-known example is classical psychoanalysis. Supportive psychotherapy by contrast stresses strengthening the client's coping mechanisms and often providing encouragement and advice, as well as reality-testing and limit-setting where necessary. Depending on the client's issues and situation, a more supportive or more uncovering approach may be optimal.
Most forms of psychotherapy use spoken conversation. Some also use various other forms of communication such as the written word, artwork, drama, narrative story or music. Psychotherapy with children and their parents often involves play, dramatization (i.e. role-play), and drawing, with a co-constructed narrative from these non-verbal and displaced modes of interacting.
There are also different formats for delivering some therapies, as well as the usual face to face: for example via telephone or via online interaction. There have also been developments in computer-assisted therapy, such as Virtual reality therapy for behavioral exposure, multimedia programs to each cognitive techniques, and handheld devices for improved monitoring or putting ideas into practice.
Humanistic.
These psychotherapies, also known as "experiential", are based on humanistic psychology and emerged in reaction to both behaviorism and psychoanalysis, being dubbed the "third force". They are primarily concerned with the human development and needs of the individual, with an emphasis on subjective meaning, a rejection of determinism, and a concern for positive growth rather than pathology. Some posit an inherent human capacity to maximize potential, "the self-actualizing tendency"; the task of therapy is to create a relational environment where this tendency might flourish. Humanistic psychology can in turn be rooted in existentialism—the belief that human beings can only find meaning by creating it. This is the goal of existential therapy. Existential therapy is in turn philosophically associated with phenomenology.
Person-centered therapy, also known as client-centered, focuses on the therapist showing openness, empathy and "unconditional positive regard", to help clients express and develop their own self.
Gestalt therapy, originally called "concentration therapy", is an existential/experiential form that facilitates awareness in the various contexts of life, by moving from talking about relatively remote situations to action and direct current experience. Derived from various influences, including an overhaul of psychoanalysis, it stands on top of essentially four load-bearing theoretical walls: phenomenological method, dialogical relationship, field-theoretical strategies, and experimental freedom.
A briefer form of humanistic therapy is the human givens approach, introduced in 1998/9. It is a solution-focused intervention based on identifying emotional needs—such as for security, autonomy and social connection—and using various educational and psychological methods to help people meet those needs more fully or appropriately.
Insight-oriented.
Insight-oriented psychotherapies focus on revealing or interpreting unconscious processes. Most commonly referring to psychodynamic therapy, of which psychoanalysis is the oldest and most intensive form, these applications of depth psychology encourage the verbalization of all the patient's thoughts, including free associations, fantasies, and dreams, from which the analyst formulates the nature of the past and present unconscious conflicts which are causing the patient's symptoms and character problems.
There are four main schools of psychoanalysis, which all influenced psychodynamic theory: Freudian, Ego psychology, Object relations theory and Glen Gabbard. and Self psychology. Techniques for analytic group therapy have also developed.
Cognitive-behavioral.
Behavior therapies use behavioral techniques, including applied behavior analysis (also known as behavior modification), to change maladaptive patterns of behavior to improve emotional responses, cognitions, and interactions with others. Functional analytic psychotherapy is one form of this approach. By nature, behavioral therapies are empirical (data-driven), contextual (focused on the environment and context), functional (interested in the effect or consequence a behavior ultimately has), probabilistic (viewing behavior as statistically predictable), monistic (rejecting mind-body dualism and treating the person as a unit), and relational (analyzing bidirectional interactions).
Cognitive therapy focuses directly on changing the thoughts, in order to improve the emotions and behaviors.
Cognitive behavioral therapy attempts to combine the above two approaches, focused on the construction and re-construction of people's cognitions, emotions and behaviors. Generally in CBT, the therapist, through a wide array of modalities, helps clients assess, recognize and deal with problematic and dysfunctional ways of thinking, emoting and behaving.
A "third wave" reflected an influence of Eastern philosophy in clinical psychology, incorporating principles such as meditation into interventions such as mindfulness-based cognitive therapy, acceptance and commitment therapy and dialectical behavior therapy.
Interpersonal psychotherapy (IPT) is a relatively brief form of psychotherapy (deriving from both CBT and psychodynamic approaches) that has been increasingly studied and endorsed by guidelines for some conditions. It focuses on the links between mood and social circumstances, helping to build social skills and social support. It aims to foster adaptation to current interpersonal roles and situations.
Other types include reality therapy/choice theory, cognitive processing therapy, EMDR, and multimodal therapy.
Systemic.
Systemic therapy seeks to address people not just individually, as is often the focus of other forms of therapy, but in relationship, dealing with the interactions of groups, their patterns and dynamics (includes family therapy & marriage counseling). Community psychology is a type of systemic psychology.
The term group therapy was first used around 1920 by Jacob L. Moreno, whose main contribution was the development of psychodrama, in which groups were used as both cast and audience for the exploration of individual problems by reenactment under the direction of the leader. The more analytic and exploratory use of groups in both hospital and out-patient settings was pioneered by a few European psychoanalysts who emigrated to the USA, such as Paul Schilder, who treated severely neurotic and mildly psychotic out-patients in small groups at Bellevue Hospital, New York. The power of groups was most influentially demonstrated in Britain during the Second World War, when several psychoanalysts and psychiatrists proved the value of group methods for officer selection in the War Office Selection Boards. A chance to run an Army psychiatric unit on group lines was then given to several of these pioneers, notably Wilfred Bion and Rickman, followed by S. H. Foulkes, Main, and Bridger. The Northfield Hospital in Birmingham gave its name to what came to be called the two "Northfield Experiments", which provided the impetus for the development since the war of both social therapy, that is, the therapeutic community movement, and the use of small groups for the treatment of neurotic and personality disorders. Today group therapy is used in clinical settings and in private practice settings.
Expressive.
Expressive therapy is any form of therapy that utilizes artistic expression as its core means of treating clients. Expressive therapists use the different disciplines of the creative arts as therapeutic interventions. This includes the modalities dance therapy, drama therapy, art therapy, music therapy, writing therapy, among others. Expressive therapists believe that often the most effective way of treating a client is through the expression of imagination in a creative work and integrating and processing what issues are raised in the act.
Postmodernist.
Also known as post-structuralist or constructivist. Narrative therapy gives attention to each person's "dominant story" by means of therapeutic conversations, which also may involve exploring unhelpful ideas and how they came to prominence. Possible social and cultural influences may be explored if the client deems it helpful. Coherence therapy posits multiple levels of mental constructs that create symptoms as a way to strive for self-protection or self-realization. Feminist therapy does not accept that there is one single or correct way of looking at reality and therefore is considered a postmodernist approach.
Other.
Transpersonal psychology addresses the client in the context of a spiritual understanding of consciousness. Positive psychotherapy (PPT) (since 1968) is a method in the field of humanistic and psychodynamic psychotherapy and is based on a positive image of humans, with a health-promoting, resource-oriented and conflict-centered approach.
Hypnotherapy is undertaken while a subject is in a state of hypnosis. Hypnotherapy is often applied in order to modify a subject's behavior, emotional content, and attitudes, as well as a wide range of conditions including: dysfunctional habits, anxiety, stress-related illness, pain management, and personal development.
Body psychotherapy, part of the field of somatic psychology, focuses on the link between the mind and the body and tries to access deeper levels of the psyche through greater awareness of the physical body and emotions. There are various "body-oriented" approaches, such as Reichian (Wilhelm Reich) character-analytic vegetotherapy and orgonomy; neo-Reichian bioenergetic analysis; Somatic Experiencing; integrative body psychotherapy; Ron Kurtz's Hakomi psychotherapy; sensorimotor psychotherapy; Biosynthesis psychotherapy; and Biodynamic psychotherapy. These approaches are not to be confused with body work or body-therapies that seek to improve primarily physical health through direct work (touch and manipulation) on the body, rather than through directly psychological methods.
Some non-Western indigenous therapies have been developed. In African countries this includes harmony restoration therapy, meseron therapy and systemic therapies based on the Ubuntu philosophy.
Integrative psychotherapy is an attempt to combine ideas and strategies from more than one theoretical approach. These approaches include mixing core beliefs and combining proven techniques. Forms of integrative psychotherapy include multimodal therapy, the transtheoretical model, cyclical psychodynamics, systematic treatment selection, cognitive analytic therapy, Internal Family Systems Model, multitheoretical psychotherapy and conceptual interaction. In practice, most experienced psychotherapists develop their own integrative approach over time.
Child.
Counseling and psychotherapy must be adapted to meet the developmental needs of children. It is generally held to be one part of an effective strategy for some purposes and not for others. These are four purposes that are generally considered inappropriate or pointless reasons for placing a child in psychotherapy:
In addition to therapy for the child, or even instead of it, children may benefit if their parents speak to a therapist, take parenting classes, attend grief counseling, or take other actions to resolve stressful situations that affect the child. Parent management training is a highly effective form of psychotherapy that teaches parents skills to reduce their child's behavior problems.
Many counseling preparation programs include courses in human development. Since children often do not have the ability to articulate thoughts and feelings, counselors will use a variety of media such as crayons, paint, clay, puppets, bibliocounseling (books), toys, board games, et cetera. The use of play therapy is often rooted in psychodynamic theory, but other approaches such as Solution Focused Brief Counseling may also employ the use of play in counseling. In many cases the counselor may prefer to work with the care taker of the child, especially if the child is younger than age four. Yet, by doing so, the counselor risks the perpetuation of maladaptive interactive patterns and the adverse effects on development that have already been affected on the child's end of the relationship. Therefore, contemporary thinking on working with this young age group has leaned towards working with parent and child simultaneously within the interaction, as well as individually as needed.
Effects.
How to assess.
There is considerable controversy about whether, or when, psychotherapy efficacy is best evaluated by randomized controlled trials or more individualized idiographic methods.
One issue with trials is what to use as a placebo treatment group or non-treatment control group. Often this is patients on a waiting list, or people receiving some kind of regular non-specific contact or support. One issue is the best way to match the use of inert tablets or sham treatments in placebo-controlled studies in pharmaceutical trials. Several interpretations and differing assumptions and language remain. Another issue is the attempt to standardize and manualize therapies and link them to specific symptoms of diagnostic categories, making them more amenable to research. Some report that this may reduce efficacy or gloss over individual needs. Finagy and Roth's opinion is that the benefits of the evidence-based approach outweighs the difficulties.
Many psychotherapists believe that the nuances of psychotherapy cannot be captured by questionnaire-style observation, and prefer to rely on their own clinical experiences and conceptual arguments to support the type of treatment they practice. Psychodynamic therapists in particular have opposed evidence-based approaches as not appropriate to their methods or assumptions, though some have increasingly accepted the challenge. 
Outcomes.
Large-scale international reviews of scientific studies have concluded that psychotherapy is effective for numerous conditions.
One line of research consistently finds that supposedly different forms of psychotherapy show similar effectiveness—historically dubbed the Dodo bird verdict because all win. Further analyses seek to identify the factors that the psychotherapies have in common that seem to account for this, known as common factors theory; for example the quality of the therapeutic relationship, interpretation of problem, and the confrontation of painful emotions.
However, specific therapies have been tested for use with specific disorders, and regulatory organizations in both the UK and US make recommendations for different conditions.
The Helsinki Psychotherapy Study was one of several large long-term clinical trials of psychotherapies that have taken place. Anxious and depressed patients in two short-term therapies (solution-focused and brief psychodynamic) improved faster, but after five years long-term psychotherapy and psychoanalysis gave greater benefits. Several patient and therapist factors appear to predict suitability for different psychotherapies.
Mechanisms of change.
Different therapeutic approaches may be associated with particular theories about what needs to change in a person for a successful therapeutic outcome.
In general, processes of emotional arousal and memory have long been held to play an important role. One theory combining these aspects proposes that permanent change occurs to the extent that the neuropsychological mechanism of memory reconsolidation is triggered and is able to incorporate new emotional experiences.
Adherence.
Adherence to a course of psychotherapy—continuing to attend sessions or complete tasks—is a major issue.
The dropout level—early termination—ranges from around 30% to 60%, depending partly on how it is defined. The range is lower for research settings for various reasons, such as the selection of clients and how they are inducted. Early termination is associated on average with various demographic and clinical characteristics of clients, therapists and treatment interactions. The high level of dropout has raised some criticism about the relevance and efficacy of psychotherapy.
Most psychologists use between-session tasks in their general therapy work, and cognitive behavioral therapies in particular use and see them as an "active ingredient". It is not clear how often clients do not complete them, but it is thought to be a pervasive phenomenon.
From the other side, the adherence of therapists to therapy protocols and techniques—known as "treatment integrity"—has also been studied, with complex mixed results.
Adverse effects.
Research on adverse effects of psychotherapy has been limited for various reasons, yet they may be expected to occur in 5% to 20% of patients. Problems include deterioration of symptoms or developing new symptoms, strains in other relationships, and dependency on the therapist. Some techniques or therapists may carry more risks than others, and some client characteristics may make them more vulnerable. Side-effects from properly conducted therapy should be distinguished from harms caused by malpractice.
General critiques.
Some are skeptical of the healing power of psychotherapeutic relationships. Some dismiss psychotherapy altogether in the sense of a scientific discipline requiring professional practitioners, instead favoring biomedical treatments. Others have pointed out ways in which the values and techniques of therapists can be harmful as well as helpful to clients (or indirectly to other people in a client's life).
Many resources available to a person experiencing emotional distress—the friendly support of friends, peers, family members, clergy contacts, personal reading, healthy exercise, research, and independent coping—all present considerable value. Critics note that humans have been dealing with crises, navigating severe social problems and finding solutions to life problems long before the advent of psychotherapy. Of course, it may well be something in the patient that does not develop these "natural" supports that requires therapy.
On the other hand, some argue psychotherapy is under-utilized and under-researched by contemporary psychiatry despite offering more promise than stagnant medication development. In 2015 the US National Institute of Mental Health is allocating only 5.4% of its budget to new clinical trials of psychotherapies (medication trials are largely funded by pharmaceutical companies), despite plentiful evidence they can work and that patients are more likely to prefer them.
Some suggest that successful therapeutic relationships, based on true acceptance of the client as a human being without contingency, require a theological assumption, an ontological acceptance of God.
Further critiques have emerged from feminist, constructionist and discursive sources. Key to these is the issue of power. In this regard there is a concern that clients are persuaded—both inside and outside the consulting room—to understand themselves and their difficulties in ways that are consistent with therapeutic ideas. This means that alternative ideas (e.g., feminist, economic, spiritual) are sometimes implicitly undermined. Critics suggest that we idealize the situation when we think of therapy only as a helping relationship - arguing instead that it is fundamentally a political practice, in that some cultural ideas and practices are supported while others are undermined or disqualified, and that while it is seldom intended, the therapist-client relationship always participates in society's power relations and political dynamics. A noted academic who espoused this criticism was Michel Foucault.

</doc>
<doc id="24932" url="https://en.wikipedia.org/wiki?curid=24932" title="Posen">
Posen

Posen may refer to:
Places in Europe:
Places in the United States:
Other:

</doc>
<doc id="24933" url="https://en.wikipedia.org/wiki?curid=24933" title="Polywater">
Polywater

Polywater was a hypothesized polymerized form of water that was the subject of much scientific controversy during the late 1960s. By 1969 the popular press had taken notice and sparked fears of a "polywater gap" in the USA.
Increased press attention also brought with it increased scientific attention, and as early as 1970 doubts about its authenticity were being circulated. By 1973 it was found to be illusory, being just water with any number of common organic compounds contaminating it.
Today, polywater is best known as an example of pathological science.
Background.
The Soviet physicist Nikolai Fedyakin, working at a small government research lab in Kostroma, Russia, had performed measurements on the properties of water that had been condensed in, or repeatedly forced through, narrow quartz capillary tubes. Some of these experiments resulted in what was seemingly a new form of water with a higher boiling point, lower freezing point, and much higher viscosity than ordinary water, about that of a syrup.
Boris Derjaguin, director of the laboratory for surface physics at the Institute for Physical Chemistry in Moscow, heard about Fedyakin's experiments. He improved on the method to produce the new water, and though he still produced very small quantities of this mysterious material, he did so substantially faster than Fedyakin did. Investigations of the material properties showed a substantially lower freezing point of −40 °C or less, a boiling point of 150 °C or greater, a density of approx. 1.1 to 1.2 g/cm³, and increased expansion with increasing temperature. The results were published in Soviet science journals, and short summaries were published in "Chemical Abstracts" in English, but Western scientists took no notice of the work.
In 1966, Derjaguin travelled to England for the "Discussions of the Faraday Society" in Nottingham. There he presented the work again, and this time English scientists took note of what he referred to as anomalous water. English scientists then started researching the effect as well, and by 1968 it was also under study in the United States.
By 1969 the concept had spread to newspapers and magazines. There was fear by the United States military that there was a polywater gap with the Soviet Union.
A scientific furor followed. Some experimentalists were able to reproduce Derjaguin's findings, while others failed. Several theories were advanced to explain the phenomenon. Some proposed that it was the cause for increasing resistance on trans-Atlantic phone cables, while others predicted that if polywater were to contact ordinary water, it would convert that water into polywater, echoing the doomsday scenario in Kurt Vonnegut's novel "Cat's Cradle". By the 1970s, polywater was well known in the general population.
During this time several people questioned the authenticity of what had come to be known in the West as polywater. The main concern was contamination of the water, but the papers went to great lengths to note the care taken to avoid this. Denis Rousseau and Sergio Porto of Bell Labs carried out infrared spectrum analysis which showed that polywater was mostly chlorine and sodium.
Denis Rousseau undertook to experiment with his own sweat after playing a handball game at the lab, and found it had identical properties. He then published a paper suggesting that polywater was nothing more than water with small amounts of biological impurities.
Another wave of research followed, this time more tightly controlled. Invariably, polywater could no longer be made. Chemical analysis found that samples of polywater were contaminated with other substances (explaining the changes in melting and boiling points due to colligative properties), and examination of polywater via electron microscopy showed that it also contained small particles of various solids from silica to phospholipids, explaining its greater viscosity.
When the experiments that had produced polywater were repeated with thoroughly cleaned glassware, the anomalous properties of the resulting water vanished, and even the scientists who had originally advanced the case for polywater agreed that it did not exist. This took a few years longer in the Soviet Union, where scientists still clung to the idea.
In August, 1973, Derjaguin and N. V. Churaev published a letter in the journal Nature in which they write that, "these properties should be attributed to impurities rather than to the existence of polymeric water molecules."
Denis Rousseau used polywater as a classic example of pathological science, and has since written on other examples as well.
It has been suggested that polywater should have been dismissed on theoretical grounds. The laws of thermodynamics predicted that, since polywater had a higher boiling point than ordinary water, it meant that it was more stable, and thus all of Earth's water should have turned spontaneously into polywater, instead of just part of it. Richard Feynman remarked that, if such a material existed, then an animal would exist that would use it for food. That animal would just ingest water and excrete polywater, using the energy released on the process to survive.
In fiction.
The story "Polywater Doodle" by Howard L. Myers (writing under the pseudonym "Dr. Dolittle") appeared in the February 1971 issue of "Analog Science Fiction and Fact". It features an animal composed entirely of polywater, with the metabolism described by Richard Feynman. (The title of the story is a pun.)
Polywater is the central idea of the 1972 espionage/thriller novel "A Report from Group 17" by Robert C. O'Brien. The story revolves around the use of a type of polywater to make people controllable and incapable of independent thought or action.
The episodes "The Naked Time" (') and its sequel, "The Naked Now" (') involve forms of polywater intoxication. In the original episode, a scientific research outpost falls victim to polywater, which causes the crew to become so incapacitated that they all died after shutting off environmental controls in the compound. In the sequel, a Starfleet vessel is discovered adrift, its crew frozen in various states due to polywater intoxication.
In Kurt Vonnegut's novel "Cat's Cradle", ice-nine was a form of water that was solid at room temperature, and solidified any water that it contacted, giving it the capability to destroy all life on Earth.

</doc>
<doc id="24935" url="https://en.wikipedia.org/wiki?curid=24935" title="Pathological science">
Pathological science

Pathological science is an area of research where "people are tricked into false results ... by subjective effects, wishful thinking or threshold interactions." The term was first used by Irving Langmuir, Nobel Prize-winning chemist, during a 1953 colloquium at the Knolls Research Laboratory. Langmuir said a pathological science is an area of research that simply will not "go away"—long after it was given up on as "false" by the majority of scientists in the field. He called pathological science "the science of things that aren't so".
Bart Simon lists it among practices pretending to be science: "categories ... such as ... pseudoscience, amateur science, deviant or fraudulent science, bad science, junk science, and popular science ... pathological science, cargo-cult science, and voodoo science". Examples of pathological science may include Martian canals, N-rays, polywater, and cold fusion. The theories and conclusions behind all of these examples are currently rejected or disregarded by the majority of scientists.
Definition.
Pathological science, as defined by Langmuir, is a psychological process in which a scientist, originally conforming to the scientific method, unconsciously veers from that method, and begins a pathological process of wishful data interpretation (see the observer-expectancy effect and cognitive bias). Some characteristics of pathological science are:
Langmuir never intended the term to be rigorously defined; it was simply the title of his talk on some examples of "weird science". As with any attempt to define the scientific endeavor, examples and counterexamples can always be found.
Langmuir's examples.
N-rays.
Langmuir discussed the issue of N-rays as an example of pathological science. It is still considered a traditional case of pathological science.
In 1903, Prosper-René Blondlot was working on X-rays (as were many physicists of the era) and noticed a new visible radiation that could penetrate aluminium. He devised experiments in which a barely visible object was illuminated by these N-rays, and thus became "more visible". Blondlot claimed that N-rays were causing a small visual reaction, too small to be seen under normal illumination, but just visible when most "normal" light sources were removed and the target was just barely visible to begin with.
N-rays became the topic of some debate within the science community. After a time, physicist Robert W. Wood decided to visit Blondlot's lab, which had moved on to the physical characterization of N-rays. An experiment passed the rays from a 2 mm slit through an aluminum prism, from which he was measuring the index of refraction to a precision that required measurements accurate to within 0.01 mm. Wood asked how it was possible that he could measure something to 0.01 mm from a 2 mm source, a physical impossibility in the propagation of any kind of wave. Blondlot replied, "That's one of the fascinating things about the N-rays. They don't follow the ordinary laws of science that you ordinarily think of." Wood then asked to see the experiments being run as usual, which took place in a room required to be very dark so the target was barely visible. Blondlot repeated his most recent experiments and got the same results—despite the fact that Wood had reached over and covertly sabotaged the N-ray apparatus by removing the prism.
Other examples.
Langmuir offered additional examples of what he regarded as pathological science in his original speech:
Later examples.
A 1985 version of Langmuir's speech offered more examples, although at least one of these (polywater) occurred entirely after Langmuir's death in 1957:
Newer examples.
Since Langmuir's original talk, a number of newer examples of what appear to be pathological science have appeared. Denis Rousseau, one of the main debunkers of polywater, gave an update of Langmuir in 1992, and he specifically cited as examples the cases of polywater, Fleischmann's cold fusion and Jacques Benveniste's "infinite dilution".
Polywater.
Polywater was a form of water which appeared to have a much higher boiling point and much lower freezing point than normal water. Many articles were published on the subject, and research on polywater was done around the world with mixed results. Eventually it was determined that many of the properties of polywater could be explained by biological contamination. When more rigorous cleaning of glassware and experimental controls were introduced, polywater could no longer be produced. It took several years for the concept of polywater to die in spite of the later negative results.
Cold fusion.
In 1989, Fleischmann and Pons announced the discovery of a simple and cheap procedure to obtain room-temperature nuclear fusion. Although there were many instances where successful results were reported they lacked consistency and hence cold fusion came to be considered to be an example of pathological science. Two panels convened by the US Department of Energy, one in 1989 and a second in 2004, did not recommend a dedicated federal program for cold fusion research. A small number of researchers continue working on the field.
Water memory.
Jacques Benveniste was a French immunologist who in 1988 published a paper in the prestigious scientific journal "Nature" describing the action of very high dilutions of anti-IgE antibody on the degranulation of human basophils, findings which seemed to support the concept of homeopathy. Biologists were puzzled by Benveniste's results, as only molecules of water, and no molecules of the original antibody, remained in these high dilutions. Benveniste concluded that the configuration of molecules in water was biologically active. Subsequent investigations have not supported Benveniste's findings.

</doc>
<doc id="24936" url="https://en.wikipedia.org/wiki?curid=24936" title="Pneumatic tube">
Pneumatic tube

Pneumatic tubes (or capsule pipelines; also known as Pneumatic Tube Transport or PTT) are systems that propel cylindrical containers through networks of tubes by compressed air or by partial vacuum. They are used for transporting solid objects, as opposed to conventional pipelines, which transport fluids. Pneumatic tube networks gained acceptance in the late 19th and early 20th centuries for offices that needed to transport small, urgent packages (such as mail, paperwork, or money) over relatively short distances (within a building, or, at most within a city). Some installations grew to great complexity, but were mostly superseded. In some settings, such as hospitals, they remain widespread and have been further extended and developed in recent decades.
A small number of pneumatic transportation systems were also built for larger cargo, to compete with more standard train and subway systems. However, these never gained popularity.
History.
Historical use.
Pneumatic capsule transportation was invented by William Murdoch. It was considered little more than a novelty until the invention of the capsule in 1836. The Victorians were the first to use "capsule pipelines" to transmit telegrams, to nearby buildings from telegraph stations.
In 1854, Josiah Latimer Clark was issued a patent "for conveying letters or parcels between places by the pressure of air and vacuum." In 1855, he installed a pneumatic system between the London Stock Exchange in Threadneedle Street, London, and the offices of the Electric Telegraph Company in Lothbury.
While they are commonly used for small parcels and documents – including as cash carriers at banks or supermarkets – they were originally proposed in the early 19th century for transport of heavy freight. It was once envisaged that networks of these massive tubes might be used to transport people.
Current use.
The technology is still used on a smaller scale. While its use for communicating information has been superseded, pneumatic tubes are widely used for transporting small objects, or where convenience and speed in a local environment is useful.
In the United States, drive-up banks often use pneumatic tubes to transport cash and documents between cars and tellers. Most hospitals have a computer-controlled pneumatic tube system to deliver drugs, documents and specimens to and from laboratories and nurses' stations. Many factories use them to deliver parts quickly across large campuses. Many larger stores use systems to securely transport excess cash from checkout stands to back offices, and to send change back to cashiers. NASA's original Mission Control Center had pneumatic tubes connecting controller consoles with staff support rooms. Denver International Airport uses many pneumatic tube systems, including a 25 cm diameter system for moving aircraft parts to remote concourses, a 10 cm system for United Airlines ticketing, and a robust system in the parking toll collection system with an outlet at every booth.
Pneumatic tube systems are used in science, to transport samples during neutron activation analysis. Samples must be moved from the nuclear reactor core, in which they are bombarded with neutrons, to the instrument that records the resulting radiation. As some of the radioactive isotopes in the sample can have very short half-lives, speed is important. These systems may be automated, with a magazine of sample tubes that are moved into the reactor core in turn for a predetermined time, before being moved to the instrument station and finally to a container for storage and disposal.
Until it closed in early 2011, a McDonald's in Edina, Minnesota claimed to be the "World's Only Pneumatic Air Drive-Thru," sending food from their strip-mall location to a drive-through in the middle of a parking lot.
Technology editor Quentin Hardy notes that renewed interest in transmission of data by pneumatic tube accompanies discussions of digital network security, and he cites research into London's forgotten pneumatic network.
Applications.
In postal service.
Pneumatic post or pneumatic mail is a system to deliver letters through pressurized air tubes. It was invented by the Scottish engineer William Murdoch in the 19th century and was later developed by the London Pneumatic Despatch Company. Pneumatic post systems were used in several large cities starting in the second half of the 19th century (including an 1866 London system powerful and large enough to transport humans during trial runs – though not intended for that purpose), but later were largely abandoned.
A major network of tubes in Paris was in use until 1984, when it was abandoned in favor of computers and fax machines. In Prague, in the Czech Republic, the network extended approximately .
Pneumatic post stations usually connect post offices, stock exchanges, banks and ministries. Italy was the only country to issue postage stamps (between 1913 and 1966) specifically for pneumatic post. Austria, France, and Germany issued postal stationery for pneumatic use.
Typical current applications are in banks, hospitals and supermarkets. Many large retailers use pneumatic tubes to transport cheques or other documents from cashiers to the accounting office.
In public transportation.
In 1812, George Medhurst first proposed, but never implemented, blowing passenger carriages through a tunnel. Precursors of pneumatic tube systems for passenger transport, the atmospheric railway (for which the tube was laid between the rails, with a piston running in it suspended from the train through a sealable slot in the top of the tube) were operated as follows:
In 1861, the London Pneumatic Despatch Company built a system large enough to move a person, although it was intended for parcels. The inauguration of the new Holborn Station on 10 October 1865 was marked by having the Duke of Buckingham, the chairman, and some company directors blown through the tube to Euston (a five-minute trip).
The 550-meter Crystal Palace pneumatic railway was exhibited at the Crystal Palace in 1864. This was a prototype for a proposed "Waterloo and Whitehall Railway" that would have run under the River Thames linking Waterloo and Charing Cross. Digging commenced in 1865 but was halted in 1868 due to financial problems.
In 1867 at the American Institute Fair in New York, Alfred Ely Beach demonstrated a 32.6 m long, 1.8 m diameter pipe that was capable of moving 12 passengers plus a conductor. In 1869, the Beach Pneumatic Transit Company of New York secretly constructed a 95 m long, 2.7 m diameter pneumatic subway line under Broadway, to demonstrate the possibilities of the new transport mode. The line only operated for a few months, closing after Beach was unsuccessful in getting permission to extend it – Boss Tweed, an influential local politician, did not want it to go ahead as he was intending to personally invest into competing schemes for an elevated rail line.
In the 1960s, Lockheed and MIT with the United States Department of Commerce conducted feasibility studies on a vactrain system powered by ambient atmospheric pressure and "gravitational pendulum assist" to connect cities on the country's East Coast. They calculated that the run between Philadelphia and New York City would average 174 meters per second, that is 626 km/h (388 mph). When those plans were abandoned as too expensive, Lockheed engineer L.K. Edwards founded Tube Transit, Inc. to develop technology based on "gravity-vacuum transportation". In 1967 he proposed a Bay Area Gravity-Vacuum Transit for California that would run alongside the then-under construction BART system. It was never built.
Research into trains running in partially evacuated tubes is continuing. For further information see Vactrain and Hyperloop.
In money transfer.
In large retail stores, pneumatic tube systems were used to transport sales slips and money from the salesperson to a centralized "tube room", where cashiers could make change, reference credit records, and so on.
Many banks with drive-throughs also use pneumatic tubes.
In medicine.
Many hospitals have pneumatic tube systems which send samples to laboratories.
Technical characteristics.
Modern systems (for smaller, i.e. "normal" tube diameters as used in the transport of small capsules) reach speeds of around per second, though some historical systems already achieved speeds of per second. Further, modern systems can also be computer-controlled, allowing, among other things, the tracking of any specific capsule. Varying air pressures also allow capsules to brake slowly, removing the jarring arrival that used to characterise earlier systems and make them unsuitable for fragile contents.
In fiction.
When pneumatic tubes first came into use in the 19th century, they symbolized technological progress and it was imagined that they would be common in the future. Jules Verne's "Paris in the Twentieth Century" (1863) includes suspended pneumatic tube trains that stretch across the oceans. Albert Robida's "The Twentieth Century" (1882) describes a 1950s Paris where tube trains have replaced railways, pneumatic mail is ubiquitous, and catering companies compete to deliver meals on tap to people's homes through pneumatic tubes. Edward Bellamy's "Looking Backward" (1888) envisions the world of 2000 as interlinked with tubes for delivering goods, while Michel Verne's "An Express of the Future" (1888) questions the sensibility of a transatlantic pneumatic subway. In Michel & Jules Verne's "The Day of an American Journalist in 2889" (1889) submarine tubes carry people faster than "aero-trains" and the "Society for Supplying Food to the Home" allows subscribers to receive meals pneumatically.
Later, because of their use by governments and large businesses, tubes began to symbolize bureaucracy. In George Orwell's "Nineteen Eighty-Four", pneumatic tubes in the Ministry of Truth deliver newspapers to Winston's desk containing articles to be "rectified". Robert A. Heinlein's 1949 novella "Gulf" offered a more neutral view of their use in general postal delivery.
Beginning with the 42nd issue of 181-issue "Doc Savage" Magazine ("The Midas Man", Volume VII, No. 6, Aug 1936), Doc Savage's penthouse on the 86th floor of an unnamed New York City skyscraper (implicitly the Empire State Building) is linked to his "Hidalgo Trading Company" warehouse-boathouse-hangar on the Hudson River waterfront by pneumatic bullet-car nicknamed the "Flea Run", "Go-Devil" and "Angel-Wagon" due to its hundred-mile per hour speed and that plummets straight down from the penthouse ninety stories to a sub-basement, makes a 90° turn to travel a mile and a quarter (a little over two kilometers) 60 feet (18 meters) below 34th Street and then comes back up to ground floor of the warehouse, presumably at a shallower but still steep incline. The interior of the car is heavily padded, with four seats, one behind the other bobsled fashion. Since the car does not turn around, the seats are designed to rotate 180° so that the passengers always face in the direction of travel. The acceleration is such that, when traveling down the tube from the 86th Floor, no sensation of falling is experienced. The system is driven by enormous air compressors and compressed air receiver vessels housed on the roofs of both the skyscraper and the Hidalgo Trading Company.
In a sequence in the 1968 film "Baisers volés" ("Stolen Kisses"), François Truffaut shows the fast transportation of a letter through the underground pneumatic tubes system in Paris. (This scene was later parodied in "The Simpsons" episode "Marge Gets a Job".)
In 1985, the movie "Brazil" also used tubes (as well as other anachronistic-seeming technologies) to evoke the stagnation of bureaucracy.
At the start of each episode of the 1998 television series "Fantasy Island", a darker version of the original, bookings for would-be visitors to the Island were sent to Mr. Roarke via a pneumatic tube from a dusty old travel agency.
The 1994 film version of "The Shadow" includes a sequence in which the camera follows a message capsule as it speeds through a pneumatic tube system. The implication is that the Shadow maintains a private network of tubes for the transportation of secret messages.
The failure of pneumatic tubes to live up to their potential as envisaged in previous centuries has placed them in the company of flying cars and dirigibles as ripe for ironic retro-futurism. The animated television series "The Jetsons" featured pneumatic tubes that people could step into and be sucked up and swiftly spat out at their destination. In the animated television series "Futurama", set in the 31st century, large pneumatic tubes are used in cities for transporting people, whilst smaller ones are used to transport mail. The tubes in "Futurama" are also used to depict the endless confusion of bureaucracy: an immense network of pneumatic tubes connects all offices in New New York City to the "Central Bureaucracy", with all the capsules being deposited directly into a huge pile in the main filing room, with no sorting or organization.
In "Ghostbusters II", the "river of slime" under New York city is found by the Ghostbusters boys to be flowing through an old pneumatic tube line – a reference to the Beach Pneumatic Transit tube.
In the 1998 PC game "Grim Fandango", pneumatic tubes play a role at Manny's office.
In the American television show "Lost", the Dharma Initiative's Pearl research station has a pneumatic tube system. The character Locke put his drawing of the blast door map in the tube without a capsule. It was sucked up into the tube, indicating the system still functioned. The tube from the Pearl leads to a capsule dump.
In Kurt Vonnegut's "Slaughterhouse-Five" pneumatic tubes are used as a way to transport information from one place to the next when covering news articles.
In the popular video game "BioShock", pneumatic tubes transport various items throughout the fictional city of Rapture. In "Portal" and "Portal 2", two other popular games, Aperture Science uses Pneumatic tubes to transport larger-scale objects such as boxes of all kinds throughout their "enrichment center".
Douglas Adams's 1998 computer game "Starship Titanic" features the "Succ-U-Bus" in almost every room –a pneumatic pipe transport system which goes all around the ship; players must understand and use the Succ-U-Bus in order to progress and solve the puzzles.
Umberto Eco in his novel "The Prague Cemetery" has one character, Simonini, send a "petit blue message by pneumatic post". Presumably these messages were on small pieces of blue paper.
In the 2004 Movie "The Polar Express", 'The Pnuematic' transports elves and lead characters from the main control room to various places throughout the North Pole.
In the CBS series, "Person of Interest", a pneumatic tube network is used to avoid tracking of communication by electronic means. The network is shown in the mafia war in the 21st episode of the fourth season, 'Asylum'.
In the 2014 Movie "", a four-seat pneumatic tube shuttle is used to link the downtown tailors office to the country estate & training area.
References.
25.M.Marcu-Pipeline conveyors(pneumatic wheeled pipeline conveyors-state of the art/photos-1990) at page 45 in the "Material handling in pyrometallurgy": proceedings of the International Symposium on Materials Handling in Pyrometallurgy, Hamilton, Ontario, August 26-30, 1990 Twigge-Molecey, T. Price, Metallurgical Society of CIM. Non-Ferrous Pyrometallurgy Section
Pergamon Press, Sep 30, 1990 - Technology & Engineering - 227 pages
External links.
London Midland Magazine – February 1963 – article on the Pneumatic Dispatch Railway in London

</doc>
<doc id="24937" url="https://en.wikipedia.org/wiki?curid=24937" title="Pinzgauer">
Pinzgauer

Pinzgauer may refer to:

</doc>
<doc id="24942" url="https://en.wikipedia.org/wiki?curid=24942" title="Patrilineality">
Patrilineality

Patrilineality, also known as the male line, the spear side, or agnatic kinship, is a common kinship system in which an individual's family membership derives from and is traced through his or her father's lineage. It generally involves the inheritance of property, rights, names, or titles by persons related through male kin.
A patriline ("father line") is a person's father, and additional ancestors, as traced only through males.
Agnatic succession.
Patrilineal or agnatic succession gives priority to or restricts inheritance of a throne or fief to heirs, male or female, descended from the original title holder through males only. Traditionally, agnatic succession is applied in determining the names and membership of European dynasties. The prevalent forms of dynastic succession in Europe, Asia and parts of Africa (but see the Rain Queen) were male-preference primogeniture, agnatic primogeniture or agnatic seniority until after World War II.
By the 21st century most European monarchies replaced their traditional agnatic succession with absolute primogeniture, meaning that the first child born to a monarch inherits the throne, regardless of the child's sex.
Salic Law.
Variations of the Salic Law, generally understood in modern times to mean exclusion of women as hereditary monarchs, restricted succession to thrones and inheritance of fiefs or land to men in parts of medieval and later Europe. Once common, strict Salic inheritance has been officially revoked in all extant European monarchies except the Principality of Liechtenstein. However it still prevails in the transmission of most European titles of nobility, notably excepting Spain.
Genetic genealogy.
The fact that human Y-chromosome DNA (Y-DNA) is paternally inherited enables patrilines, and agnatic kinships, of men to be traced through genetic analysis.
Y-chromosomal Adam (Y-MRCA) is the patrilineal most recent common ancestor from whom all Y-DNA in living men is descended. An identification of a very rare and previously unknown Y-chromosome variant in 2012 led researchers to estimate that Y-chromosomal Adam lived 338,000 years ago (237,000 to 581,000 years ago with 95% confidence), judging from molecular clock and genetic marker studies. Before this discovery, estimates of the date when Y-chromosomal Adam lived were much more recent, estimated to be tens of thousands of years.

</doc>
