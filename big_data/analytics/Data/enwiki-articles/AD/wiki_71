<doc id="22826" url="https://en.wikipedia.org/wiki?curid=22826" title="Object database">
Object database

An object database (also object-oriented database management system - OODBMS) is a database management system in which information is represented in the form of objects as used in object-oriented programming. Object databases are different from relational databases which are table-oriented. Object-relational databases are a hybrid of both approaches.
Object databases have been considered since the early 1980s.
Overview.
Object-oriented database management systems (OODBMSs) combine database capabilities with object-oriented programming language capabilities.
OODBMSs allow object-oriented programmers to develop the product, store them as objects, and replicate or modify existing objects to make new objects within the OODBMS. Because the database is integrated with the programming language, the programmer can maintain consistency within one environment, in that both the OODBMS and the programming language will use the same model of representation. Relational DBMS projects, by way of contrast, maintain a clearer division between the database model and the application.
As the usage of web-based technology increases with the implementation of Intranets and extranets, companies have a vested interest in OODBMSs to display their complex data. Using a DBMS that has been specifically designed to store data as objects gives an advantage to those companies that are geared towards multimedia presentation or organizations that utilize computer-aided design (CAD).
Some object-oriented databases are designed to work well with object-oriented programming languages such as Delphi, Ruby, Python, Perl, Java, C#, Visual Basic .NET, C++, Objective-C and Smalltalk; others such as JADE have their own programming languages. OODBMSs use exactly the same model as object-oriented programming languages.
History.
Object database management systems grew out of research during the early to mid-1970s into having intrinsic database management support for graph-structured objects. The term "object-oriented database system" first appeared around 1985. Notable research projects included Encore-Ob/Server (Brown University), EXODUS (University of Wisconsin–Madison), IRIS (Hewlett-Packard), ODE (Bell Labs), ORION (Microelectronics and Computer Technology Corporation or MCC), Vodak (GMD-IPSI), and Zeitgeist (Texas Instruments). The ORION project had more published papers than any of the other efforts. Won Kim of MCC compiled the best of those papers in a book published by The MIT Press.
Early commercial products included Gemstone (Servio Logic, name changed to GemStone Systems), Gbase (Graphael), and Vbase (Ontologic). The early to mid-1990s saw additional commercial products enter the market. These included ITASCA (Itasca Systems), Jasmine (Fujitsu, marketed by Computer Associates), Matisse (Matisse Software), Objectivity/DB (Objectivity, Inc.), ObjectStore (Progress Software, acquired from eXcelon which was originally Object Design), ONTOS (Ontos, Inc., name changed from Ontologic), O2 (O2 Technology, merged with several companies, acquired by Informix, which was in turn acquired by IBM), POET (now FastObjects from Versant which acquired Poet Software), Versant Object Database (Versant Corporation), VOSS (Logic Arts) and JADE (Jade Software Corporation). Some of these products remain on the market and have been joined by new open source and commercial products such as InterSystems Caché.
Object database management systems added the concept of persistence to object programming languages. The early commercial products were integrated with various languages: GemStone (Smalltalk), Gbase (LISP), Vbase (COP) and VOSS (Virtual Object Storage System for Smalltalk). For much of the 1990s, C++ dominated the commercial object database management market. Vendors added Java in the late 1990s and more recently, C#.
Starting in 2004, object databases have seen a second growth period when open source object databases emerged that were widely affordable and easy to use, because they are entirely written in OOP languages like Smalltalk, Java, or C#, such as Versant's db4o (db4objects), DTS/S1 from Obsidian Dynamics and Perst (McObject), available under dual open source and commercial licensing.
Adoption of object databases.
Object databases based on persistent programming acquired a niche in application areas such as
engineering and spatial databases, telecommunications, and scientific areas such as high energy physics and molecular biology.
Another group of object databases focuses on embedded use in devices, packaged software, and real-time systems.
Technical features.
Most object databases also offer some kind of query language, allowing objects to be found using a declarative programming approach. It is in the area of object query languages, and the integration of the query and navigational interfaces, that the biggest differences between products are found. An attempt at standardization was made by the ODMG with the Object Query Language, OQL.
Access to data can be faster because joins are often not needed (as in a tabular implementation of a relational database). This is because an object can be retrieved directly without a search, by following pointers.
Another area of variation between products is in the way that the schema of a database is defined. A general characteristic, however, is that the programming language and the database schema use the same type definitions.
Multimedia applications are facilitated because the class methods associated with the data are responsible for its correct interpretation.
Many object databases, for example Gemstone or VOSS, offer support for versioning. An object can be viewed as the set of all its versions. Also, object versions can be treated as objects in their own right. Some object databases also provide systematic support for triggers and constraints which are the basis of active databases.
The efficiency of such a database is also greatly improved in areas which demand massive amounts of data about one item. For example, a banking institution could get the user's account information and provide them efficiently with extensive information such as transactions, account information entries etc. The Big O Notation for such a database paradigm drops from O(n) to O(1), greatly increasing efficiency in these specific cases.
Standards.
The Object Data Management Group was a consortium of object database and object-relational mapping vendors, members of the academic community, and interested parties. Its goal was to create a set of specifications that would allow for portable applications that store objects in database management systems. It published several versions of its specification. The last release was ODMG 3.0. By 2001, most of the major object database and object-relational mapping vendors claimed conformance to the ODMG Java Language Binding. Compliance to the other components of the specification was mixed. In 2001, the ODMG Java Language Binding was submitted to the Java Community Process as a basis for the Java Data Objects specification. The ODMG member companies then decided to concentrate their efforts on the Java Data Objects specification. As a result, the ODMG disbanded in 2001.
Many object database ideas were also absorbed into and have been implemented in varying degrees in object-relational database products.
In 2005 Cook, Rai, and Rosenberger proposed to drop all standardization efforts to introduce additional object-oriented query APIs but rather use the OO programming language itself, i.e., Java and .NET, to express queries. As a result, Native Queries emerged. Similarly, Microsoft announced Language Integrated Query (LINQ) and DLINQ, an implementation of LINQ, in September 2005, to provide close, language-integrated database query capabilities with its programming languages C# and VB.NET 9.
In February 2006, the Object Management Group (OMG) announced that they had been granted the right to develop new specifications based on the ODMG 3.0 specification and the formation of the Object Database Technology Working Group (ODBT WG). The ODBT WG planned to create a set of standards that would incorporate advances in object database technology (e.g., replication), data management (e.g., spatial indexing), and data formats (e.g., XML) and to include new features into these standards that support domains where object databases are being adopted (e.g., real-time systems). The work of the ODBT WG was suspended in March 2009 when, subsequent to the economic turmoil in late 2008, the ODB vendors involved in this effort decided to focus their resources elsewhere.
In January 2007 the World Wide Web Consortium gave final recommendation status to the XQuery language. XQuery uses XML as its data model. Some of the ideas developed originally for object databases found their way into XQuery, but XQuery is not intrinsically object-oriented. Because of the popularity of XML, XQuery engines compete with object databases as a vehicle for storage of data that is too complex or variable to hold conveniently in a relational database. XQuery also allows modules to be written to provide encapsulation features that have been provided by Object-Oriented systems.
Comparison with RDBMSs.
An object database stores complex data and relationships between data directly, without mapping to relational rows and columns, and this makes them suitable for applications dealing with very complex data. Objects have a many to many relationship and are accessed by the use of pointers. Pointers are linked to objects to establish relationships. Another benefit of an OODBMS is that it can be programmed with small procedural differences without affecting the entire system.

</doc>
<doc id="22827" url="https://en.wikipedia.org/wiki?curid=22827" title="Ovo-lacto vegetarianism">
Ovo-lacto vegetarianism

An ovo-lacto vegetarian (or lacto-ovo vegetarian) is a vegetarian who does not eat any meat, fish, or poultry. A typical ovo-lacto vegetarian diet includes fruits, vegetables, grains, legumes, nuts, seeds, dairy, and egg products.
Etymology.
The terminology stems from the Latin ' meaning "milk" (as in 'lactation'), ' meaning "egg", and the English term "vegetarian", so as giving the definition of a vegetarian diet containing milk and eggs.
Diet.
In the Western World, ovo-lacto vegetarians are the most common type of vegetarian. Generally speaking, when one uses the term "vegetarian" an ovo-lacto vegetarian is assumed. Ovo-lacto vegetarians are often well-catered to in restaurants and shops, especially in some parts of Europe and metropolitan cities in North America.
Religion.
In Jainism, all individuals eat only food materials derived from plant sources and milk/milk products, and are therefore lacto vegetarians. Jainism prohibits causing harm to any animal, even eggs, as hurting a living being is against the values of Jainism.
In Hinduism, many individuals are either raised as ovo-lacto vegetarians or lacto vegetarians.
The Bible Christian Church was a Christian vegetarian sect founded by William Cowherd in 1809. Cowherd was one of the philosophical forerunners of the Vegetarian Society founded in 1847. The Bible Christian Church promoted the use of eggs, dairy and honey as God's given food per "the promised land flowing with milk and honey" (Exodus 3:8).
Many Seventh-day Adventist followers are lacto-ovo vegetarians. For over 130 years, Seventh-day Adventists have recommended a vegetarian diet which may include milk products and eggs.

</doc>
<doc id="22829" url="https://en.wikipedia.org/wiki?curid=22829" title="Orgy of the Dead">
Orgy of the Dead

Orgy of the Dead is a 1965 erotic horror film directed by Stephen C. Apostolof under the alias A. C. Stephen. The screenplay was adapted by cult film director Edward D. Wood Jr. from his own novel.
Genre.
The film belongs to the genre of nudie cuties, narrative-based films featuring female nudity. It was an evolution of earlier films, which featured striptease and burlesque shows. These predecessors mostly depicted actual stage performances, sometimes attached to a frame story.
Plot.
The film opens to two muscle-bound men dressed in loincloths approaching a crypt. They open the doors, revealing a coffin. They remove the lid and exit the crypt, then the inhabitant of the coffin (Criswell) sits up to deliver an opening narration. This narration mostly matches the prologue of "Night of the Ghouls" (1959), with one minor variation and an additional line. The phrase ""world between the living and the dead"" of the original is changed to ""void between..."". There is also a new line at the end: ""A night with the ghouls, the ghouls reborn, from the innermost depths of the world!"" The opening credits feature the image of "an immobile young woman clad in gold". The image was probably inspired by a memorable scene of "Goldfinger" (1964).
Following the credits, the camera shifts to a lone Chevrolet Corvair driving down a California desert road. Its passengers Bob (William Bates) and Shirley (Pat Barrington) are arguing over the decision to use this night to search for a cemetery. Bob is a horror writer who hopes that the scene of a cemetery at night will bring him inspiration. The conversation ends when Bob accidentally drives the car off the road and over a cliff.
The next scene opens to a nocturnal image of a fog-shrouded cemetery. The lonely figure of the Emperor (Criswell) walks towards a marble altar, sits, and then summons his "Princess of the Night", the Black Ghoul (Fawn Silver), who appears and bows before him. The Emperor warns that if the night's entertainment fails to please him, he will banish the souls of the entertainers to eternal damnation, indicating that he is an all-powerful demonic being.
As the full moon appears, the Black Ghoul summons the first dancer of the night, a Native American woman (Bunny Glaser). The Black Ghoul explains that this woman loved flames, and that both she and her lovers died in flames. The woman dances and strips before the flames of the cemetery. The Black Ghoul then introduces the second dancer of the night, a street walker in life. While the woman dances, Bob and Shirley make their way to the cemetery and start observing the dance from a distance. Shirley suspects that they are observing a college initiation, though Bob seriously doubts her theory.
The Emperor himself summons the third dancer, a woman who worshiped gold above else. The Golden Girl (Pat Barrington) dances in her turn, and the Emperor instructs his loin-clothed servants to reward her with gold. The supposed reward is soon revealed to be a punishment, as the servants place her in a cauldron with liquid gold. What emerges from the cauldron is a golden statue of the living woman who entered. The servants transport the immobile statue to a nearby crypt.
At this point, a werewolf (John Andrews) and mummy (Louis Ojena) appear and seize the intruding young couple. They are brought before the Emperor who decides to postpone deciding their fate. The intruders are tied up, side by side, and allowed to continue watching the dances. The Black Ghoul next introduces the fourth dancer, a "Cat Woman" (Texas Starr). She is depicted as a woman dressed in a leopard costume, which exposes her chest area. As she dances, a servant follows her around and thrashes her with a bullwhip. Offering a sadomasochistic show for the spectators.
The Emperor next calls for a Slave Girl (Nadejda Dobrev) to be whipped for his amusement. The slave wears a tunic and is chained to a wall. Following her torture session, the Slave Girl breaks free and becomes the fifth dancer of the night. Later, the Black Ghoul exhibits a fascination with Shirley and scratches a mark on her. She draws a knife and seems about to kill Shirley, when the Emperor decides it is not yet time for the intruders to properly join them. The female ghoul reluctantly obeys.
The Emperor is puzzled when a human skull appears instead of the next dancer. The Black Ghoul explains it is the symbol of the sixth dancer, who loved bullfighting and matadors. She used to dance over their demise, and now it's time to dance over her own. The dancer of apparent Spanish/Mexican heritage (Stephanie Jones) appears to perform. The Emperor and Ghoul briefly discuss the past of the dancer, who came to them on the Day of the Dead. The seventh dancer appears dressed in Polynesian garments. The Black Ghoul describes her as a worshiper of snakes, smoke, and flames. A rattlesnake is depicted along with her dance. The camera shifts to the mummy and the werewolf. The mummy voices his dislike of snakes and recalls the death of Cleopatra. He informs his companion that ancient Egypt had many snakes and they were the stuff of nightmares.
The Emperor next expresses his boredom and demands "unusual" entertainment, while the Black Ghoul notes that the night is almost over. She reminds her superior that they will be gone at the first sight of the morning sun. They proceed to argue over the fate of Shirley. The argument ends with the introduction of the eighth dancer (Barbara Nordin), a woman who murdered her husband on their wedding night. She dances with the skeleton of her spouse. The argument over Shirley then resumes, as the Ghoul claims her for her own. The Emperor feels the need to assert his own authority over the Black Ghoul.
The ninth dancer (Dene Starnes) was a zombie in life and remains zombie-like in death. The tenth and final dancer (Rene De Beau) is introduced as one who died for feathers, fur, and fluff. She starts her dance in clothing matching this style. When the final dance ends, the Emperor finally offers Shirley to the Ghoul. The Ghoul briefly dances herself as she prepares to claim her prize. But dawn arrives and with it sunlight. The Emperor and all his undead are reduced to bones. The final scene has Bob and Shirley waking up at the scene of the accident, surrounded by paramedics, suggesting it was all a dream. Criswell appears in his coffin to offer parting words to the audience.
Production and casting.
The film's graveyard prologue is a recreation of the opening scene from Ed Wood's then-unreleased 1958 film "Night of the Ghouls". Criswell reprises his role from the earlier film. The action begins when a young couple, Bob (William Bates) and Shirley (sexploitation actress Pat Barrington, billed as Pat Barringer) survive a car crash only to find themselves tied to posts in a misty cemetery where they are forced to watch dead spirits dance for the Emperor of the Night played by Criswell (best known for "Plan 9 from Outer Space"). Ten striptease performances by topless dancers from beyond the grave outfitted in various motifs comprise most of this movie. The Wolf Man (wearing a very obvious mask) and The Mummy are also tossed in for comic relief. Barrington doubles as the blond Gold Girl (inspired by Shirley Eaton in "Goldfinger") while her red-headed "Shirley" character watches her perform. Criswell's undead consort, the sexy Black Ghoul, was written for Maila Nurmi, a.k.a. Vampira, but was instead played by Fawn Silver, who wore a black bouffant wig.
Wood served as writer, production manager, casting agent, and even held up cue cards on this low-budget film, although he did not direct. An article on the making of this film was published in "Femme Fatales", 7:1 (June 1998).
The cape worn by Criswell as The Emperor is the same cape worn by Bela Lugosi as Count Dracula in Bud Abbott Lou Costello Meet Frankenstein (1948). 
The film based on the novel by Edward D. Wood Jr. has no werewolf character, like in the film. Wood received $600 for the novel.
The Black Ghoul appears to have "pasty white skin", with red fingernails and lipstick. She wears a black dress, implying the role of a funerary garment. Black, red, and white are the main colors associated with her.

</doc>
<doc id="22830" url="https://en.wikipedia.org/wiki?curid=22830" title="Ostwald process">
Ostwald process

The Ostwald process is a chemical process for making nitric acid (HNO3). Wilhelm Ostwald developed the process, and he patented it in 1902. The Ostwald process is a mainstay of the modern chemical industry, and it provides the main raw material for the most common type of fertilizer production. Historically and practically, the Ostwald process is closely associated with the Haber process, which provides the requisite raw material, ammonia (NH3).
Description.
Ammonia is converted to nitric acid in 2 stages. It is oxidized by heating with oxygen in the presence of a catalyst such as platinum with 10% rhodium, to form nitric oxide and water. This step is strongly exothermic, making it a useful heat source once initiated:
Stage two encompasses two reactions and is carried out in an absorption apparatus containing water. Initially nitric oxide is oxidized again to yield nitrogen dioxide: This gas is then readily absorbed by the water, yielding the desired product (nitric acid, albeit in a dilute form), while reducing a portion of it back to nitric oxide:
The NO is recycled, and the acid is concentrated to the required strength by distillation.
Alternatively, if the last step is carried out in air:
Typical conditions for the first stage, which contribute to an overall yield of about 98%, are:
A complication that needs to be taken into consideration involves a side-reaction in the first step that reverts the nitric oxide back to :
This is a secondary reaction that is minimised by reducing the time the gas mixtures are in contact with the catalyst.

</doc>
<doc id="22831" url="https://en.wikipedia.org/wiki?curid=22831" title="Oliver Heaviside">
Oliver Heaviside

Oliver Heaviside FRS (; 18 May 1850 – 3 February 1925) was a self-taught English electrical engineer, mathematician, and physicist who adapted complex numbers to the study of electrical circuits, invented mathematical techniques for the solution of differential equations (equivalent to Laplace transforms), reformulated Maxwell's field equations in terms of electric and magnetic forces and energy flux, and independently co-formulated vector analysis. Although at odds with the scientific establishment for most of his life, Heaviside changed the face of telecommunications, mathematics, and science for years to come.
Biography.
Early years.
Heaviside was born at 55 Kings Street (now Plender Street) in London's Camden Town. He was short and red-headed, and suffered from scarlet fever when young, which left him with a hearing impairment. A small legacy enabled the family to move to a better part of Camden when he was thirteen and he was sent to Camden House Grammar School. He was a good student (i.e. placed fifth out of five hundred students in 1865) but his parents could not keep him at school after he was 16 so he continued studying for a year by himself and had no further formal education.
Heaviside's uncle by marriage was Sir Charles Wheatstone (1802–1875), the original co-inventor of the first commercially successful telegraph in the mid-1830s, and an internationally celebrated expert in telegraphy and electromagnetism. Wheatstone took a strong interest in his nephew's education and in 1867 sent him north to work with his older brother Arthur who was managing one of Wheatstone's telegraph companies in Newcastle-upon-Tyne.
Two years later he took a job as a telegraph operator with the Danish Great Northern Telegraph Company laying a cable from Newcastle to Denmark using British contractors, soon becoming an electrician. Heaviside continued to study while working, and by the age of 22 he published an article in the prestigious "Philosophical Magazine" on 'The Best Arrangement of Wheatstone's Bridge for measuring a Given Resistance with a Given Galvanometer and Battery' which received positive comments from physicists who had unsuccessfully tried to solve this algebraic problem, including Sir William Thomson, to whom he gave a copy of the paper, and James Clerk Maxwell. However, when he published an article on the duplex method of using a telegraph cable, he poked fun at R. S. Culley, the engineer in chief of the Post Office telegraph system who had been dismissing duplex as impractical. Later in 1873 his application to join the Society of Telegraph Engineers was turned down with the comment that "they didn't want telegraph clerks". This riled Heaviside who asked Thomson to sponsor him, and with the support also of the president he was admitted "despite the P.O. snobs".
In 1873 Heaviside had encountered Maxwell's newly published, and today famous, two-volume "Treatise on Electricity and Magnetism". In his old age Heaviside recalled:
Doing research from home, he helped develop transmission line theory (also known as the ""telegrapher's equations""). Heaviside showed mathematically that uniformly distributed inductance in a telegraph line would diminish both attenuation and distortion, and that, if the inductance were great enough and the insulation resistance not too high, the circuit would be distortionless while currents of all frequencies would have equal speeds of propagation. Heaviside's equations helped further the implementation of the telegraph.
Middle years.
From 1882 to 1902, except for three years, he contributed regular articles to the trade paper "The Electrician", which wished to improve its standing, for which he was paid £40 per year. This was hardly enough to live on, but his demands were very small and he was doing what he most wanted to. Between 1883 and 1887 these averaged 2–3 articles per month and these articles later formed the bulk of his "Electromagnetic Theory" and "Electrical Papers".
In 1880, Heaviside researched the skin effect in telegraph transmission lines. That same year he patented, in England, the coaxial cable. In 1884 he recast Maxwell's mathematical analysis from its original cumbersome form (they had already been recast as quaternions) to its modern vector terminology, thereby reducing twelve of the original twenty equations in twenty unknowns down to the four differential equations in two unknowns we now know as Maxwell's equations. The four re-formulated Maxwell's equations describe the nature of electric charges (both static and moving), magnetic fields, and the relationship between the two, namely electromagnetic fields.
Between 1880 and 1887, Heaviside developed the operational calculus using "p" for the differential operator, (which Boole had previously denoted by "D"), giving a method of solving differential equations by direct solution as algebraic equations This later caused a great deal of controversy, owing to its lack of rigour. He famously said, "Mathematics is an experimental science, and definitions do not come first, but later on." He was replying to criticism over his use of operators that were not clearly defined. On another occasion he stated somewhat more defensively, "I do not refuse my dinner simply because I do not understand the process of digestion." 
In 1887, Heaviside worked with his brother Arthur on a paper entitled "The Bridge System of Telephony". However the paper was blocked by Arthur's superior, William Henry Preece of the Post Office, because part of the proposal was that loading coils (inductors) should be added to telephone and telegraph lines to increase their self-induction and correct the distortion which they suffered. Preece had recently declared self-inductance to be the great enemy of clear transmission. Heaviside was also convinced that Preece was behind the sacking of the editor of "The Electrician" which brought his long-running series of articles to a halt (until 1891). There was a long history of animosity between Preece and Heaviside. Heaviside considered Preece to be mathematically incompetent; an assessment supported by the biographer Paul J. Nahin: "Preece was a powerful government official, enormously ambitious, and in some remarkable ways, an utter blockhead." Preece's motivations in suppressing Heaviside's work were more to do with protecting Preece's own reputation and avoiding having to admit error than any perceived faults in Heaviside's work.
The importance of Heaviside's work remained undiscovered for some time after publication in "The Electrician", and so its rights lay in the public domain. In 1897, AT&T employed one of its own scientists, George A. Campbell, and an external investigator Michael I. Pupin to find some respect in which Heaviside's work was incomplete or incorrect. Campbell and Pupin extended Heaviside's work, and AT&T filed for patents covering not only their research, but also the technical method of constructing the coils previously invented by Heaviside. AT&T later offered Heaviside money in exchange for his rights; it is possible that the Bell engineers' respect for Heaviside influenced this offer. However, Heaviside refused the offer, declining to accept any money unless the company were to give him full recognition. Heaviside was chronically poor, making his refusal of the offer even more striking.
But this setback had the effect of turning Heaviside's attention towards electromagnetic radiation, and in two papers of 1888 and 1889, Heaviside calculated the deformations of electric and magnetic fields surrounding a moving charge, as well as the effects of it entering a denser medium. This included a prediction of what is now known as Cherenkov radiation, and inspired his friend George FitzGerald to suggest what now is known as the Lorentz–FitzGerald contraction.
In 1889, Heaviside first published a correct derivation of the magnetic force on a moving charged particle, which is now called the Lorentz Force.
In the late 1880s and early 1890s, Heaviside worked on the concept of electromagnetic mass. Heaviside treated this as material mass, capable of producing the same effects. Wilhelm Wien later verified Heaviside's expression (for low velocities).
In 1891 the British Royal Society recognized Heaviside's contributions to the mathematical description of electromagnetic phenomena by naming him a Fellow of the Royal Society, and the following year devoting more than fifty pages of the "Philosophical Transactions" of the Society to his vector methods and electromagnetic theory. In 1905 Heaviside was given an honorary doctorate by the University of Göttingen.
Later years and views.
In 1896, FitzGerald and John Perry obtained a civil list pension of £120 per year for Heaviside, who was now living in Devon, and persuaded him to accept it, after he had rejected other charitable offers from the Royal Society.
In 1902, Heaviside proposed the existence of what is now known as the Kennelly–Heaviside layer of the ionosphere. Heaviside's proposal included means by which radio signals are transmitted around the Earth's curvature. The existence of the ionosphere was confirmed in 1923. The predictions by Heaviside, combined with Planck's radiation theory, probably discouraged further attempts to detect radio waves from the Sun and other astronomical objects. For whatever reason, there seem to have been no attempts for 30 years, until Jansky's development of radio astronomy in 1932.
In later years his behavior became quite eccentric. According to associate B. A. Behrend, he became a recluse who was so averse to meeting people that he delivered the manuscripts of his "Electrician" papers to a grocery store, where the editors picked them up. Though he had been an active cyclist in his youth, his health seriously declined in his sixth decade. During this time Heaviside would sign letters with the initials ""W.O.R.M."" after his name. Heaviside also reportedly started painting his fingernails pink and had granite blocks moved into his house for furniture. In 1922, he became the first recipient of the Faraday Medal, which was established that year.
On Heaviside's religious views, he was a Unitarian, but not a religious one. He was even said to have made fun of people who put their faith in a supreme being.
Heaviside died, 3 February 1925, at Torquay in Devon, and is buried near the eastern corner of Paignton cemetery. He is buried with his father, Thomas Heaviside (1813–1896) and his mother, Rachel Elizabeth Heaviside. The gravestone was cleaned thanks to an anonymous donor sometime in 2005. Most of his recognition was gained posthumously.
Heaviside Memorial Project.
In July 2014, academics at Newcastle University, UK and the Newcastle Electromagnetics Interest Group founded the Heaviside Memorial Project in a bid to fully restore the monument through public subscription. The restored memorial was ceremonially unveiled on 30 August 2014 by Alan Heather, a distant relative of Heaviside. The unveiling was attended by the Mayor of Torbay, the MP for Torbay, an ex-curator of the Science Museum (representing the Institution of Engineering and Technology), the Chairman of the Torbay Civic Society, and delegates from Newcastle University.
The Heaviside Collection 1872-1923.
A collection of Heaviside's notebooks, papers, correspondence, notes and annotated pamphlets on telegraphy is held at Institute of Engineering and Technology (IET) Archive Centre, Savoy Hill House 7-10, Savoy Hill, London WC2R 0BU Email: archives@theiet.org
Innovations and discoveries.
Heaviside did much to develop and advocate vector methods and the vector calculus. Maxwell's formulation of electromagnetism consisted of 20 equations in 20 variables. Heaviside employed the curl and divergence operators of the vector calculus to reformulate 12 of these 20 equations into four equations in four variables (B, E, J, and ρ), the form by which they have been known ever since (see Maxwell's equations). Less well known is that Heaviside's equations and Maxwell's are not exactly the same, and in fact it is easier to modify the latter to make them compatible with quantum physics.
He invented the Heaviside step function and employed it to model the current in an electric circuit. He was the first to use the unit impulse function now usually known as the Dirac delta function. He invented his Operational calculus method for solving linear differential equations. This resembles the currently used Laplace transform method based on the "Bromwich integral" named after Bromwich who devised a rigorous mathematical justification for Heaviside's operator method using contour integration. It should be mentioned here that Heaviside was familiar with the Laplace transform method but considered his own method more direct.
Heaviside advanced the idea that the Earth's uppermost atmosphere contained an ionized layer known as the ionosphere; in this regard, he predicted the existence of what later was dubbed the Kennelly–Heaviside layer. In 1945 Edward Victor Appleton received the Nobel Prize in Physics for proving that this layer really existed. Heaviside developed the transmission line theory (also known as the "telegrapher's equations"), which had the effect of increasing the transmission rate over transatlantic cables by a factor of ten. It originally took ten minutes to transmit each character, and this immediately improved to one character per minute. Closely related to this was his discovery that telephone transmission could be greatly improved by placing electrical inductance in series with the cable. Heaviside also independently discovered the Poynting vector.
Electromagnetic terms.
Heaviside coined the following terms of art in electromagnetic theory:
Further reading.
Sorted by date.

</doc>
<doc id="22832" url="https://en.wikipedia.org/wiki?curid=22832" title="Book of Omni">
Book of Omni

The Book of Omni is one of the books that make up the Book of Mormon. The book contains only one chapter although it covers more than two centuries of Nephite history (from "ca" 323 BC to 130 BC, according to footnotes).
The record passes from generation to generation.
Nephi, who wrote First and Second Nephi forged the record, a book written on sheets, or plates of gold.
Nephi passed them to his brother Jacob,
Jacob passed them to his son Enos,
Enos passed them to his son Jarom,
Jarom passes them to his son Omni.
In the Book of Omni, we find that:
Omni passes them to his son Amaron, ()
Amaron passes them to his brother Chemish, ()
Chemish passes them to his son Abinadom, ()
Abinadom passes them to his son Amaleki ().
The moral and general civilizational decline of the Nephites is reflected in the fact that with the exception of Abinadom who writes slightly more than his father Chemish, each successive author from Nephi to Abinadom writes less than his predecessor. The final author of the Book of Omni and the Small Plates of Nephi, Amaleki, breaks this general rule. Much like Mormon (who may have taken Amaleki as his model), this last historian of the civilization that lasted for 400 years in the land of Nephi rose to the occasion and, filled with a sense of longing for what has been lost, eloquently recounted the last days of the Nephite people in their ancestral homeland, the land of Nephi.
Narrative.
The initial author was Omni, but several others were charged with keeping the record as time passed, though few made significant contributions. Verse 5 explains that "the more wicked part of the Nephites were destroyed." There is little detail about the destruction, except to say that the Lord did visit them in great judgment because of their wickedness.
Abinadom speaks of many wars between the people of Nephi and the Lamanites.
Amaleki speaks of the then current Nephite king, named Mosiah. As had happened previously, the Lord told the king (who appears to be a spiritual leader as well as a secular leader) to lead the righteous Nephites out of the land of Nephi, their ancestral home for the previous 400 years, to a new place. At the end of their journey they discover the Mulekite people whose ancestors had also come from Jerusalem, but after it was attacked by the Babylonians. These people, however, did not bring religious or historical records with them which had two results—they had lost their religion, and they were unable to preserve their language from generation to generation. These people are known as the people of Zarahemla (the name of their then current king and also the name given to the land). Mosiah arranges for the people of Zarahemla to be taught the Nephite language, and Zarahemla is able to recount to him their oral history.
The two groups of people united themselves with Mosiah as their king, and they are all known as Nephites.
The first mention of the Jaredites is found here as well. A large stone is found with writing on it. Mosiah is able to "interpret the engravings by the gift and power of God." It tells of a man named Coriantumr and the downfall of his people. Their history is recounted more fully in the Book of Ether.
Mosiah, the king dies and his son, Benjamin, becomes king. There is a war between the Nephites led by Benjamin and the Lamanites, which by this time is nothing new.
It is apparent that many of the Nephites were reluctant to leave their long-time homeland. Ameliki describes how some of the Nephites wished to return to the land of Nephi, apparently in an attempt to reclaim it. At the time Ameliki stops writing, he has not received word of them, including his brother who is among them.
Amaleki closes with some words about Christ, asserting that his words are true and that it is his intent to help others come unto Christ. He states at the close of the book that, having no descendants to carry on the record-keeping, he will give the records to King Benjamin.
The plates.
The Book of Omni is notable also for being the last of the books contained on the Small Plates of Nephi, one of two major divisions of the gold plates which Joseph Smith translated to obtain the Book of Mormon.
From First Nephi to the end of Omni, the book is a first person narrative of the writers (although there are many quotations). The book immediately following Omni, the Words of Mormon, is an editorial insertion that explains how the first person narrative came to be inserted into the Book of Mormon and how subsequent narrative will differ, being mostly third person narration by Mormon that summarizes more lengthy accounts taken from the Large Plates of Nephi. This third person record extends from Mosiah to Fourth Nephi.

</doc>
<doc id="22834" url="https://en.wikipedia.org/wiki?curid=22834" title="Ozone layer">
Ozone layer

The ozone layer or ozone shield refers to a region of Earth's stratosphere that absorbs most of the Sun's ultraviolet (UV) radiation. It contains high concentrations of ozone (O3) relative to other parts of the atmosphere, although still very small relative to other gases in the stratosphere. The ozone layer contains less than 10 parts per million of ozone, while the average ozone concentration in Earth's atmosphere as a whole is only about 0.3 parts per million. The ozone layer is mainly found in the lower portion of the stratosphere, from approximately above Earth, though the thickness varies seasonally and geographically.
The ozone layer was discovered in 1913 by the French physicists Charles Fabry and Henri Buisson. Measurements of the sun, showed that the radiation sent out from its surface, and which reaches the ground on Earth, is generally consistent with the spectrum of a black body with a temperature in the range of 5,500–6,000 K (5,227 to 5,727°C), except that there was no radiation below a wavelength of about 310 nm at the ultraviolet end of the spectrum. It was deduced that the missing radiation was being absorbed by something in the atmosphere. Eventually the spectrum of the missing radiation was matched to one known chemical, Ozone. Its properties were explored in detail by the British meteorologist G. M. B. Dobson, who developed a simple spectrophotometer (the Dobsonmeter) that could be used to measure stratospheric ozone from the ground. Between 1928 and 1958, Dobson established a worldwide network of ozone monitoring stations, which continue to operate to this day. The "Dobson unit", a convenient measure of the amount of ozone overhead, is named in his honor.
The ozone layer absorbs 97–99% of the Sun's medium-frequency ultraviolet light (from about 200 nm to 315 nm wavelength), which otherwise would potentially damage exposed life forms near the surface.
The United Nations General Assembly has designated September 16 as the International Day for the Preservation of the Ozone Layer.
Venus also has a thin ozone layer at an altitude of 100 kilometers from the planet's surface.
Sources.
The photochemical mechanisms that give rise to the ozone layer were discovered by the British physicist Sydney Chapman in 1930. Ozone in the Earth's stratosphere is created by ultraviolet light striking ordinary oxygen molecules containing two oxygen atoms (O2), splitting them into individual oxygen atoms (atomic oxygen); the atomic oxygen then combines with unbroken O2 to create ozone, O3. The ozone molecule is unstable (although, in the stratosphere, long-lived) and when ultraviolet light hits ozone it splits into a molecule of O2 and an individual atom of oxygen, a continuing process called the ozone-oxygen cycle.
Chemically, this can be described as:
About 90% of the ozone in our atmosphere is contained in the stratosphere. Ozone concentrations are greatest between about , where they range from about 2 to 8 parts per million. If all of the ozone were compressed to the pressure of the air at sea level, it would be only thick.
Ultraviolet light.
Although the concentration of the ozone in the ozone layer is very small, it is vitally important to life because it absorbs biologically harmful ultraviolet (UV) radiation coming from the sun. Extremely short or vacuum UV (10–100 nm) is screened out by nitrogen. UV radiation capable of penetrating nitrogen is divided into three categories, based on its wavelength; these are referred to as UV-A (400–315 nm), UV-B (315–280 nm), and UV-C (280–100 nm).
UV-C, which is very harmful to all living things, is entirely screened out by a combination of dioxygen (< 200 nm) and ozone (> about 200 nm) by around altitude. UV-B radiation can be harmful to the skin and is the main cause of sunburn; excessive exposure can also cause cataracts, immune system suppression, and genetic damage, resulting in problems such as skin cancer. The ozone layer (which absorbs from about 200 nm to 310 nm with a maximal absorption at about 250 nm) is very effective at screening out UV-B; for radiation with a wavelength of 290 nm, the intensity at the top of the atmosphere is 350 million times stronger than at the Earth's surface. Nevertheless, some UV-B, particularly at its longest wavelengths, reaches the surface, and is important for the skin's production of vitamin D.
Ozone is transparent to most UV-A, so most of this longer-wavelength UV radiation reaches the surface, and it constitutes most of the UV reaching the Earth. This type of UV radiation is significantly less harmful to DNA, although it may still potentially cause physical damage, premature aging of the skin, indirect genetic damage, and skin cancer.
Distribution in the stratosphere.
The thickness of the ozone layer—that is, the total amount of ozone in a column overhead—varies by a large factor worldwide, being in general smaller near the equator and larger towards the poles. It also varies with season, being in general thicker during the spring and thinner during the autumn. The reasons for this latitude and seasonal dependence are complicated, involving atmospheric circulation patterns as well as solar intensity.
Since stratospheric ozone is produced by solar UV radiation, one might expect to find the highest ozone levels over the tropics and the lowest over polar regions. The same argument would lead one to expect the highest ozone levels in the summer and the lowest in the winter. The observed behavior is very different: most of the ozone is found in the mid-to-high latitudes of the northern and southern hemispheres, and the highest levels are found in the spring, not summer, and the lowest in the autumn, not winter in the northern hemisphere. During winter, the ozone layer actually increases in depth. This puzzle is explained by the prevailing stratospheric wind patterns, known as the Brewer-Dobson circulation. While most of the ozone is indeed created over the tropics, the stratospheric circulation then transports it poleward and downward to the lower stratosphere of the high latitudes. However, owing to the ozone hole phenomenon, the lowest amounts of column ozone found anywhere in the world are over the Antarctic in the southern spring period of September and October and to a lesser extent over the Arctic in the northern spring period of March, April, and May.
The ozone layer is higher in altitude in the tropics, and lower in altitude outside the tropics, especially in the polar regions. This altitude variation of ozone results from the slow circulation that lifts the ozone-poor air out of the troposphere into the stratosphere. As this air slowly rises in the tropics, ozone is produced as the sun overhead photolyzes oxygen molecules. As this slow circulation levels off and flows towards the mid-latitudes, it carries the ozone-rich air from the tropical middle stratosphere to the mid-and-high latitudes lower stratosphere. The high ozone concentrations at high latitudes are due to the accumulation of ozone at lower altitudes.
The Brewer-Dobson circulation moves very slowly. The time needed to lift an air parcel by 1 km in the lower tropical stratosphere is about 2 months (18 m per day). However, horizontal poleward transport in the lower stratosphere is much faster and amounts to approximately 100 km per day in the northern hemisphere whilst it is only half as much in the southern hemisphere (~51 km per day). Even though ozone in the lower tropical stratosphere is produced at a very slow rate, the lifting circulation is so slow that ozone can build up to relatively high levels by the time it reaches .
Ozone amounts over the continental United States (25°N to 49°N) are highest in the northern spring (April and May). These ozone amounts fall over the course of the summer to their lowest amounts in October, and then rise again over the course of the winter. Again, wind transport of ozone is principally responsible for the seasonal changes of these higher latitude ozone patterns.
The total column amount of ozone generally increases as we move from the tropics to higher latitudes in both hemispheres. However, the overall column amounts are greater in the northern hemisphere high latitudes than in the southern hemisphere high latitudes. In addition, while the highest amounts of column ozone over the Arctic occur in the northern spring (March–April), the opposite is true over the Antarctic, where the lowest amounts of column ozone occur in the southern spring (September–October).
Depletion.
The ozone layer can be depleted by free radical catalysts, including nitric oxide (NO), nitrous oxide (N2O), hydroxyl (OH), atomic chlorine (Cl), and atomic bromine (Br). While there are natural sources for all of these species, the concentrations of chlorine and bromine increased markedly in recent decades due to the release of large quantities of man-made organohalogen compounds, especially chlorofluorocarbons (CFCs) and bromofluorocarbons. These highly stable compounds are capable of surviving the rise to the stratosphere, where Cl and Br radicals are liberated by the action of ultraviolet light. Each radical is then free to initiate and catalyze a chain reaction capable of breaking down over 100,000 ozone molecules. By 2009, nitrous oxide was the largest ozone-depleting substance (ODS) emitted through human activities.
The breakdown of ozone in the stratosphere results in reduced absorption of ultraviolet radiation. Consequently, unabsorbed and dangerous ultraviolet radiation is able to reach the Earth’s surface at a higher intensity. Ozone levels have dropped by a worldwide average of about 4% since the late 1970s. For approximately 5% of the Earth's surface, around the north and south poles, much larger seasonal declines have been seen, and are described as "ozone holes". The discovery of the annual depletion of ozone above the Antarctic was first announced by Joe Farman, Brian Gardiner and Jonathan Shanklin, in a paper which appeared in "Nature" on May 16, 1985.
Regulation.
To support successful regulation attempts, the ozone case was communicated to lay persons "with easy-to-understand bridging metaphors derived from the popular culture" and related to "immediate risks with everyday relevance". The specific metaphors used in the discussion (ozone shield, ozone hole) proved quite useful and, compared to global climate change, was much more seen as an "hot issue" and imminent risk. Lay people were cautious about a depletion of the ozone layer and the risks of skin cancer.
In 1978, the United States, Canada and Norway enacted bans on CFC-containing aerosol sprays that damage the ozone layer. The European Community rejected an analogous proposal to do the same. In the U.S., chlorofluorocarbons continued to be used in other applications, such as refrigeration and industrial cleaning, until after the discovery of the Antarctic ozone hole in 1985. After negotiation of an international treaty (the Montreal Protocol), CFC production was capped at 1986 levels with commitments to long-term reductions. Since that time, the treaty was amended to ban CFC production after 1995 in the developed countries, and later in developing countries. Today, all of the world's 197 countries have signed the treaty. Beginning January 1, 1996, only recycled and stockpiled CFCs were available for use in developed countries like the US. This production phaseout was possible because of efforts to ensure that there would be substitute chemicals and technologies for all ODS uses.
On August 2, 2003, scientists announced that the global depletion of the ozone layer may be slowing down due to the international regulation of ozone-depleting substances. In a study organized by the American Geophysical Union, three satellites and three ground stations confirmed that the upper-atmosphere ozone-depletion rate slowed down significantly during the previous decade. Some breakdown can be expected to continue due to ODSs used by nations which have not banned them, and due to gases which are already in the stratosphere. Some ODSs, including CFCs, have very long atmospheric lifetimes, ranging from 50 to over 100 years. It has been estimated that the ozone layer will recover to 1980 levels near the middle of the 21st century.
Compounds containing C–H bonds (such as hydrochlorofluorocarbons, or HCFCs) have been designed to replace CFCs in certain applications. These replacement compounds are more reactive and less likely to survive long enough in the atmosphere to reach the stratosphere where they could affect the ozone layer. While being less damaging than CFCs, HCFCs can have a negative impact on the ozone layer, so they are also being phased out. These in turn are being replaced by hydrofluorocarbons (HFCs) and other compounds that do not destroy stratospheric ozone at all.

</doc>
<doc id="22841" url="https://en.wikipedia.org/wiki?curid=22841" title="Public Enemy (band)">
Public Enemy (band)

Public Enemy is an American hip hop group consisting of Chuck D, Flavor Flav, Professor Griff, Khari Wynn, DJ Lord, and the S1W group. Formed on Long Island, New York in 1982, they are known for their politically charged music and criticism of the American media, with an active interest in the frustrations and concerns of the African American community. They remain one of the most critically acclaimed bands in history. Their first four albums during the late 1980s and early 1990s were all certified either gold or platinum and were, according to music critic Robert Hilburn in 1998, "the most acclaimed body of work ever by a hip hop act."
In 2004, "Rolling Stone" magazine ranked Public Enemy number 44 on its list of the Immortals: 100 Greatest Artists of All Time, the highest ranking for a hip hop act. The group was inducted into the Long Island Music Hall of Fame in 2007. The band were announced as inductees for the 2013 class of the Rock and Roll Hall of Fame on December 11, 2012, making them the fourth hip-hop act to be inducted.
History.
Formation and early years (1982–1986).
Carlton Ridenhour (Chuck D) and William Drayton (Flavor Flav) met at Long Island's Adelphi College in the early-1980s. Developing his talents as an MC with Flav while delivering furniture for his father's business, Chuck D and Spectrum City, as the group was called, released the record "Check Out the Radio", backed by "Lies", a social commentary—both of which would influence RUSH Productions' Run–D.M.C. and Beastie Boys. Chuck D put out a tape to promote WBAU (the radio station where he was working at the time) and to fend off a local MC who wanted to battle him. He called the tape "Public Enemy #1" because he felt like he was being persecuted by people in the local scene. This was the first reference to the notion of a public enemy in any of Chuck D's songs. The single was created by Chuck D with a contribution by Flavor Flav, though this was before the group "Public Enemy" was officially assembled. Around 1986, Bill Stephney, the former Program Director at WBAU, was approached by Ali Hafezi and offered a position with the label. Stephney accepted, and his first assignment was to help fledgling producer Rick Rubin sign Chuck D, whose song "Public Enemy Number One" Rubin had heard from Andre "Doctor Dré" Brown.
According to the book "The History of Rap Music" by Cookie Lommel, "Stephney thought it was time to mesh the hard-hitting style of Run DMC with politics that addressed black youth. Chuck recruited Spectrum City, which included Hank Shocklee, his brother Keith Shocklee, and Eric "Vietnam" Sadler, collectively known as the Bomb Squad, to be his production team and added another Spectrum City partner, Professor Griff, to become the group's Minister of Information. With the addition of Flavor Flav and another local mobile DJ named Terminator X, the group Public Enemy was born." According to Chuck, The S1W, which stands for Security of the First World, "represents that the black man can be just as intelligent as he is strong. It stands for the fact that we're not third-world people, we're first-world people; we're the original people." Public Enemy started out as opening act for the Beastie Boys during the latter's "Licensed to Ill" popularity, and in 1987 released their debut album "Yo! Bum Rush the Show". Over the next few years, Public Enemy released "It Takes a Nation of Millions to Hold Us Back", "Fear of a Black Planet", and "Apocalypse 91… The Enemy Strikes Black". In addition to ushering in the golden age of hip hop, during this time, Public Enemy reached the height of their popularity, adulation, and controversy. The group then separated from Def Jam and has since been independently producing, marketing, and publishing their music.
Mainstream success (1987–1994).
Their debut album, "Yo! Bum Rush the Show", was released in 1987 to critical acclaim. The album was the group's first step toward stardom. In October 1987, music critic Simon Reynolds dubbed Public Enemy "a superlative "rock" band". They released their second album "It Takes a Nation of Millions to Hold Us Back" in 1988, which performed better in the charts than their previous release, and included the hit single "Don't Believe the Hype" in addition to "Bring the Noise". "Nation of Millions..." was the first hip hop album to be voted album of the year in "The Village Voice"s influential Pazz & Jop critics' poll.
In 1989, the group returned to the studio to record "Fear of a Black Planet", which continued their politically charged themes. The album was supposed to be released in late 1989, but was pushed back to April 1990. It was the most successful of any of their albums and, in 2005, was selected for preservation in the Library of Congress. It included the singles "Welcome To The Terrordome", "911 Is a Joke", which criticized emergency response units for taking longer to arrive at emergencies in the black community than those in the white community, and "Fight the Power". "Fight the Power" is regarded as one of the most popular and influential songs in hip hop history. It was the theme song of Spike Lee's "Do the Right Thing".
The group's next release, "Apocalypse '91...The Enemy Strikes Black", continued this trend, with songs like "Can't Truss It", which addressed the history of slavery and how the black community can fight back against oppression; "I Don't Wanna be Called Yo Nigga", a track that takes issue with the use of the word "nigga" outside of its original derogatory context. The album also included the controversial song and video "By the Time I Get to Arizona", which chronicled the black community's frustration that some US states did not recognize Martin Luther King Jr.'s birthday as a national holiday. The video featured members of Public Enemy taking out their frustrations on politicians in the states not recognizing the holiday. In 1992, the group was one of the first rap acts to perform at the Reading Festival, in England, headlining the second day of the three day festival.
Terminator X's exit and DJ Lord's entrance (1998–current).
After a 1994 motorcycle accident shattered his left leg and kept him in the hospital for a full month, Terminator X relocated to his 15-acre farm in Vance County, North Carolina. By 1998, he was ready to retire from the group and focus full-time on raising African black ostriches on his farm. In late 1998, the group started looking for Terminator X's permanent replacement. Following several months of searching for a DJ, Professor Griff saw DJ Lord at a Vestax Battle and approached him about becoming the DJ for Public Enemy. DJ Lord joined as the group's full-time DJ just in time for Public Enemy's 40th World Tour. Since 1999, he has been the official DJ for Public Enemy on albums and world tours while winning numerous turntablist competitions, including multiple DMC finals.
In 2007, the group released an album entitled "How You Sell Soul to a Soulless People Who Sold Their Soul?". Public Enemy's single from the album was "Harder Than You Think". Four years after "How You Sell Soul...", in January 2011, Public Enemy released the album "Beats and Places", a compilation of remixes and "lost" tracks. On July 13, 2012, "Most of My Heroes Still Don't Appear on No Stamp" was released and was exclusively available on iTunes. In July 2012, on UK television an advert for the London 2012 Summer Paralympics featured a short remix of the song "Harder Than You Think". The advert caused the song to reach No. 4 in the UK Singles Chart on September 2, 2012. On July 30, 2012, Public Enemy performed a free concert with Salt-N-Pepa and Kid 'n Play at Wingate Park in Brooklyn, New York as part of the Martin Luther King Jr. Concert Series. On August 26, 2012, Public Enemy performed at South West Four music festival in Clapham Common in London. On October 1, 2012 "The Evil Empire of Everything" was released. On June 29, 2013, they performed at Glastonbury Festival 2013. On September 14, 2013 they performed at Riot Fest & Carnival 2013 in Chicago, Illinois. On September 20, 2013 they performed at Riot Fest & Side Show in Byers, Colorado.
In 2014 Chuck D launched PE 2.0 with Oakland rapper Jahi as a spiritual successor and "next generation" of Public Enemy. Jahi had met Chuck D backstage during a soundcheck at the 1999 Rock & Roll Hall of Fame and later appeared as a support act on Public Enemy's 20th Anniversary Tour in 2007. PE 2.0's task is twofold, Jahi says, to "take select songs from the PE catalog and cover or reVisit them" as well as new material with members of the original Public Enemy including DJ Lord, Davy DMX, Professor Griff and Chuck D. PE 2.0's first album "People Get Ready" was released on October 7, 2014. "InsPirEd" PE 2.0's second album and part two of a proposed trilogy was released a year later on October 11, 2015.
"Man Plans God Laughs", Public Enemy's thirteenth album, was released in July 2015.
Legacy.
Public Enemy made contributions to the hip-hop world with sonic experimentation as well as political and cultural consciousness, which infused itself into skilled and poetic rhymes. Critic Stephen Thomas Erlewine wrote that "PE brought in elements of free jazz, hard funk, even musique concrète, via producing team the Bomb Squad, creating a dense, ferocious sound unlike anything that came before." Terminator X's innovative scratching tricks can be heard on the songs "Rebel Without a Pause", "Night of the Living Baseheads", and "Shut 'Em Down".
Public Enemy held a strong, pro-Black, political stance. Before PE, politically motivated hip-hop was defined by a few tracks by Ice-T, Grandmaster Flash and the Furious Five, and KRS-One. Other politically motivated opinions were shared by prototypical artists Gil Scott-Heron and the Last Poets. PE was a revolutionary hip-hop act, basing an entire image around a specified political stance. With the successes of Public Enemy, many hip-hop artists began to celebrate Afrocentric themes, such as Kool Moe Dee, Gang Starr, X Clan, Eric B. & Rakim, Queen Latifah, the Jungle Brothers, and A Tribe Called Quest.
Public Enemy was one of the first hip-hop groups to do well internationally. PE changed the Internet's music distribution capability by being one of the first groups to release MP3-only albums, a format virtually unknown at the time.
Public Enemy helped to create and define "rap metal" by collaborating with Living Colour in 1988 (Funny Vibe) and New York thrash metal outfit Anthrax in 1991. The single "Bring the Noise" was a mix of semi-militant black power lyrics, grinding guitars, and sporadic humor. The two bands, cemented by a mutual respect and the personal friendship between Chuck D and Anthrax's Scott Ian, introduced a hitherto alien genre to rock fans, and the two seemingly disparate groups toured together. Flavor Flav's pronouncement on stage that "They said this tour would never happen" (as heard on Anthrax's "Live: The Island Years" CD) has become a legendary comment in both rock and hip-hop circles. Metal guitarist Vernon Reid (of Living Colour) contributed to Public Enemy's recordings, and PE sampled Slayer's "Angel of Death" half-time riff on "She Watch Channel Zero?!"
Members of the Bomb Squad produced or remixed works for other acts, like Bell Biv DeVoe, Ice Cube, Vanessa Williams, Sinéad O'Connor, Blue Magic, Peter Gabriel, L.L. Cool J, Paula Abdul, Jasmine Guy, Jody Watley, Eric B & Rakim, Third Bass, Big Daddy Kane, EPMD, and Chaka Khan. According to Chuck D, "We had tight dealings with MCA Records and were talking about taking three guys that were left over from New Edition and coming up with an album for them. The three happened to be Ricky Bell, Michael Bivins, and Ronnie DeVoe, later to become Bell Biv DeVoe. Ralph Tresvant had been slated to do a solo album for years, Bobby Brown had left New Edition and experienced some solo success beginning in 1988, and Johnny Gill had just been recruited to come in, but had come off a solo career and could always go back to that. At MCA, Hiram Hicks, who was their manager, and Louil Silas, who was running the show, were like, 'Yo, these kids were left out in the cold. Can y'all come up with something for them?' It was a task that Hank, Keith, Eric, and I took on to try to put some kind of hip-hop-flavored R&B shit down for them. Subsequently, what happened in the four weeks of December [1989 was that the Bomb Squad knocked out a large piece of the production and arrangement on Bell Biv DeVoe's three-million selling album "Poison". In January , they knocked out "Fear of a Black Planet" in four weeks, and PE knocked out Ice Cube's album "AmeriKKKa's Most Wanted" in four to five weeks in February." They have also produced local talent such as Son of Bazerk, Young Black Teenagers, Kings of Pressure, and True Mathematics—and gave producer Kip Collins his start in the business.
Poet and hip-hop artist Saul Williams uses a sample from Public Enemy's "Welcome to the Terrordome" in his song "Trigger" on the "Niggy Tardust" album. He also used a line from the song in his poem, "amethyst rocks".
Public Enemy's brand of politically and socially conscious hip hop has been a direct influence on new hip hop artists such as The Cornel West theory.
The Manic Street Preachers track "Repeat (Stars And Stripes)" is a remix of the band's own anti-monarchy tirade by Public Enemy production team The Bomb Squad of whom James Dean Bradfield and Richey Edwards were big fans. The song samples "Countdown to Armageddon" from It Takes a Nation of Millions to Hold Us Back. The band had previously sampled Public Enemy on their 1991 single Motown Junk.
The influence of the band goes largely beyond hip-hop as the group was cited by artists as diverse as Autechre (selected in the All Tomorrow's Parties (music festival) in 2003), Nirvana (It Takes a Nation of Millions to Hold Us Back being cited by Kurt Cobain among his favorite albums), Nine Inch Nails (mentioned the band in Pretty Hate Machine credits), Björk (included Rebel Without a Pause in her The Breezeblock Mix in July 2007), Tricky (did a cover of Black Steel in the Hour of Chaos and appears in Do You Wanna Go Our Way ??? video), Prodigy (included Public Enemy No. 1 in The Dirtchamber Sessions Volume One), Ben Harper, Underground Resistance (cited by both Mad Mike and Jeff Mills), Orlando Voorn, M.I.A., Amon Tobin, Mathew Jonson and Aphex Twin (Welcome To The Terrordome being the first track played after the introduction at the Coachella festival in April 2008).
In September 2009, VH1 aired a show called "100 Greatest Hip Hop Songs" where Public Enemy earned the number one spot with their hit song, Fight the Power.
In December 2012, the group was announced as one of the inductees to the Rock and Roll Hall of Fame for its 2013 class.
Controversy.
Political activities.
In January 1987, Arizona governor Evan Mecham canceled a state holiday for Martin Luther King, Jr. because the holiday had not been properly authorized. In response to this action, the group wrote a song entitled "By the Time I Get to Arizona." In the video for the song, the group was seen assassinating Mecham by planting a bomb underneath his limousine and detonating it by remote control, perhaps intending an analogy or other reference to the 1976 murder of Don Bolles, an investigator reporter for the Arizona Republic newspaper.
Anti-Semitism.
In 1989, in an interview with Public Enemy for the "Washington Times", the interviewing journalist, David Mills, lifted some quotations from a UK magazine in which the band were asked their opinion on the Arab–Israeli conflict. Professor Griff's comments apparently sympathized with the Palestinians and he was accused of anti-Semitism. According to Rap Attack 2, he suggested that "Jews are responsible for the majority of the wickedness in the world" (p. 177). (In turn a quote from" The International Jew") Shortly after, Ridenhour expressed an apology on his behalf. At a June 21, 1989 press conference, Ridenhour announced Griff's dismissal from the group, and a June 28 statement by Russell Simmons, president of Def Jam Recordings and Rush Artists Management, stated that Chuck D. had disbanded Public Enemy "for an indefinite period of time." By August 10, however, Ridenhour denied that he had disbanded the group, and stated that Griff had been re-hired as "Supreme Allied Chief of Community Relations" (in contrast to his previous position with the group as Minister of Information). Griff later denied holding anti-Semitic views and apologized for the remarks. Several people who had worked with Public Enemy expressed concern about Ridenhour's leadership abilities and role as a social spokesman.
In his 2009 book, entitled "Analytixz", Griff criticized his 1989 statement: "to say the Jews are responsible for the majority of wickedness that went on around the globe I would have to know about the majority of wickedness that went on around the globe, which is impossible... I'm not the best knower. Then, not only knowing that, I would have to know who is at the crux of all of the problems in the world and then blame Jewish people, which is not correct." Griff also said that not only were his words taken out of context, but that the recording has never been released to the public for an unbiased listen.
The controversy and apologies on behalf of Griff spurred Chuck D to reference the negative press they were receiving. In 1990, Public Enemy issued the single "Welcome to the Terrordome", which contains the lyrics: "Crucifixion ain't no fiction / So-called chosen frozen / Apologies made to whoever pleases / Still they got me like Jesus". These lyrics have been cited by some in the media as anti-Semitic, making supposed references to the concept of the "chosen people" with the lyric "so-called chosen" and Jewish deicide with the last line.
In 1999 the group released an album entitled There's a Poison Goin' On. The title of the last song on the album is called "Swindler's Lust". The Anti-Defamation League (ADL) claimed that the title of the song was a word play on the title of the Steven Spielberg movie "Schindler’s List" about the genocide of Jews in World War II. Similarly in 2000 a Public Enemy spin off group under the name Confrontation Camp, a name according to the ADL, that is a pun on the term concentration camp, released an album. The group consisted of Kyle Jason, Chuck D (under the name Mistachuck) and Professor Griff.
The title of the 2015 album "Man Plans God Laughs" is a well known English translation of a Yiddish proverb "Der mentsh trakht un got lakht" Chuck D has not explained why a Yiddish proverb was used.
Homophobia.
In a letter to the editor, Leo Haber alludes to criticism by New York Times writer Peter Watrous of the group's supposed homophobia.
Reviewers John Alroy and David Wilson said that "Fear of a Black Planet" contained "homophobic babbling" which challenged politically correct thinking.
Zoe Williams defended Public Enemy against charges of homophobia by stating that:
Although "Spin" magazine noted that 'It only brings agony, ask James Cagney / He beat up on a guy when he found he was a fagney / Cagney is a favorite he is my boy' from "A Letter to the "New York Post"" on their album "Apocalypse '91" has also been accused of homophobia.
Public Enemy have also been supporters of Nation of Islam Supreme Minister Louis Farrakhan, who has been controversial for his commentary which is often interpreted as being black supremacist, racist, homophobic, and anti-Semitic.
Awards and nominations.
Grammy Awards
American Music Awards
Rock and Roll Hall of Fame
Bibliography.
White, Miles. "Race, Rap and the performance of Mascinity in American Popular Culture". 2011. University of Illinois. Urbana. ISBN 978-0-252-07832-3

</doc>
<doc id="22860" url="https://en.wikipedia.org/wiki?curid=22860" title="Paleolithic">
Paleolithic

The Paleolithic (American spelling; British spelling: Palaeolithic; pronunciation: ) Age, Era or Period is a prehistoric period of human history distinguished by the development of the most primitive stone tools discovered (Grahame Clark's Modes I and II), and covers roughly 95% of human technological prehistory. It extends from the earliest known use of stone tools, probably by Homo habilis initially, 2.6 million years ago, to the end of the Pleistocene around 10,000 BP.
The Paleolithic era is followed by the Mesolithic. The date of the Paleolithic–Mesolithic boundary may vary by locality as much as several thousand years.
During the Paleolithic period, humans grouped together in small societies such as bands, and subsisted by gathering plants and fishing, hunting or scavenging wild animals. The Paleolithic is characterized by the use of knapped stone tools, although at the time humans also used wood and bone tools. Other organic commodities were adapted for use as tools, including leather and vegetable fibers; however, due to their nature, these have not been preserved to any great degree. Surviving artifacts of the Paleolithic era are known as paleoliths.
About 50,000 years ago, there was a marked increase in the diversity of artifacts. For the first time in Africa, bone artifacts and the first art appear in the archeological record. The first evidence of human fishing is also noted, from artifacts in places such as Blombos cave in South Africa. Firstly among the artifacts of Africa, archeologists found they could differentiate and classify those of less than 50,000 years into many different categories, such as projectile points, engraving tools, knife blades, and drilling and piercing tools. The new technology generated a population explosion of modern humans which is believed to have led to the extinction of the Neanderthals.
Humankind gradually evolved from early members of the genus "Homo" such as "Homo habilis" – who used simple stone tools – into fully behaviorally and anatomically modern humans ("Homo sapiens) "during the Paleolithic era. During the end of the Paleolithic, specifically the Middle and or Upper Paleolithic, humans began to produce the earliest works of art and engage in religious and spiritual behavior such as burial and ritual. The climate during the Paleolithic consisted of a set of glacial and interglacial periods in which the climate periodically fluctuated between warm and cool temperatures. Archaeological and genetic data suggest that the source populations of Paleolithic humans survived in sparsely wooded areas and dispersed through areas of high primary productivity while avoiding dense forest cover.
By 40,000-50,000 BP, first humans set foot in Australia. By 45,000 BP, humans lived at 61° north latitude in Europe. By 30,000 BP, Japan was reached, and by 27,000 BP humans were present in Siberia above the Arctic Circle. At the end of the Upper Paleolithic, a group of humans crossed the Bering land bridge and quickly expanded throughout North and South America.
The term "Paleolithic" was coined by archaeologist John Lubbock in 1865. It derives from Greek: παλαιός, "palaios", "old"; and λίθος, "lithos", "stone", meaning "old age of the stone" or "Old Stone Age."
Human evolution.
Human evolution is the part of biological evolution concerning the emergence of humans as a distinct species.
Paleogeography and climate.
The Paleolithic Period coincides almost exactly with the Pleistocene epoch of geologic time, which lasted from 2.6 million years ago to about 12,000 years ago. This epoch experienced important geographic and climatic changes that affected human societies.
During the preceding Pliocene, continents had continued to drift from possibly as far as 250 km from their present locations to positions only 70 km from their current location. South America became linked to North America through the Isthmus of Panama, bringing a nearly complete end to South America's distinctive marsupial fauna. The formation of the Isthmus had major consequences on global temperatures, because warm equatorial ocean currents were cut off, and the cold Arctic and Antarctic waters lowered temperatures in the now-isolated Atlantic Ocean.
Most of Central America formed during the Pliocene to connect the continents of North and South America, allowing fauna from these continents to leave their native habitats and colonize new areas. Africa's collision with Asia created the Mediterranean Sea, cutting off the remnants of the Tethys Ocean. During the Pleistocene, the modern continents were essentially at their present positions; the tectonic plates on which they sit have probably moved at most 100 km from each other since the beginning of the period.
Climates during the Pliocene became cooler and drier, and seasonal, similar to modern climates. Ice sheets grew on Antarctica. The formation of an Arctic ice cap around three million years ago is signaled by an abrupt shift in oxygen isotope ratios and ice-rafted cobbles in the North Atlantic and North Pacific ocean beds. Mid-latitude glaciation probably began before the end of the epoch. The global cooling that occurred during the Pliocene may have spurred on the disappearance of forests and the spread of grasslands and savannas.
The Pleistocene climate was characterized by repeated glacial cycles during which continental glaciers pushed to the 40th parallel in some places. Four major glacial events have been identified, as well as many minor intervening events. A major event is a general glacial excursion, termed a "glacial". Glacials are separated by "interglacials". During a glacial, the glacier experiences minor advances and retreats. The minor excursion is a "stadial"; times between stadials are "interstadials". Each glacial advance tied up huge volumes of water in continental ice sheets 1500–3000 m deep, resulting in temporary sea level drops of 100 m or more over the entire surface of the Earth. During interglacial times, such as at present, drowned coastlines were common, mitigated by isostatic or other emergent motion of some regions.
The effects of glaciation were global. Antarctica was ice-bound throughout the Pleistocene and the preceding Pliocene. The Andes were covered in the south by the Patagonian ice cap. There were glaciers in New Zealand and Tasmania. The now decaying glaciers of Mount Kenya, Mount Kilimanjaro, and the Ruwenzori Range in east and central Africa were larger. Glaciers existed in the mountains of Ethiopia and to the west in the Atlas mountains. In the northern hemisphere, many glaciers fused into one. The Cordilleran ice sheet covered the North American northwest; the Laurentide covered the east. The Fenno-Scandian ice sheet covered northern Europe, including Great Britain; the Alpine ice sheet covered the Alps. Scattered domes stretched across Siberia and the Arctic shelf. The northern seas were frozen. During the late Upper Paleolithic (Latest Pleistocene) "c." 18,000 BP, the Beringia land bridge between Asia and North America was blocked by ice, which may have prevented early Paleo-Indians such as the Clovis culture from directly crossing Beringa to reach the Americas.
According to Mark Lynas (through collected data), the Pleistocene's overall climate could be characterized as a continuous El Niño with trade winds in the south Pacific weakening or heading east, warm air rising near Peru, warm water spreading from the west Pacific and the Indian Ocean to the east Pacific, and other El Niño markers.
The Paleolithic is often held to finish at the end of the ice age (the end of the Pleistocene epoch), and Earth's climate became warmer. This may have caused or contributed to the extinction of the Pleistocene megafauna, although it is also possible that the late Pleistocene extinctions were (at least in part) caused by other factors such as disease and overhunting by humans. New research suggests that the extinction of the woolly mammoth may have been caused by the combined effect of climatic change and human hunting. Scientists suggest that climate change during the end of the Pleistocene caused the mammoths' habitat to shrink in size, resulting in a drop in population. The small populations were then hunted out by Paleolithic humans. The global warming that occurred during the end of the Pleistocene and the beginning of the Holocene may have made it easier for humans to reach mammoth habitats that were previously frozen and inaccessible. Small populations of wooly mammoths survived on isolated Arctic islands, Saint Paul Island and Wrangel Island, till circa 3700 and 1700 BCE respectively. The Wrangel Island population became extinct around the same time the island was settled by prehistoric humans. There's no evidence of prehistoric human presence on Saint Paul island (though early human settlements dating as far back as 6500 BCE were found on nearby Aleutian Islands).
Human way of life.
Nearly all of our knowledge of Paleolithic human culture and way of life comes from archaeology and ethnographic comparisons to modern hunter-gatherer cultures such as the !Kung San who live similarly to their Paleolithic predecessors. The economy of a typical Paleolithic society was a hunter-gatherer economy. Humans hunted wild animals for meat and gathered food, firewood, and materials for their tools, clothes, or shelters.
Human population density was very low, around only one person per square mile. This was most likely due to low body fat, infanticide, women regularly engaging in intense endurance exercise, late weaning of infants and a nomadic lifestyle. Like contemporary hunter-gatherers, Paleolithic humans enjoyed an abundance of leisure time unparalleled in both Neolithic farming societies and modern industrial societies. At the end of the Paleolithic, specifically the Middle and or Upper Paleolithic, humans began to produce works of art such as cave paintings, rock art and jewellery and began to engage in religious behavior such as burial and ritual.
Distribution.
At the beginning of the Paleolithic, hominids were found primarily in eastern Africa, east of the Great Rift Valley. Most known hominid fossils dating earlier than one million years before present are found in this area, particularly in Kenya, Tanzania, and Ethiopia.
By 1.5-2 million years before present, groups of hominids began leaving Africa and settling southern Europe and Asia. Southern Caucasus was occupied by 1.7 million years BP, and northern China was reached by 1.66 million years BP. By the end of the Lower Paleolithic, members of the hominid family were living in what is now China, western Indonesia, and, in Europe, around the Mediterranean and as far north as England, southern Germany, and Bulgaria. Their further northward expansion may have been limited by the lack of control of fire: studies of cave settlements in Europe indicate no regular use of fire prior to 300,000-400,000 BP.
East Asian fossils from this period are typically placed in the genus Homo erectus. Very little fossil evidence is available at known Lower Paleolithic sites in Europe, but it is believed that hominids who inhabited these sites were likewise "Homo erectus". There is no evidence of hominids in America, Australia, or almost anywhere in Oceania during this time period.
Fates of these early colonists, and their relationships to modern humans, are still subject to debate. According to current archeological and genetic models, there were at least two notable expansion events subsequent to peopling of Eurasia 2-1.5 million years BP. Around 500,000 BP, a group of early humans, frequently called Homo heidelbergensis, came to Europe from Africa and eventually evolved into Neanderthals. In the Middle Paleolithic, Neanderthals were present in Poland.
Both "Homo erectus" and Neanderthals became extinct by the end of the Paleolithic, having been replaced by a new wave of humans, the anatomically modern Homo sapiens, which emerged in eastern Africa circa 200,000 BP, left Africa around 50,000 BP and expanded throughout the planet. It is likely that multiple groups coexisted for some time in certain locations. Neanderthals were still found in parts of Eurasia 30,000 years before present, and engaged in a limited degree of interbreeding with "Homo sapiens". Hominid fossils not belonging either to "Homo neanderthalensis" or to "Homo sapiens" geni, found in Altai and Indonesia, were radiocarbon dated to 30,000-40,000 BP and 17,000 BP respectively.
For the duration of the Paleolithic, human populations remained low, especially outside the equatorial region. The entire population of Europe between 16,000-11,000 BP likely averaged some 30,000 individuals, and, between 40,000-16,000 BP, it was even lower, at 4,000-6,000 individuals.
Technology.
Tools.
Paleolithic humans made tools of stone, bone, and wood. The early paleolithic hominids, Australopithecus, were the first users of stone tools. Excavations in Gona, Ethiopia have produced thousands of artifacts, and through radioisotopic dating and magnetostratigraphy, the sites can be firmly dated to 2.6 million years ago. Evidence shows these early hominids intentionally selected raw materials with good flaking qualities and chose appropriate sized stones for their needs to produce sharp-edged tools for cutting.
The earliest Paleolithic stone tool industry, the Olduwan, began around 2.6 million years ago. It contained tools such as choppers, burins and awls. It was completely replaced around 250,000 years ago by the more complex Acheulean industry, which was first conceived by "Homo ergaster" around 1.8 or 1.65 million years ago. The most recent Lower Paleolithic (Acheulean) implements completely vanished from the archeological record around 100,000 years ago and were replaced by more complex Middle Paleolithic/Middle Stone Age tool kits such as the Mousterian and the Aterian industries.
Lower Paleolithic humans used a variety of stone tools, including hand axes and choppers. Although they appear to have used hand axes often, there is disagreement about their use. Interpretations range from cutting and chopping tools, to digging implements, flake cores, the use in traps and a purely ritual significance, maybe in courting behavior. William H. Calvin has suggested that some hand axes could have served as "killer Frisbees" meant to be thrown at a herd of animals at a water hole so as to stun one of them. There are no indications of hafting, and some artifacts are far too large for that. Thus, a thrown hand axe would not usually have penetrated deeply enough to cause very serious injuries. Nevertheless, it could have been an effective weapon for defense against predators. Choppers and scrapers were likely used for skinning and butchering scavenged animals and sharp ended sticks were often obtained for digging up edible roots. Presumably, early humans used wooden spears as early as five million years ago to hunt small animals, much as their relatives, chimpanzees, have been observed to do in Senegal, Africa. Lower Paleolithic humans constructed shelters such as the possible wood hut at Terra Amata.
Fire use.
Fire was used by the Lower Paleolithic hominid "Homo erectus"/"Homo ergaster" as early as 300,000 or 1.5 million years ago and possibly even earlier by the early Lower Paleolithic (Oldowan) hominid "Homo habilis" and/or by robust australopithecines such as "Paranthropus". However, the use of fire only became common in the societies of the following Middle Stone Age/Middle Paleolithic Period. Use of fire reduced mortality rates and provided protection against predators. Early hominids may have begun to cook their food as early as the Lower Paleolithic ("c." 1.9 million years ago) or at the latest in the early Middle Paleolithic ("c." 250,000 years ago). Some scientists have hypothesized that Hominids began cooking food to defrost frozen meat, which would help ensure their survival in cold regions.
Rafts.
The Lower Paleolithic hominid "Homo erectus" possibly invented rafts ("c." 800,000 or 840,000 BP) to travel over large bodies of water, which may have allowed a group of "Homo erectus" to reach the island of Flores and evolve into the small hominid "Homo floresiensis". However, this hypothesis is disputed within the anthropological community. The possible use of rafts during the Lower Paleolithic may indicate that Lower Paleolithic Hominids such as "Homo erectus" were more advanced than previously believed, and may have even spoken an early form of modern language. Supplementary evidence from Neanderthal and Modern human sites located around the Mediterranean Sea such as Coa de sa Multa ("c." 300,000 BP) has also indicated that both Middle and Upper Paleolithic humans used rafts to travel over large bodies of water (i.e. the Mediterranean Sea) for the purpose of colonizing other bodies of land.
Advanced tools.
Around 200,000 BP, Middle Paleolithic Stone tool manufacturing spawned a tool making technique known as the prepared-core technique, that was more elaborate than previous Acheulean techniques. This technique increased efficiency by allowing the creation of more controlled and consistent flakes. It allowed Middle Paleolithic humans to create stone tipped spears, which were the earliest composite tools, by hafting sharp, pointy stone flakes onto wooden shafts. In addition to improving tool making methods, the Middle Paleolithic also saw an improvement of the tools themselves that allowed access to a wider variety and amount of food sources. For example, microliths or small stone tools or points were invented around 70,000 or 65,000 BP and were essential to the invention of bows and spear throwers in the following Upper Paleolithic period.
Harpoons were invented & used for the first time during the late Middle Paleolithic (c.90,000 years ago); the invention of these devices brought fish into the human diets, which provided a hedge against starvation and a more abundant food supply. Thanks to their technology and their advanced social structures, Paleolithic groups such as the Neanderthals who had a Middle Paleolithic level of technology, appear to have hunted large game just as well as Upper Paleolithic modern humans and the Neanderthals in particular may have likewise hunted with projectile weapons. Nonetheless, Neanderthal use of projectile weapons in hunting occurred very rarely (or perhaps never) and the Neanderthals hunted large game animals mostly by ambushing them and attacking them with mêlée weapons such as thrusting spears rather than attacking them from a distance with projectile weapons.
Other inventions.
During the Upper Paleolithic, further inventions were made, such as the net ("c." 22,000 or 29,000 BP) bolas, the spear thrower (c.30,000 BP), the bow and arrow ("c." 25,000 or 30,000 BP) and the oldest example of ceramic art, the Venus of Dolní Věstonice ("c." 29,000–25,000 BCE). Early dogs were domesticated, sometime between 30,000 BP and 14,000 BP, presumably to aid in hunting. However, the earliest instances of successful domestication of dogs may be much more ancient than this. Evidence from canine DNA collected by Robert K. Wayne suggests that dogs may have been first domesticated in the late Middle Paleolithic around 100,000 BP or perhaps even earlier.
Archeological evidence from the Dordogne region of France demonstrates that members of the European early Upper Paleolithic culture known as the Aurignacian used calendars ("c." 30,000 BP). This was a lunar calendar that was used to document the phases of the moon. Genuine solar calendars did not appear until the following Neolithic period. This ability allowed humans to become efficient hunters and to exploit a wide variety of game animals. Recent research indicates that the Neanderthals timed their hunts and the migrations of game animals long before the beginning of the Upper Paleolithic.
Social organization.
The social organization of the earliest Paleolithic (Lower Paleolithic) societies remains largely unknown to scientists, though Lower Paleolithic hominids such as "Homo habilis" and "Homo erectus" are likely to have had more complex social structures than chimpanzee societies. Late Oldowan/Early Acheulean humans such as "Homo ergaster"/"Homo erectus" may have been the first people to invent central campsites or home bases and incorporate them into their foraging and hunting strategies like contemporary hunter-gatherers, possibly as early as 1.7 million years ago; however, the earliest solid evidence for the existence of home bases or central campsites (hearths and shelters) among humans only dates back to 500,000 years ago.
Similarly, scientists disagree whether Lower Paleolithic humans were largely monogamous or polygynous. In particular, the Provisional model suggests that bipedalism arose in Pre Paleolithic australopithecine societies as an adaptation to monogamous lifestyles; however, other researchers note that sexual dimorphism is more pronounced in Lower Paleolithic humans such as "Homo erectus" than in Modern humans, who are less polygynous than other primates, which suggests that Lower Paleolithic humans had a largely polygynous lifestyle, because species that have the most pronounced sexual dimorphism tend more likely to be polygynous.
Human societies from the Paleolithic to the early Neolithic farming tribes lived without states and organized governments. For most of the Lower Paleolithic, human societies were possibly more hierarchical than their Middle and Upper Paleolithic descendants, and probably were not grouped into bands, though during the end of the Lower Paleolithic, the latest populations of the hominid "Homo erectus" may have begun living in small-scale (possibly egalitarian) bands similar to both Middle and Upper Paleolithic societies and modern hunter-gatherers.
Middle Paleolithic societies, unlike Lower Paleolithic and early Neolithic ones, consisted of bands that ranged from 20 to 30 or 25 to 100 members and were usually nomadic. These bands were formed by several families. Bands sometimes joined together into larger "macrobands" for activities such as acquiring mates and celebrations or where resources were abundant. By the end of the Paleolithic era, about 10,000 BP people began to settle down into permanent locations, and began to rely on agriculture for sustenance in many locations. Much evidence exists that humans took part in long-distance trade between bands for rare commodities (such as ochre, which was often used for religious purposes such as ritual Inter-band trade may have appeared during the Middle Paleolithic because trade between bands would have helped ensure their survival by allowing them to exchange resources and commodities such as raw materials during times of relative scarcity (i.e. famine, drought). Like in modern hunter-gatherer societies, individuals in Paleolithic societies may have been subordinate to the band as a whole. Both Neanderthals and modern humans took care of the elderly members of their societies during the Middle and Upper Paleolithic.
Some sources claim that most Middle and Upper Paleolithic societies were possibly fundamentally egalitarian and may have rarely or never engaged in organized violence between groups (i.e. war).
Some Upper Paleolithic societies in resource-rich environments (such as societies in Sungir, in what is now Russia) may have had more complex and hierarchical organization (such as tribes with a pronounced hierarchy and a somewhat formal division of labor) and may have engaged in endemic warfare. Some argue that there was no formal leadership during the Middle and Upper Paleolithic. Like contemporary egalitarian hunter-gatherers such as the Mbuti pygmies, societies may have made decisions by communal consensus decision making rather than by appointing permanent rulers such as chiefs and monarchs. Nor was there a formal division of labor during the Paleolithic. Each member of the group was skilled at all tasks essential to survival, regardless of individual abilities. Theories to explain the apparent egalitarianism have arisen, notably the Marxist concept of primitive communism. Christopher Boehm (1999) has hypothesized that egalitarianism may have evolved in Paleolithic societies because of a need to distribute resources such as food and meat equally to avoid famine and ensure a stable food supply. Raymond C. Kelly speculates that the relative peacefulness of Middle and Upper Paleolithic societies resulted from a low population density, cooperative relationships between groups such as reciprocal exchange of commodities and collaboration on hunting expeditions, and because the invention of projectile weapons such as throwing spears provided less incentive for war, because they increased the damage done to the attacker and decreased the relative amount of territory attackers could gain. However, other sources claim that most Paleolithic groups may have been larger, more complex, sedentary and warlike than most contemporary hunter-gatherer societies, due to occupying more resource-abundant areas than most modern hunter-gatherers who have been pushed into more marginal habitats by agricultural societies.
Anthropologists have typically assumed that in Paleolithic societies, women were responsible for gathering wild plants and firewood, and men were responsible for hunting and scavenging dead animals. However, analogies to existent hunter-gatherer societies such as the Hadza people and the Australian aborigines suggest that the sexual division of labor in the Paleolithic was relatively flexible. Men may have participated in gathering plants, firewood and insects, and women may have procured small game animals for consumption and assisted men in driving herds of large game animals (such as woolly mammoths and deer) off cliffs. Additionally, recent research by anthropologist and archaeologist Steven Kuhn from the University of Arizona is argued to support that this division of labor did not exist prior to the Upper Paleolithic and was invented relatively recently in human pre-history. Sexual division of labor may have been developed to allow humans to acquire food and other resources more efficiently. Archeological evidence from art and funerary rituals indicates that a number of individual women enjoyed seemingly high status in their communities, and it is likely that both sexes participated in decision making. The earliest known Paleolithic shaman ("c." 30,000 BP) was female. Jared Diamond suggests that the status of women declined with the adoption of agriculture because women in farming societies typically have more pregnancies and are expected to do more demanding work than women in hunter-gatherer societies. Like most contemporary hunter-gatherer societies, Paleolithic and the Mesolithic groups probably followed mostly matrilineal and ambilineal descent patterns; patrilineal descent patterns were probably rarer than in the following Neolithic period.
Art and music.
Early examples of artistic expression, such as the Venus of Tan-Tan and the patterns found on elephant bones from Bilzingsleben in Thuringia, may have been produced by Acheulean tool users such as "Homo erectus" prior to the start of the Middle Paleolithic period. However, the earliest undisputed evidence of art during the Paleolithic period comes from Middle Paleolithic/Middle Stone Age sites such as Blombos Cave –South Africa– in the form of bracelets, beads, rock art, and ochre used as body paint and perhaps in ritual. Undisputed evidence of art only becomes common in the following Upper Paleolithic period.
According to Robert G. Bednarik, Lower Paleolithic Acheulean tool users began to engage in symbolic behavior such as art around 850,000 BP and decorated themselves with beads and collected exotic stones for aesthetic rather than utilitarian qualities. According to Bednarik, traces of the pigment ochre from late Lower Paleolithic Acheulean archeological sites suggests that Acheulean societies, like later Upper Paleolithic societies, collected and used ochre to create rock art. Nevertheless, it is also possible that the ochre traces found at Lower Paleolithic sites is naturally occurring.
Vincent W. Fallio interprets Lower and Middle Paleolithic marking on rocks at sites such as Bilzingsleben (such as zig zagging lines) as accounts or representation of altered states of consciousness though some other scholars interpret them as either simple doodling or as the result of natural processes.
Upper Paleolithic humans produced works of art such as cave paintings, Venus figurines, animal carvings and rock paintings. Upper Paleolithic art can be divided into two broad categories: figurative art such as cave paintings that clearly depicts animals (or more rarely humans); and nonfigurative, which consists of shapes and symbols. Cave paintings have been interpreted in a number of ways by modern archeologists. The earliest explanation, by the prehistorian Abbe Breuil, interpreted the paintings as a form of magic designed to ensure a successful hunt. However, this hypothesis fails to explain the existence of animals such as saber-toothed cats and lions, which were not hunted for food, and the existence of half-human, half-animal beings in cave paintings. The anthropologist David Lewis-Williams has suggested that Paleolithic cave paintings were indications of shamanistic practices, because the paintings of half-human, half-animal paintings and the remoteness of the caves are reminiscent of modern hunter-gatherer shamanistic practices. Symbol-like images are more common in Paleolithic cave paintings than are depictions of animals or humans, and unique symbolic patterns might have been trademarks that represent different Upper Paleolithic ethnic groups. Venus figurines have evoked similar controversy. Archeologists and anthropologists have described the figurines as representations of goddesses, pornographic imagery, apotropaic amulets used for sympathetic magic, and even as self-portraits of women themselves.
R. Dale Guthrie has studied not only the most artistic and publicized paintings, but also a variety of lower-quality art and figurines, and he identifies a wide range of skill and ages among the artists. He also points out that the main themes in the paintings and other artifacts (powerful beasts, risky hunting scenes and the over-sexual representation of women) are to be expected in the fantasies of adolescent males during the Upper Paleolithic.
The Venus figurines have sometimes been interpreted as representing a mother goddess; the abundance of such female imagery has led some to believe that Upper Paleolithic (and later Neolithic) societies had a female-centered religion and a female-dominated society. For example, this was proposed by the archeologist Marija Gimbutas and the feminist scholar Merlin Stone who was the author of the 1978 book "When God Was a Woman." Various other explanations for the purpose of the figurines have been proposed, such as Catherine McCoid and LeRoy McDermott’s hypothesis that the figurines were created as self-portraits of actual women and R.Dale Gutrie's hypothesis that the venus figurines represented a kind of "stone age pornography".
The origins of music during the Paleolithic are unknown, since the earliest forms of music probably did not use musical instruments but instead used the human voice and or natural objects such as rocks, which leave no trace in the archaeological record. However, the anthropological and archeological designation suggests that human music first arose when language, art and other modern behaviors developed in the Middle or the Upper Paleolithic period. Music may have developed from rhythmic sounds produced by daily activities such as cracking nuts by hitting them with stones, because maintaining a rhythm while working may have helped people to become more efficient at daily activities. An alternative theory originally proposed by Charles Darwin explains that music may have begun as a hominid mating strategy as many birds and some other animals produce music like calls to attract mates. This hypothesis is generally less accepted than the previous hypothesis, but it nonetheless provides a possible alternative. Another explanation is that humans began to make music simply because of the pleasure it produced.
Upper Paleolithic (and possibly Middle Paleolithic) humans used flute-like bone pipes as musical instruments, and music may have played a large role in the religious lives of Upper Paleolithic hunter-gatherers. As with modern hunter-gatherer societies, music may have been used in ritual or to help induce trances. In particular, it appears that animal skin drums may have been used in religious events by Upper Paleolithic shamans, as shown by the remains of drum-like instruments from some Upper Paleolithic graves of shamans and the ethnographic record of contemporary hunter-gatherer shamanic and ritual practices.
Religion and beliefs.
According to James B. Harrod humankind first developed religious and spiritual beliefs during the Middle Paleolithic or Upper Paleolithic. Controversial scholars of prehistoric religion and anthropology, James Harrod and Vincent W. Fallio, have recently proposed that religion and spirituality (and art) may have first arisen in Pre-Paleolithic chimpanzees or Early Lower Paleolithic (Oldowan) societies. According to Fallio, the common ancestor of chimpanzees and humans experienced altered states of consciousness and partook in ritual, and ritual was used in their societies to strengthen social bonding and group cohesion.
Middle Paleolithic humans' use of burials at sites such as Krapina, Croatia ("c." 130,000 BP) and Qafzeh, Israel ("c." 100,000 BP) have led some anthropologists and archeologists, such as Philip Lieberman, to believe that Middle Paleolithic humans may have possessed a belief in an afterlife and a "concern for the dead that transcends daily life". Cut marks on Neanderthal bones from various sites, such as Combe-Grenal and Abri Moula in France, suggest that the Neanderthals like some contemporary human cultures may have practiced ritual defleshing for (presumably) religious reasons. According to recent archeological findings from "H. heidelbergensis" sites in Atapuerca, humans may have begun burying their dead much earlier, during the late Lower Paleolithic; but this theory is widely questioned in the scientific community.
Likewise, some scientists have proposed that Middle Paleolithic societies such as Neanderthal societies may also have practiced the earliest form of totemism or animal worship, in addition to their (presumably religious) burial of the dead. In particular, Emil Bächler suggested (based on archeological evidence from Middle Paleolithic caves) that a bear cult was widespread among Middle Paleolithic Neanderthals. A claim that evidence was found for Middle Paleolithic animal worship c 70,000 BCE originates from the Tsodilo Hills in the African Kalahari desert has been denied by the original investigators of the site. Animal cults in the following Upper Paleolithic period, such as the bear cult, may have had their origins in these hypothetical Middle Paleolithic animal cults. Animal worship during the Upper Paleolithic was intertwined with hunting rites. For instance, archeological evidence from art and bear remains reveals that the bear cult apparently involved a type of sacrificial bear ceremonialism, in which a bear was sliced with arrows, finished off by a blast in the lungs, and ritualistically worshipped near a clay bear statue covered by a bear fur with the skull and the body of the bear buried separately. Barbara Ehrenreich controversially theorizes that the sacrificial hunting rites of the Upper Paleolithic (and by extension Paleolithic cooperative big-game hunting) gave rise to war or warlike raiding during the following Epi-Paleolithic/Mesolithic or late Upper Paleolithic period.
The existence of anthropomorphic images and half-human, half-animal images in the Upper Paleolithic period may further indicate that Upper Paleolithic humans were the first people to believe in a pantheon of gods or supernatural beings, though such images may instead indicate shamanistic practices similar to those of contemporary tribal societies. The earliest known undisputed burial of a shaman (and by extension the earliest undisputed evidence of shamans and shamanic practices) dates back to the early Upper Paleolithic era ("c." 30,000 BP) in what is now the Czech Republic. However, during the early Upper Paleolithic it was probably more common for all members of the band to participate equally and fully in religious ceremonies, in contrast to the religious traditions of later periods when religious authorities and part-time ritual specialists such as shamans, priests and medicine men were relatively common and integral to religious life. Additionally, it is also possible that Upper Paleolithic religions, like contemporary and historical animistic and polytheistic religions, believed in the existence of a single creator deity in addition to other supernatural beings such as animistic spirits.
Vincent W. Fallio writes that ancestor cults first emerged in complex Upper Paleolithic societies. He argues that the elites of these societies (like the elites of many more contemporary complex hunter-gatherers such as the Tlingit) may have used special rituals and ancestor worship to solidify control over their societies, by convincing their subjects that they possess a link to the spirit world that also gives them control over the earthly realm. Secret societies may have served a similar function in these complex quasi-theocratic societies, by dividing the religious practices of these cultures into the separate spheres of Popular Religion and Elite Religion.
Religion was possibly apotropaic; specifically, it may have involved sympathetic magic. The Venus figurines, which are abundant in the Upper Paleolithic archeological record, provide an example of possible Paleolithic sympathetic magic, as they may have been used for ensuring success in hunting and to bring about fertility of the land and women. The Upper Paleolithic Venus figurines have sometimes been explained as depictions of an earth goddess similar to Gaia, or as representations of a goddess who is the ruler or mother of the animals. James Harrod has described them as representative of female (and male) shamanistic spiritual transformation processes.
Diet and nutrition.
Paleolithic hunting and gathering people ate varying proportions of leafy vegetables, fruit, nuts and insects, meat, fish, and shellfish. However, there is little direct evidence of the relative proportions of plant and animal foods. Although the term "paleolithic diet", without references to a specific timeframe or locale, is sometimes used with an implication that most humans shared a certain diet during the entire era, that is not entirely accurate. The Paleolithic was an extended period of time, during which multiple technological advances were made, many of which had impact on human dietary structure. For example, humans probably did not possess the control of fire until the Middle Paleolithic, or tools necessary to engage in extensive fishing. On the other hand, both these technologies are generally agreed to have been widely available to humans by the end of the Paleolithic (consequently, allowing humans in some regions of the planet to rely heavily on fishing and hunting). In addition, the Paleolithic involved a substantial geographical expansion of human populations. During the Lower Paleolithic, ancestors of modern humans are thought to have been constrained to Africa east of the Great Rift Valley. During the Middle and Upper Paleolithic, humans greatly expanded their area of settlement, reaching ecosystems as diverse as New Guinea and Alaska, and adapting their diets to whatever local resources available.
Another view is that until the Upper Paleolithic, humans were frugivores (fruit eaters) who supplemented their meals with carrion, eggs, and small prey such as baby birds and mussels, and only on rare occasions managed to kill and consume big game such as antelopes. This view is supported by studies of higher apes, particularly chimpanzees. Chimpanzees are the closest to humans genetically, sharing more than 96% of their DNA code with humans, and their digestive tract is functionally very similar to that of humans. Chimpanzees are primarily frugivores, but they could and would consume and digest animal flesh, given the opportunity. In general, their actual diet in the wild is about 95% plant-based, with the remaining 5% filled with insects, eggs, and baby animals. In some ecosystems, however, chimpanzees are predatory, forming parties to hunt monkeys. Some comparative studies of human and higher primate digestive tracts do suggest that humans have evolved to obtain greater amounts of calories from sources such as animal foods, allowing them to shrink the size of the gastrointestinal tract relative to body mass and to increase the brain mass instead.
A difficulty with the frugivore point of view is that humans are established to conditionally require certain long-chain polyunsaturated fatty acids (LC-PUFAs), such as AA and DHA, from the diet. Humans' LC-PUFA requirements are much greater than chimpanzees' because of humans' larger brain mass, and humans' abilities to synthesize them from other nutrients are poor, suggesting readily available external sources. Pregnant and lactating females require 100 mg of DHA per day. However, LC-PUFAs are almost nonexistent in plants and in most tissues of warm-climate animals.
Anthropologists have diverse opinions about the proportions of plant and animal foods consumed. Just as with still existing hunters and gatherers, there were many varied "diets" - in different groups - and also varying through this vast amount of time. Some paleolithic hunter-gatherers consumed a significant amount of meat and possibly obtained most of their food from hunting, while others are shown as a primarily plant-based diet, Most, if not all, are believed to have been opportunistic omnivores. One hypothesis is that carbohydrate tubers (plant underground storage organs) may have been eaten in high amounts by pre-agricultural humans. It is thought that the Paleolithic diet included as much as 1.65–1.9 kilograms per day of fruit and vegetables. The relative proportions of plant and animal foods in the diets of Paleolithic people often varied between regions, with more meat being necessary in colder regions (which weren't populated by anatomically modern humans until 30,000-50,000 BP). It is generally agreed that many modern hunting and fishing tools, such as fish hooks, nets, bows, and poisons, weren't introduced until the Upper Paleolithic and possibly even Neolithic. The only hunting tools widely available to humans during any significant part of the Paleolithic period were hand-held spears and harpoons. There's evidence of Paleolithic people killing and eating seals and elands as far as 100,000 years BP. On the other hand, buffalo bones found in African caves from the same period are typically of very young or very old individuals, and there's no evidence that pigs, elephants or rhinos were hunted by humans at the time.
Paleolithic peoples suffered less famine and malnutrition than the Neolithic farming tribes that followed them. This was partly because Paleolithic hunter-gatherers accessed to a wider variety natural foods, which allowed them a more nutritious diet and a decreased risk of famine. Many of the famines experienced by Neolithic (and some modern) farmers were caused or amplified by their dependence on a small number of crops. It is thought that wild foods can have a significantly different nutritional profile than cultivated foods. The greater amount of meat obtained by hunting big game animals in Paleolithic diets than Neolithic diets may have also allowed Paleolithic hunter-gatherers to enjoy a more nutritious diet than Neolithic agriculturalists. It has been argued that the shift from hunting and gathering to agriculture resulted in an increasing focus on a limited variety of foods, with meat likely taking a back seat to plants. It is also unlikely that Paleolithic hunter-gatherers were affected by modern diseases of affluence such as Type 2 diabetes, coronary heart disease and cerebrovascular disease, because they ate mostly lean meats and plants and frequently engaged in intense physical activity, and because the average lifespan was shorter than the age of common-onset of these conditions.
Large-seeded legumes were part of the human diet long before the Neolithic agricultural revolution, as evident from archaeobotanical finds from the Mousterian layers of Kebara Cave, in Israel. There is evidence suggesting that Paleolithic societies were gathering wild cereals for food use at least as early as 30,000 years ago. However, seeds, such as grains and beans, were rarely eaten and never in large quantities on a daily basis. Recent archeological evidence also indicates that winemaking may have originated in the Paleolithic, when early humans drank the juice of naturally fermented wild grapes from animal-skin pouches. Paleolithic humans consumed animal organ meats, including the livers, kidneys and brains. Upper Paleolithic cultures appear to have had significant knowledge about plants and herbs and may have, albeit very rarely, practiced rudimentary forms of horticulture. In particular, bananas and tubers may have been cultivated as early as 25,000 BP in southeast Asia. Late Upper Paleolithic societies also appear to have occasionally practiced pastoralism and animal husbandry, presumably for dietary reasons. For instance, some European late Upper Paleolithic cultures domesticated and raised reindeer, presumably for their meat or milk, as early as 14,000 BP. Humans also probably consumed hallucinogenic plants during the Paleolithic period. The Australian Aborigines have been consuming a variety of native animal and plant foods, called bushfood, for an estimated 60,000 years, since the Middle Paleolithic.
People during the Middle Paleolithic, such as the Neanderthals and Middle Paleolithic Homo sapiens in Africa, began to catch shellfish for food as revealed by shellfish cooking in Neanderthal sites in Italy about 110,000 years ago and Middle Paleolithic "Homo sapiens" sites at Pinnacle Point, in Africa around 164,000 BP. Although fishing only became common during the Upper Paleolithic, fish have been part of human diets long before the dawn of the Upper Paleolithic and have certainly been consumed by humans since at least the Middle Paleolithic. For example, the Middle Paleolithic "Homo sapiens" in the region now occupied by the Democratic Republic of the Congo hunted large -long catfish with specialized barbed fishing points as early as 90,000 years ago. The invention of fishing allowed some Upper Paleolithic and later hunter-gatherer societies to become sedentary or semi-nomadic, which altered their social structures. Example societies are the Lepenski Vir as well as some contemporary hunter-gatherers such as the Tlingit. In some instances (at least the Tlingit) they developed social stratification, slavery and complex social structures such as chiefdoms.
Anthropologists such as Tim White suggest that cannibalism was common in human societies prior to the beginning of the Upper Paleolithic, based on the large amount of “butchered human" bones found in Neanderthal and other Lower/Middle Paleolithic sites. Cannibalism in the Lower and Middle Paleolithic may have occurred because of food shortages. However, it may have been for religious reasons, and would coincide with the development of religious practices thought to have occurred during the Upper Paleolithic. Nonetheless, it remains possible that Paleolithic societies never practiced cannibalism, and that the damage to recovered human bones was either the result of ritual post-mortem bone cleaning or predation by carnivores such as saber tooth cats, lions and hyenas.

</doc>
<doc id="22873" url="https://en.wikipedia.org/wiki?curid=22873" title="Presidential Medal of Freedom">
Presidential Medal of Freedom

The Presidential Medal of Freedom is an award bestowed by the President of the United States and is—along with the 
comparable Congressional Gold Medal, bestowed by an act of U.S. Congress—the highest civilian award of the United States. It recognizes those individuals who have made "an especially meritorious contribution to the security or national interests of the United States, world peace, cultural or other significant public or private endeavors". The award is not limited to U.S. citizens and, while it is a civilian award, it can also be awarded to military personnel and worn on the uniform.
It was established in 1963 and replaced the earlier Medal of Freedom that was established by President Harry S. Truman in 1945 to honor civilian service during World War II.
History of the award.
Similar in name to the Medal of Freedom, but much closer in meaning and precedence to the Medal for Merit: the Presidential Medal of Freedom is currently the supreme civilian decoration in precedence, whereas the Medal of Freedom was inferior in precedence to the Medal for Merit; the Medal of Freedom was awarded by any of three Cabinet secretaries, whereas the Medal for Merit was awarded by the president, as is the Presidential Medal of Freedom. Another measure of the difference between these two similarly named but very distinct awards is their per-capita frequency of award: from 1946 to 1961 the average annual incidence of award of the Medal of Freedom was approximately 1 per every 86,500 adult U.S. citizens; from 1996 to 2011 the average annual incidence of award of the Presidential Medal of Freedom was approximately 1 per every 20,500,000 adult U.S. citizens (so on an annualized per capita basis, 240 Medals of Freedom have been awarded per one Presidential Medal of Freedom).
President John F. Kennedy established the current decoration in 1963 through , with unique and distinctive insignia, vastly expanded purpose, and far higher prestige. It was the first U.S. civilian neck decoration and, in the grade of Awarded With Distinction, is the only U.S. sash and star decoration (the Chief Commander degree of the Legion of Merit – which may only be awarded to foreign heads of state – is a star decoration, but without a sash). The Executive Order calls for the medal to be awarded annually on or around July 4, and at other convenient times as chosen by the president, but it has not been awarded every year (e.g., 2001, 2010). Recipients are selected by the president, either on his own initiative or based on recommendations. The order establishing the medal also expanded the size and the responsibilities of the Distinguished Civilian Service Awards Board so it could serve as a major source of such recommendations.
The medal may be awarded to an individual more than once; Colin Powell received two awards; Ellsworth Bunker received both of his awards With Distinction. It may also be awarded posthumously; examples (in chronological order) include John F. Kennedy, Pope John XXIII, Lyndon Johnson, Paul "Bear" Bryant, Thurgood Marshall, Cesar Chavez, Roberto Clemente, Jack Kemp, James Chaney, Andrew Goodman and Michael Schwerner. (Chaney, Goodman and Schwerner, civil rights workers murdered in 1964, were awarded their medals in 2014, 50 years later.)
Insignia.
The badge of the Presidential Medal of Freedom is in the form of a golden star with white enamel, with a red enamel pentagon behind it; the central disc bears thirteen gold stars on a blue enamel background (taken from the Great Seal of the United States) within a golden ring. Golden American bald eagles with spread wings stand between the points of the star. It is worn around the neck on a blue ribbon with white edge stripes.
A special, rarely given grade of the medal, known as the Presidential Medal of Freedom with Distinction, has a larger execution of the same medal design worn as a star on the left chest along with a sash over the right shoulder (similar to how the insignia of a Grand Cross is worn), with its rosette (blue with white edge, bearing the central disc of the medal at its center) resting on the left hip. When the medal With Distinction is awarded, the star may be presented descending from a neck ribbon and can be identified by its larger size than the standard medal (compare size of medals in pictures below; President Reagan's was awarded With Distinction).
Both medals may also be worn in miniature form on a ribbon on the left chest, with a silver American bald eagle with spread wings on the ribbon, or a golden American bald eagle for a medal awarded With Distinction. In addition, the medal is accompanied by a service ribbon for wear on military service uniform, a miniature medal pendant for wear on mess dress or civilian formal wear, and a lapel badge for wear on civilian clothes (all shown in the accompanying photograph of the full presentation set).

</doc>
<doc id="22915" url="https://en.wikipedia.org/wiki?curid=22915" title="Planet">
Planet

A planet () is an astronomical object orbiting a star or stellar remnant that
The term "planet" is ancient, with ties to history, science, mythology, and religion. Several planets in the Solar System can be seen with the naked eye. These were regarded by many early cultures as divine, or as emissaries of deities. As scientific knowledge advanced, human perception of the planets changed, incorporating a number of disparate objects. In 2006, the International Astronomical Union (IAU) officially adopted a resolution defining planets within the Solar System. This definition is controversial because it excludes many objects of planetary mass based on where or what they orbit. Although eight of the planetary bodies discovered before 1950 remain "planets" under the modern definition, some celestial bodies, such as Ceres, Pallas, Juno and Vesta (each an object in the solar asteroid belt), and Pluto (the first trans-Neptunian object discovered), that were once considered planets by the scientific community, are no longer viewed as such.
The planets were thought by Ptolemy to orbit Earth in deferent and epicycle motions. Although the idea that the planets orbited the Sun had been suggested many times, it was not until the 17th century that this view was supported by evidence from the first telescopic astronomical observations, performed by Galileo Galilei. By careful analysis of the observation data, Johannes Kepler found the planets' orbits were not circular but elliptical. As observational tools improved, astronomers saw that, like Earth, the planets rotated around tilted axes, and some shared such features as ice caps and seasons. Since the dawn of the Space Age, close observation by space probes has found that Earth and the other planets share characteristics such as volcanism, hurricanes, tectonics, and even hydrology.
Planets are generally divided into two main types: large low-density giant planets, and smaller rocky terrestrials. Under IAU definitions, there are eight planets in the Solar System. In order of increasing distance from the Sun, they are the four terrestrials, Mercury, Venus, Earth, and Mars, then the four giant planets, Jupiter, Saturn, Uranus, and Neptune. Six of the planets are orbited by one or more natural satellites.
More than two thousand planets around other stars ("extrasolar planets" or "exoplanets") have been discovered in the Milky Way: as of , known extrasolar planets in planetary systems (including multiple planetary systems), ranging in size from just above the size of the Moon to gas giants about twice as large as Jupiter. On December 20, 2011, the Kepler Space Telescope team reported the discovery of the first Earth-sized extrasolar planets, Kepler-20e and Kepler-20f, orbiting a Sun-like star, Kepler-20. A 2012 study, analyzing gravitational microlensing data, estimates an average of at least 1.6 bound planets for every star in the Milky Way.
Around one in five Sun-like stars is thought to have an Earth-sized planet in its habitable zone.
History.
The idea of planets has evolved over its history, from the divine wandering stars of antiquity to the earthly objects of the scientific age. The concept has expanded to include worlds not only in the Solar System, but in hundreds of other extrasolar systems. The ambiguities inherent in defining planets have led to much scientific controversy.
The five classical planets, being visible to the naked eye, have been known since ancient times and have had a significant impact on mythology, religious cosmology, and ancient astronomy. In ancient times, astronomers noted how certain lights moved across the sky in relation to the other stars. Ancient Greeks called these lights (, "wandering stars") or simply (, "wanderers"), from which today's word "planet" was derived. In ancient Greece, China, Babylon, and indeed all pre-modern civilizations, it was almost universally believed that Earth was the center of the Universe and that all the "planets" circled Earth. The reasons for this perception were that stars and planets appeared to revolve around Earth each day and the apparently common-sense perceptions that Earth was solid and stable and that it was not moving but at rest.
Babylon.
The first civilization known to have a functional theory of the planets were the Babylonians, who lived in Mesopotamia in the first and second millennia BC. The oldest surviving planetary astronomical text is the Babylonian Venus tablet of Ammisaduqa, a 7th-century BC copy of a list of observations of the motions of the planet Venus, that probably dates as early as the second millennium BC. The MUL.APIN is a pair of cuneiform tablets dating from the 7th century BC that lays out the motions of the Sun, Moon and planets over the course of the year. The Babylonian astrologers also laid the foundations of what would eventually become Western astrology. The "Enuma anu enlil", written during the Neo-Assyrian period in the 7th century BC, comprises a list of omens and their relationships with various celestial phenomena including the motions of the planets. Venus, Mercury and the outer planets Mars, Jupiter and Saturn were all identified by Babylonian astronomers. These would remain the only known planets until the invention of the telescope in early modern times.
Greco-Roman astronomy.
The ancient Greeks initially did not attach as much significance to the planets as the Babylonians. The Pythagoreans, in the 6th and 5th centuries BC appear to have developed their own independent planetary theory, which consisted of the Earth, Sun, Moon, and planets revolving around a "Central Fire" at the center of the Universe. Pythagoras or Parmenides is said to have been the first to identify the evening star (Hesperos) and morning star (Phosphoros) as one and the same (Aphrodite, Greek corresponding to Latin Venus). In the 3rd century BC, Aristarchus of Samos proposed a heliocentric system, according to which Earth and the planets revolved around the Sun. The geocentric system remained dominant until the Scientific Revolution.
By the 1st century BC, during the Hellenistic period, the Greeks had begun to develop their own mathematical schemes for predicting the positions of the planets. These schemes, which were based on geometry rather than the arithmetic of the Babylonians, would eventually eclipse the Babylonians' theories in complexity and comprehensiveness, and account for most of the astronomical movements observed from Earth with the naked eye. These theories would reach their fullest expression in the "Almagest" written by Ptolemy in the 2nd century CE. So complete was the domination of Ptolemy's model that it superseded all previous works on astronomy and remained the definitive astronomical text in the Western world for 13 centuries. To the Greeks and Romans there were seven known planets, each presumed to be circling Earth according to the complex laws laid out by Ptolemy. They were, in increasing order from Earth (in Ptolemy's order): the Moon, Mercury, Venus, the Sun, Mars, Jupiter, and Saturn.
India.
In 499 CE, the Indian astronomer Aryabhata propounded a planetary model that explicitly incorporated Earth's rotation about its axis, which he explains as the cause of what appears to be an apparent westward motion of the stars. He also believed that the orbits of planets are elliptical.
Aryabhata's followers were particularly strong in South India, where his principles of the diurnal rotation of Earth, among others, were followed and a number of secondary works were based on them.
In 1500, Nilakantha Somayaji of the Kerala school of astronomy and mathematics, in his "Tantrasangraha", revised Aryabhata's model. In his "Aryabhatiyabhasya", a commentary on Aryabhata's "Aryabhatiya", he developed a planetary model where Mercury, Venus, Mars, Jupiter and Saturn orbit the Sun, which in turn orbits Earth, similar to the Tychonic system later proposed by Tycho Brahe in the late 16th century. Most astronomers of the Kerala school who followed him accepted his planetary model.
Medieval Muslim astronomy.
In the 11th century, the transit of Venus was observed by Avicenna, who established that Venus was, at least sometimes, below the Sun. In the 12th century, Ibn Bajjah observed "two planets as black spots on the face of the Sun", which was later identified as a transit of Mercury and Venus by the Maragha astronomer Qotb al-Din Shirazi in the 13th century. Ibn Bajjah could not have observed a transit of Venus, because none occurred in his lifetime.
European Renaissance.
With the advent of the Scientific Revolution, use of the term "planet" changed from something that moved across the sky (in relation to the star field); to a body that orbited Earth (or that were believed to do so at the time); and by the 18th century to something that directly orbited the Sun when the heliocentric model of Copernicus, Galileo and Kepler gained sway.
Thus, Earth became included in the list of planets, whereas the Sun and Moon were excluded. At first, when the first satellites of Jupiter and Saturn were discovered in the 17th century, the terms "planet" and "satellite" were used interchangeably – although the latter would gradually become more prevalent in the following century. Until the mid-19th century, the number of "planets" rose rapidly because any newly discovered object directly orbiting the Sun was listed as a planet by the scientific community.
19th century.
In the 19th century astronomers began to realize that recently discovered bodies that had been classified as planets for almost half a century (such as Ceres, Pallas, and Vesta) were very different from the traditional ones. These bodies shared the same region of space between Mars and Jupiter (the asteroid belt), and had a much smaller mass; as a result they were reclassified as "asteroids". In the absence of any formal definition, a "planet" came to be understood as any "large" body that orbited the Sun. Because there was a dramatic size gap between the asteroids and the planets, and the spate of new discoveries seemed to have ended after the discovery of Neptune in 1846, there was no apparent need to have a formal definition.
20th century.
In the 20th century, Pluto was discovered. After initial observations led to the belief it was larger than Earth, the object was immediately accepted as the ninth planet. Further monitoring found the body was actually much smaller: in 1936, Raymond Lyttleton suggested that Pluto may be an escaped satellite of Neptune, and Fred Whipple suggested in 1964 that Pluto may be a comet. As it was still larger than all known asteroids and seemingly did not exist within a larger population, it kept its status until 2006.
In 1992, astronomers Aleksander Wolszczan and Dale Frail announced the discovery of planets around a pulsar, PSR B1257+12. This discovery is generally considered to be the first definitive detection of a planetary system around another star. Then, on October 6, 1995, Michel Mayor and Didier Queloz of the Geneva Observatory announced the first definitive detection of an exoplanet orbiting an ordinary main-sequence star (51 Pegasi).
The discovery of extrasolar planets led to another ambiguity in defining a planet: the point at which a planet becomes a star. Many known extrasolar planets are many times the mass of Jupiter, approaching that of stellar objects known as brown dwarfs. Brown dwarfs are generally considered stars due to their ability to fuse deuterium, a heavier isotope of hydrogen. Although objects more massive than 75 times that of Jupiter fuse hydrogen, objects of only 13 Jupiter masses can fuse deuterium. Deuterium is quite rare, and most brown dwarfs would have ceased fusing deuterium long before their discovery, making them effectively indistinguishable from supermassive planets.
21st century.
With the discovery during the latter half of the 20th century of more objects within the Solar System and large objects around other stars, disputes arose over what should constitute a planet. There were particular disagreements over whether an object should be considered a planet if it was part of a distinct population such as a belt, or if it was large enough to generate energy by the thermonuclear fusion of deuterium.
A growing number of astronomers argued for Pluto to be declassified as a planet, because many similar objects approaching its size had been found in the same region of the Solar System (the Kuiper belt) during the 1990s and early 2000s. Pluto was found to be just one small body in a population of thousands.
Some of them, such as Quaoar, Sedna, and Eris, were heralded in the popular press as the tenth planet, failing to receive widespread scientific recognition. The announcement of Eris in 2005, an object then thought of as 27% more massive than Pluto, created the necessity and public desire for an official definition of a planet.
Acknowledging the problem, the IAU set about creating the definition of planet, and produced one in August 2006. The number of planets dropped to the eight significantly larger bodies that had cleared their orbit (Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune), and a new class of dwarf planets was created, initially containing three objects (Ceres, Pluto and Eris).
Extrasolar planets.
There is no official definition of extrasolar planets. In 2003, the International Astronomical Union (IAU) Working Group on Extrasolar Planets issued a position statement, but this position statement was never proposed as an official IAU resolution and was never voted on by IAU members. The positions statement incorporates the following guidelines, mostly focused upon the boundary between planets and brown dwarfs:
This working definition has since been widely used by astronomers when publishing discoveries of exoplanets in academic journals. Although temporary, it remains an effective working definition until a more permanent one is formally adopted. It does not address the dispute over the lower mass limit, and so it steered clear of the controversy regarding objects within the Solar System. This definition also makes no comment on the planetary status of objects orbiting brown dwarfs, such as 2M1207b.
One definition of a sub-brown dwarf is a planet-mass object that formed through cloud collapse rather than accretion. This formation distinction between a sub-brown dwarf and a planet is not universally agreed upon; astronomers are divided into two camps as whether to consider the formation process of a planet as part of its division in classification. One reason for the dissent is that often it may not be possible to determine the formation process. For example, a planet formed by accretion around a star may get ejected from the system to become free-floating, and likewise a sub-brown dwarf that formed on its own in a star cluster through cloud collapse may get captured into orbit around a star.
The 13 Jupiter-mass cutoff represents an average mass rather than a precise threshold value. Large objects will fuse most of their deuterium and smaller ones will fuse only a little, and the 13 value is somewhere in between. In fact, calculations show that an object fuses 50% of its initial deuterium content when the total mass ranges between 12 and 14 . The amount of deuterium fused depends not only on mass but also on the composition of the object, on the amount of helium and deuterium present. The Extrasolar Planets Encyclopaedia includes objects up to 25 Jupiter masses, saying, "The fact that there is no special feature around 13 in the observed mass spectrum reinforces the choice to forget this mass limit." The Exoplanet Data Explorer includes objects up to 24 Jupiter masses with the advisory: "The 13 Jupiter-mass distinction by the IAU Working Group is physically unmotivated for planets with rocky cores, and observationally problematic due to the sin i ambiguity."
The NASA Exoplanet Archive includes objects with a mass (or minimum mass) equal to or less than 30 Jupiter masses.
Another criterion for separating planets and brown dwarfs, rather than deuterium fusion, formation process or location, is whether the core pressure is dominated by coulomb pressure or electron degeneracy pressure.
2006 IAU definition of planet.
The matter of the lower limit was addressed during the 2006 meeting of the IAU's General Assembly. After much debate and one failed proposal, 232 members of the 10,000 member assembly, who nevertheless constituted a large majority of those remaining at the meeting, voted to pass a resolution. The 2006 resolution defines planets within the Solar System as follows:
Under this definition, the Solar System is considered to have eight planets. Bodies that fulfill the first two conditions but not the third (such as Ceres, Pluto, and Eris) are classified as dwarf planets, provided they are not also natural satellites of other planets. Originally an IAU committee had proposed a definition that would have included a much larger number of planets as it did not include (c) as a criterion. After much discussion, it was decided via a vote that those bodies should instead be classified as dwarf planets.
This definition is based in theories of planetary formation, in which planetary embryos initially clear their orbital neighborhood of other smaller objects. As described by astronomer Steven Soter:
Because it is not presently possible to determine directly whether an exoplanet has cleared its orbit, a mathematical criterion has been proposed that approximately determines whether a planet can clear its orbit during the lifetime of its star, based on the mass of the planet, its semimajor axis, and the mass of its star. This formula produces a value π that is greater than one for planets. The eight known planets and all known exoplanets have π values above 100, while Ceres, Pluto, and Eris have values of 0.1 or less. Objects with π values of 1 or more are also expected to be approximately spherical.
Objects formerly considered planets.
The table below lists Solar System bodies once considered to be planets.
Beyond the scientific community, Pluto still holds cultural significance for many in the general public due to its historical classification as a planet from 1930 to 2006. A few astronomers, such as Alan Stern, consider dwarf planets and the larger moons to be planets, based on a purely geophysical definition of "planet".
Mythology and naming.
The names for the planets in the Western world are derived from the naming practices of the Romans, which ultimately derive from those of the Greeks and the Babylonians. In ancient Greece, the two great luminaries the Sun and the Moon were called "Helios" and "Selene"; the farthest planet (Saturn) was called "Phainon", the shiner; followed by "Phaethon" (Jupiter), "bright"; the red planet (Mars) was known as "Pyroeis", the "fiery"; the brightest (Venus) was known as "Phosphoros", the light bringer; and the fleeting final planet (Mercury) was called "Stilbon", the gleamer. The Greeks also made each planet sacred to one among their pantheon of gods, the Olympians: Helios and Selene were the names of both planets and gods; Phainon was sacred to Cronus, the Titan who fathered the Olympians; Phaethon was sacred to Zeus, Cronus's son who deposed him as king; Pyroeis was given to Ares, son of Zeus and god of war; Phosphoros was ruled by Aphrodite, the goddess of love; and Hermes, messenger of the gods and god of learning and wit, ruled over Stilbon.
The Greek practice of grafting of their gods' names onto the planets was almost certainly borrowed from the Babylonians. The Babylonians named Phosphoros after their goddess of love, "Ishtar"; Pyroeis after their god of war, "Nergal", Stilbon after their god of wisdom Nabu, and Phaethon after their chief god, "Marduk". There are too many concordances between Greek and Babylonian naming conventions for them to have arisen separately. The translation was not perfect. For instance, the Babylonian Nergal was a god of war, and thus the Greeks identified him with Ares. Unlike Ares, Nergal was also god of pestilence and the underworld.
Today, most people in the western world know the planets by names derived from the Olympian pantheon of gods. Although modern Greeks still use their ancient names for the planets, other European languages, because of the influence of the Roman Empire and, later, the Catholic Church, use the Roman (Latin) names rather than the Greek ones. The Romans, who, like the Greeks, were Indo-Europeans, shared with them a common pantheon under different names but lacked the rich narrative traditions that Greek poetic culture had given their gods. During the later period of the Roman Republic, Roman writers borrowed much of the Greek narratives and applied them to their own pantheon, to the point where they became virtually indistinguishable. When the Romans studied Greek astronomy, they gave the planets their own gods' names: "Mercurius" (for Hermes), "Venus" (Aphrodite), "Mars" (Ares), "Iuppiter" (Zeus) and "Saturnus" (Cronus). When subsequent planets were discovered in the 18th and 19th centuries, the naming practice was retained with "Neptūnus" (Poseidon). Uranus is unique in that it is named for a Greek deity rather than his Roman counterpart.
Some Romans, following a belief possibly originating in Mesopotamia but developed in Hellenistic Egypt, believed that the seven gods after whom the planets were named took hourly shifts in looking after affairs on Earth. The order of shifts went Saturn, Jupiter, Mars, Sun, Venus, Mercury, Moon (from the farthest to the closest planet). Therefore, the first day was started by Saturn (1st hour), second day by Sun (25th hour), followed by Moon (49th hour), Mars, Mercury, Jupiter and Venus. Because each day was named by the god that started it, this is also the order of the days of the week in the Roman calendar after the Nundinal cycle was rejected – and still preserved in many modern languages. In English, "Saturday, Sunday," and "Monday" are straightforward translations of these Roman names. The other days were renamed after "Tiw" (Tuesday), "Wóden" (Wednesday), "Thunor" (Thursday), and "Fríge" (Friday), the Anglo-Saxon gods considered similar or equivalent to Mars, Mercury, Jupiter, and Venus, respectively.
Earth is the only planet whose name in English is not derived from Greco-Roman mythology. Because it was only generally accepted as a planet in the 17th century, there is no tradition of naming it after a god. (The same is true, in English at least, of the Sun and the Moon, though they are no longer generally considered planets.) The name originates from the 8th century Anglo-Saxon word "erda", which means ground or soil and was first used in writing as the name of the sphere of Earth perhaps around 1300. As with its equivalents in the other Germanic languages, it derives ultimately from the Proto-Germanic word "ertho", "ground", as can be seen in the English "earth", the German "Erde", the Dutch "aarde", and the Scandinavian "jord". Many of the Romance languages retain the old Roman word "terra" (or some variation of it) that was used with the meaning of "dry land" as opposed to "sea". The non-Romance languages use their own native words. The Greeks retain their original name, "Γή" "(Ge)".
Non-European cultures use other planetary-naming systems. India uses a system based on the Navagraha, which incorporates the seven traditional planets (Surya for the Sun, Chandra for the Moon, and Budha, Shukra, Mangala, Bṛhaspati and Shani for Mercury, Venus, Mars, Jupiter and Saturn) and the ascending and descending lunar nodes Rahu and Ketu. China and the countries of eastern Asia historically subject to Chinese cultural influence (such as Japan, Korea and Vietnam) use a naming system based on the five Chinese elements: water (Mercury), metal (Venus), fire (Mars), wood (Jupiter) and earth (Saturn). In traditional Hebrew astronomy, the seven traditional planets have (for the most part) descriptive names - the Sun is חמה "Ḥammah" or "the hot one," the Moon is לבנה "Levanah" or "the white one," Venus is כוכב נוגה "Kokhav Nogah" or "the bright planet," Mercury is כוכב "Kokhav" or "the planet" (given its lack of distinguishing features), Mars is מאדים "Ma'adim" or "the red one," and Saturn is שבתאי "Shabbatai" or "the resting one" (in reference to its slow movement compared to the other visible planets). The odd one out is Jupiter, called צדק "Tzedeq" or "justice." Steiglitz suggests that this may be a euphemism for the original name of כוכב בעל "Kokhav Ba'al" or "Baal's planet," seen as idolatrous and euphemized in a similar manner to Ishbosheth from II Samuel 
Formation.
It is not known with certainty how planets are formed. The prevailing theory is that they are formed during the collapse of a nebula into a thin disk of gas and dust. A protostar forms at the core, surrounded by a rotating protoplanetary disk. Through accretion (a process of sticky collision) dust particles in the disk steadily accumulate mass to form ever-larger bodies. Local concentrations of mass known as planetesimals form, and these accelerate the accretion process by drawing in additional material by their gravitational attraction. These concentrations become ever denser until they collapse inward under gravity to form protoplanets. After a planet reaches a mass somewhat larger than Mars' mass, it begins to accumulate an extended atmosphere, greatly increasing the capture rate of the planetesimals by means of atmospheric drag. Depending on the accretion history of solids and gas, a giant planet, an ice giant, or a terrestrial planet may result. 
When the protostar has grown such that it ignites to form a star, the surviving disk is removed from the inside outward by photoevaporation, the solar wind, Poynting–Robertson drag and other effects. Thereafter there still may be many protoplanets orbiting the star or each other, but over time many will collide, either to form a single larger planet or release material for other larger protoplanets or planets to absorb. Those objects that have become massive enough will capture most matter in their orbital neighbourhoods to become planets. Protoplanets that have avoided collisions may become natural satellites of planets through a process of gravitational capture, or remain in belts of other objects to become either dwarf planets or small bodies.
The energetic impacts of the smaller planetesimals (as well as radioactive decay) will heat up the growing planet, causing it to at least partially melt. The interior of the planet begins to differentiate by mass, developing a denser core. Smaller terrestrial planets lose most of their atmospheres because of this accretion, but the lost gases can be replaced by outgassing from the mantle and from the subsequent impact of comets. (Smaller planets will lose any atmosphere they gain through various escape mechanisms.)
With the discovery and observation of planetary systems around stars other than the Sun, it is becoming possible to elaborate, revise or even replace this account. The level of metallicity—an astronomical term describing the abundance of chemical elements with an atomic number greater than 2 (helium)—is now thought to determine the likelihood that a star will have planets. Hence, it is thought that a metal-rich population I star will likely have a more substantial planetary system than a metal-poor, population II star.
Solar System.
There are eight planets in the Solar System, which are in increasing distance from the Sun:
Jupiter is the largest, at 318 Earth masses, whereas Mercury is the smallest, at 0.055 Earth masses.
The planets of the Solar System can be divided into categories based on their composition:
Exoplanets.
An exoplanet (extrasolar planet) is a planet outside the Solar System. More than 2000 such planets have been discovered
( planets in planetary systems including multiple planetary systems as of ).
In early 1992, radio astronomers Aleksander Wolszczan and Dale Frail announced the discovery of two planets orbiting the pulsar PSR 1257+12. This discovery was confirmed, and is generally considered to be the first definitive detection of exoplanets. These pulsar planets are believed to have formed from the unusual remnants of the supernova that produced the pulsar, in a second round of planet formation, or else to be the remaining rocky cores of giant planets that survived the supernova and then decayed into their current orbits.
The first confirmed discovery of an extrasolar planet orbiting an ordinary main-sequence star occurred on 6 October 1995, when Michel Mayor and Didier Queloz of the University of Geneva announced the detection of an exoplanet around 51 Pegasi. From then until the Kepler mission most known extrasolar planets were gas giants comparable in mass to Jupiter or larger as they were more easily detected. The catalog of Kepler candidate planets consists mostly of planets the size of Neptune and smaller, down to smaller than Mercury.
There are types of planets that do not exist in the Solar System: super-Earths and mini-Neptunes, which could be rocky like Earth or a mixture of volatiles and gas like Neptune—a radius of 1.75 times that of Earth is a possible dividing line between the two types of planet. There are hot Jupiters that orbit very close to their star and may evaporate to become chthonian planets, which are the leftover cores. Another possible type of planet is carbon planets, which form in systems with a higher proportion of carbon than in the Solar System.
A 2012 study, analyzing gravitational microlensing data, estimates an average of at least 1.6 bound planets for every star in the Milky Way.
On December 20, 2011, the Kepler Space Telescope team reported the discovery of the first Earth-size exoplanets, Kepler-20e and Kepler-20f, orbiting a Sun-like star, Kepler-20.
Around 1 in 5 Sun-like stars have an "Earth-sized" planet in the habitable zone, so the nearest would be expected to be within 12 light-years distance from Earth.
The frequency of occurrence of such terrestrial planets is one of the variables in the Drake equation, which estimates the number of intelligent, communicating civilizations that exist in the Milky Way.
There are exoplanets that are much closer to their parent star than any planet in the Solar System is to the Sun, and there are also exoplanets that are much further from their star. Mercury, the closest planet to the Sun at 0.4 AU, takes 88-days for an orbit, but the shortest known orbits for exoplanets take only a few hours, e.g. Kepler-70b. The Kepler-11 system has five of its planets in shorter orbits than Mercury. Neptune is 30 AU from the Sun and takes 165 years to orbit, but there are exoplanets that are hundreds of AU from their star and take more than a thousand years to orbit, e.g. 1RXS1609 b.
The next few space telescopes to study exoplanets are expected to be Gaia launched in December 2013, CHEOPS in 2017, TESS in 2017, and the James Webb Space Telescope in 2018.
Planetary-mass objects.
A planetary-mass object (PMO), planemo , or planetary body is a celestial object with a mass that falls within the range of the definition of a planet: massive enough to achieve hydrostatic equilibrium (to be rounded under its own gravity), but not enough to sustain core fusion like a star. By definition, all planets are "planetary-mass objects", but the purpose of this term is to refer to objects that do not conform to typical expectations for a planet. These include dwarf planets, which are rounded by their own gravity but not massive enough to clear their own orbit, the larger moons, and free-floating planemos, which may have been ejected from a system (rogue planets) or formed through cloud-collapse rather than accretion (sometimes called sub-brown dwarfs).
Rogue planets.
Several computer simulations of stellar and planetary system formation have suggested that some objects of planetary mass would be ejected into interstellar space. Some scientists have argued that such objects found roaming in deep space should be classed as "planets", although others have suggested that they should be called low-mass brown dwarfs.
Sub-brown dwarfs.
Stars form via the gravitational collapse of gas clouds, but smaller objects can also form via cloud-collapse. Planetary-mass objects formed this way are sometimes called sub-brown dwarfs. Sub-brown dwarfs may be free-floating such as Cha 110913-773444 and OTS 44, or orbiting a larger object such as 2MASS J04414489+2301513.
Binary systems of sub-brown dwarfs are theoretically possible; Oph 162225-240515 was initially thought to be a binary system of a brown dwarf of 14 Jupiter masses and a sub-brown dwarf of 7 Jupiter masses, but further observations revised the estimated masses upwards to greater than 13 Jupiter masses, making them brown dwarfs according to the IAU working definitions.
Former stars.
In close binary star systems one of the stars can lose mass to a heavier companion. Accretion-powered pulsars may drive mass loss. The shrinking star can then become a planetary-mass object. An example is a Jupiter-mass object orbiting the pulsar PSR J1719-1438. These shrunken white dwarfs may become a helium planet or carbon planet.
Satellite planets and belt planets.
Some large satellites are of similar size or larger than the planet Mercury, e.g. Jupiter's Galilean moons and Titan. Alan Stern has argued that location should not matter and that only geophysical attributes should be taken into account in the definition of a planet, and proposes the term "satellite planet" for a planet-sized satellite. Likewise, dwarf planets in the asteroid belt and Kuiper belt should be considered planets according to Stern.
Captured planets.
Free-floating planets in stellar clusters have similar velocities to the stars and so can be recaptured. They are typically captured into wide orbits between 100 and 105 AU. The capture efficiency decreases with increasing cluster volume, and for a given cluster size it increases with the host/primary mass. It is almost independent of the planetary mass. Single and multiple planets could be captured into arbitrary unaligned orbits, non-coplanar with each other or with the stellar host spin, or pre-existing planetary system.
Attributes.
Although each planet has unique physical characteristics, a number of broad commonalities do exist among them. Some of these characteristics, such as rings or natural satellites, have only as yet been observed in planets in the Solar System, whereas others are also commonly observed in extrasolar planets.
Dynamic characteristics.
Orbit.
According to current definitions, all planets must revolve around stars; thus, any potential "rogue planets" are excluded. In the Solar System, all the planets orbit the Sun in the same direction as the Sun rotates (counter-clockwise as seen from above the Sun's north pole). At least one extrasolar planet, WASP-17b, has been found to orbit in the opposite direction to its star's rotation. The period of one revolution of a planet's orbit is known as its sidereal period or "year". A planet's year depends on its distance from its star; the farther a planet is from its star, not only the longer the distance it must travel, but also the slower its speed, because it is less affected by its star's gravity. No planet's orbit is perfectly circular, and hence the distance of each varies over the course of its year. The closest approach to its star is called its periastron (perihelion in the Solar System), whereas its farthest separation from the star is called its apastron (aphelion). As a planet approaches periastron, its speed increases as it trades gravitational potential energy for kinetic energy, just as a falling object on Earth accelerates as it falls; as the planet reaches apastron, its speed decreases, just as an object thrown upwards on Earth slows down as it reaches the apex of its trajectory.
Each planet's orbit is delineated by a set of elements:
Axial tilt.
Planets also have varying degrees of axial tilt; they lie at an angle to the plane of their stars' equators. This causes the amount of light received by each hemisphere to vary over the course of its year; when the northern hemisphere points away from its star, the southern hemisphere points towards it, and vice versa. Each planet therefore has seasons; changes to the climate over the course of its year. The time at which each hemisphere points farthest or nearest from its star is known as its solstice. Each planet has two in the course of its orbit; when one hemisphere has its summer solstice, when its day is longest, the other has its winter solstice, when its day is shortest. The varying amount of light and heat received by each hemisphere creates annual changes in weather patterns for each half of the planet. Jupiter's axial tilt is very small, so its seasonal variation is minimal; Uranus, on the other hand, has an axial tilt so extreme it is virtually on its side, which means that its hemispheres are either perpetually in sunlight or perpetually in darkness around the time of its solstices. Among extrasolar planets, axial tilts are not known for certain, though most hot Jupiters are believed to have negligible to no axial tilt as a result of their proximity to their stars.
Rotation.
The planets rotate around invisible axes through their centres. A planet's rotation period is known as a stellar day. Most of the planets in the Solar System rotate in the same direction as they orbit the Sun, which is counter-clockwise as seen from above the Sun's north pole, the exceptions being Venus and Uranus, which rotate clockwise, though Uranus's extreme axial tilt means there are differing conventions on which of its poles is "north", and therefore whether it is rotating clockwise or anti-clockwise. Regardless of which convention is used, Uranus has a retrograde rotation relative to its orbit.
The rotation of a planet can be induced by several factors during formation. A net angular momentum can be induced by the individual angular momentum contributions of accreted objects. The accretion of gas by the giant planets can also contribute to the angular momentum. Finally, during the last stages of planet building, a stochastic process of protoplanetary accretion can randomly alter the spin axis of the planet. There is great variation in the length of day between the planets, with Venus taking 243 days to rotate, and the giant planets only a few hours. The rotational periods of extrasolar planets are not known. However, for "hot" Jupiters, their proximity to their stars means that they are tidally locked (i.e., their orbits are in sync with their rotations). This means, they always show one face to their stars, with one side in perpetual day, the other in perpetual night.
Orbital clearing.
The defining dynamic characteristic of a planet is that it has "cleared its neighborhood". A planet that has cleared its neighborhood has accumulated enough mass to gather up or sweep away all the planetesimals in its orbit. In effect, it orbits its star in isolation, as opposed to sharing its orbit with a multitude of similar-sized objects. This characteristic was mandated as part of the IAU's official definition of a planet in August, 2006. This criterion excludes such planetary bodies as Pluto, Eris and Ceres from full-fledged planethood, making them instead dwarf planets. Although to date this criterion only applies to the Solar System, a number of young extrasolar systems have been found in which evidence suggests orbital clearing is taking place within their circumstellar discs.
Physical characteristics.
Mass.
A planet's defining physical characteristic is that it is massive enough for the force of its own gravity to dominate over the electromagnetic forces binding its physical structure, leading to a state of hydrostatic equilibrium. This effectively means that all planets are spherical or spheroidal. Up to a certain mass, an object can be irregular in shape, but beyond that point, which varies depending on the chemical makeup of the object, gravity begins to pull an object towards its own centre of mass until the object collapses into a sphere.
Mass is also the prime attribute by which planets are distinguished from stars. The upper mass limit for planethood is roughly 13 times Jupiter's mass for objects with solar-type isotopic abundance, beyond which it achieves conditions suitable for nuclear fusion. Other than the Sun, no objects of such mass exist in the Solar System; but there are exoplanets of this size. The 13-Jupiter-mass limit is not universally agreed upon and the Extrasolar Planets Encyclopaedia includes objects up to 20 Jupiter masses, and the Exoplanet Data Explorer up to 24 Jupiter masses.
The smallest known planet is PSR B1257+12A, one of the first extrasolar planets discovered, which was found in 1992 in orbit around a pulsar. Its mass is roughly half that of the planet Mercury. The smallest known planet orbiting a main-sequence star other than the Sun is Kepler-37b, with a mass (and radius) slightly higher than that of the Moon.
Internal differentiation.
Every planet began its existence in an entirely fluid state; in early formation, the denser, heavier materials sank to the centre, leaving the lighter materials near the surface. Each therefore has a differentiated interior consisting of a dense planetary core surrounded by a mantle that either is or was a fluid. The terrestrial planets are sealed within hard crusts, but in the giant planets the mantle simply blends into the upper cloud layers. The terrestrial planets have cores of elements such as iron and nickel, and mantles of silicates. Jupiter and Saturn are believed to have cores of rock and metal surrounded by mantles of metallic hydrogen. Uranus and Neptune, which are smaller, have rocky cores surrounded by mantles of water, ammonia, methane and other ices. The fluid action within these planets' cores creates a geodynamo that generates a magnetic field.
Atmosphere.
All of the Solar System planets except Mercury have substantial atmospheres because their gravity is strong enough to keep gases close to the surface. The larger giant planets are massive enough to keep large amounts of the light gases hydrogen and helium, whereas the smaller planets lose these gases into space. The composition of Earth's atmosphere is different from the other planets because the various life processes that have transpired on the planet have introduced free molecular oxygen.
Planetary atmospheres are affected by the varying insolation or internal energy, leading to the formation of dynamic weather systems such as hurricanes, (on Earth), planet-wide dust storms (on Mars), a greater-than-Earth-sized anticyclone on Jupiter (called the Great Red Spot), and holes in the atmosphere (on Neptune). At least one extrasolar planet, HD 189733 b, has been claimed to have such a weather system, similar to the Great Red Spot but twice as large.
Hot Jupiters, due to their extreme proximities to their host stars, have been shown to be losing their atmospheres into space due to stellar radiation, much like the tails of comets. These planets may have vast differences in temperature between their day and night sides that produce supersonic winds, although the day and night sides of HD 189733 b appear to have very similar temperatures, indicating that that planet's atmosphere effectively redistributes the star's energy around the planet.
Magnetosphere.
One important characteristic of the planets is their intrinsic magnetic moments, which in turn give rise to magnetospheres. The presence of a magnetic field indicates that the planet is still geologically alive. In other words, magnetized planets have flows of electrically conducting material in their interiors, which generate their magnetic fields. These fields significantly change the interaction of the planet and solar wind. A magnetized planet creates a cavity in the solar wind around itself called magnetosphere, which the wind cannot penetrate. The magnetosphere can be much larger than the planet itself. In contrast, non-magnetized planets have only small magnetospheres induced by interaction of the ionosphere with the solar wind, which cannot effectively protect the planet.
Of the eight planets in the Solar System, only Venus and Mars lack such a magnetic field. In addition, the moon of Jupiter Ganymede also has one. Of the magnetized planets the magnetic field of Mercury is the weakest, and is barely able to deflect the solar wind. Ganymede's magnetic field is several times larger, and Jupiter's is the strongest in the Solar System (so strong in fact that it poses a serious health risk to future manned missions to its moons). The magnetic fields of the other giant planets are roughly similar in strength to that of Earth, but their magnetic moments are significantly larger. The magnetic fields of Uranus and Neptune are strongly tilted relative the rotational axis and displaced from the centre of the planet.
In 2004, a team of astronomers in Hawaii observed an extrasolar planet around the star HD 179949, which appeared to be creating a sunspot on the surface of its parent star. The team hypothesized that the planet's magnetosphere was transferring energy onto the star's surface, increasing its already high 7,760 °C temperature by an additional 400 °C.
Secondary characteristics.
Several planets or dwarf planets in the Solar System (such as Neptune and Pluto) have orbital periods that are in resonance with each other or with smaller bodies (this is also common in satellite systems). All except Mercury and Venus have natural satellites, often called "moons". Earth has one, Mars has two, and the giant planets have numerous moons in complex planetary-type systems. Many moons of the giant planets have features similar to those on the terrestrial planets and dwarf planets, and some have been studied as possible abodes of life (especially Europa).
The four giant planets are also orbited by planetary rings of varying size and complexity. The rings are composed primarily of dust or particulate matter, but can host tiny 'moonlets' whose gravity shapes and maintains their structure. Although the origins of planetary rings is not precisely known, they are believed to be the result of natural satellites that fell below their parent planet's Roche limit and were torn apart by tidal forces.
No secondary characteristics have been observed around extrasolar planets. The sub-brown dwarf Cha 110913-773444, which has been described as a rogue planet, is believed to be orbited by a tiny protoplanetary disc and the sub-brown dwarf OTS 44 was shown to be surrounded by a substantial protoplanetary disk of at least 10 Earth masses.

</doc>
<doc id="22918" url="https://en.wikipedia.org/wiki?curid=22918" title="Paramount Pictures">
Paramount Pictures

Paramount Pictures Corporation (commonly known as Paramount Studios or simply Paramount, and formerly known as Famous Players-Lasky Corporation) is an American film studio, television production company and motion picture distributor, consistently ranked as one of the "Big Six" film studios of Hollywood. It is a subsidiary of U.S. media conglomerate Viacom. Paramount is a member of the Motion Picture Association of America (MPAA).
In 2014, Paramount Pictures became the first major Hollywood studio to distribute all of its films in digital-form only.
Paramount is the fifth oldest surviving film studio in the world, and America's oldest running studio, founded in 1912.
History.
1911–1920: Early history.
Paramount is the fifth oldest surviving film studio in the world after the French studios Gaumont Film Company (1895) and Pathé (1896), followed by the Nordisk Film company (1906), and Universal Studios (1912). It is the last major film studio still headquartered in the Hollywood district of Los Angeles.
Paramount Pictures dates its existence from the 1912 founding date of the Famous Players Film Company. Hungarian-born founder, Adolph Zukor, who had been an early investor in nickelodeons, saw that movies appealed mainly to working-class immigrants. With partners Daniel Frohman and Charles Frohman he planned to offer feature-length films that would appeal to the middle class by featuring the leading theatrical players of the time (leading to the slogan "Famous Players in Famous Plays"). By mid-1913, Famous Players had completed five films, and Zukor was on his way to success. Its first film was "Les Amours de la reine Élisabeth", which starred Sarah Bernhardt.
That same year, another aspiring producer, Jesse L. Lasky, opened his Lasky Feature Play Company with money borrowed from his brother-in-law, Samuel Goldfish, later known as Samuel Goldwyn. The Lasky company hired as their first employee a stage director with virtually no film experience, Cecil B. DeMille, who would find a suitable location site in Hollywood, near Los Angeles, for his first feature film, "The Squaw Man".
Starting in 1914, both Lasky and Famous Players released their films through a start-up company, Paramount Pictures Corporation, organized early that year by a Utah theatre owner, W. W. Hodkinson, who had bought and merged several smaller firms. Hodkinson and actor, director, producer Hobart Bosworth had started production of a series of Jack London movies. Paramount was the first successful nationwide distributor; until this time, films were sold on a statewide or regional basis which had proved costly to film producers. Also, Famous Players and Lasky were privately owned while Paramount was a corporation.
In 1916, Zukor maneuvered a three-way merger of his Famous Players, the Lasky Company, and Paramount. Zukor and Lasky bought Hodkinson out of Paramount, and merged the three companies into one. The new company Lasky and Zukor founded, Famous Players-Lasky Corporation, grew quickly, with Lasky and his partners Goldwyn and DeMille running the production side, Hiram Abrams in charge of distribution, and Zukor making great plans. With only the exhibitor-owned First National as a rival, Famous Players-Lasky and its "Paramount Pictures" soon dominated the business.
1921–1930: Rise.
Because Zukor believed in stars, he signed and developed many of the leading early stars, including Mary Pickford, Marguerite Clark, Pauline Frederick, Douglas Fairbanks, Gloria Swanson, Rudolph Valentino, and Wallace Reid. With so many important players, Paramount was able to introduce "block booking", which meant that an exhibitor who wanted a particular star's films had to buy a year's worth of other Paramount productions. It was this system that gave Paramount a leading position in the 1920s and 1930s, but which led the government to pursue it on antitrust grounds for more than twenty years.
The driving force behind Paramount's rise was Zukor. Through the teens and twenties, he built the Publix Theatres Corporation, a chain of nearly 2,000 screens, ran two production studios (in Astoria, New York, now the Kaufman Astoria Studios, and Hollywood, California), and became an early investor in radio, taking a 50% interest in the new Columbia Broadcasting System in 1928 (selling it within a few years; this would not be the last time Paramount and CBS crossed paths).
In 1926, Zukor hired independent producer B. P. Schulberg, an unerring eye for new talent, to run the new West Coast operations. They purchased the Robert Brunton Studios, a 26-acre facility at 5451 Marathon Street for US$1 million. In 1927, Famous Players-Lasky took the name Paramount Famous Lasky Corporation. Three years later, because of the importance of the Publix Theatres, it became Paramount Publix Corporation.
In 1928, Paramount began releasing "Inkwell Imps," animated cartoons produced by Max and Dave Fleischer's Fleischer Studios in New York City. The Fleischers, veterans in the animation industry, were among the few animation producers capable of challenging the prominence of Walt Disney. The Paramount newsreel series Paramount News ran from 1927 to 1957. Paramount was also one of the first Hollywood studios to release what were known at that time as "talkies", and in 1929, released their first musical, "Innocents of Paris". Richard A. Whiting and Leo Robin composed the score for the film; Maurice Chevalier starred and sung the most famous song from the film, "Louise".
Publix, Balaban and Katz, Loew's competition and wonder theaters.
By acquiring the successful Balaban & Katz chain in 1926, Zukor gained the services of Barney Balaban (who would eventually become Paramount's president in 1936), his brother A. J. Balaban (who would eventually supervise all stage production nationwide and produce talkie shorts), and their partner Sam Katz (who would run the Paramount-Publix theatre chain in New York City from the thirty-five-story Paramount Theatre Building on Times Square).
Balaban and Katz had developed the Wonder Theater concept, first publicized around 1918 in Chicago. The Chicago Theater was created as a very ornate theater and advertised as a "wonder theater." When Publix acquired Balaban, they embarked on a project to expand the wonder theaters, and starting building in New York in 1927. While Balaban and Public were dominant in Chicago, Loew's was the big player in New York, and did not want the Publix theaters to overshadow theirs. The two companies brokered a non-competition deal for New York and Chicago, and Loew's took over the New York area projects, developing five wonder theaters. Publix continued Balaban's wonder theater development in its home area.
1931–1940: Receivership.
Eventually, Zukor shed most of his early partners; the Frohman brothers, Hodkinson and Goldwyn were out by 1917 while Lasky hung on until 1932, when, blamed for the near-collapse of Paramount in the Depression years, he too was tossed out. Zukor's over-expansion and use of overvalued Paramount stock for purchases led the company into receivership in 1933. A bank-mandated reorganization team, led by John Hertz and Otto Kahn kept the company intact, and, miraculously, Zukor was kept on. In 1935, Paramount-Publix went bankrupt. In 1936, Barney Balaban became president, and Zukor was bumped up to chairman of the board. In this role, Zukor reorganized the company as Paramount Pictures, Inc. and was able to successfully bring the studio out of bankruptcy.
As always, Paramount films continued to emphasize stars; in the 1920s there were Swanson, Valentino, and Clara Bow. By the 1930s, talkies brought in a range of powerful new draws: Miriam Hopkins, Marlene Dietrich, Mae West, W.C. Fields, Jeanette MacDonald, Claudette Colbert, the Marx Brothers (whose first two films were shot at Paramount's Astoria, New York, studio), Dorothy Lamour, Carole Lombard, Bing Crosby, band leader Shep Fields, famous Argentine tango singer Carlos Gardel, and Gary Cooper among them. In this period Paramount can truly be described as a movie factory, turning out sixty to seventy pictures a year. Such were the benefits of having a huge theater chain to fill, and of block booking to persuade other chains to go along. In 1933, Mae West would also add greatly to Paramount's success with her suggestive movies "She Done Him Wrong" and "I'm No Angel". However, the sex appeal West gave in these movies would also lead to the enforcement of the Production Code, as the newly formed organization the Catholic Legion of Decency threatened a boycott if it was not enforced.
Paramount cartoons produced by Fleischer Studios continued to be successful, with characters such as Betty Boop and Popeye the Sailor becoming widely successful. One Fleischer series, "Screen Songs", featured live-action music stars under contract to Paramount hosting sing-alongs of popular songs. The animation studio would rebound with Popeye, and in 1935, polls showed that Popeye was even more popular than Mickey Mouse. After an unsuccessful expansion into feature films, as well as the fact that Max and Dave Fleischer were no longer speaking to one another, Fleischer Studios was acquired by Paramount, which renamed the operation Famous Studios. That incarnation of the animation studio continued cartoon production until 1967, but has been historically dismissed as having largely failed to maintain the artistic acclaim the Fleischer brothers achieved under their management.
1941–1950: United States v. Paramount Pictures, Inc..
In 1940, Paramount agreed to a government-instituted consent decree: block booking and "pre-selling" (the practice of collecting up-front money for films not yet in production) would end. Immediately Paramount cut back on production, from seventy-one pictures to a more modest nineteen annually in the war years. Still, with more new stars like Bob Hope, Alan Ladd, Veronica Lake, Paulette Goddard, and Betty Hutton, and with war-time attendance at astronomical numbers, Paramount and the other integrated studio-theatre combines made more money than ever. At this, the Federal Trade Commission and the Justice Department decided to reopen their case against the five integrated studios. Paramount also had a monopoly over Detroit movie theaters through subsidiary company United Detroit Theaters as well. This led to the Supreme Court decision United States v. Paramount Pictures, Inc. (1948) holding that movie studios could not also own movie theater chains. This decision broke up Adolph Zukor's creation and effectively brought an end to the classic Hollywood studio system.
1951–1966: Split and after.
With the separation of production and exhibition forced by the U.S. Supreme Court, Paramount Pictures Inc. was split in two. Paramount Pictures Corporation was formed to be the production distribution company, with the 1,500-screen theater chain handed to the new United Paramount Theaters on December 31, 1949. Leonard Goldenson, who had headed the chain since 1938, remained as the new company's president. The Balaban and Katz theatre division was spun off with UPT; its trademark eventually became the property of the Balaban and Katz Historical Foundation. The Foundation has recently acquired ownership of the Famous Players Trademark. Cash-rich and controlling prime downtown real estate, Goldenson began looking for investments. Barred from film-making by prior anti-trust rulings, he acquired the struggling ABC television network in February 1953, leading it first to financial health, and eventually, in the mid-1970s, to first place in the national Nielsen ratings, before selling out to Capital Cities in 1985 (Capital Cities would eventually sell out, in turn, to The Walt Disney Company in 1996). United Paramount Theaters was renamed ABC Theaters in 1965 and was sold to businessman Henry Plitt in 1974. The movie theater chain was renamed Plitt Theaters. In 1985, Cineplex Odeon Corporation merged with Plitt. In later years, Paramount's TV division would develop a strong relationship with ABC, providing many hit series to the network.
The DuMont Network.
Paramount Pictures had been an early backer of television, launching experimental stations in 1939 in Los Angeles and Chicago. The Los Angeles station eventually became KTLA, the first commercial station on the West Coast. The Chicago station got a commercial license as WBKB in 1943, but was sold to UPT along with Balaban & Katz in 1948 and was eventually resold to CBS as WBBM-TV.
In 1938, Paramount bought a stake in television manufacturer DuMont Laboratories. Through this stake, it became a minority owner of the DuMont Television Network. Also Paramount launched its own network, Paramount Television Network, in 1948 through its television unit, Television Productions, Inc.
Paramount management planned to acquire additional owned-and-operated stations ("O&Os"); the company applied to the FCC for additional stations in San Francisco, Detroit, and Boston. The FCC, however, denied Paramount's applications. A few years earlier, the federal regulator had placed a five-station cap on all television networks: no network was allowed to own more than five VHF television stations. Paramount was hampered by its minority stake in the DuMont Television Network. Although both DuMont and Paramount executives stated that the companies were separate, the FCC ruled that Paramount's partial ownership of DuMont meant that DuMont and Paramount were in theory branches of the same company. Since DuMont owned three television stations and Paramount owned two, the federal agency ruled neither network could acquire additional television stations. The FCC requested that Paramount relinquish its stake in DuMont, but Paramount refused. According to television historian William Boddy, "Paramount's checkered anti-trust history" helped convince the FCC that Paramount controlled DuMont. Both DuMont and Paramount Television Network suffered as a result, with neither company able to acquire five O&Os. Meanwhile, CBS, ABC, and NBC had each acquired the maximum of five stations by the mid-1950s.
When ABC accepted a merger offer from UPT in 1953, DuMont quickly realized that ABC now had more resources than it could possibly hope to match. It quickly reached an agreement in principle to merge with ABC.
In 1951, Paramount bought a stake in International Telemeter, an experimental pay TV service which operated with a coin inserted into a box. The service began operating in Palm Springs, California on November 27, 1953, but due to pressure from the FCC, the service ended on May 15, 1954.
With the loss of the theater chain, Paramount Pictures went into a decline, cutting studio-backed production, releasing its contract players, and making production deals with independents. By the mid-1950s, all the great names were gone; only Cecil B. DeMille, associated with Paramount since 1913, kept making pictures in the grand old style. Despite Paramount's losses, DeMille would, however, give the studio some relief and create his most successful film at Paramount, a 1956 remake of his 1923 film "The Ten Commandments". DeMille died in 1959. Like some other studios, Paramount saw little value in its film library, and sold 764 of its pre-1948 films to MCA Inc. (known today as Universal Studios Inc.) in February 1958.
1966–1970: Early Gulf+Western era.
By the early 1960s, Paramount's future was doubtful. The high-risk movie business was wobbly; the theater chain was long gone; investments in DuMont and in early pay-television came to nothing; and the Golden Age of Hollywood had just ended, even the flagship Paramount building in Times Square was sold to raise cash, as was KTLA (sold to Gene Autry in 1964 for a then-phenomenal $12.5 million). Their only remaining successful property at that point was Dot Records, which Paramount had acquired in 1957, and even its profits started declining by the middle of the 1960s. Founding father Adolph Zukor (born in 1873) was still chairman emeritus; he referred to chairman Barney Balaban (born 1888) as "the boy." Such aged leadership was incapable of keeping up with the changing times, and in 1966, a sinking Paramount was sold to Charles Bluhdorn's industrial conglomerate, Gulf + Western Industries Corporation. Bluhdorn immediately put his stamp on the studio, installing a virtually unknown producer named Robert Evans as head of production. Despite some rough times, Evans held the job for eight years, restoring Paramount's reputation for commercial success with "The Odd Couple", "Rosemary's Baby", "Love Story", "The Godfather", "Chinatown", and "3 Days of the Condor".
Gulf + Western Industries also bought the neighboring Desilu television studio (once the lot of RKO Pictures) from Lucille Ball in 1967. Using some of Desilu's established shows such as ', ', and "Mannix" as a foot in the door at the networks, the newly reincorporated Paramount Television eventually became known as a specialist in half-hour situation comedies.
1971–1980: CIC formation and high-concept era.
In 1970, Paramount teamed with Universal Studios to form Cinema International Corporation, a new company that would distribute films by the two studios outside the United States. Metro-Goldwyn-Mayer would become a partner in the mid-1970s. Both Paramount and CIC entered the video market with Paramount Home Video (now Paramount Home Entertainment) and CIC Video, respectively.
Robert Evans abandoned his position as head of production in 1974; his successor, Richard Sylbert, proved to be too literary and too tasteful for Gulf + Western's Bluhdorn. By 1976, a new, television-trained team was in place headed by Barry Diller and his "Killer-Dillers", as they were called by admirers or "Dillettes" as they were called by detractors. These associates, made up of Michael Eisner, Jeffrey Katzenberg, Dawn Steel and Don Simpson would each go on and head up major movie studios of their own later in their careers.
The Paramount specialty was now simpler. "High concept" pictures such as "Saturday Night Fever" and "Grease" hit big, hit hard and hit fast all over the world, and Diller's television background led him to propose one of his longest-standing ideas to the board: Paramount Television Service, a fourth commercial network. Paramount Pictures purchased the Hughes Television Network (HTN) including its satellite time in planning for PTVS in 1976. Paramount sold HTN to Madison Square Garden in 1979. But Diller believed strongly in the concept, and so took his fourth-network idea with him when he moved to 20th Century Fox in 1984, where Fox's then freshly installed proprietor, Rupert Murdoch was a more interested listener.
However, the television division would be playing catch-up for over a decade after Diller's departure in 1984 before launching its own television network – UPN – in 1995. Lasting eleven years before being merged with The WB network to become The CW in 2006, UPN would feature many of the shows it originally produced for other networks, and would take numerous gambles on series such as ' and ' that would have otherwise either gone direct-to-cable or become first-run syndication to independent stations across the country (as ' and ' were).
Paramount Pictures was not connected to either Paramount Records (1910s-1935) or ABC-Paramount Records (1955–66) until it purchased the rights to use the name (but not the latter's catalog) in the late 1960s. The Paramount name was used for soundtrack albums and some pop re-issues from the Dot Records catalog which Paramount had acquired in 1957. By 1970, Dot had become an all-country label and in 1974, Paramount sold all of its record holdings to ABC Records, which in turn was sold to MCA (now Universal Music Group) in 1979.
1980–1994: Continual success.
Paramount's successful run of pictures extended into the 1980s and 1990s, generating hits like "Airplane!", "American Gigolo", "Ordinary People", "An Officer and a Gentleman", "Flashdance", "Terms of Endearment", "Footloose", "Pretty in Pink", "Top Gun", ""Crocodile" Dundee", "Fatal Attraction", "Ghost", the "Friday the 13th" slasher series, as well as "Raiders of the Lost Ark" and its sequels. Other examples are the "Star Trek" film series and a string of films starring comedian Eddie Murphy like "Trading Places", "Coming to America", and "Beverly Hills Cop" and its sequels. While the emphasis was decidedly on the commercial, there were occasional less commercial but more artistic and intellectual efforts like "I'm Dancing as Fast as I Can", "Atlantic City", "Reds", "Witness", "Children of a Lesser God" and "The Accused". During this period, responsibility for running the studio passed from Eisner and Katzenberg to Frank Mancuso, Sr. (1984) and Ned Tanen (1984) to Stanley R. Jaffe (1991) and Sherry Lansing (1992). More so than most, Paramount's slate of films included many remakes and television spinoffs; while sometimes commercially successful, there have been few compelling films of the kind that once made Paramount the industry leader.
On August 25, 1983, Paramount Studios caught fire. Two or three sound stages and four outdoor sets were destroyed.
When Charles Bluhdorn died unexpectedly, his successor Martin Davis dumped all of G+W's industrial, mining, and sugar-growing subsidiaries and refocused the company, renaming it Paramount Communications in 1989. With the influx of cash from the sale of G+W's industrial properties in the mid-1980s, Paramount bought a string of television stations and KECO Entertainment's theme park operations, renaming them Paramount Parks. These parks included Paramount's Great America, Paramount Canada's Wonderland, Paramount's Carowinds, Paramount's Kings Dominion, and Paramount's Kings Island.
In 1993, Sumner Redstone's entertainment conglomerate Viacom made a bid for a merger with Paramount Communications; this quickly escalated into a bidding war with Barry Diller's QVC. But Viacom prevailed, ultimately paying $10 billion for the Paramount holdings. Viacom and Paramount had planned to merge as early as 1989.
Paramount is the last major film studio located in Hollywood proper. When Paramount moved to its present home in 1927, it was in the heart of the film community. Since then, former next-door neighbor RKO closed up shop in 1957 (Paramount ultimately absorbed their former lot); Warner Bros. (whose old Sunset Boulevard studio was sold to Paramount in 1949 as a home for KTLA) moved to Burbank in 1930; Columbia joined Warners in Burbank in 1973 then moved again to Culver City in 1989; and the Pickford-Fairbanks-Goldwyn-United Artists lot, after a lively history, has been turned into a post-production and music-scoring facility for Warners, known simply as "The Lot". For a time the semi-industrial neighborhood around Paramount was in decline, but has now come back. The recently refurbished studio has come to symbolize Hollywood for many visitors, and its studio tour is a popular attraction.
1994–2004: Dolgen/Lansing and "old" Viacom era.
During this time period, Paramount Pictures went under the guidance of Jonathan Dolgen, chairman and Sherry Lansing, president. During their administration over Paramount, the studio had an extremely successful period of films with two of Paramount's ten highest grossing films being produced during this period. The most successful of these films, "Titanic", a joint production with 20th Century Fox, became the highest grossing film up to that time, grossing over $1.8 billion worldwide. Also during this time, three Paramount Pictures films won the Academy Award for Best Picture; "Titanic, Braveheart", and "Forrest Gump".
Paramount's most important property, however, was "Star Trek". Studio executives had begun to call it "the franchise" in the 1980s due to its reliable revenue, and other studios envied its "untouchable and unduplicatable" success. By 1998 "Star Trek" TV shows, movies, books, videotapes, and licensing provided so much of the studio's profit that "it is not possible to spend any reasonable amount of time at Paramount and not be aware of presence"; filming for "Star Trek: Voyager" and "Star Trek: Deep Space Nine" required up to nine of the largest of the studio's 36 sound stages.
In 1995, Viacom and Chris-Craft Industries' United Television launched United Paramount Network (UPN) with "Star Trek: Voyager" as its flagship series, fulfilling Barry Diller's plan for a Paramount network from 25 years earlier. In 1999, Viacom bought out United Television's interests, and handed responsibility for the start-up network to the newly acquired CBS unit, which Viacom bought in 1999 – an ironic confluence of events as Paramount had once invested in CBS, and Viacom had once been the syndication arm of CBS as well. During this period the studio acquired some 30 TV stations to support the UPN network as well acquiring and merging in the assets of Republic Pictures, Spelling Television and Viacom Television, almost doubling the size of the studio's TV library. The TV division produced the dominant prime time show for the decade in "Frasier" as well as such long running hits as NCIS and "Becker" and the dominant prime time magazine show "Entertainment Tonight."
During this period, Paramount and its related subsidiaries and affiliates, operating under the name "Viacom Entertainment Group" also included the fourth largest group of theme parks in the United States and Canada which in addition to traditional rides and attractions launched numerous successful location-based entertainment units including a long running "Star Trek" attraction at the Las Vegas Hilton. Famous Music – the company's celebrated music publishing arm almost doubled in size and developed artists including Pink, Bush, Green Day as well as catalog favorites including Duke Ellington and Henry Mancini. The Paramount/Viacom licensing group under the leadership of Tom McGrath created the "Cheers" franchise bars and restaurants and a chain of restaurants borrowing from the studio's Academy Award winning film "Forrest Gump" – "The Bubba Gump Shrimp Company". Through the combined efforts of Famous Music and the studio over ten "Broadway" musicals were created including Irving Berlin's "White Christmas", "Footloose, Saturday Night Fever", Andrew Lloyd Weber's "Sunset Boulevard" among others. The Company's international arm, United International Pictures (UIP), was the dominant distributor internationally for ten straight years representing Paramount, Universal and MGM. Simon and Schuster became part of the Viacom Entertainment Group emerging as the US' dominant trade book publisher.
In 2002, Paramount, Buena Vista Distribution, 20th Century Fox, Sony Pictures, Universal Studios, and Warner Bros. formed the Digital Cinema Initiatives. Operating under a waiver form the anti-trust law, the studios combined under the leadership of Paramount Chief Operating Officer Tom McGrath to develop technical standards for the eventual introduction of digital film projection – replacing the now 100-year-old film technology. DCI was created "to establish and document voluntary specifications for an open architecture for digital cinema that ensures a uniform and high level of technical performance, reliability and quality control." McGrath also headed up Paramount's initiative for the creation and launch of the Blu-ray DVD.
2005: Dissolution of the Viacom Entertainment Group and Paramount.
In 2005, Viacom announced the spinoff of CBS into a separate public entity. As part of this spinoff, the Entertainment Group that was led by Dolgen, Lansing and McGrath, was dissolved and Paramount broken up into its separate assets. Famous Music, part of the company since its founding by Jesse Lasky, was sold to Sony Music. The UPN network and its TV stations were transferred to CBS. Paramount itself was broken into two parts and the television production and assets were stripped and made part of CBS. The theme parks group was sold to Cedar Fair in 2006 and renamed the parks by taking out the "Paramount's" prefix. Simon and Schuster also became part of CBS. The company's three chains of movie theaters were divested – Famous Players Theaters, the dominant theater circuit in Canada was sold to its competitor Cineplex Odeon. UCI which dominated the international theater markets consisting of 1,300+ screens in 11 countries was sold to buyout firm Terra Firma. Mann Theaters was slowly divested screen by screen with the world famous "Graumann's Chinese Theater" being sold to a consortium led by Eli Samaha.
The resulting company, approximately 20% of its former size coalesced in 2006 under the leadership of its new CEO, Brad Grey who held the same title as Sherry Lansing despite the much smaller size of the business under his leadership.
2005–present: Paramount today.
CBS Corporation/Viacom split.
Reflecting in part the troubles of the broadcasting business, in 2005 Viacom wrote off over $18 billion from its radio acquisitions and, early that year, announced that it would split itself in two. The split was completed in January 2006.
With the announcement of the split of Viacom, Dolgen and Lansing were replaced by former television executives Brad Grey and Gail Berman. The Viacom Inc. board split the company into CBS Corporation and a separate company under the Viacom name. The board scheduled the division for the first quarter of 2006. Under the plan, CBS Corp. would comprise CBS and UPN networks, Viacom Television Stations Group, Infinity Broadcasting, Viacom Outdoor, Paramount Television, KingWorld, Showtime, Simon and Schuster, Paramount Parks, and CBS News. The revamped Viacom would include "MTV, VH1, Nickelodeon, BET and several other cable networks as well as the Paramount movie studio". Paramount's home entertainment unit continues to distribute the Paramount TV library through CBS DVD, as both Viacom and CBS Corporation are controlled by Sumner Redstone's National Amusements.
In 2009, CBS stopped using the Paramount name in its series and changed the name of the production arm to CBS Television Studios, eliminating the Paramount name from television, to distance itself from the latter.
DreamWorks purchased.
On December 11, 2005, The Paramount Motion Pictures Group announced that it had purchased DreamWorks SKG (which was co-founded by former Paramount executive Jeffrey Katzenberg) in a deal worth $1.6 billion. The announcement was made by Brad Grey, chairman and CEO of Paramount Pictures who noted that enhancing Paramount's pipeline of pictures is a "key strategic objective in restoring Paramount's stature as a leader in filmed entertainment." The agreement does not include DreamWorks Animation SKG Inc., the most profitable part of the company that went public the previous year.
On October 6, 2008, DreamWorks executives announced that they were leaving Paramount and relaunching an independent DreamWorks. The DreamWorks trademarks remained with DreamWorks Animation when that company was spun off before the Paramount purchase, and DreamWorks Animation transferred the license to the name to the new company.
UIP, Famous Music and Digital Entertainment.
In 2007, Paramount sold another one of its "heritage" units, Famous Music, to Sony/ATV Music Publishing (best known for publishing many songs by The Beatles, and for being co-owned by Michael Jackson), ending a nearly-eight-decade run as a division of Paramount, being the studio's music publishing arm since the period when the entire company went by the name "Famous Players."
In early 2008, Paramount partnered with Los Angeles-based developer FanRocket to make short scenes taken from its film library available to users on Facebook. The application, called VooZoo, allows users to send movie clips to other Facebook users and to post clips on their profile pages. Paramount engineered a similar deal with Makena Technologies to allow users of vMTV and There.com to view and send movie clips.
In March 2010, Paramount founded Insurge Pictures, an independent distributor of "micro budget" films. The distributor planned ten movies with budgets of $100,000 each. The first release was "The Devil Inside", a movie with a budget of about US$1 million. In March 2015, following waning box office returns, Paramount shuttered Insurge Pictures and moved its operations to the main studio.
Other.
In July 2011, in the wake of critical and box office success of the animated feature, "Rango", and the departure of DreamWorks Animation upon completion of their distribution contract in 2012, Paramount announced the formation of a new division, devoted to the creation of animated productions. It marks Paramount's return to having its own animated division for the first time since 1967, when Paramount Cartoon Studios shut down (it was formerly Famous Studios until 1956).
In December 2013, The Walt Disney Studios (via its parent company's purchase of LucasFilm, Ltd. a year earlier) purchased Paramount's remaining distribution and marketing rights to future "Indiana Jones" films, while Paramount will continue to distribute the first four films for Disney, and will receive "financial participation" from any additional films.
In February 2016, Viacom CEO and newly appointed chairman Philippe Dauman announced that the conglomerate is in talks to find an investor to purchase a minority stake in Paramount. Viacom intends to retain controlling interest in the studio.
Investments.
DreamWorks.
In 2006, Paramount became the parent of DreamWorks SKG. Soros Strategic Partners and Dune Entertainment II soon afterwards acquired controlling interest in the live-action films released through September 16, 2005, the latest film in this package was "Just Like Heaven". The remaining live-action films through March 2006 remained under direct Paramount control.
However, Paramount does own distribution (and other ancillary) rights to the Soros/Dune films.
On February 8, 2010, Viacom repurchased Soros' controlling stake in the pre-2005 DreamWorks Pictures library for around $400 million.
Even as DreamWorks switches distribution of live-action films that are not part of existing franchises to Walt Disney Studios Motion Pictures, Paramount will continue to own the films released before the merger, and the films that Paramount themselves distributed (including sequel rights; such films as "Little Fockers" will be distributed by Paramount and DreamWorks, since it is a sequel to an existing DreamWorks film – in this case, "Meet the Parents" and "Meet the Fockers", though Paramount will only own international rights to this title, whereas Universal Studios will handle domestic distribution).
As for the DreamWorks Animation library, Paramount owned distribution rights to the pre-2013 library, and their previous distribution deal to future DWA titles expired at the end of 2012 with the last Paramount-distributed feature, "Rise of the Guardians". 20th Century Fox now handles distribution on future titles beginning with "The Croods", though Paramount's rights to distribute every film released by DreamWorks Animation before 2013 will expire 16 years after each film's initial theatrical release date. However, in July 2014, DreamWorks Animation purchased Paramount's distribution rights to the pre-2013 library with DreamWorks Animation's current distributor 20th Century Fox to distribute the library.
CBS library.
Independent company Hollywood Classics now represents Paramount in the theatrical distribution of all the films produced by the various motion picture divisions of CBS over the years, as a result of the Viacom/CBS merger.
Paramount (via CBS Home Entertainment) has outright video distribution to the aforementioned CBS library with few exceptions-for example, the original "Twilight Zone" DVDs are handled by Image Entertainment. Until 2009, the video rights to "My Fair Lady" were with original theatrical distributor Warner Bros., under license from CBS (the video license to that film has now reverted to CBS Home Entertainment under Paramount).
The CBS-produced/owned films, unlike other films in Paramount's library, are still distributed by CBS Television Distribution on TV, and not by Trifecta Entertainment & Media, because CBS (or a subdivision) is the copyright holder for these films.
Units.
Former divisions, subsidiaries, and joint ventures.
Original Paramount Television now CBS Television Studios
Other interests.
In March 2012, Paramount licensed their name and logo to a luxury hotel investment group which subsequently named the company Paramount Hotels and Resorts. The investors plan to build 50 hotels throughout the world based on the themes of Hollywood and the California lifestyle. Among the features are private screening rooms and the Paramount library available in the hotel rooms. On April 2013, Paramount Hotels and Dubai-based DAMAC Properties announced the building of the first resort: "DAMAC Towers by Paramount." 
Logo.
The distinctively pyramidal Paramount mountain has been the company's logo since its inception and is the oldest surviving Hollywood film logo. In the sound era, the logo was accompanied by a fanfare called "Paramount on Parade" after the film of the same name, released in 1930. The words to the fanfare, originally sung in the 1930 film, were "Proud of the crowd that will never be loud, it's Paramount on Parade."
Legend has it that the mountain is based on a doodle made by W. W. Hodkinson during a meeting with Adolph Zukor. It is said to be based on the memories of his childhood in Utah. Some claim that Utah's Ben Lomond is the mountain Hodkinson doodled, and that Peru's Artesonraju is the mountain in the live-action logo, while others claim that the Italian side of Monviso inspired the logo. Some editions of the logo bear a striking resemblance to the Pfeifferhorn, another Wasatch Range peak.
The motion picture logo has gone through many changes over the years:
Studio tours.
Those wishing to visit Paramount can take studio tours, which are offered seven days a week. Reservations are required, and can be made by visiting the tour website. The tour offers a behind-the-scenes look at the current operations of the studio, and what can be seen varies day to day. Most of the buildings on the tour are named for historical Paramount executives or the artists that worked at Paramount over the years. Many of the stars' dressing rooms have been converted into working offices. The stages where "Samson and Delilah, Sunset Blvd.", "White Christmas", "Rear Window", "Sabrina", "Breakfast at Tiffany's", and many other classic films were shot are still in use today. The studio's backlot set, "New York Street", features numerous blocks of façades that depict a number of New York locales: "Washington Square", (where some scenes in "The Heiress", starring Olivia de Havilland, were shot) "Brooklyn", "Financial District", and others. Led by a guide on a golf cart, the tour takes approximately two hours.
Film library.
A few years after the ruling of the United States v. Paramount Pictures, Inc. case in 1948, Music Corporation of America (MCA) approached Paramount offering $50 million for 750 sound feature films released prior to December 1, 1949 with payment to be spread over a period of several years. Paramount saw this as a bargain since the fleeting movie studio saw very little value in its library at the time. To address any anti-trust concerns, MCA set up EMKA, Ltd. as a dummy corporation to sell these films to television. EMKA's/Universal Pictures library includes the five Paramount Marx Brothers films, most of the Bob Hope-Bing Crosby "Road to..." pictures, and other classics such as "Trouble in Paradise", "Shanghai Express", "She Done Him Wrong", "Sullivan's Travels", "The Palm Beach Story", "For Whom The Bell Tolls", "Double Imdemnity", "The Lost Weekend" and "The Heiress".

</doc>
<doc id="22921" url="https://en.wikipedia.org/wiki?curid=22921" title="Psychology">
Psychology

Psychology is the study of behavior and mind, embracing all aspects of conscious and unconscious experience as well as thought. It is an academic discipline and an applied science which seeks to understand individuals and groups by establishing general principles and researching specific cases. In this field, a professional or researcher is called a psychologist and can be classified as a social, behavioral, or cognitive scientist. Psychologists attempt to understand the role of mental functions in individual and social behavior, while also exploring the physiological and biological processes that underlie cognitive functions and behaviors.
Psychologists explore concepts such as perception, cognition, attention, emotion, intelligence, phenomenology, motivation, brain functioning, personality, behavior, and interpersonal relationships, including psychological resilience, family resilience, and other areas. Psychologists of diverse orientations also consider the unconscious mind. Psychologists employ empirical methods to infer causal and correlational relationships between psychosocial variables. In addition, or in opposition, to employing empirical and deductive methods, some—especially clinical and counseling psychologists—at times rely upon symbolic interpretation and other inductive techniques. Psychology has been described as a "hub science", with psychological findings linking to research and perspectives from the social sciences, natural sciences, medicine, humanities, and philosophy.
While psychological knowledge is often applied to the assessment and treatment of mental health problems, it is also directed towards understanding and solving problems in several spheres of human activity. By many accounts psychology ultimately aims to benefit society. The majority of psychologists are involved in some kind of therapeutic role, practicing in clinical, counseling, or school settings. Many do scientific research on a wide range of topics related to mental processes and behavior, and typically work in university psychology departments or teach in other academic settings (e.g., medical schools, hospitals). Some are employed in industrial and organizational settings, or in other areas such as human development and aging, sports, health, and the media, as well as in forensic investigation and other aspects of law.
Etymology and definitions.
The word "psychology" derives from Greek roots meaning study of the psyche, or soul (ψυχή "psukhē", "breath, spirit, soul" and -λογία "-logia", "study of" or "research"). The Latin word "psychologia" was first used by the Croatian humanist and Latinist Marko Marulić in his book, "Psichiologia de ratione animae humanae" in the late 15th century or early 16th century. The earliest known reference to the word "psychology" in English was by Steven Blankaart in 1694 in "The Physical Dictionary" which refers to "Anatomy, which treats the Body, and Psychology, which treats of the Soul."
In 1890, William James defined "psychology" as "the science of mental life, both of its phenomena and their conditions". This definition enjoyed widespread currency for decades. However, this meaning was contested, notably by radical behaviorists such as John Watson, who in his 1913 manifesto defined the discipline of psychology as the acquisition of information useful to the control of behavior. Also since James defined it, the term more strongly connotes techniques of scientific experimentation. Folk psychology refers to the understanding of ordinary people, as contrasted with that of psychology professionals.
History.
The ancient civilizations of Egypt, Greece, China, India, and Persia all engaged in the philosophical study of psychology. Historians note that Greek philosophers, including Thales, Plato, and Aristotle (especially in his "De Anima" treatise), addressed the workings of the mind. As early as the 4th century BC, Greek physician Hippocrates theorized that mental disorders had physical rather than supernatural causes.
In China, psychological understanding grew from the philosophical works of Laozi and Confucius, and later from the doctrines of Buddhism. This body of knowledge involves insights drawn from introspection and observation, as well as techniques for focused thinking and acting. It frames the universe as a division of, and interaction between, physical reality and mental reality, with an emphasis on purifying the mind in order to increase virtue and power. An ancient text known as "The Yellow Emperor's Classic of Internal Medicine" identifies the brain as the nexus of wisdom and sensation, includes theories of personality based on yin–yang balance, and analyzes mental disorder in terms of physiological and social disequilibria. Chinese scholarship focused on the brain advanced in the Qing Dynasty with the work of Western-educated Fang Yizhi (1611–1671), Liu Zhi (1660–1730), and Wang Qingren (1768–1831). Wang Qingren emphasized the importance of the brain as the center of the nervous system, linked mental disorder with brain diseases, investigated the causes of dreams and insomnia, and advanced a theory of hemispheric lateralization in brain function.
Distinctions in types of awareness appear in the ancient thought of India, influenced by Hinduism. A central idea of the Upanishads is the distinction between a person's transient mundane self and their eternal unchanging soul. Divergent Hindu doctrines, and Buddhism, have challenged this hierarchy of selves, but have all emphasized the importance of reaching higher awareness. Yoga is a range of techniques used in pursuit of this goal. Much of the Sanskrit corpus was suppressed under the British East India Company followed by the British Raj in the 1800s. However, Indian doctrines influenced Western thinking via the Theosophical Society, a New Age group which became popular among Euro-American intellectuals.
Psychology was a popular topic in Enlightenment Europe. In Germany, Gottfried Wilhelm Leibniz (1646–1716) applied his principles of calculus to the mind, arguing that mental activity took place on an indivisible continuum—most notably, that among an infinity of human perceptions and desires, the difference between conscious and unconscious awareness is only a matter of degree. Christian Wolff identified psychology as its own science, writing "Psychologia empirica" in 1732 and "Psychologia rationalis" in 1734. This notion advanced further under Immanuel Kant, who established the idea of anthropology, with psychology as an important subdivision. However, Kant explicitly and notoriously rejected the idea of experimental psychology, writing that "the empirical doctrine of the soul can also never approach chemistry even as a systematic art of analysis or experimental doctrine, for in the manifold of inner observation can be separated only by mere division in thought, and cannot then be held separate and recombined at will (but still less does another thinking subject suffer himself to be experimented upon to suit our purpose), and even observation by itself already changes and displaces the state of the observed object." Having consulted philosophers Hegel and Herbart, in 1825 the Prussian state established psychology as a mandatory discipline in its rapidly expanding and highly influential educational system. However, this discipline did not yet embrace experimentation. In England, early psychology involved phrenology and the response to social problems including alcoholism, violence, and the country's well-populated mental asylums.
Beginning of experimental psychology.
Gustav Fechner began conducting psychophysics research in Leipzig in the 1830s, articulating the principle that human perception of a stimulus varies logarithmically according to its intensity. Fechner's 1860 "Elements of Psychophysics" challenged Kant's stricture against quantitative study of the mind. In Heidelberg, Hermann von Helmholtz conducted parallel research on sensory perception, and trained physiologist Wilhelm Wundt. Wundt, in turn, came to Leipzig University, establishing the psychological laboratory which brought experimental psychology to the world. Wundt focused on breaking down mental processes into the most basic components, motivated in part by an analogy to recent advances in chemistry, and its successful investigation of the elements and structure of material. Paul Flechsig and Emil Kraepelin soon created another influential psychology laboratory at Leipzig, this one focused on more on experimental psychiatry.
Psychologists in Germany, Denmark, Austria, England, and the United States soon followed Wundt in setting up laboratories. G. Stanley Hall who studied with Wundt, formed a psychology lab at Johns Hopkins University in Maryland, which became internationally influential. Hall, in turn, trained Yujiro Motora, who brought experimental psychology, emphasizing psychophysics, to the Imperial University of Tokyo. Wundt assistant Hugo Münsterberg taught psychology at Harvard to students such as Narendra Nath Sen Gupta—who, in 1905, founded a psychology department and laboratory at the University of Calcutta. Wundt students Walter Dill Scott, Lightner Witmer, and James McKeen Cattell worked on developing tests for mental ability. Catell, who also studied with eugenicist Francis Galton, went on to found the Psychological Corporation. Wittmer focused on mental testing of children; Scott, on selection of employees.
Another student of Wundt, Edward Titchener, created the psychology program at Cornell University and advanced a doctrine of "structuralist" psychology. Structuralism sought to analyze and classify different aspects of the mind, primarily through the method of introspection. William James, John Dewey and Harvey Carr advanced a more expansive doctrine called functionalism, attuned more to human–environment actions. In 1890 James wrote an influential book, "The Principles of Psychology", which expanded on the realm of structuralism, memorably described the human "stream of consciousness", and interested many American students in the emerging discipline. Dewey integrated psychology with social issues, most notably by promoting the cause progressive education to assimilate immigrants and inculcate moral values in children.
A different strain of experimentalism, with more connection to physiology, emerged in South America, under the leadership of Horacio G. Piñero at the University of Buenos Aires. Russia, too, placed greater emphasis on the biological basis for psychology, beginning with Ivan Sechenov's 1873 essay, "Who Is to Develop Psychology and How?" Sechenov advanced the idea of brain reflexes and aggressively promoted a deterministic viewpoint on human behavior.
Wolfgang Kohler, Max Wertheimer and Kurt Koffka co-founded the school of Gestalt psychology (not to be confused with the Gestalt therapy of Fritz Perls). This approach is based upon the idea that individuals experience things as unified wholes. Rather than breaking down thoughts and behavior into smaller elements, as in structuralism, the Gestaltists maintained that whole of experience is important, and differs from the sum of its parts. Other 19th-century contributors to the field include the German psychologist Hermann Ebbinghaus, a pioneer in the experimental study of memory, who developed quantitative models of learning and forgetting at the University of Berlin, and the Russian-Soviet physiologist Ivan Pavlov, who discovered in dogs a learning process that was later termed "classical conditioning" and applied to human beings.
Consolidation and funding.
One of the earliest psychology societies was "La Société de Psychologie Physiologique" in France, which lasted 1885–1893. The first meeting of the International Congress of Psychology took place in Paris, in August 1889, amidst the World's Fair celebrating the centennial of the French Revolution. William James was one of three Americans among the four hundred attendees. The American Psychological Association was founded soon after, in 1892. The International Congress continued to be held, at different locations in Europe, with wider international participation. The Sixth Congress, Geneva 1909, included presentations in Russian, Chinese, and Japanese, as well as Esperanto. After a hiatus for World War I, the Seventh Congress met in Oxford, with substantially greater participation from the war-victorious Anglo-Americans. In 1929, the Congress took place at Yale University in New Haven, Connecticut, attended by hundreds of members of the American Psychological Association Tokyo Imperial University led the way in bringing the new psychology to the East, and from Japan these ideas diffused into China.
American psychology gained status during World War I, during which a standing committee headed by Robert Yerkes administered mental tests ("Army Alpha" and "Army Beta") to almost 1.8 million GIs. Subsequent funding for behavioral research came in large part from the Rockefeller family, via the Social Science Research Council. Rockefeller charities funded the National Committee on Mental Hygiene, which promoted the concept of mental illness and lobbied for psychological supervision of child development. Through the Bureau of Social Hygiene and later funding of Alfred Kinsey, Rockefeller foundations established sex research as a viable discipline in the U.S. Under the influence of the Carnegie-funded Eugenics Record Office, the Draper-funded Pioneer Fund, and other institutions, the eugenics movement also had a significant impact on American psychology; in the 1910s and 1920s, eugenics became a standard topic in psychology classes.
During World War II and the Cold War, the U.S. military and intelligence agencies established themselves as leading funders of psychology—through the armed forces and in the new Office of Strategic Services intelligence agency. University of Michigan psychologist Dorwin Cartwright reported that university researchers began large-scale propaganda research in 1939–1941, and "the last few months of the war saw a social psychologist become chiefly responsible for determining the week-by-week-propaganda policy for the United States Government." Cartwright also wrote that psychologists had significant roles in managing the domestic economy. The Army rolled out its new General Classification Test and engaged in massive studies of troop morale. In the 1950s, the Rockefeller Foundation and Ford Foundation collaborated with the Central Intelligence Agency to fund research on psychological warfare. In 1965, public controversy called attention to the Army's Project Camelot—the "Manhattan Project" of social science—an effort which enlisted psychologists and anthropologists to analyze foreign countries for strategic purposes.
In Germany after World War I, psychology held institutional power through the military, and subsequently expanded along with the rest of the military under the Third Reich. Under the direction of Hermann Göring's cousin Matthias Göring, the Berlin Psychoanalytic Institute was renamed the Göring Institute. Freudian psychoanalysts were expelled and persecuted under the anti-Jewish policies of the Nazi Party, and all psychologists had to distance themselves from Freud and Adler. The Göring Institute was well-financed throughout the war with a mandate to create a "New German Psychotherapy". This psychotherapy aimed to align suitable Germans with the overall goals of the Reich; as described by one physician: "Despite the importance of analysis, spiritual guidance and the active cooperation of the patient represent the best way to overcome individual mental problems and to subordinate them to the requirements of the "Volk" and the "Gemeinschaft"." Psychologists were to provide "Seelenführung", leadership of the mind, to integrate people into the new vision of a German community. Harald Schultz-Hencke melded psychology with the Nazi theory of biology and racial origins, criticizing psychoanalysis as a study of the weak and deformed. Johannes Heinrich Schultz, a German psychologist recognized for developing the technique of autogenic training, prominently advocated sterilization and euthanasia of men considered genetically undesirable, and devised techniques for facilitating this process. After the war, some new institutions were created and some psychologists were discredited due to Nazi affiliation. Alexander Mitscherlich founded a prominent applied psychoanalysis journal called "Psyche" and with funding from the Rockefeller Foundation established the first clinical psychosomatic medicine division at Heidelberg University. In 1970, psychology was integrated into the required studies of medical students.
After the Russian Revolution, psychology was heavily promoted by the Bolsheviks as a way to engineer the "New Man" of socialism. Thus, university psychology departments trained large numbers of students, for whom positions were made available at schools, workplaces, cultural institutions, and in the military. An especial focus was pedology, the study of child development, regarding which Lev Vygotsky became a prominent writer. The Bolsheviks also promoted free love and embranced the doctrine of psychoanalysis as an antidote to sexual repression. Although pedology and intelligence testing fell out of favor in 1936, psychology maintained its privileged position as an instrument of the Soviet state. Stalinist purges took a heavy toll and instilled a climate of fear in the profession, as elsewhere in Soviet society. Following World War II, Jewish psychologists past and present (including Vygotsky, A. R. Luria, and Aron Zalkind) were denounced; Ivan Pavlov (posthumously) and Stalin himself were aggrandized as heroes of Soviet psychology. Soviet academics was speedily liberalized during the Khrushchev Thaw, and cybernetics, linguistics, genetics, and other topics became acceptable again. There emerged a new field called "engineering psychology" which studied mental aspects of complex jobs (such as pilot and cosmonaut). Interdisciplinary studies became popular and scholars such as Georgy Shchedrovitsky developed systems theory approaches to human behavior.
Twentieth-century Chinese psychology originally modeled the United States, with translations from American authors like William James, the establishment of university psychology departments and journals, and the establishment of groups including the Chinese Association of Psychological Testing (1930) and the Chinese Psychological Society (1937). Chinese psychologists were encouraged to focus on education and language learning, with the aspiration that education would enable modernization and nationalization. John Dewey, who lectured to Chinese audiences in 1918–1920, had a significant influence on this doctrine. Chancellor T'sai Yuan-p'ei introduced him at Peking University as a greater thinker than Confucius. Kuo Zing-yang who received a PhD at the University of California, Berkeley, became President of Zhejiang University and popularized behaviorism. After the Chinese Communist Party gained control of the country, the Stalinist USSR became the leading influence, with Marxism–Leninism the leading social doctrine and Pavlovian conditioning the approved concept of behavior change. Chinese psychologists elaborated on Lenin's model of a "reflective" consciousness, envisioning an "active consciousness" ("tzu-chueh neng-tung-li") able to transcend material conditions through hard work and ideological struggle. They developed a concept of "recognition" ("jen-shih") which referred the interface between individual perceptions and the socially accepted worldview. (Failure to correspond with party doctrine was "incorrect recognition".) Psychology education was centralized under the Chinese Academy of Sciences, supervised by the State Council. In 1951 the Academy created a Psychology Research Office, which in 1956 became the Institute of Psychology. Most leading psychologists were educated in the United States, and the first concern of the Academy was re-education of these psychologists in the Soviet doctrines. Child psychology and pedagogy for nationally cohesive education remained a central goal of the discipline.
Disciplinary organization.
Institutions.
In 1920, Édouard Claparède and Pierre Bovet created a new applied psychology organization called the International Congress of Psychotechnics Applied to Vocational Guidance, later called the International Congress of Psychotechnics and then the International Association of Applied Psychology. The IAAP is considered the oldest international psychology association. Today, at least 65 international groups deal specialized aspects of psychology. In response to male predominance in the field, female psychologists in the U.S. formed National Council of Women Psychologists in 1941. This organization became the International Council of Women Psychologists after World War II, and the International Council of Psychologists in 1959. Several associations including the Association of Black Psychologists and the Asian American Psychological Association have arisen to promote non-European racial groups in the profession.
The world federation of national psychological societies is the International Union of Psychological Science (IUPsyS), founded in 1951 under the auspices of UNESCO, the United Nations cultural and scientific authority. Psychology departments have since proliferated around the world, based primarily on the Euro-American model. Since 1966, the Union has published the "International Journal of Psychology". IAAP and IUPsyS agreed in 1976 each to hold a congress every four years, on a staggered basis.
The International Union recognizes 66 national psychology associations and at least 15 others exist. The American Psychological Association is the oldest and largest. Its membership has increased from 5,000 in 1945 to 100,000 in the present day. The APA includes 54 divisions, which since 1960 have steadily proliferated to include more specialties. Some of these divisions, such as the Society for the Psychological Study of Social Issues and the American Psychology–Law Society, began as autonomous groups.
The Interamerican Society of Psychology, founded in 1951, aspires to promote psychology and coordinate psychologists across the Western Hemisphere. It holds the Interamerican Congress of Psychology and had 1000 members in year 2000. The European Federation of Professional Psychology Associations, founded in 1981, represents 30 national associations with a total of 100,000 individual members. At least 30 other international groups organize psychologists in different regions.
In some places, governments legally regulate who can provide psychological services or represent themselves as a "psychologist". The American Psychological Association defines a psychologist as someone with a doctoral degree in psychology.
Boundaries.
Early practitioners of experimental psychology distinguished themselves from parapsychology, which in the late nineteenth century enjoyed great popularity (including the interest of scholars such as William James), and indeed constituted the bulk of what people called "psychology". Parapsychology, hypnotism, and psychism were major topics of the early International Congresses. But students of these fields were eventually ostractized, and more or less banished from the Congress in 1900–1905. Parapsychology persisted for a time at Imperial University, with publications such as "Clairvoyance and Thoughtography" by Tomokichi Fukurai, but here too it was mostly shunned by 1913.
As a discipline, psychology has long sought to fend off accusations that it is a "soft" science. Philosopher of science Thomas Kuhn's 1962 critique implied psychology overall was in a pre-paradigm state, lacking the agreement on overarching theory found in mature sciences such as chemistry and physics. Because some areas of psychology rely on research methods such as surveys and questionnaires, critics asserted that psychology is not an objective science. Skeptics have suggested that personality, thinking, and emotion, cannot be directly measured and are often inferred from subjective self-reports, which may be problematic. Experimental psychologists have devised a variety of ways to indirectly measure these elusive phenomenological entities.
Divisions still exist within the field, with some psychologists more oriented towards the unique experiences of individual humans, which cannot be understood only as data points within a larger population. Critics inside and outside the field have argued that mainstream psychology has become increasingly dominated by a "cult of empiricism" which limits the scope of its study by using only methods derived from the physical sciences. Feminist critiques along these lines have argued that claims to scientific objectivity obscure the values and agenda of (historically mostly male) researchers. Jean Grimshaw, for example, argues that mainstream psychological research has advanced a patriarchal agenda through its efforts to control behavior.
Major schools of thought.
Biological.
Psychologists generally consider the organism the basis of the mind, and therefore a vitally related area of study. Psychiatrists and neuropsychologists work at the interface of mind and body. 
Biological psychology, also known as physiological psychology, or neuropsychology is the study of the biological substrates of behavior and mental processes. Key research topics in this field include comparative psychology, which studies humans in relation to other animals, and perception which involves the physical mechanics of sensation as well as neural and mental processing. For centuries, a leading question in biological psychology has been whether and how mental functions might be localized in the brain. From Phineas Gage to H. M. and Clive Wearing, individual people with mental issues traceable to physical damage have inspired new discoveries in this area. Modern neuropsychology could be said to originate in the 1870s, when in France Paul Broca traced production of speech to the left frontal gyrus, thereby also demonstrating hemispheric lateralization of brain function. Soon after, Carl Wernicke identified a related area necessary for the understanding of speech.
The contemporary field of behavioral neuroscience focuses on physical causes underpinning behavior. For example, physiological psychologists use animal models, typically rats, to study the neural, genetic, and cellular mechanisms that underlie specific behaviors such as learning and memory and fear responses. Cognitive neuroscientists investigate the neural correlates of psychological processes in humans using neural imaging tools, and neuropsychologists conduct psychological assessments to determine, for instance, specific aspects and extent of cognitive deficit caused by brain damage or disease. The biopsychosocial model is an integrated perspective toward understanding consciousness, behavior, and social interaction. It assumes that any given behavior or mental process affects and is affected by dynamically interrelated biological, psychological, and social factors.
Evolutionary psychology examines cognition and personality traits from an evolutionary perspective. This perspective suggests that psychological adaptations evolved to solve recurrent problems in human ancestral environments. Evolutionary psychology offers complementary explanations for the mostly proximate or developmental explanations developed by other areas of psychology: that is, it focuses mostly on ultimate or "why?" questions, rather than proximate or "how?" questions. "How?" questions are more directly tackled by behavioral genetics research, which aims to understand how genes and environment impact behavior.
The search for biological origins of psychological phenomena has long involved debates about the importance of race, and especially the relationship between race and intelligence. The idea of white supremacy and indeed the modern concept of race itself arose during the process of world conquest by Europeans. Carl von Linnaeus's four-fold classification of humans classifies Europeans as intelligent and severe, Americans as contented and free, Asians as ritualistic, and Africans as lazy and capricious. Race was also used to justify the construction of socially specific mental disorders such as "drapetomania" and "dysaesthesia aethiopica"—the behavior of uncooperative African slaves. After the creation of experimental psychology, "ethnical psychology" emerged as a subdiscipline, based on the assumption that studying primitive races would provide an important link between animal behavior and the psychology of more evolved humans.
Behavioral.
Psychologists take human behavior as a main area of study. Much of the research in this area began with tests on mammals, based on the idea that humans exhibit similar fundamental tendencies. Behavioral research ever aspires to improve the effectiveness of techniques for behavior modification.
Early behavioral researchers studied stimulus–response pairings, now known as classical conditioning. They demonstrated that behaviors could be linked through repeated association with stimuli eliciting pain or pleasure. Ivan Pavlov—known best for inducing dogs to salivate in the presence of a stimulus previous linked with food—became a leading figure in the Soviet Union and inspired followers to use his methods on humans. In the United States, Edward Lee Thorndike initiated "connectionism" studies by trapping animals in "puzzle boxes" and rewarding them for escaping. Thorndike wrote in 1911: "There can be no moral warrant for studying man's nature unless the study will enable us to control his acts." From 1910–1913 the American Psychological Association went through a sea change of opinion, away from mentalism and towards "behavioralism", and in 1913 John B. Watson coined the term behaviorism for this school of thought. Watson's famous Little Albert experiment in 1920 demonstrated that repeated use of upsetting loud noises could instill phobias (aversions to other stimuli) in an infant human. Karl Lashley, a close collaborator with Watson, examined biological manifestations of learning in the brain.
Embraced and extended by Clark L. Hull, Edwin Guthrie, and others, behaviorism became a widely used research paradigm. A new method of "instrumental" or "operant" conditioning added the concepts of reinforcement and punishment to the model of behavior change. Radical behaviorists avoided discussing the inner workings of the mind, especially the unconscious mind, which they considered impossible to assess scientifically. Operant conditioning was first described by Miller and Kanorski and popularized in the U.S. by B. F. Skinner, who emerged as a leading intellectual of the behaviorist movement.
Noam Chomsky delivered an influential critique of radical behaviorism on the grounds that it could not adequately explain the complex mental process of language acquisition. Martin Seligman and colleagues discovered that the conditioning of dogs led to outcomes ("learned helplessness") that opposed the predictions of behaviorism. Skinner's behaviorism did not die, perhaps in part because it generated successful practical applications. Edward C. Tolman advanced a hybrid "cognitive behaviorial" model, most notably with his 1948 publication discussing the cognitive maps used by rats to guess at the location of food at the end of a modified maze.
The Association for Behavior Analysis International was founded in 1974 and by 2003 had members from 42 countries. The field has been especially influential in Latin America, where it has a regional organization known as ALAMOC: "La Asociación Latinoamericana de Análisis y Modificación del Comportamiento". Behaviorism also gained a strong foothold in Japan, where it gave rise to the Japanese Society of Animal Psychology (1933), the Japanese Association of Special Education (1963), the Japanese Society of Biofeedback Research (1973), the Japanese Association for Behavior Therapy (1976), the Japanese Association for Behavior Analysis (1979), and the Japanese Association for Behavioral Science Research (1994). Today the field of behaviorism is also commonly referred to as behavior modification or behavior analysis.
Cognitive.
Green Red BluePurple Blue Purple
Blue Purple RedGreen Purple Green
The Stroop effect refers to the fact that naming the color of the first set of words is easier and quicker than the second.
Cognitive psychology studies cognition, the mental processes underlying mental activity. Perception, attention, reasoning, thinking, problem solving, memory, learning, language, and emotion are areas of research. Classical cognitive psychology is associated with a school of thought known as cognitivism, whose adherents argue for an information processing model of mental function, informed by functionalism and experimental psychology.
On a broader level, cognitive science is an interdisciplinary enterprise of cognitive psychologists, cognitive neuroscientists, researchers in artificial intelligence, linguists, human–computer interaction, computational neuroscience, logicians and social scientists. Computer simulations are sometimes used to model phenomena of interest.
Starting in the 1950s, the experimental techniques developed by Wundt, James, Ebbinghaus, and others re-emerged as experimental psychology became increasingly cognitivist—concerned with information and its processing—and, eventually, constituted a part of the wider cognitive science. Some called this development the cognitive revolution because it rejected the anti-mentalist dogma of behaviorism as well as the strictures of psychoanalysis.
Social learning theorists, such as Albert Bandura, argued that the child's environment could make contributions of its own to the behaviors of an observant subject.
Technological advances also renewed interest in mental states and representations. English neuroscientist Charles Sherrington and Canadian psychologist Donald O. Hebb used experimental methods to link psychological phenomena with the structure and function of the brain. The rise of computer science, cybernetics and artificial intelligence suggested the value of comparatively studying information processing in humans and machines. Research in cognition had proven practical since World War II, when it aided in the understanding of weapons operation.
A popular and representative topic in this area is cognitive bias, or irrational thought. Psychologists (and economists) have classified and described a sizeable catalogue of biases which recur frequently in human thought. The availability heuristic, for example, is the tendency to overestimate the importance of something which happens to come readily to mind.
Elements of behaviorism and cognitive psychology were synthesized to form cognitive behavioral therapy, a form of psychotherapy modified from techniques developed by American psychologist Albert Ellis and American psychiatrist Aaron T. Beck. Cognitive psychology was subsumed along with other disciplines, such as philosophy of mind, computer science, and neuroscience, under the cover discipline of cognitive science.
Social.
Social psychology is the study of how humans think about each other and how they relate to each other. Social psychologists study such topics as the influence of others on an individual's behavior (e.g. conformity, persuasion), and the formation of beliefs, attitudes, and stereotypes about other people. Social cognition fuses elements of social and cognitive psychology in order to understand how people process, remember, or distort social information. The study of group dynamics reveals information about the nature and potential optimization of leadership, communication, and other phenomena that emerge at least at the microsocial level. In recent years, many social psychologists have become increasingly interested in implicit measures, mediational models, and the interaction of both person and social variables in accounting for behavior. The study of human society is therefore a potentially valuable source of information about the causes of psychiatric disorder. Some sociological concepts applied to psychiatric disorders are the social role, sick role, social class, life event, culture, migration, social, and total institution.
Psychoanalysis.
Psychoanalysis comprises a method of investigating the mind and interpreting experience; a systematized set of theories about human behavior; and a form of psychotherapy to treat psychological or emotional distress, especially conflict originating in the unconscious mind. This school of thought originated in the 1890s with Austrian medical doctors including Josef Breuer (physician), Alfred Adler (physician), Otto Rank (psychoanalyst), and most prominently Sigmund Freud (neurologist). Freud's psychoanalytic theory was largely based on interpretive methods, introspection and clinical observations. It became very well known, largely because it tackled subjects such as sexuality, repression, and the unconscious. These subjects were largely taboo at the time, and Freud provided a catalyst for their open discussion in polite society. Clinically, Freud helped to pioneer the method of free association and a therapeutic interest in dream interpretation.
Swiss psychiatrist Carl Jung, influenced by Freud, elaborated a theory of the collective unconscious—a primordial force present in all humans, featuring archetypes which exerted a profound influence on the mind. Jung's competing vision formed the basis for analytical psychology, which later led to the archetypal and process-oriented schools. Other well-known psychoanalytic scholars of the mid-20th century include Erik Erikson, Melanie Klein, D. W. Winnicott, Karen Horney, Erich Fromm, John Bowlby, and Sigmund Freud's daughter, Anna Freud. Throughout the 20th century, psychoanalysis evolved into diverse schools of thought which could be called Neo-Freudian. Among these schools are ego psychology, object relations, and interpersonal, Lacanian, and relational psychoanalysis.
Psychologists such as Hans Eysenck and philosophers including Karl Popper criticized psychoanalysis. Popper argued that psychoanalysis had been misrepresented as a scientific discipline, whereas Eysenck said that psychoanalytic tenets had been contradicted by experimental data. By the end of 20th century, psychology departments in American universities mostly marginalized Freudian theory, dismissing it as a "desiccated and dead" historical artifact. However, researchers in the emerging field of neuro-psychoanalysis today defend some of Freud's ideas on scientific grounds, while scholars of the humanities maintain that Freud was not a "scientist at all, but ... an interpreter".
Existential-humanistic theories.
Humanistic psychology developed in the 1950s as a movement within academic psychology, in reaction to both behaviorism and psychoanalysis. The humanistic approach sought to glimpse the whole person, not just fragmented parts of the personality or isolated cognitions. Humanism focused on uniquely human issues, such as free will, personal growth, self-actualization, self-identity, death, aloneness, freedom, and meaning. It emphasized subjective meaning, rejection of determinism, and concern for positive growth rather than pathology. Some founders of the humanistic school of thought were American psychologists Abraham Maslow, who formulated a hierarchy of human needs, and Carl Rogers, who created and developed client-centered therapy. Later, positive psychology opened up humanistic themes to scientific modes of exploration.
The "American Association for Humanistic Psychology", formed in 1963, declared:
Humanistic psychology is primarily an orientation toward the whole of psychology rather than a distinct area or school. It stands for respect for the worth of persons, respect for differences of approach, open-mindedness as to acceptable methods, and interest in exploration of new aspects of human behavior. As a "third force" in contemporary psychology, it is concerned with topics having little place in existing theories and systems: e.g., love, creativity, self, growth, organism, basic need-gratification, self-actualization, higher values, being, becoming, spontaneity, play, humor, affection, naturalness, warmth, ego-transcendence, objectivity, autonomy, responsibility, meaning, fair-play, transcendental experience, peak experience, courage, and related concepts.
In the 1950s and 1960s, influenced by philosophers Søren Kierkegaard and Martin Heidegger and, psychoanalytically trained American psychologist Rollo May pioneered an existential branch of psychology, which included existential psychotherapy: a method based on the belief that inner conflict within a person is due to that individual's confrontation with the givens of existence. Swiss psychoanalyst Ludwig Binswanger and American psychologist George Kelly may also be said to belong to the existential school. Existential psychologists differed from more "humanistic" psychologists in their relatively neutral view of human nature and their relatively positive assessment of anxiety. Existential psychologists emphasized the humanistic themes of death, free will, and meaning, suggesting that meaning can be shaped by myths, or narrative patterns, and that it can be encouraged by an acceptance of the free will requisite to an authentic, albeit often anxious, regard for death and other future prospects.
Austrian existential psychiatrist and Holocaust survivor Viktor Frankl drew evidence of meaning's therapeutic power from reflections garnered from his own internment. He created a variation of existential psychotherapy called logotherapy, a type of existentialist analysis that focuses on a "will to meaning" (in one's life), as opposed to Adler's Nietzschean doctrine of "will to power" or Freud's "will to pleasure".
Themes.
Personality.
Personality psychology is concerned with enduring patterns of behavior, thought, and emotion—commonly referred to as personality—in individuals. Theories of personality vary across different psychological schools and orientations. They carry different assumptions about such issues as the role of the unconscious and the importance of childhood experience. According to Freud, personality is based on the dynamic interactions of the id, ego, and super-ego. Trait theorists, in contrast, attempt to analyze personality in terms of a discrete number of key traits by the statistical method of factor analysis. The number of proposed traits has varied widely. An early model, proposed by Hans Eysenck, suggested that there are three traits which comprise human personality: extraversion–introversion, neuroticism, and psychoticism. Raymond Cattell proposed a theory of 16 personality factors. Dimensional models of personality are receiving increasing support, and some version of dimensional assessment will be included in the forthcoming DSM-V.
Myriad approach to systematically assess different personality types, with the Woodworth Personal Data Sheet, developed during World War I, an early example of the modern technique. The Myers–Briggs Type Indicator sought to assess people according to the personality theories of Carl Jung. Behaviorist resistance to introspection led to the development of the Strong Vocational Interest Blank and Minnesota Multiphasic Personality Inventory, tests which ask more empirical questions and focus less on the psychodynamics of the respondent.
Unconscious mind.
Study of the unconscious mind, a part of the psyche outside the awareness of the individual which nevertheless influenced thoughts and behavior was a hallmark of early psychology. In one of the first psychology experiments conducted in the USA, C. S. Peirce and Joseph Jastrow found in 1884 that subjects could choose the minutely heavier of two weights even if consciously uncertain of the difference. Freud popularized this concept, with terms like Freudian slip entering popular culture, to mean an uncensored intrusion of unconscious thought into one's speech and action. His 1901 text "The Psychopathology of Everyday Life" catalogues hundreds of everyday events which Freud explains in terms of unconscious influence. Pierre Janet advanced the idea of a subconscious mind, which could contain autonomous mental elements unavailable to the scrutiny of the subject.
Behaviorism notwithstanding, the unconscious mind has maintained its importance in psychology. Cognitive psychologists have used a "filter" model of attention, according to which much information processing takes place below the threshold of consciousness, and only certain processes, limited by nature and by simultaneous quantity, make their way through the filter. Copious research has shown that subconscious "priming" of certain ideas can covertly influence thoughts and behavior. A significant hurdle in this research is proving that a subject's conscious mind has not grasped a certain stimulus, due to the unreliability of self-reporting. For this reason, some psychologists prefer to distinguish between "implicit" and "explicit" memory. In another approach, one can also describe a subliminal stimulus as meeting an "objective" but not a "subjective" threshold.
The automaticity model, which became widespread following exposition by John Bargh and others in the 1980s, describes sophisticated processes for executing goals which can be selected and performed over an extended duration without conscious awareness. Some experimental data suggests that the brain begins to consider taking actions before the mind becomes aware of them. This influence of unconscious forces on people's choices naturally bears on philosophical questions free will. John Bargh, Daniel Wegner, and Ellen Langer are some prominent contemporary psychologists who describe free will as an illusion.
Motivation.
Psychologists such as William James initially used the term "motivation" to refer to intention, in a sense similar to the concept of "will" in European philosophy. With the steady rise of Darwinian and Freudian thinking, instinct also came to be seen as a primary source of motivation. According to drive theory, the forces of instinct combine into a single source of energy which exerts a constant influence. Psychoanalysis, like biology, regarded these forces as physical demands made by the organism on the nervous system. However, they believed that these forces, especially the sexual instincts, could become entangled and transmuted within the psyche. Classical psychoanalysis conceives of a struggle between the pleasure principle and the reality principle, roughly corresponding to id and ego. Later, in "Beyond the Pleasure Principle", Freud introduced the concept of the "death drive", a compulsion towards aggression, destruction, and psychic repetition of traumatic events. Meanwhile, behaviorist researchers used simple dichotomous models (pleasure/pain, reward/punishment) and well-established principles such as the idea that a thirsty creature will take pleasure in drinking. Clark Hull formalized the latter idea with his drive reduction model.
Hunger, thirst, fear, sexual desire, and thermoregulation all seem to constitute fundamental motivations for animals. Humans also seem to exhibit a more complex set of motivations—though theoretically these could be explained as resulting from primordial instincts—including desires for belonging, self-image, self-consistency, truth, love, and control.
Motivation can be modulated or manipulated in many different ways. Researchers have found that eating, for example, depends not only on the organism's fundamental need for homeostasis—an important factor causing the experience of hunger—but also on circadian rhythms, food availability, food palatability, and cost. Abstract motivations are also malleable, as evidenced by such phenomena as "goal contagion": the adoption of goals, sometimes unconsciously, based on inferences about the goals of others. Vohs and Baumeister suggest that contrary to the need-desire-fulfilment cycle of animal instincts, human motivations sometimes obey a "getting begets wanting" rule: the more you get a reward such as self-esteem, love, drugs, or money, the more you want it. They suggest that this principle can even apply to food, drink, sex, and sleep.
Development.
Mainly focusing on the development of the human mind through the life span, developmental psychology seeks to understand how people come to perceive, understand, and act within the world and how these processes change as they age. This may focus on cognitive, affective, moral, social, or neural development. Researchers who study children use a number of unique research methods to make observations in natural settings or to engage them in experimental tasks. Such tasks often resemble specially designed games and activities that are both enjoyable for the child and scientifically useful, and researchers have even devised clever methods to study the mental processes of infants. In addition to studying children, developmental psychologists also study aging and processes throughout the life span, especially at other times of rapid change (such as adolescence and old age). Developmental psychologists draw on the full range of psychological theories to inform their research.
Genes and environment.
All researched psychological traits are influenced by both genes and environment, to varying degrees. These two sources of influence are often confounded in observational research of individuals or families. An example is the transmission of depression from a depressed mother to her offspring. Theory may hold that the offspring, by virtue of having a depressed mother in his or her (the offspring's) environment, is at risk for developing depression. However, risk for depression is also influenced to some extent by genes. The mother may both carry genes that contribute to her depression but will also have passed those genes on to her offspring thus increasing the offspring's risk for depression. Genes and environment in this simple transmission model are completely confounded. Experimental and quasi-experimental behavioral genetic research uses genetic methodologies to disentangle this confound and understand the nature and origins of individual differences in behavior. Traditionally this research has been conducted using twin studies and adoption studies, two designs where genetic and environmental influences can be partially un-confounded. More recently, the availability of microarray molecular genetic or genome sequencing technologies allows researchers to measure participant DNA variation directly, and test whether individual genetic variants within genes are associated with psychological traits and psychopathology through methods including genome-wide association studies. One goal of such research is similar to that in positional cloning and its success in Huntington's: once a causal gene is discovered biological research can be conducted to understand how that gene influences the phenotype. One major result of genetic association studies is the general finding that psychological traits and psychopathology, as well as complex medical diseases, are highly polygenic, where a large number of genes, each of small effect, contribute to individual differences in the behavioral trait or propensity to the disorder. Active research continues to understand the genetic and environmental bases of behavior and their interaction.
Applications.
Psychology encompasses many subfields and includes different approaches to the study of mental processes and behavior:
Mental testing.
Psychological testing has ancient origins, such as examinations for the Chinese civil service dating back to 2200 BC. Written exams began during the Han dynasty (202 BC.–AD. 200). By 1370, the Chinese system required a stratified series of tests, involving essay writing and knowledge of diverse topics. The system was ended in 1906. In Europe, mental assessment took a more physiological approach, with theories of physiognomy—judgment of character based on the face—described by Aristotle in 4th century BC Greece. Physiognomy remained current through the Enlightenment, and added the doctrine of phrenology: a study of mind and intelligence based on simple assessment of neuroanatomy.
When experimental psychology came to Britain, Francis Galton was a leading practitioner, and, with his procedures for measuring reaction time and sensation, is considered an inventor of modern mental testing (a.k.a. "psychometrics"). James McKeen Cattell, a student of Wundt and Galton, brought the concept to the USA, and in fact coined the term "mental test". In 1901, Cattell's student Clark Wissler published discouraging results, suggesting that mental testing of Columbia and Barnard students failed to predict their academic performance. In response to 1904 orders from the Minister of Public Instruction, French psychologists Alfred Binet and Théodore Simon elaborated a new test of intelligence in 1905–1911, using a range of questions diverse in their nature and difficulty. Binet and Simon introduced the concept of mental age and referred to the lowest scorers on their test as "idiots". Henry H. Goddard put the Binet-Simon scale to work and introduced classifications of mental level such as "imbecile" and "feebleminded". In 1916 (after Binet's death), Stanford professor Lewis M. Terman modified the Binet-Simon scale (renamed the Stanford-Binet scale) and introduced the intelligence quotient as a score report. From this test, Terman concluded that mental retardation "represents the level of intelligence which is very, very common among Spanish-Indians and Mexican families of the Southwest and also among negroes. Their dullness seems to be racial."
Following the Army Alpha and Army Beta tests for soldiers in World War I, mental testing became popular in the US, where it was soon applied to school children. The federally created National Intelligence Test was administered to 7 million children in the 1920s, and in 1926 the College Entrance Examination Board created the Scholastic Aptitude Test to standardize college admissions. The results of intelligence tests were used to argue for segregated schools and economic functions—i.e. the preferential training of Black Americans for manual labor. These practices were criticized by black intellectuals such a Horace Mann Bond and Allison Davis. Eugenicists used mental testing to justify and organize compulsory sterilization of individuals classified as mentally retarded. In the United States, tens of thousands of men and women were sterilized. Setting a precedent which has never been overturned, the U.S. Supreme Court affirmed the constitutionality of this practice in the 1907 case "Buck v. Bell".
Today mental testing is a routine phenomenon for people of all ages in Western societies. Modern testing aspires to criteria including standardization of procedure, consistency of results, output of an interpretable score, statistical norms describing population outcomes, and, ideally, effective prediction of behavior and life outcomes outside of testing situations.
Mental health care.
The provision of psychological health services is generally called "clinical psychology" in the U.S. The definitions of this term are various and may include school psychology and counseling psychology. Practitioners typically includes people who have graduated from doctoral programs in clinical psychology but may also include others. In Canada, the above groups usually fall within the larger category of "professional psychology". In Canada and the US, practitioners get bachelor's degrees and doctorates, then spend one year in an internship and one year in postdoctoral education. In Mexico and most other Latin American and European countries, psychologists do not get bachelor's and doctorate degrees; instead, they take a three-year professional course following high school. Clinical psychology is at present the largest specialization within psychology. It includes the study and application of psychology for the purpose of understanding, preventing, and relieving psychologically based distress, dysfunction or mental illness and to promote subjective well-being and personal development. Central to its practice are psychological assessment and psychotherapy although clinical psychologists may also engage in research, teaching, consultation, forensic testimony, and program development and administration.
Credit for the first psychology clinic in the USA typically goes to Lightner Witmer, who established his practice in Philadelphia in 1896. Another modern psychotherapist was Morton Prince. For the most part, in the first part of the twentieth century, most mental health care in the United States was performed by specialized medical doctors called psychiatrists. Psychology entered the field with its refinements of mental testing, which promised to improve diagnosis of mental problems. For their part, some psychiatrists became interested in using psychoanalysis and other forms of psychodynamic psychotherapy to understand and treat the mentally ill. In this type of treatment, a specially trained therapist develops a close relationship with the patient, who discusses wishes, dreams, social relationships, and other aspects of mental life. The therapist seeks to uncover repressed material and to understand why the patient creates defenses against certain thoughts and feelings. An important aspect of the therapeutic relationship is transference, in which deep unconscious feelings in a patient reorient themselves and become manifest in relation to the therapist.
Psychiatric psychotherapy blurred the distinction between psychiatry and psychology, and this trend continued with the rise of community mental health facilities and behavioral therapy, a thoroughly non-psychodynamic model which used behaviorist learning theory to change the actions of patients. A key aspect of behavior therapy is empirical evaluation of the treatment's effectiveness. In the 1970s, cognitive-behavior therapy arose, using similar methods and now including the cognitive constructs which had gained popularity in theoretical psychology. A key practice in behavioral and cognitive-behavioral therapy is exposing patients to things they fear, based on the premise that their responses (fear, panic, anxiety) can be deconditioned.
Mental health care today involves psychologists and social workers in increasing numbers. In 1977, National Institute of Mental Health director Bertram Brown described this shift as a source of "intense competition and role confusion". Graduate programs issuing doctorates in psychology (PsyD) emerged in the 1950s and underwent rapid increase through the 1980s. This degree is intended to train practitioners who might conduct scientific research.
Some clinical psychologists may focus on the clinical management of patients with brain injury—this area is known as clinical neuropsychology. In many countries, clinical psychology is a regulated mental health profession. The emerging field of "disaster psychology" (see crisis intervention) involves professionals who respond to large-scale traumatic events.
The work performed by clinical psychologists tends to be influenced by various therapeutic approaches, all of which involve a formal relationship between professional and client (usually an individual, couple, family, or small group). Typically, these approaches encourage new ways of thinking, feeling, or behaving. Four major theoretical perspectives are psychodynamic, cognitive behavioral, existential–humanistic, and systems or family therapy. There has been a growing movement to integrate the various therapeutic approaches, especially with an increased understanding of issues regarding culture, gender, spirituality, and sexual orientation. With the advent of more robust research findings regarding psychotherapy, there is evidence that most of the major therapies have equal effectiveness, with the key common element being a strong therapeutic alliance. Because of this, more training programs and psychologists are now adopting an eclectic therapeutic orientation.
Diagnosis in clinical psychology usually follows the "Diagnostic and Statistical Manual of Mental Disorders" (DSM), a handbook first published by the American Psychiatric Association in 1952. New editions over time have increased in size and focused more on medical language. The study of mental illnesses is called abnormal psychology.
Education.
Educational psychology is the study of how humans learn in educational settings, the effectiveness of educational interventions, the psychology of teaching, and the social psychology of schools as organizations. The work of child psychologists such as Lev Vygotsky, Jean Piaget, Bernard Luskin, and Jerome Bruner has been influential in creating teaching methods and educational practices. Educational psychology is often included in teacher education programs in places such as North America, Australia, and New Zealand.
School psychology combines principles from educational psychology and clinical psychology to understand and treat students with learning disabilities; to foster the intellectual growth of gifted students; to facilitate prosocial behaviors in adolescents; and otherwise to promote safe, supportive, and effective learning environments. School psychologists are trained in educational and behavioral assessment, intervention, prevention, and consultation, and many have extensive training in research.
Work.
Industrialists soon brought the nascent field of psychology to bear on the study of scientific management techniques for improving workplace efficiency. This field was at first called "economic psychology" or "business psychology"; later, "industrial psychology", "employment psychology", or "psychotechnology". An important early study examined workers at Western Electric's Hawthorne plant in Cicero, Illinois from 1924–1932. With funding from the Laura Spelman Rockefeller Fund and guidance from Australian psychologist Elton Mayo, Western Electric experimented on thousands of factory workers to assess their responses to illumination, breaks, food, and wages. The researchers came to focus on workers' responses to observation itself, and the term Hawthorne effect is now used to describe the fact that people work harder when they think they're being watched.
The name industrial and organizational psychology (I–O) arose in the 1960s and became enshrined as the Society for Industrial and Organizational Psychology, Division 14 of the American Psychological Association, in 1973. The goal is to optimize human potential in the workplace. Personnel psychology, a subfield of I–O psychology, applies the methods and principles of psychology in selecting and evaluating workers. I–O psychology's other subfield, organizational psychology, examines the effects of work environments and management styles on worker motivation, job satisfaction, and productivity. The majority of I–O psychologists work outside of academia, for private and public organizations and as consultants. A psychology consultant working in business today might expect to provide executives with information and ideas about their industry, their target markets, and the organization of their company.
Military and intelligence.
One role for psychologists in the military is to evaluate and counsel soldiers and other personnel. In the U.S., this function began during World War I, when Robert Yerkes established the School of Military Psychology at Fort Oglethorpe in Georgia, to provide psychological training for military staff military. Today, U.S Army psychology includes psychological screening, clinical psychotherapy, suicide prevention, and treatment for post-traumatic stress, as well as other aspects of health and workplace psychology such as smoking cessation.
Psychologists may also work on a diverse set of campaigns known broadly as psychological warfare. Psychologically warfare chiefly involves the use of propaganda to influence enemy soldiers and civilians. In the case of so-called black propaganda the propaganda is designed to seem like it originates from a different source. The CIA's MKULTRA program involved more individualized efforts at mind control, involving techniques such as hypnosis, torture, and covert involuntary administration of LSD. The U.S. military used the name Psychological Operations (PSYOP) until 2010, when these were reclassified as Military Information Support Operations (MISO), part of Information Operations (IO). Psychologists are sometimes involved in assisting the interrogation and torture of suspects, though this has sometimes been denied by those involved and sometimes opposed by others.
Health, well-being, and social change.
Medical facilities increasingly employ psychologists to perform various roles. A prominent aspect of health psychology is the psychoeducation of patients: instructing them in how to follow a medical regimen. Health psychologists can also educate doctors and conduct research on patient compliance.
Psychologists in the field of public health use a wide variety of interventions to influence human behavior. These range from public relations campaigns and outreach to governmental laws and policies. Psychologists study the composite influence of all these different tools in an effort to influence whole populations of people.
Black American psychologists Kenneth and Mamie Clark studied the psychological impact of segregation and testified with their findings in the desegregation case "Brown v. Board of Education" (1954).
Positive psychology is the study of factors which contribute to human happiness and well-being, focusing more on people who are currently health. In 2010 "Clinical Psychological Review" published a special issue devoted to positive psychological interventions, such as gratitude journaling and the physical expression of gratitude. Positive psychological interventions have been limited in scope, but their effects are thought to be superior to that of placebos, especially with regard to helping people with body image problems.
Research methods.
Quantitative psychological research lends itself to the statistical testing of hypotheses. Although the field makes abundant use of randomized and controlled experiments in laboratory settings, such research can only assess a limited range of short-term phenomena. Thus, psychologists also rely on creative statistical methods to glean knowledge from clinical trials and population data. These include the Pearson product–moment correlation coefficient, the analysis of variance, multiple linear regression, logistic regression, structural equation modeling, and hierarchical linear modeling. The measurement and operationalization of important constructs is an essential part of these research designs.
Controlled experiments.
A true experiment with random allocation of subjects to conditions allows researchers to make strong inferences about causal relationships. In an experiment, the researcher alters parameters of influence, called independent variables, and measures resulting changes of interest, called dependent variables. Prototypical experimental research is conducted in a laboratory with a carefully controlled environment.
Repeated-measures experiments are those which take place through intervention on multiple occasions. In research on the effectiveness of psychotherapy, experimenters often compare a given treatment with placebo treatments, or compare different treatments against each other. Treatment type is the independent variable. The dependent variables are outcomes, ideally assessed in several ways by different professionals. Using crossover design, researchers can further increase the strength of their results by testing both of two treatments on two groups of subjects.
Quasi-experimental design refers especially to situations precluding random assignment to different conditions. Researchers can use common sense to consider how much the nonrandom assignment threatens the study's validity. For example, in research on the best way to affect reading achievement in the first three grades of school, school administrators may not permit educational psychologists to randomly assign children to phonics and whole language classrooms, in which case the psychologists must work with preexisting classroom assignments. Psychologists will compare the achievement of children attending phonics and whole language classes.
Experimental researchers typically use a statistical hypothesis testing model which involves making predictions before conducting the experiment, then assessing how well the data supports the predictions. (These predictions may originate from a more abstract scientific hypothesis about how the phenomenon under study actually works.) Analysis of variance (ANOVA) statistical techniques are used to distinguish unique results of the experiment from the null hypothesis that variations result from random fluctuations in data. In psychology, the widely usd standard ascribes statistical significance to results which have less than 5% probability of being explained by random variation.
Other forms of statistical inference.
Statistical surveys are used in psychology for measuring attitudes and traits, monitoring changes in mood, checking the validity of experimental manipulations, and for other psychological topics. Most commonly, psychologists use paper-and-pencil surveys. However, surveys are also conducted over the phone or through e-mail. Web-based surveys are increasingly used to conveniently reach many subjects.
Neuropsychological tests, such as the Wechsler scales and Wisconsin Card Sorting Test, are mostly questionnaires or simple tasks used which assess a specific type of mental function in the respondent. These can be used in experiments, as in the case of lesion experiments evaluating the results of damage to a specific part of the brain.
Observational studies analyze uncontrolled data in search of correlations; multivariate statistics are typically used to interpret the more complex situation. Cross-sectional observational studies use data from a single point in time, whereas longitudinal studies are used to study trends across the life span. Longitudinal studies track the same people, and therefore detect more individual, rather than cultural, differences. However, they suffer from lack of controls and from confounding factors such as "selective attrition" (the bias introduced when a certain type of subject disproportionately leaves a study).
Exploratory data analysis refers to a variety of practices which researchers can use to visualize and analyze existing sets of data. In Peirce's three modes of inference, exploratory data anlysis corresponds to abduction, or hypothesis formation. Meta-analysis is the technique of integrating the results from multiple studies and interpreting the statistical properties of the pooled dataset.
Technological assays.
A classic and popular tool used to relate mental and neural activity is the electroencephalogram (EEG), a technique using amplified electrodes on a person's scalp to measure voltage changes in different parts of the brain. Hans Berger, the first researcher to use EEG on an unopened skull, quickly found that brains exhibit signature "brain waves": electric oscillations which correspond to different states of consciousness. Researchers subsequently refined statistical methods for synthesizing the electrode data, and identified unique brain wave patterns such as the delta wave observed during non-REM sleep.
Newer functional neuroimaging techniques include functional magnetic resonance imaging and positron emission tomography, both of which track the flow of blood through the brain. These technologies provide more localized information about activity in the brain and create representations of the brain with widespread appeal. They also provide insight which avoids the classic problems of subjective self-reporting. It remains challenging to draw hard conclusions about where in the brain specific thoughts originate—or even how usefully such localization corresponds with reality. However, neuroimaging has delivered unmistakable results showing the existence of correlations between mind and brain. Some of these draw on a systemic neural network model rather than a localized function model.
Psychiatric interventions such as transcranial magnetic stimulation and of course drugs also provide information about brain–mind interactions. Psychopharmacology is the study of drug-induced mental effects.
Computer simulation.
Computational modeling is a tool used in mathematical psychology and cognitive psychology to simulate behavior. This method has several advantages. Since modern computers process information quickly, simulations can be run in a short time, allowing for high statistical power. Modeling also allows psychologists to visualize hypotheses about the functional organization of mental events that couldn't be directly observed in a human. Connectionism uses neural networks to simulate the brain. Another method is symbolic modeling, which represents many mental objects using variables and rules. Other types of modeling include dynamic systems and stochastic modeling.
Animal studies.
Animal experiments aid in investigating many aspects of human psychology, including perception, emotion, learning, memory, and thought, to name a few. In the 1890s, Russian physiologist Ivan Pavlov famously used dogs to demonstrate classical conditioning. Non-human primates, cats, dogs, pigeons, rats, and other rodents are often used in psychological experiments. Ideally, controlled experiments introduce only one independent variable at a time, in order to ascertain its unique effects upon dependent variables. These conditions are approximated best in laboratory settings. In contrast, human environments and genetic backgrounds vary so widely, and depend upon so many factors, that it is difficult to control important variables for human subjects. Of course, there are pitfalls in generalizing findings from animal studies to humans through animal models.
Comparative psychology refers to the scientific study of the behavior and mental processes of non-human animals, especially as these relate to the phylogenetic history, adaptive significance, and development of behavior. Research in this area explores the behavior of many species, from insects to primates. It is closely related to other disciplines that study animal behavior such as ethology. Research in comparative psychology sometimes appears to shed light on human behavior, but some attempts to connect the two have been quite controversial, for example the Sociobiology of E. O. Wilson. Animal models are often used to study neural processes related to human behavior, e.g. in cognitive neuroscience.
Qualitative and descriptive research.
Research designed to answer questions about the current state of affairs such as the thoughts, feelings, and behaviors of individuals is known as "descriptive research". Descriptive research can be qualitative or quantitative in orientation. "Qualitative research" is descriptive research that is focused on observing and describing events as they occur, with the goal of capturing all of the richness of everyday behavior and with the hope of discovering and understanding phenomena that might have been missed if only more cursory examinations have been made.
Qualitative psychological research methods include interviews, first-hand observation, and participant observation. Creswell (2003) identifies five main possibilities for qualitative research, including narrative, phenomenology, ethnography, case study, and grounded theory. Qualitative researchers sometimes aim to enrich interpretations or critiques of symbols, subjective experiences, or social structures. Sometimes hermeneutic and critical aims can give rise to quantitative research, as in Erich Fromm's study of Nazi voting or Stanley Milgram's studies of obedience to authority.
Just as Jane Goodall studied chimpanzee social and family life by careful observation of chimpanzee behavior in the field, psychologists conduct naturalistic observation of ongoing human social, professional, and family life. Sometimes the participants are aware they are being observed, and other times the participants do not know they are being observed. Strict ethical guidelines must be followed when covert observation is being carried out.
Contemporary issues in methodology and practice.
In 1959 statistician Theodore Sterling examined the results of psychological studies and discovered that 97% of them supported their initial hypotheses, implying a possible publication bias. Similarly, Fanelli (2010) found that 91.5% of psychiatry/psychology studies confirmed the effects they were looking for, and concluded that the odds of this happening (a positive result) was around five times higher than in fields such as space- or geosciences. Fanelli argues that this is because researchers in "softer" sciences have fewer constraints to their conscious and unconscious biases.
Some popular media outlets have in recent years spotlighted a replication crisis in psychology, arguing that many findings in the field cannot be reproduced. Repeats of some famous studies have not reached the same conclusions, and some researchers have been accused of outright fraud in their results. Focus on this issue has led to renewed efforts in the discipline to re-test important findings.
Some critics view statistical hypothesis testing as misplaced. Psychologist and statistician Jacob Cohen wrote in 1994 that psychologists routinely confuse statistical significance with practical importance, enthusiastically reporting great certainty in unimportant facts. Some psychologists have responded with an increased use of effect size statistics, rather than sole reliance on the Fisherian "p" < .05 significance criterion (whereby an observed difference is deemed "statistically significant" if an effect of that size or larger would occur with 5% -or less- probability in independent replications, assuming the truth of the null-hypothesis of no difference between the treatments).
In 2010, a group of researchers reported a systemic bias in psychology studies towards WEIRD ("western, educated, industrialized, rich and democratic") subjects. Although only 1/8 people worldwide fall into the WEIRD classification, the researchers claimed that 60–90% of psychology studies are performed on WEIRD subjects. The article gave examples of results that differ significantly between WEIRD subjects and tribal cultures, including the Müller-Lyer illusion.
Some observers perceive a gap between scientific theory and its application—in particular, the application of unsupported or unsound clinical practices. Critics say there has been an increase in the number of mental health training programs that do not instill scientific competence. One skeptic asserts that practices, such as "facilitated communication for infantile autism"; memory-recovery techniques including body work; and other therapies, such as rebirthing and reparenting, may be dubious or even dangerous, despite their popularity. In 1984, Allen Neuringer made a similar point regarding the experimental analysis of behavior. Psychologists, sometimes divided along the lines of laboratory vs. clinic, continue to debate these issues.
Ethics.
Ethical standards in the discipline have changed over time. Some famous past studies are today considered unethical and in violation of established codes (Ethics Code of the American Psychological Association, the Canadian Code of Conduct for Research Involving Humans, and the Belmont Report).
The most important contemporary standards are informed and voluntary consent. After World War II, the Nuremberg Code was established because of Nazi abuses of experimental subjects. Later, most countries (and scientific journals) adopted the Declaration of Helsinki. In the U.S., the National Institutes of Health established the Institutional Review Board in 1966, and in 1974 adopted the National Research Act (HR 7724). All of these measures encouraged researchers to obtain informed consent from human participants in experimental studies. A number of influential studies led to the establishment of this rule; such studies included the MIT and Fernald School radioisotope studies, the Thalidomide tragedy, the Willowbrook hepatitis study, and Stanley Milgram's studies of obedience to authority.
Humans.
University psychology departments have ethics committees dedicated to the rights and well-being of research subjects. Researchers in psychology must gain approval of their research projects before conducting any experiment to protect the interests of human participants and laboratory animals.
The ethics code of the American Psychological Association originated in 1951 as "Ethical Standards of Psychologists." This code has guided the formation of licensing laws in most American states. It has changed multiple times over the decades since its adoption. In 1989 the APA revised its policies on advertising and referral fees to negotiate the end of an investigation by the Federal Trade Commission. The 1992 incarnation was the first to distinguish between "aspirational" ethical standards and "enforceable" ones. Members of the public have a 5-year window to file ethics complaints about APA members with the APA ethics committee; members of the APA have a 3-year window.
Some of the ethical issues considered most important are the requirement to practice only within the area of competence, to maintain confidentiality with the patients, and to avoid sexual relations with them. Another important principle is informed consent, the idea that a patient or research subject must understand and freely choose a procedure they are undergoing. Some of the most common complaints against clinical psychologists include sexual misconduct, and involvement in child custody evaluations.
Other animals.
Current ethical guidelines state that using non-human animals for scientific purposes is only acceptable when the harm (physical or psychological) done to animals is outweighed by the benefits of the research. Keeping this in mind, psychologists can use certain research techniques on animals that could not be used on humans.

</doc>
<doc id="22923" url="https://en.wikipedia.org/wiki?curid=22923" title="PhpWiki">
PhpWiki

PhpWiki is a web-based wiki software application.
It began as a clone of WikiWikiWeb and was the first wiki written in PHP.
PhpWiki has been used to edit and format paper books for publication.
History.
The first version, by Steve Wainstead, was in December 1999 and was the first Wiki written in PHP to be publicly released.
The first version ran under PHP 3.x and ran on DBM files only. 
It was a feature-for-feature reimplementation of the original WikiWikiWeb at c2.com.
In early 2000 Arno Hollosi contributed a second database library to run PhpWiki on MySQL.
From then on the features and contributions started to grow, including a templating system, color diffs, rewrites of the rendering engine and much more.
Arno was interested in running a wiki for the game Go.
Jeff Dairiki was the next major contributor, and soon headed the project for the next few years, then Reini Urban up to 1.4, and then Marc-Etienne Vargenau since 1.5.
Supports Wikicreole 1.0 including additions and MediaWiki markup syntax since Version 1.4.0. With Version 1.5.0 PHP 4 was deprecated.

</doc>
<doc id="22926" url="https://en.wikipedia.org/wiki?curid=22926" title="Poetry">
Poetry

Poetry is a form of literature that uses aesthetic and rhythmic qualities of language—such as phonaesthetics, sound symbolism, and metre—to evoke meanings in addition to, or in place of, the prosaic ostensible meaning.
Poetry has a long history, dating back to the Sumerian "Epic of Gilgamesh". Early poems evolved from folk songs such as the Chinese "Shijing", or from a need to retell oral epics, as with the Sanskrit "Vedas", Zoroastrian "Gathas", and the Homeric epics, the "Iliad" and the "Odyssey". Ancient attempts to define poetry, such as Aristotle's "Poetics", focused on the uses of speech in rhetoric, drama, song and comedy. Later attempts concentrated on features such as repetition, verse form and rhyme, and emphasized the aesthetics which distinguish poetry from more objectively informative, prosaic forms of writing. From the mid-20th century, poetry has sometimes been more generally regarded as a fundamental creative act employing language.
Poetry uses forms and conventions to suggest differential interpretation to words, or to evoke emotive responses. Devices such as assonance, alliteration, onomatopoeia and rhythm are sometimes used to achieve musical or incantatory effects. The use of ambiguity, symbolism, irony and other stylistic elements of poetic diction often leaves a poem open to multiple interpretations. Similarly figures of speech such as metaphor, simile and metonymy create a resonance between otherwise disparate images—a layering of meanings, forming connections previously not perceived. Kindred forms of resonance may exist, between individual verses, in their patterns of rhyme or rhythm.
Some poetry types are specific to particular cultures and genres and respond to characteristics of the language in which the poet writes. Readers accustomed to identifying poetry with Dante, Goethe, Mickiewicz and Rumi may think of it as written in lines based on rhyme and regular meter; there are, however, traditions, such as Biblical poetry, that use other means to create rhythm and euphony. Much modern poetry reflects a critique of poetic tradition, playing with and testing, among other things, the principle of euphony itself, sometimes altogether forgoing rhyme or set rhythm. In today's increasingly globalized world, poets often adapt forms, styles and techniques from diverse cultures and languages.
History.
Poetry as an art form may predate literacy. The oldest surviving epic poem is the "Epic of Gilgamesh", from the 3rd millenniumBC in Sumer (in Mesopotamia, now Iraq), which was written in cuneiform script on clay tablets and, later, papyrus. A tablet dating to c.2000BC describes an annual rite in which the king symbolically married and mated with the goddess Inanna to ensure fertility and prosperity, and is considered the world's oldest love poem. Examples of Egyptian epic poetry include "The Story of Sinuhe" (c. 1800 BC). Other ancient epic poetry includes the Greek epics "Iliad" and "Odyssey", the Avestan books the "Gathic Avesta" and "Yasna", the Roman national epic, Virgil's "Aeneid", and the Indian epics "Ramayana" and "Mahabharata".
Epic poetry, including the Indian "Vedas", the "Gathasand" the "Odysse"BC), appears to have been composed in poetic form to aid memorization and oral transmission, in prehistoric and ancient societies. Other forms of poetry developed directly from folk songs. The earliest entries in the ancient compilation "Shijing", were initially lyrics, preceding later entries intended to be read.
The efforts of ancient thinkers to determine what makes poetry distinctive as a form, and what distinguishes good poetry from bad, resulted in "poetics"—the study of the aesthetics of poetry. Some ancient poetic traditions; such as, contextually, Classical Chinese poetry in the case of the "Shijing" ("Classic of Poetry"), which records the development of poetic canons with ritual and aesthetic importance. More recently, thinkers have struggled to find a definition that could encompass formal differences as great as those between Chaucer's "Canterbury Tales" and Matsuo Bashō's "Oku no Hosomichi", as well as differences in context spanning Tanakh religious poetry, love poetry, and rap.
Western traditions.
Classical thinkers employed classification as a way to define and assess the quality of poetry. Notably, the existing fragments of Aristotle's "Poetics" describe three genres of poetry—the epic, the comic, and the tragic—and develop rules to distinguish the highest-quality poetry in each genre, based on the underlying purposes of the genre. Later aestheticians identified three major genres: epic poetry, lyric poetry, and dramatic poetry, treating comedy and tragedy as subgenres of dramatic poetry.
Aristotle's work was influential throughout the Middle East during the Islamic Golden Age, as well as in Europe during the Renaissance. Later poets and aestheticians often distinguished poetry from, and defined it in opposition to prose, which was generally understood as writing with a proclivity to logical explication and a linear narrative structure.
This does not imply that poetry is illogical or lacks narration, but rather that poetry is an attempt to render the beautiful or sublime without the burden of engaging the logical or narrative thought process. English Romantic poet John Keats termed this escape from logic "Negative Capability". This "romantic" approach views form as a key element of successful poetry because form is abstract and distinct from the underlying notional logic. This approach remained influential into the 20th century.
During this period, there was also substantially more interaction among the various poetic traditions, in part due to the spread of European colonialism and the attendant rise in global trade. In addition to a boom in translation, during the Romantic period numerous ancient works were rediscovered.
20th-century and 21st-century disputes.
Some 20th-century literary theorists, relying less on the opposition of prose and poetry, focused on the poet as simply one who creates using language, and poetry as what the poet creates. The underlying concept of the poet as creator is not uncommon, and some modernist poets essentially do not distinguish between the creation of a poem with words, and creative acts in other media. Yet other modernists challenge the very attempt to define poetry as misguided.
The rejection of traditional forms and structures for poetry that began in the first half of the 20th century coincided with a questioning of the purpose and meaning of traditional definitions of poetry and of distinctions between poetry and prose, particularly given examples of poetic prose and prosaic poetry. Numerous modernist poets have written in non-traditional forms or in what traditionally would have been considered prose, although their writing was generally infused with poetic diction and often with rhythm and tone established by non-metrical means. While there was a substantial formalist reaction within the modernist schools to the breakdown of structure, this reaction focused as much on the development of new formal structures and syntheses as on the revival of older forms and structures.
Recently, postmodernism has come to convey more completely prose and poetry as distinct entities, and also among genres of poetry, as having meaning only as cultural artifacts. Postmodernism goes beyond modernism's emphasis on the creative role of the poet, to emphasize the role of the reader of a text (Hermeneutics), and to highlight the complex cultural web within which a poem is read. Today, throughout the world, poetry often incorporates poetic form and diction from other cultures and from the past, further confounding attempts at definition and classification that were once sensible within a tradition such as the Western canon.
The early 21st century poetic tradition appears to continue to strongly orient itself to earlier precursor poetic traditions such as those initiated by Whitman, Emerson, and Wordsworth. The literary critic Geoffrey Hartman has used the phrase "the anxiety of demand" to describe contemporary response to older poetic traditions as "being fearful that the fact no longer has a form", building on a trope introduced by Emerson. Emerson had maintained that in the debate concerning poetic structure where either "form" or "fact" could predominate, that one need simply "Ask the fact for the form." This has been challenged at various levels by other literary scholars such as Bloom who has stated in summary form concerning the early 21st century that: "The generation of poets who stand together now, mature and ready to write the major American verse of the twenty-first century, may yet be seen as what Stevens called 'a great shadow's last embellishment,' the shadow being Emerson's."
Elements.
Prosody.
Prosody is the study of the meter, rhythm, and intonation of a poem. Rhythm and meter are different, although closely related. Meter is the definitive pattern established for a verse (such as iambic pentameter), while rhythm is the actual sound that results from a line of poetry. Prosody also may be used more specifically to refer to the scanning of poetic lines to show meter.
Rhythm.
The methods for creating poetic rhythm vary across languages and between poetic traditions. Languages are often described as having timing set primarily by accents, syllables, or moras, depending on how rhythm is established, though a language can be influenced by multiple approaches. Japanese is a mora-timed language. Syllable-timed languages include Latin, Catalan, French, Leonese, Galician and Spanish. English, Russian and, generally, German are stress-timed languages. Varying intonation also affects how rhythm is perceived. Languages can rely on either pitch, such as in Vedic Sanskrit or Ancient Greek, or tone. Tonal languages include Chinese, Vietnamese and most Subsaharan languages.
Metrical rhythm generally involves precise arrangements of stresses or syllables into repeated patterns called feet within a line. In Modern English verse the pattern of stresses primarily differentiate feet, so rhythm based on meter in Modern English is most often founded on the pattern of stressed and unstressed syllables (alone or elided). In the classical languages, on the other hand, while the metrical units are similar, vowel length rather than stresses define the meter. Old English poetry used a metrical pattern involving varied numbers of syllables but a fixed number of strong stresses in each line.
The chief device of ancient Hebrew Biblical poetry, including many of the psalms, was "parallelism", a rhetorical structure in which successive lines reflected each other in grammatical structure, sound structure, notional content, or all three. Parallelism lent itself to antiphonal or call-and-response performance, which could also be reinforced by intonation. Thus, Biblical poetry relies much less on metrical feet to create rhythm, but instead creates rhythm based on much larger sound units of lines, phrases and sentences. Some classical poetry forms, such as Venpa of the Tamil language, had rigid grammars (to the point that they could be expressed as a context-free grammar) which ensured a rhythm. In Chinese poetry, tones as well as stresses create rhythm. Classical Chinese poetics identifies four tones: the level tone, rising tone, departing tone, and entering tone.
The formal patterns of meter used in Modern English verse to create rhythm no longer dominate contemporary English poetry. In the case of free verse, rhythm is often organized based on looser units of cadence rather than a regular meter. Robinson Jeffers, Marianne Moore, and William Carlos Williams are three notable poets who reject the idea that regular accentual meter is critical to English poetry. Jeffers experimented with sprung rhythm as an alternative to accentual rhythm.
Meter.
In the Western poetic tradition, meters are customarily grouped according to a characteristic metrical foot and the number of feet per line. The number of metrical feet in a line are described using Greek terminology: tetrameter for four feet and hexameter for six feet, for example. Thus, "iambic pentameter" is a meter comprising five feet per line, in which the predominant kind of foot is the "iamb". This metric system originated in ancient Greek poetry, and was used by poets such as Pindar and Sappho, and by the great tragedians of Athens. Similarly, "dactylic hexameter", comprises six feet per line, of which the dominant kind of foot is the "dactyl". Dactylic hexameter was the traditional meter of Greek epic poetry, the earliest extant examples of which are the works of Homer and Hesiod. Iambic pentameter and dactylic hexameter were later used by a number of poets, including William Shakespeare and Henry Wadsworth Longfellow, respectively. The most common metrical feet in English are:
There are a wide range of names for other types of feet, right up to a choriamb, a four syllable metric foot with a stressed syllable followed by two unstressed syllables and closing with a stressed syllable. The choriamb is derived from some ancient Greek and Latin poetry. Languages which utilize vowel length or intonation rather than or in addition to syllabic accents in determining meter, such as Ottoman Turkish or Vedic, often have concepts similar to the iamb and dactyl to describe common combinations of long and short sounds.
Each of these types of feet has a certain "feel," whether alone or in combination with other feet. The iamb, for example, is the most natural form of rhythm in the English language, and generally produces a subtle but stable verse. Scanning meter can often show the basic or fundamental pattern underlying a verse, but does not show the varying degrees of stress, as well as the differing pitches and lengths of syllables.
There is debate over how useful a multiplicity of different "feet" is in describing meter. For example, Robert Pinsky has argued that while dactyls are important in classical verse, English dactylic verse uses dactyls very irregularly and can be better described based on patterns of iambs and anapests, feet which he considers natural to the language. Actual rhythm is significantly more complex than the basic scanned meter described above, and many scholars have sought to develop systems that would scan such complexity. Vladimir Nabokov noted that overlaid on top of the regular pattern of stressed and unstressed syllables in a line of verse was a separate pattern of accents resulting from the natural pitch of the spoken words, and suggested that the term "scud" be used to distinguish an unaccented stress from an accented stress.
Metrical patterns.
Different traditions and genres of poetry tend to use different meters, ranging from the Shakespearean iambic pentameter and the Homeric dactylic hexameter to the anapestic tetrameter used in many nursery rhymes. However, a number of variations to the established meter are common, both to provide emphasis or attention to a given foot or line and to avoid boring repetition. For example, the stress in a foot may be inverted, a caesura (or pause) may be added (sometimes in place of a foot or stress), or the final foot in a line may be given a feminine ending to soften it or be replaced by a spondee to emphasize it and create a hard stop. Some patterns (such as iambic pentameter) tend to be fairly regular, while other patterns, such as dactylic hexameter, tend to be highly irregular. Regularity can vary between language. In addition, different patterns often develop distinctively in different languages, so that, for example, iambic tetrameter in Russian will generally reflect a regularity in the use of accents to reinforce the meter, which does not occur, or occurs to a much lesser extent, in English.
Some common metrical patterns, with notable examples of poets and poems who use them, include:
Rhyme, alliteration, assonance.
Rhyme, alliteration, assonance and consonance are ways of creating repetitive patterns of sound. They may be used as an independent structural element in a poem, to reinforce rhythmic patterns, or as an ornamental element. They can also carry a meaning separate from the repetitive sound patterns created. For example, Chaucer used heavy alliteration to mock Old English verse and to paint a character as archaic.
Rhyme consists of identical ("hard-rhyme") or similar ("soft-rhyme") sounds placed at the ends of lines or at predictable locations within lines ("internal rhyme"). Languages vary in the richness of their rhyming structures; Italian, for example, has a rich rhyming structure permitting maintenance of a limited set of rhymes throughout a lengthy poem. The richness results from word endings that follow regular forms. English, with its irregular word endings adopted from other languages, is less rich in rhyme. The degree of richness of a language's rhyming structures plays a substantial role in determining what poetic forms are commonly used in that language.
Alliteration is the repetition of letters or letter-sounds at the beginning of two or more words immediately succeeding each other, or at short intervals; or the recurrence of the same letter in accented parts of words. Alliteration and assonance played a key role in structuring early Germanic, Norse and Old English forms of poetry. The alliterative patterns of early Germanic poetry interweave meter and alliteration as a key part of their structure, so that the metrical pattern determines when the listener expects instances of alliteration to occur. This can be compared to an ornamental use of alliteration in most Modern European poetry, where alliterative patterns are not formal or carried through full stanzas. Alliteration is particularly useful in languages with less rich rhyming structures.
Assonance, where the use of similar vowel sounds within a word rather than similar sounds at the beginning or end of a word, was widely used in skaldic poetry, but goes back to the Homeric epic. Because verbs carry much of the pitch in the English language, assonance can loosely evoke the tonal elements of Chinese poetry and so is useful in translating Chinese poetry. Consonance occurs where a consonant sound is repeated throughout a sentence without putting the sound only at the front of a word. Consonance provokes a more subtle effect than alliteration and so is less useful as a structural element.
Rhyming schemes.
In many languages, including modern European languages and Arabic, poets use rhyme in set patterns as a structural element for specific poetic forms, such as ballads, sonnets and rhyming couplets. However, the use of structural rhyme is not universal even within the European tradition. Much modern poetry avoids traditional rhyme schemes. Classical Greek and Latin poetry did not use rhyme. Rhyme entered European poetry in the High Middle Ages, in part under the influence of the Arabic language in Al Andalus (modern Spain). Arabic language poets used rhyme extensively from the first development of literary Arabic in the sixth century, as in their long, rhyming qasidas. Some rhyming schemes have become associated with a specific language, culture or period, while other rhyming schemes have achieved use across languages, cultures or time periods. Some forms of poetry carry a consistent and well-defined rhyming scheme, such as the chant royal or the rubaiyat, while other poetic forms have variable rhyme schemes.
Most rhyme schemes are described using letters that correspond to sets of rhymes, so if the first, second and fourth lines of a quatrain rhyme with each other and the third line does not rhyme, the quatrain is said to have an "a-a-b-a" rhyme scheme. This rhyme scheme is the one used, for example, in the rubaiyat form. Similarly, an "a-b-b-a" quatrain (what is known as "enclosed rhyme") is used in such forms as the Petrarchan sonnet. Some types of more complicated rhyming schemes have developed names of their own, separate from the "a-b-c" convention, such as the ottava rima and terza rima. The types and use of differing rhyming schemes is discussed further in the main article.
Form.
Poetic form is more flexible in modernist and post-modernist poetry, and continues to be less structured than in previous literary eras. Many modern poets eschew recognisable structures or forms, and write in free verse. But poetry remains distinguished from prose by its form; some regard for basic formal structures of poetry will be found in even the best free verse, however much such structures may appear to have been ignored. Similarly, in the best poetry written in classic styles there will be departures from strict form for emphasis or effect.
Among major structural elements used in poetry are the line, the stanza or verse paragraph, and larger combinations of stanzas or lines such as cantos. Also sometimes used are broader visual presentations of words and calligraphy. These basic units of poetic form are often combined into larger structures, called "poetic forms" or poetic modes (see following section), as in the sonnet or haiku.
Lines and stanzas.
Poetry is often separated into lines on a page. These lines may be based on the number of metrical feet, or may emphasize a rhyming pattern at the ends of lines. Lines may serve other functions, particularly where the poem is not written in a formal metrical pattern. Lines can separate, compare or contrast thoughts expressed in different units, or can highlight a change in tone. See the article on line breaks for information about the division between lines.
Lines of poems are often organized into stanzas, which are denominated by the number of lines included. Thus a collection of two lines is a couplet (or distich), three lines a triplet (or tercet), four lines a quatrain, and so on. These lines may or may not relate to each other by rhyme or rhythm. For example, a couplet may be two lines with identical meters which rhyme or two lines held together by a common meter alone.
Other poems may be organized into verse paragraphs, in which regular rhymes with established rhythms are not used, but the poetic tone is instead established by a collection of rhythms, alliterations, and rhymes established in paragraph form. Many medieval poems were written in verse paragraphs, even where regular rhymes and rhythms were used.
In many forms of poetry, stanzas are interlocking, so that the rhyming scheme or other structural elements of one stanza determine those of succeeding stanzas. Examples of such interlocking stanzas include, for example, the ghazal and the villanelle, where a refrain (or, in the case of the villanelle, refrains) is established in the first stanza which then repeats in subsequent stanzas. Related to the use of interlocking stanzas is their use to separate thematic parts of a poem. For example, the strophe, antistrophe and epode of the ode form are often separated into one or more stanzas.
In some cases, particularly lengthier formal poetry such as some forms of epic poetry, stanzas themselves are constructed according to strict rules and then combined. In skaldic poetry, the dróttkvætt stanza had eight lines, each having three "lifts" produced with alliteration or assonance. In addition to two or three alliterations, the odd numbered lines had partial rhyme of consonants with dissimilar vowels, not necessarily at the beginning of the word; the even lines contained internal rhyme in set syllables (not necessarily at the end of the word). Each half-line had exactly six syllables, and each line ended in a trochee. The arrangement of dróttkvætts followed far less rigid rules than the construction of the individual dróttkvætts.
Visual presentation.
Even before the advent of printing, the visual appearance of poetry often added meaning or depth. Acrostic poems conveyed meanings in the initial letters of lines or in letters at other specific places in a poem. In Arabic, Hebrew and Chinese poetry, the visual presentation of finely calligraphed poems has played an important part in the overall effect of many poems.
With the advent of printing, poets gained greater control over the mass-produced visual presentations of their work. Visual elements have become an important part of the poet's toolbox, and many poets have sought to use visual presentation for a wide range of purposes. Some Modernist poets have made the placement of individual lines or groups of lines on the page an integral part of the poem's composition. At times, this complements the poem's rhythm through visual caesuras of various lengths, or creates juxtapositions so as to accentuate meaning, ambiguity or irony, or simply to create an aesthetically pleasing form. In its most extreme form, this can lead to concrete poetry or asemic writing.
Diction.
Poetic diction treats the manner in which language is used, and refers not only to the sound but also to the underlying meaning and its interaction with sound and form. Many languages and poetic forms have very specific poetic dictions, to the point where distinct grammars and dialects are used specifically for poetry. Registers in poetry can range from strict employment of ordinary speech patterns, as favoured in much late-20th-century prosody, through to highly ornate uses of language, as in medieval and Renaissance poetry.
Poetic diction can include rhetorical devices such as simile and metaphor, as well as tones of voice, such as irony. Aristotle wrote in the "Poetics" that "the greatest thing by far is to be a master of metaphor." Since the rise of Modernism, some poets have opted for a poetic diction that de-emphasizes rhetorical devices, attempting instead the direct presentation of things and experiences and the exploration of tone. On the other hand, Surrealists have pushed rhetorical devices to their limits, making frequent use of catachresis.
Allegorical stories are central to the poetic diction of many cultures, and were prominent in the West during classical times, the late Middle Ages and the Renaissance. "Aesop's Fables", repeatedly rendered in both verse and prose since first being recorded about 500 B.C., are perhaps the richest single source of allegorical poetry through the ages. Other notables examples include the "Roman de la Rose", a 13th-century French poem, William Langland's "Piers Ploughman" in the 14th century, and Jean de la Fontaine's "Fables" (influenced by Aesop's) in the 17th century. Rather than being fully allegorical, however, a poem may contain symbols or allusions that deepen the meaning or effect of its words without constructing a full allegory.
Another element of poetic diction can be the use of vivid imagery for effect. The juxtaposition of unexpected or impossible images is, for example, a particularly strong element in surrealist poetry and haiku. Vivid images are often endowed with symbolism or metaphor. Many poetic dictions use repetitive phrases for effect, either a short phrase (such as Homer's "rosy-fingered dawn" or "the wine-dark sea") or a longer refrain. Such repetition can add a sombre tone to a poem, or can be laced with irony as the context of the words changes.
Forms.
Specific poetic forms have been developed by many cultures. In more developed, closed or "received" poetic forms, the rhyming scheme, meter and other elements of a poem are based on sets of rules, ranging from the relatively loose rules that govern the construction of an elegy to the highly formalized structure of the ghazal or villanelle. Described below are some common forms of poetry widely used across a number of languages. Additional forms of poetry may be found in the discussions of poetry of particular cultures or periods and in the glossary.
Sonnet.
Among the most common forms of poetry, popular from the Late Middle Ages on, is the sonnet, which by the 13th century had become standardized as fourteen lines following a set rhyme scheme and logical structure. By the 14th century and the Italian Renaissance, the form had further crystallized under the pen of Petrarch, whose sonnets were translated in the 16th century by Sir Thomas Wyatt, who is credited with introducing the sonnet form into English literature. A traditional Italian or Petrarchan sonnet follows the rhyme scheme "abba, abba, cdecde," though some variation, especially within the final six lines (or "sestet"), is common. The English (or Shakespearean) sonnet follows the rhyme scheme "abab, cdcd, efef, gg", introducing a third quatrain (grouping of four lines), a final couplet, and a greater amount of variety with regard to rhyme than is usually found in its Italian predecessors. By convention, sonnets in English typically use iambic pentameter, while in the Romance languages, the hendecasyllable and Alexandrine are the most widely used meters.
Sonnets of all types often make use of a "volta," or "turn," a point in the poem at which an idea is turned on its head, a question is answered (or introduced), or the subject matter is further complicated. This "volta" can often take the form of a "but" statement contradicting or complicating the content of the earlier lines. In the Petrarchan sonnet, the turn tends to fall around the division between the first two quatrains and the sestet, while English sonnets usually place it at or near the beginning of the closing couplet.
Sonnets are particularly associated with high poetic diction, vivid imagery, and romantic love, largely due to the influence of Petrarch as well as of early English practitioners such as Edmund Spenser (who gave his name to the Spenserian sonnet), Michael Drayton, and Shakespeare, whose sonnets are among the most famous in English poetry, with twenty being included in the "Oxford Book of English Verse". However, the twists and turns associated with the "volta" allow for a logical flexibility applicable to many subjects. Poets from the earliest centuries of the sonnet to the present have utilized the form to address topics related to politics (John Milton, Percy Bysshe Shelley, Claude McKay), theology (John Donne, Gerard Manley Hopkins), war (Wilfred Owen, e. e. cummings), and gender and sexuality (Carol Ann Duffy). Further, postmodern authors such as Ted Berrigan and John Berryman have challenged the traditional definitions of the sonnet form, rendering entire sequences of "sonnets" that often lack rhyme, a clear logical progression, or even a consistent count of fourteen lines.
Shi.
"Shi" () Is the main type of Classical Chinese poetry. Within this form of poetry the most important variations are "folk song" styled verse ("yuefu"), "old style" verse ("gushi"), "modern style" verse ("jintishi"). In all cases, rhyming is obligatory. The Yuefu is a folk ballad or a poem written in the folk ballad style, and the number of lines and the length of the lines could be irregular. For the other variations of "shi" poetry, generally either a four line (quatrain, or "jueju") or else an eight line poem is normal; either way with the even numbered lines rhyming. The line length is scanned by according number of characters (according to the convention that one character equals one syllable), and are predominantly either five or seven characters long, with a caesura before the final three syllables. The lines are generally end-stopped, considered as a series of couplets, and exhibit verbal parallelism as a key poetic device. The "old style" verse ("gushi") is less formally strict than the "jintishi", or regulated verse, which, despite the name "new style" verse actually had its theoretical basis laid as far back to Shen Yue, in the 5th or 6th century, although not considered to have reached its full development until the time of Chen Zi'ang (661–702) A good example of a poet known for his "gushi" poems is Li Bai. Among its other rules, the jintishi rules regulate the tonal variations within a poem, including the use of set patterns of the four tones of Middle Chinese The basic form of jintishi (lushi) has eight lines in four couplets, with parallelism between the lines in the second and third couplets. The couplets with parallel lines contain contrasting content but an identical grammatical relationship between words. Jintishi often have a rich poetic diction, full of allusion, and can have a wide range of subject, including history and politics. One of the masters of the form was Du Fu, who wrote during the Tang Dynasty (8th century).
Villanelle.
The villanelle is a nineteen-line poem made up of five triplets with a closing quatrain; the poem is characterized by having two refrains, initially used in the first and third lines of the first stanza, and then alternately used at the close of each subsequent stanza until the final quatrain, which is concluded by the two refrains. The remaining lines of the poem have an a-b alternating rhyme. The villanelle has been used regularly in the English language since the late 19th century by such poets as Dylan Thomas, W. H. Auden, and Elizabeth Bishop.
Tanka.
Tanka is a form of unrhymed Japanese poetry, with five sections totalling 31 "onji" (phonological units identical to morae), structured in a 5-7-5-7-7 pattern. There is generally a shift in tone and subject matter between the upper 5-7-5 phrase and the lower 7-7 phrase. Tanka were written as early as the Asuka period by such poets as Kakinomoto no Hitomaro, at a time when Japan was emerging from a period where much of its poetry followed Chinese form. Tanka was originally the shorter form of Japanese formal poetry (which was generally referred to as "waka"), and was used more heavily to explore personal rather than public themes. By the tenth century, tanka had become the dominant form of Japanese poetry, to the point where the originally general term "waka" ("Japanese poetry") came to be used exclusively for tanka. Tanka are still widely written today.
Haiku.
Haiku is a popular form of unrhymed Japanese poetry, which evolved in the 17th century from the "hokku", or opening verse of a renku. Generally written in a single vertical line, the haiku contains three sections totalling 17 "onji", structured in a 5-7-5 pattern. Traditionally, haiku contain a kireji, or cutting word, usually placed at the end of one of the poem's three sections, and a kigo, or season-word. The most famous exponent of the haiku was Matsuo Bashō (1644–1694). An example of his writing:
Ode.
Odes were first developed by poets writing in ancient Greek, such as Pindar, and Latin, such as Horace. Forms of odes appear in many of the cultures that were influenced by the Greeks and Latins. The ode generally has three parts: a strophe, an antistrophe, and an epode. The antistrophes of the ode possess similar metrical structures and, depending on the tradition, similar rhyme structures. In contrast, the epode is written with a different scheme and structure. Odes have a formal poetic diction, and generally deal with a serious subject. The strophe and antistrophe look at the subject from different, often conflicting, perspectives, with the epode moving to a higher level to either view or resolve the underlying issues. Odes are often intended to be recited or sung by two choruses (or individuals), with the first reciting the strophe, the second the antistrophe, and both together the epode. Over time, differing forms for odes have developed with considerable variations in form and structure, but generally showing the original influence of the Pindaric or Horatian ode. One non-Western form which resembles the ode is the qasida in Persian poetry.
Ghazal.
The ghazal (also ghazel, gazel, gazal, or gozol) is a form of poetry common in Arabic, Persian, Turkish, Azerbaijani, Urdu and Bengali poetry. In classic form, the ghazal has from five to fifteen rhyming couplets that share a refrain at the end of the second line. This refrain may be of one or several syllables, and is preceded by a rhyme. Each line has an identical meter. The ghazal often reflects on a theme of unattainable love or divinity.
As with other forms with a long history in many languages, many variations have been developed, including forms with a quasi-musical poetic diction in Urdu. Ghazals have a classical affinity with Sufism, and a number of major Sufi religious works are written in ghazal form. The relatively steady meter and the use of the refrain produce an incantatory effect, which complements Sufi mystical themes well. Among the masters of the form is Rumi, a 13th-century Persian poet.
One of the most famous poet in this type of poetry is Hafez. Themes of his Ghazal is exposing hypocrisy. His life and poems have been the subject of much analysis, commentary and interpretation, influencing post-fourteenth century Persian writing more than any other author. West-östlicher Diwan of Johann Wolfgang von Goethe that is a collection of lyrical poems, has been inspired by the Persian poet Hafez.
Genres.
In addition to specific forms of poems, poetry is often thought of in terms of different genres and subgenres. A poetic genre is generally a tradition or classification of poetry based on the subject matter, style, or other broader literary characteristics. Some commentators view genres as natural forms of literature. Others view the study of genres as the study of how different works relate and refer to other works.
Narrative poetry.
Narrative poetry is a genre of poetry that tells a story. Broadly it subsumes epic poetry, but the term "narrative poetry" is often reserved for smaller works, generally with more appeal to human interest. Narrative poetry may be the oldest type of poetry. Many scholars of Homer have concluded that his "Iliad" and "Odyssey" were composed from compilations of shorter narrative poems that related individual episodes. Much narrative poetry—such as Scottish and English ballads, and Baltic and Slavic heroic poems—is performance poetry with roots in a preliterate oral tradition. It has been speculated that some features that distinguish poetry from prose, such as meter, alliteration and kennings, once served as memory aids for bards who recited traditional tales.
Notable narrative poets have included Ovid, Dante, Juan Ruiz, Chaucer, William Langland, Luís de Camões, Shakespeare, Alexander Pope, Robert Burns, Fernando de Rojas, Adam Mickiewicz, Alexander Pushkin, Edgar Allan Poe and Alfred Tennyson.
Epic poetry.
Epic poetry is a genre of poetry, and a major form of narrative literature. This genre is often defined as lengthy poems concerning events of a heroic or important nature to the culture of the time. It recounts, in a continuous narrative, the life and works of a heroic or mythological person or group of persons. Examples of epic poems are Homer's "Iliad" and "Odyssey", Virgil's Aeneid, the "Nibelungenlied", Luís de Camões' "Os Lusíadas", the "Cantar de Mio Cid", the "Epic of Gilgamesh", the "Mahabharata", Valmiki's "Ramayana", Ferdowsi's "Shahnama", Nizami (or Nezami)'s Khamse (Five Books), and the "Epic of King Gesar". While the composition of epic poetry, and of long poems generally, became less common in the west after the early 20th century, some notable epics have continued to be written. Derek Walcott won a Nobel prize to a great extent on the basis of his epic, "Omeros".
Dramatic poetry.
Dramatic poetry is drama written in verse to be spoken or sung, and appears in varying, sometimes related forms in many cultures. Greek tragedy in verse dates to the 6th century B.C., and may have been an influence on the development of Sanskrit drama, just as Indian drama in turn appears to have influenced the development of the "bianwen" verse dramas in China, forerunners of Chinese Opera. East Asian verse dramas also include Japanese Noh. Examples of dramatic poetry in Persian literature include Nizami's two famous dramatic works, "Layla and Majnun" and "Khosrow and Shirin", Ferdowsi's tragedies such as "Rostam and Sohrab", Rumi's "Masnavi", Gorgani's tragedy of "Vis and Ramin", and Vahshi's tragedy of "Farhad".
Satirical poetry.
Poetry can be a powerful vehicle for satire. The Romans had a strong tradition of satirical poetry, often written for political purposes. A notable example is the Roman poet Juvenal's satires.
The same is true of the English satirical tradition. John Dryden (a Tory), the first Poet Laureate, produced in 1682 "Mac Flecknoe", subtitled "A Satire on the True Blue Protestant Poet, T.S." (a reference to Thomas Shadwell). Another master of 17th-century English satirical poetry was John Wilmot, 2nd Earl of Rochester. Satirical poets outside England include Poland's Ignacy Krasicki, Azerbaijan's Sabir and Portugal's Manuel Maria Barbosa du Bocage.
Light poetry.
Light poetry, or light verse, is poetry that attempts to be humorous. Poems considered "light" are usually brief, and can be on a frivolous or serious subject, and often feature word play, including puns, adventurous rhyme and heavy alliteration. Although a few free verse poets have excelled at light verse outside the formal verse tradition, light verse in English is usually formal. Common forms include the limerick, the clerihew, and the double dactyl.
While light poetry is sometimes condemned as doggerel, or thought of as poetry composed casually, humor often makes a serious point in a subtle or subversive way. Many of the most renowned "serious" poets have also excelled at light verse. Notable writers of light poetry include Lewis Carroll, Ogden Nash, X. J. Kennedy, Willard R. Espy, and Wendy Cope.
Lyric poetry.
Lyric poetry is a genre that, unlike epic and dramatic poetry, does not attempt to tell a story but instead is of a more personal nature. Poems in this genre tend to be shorter, melodic, and contemplative. Rather than depicting characters and actions, it portrays the poet's own feelings, states of mind, and perceptions. Notable poets in this genre include John Donne, Gerard Manley Hopkins, and Antonio Machado.
Elegy.
An elegy is a mournful, melancholy or plaintive poem, especially a lament for the dead or a funeral song. The term "elegy," which originally denoted a type of poetic meter (elegiac meter), commonly describes a poem of mourning. An elegy may also reflect something that seems to the author to be strange or mysterious. The elegy, as a reflection on a death, on a sorrow more generally, or on something mysterious, may be classified as a form of lyric poetry.
Notable practitioners of elegiac poetry have included Propertius, Jorge Manrique, Jan Kochanowski, Chidiock Tichborne, Edmund Spenser, Ben Jonson, John Milton, Thomas Gray, Charlotte Turner Smith, William Cullen Bryant, Percy Bysshe Shelley, Johann Wolfgang von Goethe, Evgeny Baratynsky, Alfred Tennyson, Walt Whitman, Louis Gallet, Antonio Machado, Juan Ramón Jiménez, Giannina Braschi, William Butler Yeats, Rainer Maria Rilke, and Virginia Woolf.
Verse fable.
The fable is an ancient literary genre, often (though not invariably) set in verse. It is a succinct story that features anthropomorphized animals, plants, inanimate objects, or forces of nature that illustrate a moral lesson (a "moral"). Verse fables have used a variety of meter and rhyme patterns.
Notable verse fabulists have included Aesop, Vishnu Sarma, Phaedrus, Marie de France, Robert Henryson, Biernat of Lublin, Jean de La Fontaine, Ignacy Krasicki, Félix María de Samaniego, Tomás de Iriarte, Ivan Krylov and Ambrose Bierce.
Prose poetry.
Prose poetry is a hybrid genre that shows attributes of both prose and poetry. It may be indistinguishable from the micro-story ( the "short short story", "flash fiction"). While some examples of earlier prose strike modern readers as poetic, prose poetry is commonly regarded as having originated in 19th-century France, where its practitioners included Aloysius Bertrand, Charles Baudelaire, Arthur Rimbaud and Stéphane Mallarmé. Since the late 1980s especially, prose poetry has gained increasing popularity, with entire journals, such as "The Prose Poem: An International Journal", "Contemporary Haibun Online," and "Haibun Today" devoted to that genre and its hybrids. Latin American poets of the 20th century who wrote prose poems include Octavio Paz and Giannina Braschi
Speculative poetry.
Speculative poetry, also known as fantastic poetry, (of which weird or macabre poetry is a major subclassification), is a poetic genre which deals thematically with subjects which are 'beyond reality', whether via extrapolation as in science fiction or via weird and horrific themes as in horror fiction. Such poetry appears regularly in modern science fiction and horror fiction magazines. Edgar Allan Poe is sometimes seen as the "father of speculative poetry".

</doc>
<doc id="22934" url="https://en.wikipedia.org/wiki?curid=22934" title="Probability">
Probability

Probability is the measure of the likelihood that an event will occur. Probability is quantified as a number between 0 and 1 (where 0 indicates impossibility and 1 indicates certainty). The higher the probability of an event, the more certain we are that the event will occur. A simple example is the tossing of a fair (unbiased) coin. Since the coin is unbiased, the two outcomes ("head" and "tail") are equally probable; the probability of "head" equals the probability of "tail." Since no other outcome is possible, the probability is 1/2 (or 50%) of either "head" or "tail". In other words, the probability of "head" is 1 out of 2 outcomes and the probability of "tail" is also, 1 out of 2 outcomes.
These concepts have been given an axiomatic mathematical formalization in probability theory (see probability axioms), which is used widely in such areas of study as mathematics, statistics, finance, gambling, science (in particular physics), artificial intelligence/machine learning, computer science, game theory, and philosophy to, for example, draw inferences about the expected frequency of events. Probability theory is also used to describe the underlying mechanics and regularities of complex systems.
Interpretations.
When dealing with experiments that are random and well-defined in a purely theoretical setting (like tossing a fair coin), probabilities can be numerically described by the number of desired outcomes divided by the total number of all outcomes. For example, tossing a fair coin twice will yield "head-head", "head-tail", "tail-head", and "tail-tail" outcomes. The probability of getting an outcome of "head-head" is 1 out of 4 outcomes or 1 divided by four or 1/4 (or 25%). When it comes to practical application however, there are two major competing categories of probability interpretations, whose adherents possess different views about the fundamental nature of probability:
Etymology.
The word "probability" derives from the Latin "probabilitas", which can also mean "probity", a measure of the authority of a witness in a legal case in Europe, and often correlated with the witness's nobility. In a sense, this differs much from the modern meaning of "probability", which, in contrast, is a measure of the weight of empirical evidence, and is arrived at from inductive reasoning and statistical inference.
History.
The scientific study of probability is a modern development of mathematics. Gambling shows that there has been an interest in quantifying the ideas of probability for millennia, but exact mathematical descriptions arose much later. There are reasons of course, for the slow development of the mathematics of probability. Whereas games of chance provided the impetus for the mathematical study of probability, are still obscured by the superstitions of gamblers.
According to Richard Jeffrey, "Before the middle of the seventeenth century, the term 'probable' (Latin "probabilis") meant "approvable", and was applied in that sense, univocally, to opinion and to action. A probable action or opinion was one such as sensible people would undertake or hold, in the circumstances." However, in legal contexts especially, 'probable' could also apply to propositions for which there was good evidence.
The sixteenth century Italian polymath Gerolamo Cardano demonstrated the efficacy of defining odds as the ratio of favourable to unfavourable outcomes (which implies that the probability of an event is given by the ratio of favourable outcomes to the total number of possible outcomes).
Aside from the elementary work by Cardano, the doctrine of probabilities dates to the correspondence of Pierre de Fermat and Blaise Pascal (1654). Christiaan Huygens (1657) gave the earliest known scientific treatment of the subject. Jakob Bernoulli's "Ars Conjectandi" (posthumous, 1713) and Abraham de Moivre's "Doctrine of Chances" (1718) treated the subject as a branch of mathematics. See Ian Hacking's "The Emergence of Probability" and James Franklin's "The Science of Conjecture" for histories of the early development of the very concept of mathematical probability.
The theory of errors may be traced back to Roger Cotes's "Opera Miscellanea" (posthumous, 1722), but a memoir prepared by Thomas Simpson in 1755 (printed 1756) first applied the theory to the discussion of errors of observation. The reprint (1757) of this memoir lays down the axioms that positive and negative errors are equally probable, and that certain assignable limits define the range of all errors. Simpson also discusses continuous errors and describes a probability curve.
The first two laws of error that were proposed both originated with Pierre-Simon Laplace. The first law was published in 1774 and stated that the frequency of an error could be expressed as an exponential function of the numerical magnitude of the error, disregarding sign. The second law of error was proposed in 1778 by Laplace and stated that the frequency of the error is an exponential function of the square of the error. The second law of error is called the normal distribution or the Gauss law. "It is difficult historically to attribute that law to Gauss, who in spite of his well-known precocity had probably not made this discovery before he was two years old."
Daniel Bernoulli (1778) introduced the principle of the maximum product of the probabilities of a system of concurrent errors.
Adrien-Marie Legendre (1805) developed the method of least squares, and introduced it in his "Nouvelles méthodes pour la détermination des orbites des comètes" ("New Methods for Determining the Orbits of Comets"). In ignorance of Legendre's contribution, an Irish-American writer, Robert Adrain, editor of "The Analyst" (1808), first deduced the law of facility of error,
where formula_2 is a constant depending on precision of observation, and formula_3 is a scale factor ensuring that the area under the curve equals 1. He gave two proofs, the second being essentially the same as John Herschel's (1850). Gauss gave the first proof that seems to have been known in Europe (the third after Adrain's) in 1809. Further proofs were given by Laplace (1810, 1812), Gauss (1823), James Ivory (1825, 1826), Hagen (1837), Friedrich Bessel (1838), W. F. Donkin (1844, 1856), and Morgan Crofton (1870). Other contributors were Ellis (1844), De Morgan (1864), Glaisher (1872), and Giovanni Schiaparelli (1875). Peters's (1856) formula for "r", the probable error of a single observation, is well known.
In the nineteenth century authors on the general theory included Laplace, Sylvestre Lacroix (1816), Littrow (1833), Adolphe Quetelet (1853), Richard Dedekind (1860), Helmert (1872), Hermann Laurent (1873), Liagre, Didion, and Karl Pearson. Augustus De Morgan and George Boole improved the exposition of the theory.
Andrey Markov introduced the notion of Markov chains (1906), which played an important role in stochastic processes theory and its applications. The modern theory of probability based on the measure theory was developed by Andrey Kolmogorov (1931).
On the geometric side (see integral geometry) contributors to "The Educational Times" were influential (Miller, Crofton, McColl, Wolstenholme, Watson, and Artemas Martin).
Theory.
Like other theories, the theory of probability is a representation of probabilistic concepts in formal terms—that is, in terms that can be considered separately from their meaning. These formal terms are manipulated by the rules of mathematics and logic, and any results are interpreted or translated back into the problem domain.
There have been at least two successful attempts to formalize probability, namely the Kolmogorov formulation and the Cox formulation. In Kolmogorov's formulation (see probability space), sets are interpreted as events and probability itself as a measure on a class of sets. In Cox's theorem, probability is taken as a primitive (that is, not further analyzed) and the emphasis is on constructing a consistent assignment of probability values to propositions. In both cases, the laws of probability are the same, except for technical details.
There are other methods for quantifying uncertainty, such as the Dempster–Shafer theory or possibility theory, but those are essentially different and not compatible with the laws of probability as usually understood.
Applications.
Probability theory is applied in everyday life in risk assessment and in trade on financial markets. Governments apply probabilistic methods in environmental regulation, where it is called pathway analysis.
A good example is the effect of the perceived probability of any widespread Middle East conflict on oil prices—which have ripple effects in the economy as a whole. An assessment by a commodity trader that a war is more likely vs. less likely sends prices up or down, and signals other traders of that opinion. Accordingly, the probabilities are neither assessed independently nor necessarily very rationally. The theory of behavioral finance emerged to describe the effect of such groupthink on pricing, on policy, and on peace and conflict.
In addition to financial assessment, probability can be used to analyze trends in biology (e.g. disease spread) as well as ecology (e.g. biological Punnett squares). As with finance, risk assessment can be used as a statistical tool to calculate the likelihood of undesirable events occurring and can assist with implementing protocols to avoid encountering such circumstances.
The discovery of rigorous methods to assess and combine probability assessments has changed society. It is important for most citizens to understand how probability assessments are made, and how they contribute to decisions.
Another significant application of probability theory in everyday life is reliability. Many consumer products, such as automobiles and consumer electronics, use reliability theory in product design to reduce the probability of failure. Failure probability may influence a manufacturer's decisions on a product's warranty.
The cache language model and other statistical language models that are used in natural language processing are also examples of applications of probability theory.
Mathematical treatment.
Consider an experiment that can produce a number of results. The collection of all possible results is called the sample space of the experiment. The power set of the sample space is formed by considering all different collections of possible results. For example, rolling a dice can produce six possible results. One collection of possible results gives an odd number on the dice. Thus, the subset {1,3,5} is an element of the power set of the sample space of dice rolls. These collections are called "events." In this case, {1,3,5} is the event that the dice falls on some odd number. If the results that actually occur fall in a given event, the event is said to have occurred.
A probability is a way of assigning every event a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) is assigned a value of one. To qualify as a probability, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events with no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that at least one of the events will occur is given by the sum of the probabilities of all the individual events.
The probability of an event "A" is written as formula_4, formula_5, or formula_6. This mathematical definition of probability can extend to infinite sample spaces, and even uncountable sample spaces, using the concept of a measure.
The "opposite" or "complement" of an event "A" is the event "A" (that is, the event of "A" not occurring), often denoted as formula_7, or formula_8; its probability is given by . As an example, the chance of not rolling a six on a six-sided die is formula_9. See Complementary event for a more complete treatment.
If two events "A" and "B" occur on a single performance of an experiment, this is called the intersection or joint probability of "A" and "B", denoted as formula_10.
Independent events.
If two events, "A" and "B" are independent then the joint probability is
for example, if two coins are flipped the chance of both being heads is formula_12.
Mutually exclusive events.
If either event "A" or event "B" occurs on a single performance of an experiment this is called the union of the events "A" and "B" denoted as formula_13.
If two events are mutually exclusive then the probability of either occurring is
For example, the chance of rolling a 1 or 2 on a six-sided is formula_15
Not mutually exclusive events.
If the events are not mutually exclusive then
For example, when drawing a single card at random from a regular deck of cards, the chance of getting a heart or a face card (J,Q,K) (or one that is both) is formula_17, because of the 52 cards of a deck 13 are hearts, 12 are face cards, and 3 are both: here the possibilities included in the "3 that are both" are included in each of the "13 hearts" and the "12 face cards" but should only be counted once.
Conditional probability.
"Conditional probability" is the probability of some event "A", given the occurrence of some other event "B".
Conditional probability is written formula_18, and is read "the probability of "A", given "B"". It is defined by
If formula_20 then formula_18 is formally undefined by this expression. However, it is possible to define a conditional probability for some zero-probability events using a σ-algebra of such events (such as those arising from a continuous random variable).
For example, in a bag of 2 red balls and 2 blue balls (4 balls in total), the probability of taking a red ball is formula_22; however, when taking a second ball, the probability of it being either a red ball or a blue ball depends on the ball previously taken, such as, if a red ball was taken, the probability of picking a red ball again would be formula_23 since only 1 red and 2 blue balls would have been remaining.
Inverse probability.
In probability theory and applications, Bayes' rule relates the odds of event formula_24 to event formula_25, before (prior to) and after (posterior to) conditioning on another event formula_26. The odds on formula_24 to event formula_25 is simply the ratio of the probabilities of the two events. When arbitrarily many events formula_29 are of interest, not just two, the rule can be rephrased as posterior is proportional to prior times likelihood, formula_30 where the proportionality symbol means that the left hand side is proportional to (i.e., equals a constant times) the right hand side as formula_29 varies, for fixed or given formula_26 (Lee, 2012; Bertsch McGrayne, 2012). In this form it goes back to Laplace (1774) and to Cournot (1843); see Fienberg (2005). See Inverse probability and Bayes' rule.
Relation to randomness.
In a deterministic universe, based on Newtonian concepts, there would be no probability if all conditions were known (Laplace's demon), (but there are situations in which sensitivity to initial conditions exceeds our ability to measure them, i.e. know them). In the case of a roulette wheel, if the force of the hand and the period of that force are known, the number on which the ball will stop would be a certainty (though as a practical matter, this would likely be true only of a roulette wheel that had not been exactly levelled — as Thomas A. Bass' Newtonian Casino revealed). Of course, this also assumes knowledge of inertia and friction of the wheel, weight, smoothness and roundness of the ball, variations in hand speed during the turning and so forth. A probabilistic description can thus be more useful than Newtonian mechanics for analyzing the pattern of outcomes of repeated rolls of a roulette wheel. Physicists face the same situation in kinetic theory of gases, where the system, while deterministic "in principle", is so complex (with the number of molecules typically the order of magnitude of Avogadro constant 6.02·1023) that only a statistical description of its properties is feasible.
Probability theory is required to describe quantum phenomena. A revolutionary discovery of early 20th century physics was the random character of all physical processes that occur at sub-atomic scales and are governed by the laws of quantum mechanics. The objective wave function evolves deterministically but, according to the Copenhagen interpretation, it deals with probabilities of observing, the outcome being explained by a wave function collapse when an observation is made. However, the loss of determinism for the sake of instrumentalism did not meet with universal approval. Albert Einstein famously remarked in a letter to Max Born: "I am convinced that God does not play dice". Like Einstein, Erwin Schrödinger, who discovered the wave function, believed quantum mechanics is a statistical approximation of an underlying deterministic reality. In modern interpretations, quantum decoherence accounts for subjectively probabilistic behavior.

</doc>
<doc id="22936" url="https://en.wikipedia.org/wiki?curid=22936" title="Poland">
Poland

Poland ( ), officially the Republic of Poland (, ), is a country in Central Europe, bordered by Germany to the west; the Czech Republic and Slovakia to the south; Ukraine and Belarus to the east; and the Baltic Sea, Kaliningrad Oblast (a Russian exclave) and Lithuania to the north. The total area of Poland is , making it the 69th largest country in the world and the 9th largest in Europe. With a population of over 38.5 million people, Poland is the 34th most populous country in the world, the 8th most populous country in Europe and the sixth most populous member of the European Union, as well as the most populous post-communist member of the European Union. Poland is a unitary state divided into 16 administrative subdivisions.
The establishment of a Polish state can be traced back to 966, when Mieszko I, ruler of a territory roughly coextensive with that of present-day Poland, converted to Christianity. The Kingdom of Poland was founded in 1025, and in 1569 it cemented a longstanding political association with the Grand Duchy of Lithuania by signing the Union of Lublin. This union formed the Polish–Lithuanian Commonwealth, one of the largest and most populous countries of 16th and 17th-century Europe. The Commonwealth ceased to exist in the years 1772–1795, when its territory was partitioned among Prussia, the Russian Empire, and Austria. Poland regained its independence (as the Second Polish Republic) at the end of World War I, in 1918.
In September 1939, World War II started with the invasions of Poland by Nazi Germany and the Soviet Union (as part of the Molotov–Ribbentrop Pact). More than six million Polish citizens died in the war. In 1944, a Soviet-backed Polish Committee of National Liberation was formed which, after a falsified referendum in 1947 took control of the country and Poland became a satellite state of the Soviet Union, as People's Republic of Poland. During the Revolutions of 1989 Poland's Communist government was overthrown and Poland adopted a new constitution establishing itself as a democracy.
Despite the large number of casualties and destruction the country experienced during World War II, Poland managed to preserve much of its cultural wealth. There are 14 heritage sites inscribed on the UNESCO World Heritage and 54 Historical Monuments and many objects of cultural heritage in Poland.
Since the beginning of the transition to a primarily market-based economy that took place in the early 1990s, Poland has achieved a "very high" ranking on the Human Development Index, as well as gradually improving economic freedom. Poland is a democratic country with an advanced high-income economy, a high quality of life and a very high standard of living. Moreover, the country is visited by nearly 16 million tourists every year (2013), which makes it one of the most visited countries in the world. Poland is the sixth largest economy in the European Union and among the fastest rising economic states in the world. The country is the sole member nation of the European Union to have escaped a decline in GDP and in recent years was able to "create probably the most varied GDP growth in its history" according to OANDA, a Canadian-based foreign exchange company. Furthermore, according to the Global Peace Index for 2014, Poland is one of the safest countries in the world to live in.
Etymology.
The source of the name Poland and the ethnonyms for the Poles include endonyms (the way Polish people refer to themselves and their country) and exonyms (the way other peoples refer to the Poles and their country). Endonyms and most exonyms for Poles and Poland derive from the name of the West Slavic tribe of the Polans ("Polanie").
The origin of the name "Polanie" itself is uncertain. It may derive from such Polish words as "pole" (field). The early tribal inhabitants denominated it from the nature of the country. Lowlands and low hills predominate throughout the vast region from the Baltic shores to the foothills of the Carpathian Mountains. "Between the Alps, Hungary, and the ocean, lies Poland, which is called in their native tongue Campania" () is the description by Gervase of Tilbury in his "Otia imperialia" ("Recreation for the Emperor") of 1211. In some languages, the exonyms for Poland derive from another tribal name, Lechites ("Lechici").
History.
Prehistory and protohistory.
Historians have postulated that throughout Late Antiquity, many distinct ethnic groups populated the regions of what is now Poland. The ethnicity and linguistic affiliation of these groups have been hotly debated; the time and route of the original settlement of Slavic peoples in these regions lacks written records and can only be defined as fragmented.
The most famous archaeological find from the prehistory and protohistory of Poland is the Biskupin fortified settlement (now reconstructed as an open-air museum), dating from the Lusatian culture of the early Iron Age, around 700 BC. The Slavic groups who would form Poland migrated to these areas in the second half of the 5th century AD. Up until the creation of Mieszko's state and his subsequent conversion to Christianity in 966 AD, the main religion of Slavic tribes that inhabited the geographical area of present-day Poland was Slavic paganism. With the Baptism of Poland the Polish rulers accepted the religious authority of the Roman Church. The transition to Christianity was not a smooth and instantaneous process for the rest of the population as evident from the pagan reaction of the 1030s.
Piast dynasty.
Poland began to form into a recognizable unitary and territorial entity around the middle of the 10th century under the Piast dynasty. Poland's first historically documented ruler, Mieszko I, accepted Baptism in 966 and adopted Christianity as the new official religion of his subjects. The bulk of the population converted in the course of the next few centuries. In 1000, Boleslaw the Brave, continuing the policy of his father Mieszko, held a Congress of Gniezno and created the metropolis of Gniezno and the dioceses of Kraków, Kołobrzeg, and Wrocław. The pagan unrest however, led to the transfer of the capital to Kraków in 1038 by Casimir I the Restorer.
Prince Bolesław III Wrymouth defeated the King of Germany Henry V in the 1109 Battle of Hundsfeld, writes Gallus Anonymus in his 1118 chronicle. In 1138, Poland fragmented into several smaller duchies when Bolesław divided his lands among his sons. In 1226, Konrad I of Masovia, one of the regional Piast dukes, invited the Teutonic Knights to help him fight the Baltic Prussian pagans; a decision which led to centuries of warfare with the Knights. Elements of what is called now human rights may be found in early times of the Polish state. The Statute of Kalisz or the General Charter of Jewish Liberties (issued in 1264) introduced numerous right for the Jews in Poland, leading to a nearly autonomous "nation within a nation".
In the middle of 13th-century the Silesian branch of the Piast dynasty (Henry I the Bearded and Henry II the Pious, ruled 1238–1241) almost succeeded in uniting the Polish lands, but the Mongols devastated the country and won the Battle of Legnica where Duke Henry II the Pious died (1241). In 1320, after a number of earlier unsuccessful attempts by regional rulers at uniting the Polish dukedoms, Władysław I consolidated his power, took the throne and became the first king of a reunified Poland. His son, Casimir III (reigned 1333–1370), has a reputation as one of the greatest Polish kings, and gained wide recognition for improving the country's infrastructure. Casimir also extended royal protection to Jews, and encouraged their immigration to Poland.
The education of Polish society was a goal of rulers as early as the 12th century, and Polish nobility became one of the most educated groups in Europe. The library catalogue of the Cathedral Chapter of Kraków dating back to 1110 shows that in the early 12th-century Polish intellectuals had access to European literature.
Casimir III realized that the nation needed a class of educated people, especially lawyers, who could codify the country's laws and administer the courts and offices. His efforts to found an institution of higher learning in Poland were finally rewarded when Pope Urban V granted him permission to open the University of Kraków.
The Golden Liberty of the nobles began to develop under Casimir's rule, when in return for their military support, the king made serious concessions to the aristocrats, finally establishing their status as superior to that of the townsmen, and aiding their rise to power. When Casimir died in 1370 he left no legitimate male heir and, considering his other male descendants either too young or unsuitable, was laid to rest as the last of the nation's Piast rulers.
Poland also became a destination for German, Flemish and to a lesser extent Scottish, Danish and Walloon migrants. The Jewish community also began to settle and flourish in Poland during this era (see History of the Jews in Poland); the same applies in smaller number to Armenians. The Black Death which afflicted most parts of Europe from 1347 to 1351 affected Poland less severely.
Jagiellon dynasty.
The rule of the Jagiellon dynasty spanned the late Middle Ages and early Modern Era of Polish history. Beginning with the Lithuanian Grand Duke Jogaila (Władysław II Jagiełło), the Jagiellon dynasty (1386–1572) formed the Polish–Lithuanian union. The partnership brought vast Lithuania-controlled Rus' areas into Poland's sphere of influence and proved beneficial for the Poles and Lithuanians, who coexisted and cooperated in one of the largest political entities in Europe for the next four centuries. In the Baltic Sea region Poland's struggle with the Teutonic Knights continued and included the Battle of Grunwald (1410), where a Polish-Lithuanian army inflicted a decisive defeat on the Teutonic Knights, both countries' main adversary, allowing Poland's and Lithuania's territorial expansion into the far north region of Livonia. In 1466, after the Thirteen Years' War, King Casimir IV Jagiellon gave royal consent to the milestone Peace of Thorn, which created the future Duchy of Prussia, a Polish vassal. The Jagiellons at one point also established dynastic control over the kingdoms of Bohemia (1471 onwards) and Hungary. In the south Poland confronted the Ottoman Empire and the Crimean Tatars (by whom they were attacked on 75 separate occasions between 1474 and 1569), and in the east helped Lithuania fight the Grand Duchy of Moscow. Some historians estimate that Crimean Tatar slave-raiding cost Poland one million of its population from 1494 to 1694.
Poland was developing as a feudal state, with a predominantly agricultural economy and an increasingly powerful landed nobility. The "Nihil novi" act adopted by the Polish Sejm (parliament) in 1505, transferred most of the legislative power from the monarch to the Sejm, an event which marked the beginning of the period known as "Golden Liberty", when the state was ruled by the "free and equal" Polish nobility. Protestant Reformation movements made deep inroads into Polish Christianity, which resulted in the establishment of policies promoting religious tolerance, unique in Europe at that time. This tolerance allowed the country to avoid most the religious turmoil that spread over Europe during the late Middle Ages. The European Renaissance evoked in late Jagiellon Poland (kings Sigismund I the Old and Sigismund II Augustus) a sense of urgency in the need to promote a cultural awakening, and during this period Polish culture and the nation's economy flourished. In 1543 the Pole, Nicolaus Copernicus, an astronomer from Toruń, published his epochal works, "De revolutionibus orbium coelestium" ("On the Revolutions of the Celestial Spheres"), and thus became the first proponent of a predictive mathematical model confirming heliocentric theory which became the accepted basic model for the practice of modern astronomy. Another major figure associated with the era is classicist poet Jan Kochanowski.
Polish–Lithuanian Commonwealth.
The 1569 Union of Lublin established the Polish–Lithuanian Commonwealth, a more closely unified federal state with an elective monarchy, but which was governed largely by the nobility, through a system of local assemblies with a central parliament. The Warsaw Confederation (1573) confirmed the religious freedom of all residents of Poland, which was extremely important for the stability of the multiethnic Polish society of the time. The establishment of the Commonwealth coincided with a period of stability and prosperity in Poland, with the union thereafter becoming a European power and a major cultural entity, occupying approximately one million square kilometers of Central and Eastern Europe, as well as an agent for the dissemination of 'Western culture' through Polonization in modern-day Ukraine, Belarus and Western Russia. Poland suffered from a number of dynastic crises during the reigns of the Vasa kings Sigismund III and Władysław IV and found itself engaged in major conflicts with Russia, Sweden and the Ottoman Empire, as well as a series of minor Cossack uprisings. In 1610 Hetman Stanisław Żółkiewski seized Moscow after winning the Battle of Klushino.
From the middle of the 17th century, the nobles' democracy, suffering from internal disorder, gradually declined, thus leaving the once powerful Commonwealth vulnerable to foreign intervention. Starting in 1648, the Cossack Khmelnytsky Uprising engulfed the south and east eventually leaving Ukraine divided, with the eastern part, lost by the Commonwealth, becoming a dependency of the Tsardom of Russia. This was followed by the 'Deluge', a Swedish invasion, which marched through the Polish heartlands and ruined Poland's population, culture and infrastructure. Around four million of Poland's eleven million population died in famines and epidemics in this period. However, under John III Sobieski the Commonwealth's military prowess was re-established, and in 1683 Polish forces played a major part in relieving Vienna of a Turkish siege which was being conducted by Kara Mustafa.
Sobieski's reign marked the end of the nation's golden-era. Finding itself subjected to almost constant warfare and suffering enormous population losses as well as massive damage to its economy, the Commonwealth fell into decline. The government became ineffective as a result of large-scale internal conflicts (e.g. Lubomirski Rebellion against John II Casimir and rebellious confederations) and corrupted legislative processes. The nobility fell under the control of a handful of "magnats", and this, compounded with two relatively weak kings of the Saxon Wettin dynasty, Augustus II and Augustus III, as well as the rise of Russia and Prussia after the Great Northern War only served to worsen the Commonwealth's plight. Despite this The Commonwealth-Saxony personal union gave rise to the emergence of the Commonwealth's first reform movement, and laid the foundations for the Polish Enlightenment.
During the later part of the 18th century, the Commonwealth made attempts to implement fundamental internal reforms; with the second half of the century bringing a much improved economy, significant population growth and far-reaching progress in the areas of education, intellectual life, art, and especially toward the end of the period, evolution of the social and political system. The most populous capital city of Warsaw replaced Gdańsk (Danzig) as the leading centre of commerce, and the role of the more prosperous townsfolk increased.
The Age of Partitions.
The royal election of 1764 resulted in the elevation of Stanisław II August, a refined and worldly aristocrat connected to a major magnate faction, to the monarchy. However, a one-time lover of Empress Catherine II of Russia, the new king spent much of his reign torn between his desire to implement reforms necessary to save his nation, and his perceived necessity to remain in a relationship with his Russian sponsor. This led to the formation of the 1768 Bar Confederation, a "szlachta" rebellion directed against Russia and the Polish king that fought to preserve Poland's independence and the "szlachta"'s traditional privileges.
Attempts at reform provoked the union's neighbours, and in 1772 the First Partition of the Commonwealth by Russia, Austria and Prussia took place; an act which the "Partition Sejm", under considerable duress, eventually "ratified" "fait accompli". Disregarding this loss, in 1773 the king established the Commission of National Education, the first government education authority in Europe. Corporal punishment of children was officially prohibited in 1783 as first in the world at all schools.
The Great Sejm convened by Stanisław II August in 1788 successfully adopted the 3 May Constitution, the first set of modern supreme national laws in Europe. However, this document, accused by detractors of harbouring revolutionary sympathies, generated strong opposition from the Commonwealth's nobles and conservatives as well as from Catherine II, who, determined to prevent the rebirth of a strong Commonwealth set about planning the final dismemberment of the Polish-Lithuanian state. Russia was aided in achieving its goal when the Targowica Confederation, an organisation of Polish nobles, appealed to the Empress for help. In May 1792 Russian forces crossed the Commonwealth's frontier, thus beginning the Polish-Russian War.
The defensive war fought by the Poles ended prematurely when the King, convinced of the futility of resistance, capitulated and joined the Targowica Confederation. The Confederation then took over the government. Russia and Prussia, fearing the mere existence of a Polish state, arranged for, and in 1793 executed, the Second Partition of the Commonwealth, which left the country deprived of so much territory that it was practically incapable of independent existence. Eventually, in 1795, following the failed Kościuszko Uprising, the Commonwealth was partitioned one last time by all three of its more powerful neighbours, and with this, effectively ceased to exist.
Congress.
Poles rebelled several times against the partitioners, particularly near the end of the 18th century and the beginning of the 19th century. An unsuccessful attempt at defending Poland's sovereignty took place in 1794 during the Kościuszko Uprising, where a popular and distinguished general Tadeusz Kosciuszko, who had served under Washington in America, led Polish insurgents against numerically superior Russian forces. Despite the victory at the Battle of Racławice, his ultimate defeat ended Poland's independent existence for 123 years. In 1807, Napoleon I of France temporarily recreated a Polish state as a satellite Duchy of Warsaw, but after the failed Napoleonic Wars, Poland was again split between the victorious Allies at the Congress of Vienna of 1815. The eastern part was ruled by the Russian tsar as a Congress Kingdom, which had a very liberal constitution. However, the tsars reduced Polish freedoms, and Russia annexed the country in virtually all but name. Thus in the latter half of the 19th century, only Austrian-ruled Galicia, and particularly the Free City of Kraków, created good environment for free Polish cultural life to flourish.
Throughout the period of the partitions, political and cultural repression of the Polish nation led to the organisation of a number of uprisings against the authorities of the occupying Russian, Prussian and Austrian governments. Notable among these are the November Uprising of 1830 and January Uprising of 1863, both of which were attempts to free Poland from the rule of tsarist Russia. The November uprising began on 29 November 1830 in Warsaw when, led by Lieutenant Piotr Wysocki, young non-commissioned officers at the Imperial Russian Army's military academy in that city revolted. They were joined by large segments of Polish society, and together forced Warsaw's Russian garrison to withdraw north of the city.
Over the course of the next seven months, Polish forces successfully defeated the Russian armies of Field Marshal Hans Karl von Diebitsch and a number of other Russian commanders; however, finding themselves in a position unsupported by any other foreign powers, save distant France and the newborn United States, and with Prussia and Austria refusing to allow the import of military supplies through their territories, the Poles accepted that the uprising was doomed to failure. Upon the surrender of Warsaw to General Ivan Paskievich, many Polish troops, feeling they could not go on, withdrew into Germany and there laid down their arms. Poles would have to wait another 32 years for another opportunity to free their homeland.
When in January 1863 a new Polish uprising against Russian rule began, it did so as a spontaneous protest by young Poles against conscription into the Imperial Russian Army. However, the insurrectionists, despite being joined by high-ranking Polish-Lithuanian officers and numerous politicians, were still severely outnumbered and lacking in foreign support. They were forced to resort to guerrilla warfare tactics and failed to win any major military victories. Afterwards no major uprising was witnessed in the Russian-controlled Congress Poland, and Poles resorted instead to fostering economic and cultural self-improvement.
Despite the political unrest experienced during the partitions, Poland did benefit from large-scale industrialisation and modernisation programs, instituted by the occupying powers, which helped it develop into a more economically coherent and viable entity. This was particularly true in the Greater Poland, Pomerania and Warmia annexed by Prussia (later becoming a part of the German Empire); an area which eventually, thanks largely to the Greater Poland Uprising, was reconstituted as a part of the Second Polish Republic and became one of its most productive regions.
Reconstitution.
During World War I, all the Allies agreed on the reconstitution of Poland that United States President Woodrow Wilson proclaimed in Point 13 of his Fourteen Points. A total of 2 million Polish troops fought with the armies of the three occupying powers, and 450,000 died. Shortly after the armistice with Germany in November 1918, Poland regained its independence as the Second Polish Republic ("II Rzeczpospolita Polska"). It reaffirmed its independence after a series of military conflicts, the most notable being the Polish–Soviet War (1919–1921) when Poland inflicted a crushing defeat on the Red Army at the Battle of Warsaw, an event which is considered to have halted the advance of Communism into Europe and forced Vladimir Lenin to rethink his objective of achieving global socialism. Nowadays the event is often referred to as the "Miracle at the Vistula".
During this period, Poland successfully managed to fuse the territories of the three former partitioning powers into a cohesive nation state. Railways were restructured to direct traffic towards Warsaw instead of the former imperial capitals, a new network of national roads was gradually built up and a major seaport was opened on the Baltic Coast, so as to allow Polish exports and imports to bypass the politically charged Free City of Danzig.
The inter-war period heralded in a new era of Polish politics. Whilst Polish political activists had faced heavy censorship in the decades up until the First World War, the country now found itself trying to establish a new political tradition. For this reason, many exiled Polish activists, such as Ignacy Paderewski (who would later become Prime Minister) returned home to help; a significant number of them then went on to take key positions in the newly formed political and governmental structures. Tragedy struck in 1922 when Gabriel Narutowicz, inaugural holder of the Presidency, was assassinated at the Zachęta Gallery in Warsaw by painter and right-wing nationalist Eligiusz Niewiadomski.
The 1926 May Coup of Józef Piłsudski turned rule of the Second Polish Republic over to the Sanacja movement. By the 1930s Poland had become increasingly authoritarian; a number of 'undesirable' political parties, such as the Polish Communists, had been banned and following Piłsudski's death, the regime, unable to appoint a new leader, began to show its inherent internal weaknesses and unwillingness to cooperate in any way with other political parties.
As result of the Munich Agreement of 1 October 1938, Poland invaded and occupied the Zaolzie Region of Czechoslovakia.
World War II.
The formal beginning of World War II was marked by the Nazi German invasion of Poland on 1 September 1939, followed by the Soviet invasion of Poland on 17 September in violation of the Soviet–Polish Non-Aggression Pact. On 28 September 1939 Warsaw capitulated. As agreed earlier in the Molotov–Ribbentrop Pact, Poland was split into two occupied zones, one subdivided by Nazi Germany, while the other, including all of eastern Kresy fell under the control of the Soviet Union. In 1939–1941, the Soviets had deported hundreds of thousands of Poles out to the most distant parts of the Soviet Union. The Soviet NKVD secretly executed thousands of Polish prisoners of war (inter alia Katyn massacre) ahead of the Operation Barbarossa. German planners had in November 1939 called for "the complete destruction" of all Poles and their fate, as well as many other Slavs, was outlined in genocidal "Generalplan Ost".
All in all, Poland made the fourth-largest troop contribution to the Allied war effort, after the Soviets, the British, and the Americans. Polish troops fought under the command of both the Polish Government in Exile in the theatre of war west of Germany and under Soviet leadership in the theatre of war east of Germany. The Polish expeditionary corps, which was controlled by the exiled pre-war government based in London, played an important role in the Italian and North African Campaigns. They are particularly well remembered for their conduct at the Battle of Monte Cassino, a conflict which culminated in the raising of a Polish flag over the ruins of the mountain-top abbey by the 12th Podolian Uhlans. The Polish forces in the theatre of war east of Germany were commanded by Lieutenant General Władysław Anders who had received his command from Prime Minister of the exiled government Władysław Sikorski. On the east of Germany, the Soviet-backed Polish 1st Army distinguished itself in the battles for Berlin and Warsaw, although its actions in support of the latter have often been criticized.
Polish servicemen were also active in the theatres of naval and air warfare; during the Battle of Britain Polish squadrons such as the No. 303 "Kościuszko" fighter squadron achieved considerable success, and by the end of the war the exiled Polish Air Forces could claim 769 confirmed kills. Meanwhile, the Polish Navy was active in the protection of convoys in the North Sea and Atlantic Ocean.
In addition to the organised units of the 1st Army and the Forces in the Nazi-occupied Europe, the domestic underground resistance movement, the Armia Krajowa, or "Home Army", fought to free Poland from German occupation and establish an independent Polish state. The wartime resistance movement in Poland was one of the three largest resistance movements of the entire war, and encompassed an unusually broad range of clandestine activities, which essentially functioned as an underground state complete with degree-awarding universities and a court system. The resistance was, however, largely loyal to the exiled government and generally resented the idea of a communist Poland; for this reason, in the summer of 1944 they initiated Operation Tempest, of which the Warsaw Uprising that begun on 1 August 1944 was the best known operation. The objective of the uprising was to drive the German occupiers from the city and help with the larger fight against Germany and the Axis powers. However, secondary motives for the uprising sought to see Warsaw liberated before the Soviets could reach the capital, so as to underscore Polish sovereignty by empowering the Polish Underground State before the Soviet-backed Polish Committee of National Liberation could assume control. However, a lack of available allied military aid and Stalin's reluctance to allow the 1st Army to help their fellow countrymen take the city, led to the uprising's failure and subsequent planned destruction of the city.
During the war, German forces under direct order from Adolf Hitler set up six major extermination camps, all of which operated in the heart of Poland. They included the notorious Treblinka and Auschwitz killing grounds. This allowed the Germans to transport the condemned Jews away from public eye in the Third Reich or across occupied Europe and – under the guise of resettlement – murder them in the General Government and in brand new Warthegau among other annexed areas. The Nazi crimes against the Polish nation claimed the lives of 2.7 to 2.9 million Polish Jews, and 2.77 million ethnic Poles, including Polish intelligentsia, doctors, lawyers, nobility, priests and numerous others. Since 3,5 million Jews lived in pre-war Poland, Jewish victims make up the largest percentage of all victims of the Nazis' extermination program. It is estimated that, of pre-war Poland's Jewry, approximately 90% were killed. Throughout the occupation, many members of the Armia Krajowa, supported by the Polish government in exile, and millions of ordinary Poles – at great risk to themselves and their families – engaged in rescuing Jews from the Nazi Germans. Grouped by nationality, Poles represent the largest number of people who rescued Jews during the Holocaust. To date, 6,394 Poles have been awarded the title of "Righteous Among the Nations" by the State of Israel–more than any other nation. Some estimates put the number of Poles involved in rescue efforts at up to 3 million, and credit Poles with sheltering up to 450,000 Jews.
At the war's conclusion in 1945, Poland's borders were shifted westwards, resulting in considerable territorial losses. Most of the Polish inhabitants of Kresy were expelled along the Curzon Line in accordance with Stalin's agreements. The western border was moved to the Oder-Neisse line. As a result, Poland's territory was reduced by 20%, or . The shift forced the migration of millions of other people, most of whom were Poles, Germans, Ukrainians, and Jews. Of all the countries involved in the war, Poland lost the highest percentage of its citizens: over 6 million perished – nearly one-fifth of Poland's population — half of them Polish Jews. Over 90% of deaths were non-military in nature. Population numbers did not recover until the 1970s. An estimated 600,000 Soviet soldiers died in conquering Poland from German rule.
Postwar communism.
At the insistence of Joseph Stalin, the Yalta Conference sanctioned the formation of a new provisional pro-Communist coalition government in Moscow, which ignored the Polish government-in-exile based in London; a move which angered many Poles who considered it a betrayal by the Allies. In 1944, Stalin had made guarantees to Churchill and Roosevelt that he would maintain Poland's sovereignty and allow democratic elections to take place. However, upon achieving victory in 1945, the elections organized by the occupying Soviet authorities were falsified and were used to provide a veneer of 'legitimacy' for Soviet hegemony over Polish affairs. The Soviet Union instituted a new communist government in Poland, analogous to much of the rest of the Eastern Bloc. As elsewhere in Communist Europe the Soviet occupation of Poland met with armed resistance from the outset which continued into the fifties.
Despite widespread objections, the new Polish government accepted the Soviet annexation of the pre-war eastern regions of Poland (in particular the cities of Wilno and Lwów) and agreed to the permanent garrisoning of Red Army units on Poland's territory. Military alignment within the Warsaw Pact throughout the Cold War came about as a direct result of this change in Poland's political culture and in the European scene came to characterise the full-fledged integration of Poland into the brotherhood of communist nations.
The People's Republic of Poland ("Polska Rzeczpospolita Ludowa") was officially proclaimed in 1952. In 1956 after the death of Bolesław Bierut, the régime of Władysław Gomułka became temporarily more liberal, freeing many people from prison and expanding some personal freedoms. A similar situation repeated itself in the 1970s under Edward Gierek, but most of the time persecution of anti-communist opposition groups persisted. Despite this, Poland was at the time considered to be one of the least oppressive states of the Soviet Bloc.
Labour turmoil in 1980 led to the formation of the independent trade union "Solidarity" (""Solidarność""), which over time became a political force. Despite persecution and imposition of martial law in 1981, it eroded the dominance of the Polish United Workers' Party and by 1989 had triumphed in Poland's first partially free and democratic parliamentary elections since the end of the Second World War. Lech Wałęsa, a Solidarity candidate, eventually won the presidency in 1990. The Solidarity movement heralded the collapse of communist regimes and parties across Europe.
Present-day.
A shock therapy programme, initiated by Leszek Balcerowicz in the early 1990s enabled the country to transform its socialist-style planned economy into a market economy. As with other post-communist countries, Poland suffered slumps in social and economic standards, but it became the first post-communist country to reach its pre-1989 GDP levels, which it achieved by 1995 largely thanks to its booming economy.
Most visibly, there were numerous improvements in human rights, such as the freedom of speech, internet freedom (no censorship), civil liberties (1st class) and political rights (1st class), according to Freedom House. In 1991, Poland became a member of the Visegrád Group and joined the North Atlantic Treaty Organization (NATO) alliance in 1999 along with the Czech Republic and Hungary. Poles then voted to join the European Union in a referendum in June 2003, with Poland becoming a full member on 1 May 2004. Poland joined the Schengen Area in 2007, as a result of which, the country's borders with other member states of the European Union have been dismantled, allowing for full freedom of movement within most of the EU. In contrast to this, a section of Poland's eastern border now comprises the external EU border with Belarus, Russia and Ukraine. That border has become increasingly well protected, and has led in part to the coining of the phrase 'Fortress Europe', in reference to the seeming 'impossibility' of gaining entry to the EU for citizens of the former Soviet Union.
Poland has been one of the most prominent voices of establishing a common European Armed Forces, with Poland's Premier along with Chancellor Angela Merkel and President François Hollande (collectively also part of Weimar Triangle) taking steps to negotiate such a deal, in hope of drastically reducing dependence on NATO and increasing readiness. Poland has already built several commands of a common battle group with Hungary, Czech Republic and Slovakia, with a total of 12,000 troops ready for deployment. Poland is seeking to build more battle groups with Lithuania and Ukraine. These battle groups have vowed to serve under the European Union, and not NATO. Eurosceptics criticize such moves as further unnecessary integration and a new major step towards a federalized European Union under one government. Military integration is judged to be the most significant step after a monetary union.
On 10 April 2010, the President of the Republic of Poland, Lech Kaczyński, along with 89 other high-ranking Polish officials died in a plane crash near Smolensk, Russia. The president's party were on their way to attend an annual service of commemoration for the victims of the Katyń massacre when the tragedy took place.
In 2011, the Presidency of the Council of the European Union responsible for the functioning of the Council was awarded to Poland. The same year parliamentary elections took place to both the Senate and the Sejm. They were won by the ruling Civic Platform. Poland joined European Space Agency in 2012, as well as organised the UEFA Euro 2012 (along with Ukraine). In 2013, Poland also became a member of the Development Assistance Committee. In 2014 the Prime Minister of Poland, Donald Tusk, was elected President of the European Council.
Geography.
Poland's territory extends across several geographical regions, between latitudes 49° and 55° N, and longitudes 14° and 25° E. In the north-west is the Baltic seacoast, which extends from the Bay of Pomerania to the Gulf of Gdańsk. This coast is marked by several spits, coastal lakes (former bays that have been cut off from the sea), and dunes. The largely straight coastline is indented by the Szczecin Lagoon, the Bay of Puck, and the Vistula Lagoon. The centre and parts of the north lie within the North European Plain.
Rising above these lowlands is a geographical region comprising the four hilly districts of moraines and moraine-dammed lakes formed during and after the Pleistocene ice age. These lake districts are the Pomeranian Lake District, the Greater Polish Lake District, the Kashubian Lake District, and the Masurian Lake District. The Masurian Lake District is the largest of the four and covers much of north-eastern Poland. The lake districts form part of the Baltic Ridge, a series of moraine belts along the southern shore of the Baltic Sea.
South of the Northern European Lowlands lie the regions of Lusatia, Silesia and Masovia, which are marked by broad ice-age river valleys. Farther south lies the Polish mountain region, including the Sudetes, the Kraków-Częstochowa Upland, the Świętokrzyskie Mountains, and the Carpathian Mountains, including the Beskids. The highest part of the Carpathians is the Tatra Mountains, along Poland's southern border.
Geology.
The geological structure of Poland has been shaped by the continental collision of Europe and Africa over the past 60 million years and, more recently, by the Quaternary glaciations of northern Europe. Both processes shaped the Sudetes and the Carpathian Mountains. The moraine landscape of northern Poland contains soils made up mostly of sand or loam, while the ice age river valleys of the south often contain loess. The Kraków-Częstochowa Upland, the Pieniny, and the Western Tatras consist of limestone, while the High Tatras, the Beskids, and the Karkonosze are made up mainly of granite and basalts. The Polish Jura Chain is one of the oldest mountain ranges on earth.
Poland has 70 mountains over in elevation, all in the Tatras. The Polish Tatras, which consist of the High Tatras and the Western Tatras, is the highest mountain group of Poland and of the entire Carpathian range. In the High Tatras lies Poland's highest point, the north-western summit of Rysy, in elevation. At its foot lies the mountain lakes of Czarny Staw pod Rysami (Black Lake below Mount Rysy), and Morskie Oko (the Marine Eye).
The second highest mountain group in Poland is the Beskids, whose highest peak is Babia Góra, at . The next highest mountain groups is the Karkonosze in the Sudetes, whose highest point is Śnieżka, at ; Śnieżnik Mountains whose highest point is Śnieżnik, at .
Tourists also frequent the Bieszczady Mountains in the far southeast of Poland, whose highest point in Poland is Tarnica, with an elevation of , Gorce Mountains in Gorce National Park, whose highest point is Turbacz, with elevations , and the Pieniny in Pieniny National Park, whose highest point is Wysokie Skałki (Wysoka), with elevations . The lowest point in Poland – at below sea level – is at Raczki Elbląskie, near Elbląg in the Vistula Delta.
The only desert located in Poland stretches over the Zagłębie Dąbrowskie (the Coal Fields of Dąbrowa) region. It is called the Błędów Desert, located in the Silesian Voivodeship in southern Poland. It has a total area of . It is one of only five natural deserts in Europe. But also, it is the warmest desert that appears at this latitude.
The Baltic Sea activity in Słowiński National Park created sand dunes which in the course of time separated the bay from the sea creating two lakes. As waves and wind carry sand inland the dunes slowly move, at a rate of meters per year. Some dunes are quite high – up to . The highest peak of the park – Rowokol ( above sea level) — is also an excellent observation point.
Waters.
The longest rivers are the Vistula (), long; the Oder () which forms part of Poland's western border, long; its tributary, the Warta, long; and the Bug, a tributary of the Vistula, long. The Vistula and the Oder flow into the Baltic Sea, as do numerous smaller rivers in Pomerania.
The Łyna and the Angrapa flow by way of the Pregolya to the Baltic, and the Czarna Hańcza flows into the Baltic through the Neman. While the great majority of Poland's rivers drain into the Baltic Sea, Poland's Beskids are the source of some of the upper tributaries of the Orava, which flows via the Váh and the Danube to the Black Sea. The eastern Beskids are also the source of some streams that drain through the Dniester to the Black Sea.
Poland's rivers have been used since early times for navigation. The Vikings, for example, traveled up the Vistula and the Oder in their longships. In the Middle Ages and in early modern times, when the Polish–Lithuanian Commonwealth was the breadbasket of Europe; the shipment of grain and other agricultural products down the Vistula toward Gdańsk and onward to other parts of Europe took on great importance.
With almost ten thousand closed bodies of water covering more than each, Poland has one of the highest numbers of lakes in the world. In Europe, only Finland has a greater density of lakes. The largest lakes, covering more than , are Lake Śniardwy and Lake Mamry in Masuria, and Lake Łebsko and Lake Drawsko in Pomerania.
In addition to the lake districts in the north (in Masuria, Pomerania, Kashubia, Lubuskie, and Greater Poland), there is also a large number of mountain lakes in the Tatras, of which the Morskie Oko is the largest in area. The lake with the greatest depth—of more than —is Lake Hańcza in the Wigry Lake District, east of Masuria in Podlaskie Voivodeship.
Among the first lakes whose shores were settled are those in the Greater Polish Lake District. The stilt house settlement of Biskupin, occupied by more than one thousand residents, was founded before the 7th century BC by people of the Lusatian culture.
Lakes have always played an important role in Polish history and continue to be of great importance to today's modern Polish society. The ancestors of today's Poles, the Polanie, built their first fortresses on islands in these lakes. The legendary Prince Popiel ruled from Kruszwica tower erected on the Lake Gopło. The first historically documented ruler of Poland, Duke Mieszko I, had his palace on an island in the Warta River in Poznań. Nowadays the Polish lakes provide a location for the pursuit of water sports such as yachting and wind-surfing.
The Polish Baltic coast is approximately long and extends from Świnoujście on the islands of Usedom and Wolin in the west to Krynica Morska on the Vistula Spit in the east. For the most part, Poland has a smooth coastline, which has been shaped by the continual movement of sand by currents and winds. This continual erosion and deposition has formed cliffs, dunes, and spits, many of which have migrated landwards to close off former lagoons, such as Łebsko Lake in Słowiński National Park.
Prior to the end of the Second World War and subsequent change in national borders, Poland had only a very small coastline; this was situated at the end of the 'Polish Corridor', the only internationally recognised Polish territory which afforded the country access to the sea. However, after World War II, the redrawing of Poland's borders and resulting 'shift' of the country's borders left it with an expanded coastline, thus allowing for far greater access to the sea than was ever previously possible. The significance of this event, and importance of it to Poland's future as a major industrialised nation, was alluded to by the 1945 Wedding to the Sea.
The largest spits are Hel Peninsula and the Vistula Spit. The largest Polish Baltic island is Wolin. The largest sea harbours are Szczecin, Świnoujście, Gdańsk, Gdynia, Police and Kołobrzeg. The main coastal resorts are Świnoujście, Międzyzdroje, Kołobrzeg, Łeba, Sopot, Władysławowo and the Hel Peninsula.
Land use.
Poland is the fourth most forested country in Europe. Forests cover about 30.5% of Poland's land area based on international standards. Its overall percentage is still increasing. Forests of Poland is managed by the national program of reforestation (KPZL), aiming at an increase of forest-cover to 33% in 2050. The richness of Polish forest (per SoEF 2011 statistics) is more than twice as high as European average (with Germany and France at the top), containing 2.304 billion cubic metres of trees. The largest forest complex in Poland is Lower Silesian Wilderness.
More than 1% of Poland's territory, , is protected within 23 Polish national parks. Three more national parks are projected for Masuria, the Kraków-Częstochowa Upland, and the eastern Beskids. In addition, wetlands along lakes and rivers in central Poland are legally protected, as are coastal areas in the north. There are over 120 areas designated as landscape parks, along with numerous nature reserves and other protected areas (e.g. Natura 2000).
Since Poland's accession to the European Union in 2004, Polish agriculture has performed extremely well and the country has over two million private farms. It is the leading producer in Europe of potatoes and rye (world's second largest in 1989) the world's largest producer of triticale, and one of the more important producers of barley, oats, sugar beets, flax, and fruits.It is the European Union's fourth largest supplier of pigmeat after Germany, Spain and France. The government continues debating further agricultural reform and pursuing the option of auctioning off large tracts of state-owned agricultural land.
Biodiversity.
Phytogeographically, Poland belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the World Wide Fund for Nature, the territory of Poland belongs to three Palearctic Ecoregions of the continental forest spanning Central and Northern European temperate broadleaf and mixed forest ecoregions as well as the Carpathian montane conifer forest.
Many animals that have since died out in other parts of Europe still survive in Poland, such as the wisent in the ancient woodland of the Białowieża Forest and in Podlaskie. Other such species include the brown bear in Białowieża, in the Tatras, and in the Beskids, the gray wolf and the Eurasian lynx in various forests, the moose in northern Poland, and the beaver in Masuria, Pomerania, and Podlaskie.
In the forests, one also encounters game animals, such as red deer, roe deer and wild boars. In eastern Poland there are a number of ancient woodlands, like Białowieża forest, that have never been cleared or have been disturbed much by people. There are also large forested areas in the mountains, Masuria, Pomerania, Lubusz Land and Lower Silesia.
Poland is the most important breeding ground for a variety of European migratory birds. Out of all of the migratory birds who come to Europe for the summer, one quarter of the global population of white storks (40,000 breeding pairs) live in Poland, particularly in the lake districts and the wetlands along the Biebrza, the Narew, and the Warta, which are part of nature reserves or national parks.
Climate.
The climate is mostly temperate throughout the country. The climate is oceanic in the north and west and becomes gradually warmer and continental towards the south and east. Summers are generally warm, with average temperatures between depending on a region. Winters are rather cold, with average temperatures around in the northwest and in the northeast. Precipitation falls throughout the year, although, especially in the east; winter is drier than summer.
The warmest region in Poland is Lower Silesia located in south-western Poland where temperatures in the summer average between but can go as high as on some days in the warmest month of July and August. The warmest cities in Poland are Tarnów, which is situated in Lesser Poland and Wrocław, which is located in Lower Silesia. The average temperatures in Wrocław are in the summer and in the winter, but Tarnów has the longest summer in all of Poland, which lasts for 115 days, from mid-May to mid-September. The coldest region of Poland is in the northeast in the Podlaskie Voivodeship near the border of Belarus and Lithuania. Usually the coldest city is Suwałki. The climate is affected by cold fronts which come from Scandinavia and Siberia. The average temperature in the winter in Podlaskie ranges from .
Politics.
Poland is a representative democracy, with a president as a head of state, whose current constitution dates from 1997. Poland is a peaceful country. The government structure centers on the Council of Ministers, led by a prime minister. The president appoints the cabinet according to the proposals of the prime minister, typically from the majority coalition in the Sejm. The president is elected by popular vote every five years. The president is Andrzej Duda and the current prime minister is Beata Szydło.
Polish voters elect a bicameral parliament consisting of a 460-member lower house (Sejm) and a 100-member Senate (Senat). The Sejm is elected under proportional representation according to the d'Hondt method, a method similar to that used in many parliamentary political systems. The Senat, on the other hand, is elected under the first-past-the-post voting method, with one senator being returned from each of the 100 constituencies.
With the exception of ethnic minority parties, only candidates of political parties receiving at least 5% of the total national vote can enter the Sejm. When sitting in joint session, members of the Sejm and Senat form the National Assembly (the "Zgromadzenie Narodowe"). The National Assembly is formed on three occasions: when a new President takes the oath of office; when an indictment against the President of the Republic is brought to the State Tribunal ("Trybunał Stanu"); and when a president's permanent incapacity to exercise his duties due to the state of his health is declared. To date only the first instance has occurred.
The judicial branch plays an important role in decision-making. Its major institutions include the Supreme Court of the Republic of Poland ("Sąd Najwyższy"); the Supreme Administrative Court of the Republic of Poland ("Naczelny Sąd Administracyjny"); the Constitutional Tribunal of the Republic of Poland ("Trybunał Konstytucyjny"); and the State Tribunal of the Republic of Poland ("Trybunał Stanu"). On the approval of the Senat, the Sejm also appoints the ombudsman or the Commissioner for Civil Rights Protection ("Rzecznik Praw Obywatelskich") for a five-year term. The ombudsman has the duty of guarding the observance and implementation of the rights and liberties of Polish citizens and residents, of the law and of principles of community life and social justice.
Law.
The Constitution of Poland is the supreme law in contemporary Poland, and the Polish legal system is based on the principle of civil rights, governed by the code of Civil Law. Historically, the most famous Polish legal act is the Constitution of 3 May 1791. Historian Norman Davies describes it as the first of its kind in Europe. The Constitution was instituted as a Government Act () and then adopted on 3 May 1791 by the Sejm of the Polish–Lithuanian Commonwealth. Primarily, it was designed to redress long-standing political defects of the federative Polish–Lithuanian Commonwealth and its Golden Liberty. Previously only the Henrican articles signed by each of Poland's elected kings could perform the function of a set of basic laws.
The new Constitution introduced political equality between townspeople and the nobility ("szlachta"), and placed the peasants under the protection of the government. The Constitution abolished pernicious parliamentary institutions such as the "liberum veto", which at one time had placed the sejm at the mercy of any deputy who might choose, or be bribed by an interest or foreign power, to have rescinded all the legislation that had been passed by that sejm. The 3 May Constitution sought to supplant the existing anarchy fostered by some of the country's reactionary magnates, with a more egalitarian and democratic constitutional monarchy. The adoption of the constitution was treated as a threat by Poland's neighbours. In response Prussia, Austria and Russia formed an anti-Polish alliance and over the next decade collaborated with one another to partition their weaker neighbour and destroyed the Polish state. In the words of two of its co-authors, Ignacy Potocki and Hugo Kołłątaj, the constitution represented "the last will and testament of the expiring Fatherland." Despite this, its text influenced many later democratic movements across the globe. In Poland, freedom of expression is guaranteed by the Article 25 (section I. The Republic) and Article 54 (section II. The Freedoms, Rights and Obligations of Persons and Citizens) of the Constitution of Poland.
Feminism in Poland started in the 1800s in the age of the foreign Partitions. Poland's precursor of feminism, Narcyza Żmichowska, founded a group of Suffragettes in 1842. Prior to the last Partition in 1795, tax-paying females were allowed to take part in political life. Since 1918, following the return to independence, all women could vote. Poland was the 15th (12th sovereign) country to introduce universal women's suffrage. Nevertheless, there is a number of issues concerning women in modern-day Poland such as the abortion rights (formally allowed only in special circumstances) and the "glass ceiling". Homosexuality in Poland was confirmed as legal in 1932. Poland recognises gender change.
A 2010 article in "Rzeczpospolita" reported that in a 2008 study three-quarters of Poles were against gay marriage or the adoption of children by gay couples in accordance with the Catholic teachings. The same study revealed that 66% of respondents were opposed to Pride parade as the demonstration of a way of life, and 69% believed that gay people should not show their sexual orientation in public. Poland belongs to the group of 'Tier 1' countries in Trafficking in Persons Report. Trafficking women is 'illegal and rare' (top results worldwide).
Poland's current constitution was adopted by the National Assembly of Poland on 2 April 1997, approved by a national referendum on 25 May 1997, and came into effect on 17 October 1997. It guarantees a multi-party state, the freedoms of religion, speech and assembly, and specifically casts off many Communist ideals to create a 'free market economic system'. It requires public officials to pursue ecologically sound public policy and acknowledges the inviolability of the home, the right to form trade unions, and to strike, whilst at the same time prohibiting the practices of forced medical experimentation, torture and corporal punishment.
Foreign relations.
In recent years, Poland has extended its responsibilities and position in European and international affairs, supporting and establishing friendly relations with other European nations and a large number of 'developing' countries.
Poland is a member of the European Union, NATO, the UN, the World Trade Organization, the Organisation for Economic Co-operation and Development (OECD), European Economic Area, International Energy Agency, Council of Europe, Organization for Security and Co-operation in Europe, International Atomic Energy Agency, European Space Agency, G6, Council of the Baltic Sea States, Visegrád Group, Weimar Triangle and Schengen Agreement.
In 1994, Poland became an associate member of the European Union (EU) and its defensive arm, the Western European Union (WEU), having submitted preliminary documentation for full membership in 1996, it formally joined the European Union in May 2004, along with the other members of the Visegrád group. In 1996, Poland achieved full OECD membership, and at the 1997 Madrid Summit was invited to join the North Atlantic Treaty Organisation (NATO) in the first wave of policy enlargement finally becoming a full member of NATO in March 1999.
As changes since the fall of Communism in 1989 have redrawn the map of Europe, Poland has tried to forge strong and mutually beneficial relationships with its seven new neighbours, this has notably included signing 'friendship treaties' to replace links severed by the collapse of the Warsaw Pact. The Poles have forged special relationships with Lithuania and particularly Ukraine, with whom they co-hosted the UEFA Euro 2012 football tournament, in an effort to firmly anchor these countries within the Western world and provide them with an alternative to aligning themselves with the Russian Federation respectively. Despite many positive developments in the region, Poland has found itself in a position where it must seek to defend the rights of ethnic Poles living in the former Soviet Union; this is particularly true of Belarus, where in 2005 the Lukashenko regime launched a campaign against the Polish ethnic minority.
Poland is the sixth most populous member state of the European Union and has a grand total of 51 representatives in the European Parliament. Ever since joining the union in 2004, successive Polish governments have pursued policies to increase the country's role in European and regional affairs.
Administrative divisions.
Poland's current voivodeships (provinces) are largely based on the country's historic regions, whereas those of the past two decades (to 1998) had been centred on and named for individual cities. The new units range in area from less than for Opole Voivodeship to more than for Masovian Voivodeship. Administrative authority at voivodeship level is shared between a government-appointed voivode (governor), an elected regional assembly ("sejmik") and an executive elected by that assembly.
The voivodeships are subdivided into "powiats" (often referred to in English as counties), and these are further divided into "gminas" (also known as communes or municipalities). Major cities normally have the status of both "gmina" and "powiat". Poland has 16 voivodeships, 379 powiats (including 65 cities with "powiat" status), and 2,478 "gminas".
Military.
The Polish armed forces are composed of four branches: Land Forces ("Wojska Lądowe"), Navy ("Marynarka Wojenna"), Air Force ("Siły Powietrzne") and Special Forces ("Wojska Specjalne"). The military is subordinate to the Minister for National Defence. However, its sole commander-in-chief is the President of the Republic.
The Polish army consists of 65,000 active personnel, whilst the navy and air force respectively employ 14,300 and 26,126 servicemen and women. The Polish Navy is one of the larger navies on the Baltic Sea and is mostly involved in Baltic operations such as search and rescue provision for the section of the Baltic under Polish command, as well as hydrographic measurements and research; however, the Polish Navy played a more international role as part of the 2003 invasion of Iraq, providing logistical support for the United States Navy. The current position of the Polish Air Force is much the same; it has routinely taken part in Baltic Air Policing assignments, but otherwise, with the exception of a number of units serving in Afghanistan, has seen no active combat since the end of the Second World War. In 2003, the F-16C Block 52 was chosen as the new general multi-role fighter for the air force, the first deliveries taking place in November 2006; it is expected (2010) that the Polish Air Force will create three squadrons of F-16s, which will all be fully operational by 2012.
The most important mission of the armed forces is the defence of Polish territorial integrity and Polish interests abroad. Poland's national security goal is to further integrate with NATO and European defence, economic, and political institutions through the modernisation and reorganisation of its military. The armed forces is being re-organised according to NATO standards, and as of 1 January 2010, the transition to an entirely contract-based military has been completed. During the previous period, men were obliged to undertake compulsory military service. In the final stage of validity of this type of military service (since 2007 until the amendment of the law on conscription in 2008) the duration of compulsory service amounted nine months.
Polish military doctrine reflects the same defensive nature as that of its NATO partners. From 1953 to 2009 Poland was a large contributor to various United Nations peacekeeping missions. The Polish Armed Forces took part in the 2003 invasion of Iraq, deploying 2,500 soldiers in the south of that country and commanding the 17-nation Multinational force in Iraq.
The military was temporarily, but severely, affected by the loss of many of its top commanders in the wake the 2010 Polish Air Force Tu-154 crash near Smolensk, Russia, which killed all 96 passengers and crew, including, among others, the Chief of the Polish Army's General Staff Franciszek Gągor and Polish Air Force commanding general Andrzej Błasik. They were en route from Warsaw to attend an event to mark the 70th anniversary of the Katyn massacre, whose site is commemorated approximately west of Smolensk.
Law enforcement and emergency services.
Poland has a highly developed system of law enforcement with a long history of effective policing by the State Police Service. The structure of law enforcement agencies within Poland is a multi-tier one, with the State Police providing criminal-investigative services, Municipal Police serving to maintain public order and a number of other specialised agencies, such as the Polish Border Guard, acting to fulfil their assigned missions. In addition to these state services, private security companies are also common, although they possess no powers assigned to state agencies, such as, for example, the power to make an arrest or detain a suspect.
Emergency services in Poland consist of the emergency medical services, search and rescue units of the Polish Armed Forces and State Fire Service. Emergency medical services in Poland are, unlike other services, provided for by local and regional government.
Since joining the European Union all of Poland's emergency services have been undergoing major restructuring and have, in the process, acquired large amounts of new equipment and staff. All emergency services personnel are now uniformed and can be easily recognised thanks to a number of innovative design features, such as reflective paint and printing, present throughout their service dress and vehicle liveries. In addition to this, in an effort to comply with EU standards and safety regulations, the police and other agencies have been steadily replacing and modernising their fleets of vehicles; this has left them with thousands of new automobiles, as well as many new aircraft, boats and helicopters.
Economy.
Poland's high-income economy is considered to be one of the healthiest of the post-Communist countries and is one of the fastest growing within the EU. Having a strong domestic market, low private debt, flexible currency, and not being dependent on a single export sector, Poland is the only European economy to have avoided the late-2000s recession. Since the fall of the communist government, Poland has pursued a policy of liberalising the economy. It is an example of the transition from a centrally planned to a primarily market-based economy. In 2009 Poland had the highest GDP growth in the EU - 2.6%. The country's most successful exports include machinery, furniture, foods and meats, motor boats, light planes, hardwood products, casual clothing, shoes and cosmetics. Germany is by far the biggest importer of Poland's exports .
The privatization of small and medium state-owned companies and a liberal law on establishing new firms have allowed the development of the private sector. As a consequence, consumer rights organizations have also appeared. Restructuring and privatisation of "sensitive sectors" such as coal, steel, rail transport and energy has been continuing since 1990. Between 2007 and 2010, the government plans to float twenty public companies on the Warsaw Stock Exchange, including parts of the coal industry. The biggest privatisations have been the sale of the national telecoms firm Telekomunikacja Polska to France Télécom in 2000, and an issue of 30% of the shares in Poland's largest bank, PKO Bank Polski, on the Polish stockmarket in 2004.
The Polish banking market is the largest in East Central and Eastern European region, with 32.3 branches per 100,000 adults. The banks are the largest and most developed sector of the country's financial markets. They are regulated by the Polish Financial Supervision Authority. During the transformation to a market-oriented economy, the government privatized some of them, recapitalized the rest, and introduced legal reforms that made the sector competitive. This has attracted a significant number of strategic foreign investors (ICFI). Poland's banking sector has approximately 5 national banks, a network of nearly 600 cooperative banks and 18 branches of foreign-owned banks. In addition, foreign investors have controlling stakes in nearly 40 commercial banks, which make up 68% of the banking capital.
Poland has a large number of private farms in its agricultural sector, with the potential to become a leading producer of food in the European Union. The biggest money-makers abroad include smoked and fresh fish, fine chocolate, and dairy products, meats and specialty breads, with the exchange rate conducive to export growth. Food exports amounted to 62 billion zloty in 2011, increasing by 17% from 2010. Structural reforms in health care, education, the pension system, and state administration have resulted in larger-than-expected fiscal pressures. Warsaw leads Central Europe in foreign investment. GDP growth had been strong and steady from 1993 to 2000 with only a short slowdown from 2001 to 2002.
The economy had growth of 3.7% annually in 2003, a rise from 1.4% annually in 2002. In 2004, GDP growth equaled 5.4%, in 2005 3.3% and in 2006 6.2%. According to Eurostat data, Polish PPS GDP per capita stood at 67% of the EU average in 2012.
In terms of the clarity, efficiency and neutrality of Poland's legal framework for multinational investors, a 2012 report by the World Economic Forum concluded that the ongoing foreign business disputes may "have damaged Poland's reputation as an attractive location for FDI" from other countries by creating the impression of "substandard reputation for maintaining an efficient and neutral framework to settle business disputes." Ernst and Young's 2010 European attractiveness survey reported that Poland saw a 52% decrease in FDI foreign job creation and a 42% decrease in number of FDI projects since 2008.
Average salaries in the enterprise sector in December 2010 were 3,848 PLN (1,012 euro or 1,374 US dollars) and growing sharply. Salaries vary between the regions: the median wage in the capital city Warsaw was 4,603 PLN (1,177 euro or 1,680 US dollars) while in Kielce it was 3,083 PLN (788 euro or 1125 US dollars). There is a wide distribution of salaries among the various districts of Poland. They range from 2,020 PLN (517 euro or 737 US dollars) in Kępno County, which is located in Greater Poland Voivodeship to 5,616 (1,436 euro or 2,050 US dollars) in Lubin County, which lies in Lower Silesian Voivodeship.
According to a Credit Suisse report, Poles are the second wealthiest (after Czechs) of the Central European peoples. Even though since World War II Poland is almost an ethnically homogeneous country, the number of foreign investors among immigrants is growing every year.
Since the opening of the labor market in the European Union, Poland experienced a mass emigration of over 2.3 million abroad, mainly due to higher wages offered abroad, and due to the raise in levels of unemployment following the global Great Recession of 2008. The out migration has increased the average wages for the workers who remained in Poland, in particular for those with intermediate level skills.
Products and goods manufactured in Poland include: electronics, buses (Solaris, Solbus), helicopters (PZL Świdnik), trains (Pesa SA), transport equipment, locomotives, planes (PZL Mielec), ships, military engineering (Bumar-Łabędy SA), medicines (Polpharma, Polfa), food (Tymbark), clothes (LLP), glass, pottery (Bolesławiec), chemical products and others.
Corporations.
Poland is recognised as a regional economic power within East-Central Europe, with nearly 40 percent of the 500 biggest companies in the region (by revenues) as well as a high globalisation rate. Poland was the only member of the EU to avoid the recession of the late 2000s, a testament to the Polish economy's stability. The country's most competitive firms are components of the WIG30 which is traded on the Warsaw Stock Exchange.
Well known Polish brands include, among others, PKO BP, PKN Orlen, PGE, PZU, PGNiG, Tauron Group, Lotos Group, KGHM Polska Miedź, Asseco, Plus, Play, PLL LOT, Poczta Polska, PKP, Biedronka, and TVP.
Poland is recognised as having an economy with development potential, overtaking the Netherlands in mid-2010 to become Europe's sixth largest economy. Foreign Direct Investment in Poland has remained steady ever since the country's re-democratisation following the Round Table Agreement in 1989. However, problems still exist. It is believed that progress of privatization was uneven across sectors due to emergence of interest groups supporting government's push for the reforms based on "feasibility" rather than "efficiency", at the cost of Poland's remaining sectors in need of development and modernisation, such as the extractive industries.
The list includes the largest companies by turnover in 2011, but does not include major banks or insurance companies:
Tourism.
Poland experienced an increase in the number of tourists after joining the European Union. Tourism contributes significantly to Poland's overall economy and makes up a relatively large proportion of the country's service market.
Kraków was the former capital and a relic of Poland's Golden Age of Renaissance. It contains the place of coronation of most Polish kings. It was named a European Capital of Culture by the European Union for the year 2000. The city of Wrocław, designated as a European Capital of Culture in 2016, is one of the oldest in Poland. During World War II, Wrocław was a fortress (Festung Breslau), and was heavily damaged in the nearly three months long Battle of Breslau. The city has been restored and attracts several million tourists every year. The Old Town of Poland's capital, Warsaw, was reconstructed after its wartime destruction and it offers a variety of attractions. Other cities attracting tourists include Gdańsk, Poznań, Szczecin, Lublin and Toruń. The historic site of the Nazi-German Auschwitz concentration camp is located near Oświęcim.
Poland's main tourist offerings include outdoor activities such as skiing, sailing and mountain hiking, as well as agrotourism, sightseeing walks, countryside excursions and also holiday and business trips. Poland is the 17th most visited country in the world by foreign tourists, as ranked by World Tourism Organization (UNWTO) in 2012. Tourist destinations include the Baltic Sea coast in the north, the Masurian Lake District and Białowieża Forest in the east, the northern Karkonosze, the Table Mountains and the Tatra Mountains, where Rysy, the highest peak of Poland, and the famous Orla Perć long-distance path are located. The Pieniny and Bieszczady Mountains lie in the extreme south-east. There are over 100 castles in the country, many along the popular Trail of the Eagles' Nests.
Every year during the second weekend of June the city of Wrocław holds the Festival of Good Beer — one of Europe's largest international beer festivals.
Energy.
The electricity generation sector in Poland is largely fossil-fuel–based. Many power plants nationwide use Poland's position as a major European exporter of coal to their advantage by continuing to use coal as the primary raw material in production of their energy. In 2013 Poland scored 48 out of 129 states in the Energy Sustainability Index. The three largest Polish coal mining firms (Węglokoks, Kompania Węglowa and JSW) extract around 100 million tonnes of coal annually. All three of these companies are key constituents of the Warsaw Stock Exchange's lead economic indexes.
Renewable forms of energy account for a small proportion of Poland's full energy generation capacity. However, the national government has set targets for the development of renewable energy sources in Poland which should see the portion of power produced by renewable resources climb to 7.5% by 2010 and 15% by 2020. This is to be achieved mainly through the construction of wind farms and a number of hydroelectric stations.
Poland is thought to have around 164,800,000,000 m3 of proven natural gas reserves and around 96,380,000 barrels of proven oil reserves. These reserves are exploited by energy supply companies such as PKN Orlen ("the only Polish company listed in the Fortune Global 500"). However, the small amounts of fossil fuels naturally occurring in Poland is insufficient to satisfy the full energy consumption needs of the population. Therefore, the country is a net importer of oil and natural gas.
Transport.
Transport in Poland is provided by means of rail, road, marine shipping and air travel. Positioned in Central Europe with its eastern and part of its northeastern border constituting the longest land border of the Schengen Area with the rest of Northern and Central Europe, Poland has long been and remains a key country through which imports to the European Union and exports from it pass.
Since joining the EU in May 2004, Poland has invested large amounts of money into the modernisation of its transport networks. The country now has a developing expressway network composed of motorways such as the A1, A2, A4, A8, A18 and express roads such as the S1, S3, S5, S7, S8. In addition to these newly built roads, many local and regional roads are being rebuilt as part of a national programme to rebuild all roads in Poland.
In 2015, the nation had of railway track. Trains can operate up to on 7.5% of the track. Most trains operate between . Part of the system operates at .
Polish authorities maintain a program of improving operating speeds across the entire Polish rail network. Polish State Railways (PKP) are using new rolling stock such as Siemens Taurus ES64U4, which is in principle capable of speeds up to . In December 2014, Poland began to implement high–speed rail routes connecting major Polish cities. The Polish government has revealed that it intends to connect all major cities to a future high-speed rail network by 2020. The new PKP Pendolino ETR 610 test train set the record for the fastest train in the history of Poland, reaching on 24 November 2013. Previously, the speed record had been since 1985. Most intercity rail routes in Poland are operated by PKP Intercity, whilst regional trains are run by a number of operators, the largest of which is Przewozy Regionalne.
On 14 December 2014, Polish State Railways started passenger service using the PKP Pendolino ED250, operating at 200 km/h speed on 80 km of line between Olszamowice and Zawiercie (part of the Central Rail Line from Warsaw to Kraków). Currently it is the line with highest railway speed in Poland. Poland is the first country from the 2004 enlargement of the European Union which offers passenger rail services with scheduled speeds exceeding 160 km/h.
The air and maritime transport markets in Poland are largely well developed. Poland has a number of international airports, the largest of which is Warsaw Chopin Airport, the primary global hub for LOT Polish Airlines. LOT is the 28th largest European airline and the world's 12th oldest still in operation, established in 1929 from a merger of Aerolloyd (1922) and Aero (1925). Major airports with international connections exist in almost every region, for example John Paul II International Airport Kraków–Balice and Wrocław–Copernicus Airport.
Seaports exist all along Poland's Baltic coast, with most freight operations using Szczecin, Świnoujście, Gdynia and Gdańsk as well as Police, Kołobrzeg and Elbląg as their base. Passenger ferries link Poland with Scandinavia all year round; these services are provided from Gdańsk and Świnoujście by Polferries, Stena Line from Gdynia and Unity Line from the Port of Świnoujście.
Science and technology.
According to Frost & Sullivan's Country Industry Forecast the country is becoming an interesting location for research and development investments. Multinational companies such as: ABB, Delphi, GlaxoSmithKline, Google, Hewlett–Packard, IBM, Intel, LG Electronics, Microsoft, Motorola, Siemens and Samsung have set up research and development centres in Poland. Over 40 research and development centers and 4,500 researchers make Poland the biggest research and development hub in Central and Eastern Europe. Companies chose Poland because of the availability of highly qualified labour force, presence of universities, support of authorities, and the largest market in East-Central Europe.
Today Poland's tertiary education institutions; traditional universities (found in its major cities), as well as technical, medical, and economic institutions, employ around 61,000 researchers and members of staff. There are around 300 research and development institutes, with about 10,000 researchers. In total, there are around 91,000 scientists in Poland today. However, in the 19th and 20th centuries many Polish scientists worked abroad; one of the most important of these exiles was Maria Skłodowska-Curie, a physicist and chemist who lived much of her life in France. In the first half of the 20th century, Poland was a flourishing centre of mathematics. Outstanding Polish mathematicians formed the Lwów School of Mathematics (with Stefan Banach, Stanisław Mazur, Hugo Steinhaus, Stanisław Ulam) and Warsaw School of Mathematics (with Alfred Tarski, Kazimierz Kuratowski, Wacław Sierpiński). The events of World War II pushed many of them into exile. Such was the case of Benoît Mandelbrot, whose family left Poland when he was still a child. An alumnus of the Warsaw School of Mathematics was Antoni Zygmund, one of the shapers of 20th-century mathematical analysis.
According to a KPMG report 80% of Poland's current investors are content with their choice and willing to reinvest. In 2006, Intel decided to double the number of employees in its research and development centre in Gdańsk.
Communications.
The share of the telecom sector in the GDP is 4.4% (end of 2000 figure), compared to 2.5% in 1996. The coverage increased from 78 users per 1,000 inhabitants in 1989 to 282 in 2000. The value of the telecommunication market is zl 38.2bn (2006), and it grew by 12.4% in 2007 PMR. The coverage mobile cellular is over 1000 users per 1000 people (2007). Telephones—mobile cellular: 38.7 million (Onet.pl & GUS Report, 2007), telephones—main lines in use: 12.5 million (Telecom Team Report, 2005).
With regard to internet access, the most popular ADSL services for home users in Poland are Neostrada provided by TPSA, and Net24 provided by Netia. Business users as well as some home users use Internet DSL TP also offered by TPSA. According to Eurostat, OECD and others, Internet access in Poland is amidst the most expensive in Europe. This is mostly caused by the lack of competitiveness. New operators, such as Dialog and GTS Energis are making their own provider lines and offer more attractive and cheaper service. The Polish Office of Electronical Communication is forcing the TPSA to rent 51% of their ADSL lines to other ISPs for 60% lower prices. This move will affect the prices of DSL in Poland. In 2012, the process of converting to Digital terrestrial television started, to be compatible with the rest of Europe.
The public postal service in Poland is operated by "Poczta Polska" (the Polish Post). It was created on 18 October 1558, when King Sigismund II Augustus established a permanent postal route from Kraków to Venice. The service was dissolved during the foreign partitions. After regaining independence in 1918, Poland saw the rapid development of the postal system as new services were introduced including money transfers, payment of pensions, delivery of magazines, and air mail. During wars and national uprisings communication was provided mainly through the military authorities. Many important events in the history of Poland involved the postal service, like the heroic defence of the Polish Post Office in Gdańsk in 1939, and the participation of the Polish Scouts' Postal Service in the Warsaw Uprising. Nowadays the service is a modern state-owned company that provides a number of standard and express delivery as well as home-delivery services. Digital technologies are made available through the Internet platform "Envelo".
Demographics.
Poland, with 38,544,513 inhabitants, has the eighth-largest population in Europe and the sixth-largest in the European Union. It has a population density of 122 inhabitants per square kilometer (328 per square mile).
Poland historically contained many languages, cultures and religions on its soil. The country had a particularly large Jewish population prior to World War II, when the Nazi Germany's regime led to The Holocaust. There were an estimated 3 million Jews before the war; 300,000 after. The outcome of the war, particularly the shift of Poland's borders to the area between the Curzon Line and the Oder-Neisse line, coupled with post-war expulsion of minorities, significantly reduced the country's ethnic diversity. Over 7 million Germans fled or were expelled from the Polish side of the Oder-Neisse boundary.
According to the 2002 census, 36,983,700 people, or 96.74% of the population, consider themselves Polish, while 471,500 (1.23%) declared another nationality, and 774,900 (2.03%) did not declare any nationality. The largest minority nationalities and ethnic groups in Poland are Silesians (173,153 according to the census), Germans (152,897 according to the census, 92% of whom live in Opole Voivodeship and Silesian Voivodeship), Belarusians (c. 49,000), Ukrainians (c. 30,000), Lithuanians, Russians, Roma, Jews, Lemkos, Slovaks, Czechs, and Lipka Tatars. Among foreign citizens, the Vietnamese are the largest ethnic group, followed by Armenians. Greeks in Poland aren't a legal national minority, because they arrived only after WWII.
The Polish language, part of the West Slavic branch of the Slavic languages, functions as the official language of Poland. Until recent decades Russian was commonly learned as a second language but has been replaced by English as the most common second language studied and spoken. In 2015, more than 50% of Poles declared to speak English - Russian came second and German came third, whilst French, Italian and Spanish are less popular.
In recent years, Poland's population has decreased due to an increase in emigration and a sharp decline in the birth rate. Since Poland's accession to the European Union, a significant number of Poles have emigrated, primarily to the United Kingdom, Germany and Republic of Ireland in search of better work opportunities abroad.
Polish minorities are still present in the neighboring countries of Ukraine, Belarus, and Lithuania, as well as in other countries (see Poles for population numbers). Altogether, the number of ethnic Poles living abroad is estimated to be around 20 million. The largest number of Poles outside of Poland can be found in the United States.
The total fertility rate (TFR) in Poland was estimated in 2013 at 1.32 children born/woman, which is below the replacement rate of 2.1.
Languages.
Polish ("język polski", "polszczyzna") is a Slavic language spoken primarily in Poland and the native language of Poles. It belongs to the Lechitic subgroup of West Slavic languages. Polish is the official language of Poland, but it is also used throughout the world by Polish minorities in other countries. It is one of the official languages of the European Union. Its written standard is the Polish alphabet, which has 9 additions to the letters of the basic Latin script ("ą", "ć", "ę", "ł", "ń", "ó", "ś", "ź", "ż"). The deaf communities use Polish Sign Language belonging to the German family of Sign Languages.
According to the "Act of 6 January 2005 on national and ethnic minorities and on the regional languages", 16 other languages have officially recognized status of minority languages: 1 regional language, 10 languages of 9 national minorities (the minorities that have their own independent state elsewhere) and 5 languages of 4 ethnic minorities spoken by the members of minorities not having a separate state elsewhere). Jewish and Romani minorities each have 2 minority languages recognized.
Languages having the status of national minority's language are Armenian, Belarusian, Czech, German, Yiddish, Hebrew, Lithuanian, Russian, Slovak and Ukrainian. Languages having the status of ethnic minority's language are Karaim, Kashubian, Rusyn (called "Lemko" in Poland) and Tatar. Also, official recognition is granted to two Romani languages: Polska Roma and Bergitka Roma.
Official recognition of a language provides certain rights (under conditions prescribed by the law): of education in that language, of having the language established as the secondary administrative language or help language in bilingual municipalities and of financial support from the state for the promotion of that language.
Religion.
From its beginnings, Poland has contributed substantially to the development of religious freedom. Since the country adopted Christianity in 966, it was also welcoming to other religions through a series of laws: Statute of Kalisz (1264), Warsaw Confederation (1573). The Polish king Władysław II Jagiełło, however, was pressed by the Catholic Church to issue the Edict of Wieluń (1424), outlawing early Protestant Hussitism. Polish theological thought includes theological movements, such as Calvinist Polish Brethren and a number of other Protestant groups, as well as atheists, such as ex-Jesuit philosopher Kazimierz Łyszczyński, one of the first atheist thinkers in Europe.
Until World War II Poland was a religiously diverse society, in which substantial Jewish, Christian Orthodox, Protestant and Roman Catholic groups coexisted. In the Second Polish Republic, Roman Catholic was the dominant religion, declared by about 65% of the Polish citizens, followed by other Christian denominations, and about 3% of Judaism believers. As a result of the Holocaust and the post–World War II flight and expulsion of German and Ukrainian populations, Poland has become overwhelmingly Roman Catholic. In 2007, 88.4% of the population belonged to the Catholic Church. Though rates of religious observance are lower, at 52% or 51% of the Polish Catholics, Poland remains one of the most devoutly religious countries in Europe.
From 16 October 1978 until his death on 2 April 2005 Karol Józef Wojtyła (later Pope John Paul II), a Polish native, reigned as Supreme Pontiff of the Roman Catholic Church. He has been the only Slavic and Polish Pope to date, and was the first non-Italian Pope since Dutch Pope Adrian VI in 1522. Additionally he is credited with having played a significant role in hastening the downfall of communism in Poland and throughout Central and Eastern Europe; he is famously quoted as having, at the height of communism in 1979, told Poles "not be afraid", later praying: "Let your Spirit descend and change the image of the land... this land".
Religious minorities include Polish Orthodox (about 506,800), various Protestants (about 150,000), Jehovah's Witnesses (126,827), Eastern Catholics, Mariavites, Polish Catholics, Jews, and Muslims (including the Tatars of Białystok). Members of Protestant churches include about 77,500 Lutherans in the largest Evangelical-Augsburg Church, 23,000 Pentecostals in the Pentecostal Church in Poland, and smaller numbers in various Evangelical Protestant churches. There are also tiny Reformed communities. There are also a few thousand pagans some of whom are members of such officially registered churches as the Native Polish Church, (Rodzimy Kościół Polski).
Freedom of religion is now guaranteed by the 1989 statute of the Polish Constitution, enabling the emergence of additional denominations. The Concordat between the Holy See and Poland guarantees the teaching of religion in state schools. According to a 2007 survey, 72% of respondents were not opposed to religious instruction in public schools; alternative courses in ethics are available only in one percent of the entire public educational system.
Famous sites of Christian pilgrimage in Poland include the Monastery of Jasna Góra in the southern Polish city of Częstochowa, as well as the Family home of John Paul II in Wadowice just outside Kraków.
Health.
Poland's healthcare system is based on an all-inclusive insurance system. State subsidised healthcare is available to all Polish citizens who are covered by this general health insurance program. However, it is not compulsory to be treated in a state-run hospital as a number of private medical complexes do exist nationwide.
All medical service providers and hospitals in Poland are subordinate to the Polish Ministry of Health, which provides oversight and scrutiny of general medical practice as well as being responsible for the day-to-day administration of the healthcare system. In addition to these roles, the ministry is also tasked with the maintenance of standards of hygiene and patient-care.
Hospitals in Poland are organised according to the regional administrative structure, resultantly most towns have their own hospital "(Szpital Miejski)". Larger and more specialised medical complexes tend only to be found in larger cities, with some even more specialised units located only in the capital, Warsaw. However, all voivodeships have their own general hospital (most have more than one), all of which are obliged to have a trauma centre; these types of hospital, which are able to deal with almost all medical problems are called 'regional hospitals' "(Szpital Wojewódzki)". The last category of hospital in Poland is that of specialised medical centres, an example of which would be the Skłodowska-Curie Institute of Oncology, Poland's leading, and most highly specialised centre for the research and treatment of cancer.
In 2012, the Polish health-care industry experienced a transformation. Hospitals were given priority for refurbishment where necessary. As a result of this process, many hospitals were updated with the latest medical equipment.
In 2013, the average life expectancy at birth was 76.45 years
(72.53 years infant male/80.62 years infant female).
Education.
The Commission of National Education ("Komisja Edukacji Narodowej") established in 1773, was the world's first state ministry of education. The education of Polish society was a goal of rulers as early as the 12th century. Poland became one of the most educated countries in Europe. The library catalogue of the Cathedral Chapter of Kraków dating back to 1110 shows that in the early 12th-century Polish intellectuals had access to European literature. The Jagiellonian University, founded in 1364 by King Casimir III in Kraków was blessed by Pope Urban V. It is the world's 19th oldest university.
The modern-day Programme for International Student Assessment, coordinated by the Organisation for Economic Co-operation and Development, ranks Poland's educational system in its PISA 2012 as the 10th best in the world, scoring higher than the OECD average.
Education in Poland starts at the age of five or six (with the particular age chosen by the parents) for the '0' class (Kindergarten) and six or seven years in the 1st class of primary school (Polish "szkoła podstawowa"). It is compulsory that children participate in one year of formal education before entering the 1st class at no later than 7 years of age. Corporal punishment of children in schools is officially prohibited since 1783 (before the partitions) and criminalised since 2010 (in schools as well as at home).
At the end of the 6th class when students are 13, students take a compulsory exam that will determine their acceptance and transition into a specific lower secondary school ("gimnazjum, pronounced gheem-nah-sium") (Middle School/Junior High). They will attend this school for three years during classes 7, 8, and 9. Students then take another compulsory exam to determine the upper secondary level school they will attend. There are several alternatives, the most common being the three years in a "liceum" or four years in a technikum. Both end with a maturity examination (matura, quite similar to French baccalauréat), and may be followed by several forms of upper education, leading to licencjat or inżynier (the Polish Bologna Process first cycle qualification), magister (second cycle qualification) and eventually doktor (third cycle qualification).
There are 500 university-level institutions for the pursuit of higher education in Poland, one of the largest number in Europe. The Jagiellonian University in Kraków, the first Polish university, was founded in 1364 by King Casimir III, as the 19th oldest university in the world, established in 1364.
There are 18 fully accredited traditional universities in Poland. There are twenty technical universities, nine independent medical universities, five universities for the study of economics, nine agricultural academies, three pedagogical universities, a theological academy and three maritime service universities.
There are a number of higher educational institutions dedicated to the teaching of the arts. Amongst these are the seven higher state academies of music. There are a number of private educational institutions and four national military academies (two for the army and one each for the other branches of service).
Culture.
The culture of Poland is closely connected with its intricate 1,000-year history Its unique character developed as a result of its geography at the confluence of European cultures. With origins in the culture of the Proto-Slavs, over time Polish culture has been profoundly influenced by its interweaving ties with the Germanic, Latinate and Byzantine worlds as well as in continual dialog with the many other ethnic groups and minorities living in Poland. The people of Poland have traditionally been seen as hospitable to artists from abroad and eager to follow cultural and artistic trends popular in other countries. In the 19th and 20th centuries the Polish focus on cultural advancement often took precedence over political and economic activity. These factors have contributed to the versatile nature of Polish art, with all its complex nuances.
Famous people.
The list of famous Poles begins in earnest with the polymath Mikołaj Kopernik, who studied at the Jagiellonian University founded in 1364 by Casimir the Great from proceeds of his Wieliczka Salt Mine. Poland is the birthplace of many distinguished personalities among whom are: Fryderyk Chopin, Maria Skłodowska Curie, Tadeusz Kościuszko, Kazimierz Pułaski, Józef Piłsudski, Lech Wałęsa and Pope John Paul II (Karol Wojtyła). Great Polish painter Jan Matejko devoted his monumental art to the most significant historical events on Polish lands, along with the playwright, painter and poet Stanisław Wyspiański. Stanisław Ignacy Witkiewicz (Witkacy) was an example of a Polish avant-garde philosopher and author of aesthetic theories. Polish Joseph Conrad was a notable author of works in English. Many world famous Polish movie directors include Academy Awards winners Roman Polański, Andrzej Wajda, Zbigniew Rybczyński, Janusz Kamiński, Krzysztof Kieślowski, and Agnieszka Holland. Actresses known outside of Poland, include Helena Modjeska and Pola Negri.
Society.
Poland has a long-standing tradition of tolerance towards minorities, as well as an absence of discrimination on the grounds of religion, nationality or race.
Prior to World War II, ethnic minorities made up a significant proportion of the Polish population. Poland has maintained a high level of gender equality, an established disability rights movement and promotes peaceful equality.
Poland was the first country in the world to prohibit corporal punishment in all its forms.Poland has, throughout most of its long history, experienced only very limited immigration from abroad; this trend can be largely attributed to Poland's rejection of slavery and to a lack of overseas colonies as well as occupation of its territories during much of the 19th and early 20th centuries. Despite this, the country has for a long time been regarded as having a very tolerant society, which affords equal rights to all people no matter what their ethnic background. This can be said to stem largely from the reign of King Casimir III the Great and his acceptance of Poland's Jewish community, in a time when most of Europe recessed into antisemitic moods and actions. The history of Jews in Poland exemplifies peaceful co-existence of a nation with a particular ethnic group.
Today, as many as 96.7% of Polish citizens declare to be Poles, and 97.8% declare that they speak Polish at home (Census 2002). The population of Poland became one of the most ethnically homogeneous in the world as a result of the radically altered borders after World War II and the subsequent migrations. This homogeneity is a result of post World War II deportations ordered by the Soviet authorities, who wished to remove the sizeable Polish minorities from Lithuania, Belarus and Ukraine and repatriation of Ukrainians from Poland to the Soviet Union (see territorial changes of Poland and historical demography of Poland for details). Unlike in many other countries, the ethnic minority rights in Poland are guaranteed directly by the Constitution of Poland (art. 35), and today there are, among others, sizeable German, Ukrainian and Belarusian minorities in the country.
In 2013, the Polish parliament rejected proposed legislation for civil partnerships, which the majority of Polish society is against, but for the first time it gave an asylum to a gay person from Uganda on the basis of the sexual orientation. In a 2013 opinion poll conducted by CBOS, 60% of Poles were against homosexual civil partnerships, 72% were against same-sex marriage, 88% were against adoption by same-sex couples, and 68% were against gays and lesbians publicly showing their way of life. Article 18 of the Constitution of Poland bans same-sex marriage.
The results of an Organization for Security and Co-operation in Europe (OSCE) survey from 2004 showed that Poles worked the second most hours per week of any nationality worldwide. Poland remains one of the most peaceful countries in the world.
Music.
Artists from Poland, including famous composers like Chopin or Penderecki and traditional, regionalized folk musicians, create a lively and diverse music scene, which even recognizes its own music genres, such as poezja śpiewana and disco polo. , Poland is one of the few countries in Europe where rock and hip hop dominate over pop music, while all kinds of alternative music genres are encouraged.
The origins of Polish music can be traced as far back as the 13th century; manuscripts have been found in Stary Sącz, containing polyphonic compositions related to the Parisian Notre Dame School. Other early compositions, such as the melody of "Bogurodzica" and "Bóg się rodzi" (a coronation polonaise for Polish kings by an unknown composer), may also date back to this period, however, the first known notable composer, Mikołaj z Radomia, was born and lived in the 15th century. During the 16th century, two main musical groups – both based in Kraków and belonging to the King and Archbishop of the Wawel – led to the rapid development of Polish music. Composers writing during this period include Wacław z Szamotuł, Mikołaj Zieleński, and Mikołaj Gomółka. Diomedes Cato, a native-born Italian who lived in Kraków from about the age of five, became a renowned lutenist at the court of Sigismund III, and not only imported some of the musical styles from southern Europe, but blended them with native folk music.
At the end of the 18th century, Polish classical music evolved into national forms like the polonaise. In the 19th century the most popular composers were: Józef Elsner and his pupils Fryderyk Chopin and Ignacy Dobrzyński. Important opera composers of the era were Karol Kurpiński and Stanisław Moniuszko whilst the list of famous soloists and composers included Henryk Wieniawski, Juliusz Zarębski. At the turn of the 19th and 20th centuries the most prominent composers could said to have been Władysław Zeleński and Mieczysław Karłowicz, with Karol Szymanowski gaining prominence prior to World War II. Alexandre Tansman lived in Paris but had strong connections with Poland. Witold Lutosławski, Henryk Górecki, and Krzysztof Penderecki composed in Poland, Andrzej Panufnik emigrated.
Traditional Polish folk music has had a major effect on the works of many well-known Polish composers, and no more so than on Fryderyk Chopin, a widely recognised national hero of the arts. All of Chopin's works involve the piano and are technically demanding, emphasising nuance and expressive depth. As a great composer, Chopin invented the musical form known as the instrumental ballade and made major innovations to the piano sonata, mazurka, waltz, nocturne, polonaise, étude, impromptu and prélude, he was also the composer of a number of polonaises which borrowed heavily from traditional Polish folk music. It is largely thanks to him that the such pieces gained great popularity throughout Europe during the 19th century. Nowadays the most distinctive folk music can be heard in the towns and villages of the mountainous south, particularly in the region surrounding the winter resort town of Zakopane.
Today Poland has a very active music scene, with the jazz and metal genres being particularly popular among the contemporary populace. Polish jazz musicians such as Krzysztof Komeda, created a unique style, which was most famous in the 1960s and 1970s and continues to be popular to this day. Since the fall of Communism, Poland has become a major venue for large-scale music festivals, chief among which are the Open'er Festival, Opole Festival and Sopot Festival.
Visual arts.
Polish art has always reflected European trends while maintaining its unique character. The Kraków school of Historicist painting developed by Jan Matejko produced monumental portrayals of customs and significant events in Polish history. Stanisław Witkiewicz was an ardent supporter of realism in Polish art, its main representative being Jozef Chełmoński. The Młoda Polska (Young Poland) movement witnessed the birth of modern Polish art, and engaged in a great deal of formal experimentation led by Jacek Malczewski (Symbolism), Stanisław Wyspiański, Józef Mehoffer, and a group of Polish Impressionists. Artists of the twentieth-century Avant-Garde represented various schools and trends. The art of Tadeusz Makowski was influenced by Cubism; while Władysław Strzemiński and Henryk Stażewski worked within the Constructivist idiom. Distinguished contemporary artists include Roman Opałka, Leon Tarasewicz, Jerzy Nowosielski, Wojciech Siudmak, Mirosław Bałka, and Katarzyna Kozyra and Zbigniew Wąsiel in the younger generation. The most celebrated Polish sculptors include Xawery Dunikowski, Katarzyna Kobro, Alina Szapocznikow and Magdalena Abakanowicz. Since the inter-war years, Polish art and documentary photography has enjoyed worldwide recognition. In the sixties the Polish Poster School was formed, with Henryk Tomaszewski and Waldemar Świerzy at its head. Top fine Art schools in Poland are Jan Matejko Academy of Fine Arts, Cracow School of Art and Fashion Design, Academy of Fine Arts in Warsaw, Art Academy of Szczecin, University of Fine Arts in Poznań and Eugeniusz Geppert Academy of Fine Arts.
Architecture.
Polish cities and towns reflect the whole spectrum of European styles. Romanesque architecture is represented by St. Andrew's Church, Kraków, and St. Mary's Church, Gdańsk, is characteristic for the Brick Gothic style found in Poland. Richly decorated attics and arcade loggias are the common elements of the Polish Renaissance architecture, as evident in the City Hall in Poznań. For some time the late renaissance style known as mannerism, most notably in the Bishop's Palace in Kielce, coexisted with the early baroque style, typified in the Church of SS. Peter and Paul in Kraków.
History has not been kind to Poland's architectural monuments. Nonetheless, a number of ancient structures has survived: castles, churches, and stately homes, often unique in the regional or European context. Some of them have been painstakingly restored, like Wawel Castle, or completely reconstructed after being destroyed in the Second World War, including the Old Town and Royal Castle of Warsaw and the Old Town of Gdańsk.
The architecture of Gdańsk is mostly of the Hanseatic variety, a Gothic style common among the former trading cities along the Baltic sea and in the northern part of Central Europe. The architectural style of Wrocław is mainly representative of German architecture, since it was for centuries located within the German states. The centre of Kazimierz Dolny on the Vistula is a good example of a well-preserved medieval town. Poland's ancient capital, Kraków, ranks among the best-preserved Gothic and Renaissance urban complexes in Europe. Meanwhile, the legacy of the Kresy Marchlands of Poland's eastern regions, where Wilno and Lwów (now "Vilnius" and "Lviv") were recognised as two major centres for the arts, played a special role in the development of Polish architecture, with Catholic church architecture deserving special note.
The second half of the 17th century is marked by baroque architecture. Side towers, such as those of Branicki Palace in Białystok, are typical for the Polish baroque. The classical Silesian baroque is represented by the University in Wrocław. The profuse decorations of the Branicki Palace in Warsaw are characteristic of the rococo style. The centre of Polish classicism was Warsaw under the rule of the last Polish king Stanisław August Poniatowski.
The Palace on the Water is the most notable example of Polish neoclassical architecture. Lublin Castle represents the Gothic Revival style in architecture, while the Izrael Poznański Palace in Łódź is an example of eclecticism.
Literature.
Polish literature dates back to the 12th century, and includes many renowned writers. Two Polish novelists have won the Nobel Prize in Literature: Henryk Sienkiewicz, and Władysław Reymont; along with two poets: Czesław Miłosz, and Wisława Szymborska. A prose poet of the highest order, Joseph Conrad (1857–1924), son of the Polish dramatist Apollo Korzeniowski, won world-wide fame with his English-language novels and stories that are informed with elements of the Polish national experience. Among the best known Polish Romantics are the "Three Bards" — the three national poets active in the age of Partitions: Adam Mickiewicz, Juliusz Słowacki, and Zygmunt Krasiński.
During the Middle Ages, most Polish writers and scholars (e.g., Jan Długosz) wrote only in Latin, the common language of European letters. This tradition was broken by Jan Kochanowski, who became one of the first Polish Renaissance authors to write most of his works in Polish, along with Mikołaj Rej. Especially notable 19th- and 20th-century Polish authors include Bolesław Prus, Kornel Makuszyński, Stanisław Lem, and Witold Gombrowicz among others.
Media.
Poland has instituted freedom of press since the fall of communism, a system under which the media was heavily politically controlled and censored. However, public TV and radio are still regulated by the government, this is exercised through an agency called "Krajowa Rada Radiofonii i Telewizji" ("The National Radio and Television Committee"), which is similar to television regulatory commissions in other developed nations.
Poland has a number of major media outlets, chief among which are the national television channels. TVP is Poland's public broadcasting corporation; about a third of its income comes from a broadcast receiver licence, while the rest is made through revenue from commercials and sponsorships. State television operates two mainstream channels, TVP 1 and TVP 2, as well as regional programs (TVP Info) for each of the country's 16 voivodeships. In addition to these general channels, TVP runs a number of genre-specific programmes such as TVP Sport, TVP Historia, TVP Kultura, TVP Seriale and TV Polonia, the latter is a state-run channel dedicated to the transmission of Polish language television for the Polish diaspora abroad.
Poland has a number of internationally broadcast and 24-hour news channels, chief among which are Polsat News, TVN 24. There are a number of major private television outlets such as Polsat and the TVN network.
Poland has a highly developed printed news industry, with daily newspapers like "Gazeta Wyborcza" ("Electoral Gazette"), "Rzeczpospolita" ("The Republic") and "Gazeta Polska Codziennie" ("Polish Daily Newspaper") providing more traditional reporting and tabloids such as "Fakt" providing more sensationalist writing which is less current affairs orientated. "Rzeczpospolita" is one of the nation's oldest publications still in operation. Founded in 1920, it has become a stalwart bastion of Polish reporting and in 2006 won a prestigious award for being, along with the "Guardian" (a British daily), the best designed newspaper in the world. The most popular weeklies are Tygodnik Angora, Polityka, Wprost, Newsweek Polska, Gość Niedzielny, and Gazeta Polska.
Cuisine.
Polish cuisine has evolved over the centuries to become very eclectic due to Poland's history. Polish cuisine shares many similarities with other Central European cuisines, especially German and Austrian as well as Jewish, Belarusian, Ukrainian, Russian, French and Italian culinary traditions. It is rich in meat, especially pork, chicken and beef (depending on the region) and winter vegetables (cabbage in the dish "bigos"), and spices. It is also characteristic in its use of various kinds of noodles the most notable of which are kluski as well as cereals such as "kasha" (from the Polish word kasza). Polish cuisine is hearty and uses a lot of cream and eggs. Festive meals such as the meatless Christmas eve dinner ("Wigilia") or Easter breakfast could take days to prepare in their entirety.
The main course usually includes a serving of meat, such as roast, chicken, or "kotlet schabowy" (breaded pork cutlet), vegetables, side dishes and salads, including "surówka" – shredded root vegetables with lemon and sugar (carrot, celeriac, seared beetroot) or sauerkraut (, ). The side dishes are usually potatoes, rice or "kasza" (cereals). Meals conclude with a dessert such as "sernik", "makowiec" (a poppy seed pastry), or "drożdżówka" yeast pastry, and tea.
The Polish national dishes are "bigos" ; "pierogi" ; "kielbasa"; "kotlet schabowy" breaded cutlet; "gołąbki" cabbage rolls; "zrazy" roulade; "pieczeń" roast ; sour cucumber soup ("zupa ogórkowa", ); mushroom soup, ("zupa grzybowa", quite different from the North American cream of mushroom); "zupa pomidorowa" tomato soup ; "rosół" variety of meat broth; "żurek" sour rye soup; "flaki" tripe soup; "barszcz" and "chłodnik" among others.
Traditional alcoholic beverages include honey mead, widespread since the 13th century, beer, wine and vodka (old Polish names include "okowita" and "gorzałka"). The world's first written mention of vodka originates from Poland. The most popular alcoholic drinks at present are beer and wine which took over from vodka more popular in the years 1980-1998. Tea remains common in Polish society since the 19th century, whilst coffee is drunk widely since the 18th century. Other frequently consumed beverages include various mineral waters and juices, soft drinks popularized by the fast-food chains since the late 20th century, as well as buttermilk, soured milk and kefir.
Sports.
Association football is one of country's most popular sports, with a rich history of international competitions. Track and field, basketball, volleyball, handball, boxing, MMA, motorcycle speedway, ski jumping, cross-country skiing, ice hockey, tennis, fencing, swimming and weightlifting are other popular sports.
The golden era of football in Poland occurred throughout the 1970s and went on until the early 1980s when the Polish national football team achieved their best results in any FIFA World Cup competitions finishing 3rd place in the 1974 and the 1982 tournaments. The team won a gold medal in football at the 1972 Summer Olympics and two silver medals, in 1976 and in 1992. Poland, along with Ukraine, hosted the UEFA European Football Championship in 2012.
The Polish men's national volleyball team is ranked as 3rd in the world. Mariusz Pudzianowski is a highly successful strongman competitor and has won more World's Strongest Man titles than any other competitor in the world, winning the event in 2008 for the fifth time. The first Polish Formula One driver, Robert Kubica, has brought awareness of Formula One racing to Poland. He won the 2008 Canadian Grand Prix and now does rallying following a crash in 2011 that left him unable to drive F1 cars.
Poland has made a distinctive mark in motorcycle speedway racing thanks to Tomasz Gollob, a highly successful Polish rider. The top Ekstraliga division has one of the highest average attendances for any sport in Poland. The national speedway team of Poland, one of the major teams in international speedway, has won the Speedway World Team Cup championships three times consecutively, in 2009, 2010, and 2011. No team has ever managed such feat.
Poles made significant achievements in mountaineering, in particular, in the Himalayas and the winter ascending of the eight-thousanders. The most famous Polish climbers are Jerzy Kukuczka, Krzysztof Wielicki, Piotr Pustelnik, Andrzej Zawada, Maciej Berbeka, Artur Hajzer, Andrzej Czok, Wojciech Kurtyka, and women Wanda Rutkiewicz, and Kinga Baranowska. Polish mountains are one of the tourist attractions of the country. Hiking, climbing, skiing and mountain biking and attract numerous tourists every year from all over the world. Water sports are the most popular summer recreation activities, with ample locations for fishing, canoeing, kayaking, sailing and windsurfing especially in the northern regions of the country.
International rankings.
The following are links to international rankings of Poland from selected research institutes and foundations including economic output and various composite indices.

</doc>
<doc id="22938" url="https://en.wikipedia.org/wiki?curid=22938" title="Performing arts">
Performing arts

Performing arts are art forms in which artists use their voices and/or the movements of their bodies, often in relation to other objects, to convey artistic expression—as opposed to, for example, purely visual arts, in which artists use paint/canvas or various materials to create physical or static art objects. Performing arts include a variety of disciplines but all are intended to be performed in front of a live audience.
Performers.
Artists who participate in performing arts in front of an audience are called performers. Example of this include actors, comedians, dancers, magicians, circus artists, musicians, and singers. Performing arts are also supported by workers in related fields, such as songwriting, choreography and stagecraft.
A performer who excels in acting, singing, and dancing is commonly referred to as a "triple threat". Well-known examples of historical triple threat artists include Gene Kelly, Fred Astaire, and Judy Garland.
Performers often adapt their appearance, such as with costumes and stage makeup, stage lighting, and sound.
Types.
Performing arts may include dance, music, opera, theatre and musical theatre, magic, illusion, mime, spoken word, puppetry, circus arts, performance art, recitation and public speaking.
There is also a specialized form of fine art, in which the artists "perform" their work live to an audience. This is called performance art. Most performance art also involves some form of plastic art, perhaps in the creation of props. Dance was often referred to as a "plastic art" during the Modern dance era.
Theatre.
Theatre is the branch of performing arts; concerned with acting out stories in front of an audience, using a combination of speech, gesture, music, dance, sound and spectacle. Any one or more of these elements is performing arts. In addition to the standard narrative dialogue style of plays. Theatre takes such forms as plays, musicals, opera, ballet, illusion, mime, classical Indian dance, kabuki, mummers' plays, improvisational theatre, stand-up comedy, pantomime, and non-conventional or contemporary forms like postmodern theatre, postdramatic theatre, or performance art .
Dance.
In the context of performing arts, dance generally refers to human movement, typically rhythmic and to music, used as a form of audience entertainment in a performance setting. Definitions of what constitutes dance are dependent on social, cultural, aesthetic artistic and moral constraints and range from functional movement (such as folk dance) to codified, virtuoso techniques such as ballet.
Dance is a powerful impulse, but the art of dance is that impulse channeled by skillful performers into something that becomes intensely expressive and that may delight spectators who feel no wish to dance themselves. These two concepts of the art of dance—dance as a powerful impulse and dance as a skillfully choreographed art practiced largely by a professional few—are the two most important connecting ideas running through any consideration of the subject. In dance, the connection between the two concepts is stronger than in some other arts, and neither can exist without the other.
Choreography is the art of making dances, and the person who practices this art is called a choreographer.
Music.
Music is an art form which combines pitch, rhythm, and dynamic in order to create sound. It can be performed using a variety of instruments and styles and is divided into genres. As an art form, music can occur in live or recorded formats, and can be planned or improvised.
History.
History of Western performing arts.
Starting in the 6th century BC, the Classical period of performing art began in Greece, ushered in by the tragic poets such as Sophocles. These poets wrote plays which, in some cases, incorporated dance (see Euripides). The Hellenistic period began the widespread use of comedy.
However, by the 6th century AD, Western performing arts had been largely ended, as the Dark Ages began. Between the 9th century and 14th century, performing art in the West was limited to religious historical enactments and morality plays, organized by the Church in celebration of holy days and other important events.
Renaissance.
In the 15th century performing arts, along with the arts in general, saw a revival as the Renaissance began in Italy and spread throughout Europe plays, some of which incorporated dance, which were performed and Domenico da Piacenza credited with the first use of the term "ballo" (in "De Arte Saltandi et Choreas Ducendi") instead of "danza" (dance) for his "baletti" or "balli". The term eventually became "Ballet". The first Ballet "per se" is thought to be Balthasar de Beaujoyeulx's Ballet Comique de la Reine (1581).
By the mid-16th century Commedia Dell'arte became popular in Europe, introducing the use of improvisation. This period also introduced the Elizabethan masque, featuring music, dance and elaborate costumes as well as professional theatrical companies in England. William Shakespeare's plays in the late 16th century developed from this new class of professional performance.
In 1597, the first opera, Dafne was performed and throughout the 17th century, opera would rapidly become the entertainment of choice for the aristocracy in most of Europe, and eventually for large numbers of people living in cities and towns throughout Europe.
Modern era.
The introduction of the proscenium arch in Italy during the 17th century established the traditional theatre form that persists to this day. Meanwhile, in England, the Puritans forbade acting, bringing a halt to performing arts that lasted until 1660. After that, women began to appear in both French and English plays. The French introduced a formal dance instruction in the late 17th century.
It is also during this time that the first plays were performed in the American Colonies.
During the 18th century, the introduction of the popular opera buffa brought opera to the masses as an accessible form of performance. Mozart's "The Marriage of Figaro" and "Don Giovanni" are landmarks of the late 18th century opera.
At the turn of the 19th century, Beethoven and the Romantic movement ushered in a new era that led first to the spectacles of grand opera and then to the musical dramas of Giuseppe Verdi and the Gesamtkunstwerk (total work of art) of the operas of Richard Wagner leading directly to the music of the 20th century.
The 19th century was a period of growth for the performing arts for all social classes, technical advances such as the introduction of gaslight to theatres, burlesque, minstrel dancing, and variety theatre. In ballet, women make great progress in the previously male-dominated art.
Modern dance began in the late 19th century and early 20th century in response to the restrictions of traditional ballet.
Konstantin Stanislavski's "System" revolutionized acting in the early 20th century, and continues to have a major influence on actors of stage and screen to the current day. Both impressionism and modern realism were introduced to the stage during this period.
The arrival of Sergei Diaghilev's Ballets Russes (1909–1929) revolutionized ballet and the performing arts generally throughout the Western world, most importantly through Diaghilev's emphasis on collaboration, which brought choreographers, dancers, set designers/artists, composers and musicians together to revitalize and revolutionize ballet. It is extremely complex.
With the invention of the motion picture in the late 19th century by Thomas Edison and the growth of the motion picture industry in Hollywood in the early 20th century, film became a dominant performance medium throughout the 20th and 21st centuries.
Rhythm and blues, a cultural phenomenon of black America, became to prominence in the early 20th century; influencing a range of later popular music styles internationally.
In the 1930s Jean Rosenthal introduced what would become modern stage lighting, changing the nature of the stage as the Broadway musical became a phenomenon in the United States.
Post-War performance.
Post-World War II performing arts were highlighted by the resurgence of both ballet and opera in the Western world.
Postmodernism in performing arts dominated the 1960s to large extent.
History of Eastern performing arts.
Middle East.
The earliest recorded theatrical event dates back to 2000 BC with the passion plays of Ancient Egypt. This story of the god Osiris was performed annually at festivals throughout the civilization, marking the known beginning of a long relationship between theatre and religion.
The most popular forms of theater in the medieval Islamic world were puppet theatre (which included hand puppets, shadow plays and marionette productions) and live passion plays known as "ta'ziya", where actors re-enact episodes from Muslim history. In particular, Shia Islamic plays revolved around the "shaheed" (martyrdom) of Ali's sons Hasan ibn Ali and Husayn ibn Ali. Live secular plays were known as "akhraja", recorded in medieval "adab" literature, though they were less common than puppetry and "ta'ziya" theater.
Iran.
In Iran there are other forms of theatrical events such as "Naghali" (story telling), "ٰRu-Howzi", "Siah-Bazi", "Parde-Khani, ""Mareke giri".
India and Pakistan.
Folk theatre and dramatics can be traced to the religious ritualism of the Vedic peoples in the 2nd millennium BC. This folk theatre of the misty past was mixed with dance, food, ritualism, plus a depiction of events from daily life. The last element made it the origin of the classical theatre of later times. Many historians, notably D. D. Kosambi, Debiprasad Chattopadhyaya, Adya Rangacharaya, etc. have referred to the prevalence of ritualism amongst Indo-Aryan tribes in which some members of the tribe acted as if they were wild animals and some others were the hunters. Those who acted as mammals like goats, buffaloes, reindeer, monkeys, etc. were chased by those playing the role of hunters.
Bharata Muni (fl. 5th–2nd century BC) was an ancient Indian writer best known for writing the "Natya Shastra of Bharata", a theoretical treatise on Indian performing arts, including theatre, dance, acting, and music, which has been compared to Aristotle's "Poetics". Bharata is often known as the father of Indian theatrical arts. His "Natya Shastra" seems to be the first attempt to develop the technique or rather art, of drama in a systematic manner. The Natya Shastra tells us not only what is to be portrayed in a drama, but how the portrayal is to be done. Drama, as Bharata Muni says, is the imitation of men and their doings ("loka-vritti"). As men and their doings have to be respected on the stage, so drama in Sanskrit is also known by the term "roopaka," which means portrayal.
The "Ramayana" and "Mahabharata" can be considered the first recognized plays that originated in India. These epics provided the inspiration to the earliest Indian dramatists and they do it even today. Indian dramatists such as Bhāsa in the 2nd century BC wrote plays that were heavily inspired by the "Ramayana" and "Mahabharata".
Kālidāsa in the 1st century BC, is arguably considered to be ancient India's greatest dramatist. Three famous romantic plays written by Kālidāsa are the "Mālavikāgnimitram" ("Mālavikā and Agnimitra"), "Vikramōrvaśīyam" ("Pertaining to Vikrama and Urvashi"), and "Abhijñānaśākuntala" ("The Recognition of Shakuntala"). The last was inspired by a story in the "Mahabharata" and is the most famous. It was the first to be translated into English and German. In comparison to Bhāsa, who drew heavily from the epics, Kālidāsa can be considered an original playwright.
The next great Indian dramatist was Bhavabhuti (c. 7th century). He is said to have written the following three plays: "Malati-Madhava", "Mahaviracharita" and "Uttar Ramacharita". Among these three, the last two cover between them, the entire epic of "Ramayana". The powerful Indian emperor Harsha (606–648) is credited with having written three plays: the comedy "Ratnavali", "Priyadarsika", and the Buddhist drama "Nagananda". Many other dramatists followed during the Middle Ages.
There were many performing art forms in the southern part of India, Kerala is such a state with different such art forms like Koodiyattam, Nangyarkoothu, Kathakali, Chakyar koothu and there were many prominent artists like Painkulam Raman Chakyar and others.
China.
There are references to theatrical entertainments in China as early as 1500 BC during the Shang Dynasty; they often involved music, clowning and acrobatic displays.
The Tang dynasty is sometimes known as "The Age of 1000 Entertainments". During this era, Emperor Xuanzong formed an acting school known as the Children of the Pear Garden to produce a form of drama that was primarily musical.
During the Han Dynasty, shadow puppetry first emerged as a recognized form of theatre in China. There were two distinct forms of shadow puppetry, Cantonese southern and Pekingese northern. The two styles were differentiated by the method of making the puppets and the positioning of the rods on the puppets, as opposed to the type of play performed by the puppets. Both styles generally performed plays depicting great adventure and fantasy, rarely was this very stylized form of theatre used for political propaganda. Cantonese shadow puppets were the larger of the two. They were built using thick leather that created more substantial shadows. Symbolic color was also very prevalent; a black face represented honesty, a red one bravery. The rods used to control Cantonese puppets were attached perpendicular to the puppets' heads. Thus, they were not seen by the audience when the shadow was created. Pekingese puppets were more delicate and smaller. They were created out of thin, translucent leather usually taken from the belly of a donkey. They were painted with vibrant paints, thus they cast a very colorful shadow. The thin rods that controlled their movements were attached to a leather collar at the neck of the puppet. The rods ran parallel to the bodies of the puppet then turned at a ninety degree angle to connect to the neck. While these rods were visible when the shadow was cast, they laid outside the shadow of the puppet; thus they did not interfere with the appearance of the figure. The rods attached at the necks to facilitate the use of multiple heads with one body. When the heads were not being used, they were stored in a muslin book or fabric lined box. The heads were always removed at night. This was in keeping with the old superstition that if left intact, the puppets would come to life at night. Some puppeteers went so far as to store the heads in one book and the bodies in another, to further reduce the possibility of reanimating puppets. Shadow puppetry is said to have reached its highest point of artistic development in the 11th century before becoming a tool of the government.
In the Song dynasty, there were many popular plays involving acrobatics and music. These developed in the Yuan Dynasty into a more sophisticated form with a four- or five-act structure. Yuan drama spread across China and diversified into numerous regional forms, the best known of which is Beijing Opera, which is still popular today.
Thailand.
In Thailand, it has been a tradition from the Middle Ages to stage plays based on plots drawn from Indian epics. In particular, the theatrical version of Thailand's national epic "Ramakien", a version of the Indian "Ramayana", remains popular in Thailand even today.
Cambodia.
In Cambodia, at the ancient capital Angkor Wat, stories from the Indian epics "Ramayana" and "Mahabharata" have been carved on the walls of temples and palaces. Similar reliefs are found at Borobudur in Indonesia.
Japan.
During the 14th century, there were small companies of actors in Japan who performed short, sometimes vulgar comedies. A director of one of these companies, Kan'ami (1333–1384), had a son, Zeami Motokiyo (1363–1443) who was considered one of the finest child actors in Japan. When Kan'ami's company performed for Ashikaga Yoshimitsu (1358–1408), the Shogun of Japan, he implored Zeami to have a court education for his arts. After Zeami succeeded his father, he continued to perform and adapt his style into what is today Noh. A mixture of pantomime and vocal acrobatics, this style has fascinated the Japanese for hundreds of years.
Japan, after a long period of civil wars and political disarray, was unified and at peace primarily due to shogun Tokugawa Ieyasu (1600–1668). However, alarmed at increasing Christian growth, he cut off contact from Japan to Europe and China and outlawed Christianity. When peace did come, a flourish of cultural influence and growing merchant class demanded its own entertainment. The first form of theatre to flourish was Ningyō jōruri (commonly referred to as Bunraku). The founder of and main contributor to Ningyō jōruri, Chikamatsu Monzaemon (1653–1725), turned his form of theatre into a true art form. Ningyō jōruri is a highly stylized form of theatre using puppets, today about 1/3d the size of a human. The men who control the puppets train their entire lives to become master puppeteers, when they can then operate the puppet's head and right arm and choose to show their faces during the performance. The other puppeteers, controlling the less important limbs of the puppet, cover themselves and their faces in a black suit, to imply their invisibility. The dialogue is handled by a single person, who uses varied tones of voice and speaking manners to simulate different characters. Chikamatsu wrote thousands of plays during his lifetime, most of which are still used today.
Kabuki began shortly after Bunraku, legend has it by an actress named Okuni, who lived around the end of the 16th century. Most of Kabuki's material came from Nõ and Bunraku, and its erratic dance-type movements are also an effect of Bunraku. However, Kabuki is less formal and more distant than Nõ, yet very popular among the Japanese public. Actors are trained in many varied things including dancing, singing, pantomime, and even acrobatics. Kabuki was first performed by young girls, then by young boys, and by the end of the 16th century, Kabuki companies consisted of all men. The men who portrayed women on stage were specifically trained to elicit the essence of a woman in their subtle movements and gestures.

</doc>
