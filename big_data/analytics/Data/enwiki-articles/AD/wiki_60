<doc id="22102" url="https://en.wikipedia.org/wiki?curid=22102" title="Naval mine">
Naval mine

A naval mine is a self-contained explosive device placed in water to damage or destroy surface ships or submarines. Unlike depth charges, mines are deposited and left to wait until they are triggered by the approach of, or contact with, an enemy vessel. Naval mines can be used offensively—to hamper enemy shipping movements or lock vessels into a harbour; or defensively—to protect friendly vessels and create "safe" zones.
Description.
Mines can be laid in many ways: by purpose-built minelayers, refitted ships, submarines, or aircraft—and even by dropping them into a harbour by hand. They can be inexpensive: some variants can cost as little as US$2000, though more sophisticated mines can cost millions of dollars, be equipped with several kinds of sensors, and deliver a warhead by rocket or torpedo.
Their flexibility and cost-effectiveness make mines attractive to the less powerful belligerent in asymmetric warfare. The cost of producing and laying a mine is usually anywhere from 0.5% to 10% of the cost of removing it, and it can take up to 200 times as long to clear a minefield as to lay it. Parts of some World War II naval minefields still exist because they are too extensive and expensive to clear. It is possible for some of these 1940s-era mines to remain dangerous for many years to come.
Mines have been employed as offensive or defensive weapons in rivers, lakes, estuaries, seas, and oceans, but they can also be used as tools of psychological warfare. Offensive mines are placed in enemy waters, outside harbours and across important shipping routes with the aim of sinking both merchant and military vessels. Defensive minefields safeguard key stretches of coast from enemy ships and submarines, forcing them into more easily defended areas, or keeping them away from sensitive ones.
Minefields designed for psychological effect are usually placed on trade routes and are used to stop shipping from reaching an enemy nation. They are often spread thinly, to create an impression of minefields existing across large areas. A single mine inserted strategically on a shipping route can stop maritime movements for days while the entire area is swept.
International law requires nations to declare when they mine an area, in order to make it easier for civil shipping to avoid the mines. The warnings do not have to be specific; for example, during World War II, Britain declared simply that it had mined the English Channel, North Sea, and French coast.
History.
Early use.
The precursor to naval mines was first described by the early Ming dynasty Chinese artillery officer Jiao Yu, in his 14th century military treatise known as the "Huolongjing". Chinese records tell of naval explosives in the 16th century, used to fight against Japanese pirates ("wokou"). This kind of naval mine was loaded in a wooden box, sealed with putty. General Qi Jiguang made several timed, drifting explosives, to harass Japanese pirate ships. However, in the "Tiangong Kaiwu" ("The Exploitation of the Works of Nature") treatise, written by Song Yingxing in 1637 AD, it describes naval mines with a rip cord pulled by hidden ambushers located on the nearby shore who rotated a steel wheellock flint mechanism to produce sparks and ignite the fuse of the naval mine. Although this is the rotating steel wheellock's first use with naval mines, Jiao Yu had described their use for land mines back in the 14th century.
The first plan for a sea mine in the West was by Ralph Rabbards, who presented his design to Queen Elizabeth I of England in 1574. The Dutch inventor Cornelius Drebbel was employed in the Office of Ordnance by King Charles I of England to make weapons, including a "floating petard" which proved a failure. Weapons of this type were apparently tried by the English at the Siege of La Rochelle in 1627.
American David Bushnell invented the first practical mine, for use against the British in the American War of Independence. It was a watertight keg filled with gunpowder that was floated toward the enemy, detonated by a sparking mechanism if it struck a ship. It was used on the Delaware River as a drift mine, and was regarded as unethical.
19th century.
In 1812 Russian engineer Pavel Shilling exploded an underwater mine using an electrical circuit. In 1854, during the unsuccessful attempt of the Anglo-French fleet to seize the Kronstadt fortress, British steamships HMS "Merlin" (9 June 1855, the first successful mining in history), HMS "Vulture" and HMS "Firefly" suffered damage due to the underwater explosions of Russian naval mines. Russian naval specialists set more than 1500 naval mines, or "infernal machines", designed by Moritz von Jacobi and by Immanuel Nobel,
in the Gulf of Finland during the Crimean War of 1853-1856. The mining of "Vulcan" led to the world's first minesweeping operation.
During the next 72 hours, 33 mines were swept.
The American Civil War of 1861-1865 also saw the successful use of mines. The first ship sunk by a mine, , foundered in 1862 in the Yazoo River. Rear Admiral David Farragut's famous/apocryphal command during the Battle of Mobile Bay in 1864, "Damn the torpedoes, full speed ahead!" refers to a minefield laid at Mobile, Alabama.
In the 19th century, mines were called torpedoes, a name probably conferred by Dennis Fletcher after the torpedo fish, which gives powerful electric shocks. A spar torpedo was a mine attached to a long pole and detonated when the ship carrying it rammed another one and withdrew a safe distance. The submarine used one to sink on 17 February 1864. A Harvey torpedo was a type of floating mine towed alongside a ship, and was briefly in service in the Royal Navy in the 1870s. Other "torpedoes" were attached to ships or propelled themselves. One such weapon, called the Whitehead torpedo after its inventor, caused the word "torpedo" to apply to self-propelled underwater missiles as well as to static devices. These mobile devices were also known as "fish torpedos".
After 1865 the United States adopted the mine as its primary weapon for coastal defense. In the decade following 1868, Major Henry Larcom Abbot carried out a lengthy set of experiments to design and test moored mines that could be exploded on contact or be detonated at will as enemy shipping passed near them. This initial development of mines in the United States took place under the purview of the U.S. Army Corps of Engineers, which trained officers and men in their use at the Engineer School of Application at Willets Point, New York (later the site of Fort Totten).
The Imperial Russian Navy, a pioneer in mine warfare, successfully deployed mines against the Ottoman Navy during both the Crimean War and the Russo-Turkish War (1877-1878).
During the Battle of Tamsui (1884), in the Keelung Campaign of the Sino-French War, Chinese forces in Taiwan under Liu Mingchuan took measures to reinforce Tamsui against the French; they planted nine torpedo mines in the river and blocked the entrance.
Early 20th century.
During the Boxer Rebellion, Imperial Chinese forces deployed a command-detonated mine field at the mouth of the Peiho river before the Dagu forts, to prevent the western Allied forces from sending ships to attack.
The next major use of mines was during the Russo-Japanese War of 1904–1905. They proved their worth as weapons in this conflict. For instance, two mines blew up when the struck them near Port Arthur, sending the holed vessel to the bottom and killing the fleet commander, Admiral Stepan Makarov, and most of his crew in the process. The toll inflicted by mines was not confined to the Russians, however. The Japanese Navy lost two battleships, four cruisers, two destroyers and a torpedo-boat to offensively laid mines during the war. Most famously, on May 15, 1904, the Russian minelayer "Amur" planted a 50-mine minefield off Port Arthur and succeeded in sinking the Japanese battleships and .
Following the end of the Russo-Japanese War, several nations attempted to have mines banned as weapons of war at the Hague Peace Conference (1907).
Many early mines were fragile and dangerous to handle, as they contained glass containers filled with nitroglycerin or mechanical devices that activated a blast upon tipping. Several mine-laying ships were destroyed when their cargo exploded.
Beginning around the start of the 20th century, submarine mines played a major role in the defense of U.S. harbors against enemy attack as part of the Endicott and Taft Programs. The mines employed were controlled mines, anchored to the bottoms of the harbors and detonated under control from large mine casemates on shore.
During World War I, mines were used extensively to defend coasts, coastal shipping, ports and naval bases around the globe. The Germans laid mines in shipping lanes to sink merchant and naval vessels serving Britain. The Allies targeted the German U-boats in the Strait of Dover and the Hebrides. In an attempt to seal up the northern exits of the North Sea, the Allies developed the North Sea Mine Barrage. During a period of five months from June 1918 almost 70,000 mines were laid spanning the North Sea's northern exits. The total number of mines laid in the North Sea, the British East Coast, Straits of Dover, and Heligoland Bight is estimated at 190,000 and the total number during the whole of WWI was 235,000 sea mines. Clearing the barrage after the war took 82 ships and five months, working around the clock.
World War II.
During World War II, the U-boat fleet, which dominated much of the battle of the Atlantic, was small at the beginning of the war and much of the early action by German forces involved mining convoy routes and ports around Britain. German submarines also operated in the Mediterranean Sea, in the Caribbean Sea, and along the U.S. coast.
Initially, contact mines—requiring a ship physically strike a mine to detonate it—were employed, usually tethered at the end of a cable just below the surface of the water. Contact mines usually blew a hole in ships' hulls. By the beginning of World War II, most nations had developed mines that could be dropped from aircraft and floated on the surface, making it possible to lay them in enemy harbours. The use of dredging and nets was effective against this type of mine, but this consumed valuable time and resources, and required harbours to be closed.
Later, some ships survived mine blasts, limping into port with buckled plates and broken backs. This appeared to be due to a new type of mine, detecting ships by their proximity to the mine (an influence mine) and detonating at a distance, causing damage with the shock wave of the explosion. Ships that had successfully run the gauntlet of the Atlantic crossing were sometimes destroyed entering freshly cleared British harbours. More shipping was being lost than could be replaced, and Churchill ordered the intact recovery of one of these new mines to be of the highest priority.
The British experienced a stroke of luck in November 1939. A German mine was dropped from an aircraft onto the mud flats off Shoeburyness during low tide. As if this was not sufficiently good fortune, the land belonged to the army, and a base with men and workshops was at hand. Experts were dispatched from HMS Vernon to investigate the mine. They had some idea that the mines could use magnetic sensors, so everyone removed all metal, including their buttons, and made tools of non-magnetic brass. They disarmed the mine and rushed it to labs at HMS Vernon, where scientists discovered a new type of arming mechanism. A large ferrous object passing through the Earth's magnetic field will concentrate the field through it; the mine's detector was designed to trigger as a ship passed over, when its magnetic field was concentrated as measured by the mine. The mechanism had an adjustable sensitivity, calibrated in milligauss. (As it turned out, the German firing mechanism was overly sensitive, making sweeping easier.) The U.S. began adding delay counters to their magnetic mines in June 1945.
From this data, methods were developed to clear the mines. Early methods included the use of large electromagnets dragged behind ships or below low-flying aircraft (a number of older bombers like the Vickers Wellington were used for this). Both of these methods had the disadvantage of "sweeping" only a small strip. A better solution was found in the "Double-L Sweep" using electrical cables dragged behind ships that passed large pulses of current through the seawater. This induced a large magnetic field and swept the entire area between the two ships. The older methods continued to be used in smaller areas. The Suez Canal continued to be swept by aircraft, for instance. Wartime Japanese sweep methods, by contrast, never advanced much past 1930s standards, and failed entirely to keep up with new American mines, clearing no more than 15% of all the mines laid in Japan's coastal waters. Moreover, IJN's minesweeping force was far too small with 350 ships, and 20,000 men.
While these methods were useful for clearing mines from local ports, they were of little or no use for enemy-controlled areas. These were typically visited by warships, and the majority of the fleet then underwent a massive degaussing process, where their hulls had a slight "south" bias induced into them which offset the concentration effect almost to zero.
Initially, major warships and large troopships had a copper "degaussing coil" fitted around the perimeter of the hull, energized by the ship's electrical system whenever in suspected magnetic-mined waters. Some of the first to be so-fitted were the carrier HMS "Ark Royal" and the liners and . This was felt to be impracticable for the myriad of smaller warships and merchant vessels, mainly because the ships lacked the generating capacity to energise such a coil. It was found that "wiping" a current-carrying cable up and down a ship's hull temporarily cancelled the ships' magnetic signature sufficiently to nullify the threat. This started in late 1939, and by 1940 merchant vessels and the smaller British warships were largely immune for a few months at a time until they once again built up a field. Many of the boats that sailed to Dunkirk were degaussed in a marathon four-day effort by degaussing stations.
The Allies deployed acoustic mines, against which even wooden-hulled ships (in particular minesweepers) remained vulnerable. Japan developed sonic generators to sweep these; the gear was not ready by war's end. The primary method Japan used was small air-delivered bombs. This was profligate and ineffectual; used against acoustic mines at Penang, 200 bombs were needed to detonate just 13 mines.
The Germans had also developed a pressure-activated mine and planned to deploy it as well, but they saved it for later use when it became clear the British had defeated the magnetic system. The U.S. also deployed these, adding "counters" which would allow a variable number of ships to pass unharmed before detonating. This made them a great deal harder to sweep. Japan's antiquated sweep methods, lifting mines in nets, accidentally proved useful against these mines; it remained too slow and hazardous to be truly effective, especially in light of the high numbers being laid.
Mining campaigns could have devastating consequences. The U.S. effort against Japan, for instance, closed major ports, such as Hiroshima, for days, and by the end of the Pacific War had cut the amount of freight passing through Kobe–Yokohama by 90%.
When the war ended, more than 25,000 U.S.-laid mines were still in place, and the Navy proved unable to sweep them all, limiting efforts to critical areas. After sweeping for almost a year, in May 1946, the Navy abandoned the effort with 13,000 mines still unswept. Over the next thirty years, more than 500 minesweepers (of a variety of types) were damaged or sunk in continuing clearance efforts.
Cold War era.
Since World War II, mines have damaged 14 United States Navy ships, whereas air and missile attacks have damaged four. During the Korean War, mines laid by North Korean forces caused 70% of the casualties suffered by U.S. naval vessels and caused 4 sinkings.
During the Iran–Iraq War from 1980 to 1988, the belligerents mined several areas of the Persian Gulf and nearby waters. On April 14, 1988, struck an Iranian M-08/39 mine in the central Persian Gulf shipping lane, wounding 10 sailors.
In the summer of 1984, magnetic sea mines damaged at least 19 ships in the Red Sea. The U.S. concluded Libya was probably responsible for the minelaying. In response the U.S., Britain, France, and three other nations launched Operation Intense Look, a minesweeping operation in the Red Sea involving more than 46 ships.
On the orders of the Reagan administration, the CIA mined Nicaragua's Sandino port in 1984 in support of the Contra guerrilla group. A Soviet tanker was among the ships damaged by these mines. In 1986, in the case of "Nicaragua v. United States", the International Court of Justice ruled that this mining was a violation of international law.
During the Gulf War, Iraqi naval mines severely damaged and . When the war concluded, eight countries conducted clearance operations.
Types.
Naval mines may be classified into three major groups; contact, remote and influence mines.
Contact mines.
The earliest mines were usually of this type. They are still used today, as they are extremely low cost compared to any other anti-ship weapon and are effective, both as a terror weapon and to sink enemy ships. Contact mines need to be touched by the target before they detonate, limiting the damage to the direct effects of the explosion and usually affecting only the vessel that triggers them.
Early mines had mechanical mechanisms to detonate them, but these were superseded in the 1870s by the "Herz horn" (or "chemical horn"), which was found to work reliably even after the mine had been in the sea for several years. The mine's upper half is studded with hollow lead protuberances, each containing a glass vial filled with sulfuric acid. When a ship's hull crushes the metal horn, it cracks the vial inside it, allowing the acid to run down a tube and into a lead–acid battery which until then contained no acid electrolyte. This energizes the battery, which detonates the explosive.
Earlier forms of the detonator employed a vial of sulfuric acid surrounded by a mixture of potassium perchlorate and sugar. When the vial was crushed, the acid ignited the perchlorate-sugar mix, and the resulting flame ignited the gunpowder charge.
During the initial period of World War I, the British Navy used contact mines in the English Channel and later in large areas of the North Sea to hinder patrols by German submarines. Later, the American antenna mine was widely used because submarines could be at any depth from the surface to the seabed. This type of mine had a copper wire attached to a buoy that floated above the explosive charge which was weighted to the seabed with a steel cable. If a submarine's steel hull touched the copper wire, the slight voltage change caused by contact between two dissimilar metals was amplified and detonated the explosives.
Limpet mines.
Limpet mines are a special form of contact mine that are manually attached to the target by magnets and left, and are so named because of the superficial similarity to the limpet, a mollusk.
Moored contact mines.
Generally, this mine type is set to float just below the surface of the water or as deep as five meters. A steel cable connecting the mine to an anchor on the seabed prevents it from drifting away. The explosive and detonating mechanism is contained in a buoyant metal or plastic shell. The depth below the surface at which the mine floats can be set so that only deep draft vessels such as aircraft carriers, battleships or large cargo ships are at risk, saving the mine from being used on a less valuable target. In littoral waters it is important to ensure that the mine does not become visible when the sea level falls at low tide, so the cable length is adjusted to take account of tides. Even during the Second World War, there were mines that could be moored in 300m-deep water (Example: The U.S. Mark 6).
Floating mines typically have a mass of around 200 kg, including 80 kg of explosives e.g. TNT, minol or amatol.
Drifting contact mines.
Drifting mines were occasionally used during World War I and World War II. However, they were more feared than effective. Sometimes floating mines break from their moorings and become drifting mines; modern mines are designed to deactivate in this event. After several years at sea, the deactivation mechanism might not function as intended and the mines may remain live. Admiral Jellicoe's British fleet did not pursue and destroy the outnumbered German High Seas Fleet when it turned away at the Battle of Jutland because he thought they were leading him into a trap: he believed it possible that the Germans were either leaving floating mines in their wake, or were drawing him towards submarines, although neither of these was the case.
Churchill promoted "Operation Royal Marine" in 1940 and again in 1944 where floating mines were put into the Rhine in France to float down the river, becoming active after a time calculated to be long enough to reach German territory.
After World War I the drifting contact mine was banned, but was occasionally used during World War II. The drifting mines were much harder to remove than tethered mines after the war, and they caused about the same damage to both sides.
Bottom contact mines.
A bottom contact mine is the simplest form of mine. It is merely an explosive charge with some form of fuze fitted lying on the seafloor. They have been used against submarines, as submarines sometimes lie on the seafloor to reduce their acoustic signature. They are also used to prevent landing craft from reaching the shore and were a major obstacle during the D-Day landings. The Germans used antitank mines here with minor modifications to make them more reliable underwater, attaching the mines to the front of many of the obstacles seen in photos of the landing.
These mines usually weighed 2 to 50 kg, including 1 to 40 kg of explosives (TNT or hexatonal).
Remotely controlled mines.
Frequently used in combination with coastal artillery and hydrophones, controlled mines (or command detonation mines) can be in place in peacetime, which is a huge advantage in blocking important shipping routes. The mines can usually be turned into "normal" mines with a switch (which prevents the enemy from simply capturing the controlling station and deactivating the mines), detonated on a signal or be allowed to detonate on their own. The earliest ones were developed around 1812 by Robert Fulton. The first remotely controlled mines were moored mines used in the American Civil War, detonated electrically from shore. They were considered superior to contact mines because they did not put friendly shipping at risk.
Modern examples usually weigh , including of explosives (TNT or hexatonal).
Influence mines.
These mines are triggered by the influence of a ship or submarine, rather than direct contact. Such mines incorporate electronic sensors designed to detect the presence of a vessel and detonate when it comes within the blast range of the warhead. The fuzes on such mines may incorporate one or more of the following sensors: magnetic, passive acoustic or water pressure displacement caused by the proximity of a vessel.
First used during the First World War, their use became more general in the Second World War. The sophistication of influence mine fuzes has increased considerably over the years as first transistors and then microprocessors have been incorporated into designs. Simple magnetic sensors have been superseded by total-field magnetometers. Whereas early magnetic mine fuzes would respond only to changes in a single component of a target vessel's magnetic field, a total field magnetometer responds to changes in the magnitude of the total background field (thus enabling it to better detect even degaussed ships). Similarly, the original broadband hydrophones of 1940s acoustic mines (which operate on the integrated volume of all frequencies) have been replaced by narrow-band sensors which are much more sensitive and selective. Mines can now be programmed to listen for highly specific acoustic signatures (e.g. a gas turbine powerplant or cavitation sounds from a particular design of propeller) and ignore all others. The sophistication of modern electronic mine fuzes incorporating these digital signal processing capabilities makes it much more difficult to detonate the mine with electronic countermeasures because several sensors working together (e.g. magnetic, passive acoustic and water pressure) allow it to ignore signals which are not recognised as being the unique signature of an intended target vessel.
Modern influence mines such as the BAE Stonefish are computerised, with all the programmability that this implies e.g. the ability to quickly load new acoustic signatures into fuzes, or program them to detect a single, highly distinctive target signature. In this way, a mine with a passive acoustic fuze can be programmed to ignore all friendly vessels and small enemy vessels, only detonating when a very large enemy target passes over it. Alternatively, the mine can be programmed specifically to ignore all surface vessels regardless of size and exclusively target submarines.
Even as far back as the Second World War it was possible to incorporate a "ship counter" facility into mine fuzes e.g. set the mine to ignore the first two ships to pass over it (which could be minesweepers deliberately trying to trigger mines) but detonate when the third ship passes overhead—which could be a high-value target such as an aircraft carrier or oil tanker. Even though modern mines are generally powered by a long life lithium battery, it is important to conserve power because they may need to remain active for months or even years. For this reason, most influence mines are designed to remain in a semi-dormant state until an unpowered (e.g. deflection of a mu-metal needle) or low-powered sensor detects the possible presence of a vessel, at which point the mine fuze powers up fully and the passive acoustic sensors will begin to operate for some minutes. It is possible to program computerised mines to delay activation for days or weeks after being laid; similarly, they can be programmed to self-destruct or render themselves safe after a preset period of time. Generally, the more sophisticated the mine design, the more likely it is to have some form of anti-handling device fitted in order to hinder clearance by divers or remotely piloted submersibles.
Moored mines.
The moored mine is the backbone of modern mine systems. They are deployed where water is too deep for bottom mines. They can use several kinds of instruments to detect an enemy, usually a combination of acoustic, magnetic and pressure sensors, or more sophisticated optical shadows or electro potential sensors. These cost many times more than contact mines. Moored mines are effective against most kinds of ships. As they are cheaper than other anti-ship weapons they can be deployed in large numbers, making them useful area denial or "channelizing" weapons.
Moored mines usually have lifetimes of more than 10 years, and some almost unlimited. These mines usually weigh , including of explosives (RDX). In excess of of explosives the mine becomes inefficient, as it becomes too large to handle and the extra explosives add little to the mine's effectiveness.
Bottom mines.
Bottom mines are used when the water is no more than deep or when mining for submarines down to around . They are much harder to detect and sweep, and can carry a much larger warhead than a moored mine. Bottom mines commonly utilize multiple types of sensors, which are less sensitive to sweeping.
These mines usually weigh between , including between of explosives.
Unusual mines.
Several specialized mines have been developed for other purposes than the common minefield.
Bouquet mine.
The bouquet mine is a single anchor attached to several floating mines. It is designed so that when one mine is swept or detonated, another takes its place. It is a very sensitive construction and lacks reliability.
Anti-sweep mine.
The anti-sweep mine is a very small mine (40 kg warhead) with as small a floating device as possible. When the wire of a mine sweep hits the mine, it sinks, letting the sweep wire drag along the anchoring wire of the mine until the sweep hits the mine. That detonates the mine and cuts the sweeping wire. They are very cheap and usually used in combination with other mines in a minefield to make sweeping more difficult. One type is the Mark 23 used by the United States during World War II.
Oscillating mine.
The mine is hydrostatically controlled to maintain a pre-set depth below the water's surface independently of the rise and fall of the tide.
Ascending mine.
The ascending mine is a floating distance mine that may cut its mooring or in some other way float higher when it detects a target. It lets a single floating mine cover a much larger depth range.
Homing mines.
These are mines containing a moving weapon as a warhead, either a torpedo or a rocket.
Rocket mine: a Russian invention, the rocket mine is a bottom distance mine that fires a homing high-speed rocket (not torpedo) upwards towards the target. It is intended to allow a bottom mine to attack surface ships as well as submarines from a greater depth. One type is the Te-1 rocket propelled mine.
Torpedo mine: the torpedo mine is a self-propelled variety, able to lie in wait for a target and then pursue it e.g. the Mark 60 CAPTOR. Other designs such as the Mk 67 submarine launched mobile mine (which is based on a Mark 37 torpedo) are capable of travelling as far as 10 miles through or into a channel, harbor, shallow water area and other zones which would normally be inaccessible to craft laying the device. After reaching the target area they sink to the sea bed and act like conventionally laid influence mines. Generally, torpedo mines incorporate computerised acoustic and magnetic fuzes.
The U.S. Mark 24 "mine", code-named Fido, was actually an ASW homing torpedo. The mine designation was disinformation to conceal its function.
Mobile mine.
The mine is propelled to its intended position by propulsion equipment such as a torpedo. After reaching its destination, it sinks to the seabed and operates like a standard mine. It differs from the homing mine in that its mobile stage is before it lays in wait, rather than as part of the attacking phase.
Nuclear mine.
During the Cold War a test was conducted with naval mine fitted with tactical nuclear warheads for the "Baker" shot of Operation Crossroads. This weapon was experimental and never went into production. There have been some reports that North Korea may be developing a nuclear mine The Seabed Arms Control Treaty prohibits the placement of nuclear weapons on the seabed beyond a 12-mile coast zone.
Daisy-chained mine.
This comprises two moored, floating contact mines which are tethered together by a length of steel cable or chain. Typically, each mine is situated approximately away from its neighbour, and each floats a few metres below the surface of the ocean. When the target ship hits the steel cable, the mines on either side are drawn down the side of the ship's hull, exploding on contact. In this manner it is almost impossible for target ships to pass safely between two individually moored mines. Daisy-chained mines are a very simple concept which was used during World War II.
Dummy mine.
Plastic drums filled with sand or concrete are periodically rolled off the side of ships as real mines are laid in large mine-fields. These inexpensive false targets (designed to be of a similar shape and size as genuine mines) are intended to slow down the process of mine clearance: a mine-hunter is forced to investigate each suspicious sonar contact on the sea bed, whether it is real or not. Often a maker of naval mines will provide both training and dummy versions of their mines.
Mine laying.
Historically several methods were used to lay mines. During the First and Second world wars, the Germans used U-boats to lay mines around the UK. In the Second World War, aircraft came into favour for mine laying with one of the largest such examples being the mining of the Japanese sea routes in Operation Starvation.
Laying a minefield is a relatively fast process with specialized ships, which is still today the most common method. These minelayers can carry several thousand mines and manoeuvre with high precision. The mines are dropped at predefined intervals into the water behind the ship. Each mine is recorded for later clearing, but it is not unusual for these recordings to be lost together with the ships. Therefore, many countries demand that all mining operations be planned on land and records kept so the mines can later be recovered more easily.
Other methods to lay minefields include:
In some cases, mines are automatically activated upon contact with the water. In others, a safety lanyard is pulled (e.g. one end attached to the rail of a ship, aircraft or torpedo tube) which starts an automatic timer countdown before the arming process is complete. Typically, the automatic safety-arming process takes some minutes to complete. This is in order to give the people laying the mines sufficient time to move out of its activation and blast zones.
Aerial mining in World War II.
Germany.
In the 1930s, Germany had experimented with the laying of mines by aircraft; it became a crucial element in their overall mining strategy. Aircraft had the advantage of speed, and they would never get caught in their own minefields. German mines held a large explosive charge. From April to June 1940, the Luftwaffe laid 1,000 mines in British waters. Soviet ports were mined, as was the Arctic convoy route to Murmansk. The Heinkel He 115 could carry two medium or one large mine while the Heinkel He 59, Dornier Do 18, Junkers Ju 88 and Heinkel He 111 could carry more.
Soviet Union.
The USSR was relatively ineffective in its use of naval mines in WWII in comparison with its record in previous wars. Small mines were developed for use in rivers and lakes, and special mines for shallow water. A very large chemical mine was designed to sink through ice with the aid of a melting compound. Special aerial mine designs finally arrived in 1943–1944, the AMD-500 and AMD-1000. Various Soviet Naval Aviation torpedo bombers were pressed into the role of aerial mining in the Baltic Sea and the Black Sea, including Ilyushin DB-3s, Il-4s and Lend Lease Douglas Boston IIIs.
United Kingdom.
In September 1939, the UK announced the placement of extensive defensive minefields in waters surrounding the Home Islands. Offensive aerial mining operations began in April 1940 when 38 mines were laid at each of these locations: the Elbe River, the port of Lübeck and the German naval base at Kiel. In the next 20 months, mines delivered by aircraft sank or damaged 164 Axis ships with the loss of 94 aircraft. By comparison, direct aerial attacks on Axis shipping had sunk or damaged 105 vessels at a cost of 373 aircraft lost. The advantage of aerial mining became clear, and the United Kingdom geared up for it. A total of 48,000 aerial mines were laid by the Royal Air Force (RAF) in the European Theatre during World War II.
United States.
The United States' early aerial mining efforts used smaller aircraft unable to carry many mines. Using TBF Avenger torpedo bombers, the US Navy mounted a direct aerial mining attack on enemy shipping in Palau on 30 March 1944 in concert with simultaneous conventional bombing and strafing attacks. The dropping of 78 mines stopped 32 Japanese ships from escaping Koror harbor; the combined operation sank or damaged 36 ships. Two Avengers were lost; and their crews were recovered. The mines brought port usage to a halt for 20 days; further mine-laying in the area contributed to the Japanese abandoning Palau as a base.
As early as 1942, American mining experts such as Naval Ordnance Laboratory scientist Dr. Ellis A. Johnson, CDR USNR, suggested massive aerial mining operations against Japan's "outer zone" (Korea and northern China) as well as the "inner zone", their home islands. First, aerial mines would have to be developed further and manufactured in large numbers. Second, laying the mines would require a sizable air group. The US Army Air Force had the carrying capacity but considered mining to be the navy's job. The US Navy lacked suitable aircraft. Johnson set about convincing General Curtis LeMay of the efficacy of very heavy bombers laying aerial mines.
In the meantime, B-24 Liberators, PBY Catalinas and other available bomber aircraft took part in localized mining operations in the Southwest Pacific and the China Burma India (CBI) theaters, beginning with a very successful attack on the Yangon River in February 1943. Aerial minelaying operations involved a coalition of British, Australian and American aircrews, with the RAF and the Royal Australian Air Force (RAAF) carrying out 60% of the sorties and the USAAF and US Navy covering 40%. Both British and American mines were used. Japanese merchant shipping suffered tremendous losses, while Japanese mine sweeping forces were spread too thin attending to far-flung ports and extensive coastlines. Admiral Thomas C. Kinkaid, who directed nearly all RAAF mining operations in CBI, heartily endorsed aerial mining, writing in July 1944 that "aerial mining operations were of the order of 100 times as destructive to the enemy as an equal number of bombing missions against land targets."
In March 1945, Operation Starvation began in earnest, using 160 of LeMay's B-29 Superfortress bombers to attack Japan's inner zone. Almost half of the mines were the US-built Mark 25 model, carrying 1250 lbs of explosives and weighing about 2,000 lbs. Other mines used included the smaller 1,000 lb Mark 26. Fifteen B-29s were lost while 293 Japanese merchant ships were sunk or damaged. Twelve thousand aerial mines were laid, a significant barrier to Japan's access to outside resources. Prince Fumimaro Konoe said after the war that the aerial mining by B-29s had been "equally as effective as the B-29 attacks on Japanese industry at the closing stages of the war when all food supplies and critical material were prevented from reaching the Japanese home islands." The United States Strategic Bombing Survey (Pacific War) concluded that it would have been more efficient to combine the United States's effective anti-shipping submarine effort with land- and carrier-based air power to strike harder against merchant shipping and begin a more extensive aerial mining campaign earlier in the war. Survey analysts projected that this would have starved Japan, forcing an earlier end to the war. After the war, Dr. Johnson looked at the Japan inner zone shipping results, comparing the total economic cost of submarine-delivered mines versus air-dropped mines and found that, though 1 in 12 submarine mines connected with the enemy as opposed to 1 in 21 for aircraft mines, the aerial mining operation was about ten times less expensive per enemy ton sunk.
Clearing WWII aerial mines.
Between 600,000 and 1,000,000 naval mines of all types were laid in World War II. Advancing military forces worked to clear mines from newly taken areas, but extensive minefields remained in place after the war. Air-dropped mines had an additional problem for mine sweeping operations: they were not meticulously charted. In Japan, much of the B-29 mine-laying work had been performed at high altitude, with the drifting on the wind of mines carried by parachute adding a randomizing factor to their placement. Generalized danger areas were identified, with only the quantity of mines given in detail. Mines used in Operation Starvation were supposed to be self-sterilizing, but the circuit did not always work. Clearing the mines from Japanese waters took so many years that the task was eventually given to the Japan Maritime Self-Defense Force.
For the purpose of clearing all types of naval mines, the Royal Navy employed German crews and minesweepers from June 1945 to January 1948, organised in the German Mine Sweeping Administration (GMSA), which consisted of 27,000 members of the former "Kriegsmarine" and 300 vessels. Mine clearing was not always successful: a number of ships were damaged or sunk by mines after the war. Two such examples were the liberty ships "Pierre Gibault" which was scrapped after hitting a mine in a previously cleared area off the Greek island of Kythira in June 1945, and "Nathaniel Bacon" which hit a minefield off Civitavecchia, Italy in December 1945, caught fire, was beached, and broke in two.
Damage.
The damage that may be caused by a mine depends on the "shock factor value", a combination of the initial strength of the explosion and of the distance between the target and the detonation. When taken in reference to ship hull plating, the term "Hull Shock Factor" (HSF) is used, while keel damage is termed "Keel Shock Factor" (KSF). If the explosion is directly underneath the keel, then HSF is equal to KSF, but explosions that are not directly underneath the ship will have a lower value of KSF.
Direct damage.
Usually only created by contact mines, direct damage is a hole blown in the ship. Among the crew, fragmentation wounds are the most common form of damage. Flooding typically occurs in one or two main watertight compartments which can sink smaller ships or disable larger ones. Contact mine damage often occurs at or close to the waterline near the bow, but depending on circumstances a ship could be hit anywhere on its outer hull surface (the mine attack being a good example of a contact mine detonating amidships and underneath the ship).
Bubble jet effect.
The bubble jet effect occurs when a mine or torpedo detonates in the water a short distance away from the targeted ship. The explosion creates a bubble in the water, and due to the difference in pressure, the bubble will collapse from the bottom. The bubble is buoyant and so it rises towards the surface. If the bubble reaches the surface as it collapses it can create a pillar of water that can go over a hundred meters into the air (a "columnar plume"). If conditions are right and the bubble collapses onto the ship's hull, the damage to the ship can be extremely serious; the collapsing bubble forms a high energy jet that can break a meter wide hole straight through the ship, flooding one or more compartments, and is capable of breaking smaller ships apart. The crew in the areas hit by the pillar are usually killed instantly. Other damage is usually limited.
The Baengnyeong incident, in which the ROKS "Cheonan" broke in half and sank off the coast South Korea in 2010, was caused by the bubble jet effect according to an international investigation.
Shock effect.
If the mine detonates at a distance from the ship, the change in water pressure causes the ship to resonate. This is frequently the most deadly type of explosion, if it is strong enough. The whole ship is dangerously shaken and everything on board is tossed around. Engines rip from their beds, cables from their holders, etc.. A badly shaken ship usually sinks quickly, with hundreds, or even thousands of small leaks all over the ship and no way to power the pumps. The crew fare no better, as the violent shaking tosses them around. This shaking is powerful enough to cause disabling injury to knees and other joints in the body, particularly if the affected person stands on surfaces connected directly to the hull (such as steel decks).
The resulting gas cavitation and shock-front-differential over the width of the human body is sufficient to stun or kill divers.
Countermeasures.
Weapons are frequently a few steps ahead of countermeasures, and mines are no exception. In this field the British, with their large seagoing navy, have had the bulk of world experience, and most anti-mine developments, such as degaussing and the double-L sweep were British inventions. When on operational missions, such as the recent invasion of Iraq, the US still relies on British and Canadian minesweeping services. The US has worked on some innovative mine hunting countermeasures, such as the use of military dolphins to detect and flag mines. However, they are of questionable effectiveness.
Passive countermeasures.
Ships can be designed to be difficult for mines to detect, to avoid detonating them. This is especially true for minesweepers and mine hunters that work in minefields, where a minimal signature outweighs the need for armour and speed. These ships have hulls of glass fibre or wood instead of steel to avoid magnetic signatures, they use special propulsion systems, such as Voith-Schneider propellers, to limit the acoustic signature. They are built with hulls that produce a minimal pressure signature. These measures create other problems. They are expensive, slow, and vulnerable to enemy fire. Therefore, they need protection. Many modern ships have a mine-warning sonar—a simple sonar looking forward and warning the crew if it detects possible mines ahead. It is only effective when the ship is moving slowly.<br> (See Also SQQ-32 Mine-hunting sonar)
A steel-hulled ship can be "degaussed" (more correctly, de-oerstedted or depermed) using a special degaussing station that contains many large coils and induces a magnetic field in the hull with alternating current to demagnetize the hull. This is a rather problematic solution, as magnetic compasses need recalibration and all metal objects must be kept in exactly the same place. Ships slowly regain their magnetic field as they travel through the Earth's magnetic field, so the process has to be repeated every six months.
A simpler variation of this technique, called "wiping", was developed by Charles F. Goodeve which saved time and resources.
Between 1941 and 1943 the US Naval Gun factory (a division of the Naval Ordnance Laboratory) in Washington D.C. built physical models of all US Naval ships. Three kinds of steel were used in shipbuilding: mild steel for bulkheads, a mixture of mild steel and high tensile steel for the hull, and special treatment steel for armor plate. The models were placed within coils which could simulate the Earth's magnetic field at any location. The magnetic signatures were measured with degaussing coils. The objective was to reduce the vertical component of the combination of the Earth's field and the ship's field at the usual depth of German mines. From the measurements, coils were placed and coil currents determined to minimize the chance of detonation for any ship at any heading at any latitude.
Some ships are built with magnetic inductors, large coils placed along the ship to counter the ship's magnetic field. Using magnetic probes in strategic parts of the ship, the strength of the current in the coils can be adjusted to minimize the total magnetic field. This is a heavy and clumsy solution, suited only to small-to-medium-sized ships. Boats typically lack the generators and space for the solution, while the amount of power needed to overcome the magnetic field of a large ship is impractical.
Active countermeasures.
Active countermeasures are ways to clear a path through a minefield or remove it completely. This is one of the most important tasks of any mine warfare flotilla.
Mine sweeping.
A sweep is either a contact sweep, a wire dragged through the water by one or two ships to cut the mooring wire of floating mines, or a distance sweep that mimics a ship to detonate the mines. The sweeps are dragged by minesweepers, either purpose-built military ships or converted trawlers. Each run covers between one and two hundred meters, and the ships must move slowly in a straight line, making them vulnerable to enemy fire. This was exploited by the Turkish army in the Battle of Gallipoli in 1915, when mobile howitzer batteries prevented the British and French from clearing a way through minefields.
If a contact sweep hits a mine, the wire of the sweep rubs against the mooring wire until it is cut. Sometimes "cutters", explosive devices to cut the mine's wire, are used to lessen the strain on the sweeping wire. Mines cut free are recorded and collected for research or shot with a deck gun.
Minesweepers protect themselves with an oropesa or paravane instead of a second minesweeper. These are torpedo-shaped towed bodies, similar in shape to a Harvey Torpedo, that are streamed from the sweeping vessel thus keeping the sweep at a determined depth and position. Some large warships were routinely equipped with paravane sweeps near the bows in case they inadvertently sailed into minefields—the mine would be deflected towards the paravane by the wire instead of towards the ship by its wake. More recently, heavy-lift helicopters have dragged minesweeping sleds, as in the 1991 Persian Gulf War.
The distance sweep mimics the sound and magnetism of a ship and is pulled behind the sweeper. It has floating coils and large underwater "drums". It is the only sweep effective against bottom mines.
During the Second World War, RAF Coastal Command used Vickers Wellington bombers Wellington DW.Mk I fitted with degaussing coils to trigger magnetic mines.
Modern influence mines are designed to discriminate against false inputs and are therefore much harder to sweep. They often contain inherent anti-sweeping mechanisms. For example, they may be programmed to respond to the unique noise of a particular ship-type, its associated magnetic signature and the typical pressure displacement of such a vessel. As a result, a mine-sweeper must accurately guess and mimic the required target signature in order to trigger detonation. The task is complicated by the fact that an influence mine may have one or more of a hundred different potential target signatures programmed into it.
Another anti-sweeping mechanism is a ship-counter in the mine fuze. When enabled, this allows detonation only after the mine fuze has been triggered a pre-set number of times. To further complicate matters, influence mines may be programmed to arm themselves (or disarm automatically—known as "self-sterilization") after a pre-set time. During the pre-set arming delay (which could last days or even weeks) the mine would remain dormant and ignore any target stimulus, whether genuine or faked.
When influence mines are laid in an ocean minefield, they may have various combinations of fuze settings configured. For example, some mines (with the acoustic sensor enabled) may become active within three hours of being laid, others (with the acoustic and magnetic sensors enabled) may become active after two weeks but have the ship-counter mechanism set to ignore the first two trigger events, and still others in the same minefield (with the magnetic and pressure sensors enabled) may not become armed until three weeks have passed. Groups of mines within this mine-field may have different target signatures which may or may not overlap. The fuzes on influence mines allow many different permutations, which complicates the clearance process.
Mines with ship-counters, arming delays and highly specific target signatures in mine fuzes can falsely convince a belligerent that a particular area is clear of mines or has been swept effectively because a succession of vessels have already passed through safely.
Mine hunting.
As naval mines have become more sophisticated, and able to discriminate between targets, so they have become more difficult to deal with by conventional sweeping. This has given rise to the practice of mine-hunting.
Mine hunting is very different from sweeping, although some minehunters can do both tasks. Mines are hunted using sonar, then inspected and destroyed either by divers or ROVs (remote controlled unmanned mini submarines). It is slow, but also the most reliable way to remove mines. Mine hunting started during the Second World War, but it was only after the war that it became truly effective.
Sea mammals (mainly the Bottlenose Dolphin) have been trained to hunt and mark mines, most famously by the U.S. Navy Marine Mammal Program. Mine-clearance dolphins were deployed in the Persian Gulf during the Iraq War in 2003. The US Navy claims that these dolphins were effective in helping to clear more than 100 antiship mines and underwater booby traps from Umm Qasr Port.
French naval officer Jacques Yves Cousteau's Undersea Research Group was once involved in mine-hunting operations: They removed or detonated a variety of German mines, but one particularly defusion-resistant batch—equipped with acutely sensitive pressure, magnetic, and acoustic sensors and wired together so that one explosion would trigger the rest—was simply left undisturbed for years until corrosion would (hopefully) disable the mines.
Mine running.
A more drastic method is simply to run ship through the minefield, letting other ship to be protected follow the same path. An early example of this was Farragut's actions at Mobile Bay during the American Civil War. However, as mine warfare became more developed this method became uneconomical.
This method was revived by the German "Kriegsmarine" during WWII. Left with a surfeit of idle ships due to the Allied blockade, the "Kriegsmarine" introduced a ship known as "Sperrbrecher" ("barrage breaker"). Typically an old cargo ship, loaded with cargo that made her less vulnerable to sinking (wood for example), the "Sperrbrecher" was run ahead of the ship to be protected, detonating any mines that might be in their path. The use of "Sperrbrecher" obviated the need to continuous and painstaking sweeping, but the cost was high. Over half the 100 or so ships used as "Sperrbrecher" were sunk during the war. Alternatively, a shallow draught vessel can be steamed through the minefield at high speed to generate a pressure wave sufficient to trigger mines, with the minesweeper moving fast enough to be sufficiently clear of the pressure wave so that triggered mines do not destroy the ship itself. These techniques are the only publicly known to be employed way to sweep pressure mines. The technique can be simply countered by use of a ship-counter, set to allow a certain number of passes before the mine is actually triggered. Modern doctrine calls for ground mines to be hunted rather than swept. A new system is being introduced for sweeping pressure mines, however counters are going to remain a problem.
An updated form of this method is the use of small unmanned ROVs (such as the "Seehund" drone) that simulate the acoustic and magnetic signatures of larger ships and are built to survive exploding mines. Repeated sweeps would be required in case one or more of the mines had its "ship counter" facility enabled i.e. were programmed to ignore the first 2, 3, or even 6 target activations.
National arsenals.
US mines.
The United States Navy MK56 ASW mine (the oldest still in use by the US) was developed in 1966. More advanced mines include the MK60 CAPTOR (short for "encapsulated torpedo"), the MK62 and MK63 Quickstrike and the MK67 SLMM (Submarine Launched Mobile Mine). Today, most U.S. naval mines are delivered by aircraft.
MK67 SLMM Submarine Launched Mobile Mine<br>
The SLMM was developed by the United States as a submarine deployed mine for use in areas inaccessible for other mine deployment techniques or for covert mining of hostile environments. The SLMM is a shallow-water mine and is basically a modified Mark 37 torpedo.
General characteristics
MK65 Quickstrike<br>
The Quickstrike is a family of shallow-water aircraft-laid mines used by the United States, primarily against surface craft. The MK65 is a 2,000-lb (900 kg) dedicated, purpose-built mine. However, other Quickstrike versions (MK62, MK63, and MK64) are converted general-purpose bombs. These latter three mines are actually a single type of electronic fuze fitted to Mk82, Mk83 and Mk84 air-dropped bombs. Because this latter type of Quickstrike fuze only takes up a small amount of storage space compared to a dedicated sea mine, the air-dropped bomb casings have dual purpose i.e. can be fitted with conventional contact fuzes and dropped on land targets, or have a Quickstrike fuze fitted which converts them into sea mines.
General characteristics
MK56<br>
General characteristics
Royal Navy.
According to a statement made to the UK Parliament in 2002:
However, a British company (BAE Systems) does manufacture the Stonefish influence mine for export to friendly countries such as Australia, which has both war stock and training versions of Stonefish, in addition to stocks of smaller Italian MN103 Manta mines. The computerised fuze on a Stonefish mine contains acoustic, magnetic and water pressure displacement target detection sensors. Stonefish can be deployed by fixed-wing aircraft, helicopters, surface vessels and submarines. An optional kit is available to allow Stonefish to be air-dropped, comprising an aerodynamic tail-fin section and parachute pack to retard the weapon's descent. The operating depth of Stonefish ranges between 30 and 200 metres. The mine weighs 990 kilograms and contains a 600 kilogram aluminised PBX explosive warhead.

</doc>
<doc id="22104" url="https://en.wikipedia.org/wiki?curid=22104" title="Nawal El Moutawakel">
Nawal El Moutawakel

Nawal El Moutawakel (Amazigh: Nawal Lmutawakkil ; ) (born on April 15, 1962 in Casablanca) is a former Moroccan hurdler, who won the inaugural women's 400 metres hurdles event at the 1984 Summer Olympics, thereby becoming the first female Muslim born on the continent of Africa to become an Olympic champion. She was also the first Moroccan and the first woman from a Muslim majority country to win an Olympic gold medal. In 2007, El Moutawakel was named the Minister of Sports in the upcoming cabinet of Morocco.
Life.
Although she had been a quite accomplished runner, the victory of El Moutawakel, who studied at Iowa State University at the time, was a surprise. King Hassan II of Morocco telephoned El Moutawakel to give his congratulations, and he declared that all girls born the day of her victory were to be named in her honor. Her medal also meant the breakthrough for sporting women in Morocco and other mostly Muslim countries.
She was a pioneer for Muslim and Arabic athletes in that she confounded long-held beliefs that women of such backgrounds could not succeed in athletics.
In 1993 she started running for fun, a 5 km run for women in Casablanca that has since become the biggest women’s race held in a Muslim country, with up to 30,000 who came to run.
In 1995, El Moutawakel became a council member of the International Association of Athletics Federations (IAAF), and in 1998 she became a member of the International Olympic Committee (IOC).
El Moutawakel is a member of the International Olympic Committee, and she was the president of evaluation commissions for the selection of the host city for the 2012 and 2016 Summer Olympic Games.
In 2006, El Moutawakel was one of the eight bearers of the Olympic flag at the 2006 Winter Olympics Opening Ceremony in Turin, Italy. On 26 July 2012, she carried the Olympic torch through Westminster, London, for the London Olympics.

</doc>
<doc id="22106" url="https://en.wikipedia.org/wiki?curid=22106" title="North Melbourne Football Club">
North Melbourne Football Club

The North Melbourne Football Club, nicknamed the Kangaroos or less formally the Roos, the Kangas or North, is the fourth oldest Australian rules football club in the Australian Football League (AFL) and is one of the oldest sporting clubs in Australia and the world. It is based at the Arden Street Oval in the inner Melbourne suburb of North Melbourne, but plays its home matches at the nearby Docklands Stadium.
The club's mascot is a grey or red kangaroo, and its use dates from the middle of the 20th century. The club is also unofficially known as 'The Shinboners', a term which dates back to its 19th-century abattoir-worker origins. The club's motto is "Victoria amat curam", Latin for "Victory Demands Dedication".
Club history.
Formative years.
North Melbourne Football Club originated in the year 1869, when a football team was formed for local cricketers desiring to keep fit over the winter months. One thought is that the club was connected to the St Mary's Church of England Cricket Club, now the St Mary's Anglican Church North Melbourne, whose colours – blue and white – are reflected in the North Melbourne's colours today. The association between the St Mary's Church of England Cricket Club and the establishment of the North Melbourne Football Club is believed to have been an informal gathering to play some competitive sport. Information on the club's first ever match is limited, but it is known that it took place in Royal Park, which also served as the club's home ground until 1882. The ball used in the match was purchased by a local resident called Tom Jacks, who sold some roofing iron to pay for it. James Henry Gardiner is considered the founder of the club. He continued an active role with North Melbourne until his death in 1921.
Regular premiership matches of Australian Football commenced in Victoria in 1870. Although North Melbourne was a part of this, it was classed as a "junior club". "The Australasian" noted them as being "one of the best of many junior clubs".
The club continued to develop, graduating to senior ranks in 1874 finishing 4th. Along with the promotion, the club adopted its first uniform of blue and white horizontal stripes.
In 1876 North Melbourne disbanded and many of its player and members joined Albert-park, giving the club such a strong North Melbourne character that many described it as "Albert-park "cum" North Melbourne". In 1877, the club was re-established as a stand-alone club under the new name of "Hotham".
Association years.
Football took a giant step forward in 1877, with the formation of Victoria's first colonial football league, the VFA. Hotham were prime movers in establishing this league and were afforded a place in light of their previous contributions to Australian Football.
The 1880s marked the emergence of the modern identity we now associate with North today. In 1882, the club amalgamated with the Hotham Cricket Club and moved into the North Melbourne Recreation Reserve (Arden St Oval), which remains the home of the club today. The joint venture was aimed at affecting improvements at the Hotham Cricket Ground, which was the name of the Reserve at the time. Four years later the club adopted the traditional uniform of blue and white vertical stripes at the insistence of the VFA, who wanted a visible contrast between Geelong's and Hotham's uniforms. The third significant development occurred in 1888 with the club returning to its original name of the North Melbourne Football Club. This followed the name of the local area reverting from Hotham to North Melbourne.
The 1880s saw the club develop a penchant for inter-colonial travel with trips to Tasmania (1881/1887) and South Australia (1889). Hotham also found itself well represented at the first ever inter-colonial representative game in 1879 with four players from the club gaining selection for Victoria.
Disregarded by the VFL.
The VFA grew to 13 senior clubs in the 1890s. Led by Geelong and Essendon, the largest clubs of the VFA formed their own break away league, the Victorian Football League (VFL), in 1896. Despite finishing 6th in 1896, North Melbourne was not invited to the breakaway competition. The main reasons for being excluded were:
North continued on in the depleted VFA, emerging as a powerhouse, finishing 2nd in 1897, 1898 and 1899. In 1903, after 34 years of competing, the club won its first premiership, defeating Richmond in the final. The club became back to back premiers in 1904 after Richmond forfeited the grand final due to the appointment of an umpire whose performance when the two teams met earlier in the year was severely criticised by Richmond players and officials.
North merged with fellow VFA football club West Melbourne in 1907, which at the time had lost its home ground. The joint venture saw a chance of promotion, and the club applied for admission to the more prestigious VFL in 1908, but Richmond and University were admitted instead. North was kicked out of the VFA during the 1907/08 offseason as a result of applying to join the VFL, before the local community reestablished the North Melbourne Football Club under a new committee, successfully enabling the club to play in the VFA in the 1908 season.
"The Invincibles".
The reformation of the Club necessitated a massive clean out of the team, leaving only two players remaining from the previous season. The 1910 season was marked by one of the most sensational transfers in Victorian football history, when Andy Curran masterminded the clearance of Carlton's famed "Big Four" of 'Mallee' Johnson, Fred Jinks, Charlie Hammond and Frank 'Silver' Caine to North Melbourne. These signings secured the Northerners' third premiership in 1910.
The 1912 finals series was one of the most amazing ever, with the semi-final having to be played three times, after North and Brunswick drew twice. North was eventually victorious and moved on to the final, but lost the game by a mere four points with the last kick of the day.
The next few years were punctuated by "The Invincibles". In the Northerners' most illustrious period ever, the club went undefeated from 1914 to 1919, collecting premierships in 1914, 1915 and 1918 – the league was in recess in 1916 and 1917 due to World War I. As well as this, the club won the championship in both 1915 and 1918 for finishing on top of the ladder, and accounted for VFL side St Kilda comfortably. During this period the club won 58 consecutive matches including 49 successive premiership matches, a record that has remained unmatched in Association or League history since.
Despite being rejected from the VFL in both 1896 and 1907, North persisted in trying to gain admission into the League. On 30 June 1921, North told its players it would disband and try to gain entry to the VFL by the 'back-door'. Essendon League Football Club had lost its playing ground at East Melbourne and had decided to acquire the North Melbourne Recreation Reserve as a new playing ground. North accepted their proposal in the idea that the clubs would amalgamate. All of North's players were urged to join the Essendon League Club to help facilitate the amalgamation. The amalgamation was foiled when some members of the VFA launched a successful legal challenge. As a result, the Essendon League Club moved instead to the Essendon Oval, replacing the ground's original occupants, Essendon Association.
North was now without a playing team and the Essendon Association Club was now without a ground, so as a matter of convenience the two clubs amalgamated so they could compete in the 1922 season. As it had after the merger with West Melbourne, North once again managed to avert its destruction.
Entering the VFL.
After three attempts, 29 years of waiting and numerous other applications to enter the VFL, finally North was rewarded for its persistence with admittance to the League in 1925, along with Footscray and Hawthorn. Even then, the opportunity was almost lost as the League delegates debated into the early hours of the morning on which clubs should be invited to join the intake. It was only after much deliberation that North Melbourne's name was eventually substituted for Prahran's making North "the lucky side" of the invitees that included Footscray and Hawthorn. North Melbourne was forced to change its uniform to avoid a clash when it joined the VFL.
North Melbourne were cellar dwellers for its first twenty-five years of VFL membership and struggled to win matches in the superior VFL competition, but by the late 1940s had developed a strong list and significant supporter base. In 1949 North secured the VFL Minor Premiership, finishing top of the ladder at the end of the home-and-away season with 14 wins and 5 losses. They failed to make the Grand Final that year (eventually won by Essendon), but in 1950 they did reach the final, defeated by a more efficient Essendon. It was in this year that the club adopted the "Kangaroos" mascot.
In February 1965, North Melbourne moved its playing and training base from the Arden Street Oval to Coburg Oval, signing a seven-year lease with the City of Coburg after initially negotiating long-term leases for up to 40 years. The club came to an arrangement to merge with the VFA's Coburg Football Club, whom it was displacing from the ground; fourteen Coburg committeemen joined the North Melbourne committee, but the merger was never completed after Coburg established a rival committee which remained loyal to the VFA. The lease at Coburg lasted only eight months; the Coburg council was hesitant to build a new grandstand without the security of a long-term lease, and neither party made the returns they expected, so it was terminated by mutual agreement in September 1965 and North Melbourne returned to the Arden Street Oval.
Onfield, the 1950s and 1960s were lean years for North Melbourne, though the club did secure two consecutive Night Premierships in 1965 and 1966. Allen Aylett was a brilliant player in the late 1950s and early 1960s (and captain between 1961 and 1964), as was Noel Teasdale, who lost the Brownlow Medal on a countback in 1965 (he was later awarded a retrospective medal when the counting system was amended).
Golden era.
In the late 1960s, under the leadership of Allen Aylett, North Melbourne began its climb to supremacy. As part of a major recruitment drive North secured the services of several big name stars including Barry Davis from Essendon and Doug Wade (Geelong), John Rantall (South Melbourne), Barry Cable (Perth). In a major coup, the great Ron Barassi was appointed coach in 1973. Barrassi reversed the club's playing fortunes, taking an unremarkable team that was once regarded as the traditional cellar dwellers of the competition, through a golden era of success that transformed North into one of the powerhouses of the VFL. Barassi took North to a Grand Final (defeated by Richmond) in 1974 and brought success in his 1975 and 1977 seasons. North made five consecutive Grand Finals from 1974–1978) and defeated Norwood in the 1975 national championship to be declared Champions of Australia.
In 1973 and 1974, North's wingman Keith Greig won consecutive Brownlow Medals; forward Malcolm Blight then won the award in 1978. Doug Wade won the Coleman medal in 1974 with his 103 goals for the season.
Barassi remained team coach until 1980, but only a Night Premiership in that year resulted in him leaving Arden Street. North then entered another period of decline, though Malcolm Blight kicked 103 goals to take out the Coleman medal in 1982, and another Brownlow win came through the talented Ross Glendinning in 1983. In that year, North Melbourne won a third Minor Premiership with 16 wins and 6 losses for the season, but failed to make the Grand Final.
Team of the 1990s.
The capable coaching of John Kennedy aside, the 1980s and early 1990s were lean years for the Kangaroos. However, the rebuilding of the club was taking place. The Krakouer brothers (Jim and Phil) brought a spark into the side and lifted many hopes for North supporters and the excitement to the general football public. The innovative idea of night games was instigated by the club and meeting the challenges, the club survived. One major highlight was the recruitment of forward John Longmire in 1989, who topped the club goalkicking over five consecutive seasons (1990–1994) and won the Coleman medal in 1990 with 98 goals. At the beginning of the 1993 season, in a dramatic and controversial move, the board of the club sacked coach and long-time player Wayne Schimmelbusch, and appointed Denis Pagan in his place. Results were immediate, as North reached the finals for the first time in nearly a decade.
Pagan was instrumental in appointing young centre half-forward Wayne Carey as the club's youngest-ever captain. Carey had been recruited at the same time as Longmire, but taken longer to develop as a player. Over the next nine seasons, Carey came to be regarded as the standout player in the league, and was known as 'the King'.
North Melbourne became a powerhouse through the 1990s under Pagan and Carey, and finished in the top four from 1994 until 2000. After being eliminated in the preliminary finals in 1994 and 1995, North went on to defeat the Sydney Swans in the 1996 Grand Final to take out the club's third premiership, and the gold centenary AFL cup; Glenn Archer won the Norm Smith Medal. The club was again eliminated in the preliminary final in 1997. In 1998, as the club won both the pre-season Ansett Cup and topped the ladder with 16 wins and 6 losses, but went on to lose the 1998 Grand Final to Adelaide, not helped by an inaccurate goalkicking performance of 8.22 (70) to Adelaide's 15.15 (105). In 1999, the Kangaroos finished in second position on the ladder, and went on to defeat Carlton in the Grand Final, winning the club's fourth VFL/AFL premiership; former Sydney midfielder Shannon Grant taking out the Norm Smith Medal. The club was eliminated in the preliminary finals in 2000 against Melbourne.
In 1996, the club was in advanced talks with the Fitzroy Football Club, which was in a terminal financial condition, to a merger between the two clubs; however, Fitzroy ultimately merged with the Brisbane Bears instead.
Seeking new markets and greater financial security in an increasingly corporatized AFL environment, the title "North Melbourne" was officially dropped from the logo in 1999, from which time the team played only as the "Kangaroos". During the successful 1999 season, North Melbourne played home games in Sydney with a view of becoming a second team in New South Wales; however, the experiment was not successful, with crowds averaging only 12,000.
21st century.
The 21st century did not begin well for North Melbourne. Its decade-long onfield potency was in decline, questions were raised about its financial position and long-term sustainability. Furthermore, three of the people most important to the club's success in the 1990s left the club under acrimonious circumstances: CEO Greg Miller left the club, captain Wayne Carey left prior to the 2002 season following an extramarital affair with the wife of team-mate and vice captain Anthony Stevens, coach Denis Pagan was lured to Carlton at the end of 2002. Pagan was replaced by 1996 premiership player Dean Laidley, who had previously been an Assistant Coach at Collingwood from 1999 until the end of season 2002.
On a post-season holiday, several players were caught in the 2002 Bali bombing terrorist attack. Defender and sometime forward Jason McCartney suffered severe burns in the incident. He memorably played one final game for the club, on 6 June 2003 against Richmond, and he set up the winning goal with seconds remaining. He retired immediately after the game.
Onfield, the club reached the elimination finals in 2002 and 2005, but otherwise failed to reach the finals from 2001 until 2006.
After two seasons of finals, North Melbourne dropped to 13th in 2009, and coach Dean Laidley, was replaced by ex-Brisbane Lions premiership player and Collingwood assistant coach Brad Scott. A$15 million redevelopment of the Arden Street, which had started in 2006, was completed in 2009, giving the club top-class training facilities.
North Melbourne struggled in its first two years under Scott, finishing 9th in both 2010 and 2011. In 2012, the club returned to the finals for the first time since 2008, finishing the season in 8th place but would go down to the West Coast Eagles by 96 points in the elimination final. In 2012, the club began a three-year deal to play two games each year at Blundstone Arena in Hobart, Tasmania. The club finished 10th in 2013 in a season full of close losses.
Nick Dal Santo signed with the club at the end of the 2013 season as a restricted free agent.
In 2014, North Melbourne finished 6th at the end of the home and away season and reached 40,000 members for the first time in the club's history.
In September, North Melbourne went on to defeat Essendon by 12 points in the 2nd Elimination Final, only taking the lead in the last quarter. The following week, North Melbourne beat Geelong in the 2nd Semi-final by 6 points advancing them through to their first Preliminary Final since 2007. They lost to Sydney by 71 points. In 2015 the club made history by becoming the first team to qualify for a preliminary final from 8th spot, losing to the West Coast Eagles by 25 points.
Club symbols and identity.
Name and mascot.
The club was widely known as the 'Shinboners' for much of their early history. The origins of this nickname are unknown but it may have had something to do with the club's reputation for targeting the shinbones of opposition players, or to do with local butchers who showed their support for North by dressing up beef leg-bones in the club colours. By 1926, the club was known as the 'Blue Birds' but this nickname did not last. It was Phonse Tobin, North president from 1953–56, who oversaw the club adopting the Kangaroos emblem in 1954; Tobin found the image of a shinbone unsavoury and wanted the club to have a mascot it could show with pride. In selecting a new name, he wanted something characteristically Australian and got inspiration from a giant Kangaroo he saw on display outside a city store.
The official name of the club is North Melbourne, but the club has gone under several other aliases over the years. The club was originally founded as the 'North Melbourne Football Club', but changed to 'North Melbourne cum Albert Park' after merging with Albert Park in 1876. Following the reformation of the club in 1877, it was known as the 'Hotham Football Club' but later retook the name 'North Melbourne' in 1888. In 1998 the club proposed changing its name to the 'Northern Kangaroos', but it was rejected by the AFL. Between 1999 and 2007, the club traded without much success as 'The Kangaroos' in a bid to increase its appeal nationally; this decision was reversed at the end of 2007, and the club has once again reverted to the name 'North Melbourne'.
Guernsey.
The North Melbourne Football Club has a long history of wearing various designs in the colours of royal blue and white.
Most of the club's earliest jumpers were long-sleeved and not the sleeveless design common today. In their early years the club sported a hooped design when they took to the field. This changed at the behest of the VFA in 1884 who insisted that Hotham change their jumpers to vertical stripes to provide a visible contrast between Hotham and Geelong.
After 1884 the vertical top was worn more often, usually in the lace up design in the gallery below.
After the merger with West Melbourne, North used a composite jumper that incorporated West Melbourne's red sash for the 1908 season. The merger was in reality, a takeover. The red sash was a token gesture and was removed the following season.
In the early 1920s North experimented with an NMFC monogram design, following League clubs like Carlton and South Melbourne.
Upon promotion to the VFL in 1925, North Melbourne was forced to abandon its royal blue and white striped jumper as it was deemed the jumper design clashed with other clubs. During this period a jumper with a V design was used for several years, before the club returned to using its striped jumper combination of royal blue and white which has been used continuously since 1932.
North Melbourne's guernsey since entering the VFL in 1925 has consisted of white and royal blue vertical stripes. The guernsey is predominantly white.
The current clash guernsey is a reversed version of the home strip, with blue stripes where the white stripes traditionally are placed and vice versa; as such, the clash strip is predominantly royal blue, rather than predominantly white, creating a much darker design.
Club song.
"Join in the Chorus" is the official anthem of the North Melbourne Football Club. It is sung to the tune of a Scottish folk song "A Wee Deoch an Doris", from around 1911.
The famed song is generally sung, in accordance to common football tradition, after a victory. It is also played before every match.
"Join in the Chorus" is believed to be the oldest club anthem of any AFL club, and has been associated with North from its early VFA days. The preamble of the song originates from a score of a Theatre Musical called 'Australia: Heart to Heart and Hand to Hand" written by Toso Taylor in the 1890s in pre-federation Australia. The second verse is unknown in origin and was presumably added later by members of the North Melbourne Football Club when the song was chosen as the club theme. The chorus was appropriated from a song written and performed by Scottish musician Harry Lauder. The recording currently used by the club was performed by the Fable Singers in April 1972 and only includes the choruses.
The song has a strong Victorian heritage, and has been traditionally sung by the Victorian State Football and Victorian Cricket teams respectively. The lyrics have occasionally been changed, including updating the year in the song ("e.g." "North Melbourne will be premiers in 1993"), or to remove the words "North Melbourne" during the period when the club was competing as 'Kangaroos'.
For the 2015 premiership season, "You Am I" lead singer Tim Rogers, a fan of North Melbourne, announced he will assist in an updated version of the club song including the 2 verses. This version is only played at North home games as they run out onto the ground.
Shinboner spirit.
The term "Shinboner spirit" is often used to refer to camaraderie and determination of players or members of the North Melbourne Football Club. The term persists to the modern day, despite North Melbourne having switched its official nickname from Shinboners to Kangaroos in the 1950s.
Because it relates to the club's original nickname, Shinboner spirit is often associated with the complete history of the club. In 2005, to celebrate the club's 80th anniversary of senior competition in the VFL and the thirtieth anniversary of the first VFL premiership, the Kangaroos held a "Shinboner Spirit" gala event, attended by almost the entire surviving playing list. In the awards ceremony, the key Shinboners of the past eighty years were acknowledged, and Glenn Archer was named the "Shinboner of the Century".
Corporate.
Ownership.
The North Melbourne Football Club is non-a profit organisation limited by guarantee. Members of the club serve as the guarantees of capital, and have full voting rights at AGMs to elect directors to the club's board.
The club's board of directors has nine members, with each director serving a 3-year term before their position is put up for re-election at an AGM. Only one-third of the board is contested at each AGM due to the rolling structure of the terms of the directors. This structure safeguards the entire board from being ousted at a single AGM, and has made North Melbourne immune to a lot of the in house fighting witnessed at other AFL football clubs. The board governs the club as well as selecting a chairman to head the club through a majority vote of directors.
North Melbourne is unique in its structure, because from 1986 to 2006 the club was privately owned and limited by shares. The club was floated in 1986 through a membership vote led by then chairman Bob Ansett. At the meeting, members were encouraged to buy into the club by purchasing shares. The float ended up raising over $3 million and helped to keep the club solvent through the next decade.
In 1991, the John Elliott-led Carlton Football Club attempted a hostile take over North Melbourne by purchasing a large parcel of shares formerly owned by Bob Ansett. The Blues acquired 20 per cent of the capital but that stake was eventually bought back by John Magowan, the former head of Merrill Lynch Australia, in 2001. The resulting melodrama saw the formation of B-Class shareholders who had the effective power of veto over any attempt to merge or relocate the club.
Further takeover attempts were made in the first decade of the 21st century by the Southport Sharks. Then chairman Allan Aylett knocked back a proposal from the Sharks that would have seen them gain a majority stake in the club in exchange for an injection of capital. In early 2006, another proposal from Sharks to underwrite Kangaroos games on the Gold Coast, in exchange for a slice of the shareholder structure at the club was knocked back after AFL intervention.
Due to an Australian Tax Office ruling in 2006, the club proposed a shareholder restructure that would have seen the B Class shareholders power reduced significantly and some voting rights returned to members. This was done to avoid extraordinary taxes being placed on the club, but the move was blocked in December by Bob Ansett and his proxies who feared that the restructure would make the club vulnerable to further takeover bids.
On 28 February 2007, another meeting was called to resolve the shareholder issue, and a motion was passed that would return see some voting rights return to members and stop any future tax increments.
In April 2007 it was revealed the AFL was attempting to buy out the shareholders of the club in a bid to gain full ownership, and force a relocation of the club to the Gold Coast.
During October 2007, a group called We Are North Melbourne emerged and launched a public campaign, calling for ordinary members to be given the final say on the relocation issue. While the group became synonymous with the push to keep the club in Melbourne, its first priority was to see the club's shareholder structure wound-up and control returned to ordinary members.
North Melbourne reverted to public company in November 2008. A moratorium was passed at an extraordinary general meeting that will allow James Brayshaw's board to serve unopposed until 2010, so as to allow his ticket the maximum time to enact their policies to make the North Melbourne Football Club financially viable.
Reputation.
Night football.
In 1985, North Melbourne pioneered the concept of playing football on Friday nights. Since then, North Melbourne has played the most Friday night games of any AFL club.
Friday night matches later became the most lucrative timeslot for televised games, and North Melbourne's relatively low supporter base resulted in less Friday night matches. Between 2010 and 2014, North Melbourne had hosted an annual Friday night match against Carlton in recognition of its pioneering role in the concept.
Indigenous players.
North Melbourne has a strong history of supporting Aboriginal footballers and fostering Aboriginal talent in the VFL and AFL. The first indigenous footballer to play for the club was Percy Johnson in the 1950s, and was followed by other fan favorites like Bertie Johnson, Barry Cable and the Krakouer brothers in the following decades.
The following is a list of Indigenous footballers to have played senior football at the club:
†: Aboriginality uncertain
Killed in action.
The following footballers who were killed in action during the World Wars played senior football for North Melbourne.
Rivalries.
Major.
North Melbourne defeated Hawthorn in the 1975 Grand Final by 55 points. However, Hawthorn defeated North Melbourne in the 1976 Grand Final by 30 points and in the 1978 Grand Final by 18 points.
The rivalry re-ignited in 2014 following a choking incident involving Brian Lake having North Melbourne forward Drew Petrie in a choking hold during a clash between the two sides at Docklands Stadium and reached fever pitch in 2015 following several fights including an all in during the first term of their round 5 clash.
Minor.
Port Adelaide lost their first finals appearance to North Melbourne in 1999 in the qualifying final, and in Port's premiership year of 2004, North beat Port by 92 points, however, Port beat North Melbourne in the 2007 Preliminary Final by 87 points.
Club honour board.
North Melbourne Team of the Century.
At a special function in August 2001 the North Melbourne Team of the Century was announced. There was no minimum number of games set for selection. Wayne Carey was named as captain and Denis Pagan as coach. The selection panel was Geoff Poulter (journalist), Father Gerard Dowling (club historian), Keith McKenzie (former coach), Lloyd Holyoak (former president), Max Ritchie (former player and chairman of selectors) and Greg Miller (chief executive).
Shinboner of the Century.
On 18 March 2005, the North Melbourne football club held a special gala dinner entitled the "North Story" to celebrate the 80th anniversary of North's admission to the VFL, and the 30th anniversary of the club's first VFL premiership. Over 3500 people attended the historic event held at the Royal Exhibition Building, including almost all surviving North Melbourne players. Glenn Archer was voted the Shinboner of the Century by his peers as the player who most represents the 'Shinboner Spirit'. The following players were voted 'Shinboners' of their era:

</doc>
<doc id="22107" url="https://en.wikipedia.org/wiki?curid=22107" title="Treaty on the Non-Proliferation of Nuclear Weapons">
Treaty on the Non-Proliferation of Nuclear Weapons

The Treaty on the Non-Proliferation of Nuclear Weapons, commonly known as the Non-Proliferation Treaty or NPT, is an international treaty whose objective is to prevent the spread of nuclear weapons and weapons technology, to promote cooperation in the peaceful uses of nuclear energy, and to further the goal of achieving nuclear disarmament and general and complete disarmament.
Opened for signature in 1968, the Treaty entered into force in 1970. On 11 May 1995, the Treaty was extended indefinitely. More countries have adhered to the NPT than any other arms limitation and disarmament agreement, a testament to the Treaty's significance. A total of 191 states have joined the Treaty, though North Korea, which acceded to the NPT in 1985 but never came into compliance, announced its withdrawal in 2003. Four UN member states have never joined the NPT: India, Israel, Pakistan and South Sudan.
The treaty recognizes five states as nuclear-weapon states: the United States, Russia, the United Kingdom, France, and China (also the five permanent members of the United Nations Security Council). Four other states are known or believed to possess nuclear weapons: India, Pakistan and North Korea have openly tested and declared that they possess nuclear weapons, while Israel has had a policy of opacity regarding its nuclear weapons program.
The NPT consists of a preamble and eleven articles. Although the concept of "pillars" is not expressed anywhere in the NPT, the treaty is nevertheless sometimes interpreted as a "three-pillar" system, with an implicit balance among them:
The NPT is often seen to be based on a central bargain: “the NPT non-nuclear-weapon states agree never to acquire nuclear weapons and the NPT nuclear-weapon states in exchange agree to share the benefits of peaceful nuclear technology and to pursue nuclear disarmament aimed at the ultimate elimination of their nuclear arsenals”. The treaty is reviewed every five years in meetings called Review Conferences of the Parties to the Treaty of Non-Proliferation of Nuclear Weapons. Even though the treaty was originally conceived with a limited duration of 25 years, the signing parties decided, by consensus, to extend the treaty indefinitely and without conditions during the Review Conference in New York City on 11 May 1995, culminating successful U.S. government efforts led by Ambassador Thomas Graham Jr..
At the time the NPT was proposed, there were predictions of 25–30 nuclear weapon states within 20 years. Instead, over forty years later, five states are not parties to the NPT, and they include the only four additional states believed to possess nuclear weapons. Several additional measures have been adopted to strengthen the NPT and the broader nuclear nonproliferation regime and make it difficult for states to acquire the capability to produce nuclear weapons, including the export controls of the Nuclear Suppliers Group and the enhanced verification measures of the IAEA Additional Protocol.
Critics argue that the NPT cannot stop the proliferation of nuclear weapons or the motivation to acquire them. They express disappointment with the limited progress on nuclear disarmament, where the five authorized nuclear weapons states still have 22,000 warheads in their combined stockpile and have shown a reluctance to disarm further. Several high-ranking officials within the United Nations have said that they can do little to stop states using nuclear reactors to produce nuclear weapons.
Treaty "pillars".
The NPT is commonly described as having three main "pillars": non-proliferation, disarmament, and peaceful use. This "pillars" concept has been questioned by some who believe that the NPT is, as its name suggests, principally about nonproliferation, and who worry that "three pillars" language misleadingly implies that the three elements have equivalent importance.
First pillar: non-proliferation.
Five states are recognized by the Non-Proliferation Treaty as nuclear weapon states (NWS): China (signed 1992), France (1992), the Soviet Union (1968; obligations and rights now assumed by the Russian Federation), the United Kingdom (1968), and the United States (1968) (The United States, UK, and the Soviet Union – the World War II's “Big Three” — were the only states openly possessing such weapons among the original ratifiers of the treaty, which entered into force in 1970). These five nations are also the five permanent members of the United Nations Security Council.
These five NWS agree not to transfer "nuclear weapons or other nuclear explosive devices" and "not in any way to assist, encourage, or induce" a non-nuclear weapon state (NNWS) to acquire nuclear weapons (Article I). NNWS parties to the NPT agree not to "receive," "manufacture" or "acquire" nuclear weapons or to "seek or receive any assistance in the manufacture of nuclear weapons" (Article II). NNWS parties also agree to accept safeguards by the International Atomic Energy Agency (IAEA) to verify that they are not diverting nuclear energy from peaceful uses to nuclear weapons or other nuclear explosive devices (Article III).
The five NWS parties have made undertakings not to use their nuclear weapons against a non-NWS party except in response to a nuclear attack, or a conventional attack in alliance with a Nuclear Weapons State. However, these undertakings have not been incorporated formally into the treaty, and the exact details have varied over time. The U.S. also had nuclear warheads targeted at North Korea, a non-NWS, from 1959 until 1991. The previous United Kingdom Secretary of State for Defence, Geoff Hoon, has also explicitly invoked the possibility of the use of the country's nuclear weapons in response to a non-conventional attack by "rogue states". In January 2006, President Jacques Chirac of France indicated that an incident of state-sponsored terrorism on France could trigger a small-scale nuclear retaliation aimed at destroying the "rogue state's" power centers.
Second pillar: disarmament.
Article VI of the NPT represents the only binding commitment in a multilateral treaty to the goal of disarmament by the nuclear-weapon States. The NPT's preamble contains language affirming the desire of treaty signatories to ease international tension and strengthen international trust so as to create someday the conditions for a halt to the production of nuclear weapons, and treaty on general and complete disarmament that liquidates, in particular, nuclear weapons and their delivery vehicles from national arsenals.
The wording of the NPT's Article VI arguably imposes only a vague obligation on all NPT signatories to move in the general direction of nuclear and total disarmament, saying, "Each of the Parties to the Treaty undertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a treaty on general and complete disarmament." Under this interpretation, Article VI does not strictly require all signatories to actually conclude a disarmament treaty. Rather, it only requires them "to negotiate in good faith."
On the other hand, some governments, especially non-nuclear-weapon states belonging to the Non-Aligned Movement, have interpreted Article VI's language as being anything but vague. In their view, Article VI constitutes a formal and specific obligation on the NPT-recognized nuclear-weapon states to disarm themselves of nuclear weapons, and argue that these states have failed to meet their obligation. The International Court of Justice (ICJ), in its advisory opinion on the Legality of the Threat or Use of Nuclear Weapons, issued 8 July 1996, unanimously interprets the text of Article VI as implying that
"There exists an obligation to pursue in good faith and bring to a conclusion negotiations leading to nuclear disarmament in all its aspects under strict and effective international control."
The ICJ opinion notes that this obligation involves all NPT parties (not just the nuclear weapon states) and does not suggest a specific time frame for nuclear disarmament.
Critics of the NPT-recognized nuclear-weapon states (the United States, Russia, China, France, and the United Kingdom) sometimes argue that what they view as the failure of the NPT-recognized nuclear weapon states to disarm themselves of nuclear weapons, especially in the post–Cold War era, has angered some non-nuclear-weapon NPT signatories of the NPT. Such failure, these critics add, provides justification for the non-nuclear-weapon signatories to quit the NPT and develop their own nuclear arsenals.
Other observers have suggested that the linkage between proliferation and disarmament may also work the other way, i.e., that the failure to resolve proliferation threats in Iran and North Korea, for instance, will cripple the prospects for disarmament. No current nuclear weapons state, the argument goes, would seriously consider eliminating its last nuclear weapons without high confidence that other countries would not acquire them. Some observers have even suggested that the very progress of disarmament by the superpowers—which has led to the elimination of thousands of weapons and delivery systems—could eventually make the possession of nuclear weapons more attractive by increasing the perceived strategic value of a small arsenal. As one U.S. official and NPT expert warned in 2007, "logic suggests that as the number of nuclear weapons decreases, the 'marginal utility' of a nuclear weapon as an instrument of military power increases. At the extreme, which it is precisely disarmament's hope to create, the strategic utility of even one or two nuclear weapons would be huge."
Third pillar: peaceful use of nuclear energy.
The third pillar allows for and agrees upon the transfer of nuclear technology and materials to NPT signatory countries for the development of civilian nuclear energy programs in those countries, as long as they can demonstrate that their nuclear programs are not being used for the development of nuclear weapons.
Since very few of the states with nuclear energy programs are willing to abandon the use of nuclear energy, the third pillar of the NPT under Article IV provides other states with the possibility to do the same, but under conditions intended to make it difficult to develop nuclear weapons.
The treaty recognizes the inalienable right of sovereign states to use nuclear energy for peaceful purposes, but restricts this right for NPT parties to be exercised "in conformity with Articles I and II" (the basic nonproliferation obligations that constitute the "first pillar" of the Treaty). As the commercially popular light water reactor nuclear power station uses enriched uranium fuel, it follows that states must be able either to enrich uranium or purchase it on an international market. Mohamed ElBaradei, then Director General of the International Atomic Energy Agency, has called the spread of enrichment and reprocessing capabilities the "Achilles' heel" of the nuclear nonproliferation regime. As of 2007 13 states have an enrichment capability.
Because the availability of fissile material has long been considered the principal obstacle to, and "pacing element" for, a country's nuclear weapons development effort, it was declared a major emphasis of U.S. policy in 2004 to prevent the further spread of uranium enrichment and plutonium reprocessing (a.k.a. "ENR") technology. Countries possessing ENR capabilities, it is feared, have what is in effect the option of using this capability to produce fissile material for weapons use on demand, thus giving them what has been termed a "virtual" nuclear weapons program. The degree to which NPT members have a "right" to ENR technology notwithstanding its potentially grave proliferation implications, therefore, is at the cutting edge of policy and legal debates surrounding the meaning of Article IV and its relation to Articles I, II, and III of the Treaty.
Countries that have signed the treaty as Non-Nuclear Weapons States and maintained that status have an unbroken record of not building nuclear weapons. However, Iraq was cited by the IAEA with punitive sanctions enacted against it by the UN Security Council for violating its NPT safeguards obligations; North Korea never came into compliance with its NPT safeguards agreement and was cited repeatedly for these violations, and later withdrew from the NPT and tested multiple nuclear devices; Iran was found in non-compliance with its NPT safeguards obligations in an unusual non-consensus decision because it "failed in a number of instances over an extended period of time" to report aspects of its enrichment program; and Libya pursued a clandestine nuclear weapons program before abandoning it in December 2003.
In 1991, Romania reported previously undeclared nuclear activities by the former regime and the IAEA reported this non-compliance to the Security Council for information only. In some regions, the fact that all neighbors are verifiably free of nuclear weapons reduces any pressure individual states might feel to build those weapons themselves, even if neighbors are known to have peaceful nuclear energy programs that might otherwise be suspicious. In this, the treaty works as designed.
In 2004, Mohamed ElBaradei said that by some estimates thirty-five to forty states could have the knowledge to develop nuclear weapons.
Key articles.
"Article I": Each nuclear-weapons state (NWS) undertakes not to transfer, to any recipient, nuclear weapons, or other nuclear explosive devices, and not to assist any non-nuclear weapon state to manufacture or acquire such weapons or devices.
"Article II": Each non-NWS party undertakes not to receive, from any source, nuclear weapons, or other nuclear explosive devices; not to manufacture or acquire such weapons or devices; and not to receive any assistance in their manufacture.
"Article III": Each non-NWS party undertakes to conclude an agreement with the IAEA for the application of its safeguards to all nuclear material in all of the state's peaceful nuclear activities and to prevent diversion of such material to nuclear weapons or other nuclear explosive devices.
"Article IV": 1. Nothing in this Treaty shall be interpreted as affecting the inalienable right of all the Parties to the Treaty to develop research, production and use of nuclear energy for peaceful purposes without discrimination and in conformity with Articles I and II of this Treaty.
2. All the Parties to the Treaty undertake to facilitate, and have the right to participate in, the fullest possible exchange of equipment, materials and scientific and technological information for the peaceful uses of nuclear energy. Parties to the Treaty in a position to do so shall also co-operate in contributing alone or together with other States or international organizations to the further development of the applications of nuclear energy for peaceful purposes, especially in the territories of non-nuclear-weapon States Party to the Treaty, with due consideration for the needs of the developing areas of the world.
"Article VI": Each party "undertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a Treaty on general and complete disarmament under strict and effective international control".
"Article X". Establishes the right to withdraw from the Treaty giving 3 months' notice. It also establishes the duration of the Treaty (25 years before 1995 Extension Initiative).
History.
The impetus behind the NPT was concern for the safety of a world with many nuclear weapon states. It was recognized that the cold war deterrent relationship between just the United States and Soviet Union was fragile. Having more nuclear-weapon states would reduce security for all, multiplying the risks of miscalculation, accidents, unauthorized use of weapons, or from escalation in tensions, nuclear conflict.
The NPT process was launched by Frank Aiken, Irish Minister for External Affairs, in 1958. It was opened for signature in 1968, with Finland the first State to sign. Accession became nearly universal after the end of the Cold War and of South African apartheid.
In 1992 China and France acceded to the NPT, the last of the five nuclear powers recognized by the treaty to do so.
In 1995 the treaty was extended indefinitely. After Brazil acceded to the NPT in 1998 the only remaining non-nuclear-weapons state which had not signed was Cuba, which joined NPT (and the Treaty of Tlatelolco NWFZ) in 2002.
Several NPT signatories have given up nuclear weapons or nuclear weapons programs. South Africa undertook a nuclear weapons program, but has since renounced it and signed the treaty in 1991 after destroying its small nuclear arsenal; after this, the remaining African countries signed the treaty. The former Soviet Republics where nuclear weapons had been based, namely Ukraine, Belarus and Kazakhstan, transferred those weapons to Russia and joined NPT by 1994 following the signature of the Budapest Memorandum on Security Assurances.
Successor states from the breakups of Yugoslavia and Czechoslovakia also joined the treaty soon after their independence. Montenegro and East Timor were the last countries to sign the treaty on their independence in 2006 and 2003; the only other country to sign in the 21st century was Cuba in 2002. The three Micronesian countries in Compact of Free Association with the USA joined NPT in 1995, along with Vanuatu.
Major South American countries Argentina, Chile, and Brazil joined in 1995 and 1998. Arabian Peninsula countries included Saudi Arabia and Bahrain in 1988, Qatar and Kuwait in 1989, UAE in 1995, and Oman in 1997. The tiny European states of Monaco and Andorra joined in 1995-6. Also signing in the 1990s were Myanmar in 1992 and Guyana in 1993.
United States-NATO nuclear weapons sharing.
At the time the treaty was being negotiated, NATO had in place secret nuclear weapons sharing agreements whereby the United States provided nuclear weapons to be deployed by, and stored in, other NATO states. Some argue this is an act of proliferation violating Articles I and II of the treaty. A counter-argument is that the U.S. controlled the weapons in storage within the NATO states, and that no transfer of the weapons or control over them was intended "unless and until a decision were made to go to war, at which the treaty would no longer be controlling", so there is no breach of the NPT. These agreements were disclosed to a few of the states, including the Soviet Union, negotiating the treaty, but most of the states that signed the NPT in 1968 would not have known about these agreements and interpretations at that time.
As of 2005, it is estimated that the United States still provides about 180 tactical B61 nuclear bombs for use by Belgium, Germany, Italy, the Netherlands and Turkey under these NATO agreements. Many states, and the Non-Aligned Movement, now argue this violates Articles I and II of the treaty, and are applying diplomatic pressure to terminate these agreements. They point out that the pilots and other staff of the "non-nuclear" NATO states practice handling and delivering the U.S. nuclear bombs, and non-U.S. warplanes have been adapted to deliver U.S. nuclear bombs which must have involved the transfer of some technical nuclear weapons information. NATO believes its "nuclear forces continue to play an essential role in war prevention, but their role is now more fundamentally political".
U.S. nuclear sharing policies were originally designed to help prevent the proliferation of nuclear weapons—not least by persuading the then West Germany not to develop an independent nuclear capability by assuring it that West Germany would be able, in the event of war with the Warsaw Pact, to wield (U.S.) nuclear weapons in self-defense. (Until that point of all-out war, however, the weapons themselves would remain in U.S. hands.) The point was to limit the spread of countries having their own nuclear weapons programs, helping ensure that NATO allies would not choose to go down the proliferation route. (West Germany was discussed in U.S. intelligence estimates for a number of years as being a country with the potential to develop nuclear weapons capabilities of its own if officials in Bonn were not convinced that their defense against the Soviet Union and its allies could otherwise be met.)
Non-signatories.
Four states—India, Israel, Pakistan, and South Sudan—have never signed the treaty. India and Pakistan have publicly disclosed their nuclear weapon programs, and Israel has a long-standing policy of deliberate ambiguity with regards to its nuclear program (see List of countries with nuclear weapons).
India.
India has detonated nuclear devices, first in 1974 and again in 1998. India is estimated to have enough fissile material for more than 150 warheads. India was among the few countries to have a no first use policy, a pledge not to use nuclear weapons unless first attacked by an adversary using nuclear weapons, however India's NSA Shivshankar Menon signaled "a significant shift from "no first use" to "no first use against non-nuclear weapon states"" in a speech on the occasion of Golden Jubilee celebrations of the National Defence College in New Delhi on 21 October 2010, a doctrine Menon said reflected India's "strategic culture, with its emphasis on minimal deterrence".
India argues that the NPT creates a club of "nuclear haves" and a larger group of "nuclear have-nots" by restricting the legal possession of nuclear weapons to those states that tested them before 1967, but the treaty never explains on what ethical grounds such a distinction is valid. India's then External Affairs Minister Pranab Mukherjee said during a visit to Tokyo in 2007: ""If India did not sign the NPT, it is not because of its lack of commitment for non-proliferation, but because we consider NPT as a flawed treaty and it did not recognize the need for universal, non-discriminatory verification and treatment.""
In early March 2006, India and the United States finalized an agreement, in the face of criticism in both countries, to restart cooperation on civilian nuclear technology. Under the deal India has committed to classify 14 of its 22 nuclear power plants as being for civilian use and to place them under IAEA safeguards. Mohamed ElBaradei, then Director General of the IAEA, welcomed the deal by calling India "an important partner in the non-proliferation regime."
In December 2006, United States Congress approved the United States-India Peaceful Atomic Energy Cooperation Act, endorsing a deal that was forged during Prime Minister Singh's visit to the United States in July 2005 and cemented during President Bush's visit to India earlier in 2006. The legislation allows for the transfer of civilian nuclear material to India. Despite its status outside the Nuclear Non-Proliferation Treaty, nuclear cooperation with India was permitted on the basis of its clean non-proliferation record, and India's need for energy fueled by its rapid industrialization and a billion-plus population.
On 1 August 2008, the IAEA approved the India Safeguards Agreement and on 6 September 2008, India was granted the waiver at the Nuclear Suppliers Group (NSG) meeting held in Vienna, Austria. The consensus was arrived after overcoming misgivings expressed by Austria, Ireland and New Zealand and is an unprecedented step in giving exemption to a country, which has not signed the NPT and the Comprehensive Test Ban Treaty (CTBT). While India could commence nuclear trade with other willing countries. The U.S. Congress approved this agreement and President Bush signed it on 8 October 2008.
When China announced expanded nuclear cooperation with Pakistan in 2010, proponents of arms control denounced both the deals, claiming that they weakened the NPT by facilitating nuclear programmes in states which are not parties to the NPT.
, Australia, a top three producer and home to worlds largest known reserves, had continued its refusal to export Uranium to India despite diplomatic pressure from India.
In November 2011 the Australian Prime Minister announced a desire to allow exports to India, a policy change which was authorized by her party's national conference in December. On 4 December 2011, Prime Minister Julia Gillard overturned Australia's long-standing ban on exporting uranium to India. She further said "We should take a decision in the national interest, a decision about strengthening our strategic partnership with India in this the Asian century," and said that any agreement to sell uranium to India would include strict safeguards to ensure it would only be used for civilian purposes, and not end up in nuclear weapons. On Sep 5, 2014; Australian Prime Minister Tony Abbott sealed a civil nuclear deal to sell uranium to India. "We signed a nuclear cooperation agreement because Australia trusts India to do the right thing in this area, as it has been doing in other areas," Abbott told reporters after he and Indian Prime Minister Narendra Modi signed a pact to sell uranium for peaceful power generation.
Pakistan.
In May 1998, following India's nuclear tests earlier that month, Pakistan conducted two sets of nuclear tests, the Chagai-I and Chagai-II. As of 2015, Pakistan is estimated to have around 120 warheads. According to the Carnegie Endowment for International Peace and the Stimson Center, Pakistan has enough fissile material for 350 warheads.
Like India, Pakistan believes the treaty does not give equal rights to all states. Foreign Secretary Aizaz Ahmad Chaudhry has been quoted as responding "It is a discriminatory treaty. Pakistan has the right to defend itself, so Pakistan will not sign the NPT. Why should we?" when asked at a briefing whether Islamabad would sign the NPT if Washington asked it to do so. Until 2010, Pakistan had always maintained the position that it would sign the NPT if India did so. In 2010, Pakistan abandoned this historic position and stated that it would join the NPT only as a recognized nuclear-weapon state.
The NSG Guidelines currently rule out nuclear exports by all major suppliers to Pakistan, with very narrow exceptions, since it does not have full-scope IAEA safeguards (i.e. safeguards on all its nuclear activities). Pakistan has sought to reach an agreement similar to that with India, but these efforts have been rebuffed by the United States and other NSG members, arguing that Pakistan's track record as a nuclear proliferator makes it impossible for it to have any sort of nuclear deal in the near future.
By 2010, China reportedly signed a civil nuclear deal with Pakistan claiming that the deal was "peaceful." The British government looked askance at the deal purporting that 'the time is not yet right for a civil nuclear deal with Pakistan'. China did not seek formal approval from the nuclear suppliers group, and claimed instead that its cooperation with Pakistan was "grandfathered" when China joined the NSG, a claim that was disputed by other NSG members.
Israel.
Israel has a long-standing policy of deliberate ambiguity with regards to its nuclear program (see List of countries with nuclear weapons). As with Pakistan, the NSG Guidelines currently rule out nuclear exports by all major suppliers to Israel. According to leaked intelligence, Israel has been developing nuclear weapons at its Dimona site in the Negev since 1958, and many nonproliferation analysts like David Albright estimate that Israel may have stockpiled between 100 and 200 warheads using the plutonium reprocessed from Dimona. The Israeli government refuses to confirm or deny possession of nuclear weapons, although this is now regarded as an open secret after Israeli low level nuclear technician Mordechai Vanunu—subsequently arrested and sentenced for treason by Israel—published evidence about the program to the British "Sunday Times" in 1986.
On 18 September 2009 the General Conference of the International Atomic Energy Agency called on Israel to open its nuclear facilities to IAEA inspection and adhere to the non-proliferation treaty as part of a resolution on "Israeli nuclear capabilities," which passed by a narrow margin of 49–45 with 16 abstentions. The chief Israeli delegate stated that "Israel will not co-operate in any matter with this resolution." However, similar resolutions were defeated in 2010, 2013 and 2014.
North Korea.
North Korea ratified the treaty on 12 December 1985, but gave notice of withdrawal from the treaty on 10 January 2003 following U.S. allegations that it had started an illegal enriched uranium weapons program, and the U.S. subsequently stopping fuel oil shipments under the Agreed Framework which had resolved plutonium weapons issues in 1994. The withdrawal became effective 10 April 2003 making North Korea the first state ever to withdraw from the treaty. North Korea had once before announced withdrawal, on 12 March 1993, but suspended that notice before it came into effect.
On 10 February 2005, North Korea publicly declared that it possessed nuclear weapons and pulled out of the six-party talks hosted by China to find a diplomatic solution to the issue. "We had already taken the resolute action of pulling out of the Nuclear Non-Proliferation Treaty and have manufactured nuclear arms for self-defence to cope with the Bush administration's evermore undisguised policy to isolate and stifle the DPRK People's Republic of Korea," a North Korean Foreign Ministry statement said regarding the issue. Six-party talks resumed in July 2005.
On 19 September 2005, North Korea announced that it would agree to a preliminary accord. Under the accord, North Korea would scrap all of its existing nuclear weapons and nuclear production facilities, rejoin the NPT, and readmit IAEA inspectors. The difficult issue of the supply of light water reactors to replace North Korea's indigenous nuclear power plant program, as per the 1994 Agreed Framework, was left to be resolved in future discussions. On the next day North Korea reiterated its known view that until it is supplied with a light water reactor it will not dismantle its nuclear arsenal or rejoin the NPT.
On 2 October 2006, the North Korean foreign minister announced that his country was planning to conduct a nuclear test "in the future", although it did not state when. On Monday, 9 October 2006 at 01:35:28 (UTC) the United States Geological Survey detected a magnitude 4.3 seismic event north of Kimchaek, North Korea indicating a nuclear test. The North Korean government announced shortly afterward that they had completed a successful underground test of a nuclear fission device.
In 2007, reports from Washington suggested that the 2002 CIA reports stating that North Korea was developing an enriched uranium weapons program, which led to North Korea leaving the NPT, had overstated or misread the intelligence. On the other hand, even apart from these press allegations—which some critics worry could have been planted in order to justify the United States giving up trying to verify the dismantlement of Pyongyang's uranium program in the face of North Korean intransigence—there remains some information in the public record indicating the existence of a uranium effort. Quite apart from the fact that North Korean First Vice Minister Kang Sok Ju at one point admitted the existence of a uranium enrichment program, Pakistan's then-President Musharraf revealed that the A.Q. Khan proliferation network had provided North Korea with a number of gas centrifuges designed for uranium enrichment. Additionally, press reports have cited U.S. officials to the effect that evidence obtained in dismantling Libya's WMD programs points toward North Korea as the source for Libya's uranium hexafluoride (UF6) – which, if true, would mean that North Korea has a uranium conversion facility for producing feedstock for centrifuge enrichment.
Iran.
Iran is a party to the NPT but was found in non-compliance with its NPT safeguards agreement and the status of its nuclear program remains in dispute. In November 2003 IAEA Director General Mohamed ElBaradei reported that Iran had repeatedly and over an extended period failed to meet its safeguards obligations, including by failing to declare its uranium enrichment program. the IAEA Board of Governors, acting under Article XII.C of the IAEA Statute, found in a rare non-consensus decision with 12 abstentions that these failures constituted non-compliance with the IAEA safeguards agreement. after which the Security Council passed a resolution demanding that Iran suspend its enrichment.
Instead, Iran resumed its enrichment program.
The IAEA has been able to verify the non-diversion of declared nuclear material in Iran, and is continuing its work on verifying the absence of undeclared activities. In February 2008, the IAEA also reported that it was working to address "alleged studies" of weaponization, based on documents provided by certain Member States, which those states claimed originated from Iran. Iran rejected the allegations as "baseless" and the documents as "fabrications." In June 2009, the IAEA reported that Iran had not “cooperated with the Agency in connection with the remaining issues ... which need to be clarified to exclude the possibility of military dimensions to Iran's nuclear program.”
The United States concluded that Iran violated its Article III NPT safeguards obligations, and further argued based on circumstantial evidence that Iran's enrichment program was for weapons purposes and therefore violated Iran's Article II nonproliferation obligations. The November 2007 US National Intelligence Estimate (NIE) later concluded that Iran had halted an active nuclear weapons program in the fall of 2003 and that it had remained halted as of mid-2007. The NIE's "Key Judgments," however, also made clear that what Iran had actually stopped in 2003 was only "nuclear weapon design and weaponization work and covert uranium conversion-related and uranium enrichment-related work"-namely, those aspects of Iran's nuclear weapons effort that had not by that point already been leaked to the press and become the subject of IAEA investigations.
Since Iran's uranium enrichment program at Natanz—and its continuing work on a heavy water reactor at Arak that would be ideal for plutonium production—began secretly years before in conjunction with the very weaponization work the NIE discussed and for the purpose of developing nuclear weapons, many observers find Iran's continued development of fissile material production capabilities distinctly worrying. Particularly because fissile material availability has long been understood to be the principal obstacle to nuclear weapons development and the primary "pacing element" for a weapons program, the fact that Iran has reportedly suspended weaponization work may not mean very much. As U.S. Director of National Intelligence Mike McConnell has put it, the aspects of its work that Iran allegedly suspended were thus "probably the least significant part of the program."
Iran states it has a legal right to enrich uranium for peaceful purposes under the NPT, and further says that it "has constantly complied with its obligations under the NPT and the Statute of the International Atomic Energy Agency". Iran also states that its enrichment program is part of its civilian nuclear energy program, which is allowed under Article IV of the NPT. The Non-Aligned Movement has welcomed the continuing cooperation of Iran with the IAEA and reaffirmed Iran's right to the peaceful uses of nuclear technology. UN Secretary General Ban Ki-moon has welcomed the continued dialogue between Iran and the IAEA, and has called for a peaceful resolution to the issue.
In April 2010, during the signing of the U.S.-Russia New START Treaty, President Obama said that the United States, Russia, and other nations are demanding that Iran face consequences for failing to fulfill their obligations under the Nuclear Non-Proliferation Treaty, and that "we will not tolerate actions that flout the NPT, risk an arms race in a vital region, and threaten the credibility of the international community and our collective security."
South Africa.
South Africa is the only country that developed nuclear weapons by itself and later dismantled them – unlike the former Soviet states Ukraine, Belarus and Kazakhstan, which inherited nuclear weapons from the former USSR and also acceded to the NPT as non-nuclear weapon states.
During the days of apartheid, the South African government developed a deep fear of both a black uprising and the threat of communism. This led to the development of a secret nuclear weapons program as an ultimate deterrent. South Africa has a large supply of uranium, which is mined in the country's gold mines. The government built a nuclear research facility at Pelindaba near Pretoria where uranium was enriched to fuel grade for the Koeberg Nuclear Power Station as well as weapon grade for bomb production.
In 1991, after international pressure and when a change of government was imminent, South African Ambassador to the United States Harry Schwarz signed the Nuclear Non-Proliferation Treaty. In 1993, the then president Frederik Willem de Klerk openly admitted that the country had developed a limited nuclear weapon capability. These weapons were subsequently dismantled before South Africa acceded to the NPT and opened itself up to IAEA inspection. In 1994, the IAEA completed its work and declared that the country had fully dismantled its nuclear weapons program.
Libya.
Libya had signed and ratified the Nuclear Non-Proliferation Treaty and was subject to IAEA nuclear safeguards inspections, but undertook a secret nuclear weapons development program in violation of its NPT obligations, using material and technology provided by the A.Q. Khan proliferation network—including actual nuclear weapons designs allegedly originating in China. Libya began secret negotiations with the United States and the United Kingdom in March 2003 over potentially eliminating its WMD programs. In October 2003, Libya was embarrassed by the interdiction of a shipment of Pakistani-designed centrifuge parts sent from Malaysia, also as part of A. Q. Khan's proliferation ring.
In December 2003, Libya announced that it had agreed to eliminate all its WMD programs, and permitted U.S. and British teams (as well as IAEA inspectors) into the country to assist this process and verify its completion. The nuclear weapons designs, gas centrifuges for uranium enrichment, and other equipment—including prototypes for improved SCUD ballistic missiles—were removed from Libya by the United States. (Libyan chemical weapons stocks and chemical bombs were also destroyed on site with international verification, with Libya joining the Chemical Weapons Convention.) Libya's non-compliance with its IAEA safeguards was reported to the U.N. Security Council, but with no action taken, as Libya's return to compliance with safeguards and Article II of the NPT was welcomed.
In 2011 the Libyan government was overthrown in the Libyan Civil War with the assistance of a military intervention by NATO forces acting under the auspices of United Nations Security Council Resolution 1973. It was speculated in the media (especially in the Middle Eastern media) that NATO's intervention in Libya shortly after the nation agreed to nuclear and chemical weapons disarmament would make other countries such as North Korea more reluctant to give up nuclear programs due to the risk of being weakened as a result.
Leaving the treaty.
Article X allows a state to leave the treaty if "extraordinary events, related to the subject matter of this Treaty, have jeopardized the supreme interests of its country", giving three months' (ninety days') notice. The state is required to give reasons for leaving the NPT in this notice.
NATO states argue that when there is a state of "general war" the treaty no longer applies, effectively allowing the states involved to leave the treaty with no notice. This is a necessary argument to support the NATO nuclear weapons sharing policy, but a troubling one for the logic of the treaty. NATO's argument is based on the phrase "the consequent need to make every effort to avert the danger of such a war" in the treaty preamble, inserted at the behest of U.S. diplomats, arguing that the treaty would at that point have failed to fulfill its function of prohibiting a general war and thus no longer be binding. Many states do not accept this argument. See United States-NATO nuclear weapons sharing above.
North Korea has also caused an uproar by its use of this provision of the treaty. Article X.1 only requires a state to give three months' notice in total, and does not provide for other states to question a state's interpretation of "supreme interests of its country". In 1993, North Korea gave notice to withdraw from the NPT. However, after 89 days, North Korea reached agreement with the United States to freeze its nuclear program under the Agreed Framework and "suspended" its withdrawal notice. In October 2002, the United States accused North Korea of violating the Agreed Framework by pursuing a secret uranium enrichment program, and suspended shipments of heavy fuel oil under that agreement. In response, North Korea expelled IAEA inspectors, disabled IAEA equipment, and, on 10 January 2003, announced that it was ending the suspension of its previous NPT withdrawal notification. North Korea said that only one more day's notice was sufficient for withdrawal from the NPT, as it had given 89 days before.
The IAEA Board of Governors rejected this interpretation. Most countries held that a new three-months withdrawal notice was required, and some questioned whether North Korea's notification met the "extraordinary events" and "supreme interests" requirements of the Treaty. The Joint Statement of 19 September 2005 at the end of the Fourth Round of the Six-Party Talks called for North Korea to "return" to the NPT, implicitly acknowledging that it had withdrawn.
Recent and coming events.
The main outcome of the 2000 Conference was the adoption by consensus of a comprehensive Final Document, which included among other things "practical steps for the systematic and progressive efforts" to implement the disarmament provisions of the NPT, commonly referred to as the Thirteen Steps.
On 18 July 2005, US President George W. Bush met Indian Prime Minister Manmohan Singh and declared that he would work to change US law and international rules to permit trade in US civilian nuclear technology with India. Some, such as British columnist George Monbiot, argue that the U.S.-India nuclear deal, in combination with US attempts to deny Iran (an NPT signatory) civilian nuclear fuel-making technology, may destroy the NPT regime, while others contend that such a move will likely bring India, an NPT non-signatory, under closer international scrutiny.
In the first half of 2010, it was strongly believed that China had signed a civilian nuclear deal with Pakistan claiming that the deal was "peaceful".
Arms control advocates criticised the reported China-Pakistan deal as they did in case of U.S.-India deal claiming that both the deals violate the NPT by facilitating nuclear programmes in states which are not parties to the NPT. Some reports asserted that the deal was a strategic move by China to balance US influence in South-Asia.
According to a report published by U.S. Department of Defense in 2001, China had provided Pakistan with nuclear materials and has given critical technological assistance in the construction of Pakistan's nuclear weapons development facilities, in violation of the Nuclear Non-Proliferation Treaty, of which China even then was a signatory.
At the Seventh Review Conference in May 2005, there were stark differences between the United States, which wanted the conference to focus on non-proliferation, especially on its allegations against Iran, and most other countries, who emphasized the lack of serious nuclear disarmament by the nuclear powers. The non-aligned countries reiterated their position emphasizing the need for nuclear disarmament.
The 2010 Review Conference was held in May 2010 in New York City, and adopted a final document that included a summary by the Review Conference President, Ambassador Libran Capactulan of the Philippines, and an Action Plan that was adopted by consensus. The 2010 conference was generally considered a success because it reached consensus where the previous Review Conference in 2005 ended in disarray, a fact that many attributed to the U.S. President Barack Obama's commitment to nuclear nonproliferation and disarmament. Some have warned that this success raised unrealistically high expectations that could lead to failure at the next Review Conference in 2015.
The "Global Summit on Nuclear Security" took place 12–13 April 2010. The summit was proposed by President Obama in Prague and was intended to strengthen the Nuclear Non-Proliferation Treaty in conjunction with the Proliferation Security Initiative and the Global Initiative to Combat Nuclear Terrorism. Forty seven states and three international organizations took part in the summit, which issued a communiqué and a work plan. For further information see 2010 Nuclear Security Summit.
In a major policy speech at the Brandenburg Gate in Berlin on 19 June 2013, United States President Barack Obama outlined plans to further reduce the number of warheads in the U.S. nuclear arsenal. According to "Foreign Policy", Obama proposed a "one-third reduction in strategic nuclear warheads - on top of the cuts already required by the New START treaty - bringing the number of deployed warheads to about 1,000." Obama is seeking to "negotiate these reductions with Russia to continue to move beyond Cold War nuclear postures," according to briefing documents provided to "Foreign Policy". In the same speech, Obama emphasized his administration's efforts to isolate any nuclear weapons capabilities emanating from Iran and North Korea. He also called for a renewed bipartisan effort in the United States Congress to ratify the Comprehensive Nuclear-Test-Ban Treaty and called on countries to negotiate a new treaty to end the production of fissile material for nuclear weapons.
On 24 April 2014, it was announced that the nation of the Marshall Islands has brought suit in The Hague against the United States, the former Soviet Union, the United Kingdom, France, China, India, Pakistan, North Korea and Israel seeking to have the disarmament provisions of the NNPT enforced.
Criticism and responses.
Over the years the NPT has come to be seen by many Third World states as “a conspiracy of the nuclear 'haves' to keep the nuclear ‘have-nots’ in their place”. This argument has roots in Article VI of the treaty which “obligates the nuclear weapons states to liquidate their nuclear stockpiles and pursue complete disarmament. The non-nuclear states see no signs of this happening”. Some argue that the NWS have not fully complied with their disarmament obligations under Article VI of the NPT. Some countries such as India have criticized the NPT, because it "discriminated against states not possessing nuclear weapons on January 1, 1967," while Iran and numerous Arab states have criticized Israel for not signing the NPT. There has been disappointment with the limited progress on nuclear disarmament, where the five authorized nuclear weapons states still have 22,000 warheads among them and have shown a reluctance to disarm further.
As noted , the International Court of Justice, in its advisory opinion on the Legality of the Threat or Use of Nuclear Weapons, stated that "there exists an obligation to pursue in good faith and bring to a conclusion negotiations leading to nuclear disarmament in all its aspects under strict and effective international control. Such an obligation requires that states actively pursue measures to reduce the numbers of nuclear weapons and the importance of their role in military force structures. Some critics of the nuclear-weapons states contend that they have failed to comply with Article VI by failing to make disarmament the driving force in national planning and policy with respect to nuclear weapons, even while they ask other states to plan for their security without nuclear weapons.
The United States responds to criticism of its disarmament record by pointing out that since the end of the Cold War it has eliminated over 13,000 nuclear weapons and eliminated over 80% of its deployed strategic warheads and 90% of non-strategic warheads deployed to NATO, in the process eliminating whole categories of warheads and delivery systems and reducing its reliance on nuclear weapons. U.S. officials have also pointed out the ongoing U.S. work to dismantle nuclear warheads. When current accelerated dismantlement efforts ordered by President George W. Bush have been completed, the U.S. arsenal will be less than a quarter of its size at the end of the Cold War, and smaller than it has been at any point since the Eisenhower administration, well before the drafting of the NPT.
The United States has also purchased many thousands of weapons' worth of uranium formerly in Soviet nuclear weapons for conversion into reactor fuel. As a consequence of this latter effort, it has been estimated that the equivalent of one lightbulb in every ten in the United States is powered by nuclear fuel removed from warheads previously targeted at the United States and its allies during the Cold War.
The U.S. Special Representative for Nuclear Nonproliferation agreed that nonproliferation and disarmament are linked, noting that they can be mutually reinforcing but also that growing proliferation risks create an environment that makes disarmament more difficult. The United Kingdom, France and Russia likewise defend their nuclear disarmament records, and the five NPT NWS issued a joint statement in 2008 reaffirming their Article VI disarmament commitments.
According to Thomas Reed and Danny Stillman, the “NPT has one giant loophole”: Article IV gives each non-nuclear weapon state the 'inalienable right' to pursue nuclear energy for the generation of power. A "number of high-ranking officials, even within the United Nations, have argued that they can do little to stop states using nuclear reactors to produce nuclear weapons". A 2009 United Nations report said that:
The revival of interest in nuclear power could result in the worldwide dissemination of uranium enrichment and spent fuel reprocessing technologies, which present obvious risks of proliferation as these technologies can produce fissile materials that are directly usable in nuclear weapons.
According to critics, those states which possess nuclear weapons, but are not authorized to do so under the NPT, have not paid a significant price for their pursuit of weapons capabilities. Also, the NPT has been explicitly weakened by a number of bilateral deals made by NPT signatories, notably the United States.

</doc>
<doc id="22109" url="https://en.wikipedia.org/wiki?curid=22109" title="Nikolai Bukharin">
Nikolai Bukharin

Nikolai Ivanovich Bukharin (; – 15 March 1938) was a Russian Bolshevik revolutionary, Soviet politician and prolific author on revolutionary theory. 
As a young man, he spent six years in exile, working closely with fellow exiles Lenin and Trotsky. After the revolution of February 1917, he returned to Moscow, where his Bolshevik credentials earned him a high rank in the party, and after the October Revolution, he became editor of the party newspaper "Pravda."
Within the bitterly divided Bolsheviks, his gradual move to the right, as a defender of the New Economic Policy (NEP), positioned him favourably as Stalin's chief ally, and together they ousted Trotsky, Zinoviev and Kamenev from the party leadership. From 1926 to 1929, Bukharin enjoyed great power as General Secretary of Comintern's executive committee. But Stalin’s decision to proceed with collectivisation drove the two men apart, and Bukharin was expelled from the Politburo.
When the Great Purge began in 1936, Stalin looked for any pretext to liquidate his former allies and rivals for power, and some of Bukharin's letters, conversations and tapped phone calls indicated disloyalty. Arrested in February 1937, he was charged with conspiring to overthrow the Soviet state and executed in March 1938, after a trial that alienated many Western communist sympathisers.
Before 1917.
Nikolai Bukharin was born on September 27 (October 9, new style), 1888 in Moscow. He was the second son of two schoolteachers, Ivan Gavrilovich Bukharin and Liubov Ivanovna Bukharina. His childhood is vividly recounted in his mostly autobiographic novel "How It All Began".
Bukharin's political life began at the age of sixteen with his lifelong friend Ilya Ehrenburg when he participated in student activities at Moscow University related to the Russian Revolution of 1905. He joined the Russian Social Democratic Labour Party in 1906, becoming a member of the Bolshevik faction. With Grigori Sokolnikov, he convened the 1907 national youth conference in Moscow, which was later considered the founding of Komsomol.
By age twenty, he was a member of the Moscow Committee of the party. The committee was heavily infiltrated by the Tsarist secret police, the Okhrana. As one of its leaders, Bukharin quickly became a person of interest to them. During this time, he became closely associated with Valerian Obolensky and Vladimir Smirnov, and also met his future first wife, Nadezhda Mikhailovna Lukina, his cousin and the sister of Nikolai Lukin, who was also a member of the party. They married soon after their exile, in 1911.
In 1911, after a brief imprisonment, Bukharin was exiled to Onega in Arkhangelsk, but soon escaped to Hanover, where he stayed for a year before visiting Kraków in 1912 to meet Vladimir Lenin for the first time. During the exile, he continued his education and wrote several books that established him as a major Bolshevik theorist in his 20's. His work, "Imperialism and World Economy" influenced Lenin, who freely borrowed from it in his larger and better known work, "Imperialism, the Highest Stage of Capitalism". Nevertheless, he and Lenin often had hot disputes on theoretical issues and Bukharin's closeness with the European Left and his anti-statist tendencies. Bukharin developed an interest in the works of Austrian Marxists and non-Marxist economic theorists, such as Aleksandr Bogdanov, who deviated from Leninist positions. Also while in Vienna in 1913, he helped the Georgian Bolshevik Joseph Stalin write an article, "Marxism and the National Question," at Lenin's request.
In October 1916, while based in New York City, he edited the newspaper "Novy Mir" ("New World") with Leon Trotsky and Alexandra Kollontai. When Trotsky arrived in New York in January 1917, Bukharin was the first to greet him (as Trotsky's wife recalled, "with a bear hug and immediately began to tell them about a public library which stayed open late at night and which he proposed to show us at once" dragging the tired Trotskys across town "to admire his great discovery").
1917 to 1923.
At the news of the Russian Revolution of February 1917, exiled revolutionaries from around the world began to flock back to the homeland. Trotsky left New York on March 27, 1917, sailing for St. Petersburg. Bukharin left New York in early April and returned to Russia by way of Japan, arriving in Moscow in early May 1917. Politically, the Bolsheviks in Moscow remained a definite minority to the Mensheviks and Socialist Revolutionaries. However, as the Russian soldiers and workers began to realize that only the Bolsheviks would bring peace by withdrawing from the war and the peasants realized that only the Bolsheviks would give them their own land, membership in the Bolshevik faction began to skyrocket—from 24,000 members in February 1917 to 200,000 members in October 1917. Upon his return to Moscow, Bukharin resumed his seat on the Moscow City Committee and also became a member of the Moscow Regional Bureau of the Party.
Initially, the Bolshevik position in Moscow was that of a minority position to the stronger Mensheviks and Socialist Revolutionaries. To make matters worse, the Bolsheviks themselves were divided into a right wing and a left wing. The right wing of the Bolsheviks, including Aleksei Rykov and Viktor Nogin, controlled the Moscow Committee, while the younger left-wing Bolsheviks, including Vladimir Smirnov, , Georgii Lomov, , Ivan Kizelshtein and Ivan Stukov, were members of the Moscow Regional Bureau. On October 10, 1917, Bukharin, along with two other Moscow Bolsheviks—A. S. Bubnov and G. Iu. Sokolnikov—were elected to the Central Committee. This strong representation on the Central Committee was a direct recognition of the fact that the Moscow Bureau had grown in importance. Whereas the Bolsheviks had previously been a minority in Moscow behind the Mensheviks and the Socialist Revolutionaries, by September 1917 the Bolsheviks were in the majority in Moscow. Furthermore, the Moscow Regional Bureau was formally responsible for the party organizations in each of the thirteen (13) central provinces around Moscow—which accounted for 37% of the whole population of Russia and 20% of the Bolshevik membership.
While no one dominated revolutionary politics in Moscow during the October Revolution, as Trotsky did in St. Petersburg, Bukharin certainly was the most prominent leader in Moscow. During the October Revolution, Bukharin drafted, introduced, and defended the revolutionary decrees of the Moscow Soviet. Bukharin then represented the Moscow Soviet in their report to the revolutionary government in Petrograd. Following the October Revolution, Bukharin became the editor of the party's newspaper, "Pravda".
Bukharin believed passionately in the promise of world revolution. In the Russian turmoil near the end of World War I, when a negotiated peace with the Central Powers was looming, he demanded a continuance of the war, fully expecting to incite all the foreign proletarian classes to arms. Even as he was uncompromising toward Russia's battlefield enemies, he also rejected any fraternization with the capitalist Allied powers: he reportedly wept when he learned of official negotiations for assistance. 
Bukharin emerged as the leader of the Left Communists in bitter opposition to Lenin's decision to sign the Treaty of Brest-Litovsk. In this wartime power struggle, he was urged by some of his more fiery allies to have Lenin arrested. He rejected this idea immediately, but the issue would later become the basis of Stalinist charges against him, culminating in the show trial of 1938.
After the ratification of the treaty, Bukharin resumed his responsibilities within the party. In March 1919, he became a member of the Comintern's executive committee and a candidate member of the Politburo. During the Civil War period, he published several theoretical economic works, including the popular primer "The ABC of Communism" (with Yevgeni Preobrazhensky, 1919), and the more academic "Economics of the Transitional Period" (1920) and "Historical Materialism" (1921).
By 1921, he changed his position and accepted Lenin's emphasis on the survival and strengthening of the Soviet state as the bastion of the future world revolution. He became the foremost supporter of the New Economic Policy (NEP), to which he was to tie his political fortunes. Considered by the Left Communists as a retreat from socialist policies, the NEP reintroduced money, allowed private ownership and capitalistic practices in agriculture, retail trade, and light industry while the state retained control of heavy industry. While some have criticized Bukharin for this apparent U-turn, his change of emphasis can be partially explained by the necessity for peace and stability following seven years of war in Russia, and the failure of communist revolutions in Central and Eastern Europe, which ended the prospect of worldwide revolution.
Power struggle.
After Lenin's death in 1924, Bukharin became a full member of the Politburo. In the subsequent power struggle among Leon Trotsky, Grigory Zinoviev, Lev Kamenev, and Stalin, Bukharin allied himself with Stalin, who positioned himself as centrist of the Party and supported the NEP against the Left Opposition, which wanted more rapid industrialization, escalation of class struggle against the kulaks (wealthier peasants), and agitation for world revolution. It was Bukharin who formulated the thesis of "Socialism in One Country" put forth by Stalin in 1924, which argued that socialism (in Marxist theory, the transitional stage from capitalism to communism) could be developed in a single country, even one as underdeveloped as Russia.). This new theory stated that revolution need no longer be encouraged in the capitalist countries since Russia could and should achieve socialism alone. The thesis would become a hallmark of Stalinism.
Trotsky, the prime force behind the Left Opposition, was defeated by a triumvirate formed by Stalin, Zinoviev and Kamenev, with the support of Bukharin. At the Fourteenth Party Congress in December 1925, Stalin openly attacked Kamenev and Zinoviev, revealing that they had asked for his aid in expelling Trotsky from the Party. By 1926, the Stalin-Bukharin alliance ousted Zinoviev and Kamenev from the Party leadership, and Bukharin enjoyed the highest degree of power during the 1926–1928 period. He emerged as the leader of the Party's right wing, which included two other Politburo members Alexei Rykov, Lenin's successor as Chairman of the Council of People's Commissars and Mikhail Tomsky, head of trade unions, and he became General Secretary of the Comintern's executive committee in 1926. However, prompted by a grain shortage in 1928, Stalin reversed himself and proposed a program of rapid industrialization and forced collectivization because he believed that the NEP was not working fast enough. Stalin felt that in the new situation the policies of his former foes–Trotsky, Zinoviev, and Kamenev—were the right ones.
Bukharin was worried by the prospect of Stalin's plan, which he feared would lead to “military-feudal exploitation” of the peasantry. Bukharin did want the Soviet Union to achieve industrialization but he preferred the more moderate approach of offering the peasants the opportunity to become prosperous, which would lead to greater grain production for sale abroad. Bukharin pressed his views throughout 1928 in meetings of the Politburo and at the Party Congress, insisting that enforced grain requisition would be counterproductive, as War Communism had been a decade earlier.
Fall from power.
Bukharin's support of continuation of the NEP was not popular with higher Party cadres, and his slogan to peasants, "Enrich yourselves!" and proposal to achieve socialism "at snail's pace" left him vulnerable to attacks first by Zinoviev and later by Stalin. Stalin attacked Bukharin's views, portraying them as capitalist deviation and declaring that the revolution would be at risk without a strong policy that encouraged rapid industrialization.
Having helped Stalin achieve unchecked power against the Left Opposition, Bukharin found himself easily outmaneuvered by Stalin. Yet Bukharin played to Stalin's strength by maintaining the appearance of unity within the Party leadership. Meanwhile, Stalin used his control of the Party machine to replace Bukharin's supporters in the Rightist power base in Moscow, trade unions, and the Comintern.
Bukharin attempted to gain support from earlier foes including Kamenev and Zinoviev who had fallen from power and held mid-level positions within the Communist party. The details of his meeting with Kamenev, to whom he confided that Stalin was "Genghis Khan" and changed policies to get rid of rivals, were leaked by the Trotskyist press and subjected him to accusations of factionalism. Eventually, Bukharin lost his position in the Comintern and the editorship of "Pravda" in April 1929 and he was expelled from the Politburo on 17 November of that year.
Bukharin was forced to renounce his views under pressure. He wrote letters to Stalin pleading for forgiveness and rehabilitation, but through wiretaps of Bukharin's private conversations with Stalin's enemies, Stalin knew Bukharin's repentance was insincere.
International supporters of Bukharin, Jay Lovestone of the Communist Party USA among them, were also expelled from the Comintern. They formed an international alliance to promote their views, calling it the "International Communist Opposition", though it became better known as the Right Opposition, after a term used by the Trotskyist Left Opposition in the Soviet Union to refer to Bukharin and his supporters there.
Great purge.
Stalin's collectivization policy proved to be as disastrous as Bukharin predicted, but Stalin had by then achieved unchallenged authority in the party leadership. However, there were signs that moderates among Stalin's supporters sought to end official terror and bring a general change in policy, now that mass collectivization was largely completed and the worst was over. Although Bukharin had not challenged Stalin since 1929, his former supporters, including Martemyan Ryutin, drafted and clandestinely circulated an anti-Stalin platform, which called Stalin the "evil genius of the Russian Revolution".
In the brief period of thaw in 1934–1936, Bukharin was politically rehabilitated and was made editor of "Izvestia" in 1934. There, he consistently highlighted the dangers of fascist regimes in Europe and the need for "proletarian humanism".
However, Sergey Kirov, First Secretary of the Leningrad Regional Committee was assassinated in Leningrad in December 1934, and his death was used by Stalin as a pretext to launch the Great Purge, in which about a million people were to perish as Stalin eliminated all past and potential opposition to his authority. Some historians now believe that Kirov's assassination in 1934 was arranged by Stalin himself or at least that there is sufficient evidence to plausibly posit such a conclusion. After Kirov's assassination, the NKVD charged an ever-growing group of former oppositionists with Kirov's murder and other acts of treason, terrorism, sabotage, and espionage.
Tightening noose.
In February 1936, shortly before the purge started in earnest, Bukharin was sent to Paris by Stalin to negotiate the purchase of the Marx and Engels archives, held by the German Social Democratic Party (SPD) before its dissolution by Hitler. He was joined by his young wife Anna Larina, which therefore opened the possibility of exile, but he decided against it, saying that he could not live outside the Soviet Union.
Bukharin, who had been forced to follow the Party line since 1929, confided to his old friends and former opponents his real view of Stalin and his policy. His conversations with Boris Nicolaevsky, a Menshevik leader who held the manuscripts on behalf of the SPD, formed the basis of "Letter of an Old Bolshevik", which was very influential in contemporary understanding of the period (especially the Ryutin Affair and the Kirov murder) although there are doubts about its authenticity.
According to Nicolaevsky, Bukharin spoke of "the mass annihilation of completely defenseless men, with women and children" under forced collectivization and liquidation of kulaks as a class that dehumanized the Party members with "the profound psychological change in those communists who took part in the campaign. Instead of going mad, they accepted terror as a normal administrative method and regarded obedience to all orders from above as a supreme virtue. ... They are no longer human beings. They have truly become the cogs in a terrible machine."
Yet to another Menshevik leader, Fyodor Dan, he confided that Stalin became "the man to whom the Party granted its confidence" and "is a sort of a symbol of the Party" even though he "is not a man, but a devil." In Dan's account, Bukharin's acceptance of the Soviet Union's new direction was thus a result of his utter commitment to Party solidarity.
To André Malraux, he also confided, "Now he is going to kill me". To his boyhood friend, Ilya Ehrenburg, he expressed the suspicion that the whole trip was a trap set up by Stalin. Indeed, his contacts with Mensheviks during this trip were to feature prominently in his trial.
Trial.
Following the trial and execution of Zinoviev, Kamenev, and other leftist Old Bolsheviks in 1936, Bukharin and Rykov were arrested on 27 February 1937 following a plenum of the Central Committee and were charged with conspiring to overthrow the Soviet state.
Bukharin was tried in the Trial of the Twenty One on 2–13 March 1938 during the Great Purges, along with ex-premier Alexei Rykov, Christian Rakovsky, Nikolai Krestinsky, Genrikh Yagoda, and 16 other defendants alleged to belong to the so-called "Bloc of Rightists and Trotskyites". Meant to be the culmination of previous show trials, it was now alleged that Bukharin and others sought to assassinate Lenin and Stalin from 1918, murder Maxim Gorky by poison, partition the Soviet Union and hand out her territories to Germany, Japan, and Great Britain.
Even more than earlier Moscow show trials, Bukharin's trial horrified many previously sympathetic observers as they watched allegations become more absurd than ever and the purge expand to include almost every living Old Bolshevik leader except Stalin. For some prominent communists such as Bertram Wolfe, Jay Lovestone, Arthur Koestler, and Heinrich Brandler, the Bukharin trial marked their final break with communism and even turned the first three into fervent anti-Communists eventually.
While Anastas Mikoyan and Vyacheslav Molotov later claimed that Bukharin was never tortured and his letters from prison do not give the suggestion that he was tortured, it is also known that his interrogators were instructed with the order: "beating permitted". Bukharin held out for three months, but threats to his young wife and infant son, combined with "methods of physical influence" wore him down. But when he read his confession amended and corrected personally by Stalin, he withdrew his whole confession. The examination started all over again, with a double team of interrogators.
Bukharin's confession and his motivation became subject of much debate among Western observers, inspiring Koestler's acclaimed novel "Darkness at Noon" and a philosophical essay by Maurice Merleau-Ponty in "Humanism and Terror." His confessions were somewhat different from others in that while he pled guilty to the "sum total of crimes," he denied knowledge when it came to specific crimes. Some astute observers noted that he would allow only what was in the written confession and refuse to go any further.
There are several interpretations of Bukharin's motivations (beside being coerced) in the trial. Koestler and others viewed it as a true believer's last service to the Party (while preserving the little amount of personal honor left) whereas Bukharin biographer Stephen Cohen and Robert Tucker saw traces of Aesopian language, with which Bukharin sought to turn the table into an anti-trial of Stalinism (while keeping his part of the bargain to save his family). While his letters to Stalin – he wrote 34 very emotional and desperate letters tearfully protesting his innocence and professing his loyalty – suggest a complete capitulation and acceptance of his role in the trial, it contrasts with his actual conduct in the trial.
Bukharin himself speaks of his "peculiar duality of mind" in his last plea, which led to "semi-paralysis of the will" and Hegelian "unhappy consciousness", which likely stemmed not only from his knowledge of the ruinous reality of Stalinism (although he could not of course say so in the trial) but also of the impending threat of fascism.
The result was a curious mix of fulsome confessions (of being a "degenerate fascist" working for the "restoration of capitalism") and subtle criticisms of the trial. After disproving several charges against him (one observer noted that he "proceeded to demolish or rather showed he could very easily demolish the whole case.") and saying that "the confession of the accused is not essential. The confession of the accused is a medieval principle of jurisprudence" in a trial that was solely based on confessions, he finished his last plea with the words:
"the monstrousness of my crime is immeasurable especially in the new stage of struggle of the U.S.S.R. May this trial be the last severe lesson, and may the great might of the U.S.S.R. become clear to all."
While in prison, he wrote at least four book-length manuscripts including a lyrical autobiographical novel, "How It All Began", philosophical treatise "Philosophical Arabesques", a collection of poems, and "Socialism and Its Culture" – all of which were found in Stalin's archive and published in the 1990s.
Execution.
Among other intercessors, the French author and Nobel laureate Romain Rolland wrote to Stalin seeking clemency, arguing that "an intellect like that of Bukharin is a treasure for his country." He compared Bukharin's situation to that of the great chemist Antoine Lavoisier who was guillotined during the French Revolution: "We in France, the most ardent revolutionaries... still profoundly grieve and regret what we did. ... I beg you to show clemency." He had earlier written to Stalin in 1937, "For the sake of Gorky I am asking you for mercy, even if he may be guilty of something," to which Stalin noted: "We must not respond." Bukharin was executed on 15 March 1938, but the announcement of his death was overshadowed by the Nazi Anschluss of Austria.
Bukharin's last message to Stalin: 'Koba, why do you need me to die?' (Russian: "Коба, зачем тебе нужна моя смерть?") was written in a note to Stalin just before his execution. ("Koba" was Stalin's revolutionary pseudonym, and Bukharin's use of it was a sign of how close the two had once been. The note was found still in Stalin's desk after his death in 1953).
Despite the promise to spare his family, Bukharin's wife, Anna Larina, was sent to a labor camp, but she survived to see her husband officially rehabilitated by the Soviet state under Mikhail Gorbachev in 1988.
Political stature and achievements.
Bukharin was immensely popular within the party throughout the twenties and thirties, even after his fall from power. In his testament, Lenin portrayed him as the Golden Boy of the party, writing:
Speaking of the young C.C. members, I wish to say a few words about Bukharin and Pyatakov. They are, in my opinion, the most outstanding figures (among the youngest ones), and the following must be borne in mind about them: Bukharin is not only a most valuable and major theorist of the Party; he is also rightly considered the favourite of the whole Party, but his theoretical views can be classified as fully Marxist only with great reserve, for there is something scholastic about him (he has never made a study of the dialectics, and, I think, never fully understood it) ... Both of these remarks, of course, are made only for the present, on the assumption that both these outstanding and devoted Party workers fail to find an occasion to enhance their knowledge and amend their one-sidedness.
Bukharin made several notable contributions to Marxist–Leninist thought, most notably "The Economics of the Transition Period" (1920) and his prison writings, "Philosophical Arabesques", (which clearly reveal Bukharin had corrected the 'one-sidedness' of his thought), as well as being a founding member of the Soviet Academy of Arts and Sciences, and a keen botanist. His primary contributions to economics were his critique of marginal utility theory, his analysis of imperialism, and his writings on the transition to communism in the Soviet Union.
His ideas, especially in economy and question of market-socialism, later became basic idea of Chinese market-socialism and Deng Xiao Ping reforms.
Works.
Cartoons.
Nikolai Bukharin was a cartoonist who left many cartoons of contemporary Soviet politicians. The renowned artist Konstantin Yuon once told him: "Forget about politics. There is no future in politics for you. Painting is your real calling." His cartoons are sometimes used to illustrate biographies of Soviet officials. Russian historian Yury Zhukov stated that Nikolai Bukarin's portraits of Joseph Stalin were the only ones drawn from the original, not from a photograph.

</doc>
<doc id="22110" url="https://en.wikipedia.org/wiki?curid=22110" title="Nasal consonant">
Nasal consonant

In phonetics, a nasal, also called a nasal occlusive, nasal stop in contrast with a nasal fricative, or nasal continuant, is an occlusive consonant produced with a lowered velum, allowing air to escape freely through the nose. Examples of nasals in English are and , in words such as "nose" and "mouth". Nasal occlusives are nearly universal in human languages. There are also other kinds of nasal consonants in some languages.
Definition.
Nearly all nasal consonants are nasal occlusives, in which air escapes through the nose but not through the mouth, as it is blocked (occluded) by the lips or tongue. The oral cavity still acts as a resonance chamber for the sound. Rarely, non-occlusive consonants may be nasalized.
Most nasals are voiced, and in fact, the nasal sounds and are among the most common sounds cross-linguistically. Voiceless nasals occur in a few languages such as Burmese, Welsh, Icelandic and Guaraní. (Compare oral stops, which block off the air completely, and fricatives, which obstruct the air with a narrow channel. Both stops and fricatives are more commonly voiceless than voiced, and are known as obstruents.)
In terms of acoustics, nasals are sonorants, which means that they do not significantly restrict the escape of air (as it can freely escape out the nose). However, nasals are also obstruents in their articulation because the flow of air through the mouth is blocked. This duality, a sonorant airflow through the nose along with an obstruction in the mouth, means that nasal occlusives behave both like sonorants and like obstruents. For example, nasals tend to pattern with other sonorants such as and , but in many languages, they may develop from or into stops.
Acoustically, nasals have bands of energy at around 200 and 2,000 Hz.
1. The symbol is commonly used to represent the dental nasal as well, rather than , as it is rarely distinguished from the alveolar nasal.
Examples of languages containing nasal occlusives:
The voiced retroflex nasal is is a common sound in Languages of India.
The voiced palatal nasal is a common sound in European languages, such as: Spanish , French and Italian , Catalan and Hungarian , Czech and Slovak , Polish , Occitan and Portuguese , Serbo-Croatian , and (before a vowel) Modern Greek .
Many Germanic languages, including German, Dutch, English and Swedish, as well as varieties of Chinese such as Mandarin and Cantonese, have , and . Tamil has a six-fold distinction between , , , , and (ம,ந,ன,ண,ஞ,ங).
Catalan, Occitan, Spanish, and Italian have , , as phonemes, and and as allophones. Nevertheless, in several American dialects of Spanish, there is no palatal nasal but only a palatalized nasal, , as in English "canyon".
In Brazilian Portuguese and Angolan Portuguese , written , is typically pronounced as , a nasal palatal approximant, a nasal glide (in Polish, this feature is also possible as an allophone). Semivowels in Portuguese often nasalize before and always after nasal vowels, resulting in and []. What would be coda nasal occlusives in other West Iberian languages is only slightly pronounced before dental consonants. Outside this environment the nasality is spread over the vowel or become a nasal diphthong ("mambembe" , outside the final, only in Brazil, and "mantém" in all Portuguese dialects).
The term 'nasal occlusive' (or 'nasal stop') is generally abbreviated to "nasal". However, there are also nasalized fricatives, nasalized flaps, nasal glides, and nasal vowels, as in French, Portuguese, and Polish. In the , nasal vowels and nasalized consonants are indicated by placing a tilde (~) over the vowel or consonant in question: French "sang" , Portuguese "bom" .
Voiceless nasals.
A few languages have phonemic voiceless nasal occlusives. Among them are Icelandic, Faroese, Burmese, Jalapa Mazatec, Kildin Sami, Welsh, and Central Alaskan Yup'ik. Iaai of New Caledonia has an unusually large number of them, with , along with a number of voiceless approximants.
Other kinds of nasal consonant.
Ladefoged and Maddieson (1996) distinguish purely nasal consonants, the nasal occlusives such as "m n ng" in which the airflow is purely nasal, from partial nasal consonants such as prenasalized stops and prestopped nasals, which are nasal for only part of their duration, as well as from nasalized consonants, which have simultaneous oral and nasal airflow. In some languages, such as Portuguese, a nasal consonant may have occlusive and non-occlusive allophones. In general, therefore, a nasal consonant may be:
Languages without nasals.
A few languages, perhaps 2%, contain no phonemically distinctive nasals. This led Ferguson (1963) to assume that all languages have at least one primary nasal occlusive. However, there are exceptions.
Lack of phonemic nasals.
When a language is claimed to lack nasals altogether, as with several Niger–Congo languages or the Pirahã language of the Amazon, nasal and non-nasal or prenasalized consonants usually alternate allophonically, and it is a theoretical claim on the part of the individual linguist that the nasal is not the basic form of the consonant. In the case of some Niger–Congo languages, for example, nasals occur before only nasal vowels. Since nasal vowels are phonemic, it simplifies the picture somewhat to assume that nasalization in occlusives is allophonic. There is then a second step in claiming that nasal vowels nasalize oral occlusives, rather than oral vowels denasalizing nasal occlusives, that is, whether are phonemically without full nasals, or without prenasalized stops. Postulating underlying oral or prenasalized stops rather than true nasals helps to explain the apparent instability of nasal correspondences throughout Niger–Congo compared with, for example, Indo-European.
This analysis comes at the expense, in some languages, of postulating either a single nasal consonant that can only be syllabic, or a larger set of nasal vowels than oral vowels, both typologically odd situations. The way such a situation could develop is illustrated by a Jukunoid language, Wukari. Wukari allows oral vowels in syllables like "ba, mba" and nasal vowels in "bã, mã", suggesting that nasals become prenasalized stops before oral vowels. Historically, however, *mb became **mm before nasal vowels, and then reduced to *m, leaving the current asymmetric distribution.
In older speakers of the Tlingit language, and are allophones. Tlingit is usually described as having an unusual, perhaps unique lack of despite having five lateral obstruents; the older generation could be argued to have but at the expense of having no nasals.
Lack of phonetic nasals.
Several of languages surrounding Puget Sound, such as Quileute (Chimakuan family), Lushootseed (Salishan family), and Makah (Wakashan family), are truly without any nasalization whatsoever, in consonants or vowels, except in special speech registers such as baby talk or the archaic speech of mythological figures (and perhaps not even that in the case of Quileute). This is an areal feature, only a few hundred years old, where nasals became voiced stops ( became , etc.) after colonial contact. For example, Snohomish is currently pronounced "sdohobish", but was transcribed with nasals in the first English-language records. 
The only other places in the world where this is known to occur is in New Guinea. In the central dialect of the Rotokas language of Bougainville Island, nasals are only used when imitating foreign accents. (A second dialect has a series of nasals.) The Foau language of West Irian is similar. 
The unconditioned loss of nasals, as in Puget Sound, is unusual. However, currently in Korean, word-initial and are shifting to and . This started out in nonstandard dialects and was restricted to the beginning of prosodic units (a common position for fortition), but has expanded to many speakers of the standard language to the beginnings of common words even within prosodic units.

</doc>
<doc id="22111" url="https://en.wikipedia.org/wiki?curid=22111" title="Nuvistor">
Nuvistor

The nuvistor is a type of vacuum tube announced by RCA in 1959. Most nuvistors are basically thimble-shaped, but somewhat smaller than a thimble, and much smaller than conventional tubes of the day. Triodes and a few tetrodes were made. The tube is made entirely of metal and ceramic. Making nuvistors requires special equipment, since there is no intubation to pump gases out of the envelope. Instead, the entire structure is assembled, inserted into its metal envelope, sealed and processed in a large vacuum chamber with simple robotic devices.
Nuvistors are among the highest performing small signal receiving tubes. They feature excellent VHF and UHF performance plus low noise figures, and were widely used throughout the 1960s in television sets (beginning with RCA's "New Vista" line of color sets in 1961 with the CTC-11 chassis) and radio equipment and high-fidelity equipment, primarily in RF sections. They competed with the solid state revolution, and along with GE's Compactron, probably held it at bay for a few years. RCA discontinued their use in television tuners for its product line in late 1971. One famous application was in the Ampex MR-70, a costly studio tape recorder whose entire electronics section was based on nuvistors. Another limited application of this very small tube was in studio-grade microphones from that era, the AKG/Norelco C12a, which employed the 7586, being a good example. It was also later found that, with minor circuit modification, the nuvistor made a sufficient replacement for the obsolete Telefunken VF14 tube, used in the famed Neumann U 47 studio microphone.

</doc>
<doc id="22113" url="https://en.wikipedia.org/wiki?curid=22113" title="No Logo">
No Logo

No Logo: Taking Aim at the Brand Bullies is a book by the Canadian author Naomi Klein. First published by Knopf Canada and Picador in December 1999, shortly after the 1999 WTO Ministerial Conference protests in Seattle had generated media attention around such issues, it became one of the most influential books about the alter-globalization movement and an international bestseller.
Focus.
The book focuses on branding and often makes connections with the alter-globalization movement. Throughout the four parts ("No Space", "No Choice", "No Jobs", and "No Logo"), Klein writes about issues such as sweatshops in the Americas and Asia, culture jamming, corporate censorship, and Reclaim the Streets. She pays special attention to the deeds and misdeeds of Nike, The Gap, McDonald's, Shell, and Microsoft – and of their lawyers, contractors, and advertising agencies. Many of the ideas in Klein's book derive from the influence of the Situationists, an art/political group founded in the late 1950s.
However, while globalization appears frequently as a recurring theme, Klein rarely addresses the topic of globalization itself, and when she does, it is usually indirectly. She goes on to discuss globalization in much greater detail in her book, "Fences and Windows" (2002).
Summary.
The book comprises four sections: "No Space", "No Choice", "No Jobs", and "No Logo". The first three deal with the negative effects of brand-oriented corporate activity, while the fourth discusses various methods people have taken in order to fight back.
"No Space".
The book begins by tracing the history of brands. Klein argues that there has been a shift in the usage of branding and gives examples of this shift to "anti-brand" branding. Early examples of brands were often used to put a recognizable face on factory-produced products. These slowly gave way to the idea of selling lifestyles. According to Klein, in response to an economic crash in the 1980s (due to the Latin American debt crisis, Black Monday (1987), the savings and loan crisis, and the Japanese asset price bubble), corporations began to seriously rethink their approach to marketing and to target the youth demographic, as opposed to the baby boomers, who had previously been considered a much more valuable segment.
The book discusses how brand names such as Nike or Pepsi expanded beyond the mere products which bore their names, and how these names and logos began to appear everywhere. As this happened, the brands' obsession with the youth market drove them to further associate themselves with whatever the youth considered "cool". Along the way, the brands attempted to associate their names with everything from movie stars and athletes to grassroots social movements.
Klein argues that large multinational corporations consider the marketing of a brand name to be more important than the actual manufacture of products; this theme recurs in the book, and Klein suggests that it helps explain the shift to production in Third World countries in such industries as clothing, footwear, and computer hardware.
This section also looks at ways in which brands have "muscled" their presence into the school system, and how in doing so, they have pipelined advertisements into the schools and used their position to gather information about the students. Klein argues that this is part of a trend toward targeting younger and younger consumers.
"No Choice".
In the second section, Klein discusses how brands use their size and clout to limit the number of choices available to the public – whether through market dominance (e.g., Wal-Mart) or through aggressive invasion of a region (e.g., Starbucks). Klein argues that each company's goal is to become the dominant force in its respective field. Meanwhile, other corporations, such as Sony or Disney, simply open their own chains of stores, preventing the competition from even putting their products on the shelves.
This section also discusses the way that corporations merge with one another in order to add to their ubiquity and provide greater control over their image. ABC News, for instance, is allegedly under pressure not to air any stories that are overly critical of Disney, its parent company. Other chains, such as Wal-Mart, often threaten to pull various products off their shelves, forcing manufacturers and publishers to comply with their demands. This might mean driving down manufacturing costs or changing the artwork or content of products like magazines or albums so they better fit with Wal-Mart's image of family friendliness.
Also discussed is the way that corporations abuse copyright laws in order to silence anyone who might attempt to criticize their brand.
"No Jobs".
In this section, the book takes a darker tone and looks at the way in which manufacturing jobs move from local factories to foreign countries, and particularly to places known as export processing zones. Such zones often have no labor laws, leading to dire working conditions.
The book then shifts back to North America, where the lack of manufacturing jobs has led to an influx of work in the service sector, where most of the jobs are for minimum wage and offer no benefits. The term "McJob" is introduced, defined as a job with poor compensation that does not keep pace with inflation, inflexible or undesirable hours, little chance of advancement, and high levels of stress. Meanwhile, the public is being sold the perception that these jobs are temporary employment for students and recent graduates, and therefore need not offer living wages or benefits.
All of this is set against a backdrop of massive profits and wealth being produced within the corporate sector. The result is a new generation of employees who have come to resent the success of the companies they work for. This resentment, along with rising unemployment, labour abuses abroad, disregard for the environment, and the ever-increasing presence of advertising breeds a new disdain for corporations.
"No Logo".
The final section of the book discusses various movements that have sprung up during the 1990s. These include "Adbusters" magazine and the culture-jamming movement, as well as Reclaim the Streets and the McLibel trial. Less radical protests are also discussed, such as the various movements aimed at putting an end to sweatshop labour.
Klein concludes by contrasting consumerism and citizenship, opting for the latter. "When I started this book," she writes, "I honestly didn't know whether I was covering marginal atomized scenes of resistance or the birth of a potentially broad-based movement. But as time went on, what I clearly saw was a movement forming before my eyes."
Criticism.
After the book's release, Klein was heavily criticized by the news magazine "The Economist", leading to a broadcast debate with Klein and the magazine's writers, dubbed "No Logo vs. Pro Logo".
The 2004 book "The Rebel Sell" (published as "Nation of Rebels" in the United States) specifically criticised "No Logo", stating that turning the improving quality of life in the working class into a fundamentally anti-market ideology is shallow. 
Awards.
In 2000, "No Logo" was short-listed for the "Guardian" First Book Award in 2000.
In 2001, the book won the following awards:
Editions.
Several imprints of "No Logo" exist, including a hardcover first edition a subsequent hardcover edition, and a paperback. A 10th anniversary edition was published by Fourth Estate that includes a new introduction by the author. Translations from the original English into several other languages have also been published. The subtitle, "Taking Aim at the Brand Bullies", was dropped in some later editions.
Video.
Naomi Klein explains her ideas in the 40-minute video "No Logo – Brands, Globalization & Resistance" (2003), directed by Sut Jhally.

</doc>
<doc id="22115" url="https://en.wikipedia.org/wiki?curid=22115" title="National War College">
National War College

The National War College (NWC) of the United States is a school in the National Defense University. It is housed in Roosevelt Hall on Fort Lesley J. McNair, Washington, D.C., the third-oldest Army post still active.
History.
The National War College ("NWC") was officially established on July 1, 1946, as an upgraded replacement for the Army-Navy Staff College, which operated from June 1943 to July 1946. The college was one of James Forrestal's favorite causes.
According to Lt. Gen. Leonard T. Gerow, President of the Board which recommended its formation,
The College is concerned with grand strategy and the utilization of the national resources necessary to implement that strategy... Its graduates will exercise a great influence on the formulation of national and foreign policy in both peace and war...
Mid-level and senior military officers who are likely to be promoted to the most senior ranks are selected to study at the War College in preparation for higher staff and command positions. About 75 percent of the student body is composed of equal representation from the land, air, and sea (including Marine and Coast Guard) services. The remaining 25 percent are drawn from the Department of State and other federal departments and agencies. In addition, international fellows from a number of countries join the student body. The curriculum is based upon critical analysis of strategic problem solving with emphasis on strategic leadership. Starting with the 2014–2015 academic year, the curriculum will be based upon a core standard throughout National Defense University.
Because of NWC's privileged location close to the White House, the Supreme Court, and Capitol Hill, it has been able throughout its history to call upon an extraordinarily well-connected array of speakers to animate its discussions. All lectures at the National War College are conducted under a strict "no quotation nor attribution" policy which has facilitated discussion on some of the most difficult issues of the day.
Alumni and influence.
Graduates of the National War College include numerous current and former flag officers, general officers, and U.S. ambassadors. Notable graduates include former U.S. Secretary of State and Chairman of the Joint Chiefs of Staff Colin Powell; U.S. Senator John McCain; former NATO Supreme Allied Commander Europe Wesley Clark; former Chairmen of the Joint Chiefs of Staff Peter Pace and Hugh Shelton; former National Security Advisor and NATO Supreme Allied Commander Europe James L. Jones; former U.S Army Chief of Staff Eric Shinseki; former U.S. Chief of Naval Operations Elmo Zumwalt; Commandant of the Marine Corps Robert H. Barrow; retired Air Force General Arnold W. Braswell; U.S. Ambassador to Russia John Beyrle; World War II submarine officer and best-selling novelist Edward L. Beach Jr.; former military aide to President John F. Kennedy, Godfrey McHugh; the late U.S. Ambassador to Libya J. Christopher Stevens; and former U.S. Air Force Chief of Staff Norton A. Schwartz; one of the initial nuclear theorists Bernard Brodie was a founding faculty member.
Roosevelt Hall.
Roosevelt Hall (built 1903–1907) is a Beaux Arts–style building housing the NWC since its inception in 1946. Designed by the New York architectural firm McKim, Mead and White, it is now designated a National Historical Landmark and is listed on the National Register of Historic Places.

</doc>
<doc id="22117" url="https://en.wikipedia.org/wiki?curid=22117" title="Neelin, Manitoba">
Neelin, Manitoba

Neelin is a small community in the Canadian province of Manitoba. It is located on Manitoba Provincial Highway 5 in the Rural Municipality of Argyle, about 29 km east of Killarney, or about 200 km southwest of Winnipeg.

</doc>
<doc id="22118" url="https://en.wikipedia.org/wiki?curid=22118" title="Norn language">
Norn language

Norn, an extinct North Germanic language, was spoken in the Northern Isles (Orkney and Shetland) off the north coast of mainland Scotland and in Caithness in the far north of the Scottish mainland. After Orkney and Shetland were pledged to Scotland by Norway in 1468/69, it was gradually replaced by Scots.
History.
Norse settlement in the islands probably began in the early 9th century. These settlers are believed to have arrived in very substantial numbers and like those who migrated to Iceland and the Faroe Islands it is probable that most came from the west coast of Norway. Shetland toponymy bears some resemblance to that of northwest Norway, while Norn vocabulary implies links with more southerly Norwegian regions.
Orkney and Shetland were pledged to James III in 1468 and 1469 respectively, and it is with these pledges that the replacement of Norn with Scots is most associated. However, the decline of Norse speech in Orkney probably began in 1379 when the earldom passed into the hands of the Sinclairs, and Scots had superseded Norse as the language of prestige on the island by the early 15th century. In Shetland the transition began later, but by the end of the 15th century both islands were bilingual. Despite this, the process by which Scots overtook Norn as the primary spoken language on the islands was not a swift one, and most natives of Orkney and Shetland likely spoke Norn as a first language until the late 16th and early-to-mid 17th centuries respectively.
Death.
It is not known exactly when Norn became extinct. Sources from the 17th and 18th centuries speak of Norn (sometimes identified as "Norse", "Norwegian" or "Danish") as being in a state of decline and generally indicate that the language remained stronger in Shetland than in Orkney. A source from 1670 states that there are "only three or four parishes" in Orkney where people speak "Noords or rude Danish" and that they do so "chiefly when they are at their own houses." Another from 1701 indicates that there were still a few monoglot "Norse" speakers who were capable of speaking "no other thing," and notes that there were more speakers of the language in Shetland than in Orkney. It was said in 1703 that the people of Shetland generally spoke English, but that "many among them retain the ancient Danish Language"; while in 1750 Orkney-born James Mackenzie wrote that Norn was not yet entirely extinct, being "retained by old people," who still spoke it among each other.
The last reports of Norn speakers are claimed to be from the 19th century, but it is more likely that the language was dying out in the late 18th century. The isolated islands of Foula and Unst are variously claimed as the last refuges of the language in Shetland, where there were people "who could repeat sentences in Norn, probably passages from folk songs or poems, as late as 1893. Walter Sutherland from Skaw in Unst, who died about 1850, has been cited as the last native speaker of the Norn language. However, fragments of vocabulary survived the death of the main language and remain to this day, mainly in place-names and terms referring to plants, animals, weather, mood, and fishing vocabulary.
Norn had also been a spoken language in Caithness but had probably become extinct there by the 15th century, replaced by Scots. Hence, some scholars also speak about "Caithness Norn", but others avoid this. Even less is known about "Caithness Norn" than about Orkney and Shetland Norn. Almost no written Norn has survived, but what little remains includes a version of the Lord's Prayer and a ballad, "Hildina". Michael P Barnes, professor of Scandinavian Studies at University College London, has published a study, "The Norn Language of Orkney and Shetland".
Classification.
Norn is an Indo-European language belonging to the North Germanic branch of the Germanic languages. Together with Faroese, Icelandic and Norwegian, it belongs to the West Scandinavian group, separating it from the East Scandinavian group consisting of Swedish, Danish and Gutnish. While this classification is based on the differences between the North Germanic languages at the time they split, their present-day characteristics justify another classification, dividing them into "Insular Scandinavian" and "Mainland Scandinavian" language groups, based on mutual intelligibility. Under this system, Norwegian is grouped together with Danish and Swedish, because the last millennium has seen all three undergo important changes, especially in grammar and lexis, which have set them apart from Faroese and Icelandic. Norn is generally considered to have been fairly similar to Faroese, sharing many phonological and grammatical traits, and might even have been mutually intelligible with it; thus, it can be considered an Insular Scandinavian language.
Few written texts remain. It is distinct from the present day dialect of Shetland, termed by linguists Shetlandic.
Phonology.
The phonology of Norn can never be determined with much precision due to the lack of source material, but the general aspects can be extrapolated from the few written sources that do exist. Norn shared many traits with the dialects of south-west Norway. This includes a voicing of to before or between vowels and (in the Shetland dialect, but only partially in the Orkney dialect) a conversion of and ("thing" and "that" respectively) to and respectively.
Grammar.
The features of Norn grammar were very similar to the other Scandinavian languages. There were two numbers, three genders and four cases (nominative, accusative, genitive and dative). The two main conjugations of verbs in present and past tense were also present and like all other North Germanic languages, it used a suffix instead of a prepositioned article to indicate definiteness as in modern Scandinavian: ' ("man"); ' ("the man"). Though it is difficult to be certain of many of the aspects of Norn grammar, documents indicate that it may have featured subjectless clauses, which were common in the West Scandinavian languages.
Sample text.
The following are Norn and Old Norse versions of the Lord's Prayer:
A Shetland "guddick" (riddle) in Norn, which Jakob Jakobsen heard told on Unst, the northernmost island in Shetland, in the 1890s. The same riddle is also known from the Faroe Islands, from Iceland, and a variation also occurs in England.
The answer is a cow: four teats hang, four legs walk, two horns and two ears stand skyward, two eyes show the way to the field and one tail comes shaking (dangling) behind.
Modern use.
Most of the use of Norn/Norse in modern day Shetland and Orkney is purely ceremonial, and mostly in Old Norse, for example the Shetland motto, which is "" ("with law shall land be built") which is the same motto used by the Icelandic police force and inspired by the Danish Codex Holmiensis.
Another example of the use of Norse/Norn in the Northern Isles can be found in the names of ferries:
Norn words are still used to describe many of the colour and pattern variations in the native sheep of Shetland and Orkney, which survive as the Shetland and North Ronaldsay breeds. Icelandic uses similar words for many of the same colour variations in Icelandic sheep.
There are some enthusiasts who are engaged in developing and disseminating a modern form called Nynorn ("New Norn"), based upon linguistic analysis of the known records and Norse linguistics in general.

</doc>
<doc id="22120" url="https://en.wikipedia.org/wiki?curid=22120" title="Nuoro">
Nuoro

Nuoro ( or less correctly ; ) is a city and "comune" (municipality) in central-eastern Sardinia, Italy, situated on the slopes of the Monte Ortobene. It is the capital of the province of Nuoro. With a population of 36,347 (2011), it is the sixth-largest city in Sardinia.
Birthplace of several renowned artists, including writers, poets, painters, and sculptors, Nuoro hosts some of the most important museums in Sardinia. It is considered an important cultural center of the region and it has been referred as the "Atene sarda" (Sardinian Athens). Nuoro is the hometown of Grazia Deledda, the first and only Italian woman to win (1926) the Nobel Prize in Literature.
History.
The earliest traces of human settlement in the Nuoro area (called " the Nuorese") are the so-called Domus de janas, rock-cut tombs dated at the third millennium BC. However, fragments of ceramics of the Ozieri culture have also been discovered and dated at c. 3500 BC.
The Nuorese was a centre of the Nuragic civilization (which developed in Sardinia from c. 1500 BC to c. 250 BC), as attested by more than 30 Nuragic sites, such has the village discovered in the countryside of Tanca Manna, just outside Nuoro, which was made of about 800 huts.
The Nuorese was crossed by a Roman road which connected Karalis (Cagliari) to Ulbia (Olbia). The legacy of the Roman colonization can especially be found in the variety of the Sardinian language which is still spoken today in Nuoro: "Sardu nugoresu" is considered the most conservative lect of the Romance family.
After the fall of the Western Roman Empire, Sardinia was held first by the Vandals and then by the Byzantines. According to the letters of Pope Gregory I, a Romanized and Christianized culture (that of the "provinciales") co-existed with several Pagan cultures (those of the "Gens Barbaricina", i.e. "Barbarian People") mainly located in the island's interior. As the Byzantine control waned, the Giudicati appeared. A small village known as Nugor appears on a medieval map from 1147. In the two following centuries it grew to more than 1000 inhabitants. Nuoro remained a town of average importance under the Aragonese and Spanish domination of Sardinia, until famine and plague struck it in the late 17th century.
After the annexation to the Kingdom of Sardinia, the town became the administrative center of the area, obtaining the title of city in 1836.
Culture.
Language.
The traditional language spoken in Nuoro is Sardinian, in its Logudorese-Nuorese variety.
Transportation.
Nuoro is served by the SS 131 DCN (Olbia-Abbasanta), the SS 129 (Orosei-Macomer), and the SS 389 (Monti-Lanusei). It is connected by train (FdS) to Macomer and by bus (ARST, Azienda Regionale Sarda Trasporti) to Cagliari, Sassari, Olbia, and to several minor centres in the province and the region. ATP Nuoro's bus system provides service within the city.

</doc>
<doc id="22122" url="https://en.wikipedia.org/wiki?curid=22122" title="Nürburgring">
Nürburgring

Nürburgring is a 150,000-capacity motorsports complex located in the town of Nürburg, Rhineland-Palatinate, Germany. It features a Grand Prix race track built in 1984, and a much longer old "North loop" track which was built in the 1920s around the village and medieval castle of Nürburg in the Eifel mountains. The north loop is long and has more than 300 metres (1,000 feet) of elevation change from its lowest to highest points. Jackie Stewart nicknamed the old track "The Green Hell".
Originally, the track featured four configurations: the -long "Gesamtstrecke" ("Whole Course"), which in turn consisted of the "Nordschleife" ("North Loop"), and the "Südschleife" ("South Loop"). There also was a warm-up loop called "Zielschleife" ("Finish Loop") or "Betonschleife" ("Concrete Loop"), around the pit area.
Between 1982 and 1983 the start/finish area was demolished to create a new "GP-Strecke", and this is used for all major and international racing events. However, the shortened "Nordschleife" is still in use for racing, testing and public access.
History.
1925–1939: The beginning of the ""Nürburg-Ring"".
In the early 1920s, ADAC Eifelrennen races were held on public roads in the Eifel mountains. This was soon recognised as impractical and dangerous. The construction of a dedicated race track was proposed, following the examples of Italy's Monza and Targa Florio courses, and Berlin's AVUS, yet with a different character. The layout of the circuit in the mountains was similar to the Targa Florio event, one of the most important motor races at that time. The original Nürburgring was to be a showcase for German automotive engineering and racing talent. Construction of the track, designed by the "Eichler Architekturbüro" from Ravensburg (led by architect Gustav Eichler), began in September 1925.
The track was completed in spring of 1927, and the ADAC Eifelrennen races were continued there. The first races to take place on 18 June 1927 showed motorcycles and sidecars. The first motorcycle race was won by Toni Ulmen on an English 350 cc Velocette. The cars followed a day later, and Rudolf Caracciola was the winner of the over 5000 cc class in a Mercedes Compressor. In addition, the track was opened to the public in the evenings and on weekends, as a one-way toll road. The whole track consisted of 174 bends (prior to 1971 changes), and averaged in width. The fastest time ever around the full "Gesamtstrecke" was by Louis Chiron, at an average speed of 112.31 km/h (72 mph) in his Bugatti.
In 1929 the full Nürburgring was used for the last time in major racing events, as future Grands Prix would be held only on the "Nordschleife". Motorcycles and minor races primarily used the shorter and safer "Südschleife". Memorable pre-war races at the circuit featured the talents of early "Ringmeister" (Ringmasters) such as Rudolf Caracciola, Tazio Nuvolari and Bernd Rosemeyer.
1947–1970: The Green Hell.
After World War II, racing resumed in 1947 and in 1951, the "Nordschleife" of the Nürburgring again became the main venue for the German Grand Prix as part of the Formula One World Championship (with the exception of 1959, when it was held on the AVUS in Berlin). A new group of "Ringmeister" arose to dominate the race – Alberto Ascari, Juan Manuel Fangio, Stirling Moss, Jim Clark, John Surtees, Jackie Stewart and Jacky Ickx.
On 5 August 1961, during practice for the 1961 German Grand Prix, Phil Hill became the first person to complete a lap of the "Nordschleife" in under 9 minutes, with a lap of 8 minutes 55.2 seconds (153.4 km/h or 95.3 mph) in the Ferrari 156 "Sharknose" Formula One car. Over half a century later, the highest-performing road cars have difficulty breaking 8 minutes without a professional race driver or one very familiar with the track. Also, several rounds of the German motorcycle Grand Prix were held, mostly on the "Südschleife", but the Hockenheimring and the Solitudering were the main sites for Grand Prix motorcycle racing.
In 1953, the ADAC 1000 km Nürburgring race was introduced, an Endurance race and Sports car racing event that counted towards the World Sportscar Championship for decades. The 24 Hours Nürburgring for touring car racing was added in 1970.
By the late 1960s, the "Nordschleife" and many other tracks were becoming increasingly dangerous for the latest generation of F1 cars. In 1967, a chicane was added before the start/finish straight, called "Hohenrain", in order to reduce speeds at the pit lane entry. This made the track longer. Even this change, however, was not enough to keep Stewart from nicknaming it "The Green Hell" following his victory in the 1968 German Grand Prix amid a driving rainstorm and thick fog. In 1970, after the fatal crash of Piers Courage at Zandvoort, the F1 drivers decided at the French Grand Prix to boycott the Nürburgring unless major changes were made, as they did at Spa the year before. The changes were not possible on short notice, and the German GP was moved to the Hockenheimring, which had already been modified.
1971–1983: Changes.
In accordance with the demands of the F1 drivers the "Nordschleife" was reconstructed by taking out some bumps, smoothing out some sudden jumps (particularly at Brünnchen), and installing Armco safety barriers. The track was made straighter, following the race line, which reduced the number of corners. The German GP could be hosted at the Nürburgring again, and was for another six years from 1971 to 1976.
In 1973 the entrance into the dangerous and bumpy Kallenhard corner was made slower by adding another left-hand corner after the fast Metzgesfeld sweeping corner. Safety was improved again later on, e.g. by removing the jumps on the long main straight and widening it, and taking away the bushes right next to the track at the main straight, which made that section of the Nürburgring dangerously narrow. A second series of three more F1 races was held until 1976. However, primarily due to its length of over , and the lack of space due to its situation on the sides of the mountains, increasing demands by the F1 drivers and the FIA's CSI commission were too expensive or impossible to meet. For instance, by the 1970s the German Grand Prix required five times the marshals and medical staff as a typical F1 race, something the German organizers were unwilling to provide. Additionally, even with the 1971 modifications it was still possible for cars to become airborne off the track. The Nürburgring was also unsuitable for the burgeoning television market; its vast expanse made it almost impossible to effectively cover a race there. As a result, early in the season it was decided that the 1976 race would be the last to be held on the old circuit.
Niki Lauda, the reigning world champion and only person ever to lap the full "Nordschleife" in under 7 minutes (6:58.6, 1975), proposed to the other drivers that they boycott the circuit in 1976. Lauda was not only concerned about the safety arrangements and the lack of marshals around the circuit, but did not like the prospect of running the race in another rainstorm. Usually when that happened, some parts of the circuit were wet and other parts were dry, which is what the conditions of the circuit were for that race. The other drivers voted against the idea and the race went ahead. Lauda crashed in his Ferrari coming out of the left-hand kink before Bergwerk, for causes that were never established. He was badly burned as his car was still loaded with fuel in lap 2. Lauda was saved by the combined actions of fellow drivers Arturo Merzario, Guy Edwards, Brett Lunger, and Harald Ertl, rather than by the ill-equipped track marshals.
The crash also showed that the track's distances were too long for regular fire engines and ambulances, even though the "ONS-Staffel" was equipped with a Porsche 911 rescue car, marked (R). The old Nürburgring never hosted another F1 race again, as the German Grand Prix was moved to the Hockenheimring for 1977. The German motorcycle Grand Prix was held for the last time on the old Nürburgring in 1980, also permanently moving to Hockenheim.
By its very nature, the "Nordschleife" was impossible to make safe in its old configuration. It soon became apparent that it would have to be completely overhauled if there was any prospect of Formula One returning there. With this in mind, in 1981 work began on a -long new circuit, which was built on and around the old pit area.
At the same time, a bypass shortened the "Nordschleife" to , and with an additional small pit lane, this version was used for races in 1983, e.g. the 1000km Nürburgring endurance race, while construction work was going on nearby. In training for that race, the late Stefan Bellof set the all-time lap record for the "Nordschleife" in his Porsche 956, which is still unbeaten at 6:11.13, or over on average (partially because no major racing has taken place there since 1984).
Meanwhile, more run-off areas were added at corners like Aremberg and Brünnchen, where originally there were just embankments protected by Armco barriers. The track surface was made safer in some spots where there had been nasty bumps and jumps. Racing line markers were added to the corners all around the track as well. Also, bushes and hedges at the edges of corners were taken out and replaced with Armco and grass.
The former "Südschleife" had not been modified in 1970/71 and was abandoned a few years later in favour of the improved "Nordschleife". It is now mostly gone (in part due to the construction of the new circuit) or converted to a normal public road, but since 2005 a vintage car event has been hosted on the old track layout, including part of the parking area.
1984: The new Grand Prix track.
The new track was completed in 1984 and named "GP-Strecke" (: literally, ""Grand Prix Course""). It was built to meet the highest safety standards. 
However, it was considered in character a mere shadow of its older sibling. Some fans, who had to sit much farther away from the track, called it "Eifelring", "Ersatzring", "Grünering" or similar nicknames, believing it did not deserve to be called Nürburgring. Like many circuits of the time, it offered few overtaking opportunities.
Prior to the 2013 German Grand Prix both Mark Webber and Lewis Hamilton said they like the track. Webber described the layout as "an old school track" before adding, "It’s a beautiful little circuit for us to still drive on so I think all the guys enjoy driving here." While Hamilton said "It’s a fantastic circuit, one of the classics and it hasn’t lost that feel of an old classic circuit."
To celebrate its opening, an exhibition race was held, on 12 May, featuring an array of notable drivers. Driving identical Mercedes 190E 2.3–16's, the line-up was Elio de Angelis, Jack Brabham (Formula 1 World Champion 1959, 1960, 1966), Phil Hill (1961), Denis Hulme (1967), James Hunt (1976), Alan Jones (1980), Jacques Laffite, Niki Lauda (1975, 1977)*, Stirling Moss, Alain Prost*, Carlos Reutemann, Keke Rosberg (1982), Jody Scheckter (1979), Ayrton Senna*, John Surtees (1964) and John Watson. Senna won ahead of Lauda, Reutemann, Rosberg, Watson, Hulme and Jody Scheckter, being the only one to resist Lauda's overwhelming performance who – having missed the qualifying – had to start from the last row and overtook all the others except Senna.
The asterisk ( * ) in the previous paragraph indicate that titles which were not yet won at the time of the race are not mentioned here, so there were nine former and two future Formula 1 World Champions competing, in a field of 20 cars with 16 Formula 1 drivers; the other four were local drivers: Klaus Ludwig, Manfred Schurti, Udo Schütz and Hans Herrmann.
Besides other major international events, the Nürburgring has seen the brief return of Formula One racing, as the 1984 European Grand Prix was held at the track, followed by the 1985 German Grand Prix. As F1 did not stay, other events were the highlights at the new Nürburgring, including the 1000km Nürburgring, DTM, motorcycles, and newer types of events, like truck racing, vintage car racing at the AvD "Oldtimer Grand Prix", and even the "Rock am Ring" concerts.
Following the success and first world championship of Michael Schumacher, a second German F1 race was held at the Nürburgring between 1995 and 2006, called the European Grand Prix, or in 1997 and 1998, the Luxembourg Grand Prix.
For 2002, the track was changed, by replacing the former "Castrol-chicane" at the end of the start/finish straight with a sharp right-hander (nicknamed "Haug-Hook"), in order to create an overtaking opportunity. Also, a slow Omega-shaped section was inserted, on the site of the former kart track. This extended the GP track from , while at the same time, the Hockenheimring was shortened from .
Both the Nürburgring and the Hockenheimring events have been losing money due to high and rising Formula One license fees charged by Bernie Ecclestone and low attendance due to high ticket prices; starting with the 2007 Formula One season, Hockenheim and Nürburgring will alternate for hosting of the German GP.
In Formula One, Ralf Schumacher collided with his brother at the start of the 1997 race, which may have cost Michael the championship. In 1999, in changing conditions, Johnny Herbert managed to score the only win for the team of former "Ringmeister" Jackie Stewart. One of the highlights of the 2005 season was Kimi Räikkönen's spectacular exit while in the last lap of the race, when his suspension gave way after being rattled lap after lap by a flat-spotted tire that was not changed due to the short-lived rule.
Prior to the 2007 European Grand Prix, the "Audi S" (turns 8 and 9) was renamed "Michael Schumacher S" after Michael Schumacher. Schumacher had retired from Formula One the year before, but returned in 2010, and in 2011 became the second Formula One driver to drive through a turn named after them (after Ayrton Senna driving his "S for Senna" at Autódromo José Carlos Pace).
Alternation with Hockenheim.
In 2007, the FIA announced that Hockenheimring and Nürburgring would alternate with the German Grand Prix with Nürburgring hosting in 2007. Due to name-licensing problems, it was held as the European Grand Prix that year. However, in 2008 the European Grand Prix was held at Valencia Street Circuit, Eastern Spain.
Fatal accidents.
While it is unusual for deaths to occur during sanctioned races, there are many accidents and several deaths each year during public sessions. It is common for the track to be closed several times a day for cleanup, repair, and medical intervention. While track management does not publish any official figures, several regular visitors to the track have used police reports to estimate the number of fatalities at somewhere between 3 and 12 in a full year. Jeremy Clarkson noted in "Top Gear" in 2004 that "over the years this track has claimed over 200 lives".
"Nordschleife" racing today.
Several touring car series still compete on the "Nordschleife", using either only the simple version with its separate small pit lane, or a combined -long track that uses a part of the original modern F1 track (without the Mercedes Arena section, which is often used for support pits) plus its huge pit facilities. Entry-level competition requires a regularity test (GLP) for street-legal cars. Two racing series (RCN/CHC and VLN) compete on 15 Saturdays each year, for several hours.
The annual highlight is the 24 Hours Nürburgring weekend, held usually in mid-May, featuring 220 cars - from small cars to Turbo Porsches or factory race cars built by BMW, Opel, Audi, Mercedes-Benz, over 700 drivers (amateurs and professionals), and up to 290,000 spectators.
In 2015 the World Touring Car Championship is scheduled to host the FIA WTCC Race of Germany at the Nordschleife as a support category to the 24h.
Automotive media outlets and manufacturers use the "Nordschleife" as a standard to publish their lap times achieved with production vehicles.
BMW Sauber’s Nick Heidfeld made history on 28 April 2007 as the first driver in over 30 years to tackle the Nürburgring "Nordschleife" track in a contemporary Formula One car. Heidfeld’s three demonstration laps round the German circuit in an F1.06 were the highlight of festivities celebrating BMW’s contribution to motorsport. About 45,000 spectators showed up for the main event, the third four-hour VLN race of the season, and the subsequent show by Heidfeld. Conceived largely as a photo opportunity, the lap times were not as fast as the car was capable of, BMW instead choosing to run the chassis at a particularly high ride height to allow for the "Nordschleife"'s abrupt gradient changes and to limit maximum speeds accordingly. Former F1 driver Hans-Joachim Stuck was injured during the race when he crashed his BMW Z4.
As part of the festivities before the 2013 Nürburgring 24 Hour race, Michael Schumacher and other Mercedes-Benz drivers took part in a promotional event which saw Schumacher complete a demonstration lap of the Nordschleife at the wheel of a 2011 Mercedes W02. As with Heidfeld's lap, and also partly due to F1's strict in-season testing bans, the lap left many motorsport fans underwhelmed.
"Nordschleife" public access.
Since its opening in 1927, the track has been used by the public for the so-called ""Touristenfahrten"," i.e. anyone with a road-legal car or motorcycle, as well as tour buses, motor homes, or cars with trailers. It is opened mainly on Sundays, but also many Saturdays and weekday evenings. The track may be closed for weeks during the winter months, depending on weather conditions and maintenance work. Passing on the right is prohibited, and some sections have speed limits.
This Nürburgring is a popular attraction for many driving enthusiasts and riders from all over the world, partly because of its history and the challenge it provides. The lack of oncoming traffic and intersections sets it apart from regular roads, and the absence of a blanket speed limit is a further attraction.
Normal ticket buyers on these tourist days cannot quite complete a full lap of the "Nordschleife", which bypasses the modern "GP-Strecke", as they are required to slow down and pass through a "pit lane" section where the toll gates are installed. On busier days, a mobile ticket barrier is installed on the main straight in order to reduce the length of queues at the fixed barriers. This is open to all ticket holders. On rare occasions, it is possible to drive both the "Nordschleife" and the Grand Prix circuit combined.
Drivers interested in lap times often time themselves from the first bridge after the barriers to the last gantry (aka Bridge-to-Gantry or BTG time) before the exit. However, the track's general conditions state that any form of racing, including speed record attempts, is forbidden. The driver's insurance coverage may consequently be voided, leaving the driver fully liable for damage. Normal, non-racing, non-timed driving accidents might be covered by driver's insurance, but it is increasingly common for UK insurers especially to insert exclusion clauses that mean drivers and riders on the Nürburgring only have third-party cover only or are not covered at all.
Drivers who have crashed into the barriers, suffered mechanical failure or been otherwise required to be towed off track during Touristenfahrten sessions are referred to as having joined the 'Bongard Club'. This nickname is derived from the name of the company which operates the large yellow recovery flatbed trucks which ferry those unfortunate drivers and their vehicles to the nearest exit. Due to the high volume of traffic, there is an emphasis on quickly clearing and repairing any compromised safety measures so the track can be immediately re-opened for use. 
Additionally, those found responsible for damage to the track and safety barriers on track are required to pay for those repairs, along with the time and cost associated with personnel and equipment to address those damages, making any accident or breakdown a potentially expensive incident. Because it is technically operated as a public toll road, failing to report an accident or instance where track surfaces are affected is considered unlawfully leaving the scene of an accident. This is all part of the rules and regulations which aim ensure a safe experience for all visitors to the track.
Commercial aspects.
One of the original purposes of the "Nordschleife" was as a test track for auto manufacturers, and its demanding layout had been traditionally used as a proving ground. Weekdays are often booked for so-called "Industriefahrten" for auto makers and the media. With the advent of the Internet, awareness of the "Nordschleife" has risen in Germany and abroad, in addition to publicity in print media. In 1999, Porsche reported that their new 996 GT3 had lapped the Nürburgring in under eight minutes, and in subsequent years, manufacturers from overseas also showed up to test cars. Some high-performance models are promoted with videotaped laps published on the web, and the claimed lap times are generating discussion. Few of these "supercars" are actually entered in racing where the claims could be backed up.
The TV Series "Top Gear" has also used the "Nordschleife" for its challenges, often involving Sabine Schmitz. In addition, during series 17 (summer 2011) of Top Gear, James May was very critical of the ride quality of cars whose development processes included testing on the "Nordschleife", saying that cars which were tested at Nordschleife got ruined.
Other pastimes are hosted at the Nürburgring, such as the "Rock am Ring", Germany's biggest rock festival, attracting close to 100,000 rock fans each year since 1985. Since 1978, the "Nordschleife" is also the venue of a major running event (Nürburgring-Lauf/Run am Ring). In 2003, a major cycling event (Rad am Ring) was added and it became the multi-sports event "Rad & Run am Ring".
In 2009, new commercial areas opened, including a hotel and shopping mall. In the summer of 2009, ETF Ride Systems opened a new interactive dark ride application called "Motor Mania" at the racetrack, in collaboration with Lagotronics B.V. The roller coaster "ring°racer" was scheduled to open in 2011 but never started its operations due to technical failures.
In 2012, the track was preparing to file for bankruptcy as a result of nearly $500 million in debts and the inability to secure financing. On 1 August 2012, the government of Rheinland-Pfalz guaranteed $312 million to allow the track to meet its debt obligations.
In 2013, the Nürburgring was for sale for US$165 million (€127.3 million). The sale process was by sealed-bid auction with an expected completion date of "Late Summer". This meant there was to be a new owner in 2013, unencumbered by the debts of the previous operation, with the circuit expected to return to profitability.
On March 11, 2014 it was reported that the Nürburgring was sold for 77 million euros ($106.8 million). Düsseldorf-based Capricorn Development was the buyer. The company was to take full ownership of the Nürburgring on January 1, 2015. But in October 2014, Russian billionaire, the chairman of Moscow-based Pharmstandard, Viktor Kharitonin, bought a majority stake in 'The Ring.'
In May 2015, the Nürburgring was set to hold the first "Grüne Hölle Rock" festival as a replacement for the "Rock am Ring" festival, but it fell through. "Grüne Hölle Rock" has changed their name to "Rock im Revier" and will be held in the Schalke area.
"Nordschleife" map.
Locations of note.
"Flugplatz" ("air field", a small airport).
The "Nordschleife" was formerly known for its abundance of sharp crests, causing fast-moving, firmly-sprung racing cars to jump clear off the track surface at many locations. Although by no means the most fearsome, "Flugplatz" is perhaps the most aptly (although coincidentally) named and widely remembered. The name of this part of the track comes from a small airfield, which in the early years was located close to the track in this area. The track features a very short straight that climbs sharply uphill for a short time, then suddenly drops slightly downhill, and this is immediately followed by two very fast right-hand kinks. Chris Irwin's career was ended following a massive accident at "Flugplatz", in a Ford 3L GT sports car in 1968. Manfred Winkelhock flipped his March F2 car at the same corner in 1980. The Flugplatz is one of the most important parts of the Nürburgring because after the two very fast right handers comes what is possibly the fastest part of the track: a downhill straight called "Kottenborn", into a very fast curve called "Schwedenkreuz" (Swedish Cross). Drivers are flat for some time here.
Right before Flugplatz is Quiddelbacher Höhe (Peak, as in "Mountain Summit"), where the track crosses a bridge over the Bundesstraße 257.
"Fuchsröhre" ("Fox Hole").
The "Fuchsröhre" is soon after the very fast downhill section succeeding the Flugplatz. After negotiating a long right hand corner called Aremberg (which is after Schwedenkreuz) the road goes slightly uphill, under a bridge and then it plunges downhill, and the road switches back left and right and finding a point of reference for the racing line is difficult. This whole sequence is flat out and then, the road climbs sharply uphill. The road then turns left and levels out at the same time; this is one of the many jumps of the Nürburgring where the car goes airborne. This leads to the Adenauer Forst (Forest) turns. The Fuchsrohre is one of the fastest and most dangerous parts of the Nürburgring because of the extremely high speeds in such a tight and confined place; this part of the Nürburgring goes right through a forest and there is only about 7–8 feet of grass separating the track from Armco barrier, and beyond the barriers is a wall of trees.
"Bergwerk" ("Mine").
Perhaps the most notorious corner on the long circuit, "Bergwerk" has been responsible for some serious and sometimes fatal accidents. A tight right-hand corner, coming just after a long, fast section and a left-hand kink on a small crest, was where Carel Godin de Beaufort fatally crashed. The fast kink was also the scene of Niki Lauda's infamous fiery accident during the 1976 German Grand Prix. This left kink is often referred to as the Lauda Links (Lauda left). The Bergwerk, along with the Breidscheid/Adenauer Bridge corners before it, are one of the series of corners that make or break one's lap time around the Nürburgring because of the fast, lengthy uphill section called "Kesselchen" (Little Valley) that comes after the Bergwerk.
Caracciola "Karussell" ("Carousel").
Although being one of the slower corners on the "Nordschleife", the "Karussell" is perhaps its most famous and one of its most iconic- it is one of two berm-style, banked corners on the track. Soon after the driver has negotiated the long uphill section after Bergwerk and gone through a section called "Klostertal" (Monastery Valley), the driver turns right through a long hairpin, past an abandoned section called "Steilstrecke" (Steep Route) and then goes up another hill towards the Karrusell. The entrance to the corner is blind, although Juan Manuel Fangio is reputed to have advised a young driver to "aim for the tallest tree," a feature that was also built into the rendering of the circuit in the Gran Turismo 4 and Grand Prix Legends video games. Once the driver has reached the top of the hill, the road then becomes sharply banked on one side and level on the other- this banking drops off, rather than climbing up like most bankings on circuits. The sharply banked side has a concrete surface, and there is a foot-wide tarmac surface on the bottom of the banking for cars to get extra grip through the very rough concrete banking. Cars drop into the concrete banking, and keep the car in the corner (which is 210 degrees, much like a hairpin bend) until the road levels out and the concrete surface becomes tarmac again. This corner is very hard on the driver's wrists and hands because of the prolonged bumpy cornering the driver must do while in the Karrusell. Usually cars come out of the top of the end of the banking to hit the apex that comes right after the end of the Karrusell.
The combination of a recognisable corner, slow-moving cars, and the variation in viewing angle as cars rotate around the banking, means that this is one of the circuit's most popular locations for photographers. It is named after German pre-WWII racing driver Rudolf Caracciola, who reportedly made the corner his own by hooking the inside tires into a drainage ditch to help his car "hug" the curve. As more concrete was uncovered and more competitors copied him, the trend took hold. At a later reconstruction, the corner was remade with real concrete banking, as it remains to this day.
Shortly after the Karussell is a steep section, with gradients in excess of 16%, leading to a right-hander called Hohe Acht, which is some 300 m higher in altitude than Breidscheid.
"Brünnchen" ("Small Fountain").
A favourite spectator vantage point, the Brünnchen section is composed of two right-hand corners and a very short straight. The first corner goes sharply downhill and the next, after the very short downhill straight, goes uphill slightly. This is a section of the track where on public days, accidents happen particularly at the blind uphill right-hand corner. Like almost every corner at the Nürburgring, both right-handers are blind. The short straight used to have a steep and sudden drop-off that caused cars to take off and a bridge that went over a pathway; these were taken out and smoothed over when the circuit was rebuilt in 1970 and 1971.
"Pflanzgarten" ("Planting Garden") and "Stefan Bellof S" ("Stefan Bellof Esses").
The Pflanzgarten, which is soon after the Brunnchen, is one of the fastest, trickiest and most difficult sections of the Nürburgring. It is full of jumps, including 2 huge ones, one of which is called "Sprunghugel" (Hill Jump). This very complex section is unique in that it is made up of two different sections; getting the entire Pflanzgarten right is crucial to a good lap time around the Nürburgring. This section was the scene of Briton Peter Collins's fatal accident during the German Grand Prix in 1958, and the scene of a number of career-ending accidents in Formula One in the 1970s —Britons Mike Hailwood and Ian Ashley were two victims of the Pflanzgarten.
Pflanzgarten 1 is made up of a slightly banked, downhill left hander which then suddenly switches back left, then right. Then immediately, giving the driver nearly no time to react (knowledge of this section is key) the road drops away twice: the first jump is only slight, then right after (somewhat like a staircase) the road drops away very sharply which usually causes almost all cars to go airborne at this jump; the drop is so sudden. Then, immediately after the road levels out very shortly after the jump and the car touches the ground again, the road immediately and suddenly goes right very quickly and then right again; this is what makes up the end of the first Pflanzgarten- a very fast multiple apex sequence of right hand corners.
The road then goes slightly uphill and then through another jump; the road suddenly drops away and levels out and at the same time, the road turns through a flat-out left hander. Then, the road drops away again very suddenly, which is the 2nd huge jump of the Pflanzgarten known as the Sprunghugel. The road then goes downhill then quickly levels out, then it goes through a flat-out right hander and this starts the Stefan Bellof S, which was known as Pflanzgarten 2 prior to 2013. The Stefan Bellof S is very tricky because the road quickly switches back left and right—a car is going so fast through here that it is like walking on a tightrope. It is very difficult to find the racing line here because the curves come up so quickly, so it is hard to find any point of reference. Then, after a jump at the end of the switchback section, it goes through a flat-out, top gear right hander and into a short straight that leads into two very fast curves called the Schwalbenschwanz (Swallow's Tail).
The room for error on every part of the consistently high-speed Pflanzgarten and Bellof Esses is virtually non-existent (much like the entire track itself)—this is why it is such a difficult part of the circuit. The road and the surface of the Pflanzgarten and Bellof moves around unpredictably; knowledge of this section is key to getting through cleanly.
"Schwalbenschwanz/Kleines Karussell" ("Swallow's Tail"/"Little Carousel").
The Schwalbenschwanz is a sequence of very fast sweepers located after the second Pflanzgarten. After a short straight, there is a very fast right hand sweeper that progressively goes uphill, and this leads into a blind left-hander that is a bit slower (but still rather fast). The apex is completely blind, and the corner then changes gradient a bit; it goes up then down, which leads into a short straight that ends at the Kleines Karussell. Originally, this part had a bridge that went over a stream and it was very bumpy; this bridge was taken out and replaced with a culvert (large industrial pipe) so that the road could be smoothed over.
The Kleines Karussell is similar to its bigger brother, except that it is a 90 degree corner instead of 210 degrees, and is faster and slightly less banked. Once this part of the track is dealt with, the drivers are near the end of the lap; with 2 more corners to negotiate before the 2.135 km long Döttinger Höhe straight.
Lap times.
Lap times recorded on the Nürburgring "Nordschleife" are published by several manufacturers. They are published and discussed in print media, and online.

</doc>
<doc id="22126" url="https://en.wikipedia.org/wiki?curid=22126" title="Northern Hemisphere">
Northern Hemisphere

The Northern Hemisphere of Earth is the half that is north of the equator. For other planets in the Solar System, north is defined as being in the same celestial hemisphere relative to the invariable plane of the solar system as Earth's North pole.
Due to the Earth's axial tilt, winter in the Northern Hemisphere lasts from the winter solstice (typically December 21 UTC) to the March Equinox (typically March 20 UTC), while summer lasts from the summer solstice (typically June 21 UTC) through to the autumnal equinox (typically September 23 UTC). The dates vary each year due to the difference between the calendar year and the astronomical year.
Geography and climate.
The Arctic is the region north of the Arctic Circle. Its climate is characterized by cold winters and cool summers. Precipitation mostly comes in the form of snow. The Arctic experiences some days in summer when the Sun never sets, and some days during the winter when it never rises. The duration of these phases varies from one day for locations right on the Arctic Circle to several months near the North Pole.
Between the Arctic Circle and the Tropic of Cancer lies the Northern Temperate Zone. The changes in these regions between summer and winter are generally mild, rather than extreme hot or cold. However, a temperate climate can have very unpredictable weather.
Tropical regions (between the Tropic of Cancer and the equator) are generally hot all year round and tend to experience a rainy season during the summer months, and a dry season during the winter months.
In the Northern Hemisphere, objects moving across or above the surface of the Earth tend to turn to the right because of the coriolis effect. As a result, large-scale horizontal flows of air or water tend to form clockwise-turning gyres. These are best seen in ocean circulation patterns in the North Atlantic and North Pacific oceans.
For the same reason, flows of air down toward the northern surface of the Earth tend to spread across the surface in a clockwise pattern. Thus, clockwise air circulation is characteristic of high pressure weather cells in the Northern Hemisphere. Conversely, air rising from the northern surface of the Earth (creating a region of low pressure) tends to draw air toward it in a counterclockwise pattern. Hurricanes and tropical storms (massive low-pressure systems) spin counter-clockwise in the Northern Hemisphere.
The shadow of a sundial moves clockwise in the Northern Hemisphere (opposite of the Southern Hemisphere). During the day, the Sun tends to rise to its maximum at a southerly position.
When viewed from the Northern Hemisphere, the Moon appears inverted compared to a view from the Southern Hemisphere. The North Pole faces away from the galactic center of the Milky Way. This results in the Milky Way being sparser and dimmer in the Northern Hemisphere compared to the Southern Hemisphere, making the Northern Hemisphere more suitable for deep-space observation, as it is not "blinded" by the Milky Way.
Demographics.
Approximately 6.57 billion people reside in the Northern Hemisphere which is around 88-90% of the earth's total population of 7.3 billion.

</doc>
<doc id="22130" url="https://en.wikipedia.org/wiki?curid=22130" title="Noun class">
Noun class

In linguistics, a noun class is a particular category of nouns. A noun may belong to a given class because of characteristic features of its referent, such as sex, animacy, shape, but counting a given noun among nouns of such or another class is often clearly conventional. Some authors use the term "grammatical gender" as a synonym of "noun class", but others use different definitions for each (see below). Noun classes should not be confused with noun classifiers.
Notion.
In general, there are three main ways by which natural languages categorize nouns into noun classes:
Usually, a combination of the three types of criteria is used, though one is more prevalent.
Noun classes form a system of grammatical agreement. The fact that a noun belongs to a given class may imply the presence of:
Modern English expresses noun classes through the third person singular personal pronouns "he" (male person), "she" (female person), and "it" (object, abstraction, or animal), and their other inflected forms. The choice between the relative pronoun "who" (persons) and "which" (non-persons) may also be considered a way of categorizing nouns into noun classes. A few nouns also exhibit vestigial noun classes, such as "stewardess", where the suffix "-ess" added to "steward" denotes a female person. This type of noun affixation is not very frequent in English, but quite common in languages which have the true grammatical gender, including most of the Indo-European family, to which English belongs. 
When noun class is expressed on other parts of speech, besides nouns and pronouns, the language is said to have grammatical gender.
In languages without inflectional noun classes, nouns may still be extensively categorized by independent particles called noun classifiers.
Common criteria for noun classes.
Common criteria that define noun classes include:
See Swahili for the semantic motivations for an elaborate noun-class system.
Language families.
Algonquian languages.
The Ojibwe language and other members of the Algonquian languages distinguish between animate and inanimate classes. Some sources argue that the distinction is between things which are powerful and things which are not. All living things, as well as sacred things and things connected to the Earth are considered powerful and belong to the animate class. Still, the assignment is somewhat arbitrary, as "raspberry" is animate, but "strawberry" is inanimate.
Athabaskan languages.
In Navajo (Southern Athabaskan) nouns are classified according to their animacy, shape, and consistency. Morphologically, however, the distinctions are not expressed on the nouns themselves, but on the verbs of which the nouns are the subject or direct object. For example, in the sentence ' "My shirt is lying on the bed", the verb "lies" is used because the subject ' "my shirt" is a flat, flexible object. In the sentence "My belt is lying on the bed", the verb ' "lies" is used because the subject ' "my belt" is a slender, flexible object. See Navajo language: Classificatory Verbs for more discussion.
Koyukon (Northern Athabaskan) has a more intricate system of classification. Like Navajo, it has classificatory verb stems that classify nouns according to animacy, shape, and consistency. However, in addition to these verb stems, Koyukon verbs have what are called "gender prefixes" that further classify nouns. That is, Koyukon has two different systems that classify nouns: (a) a classificatory verb system and (b) a gender system. To illustrate, the verb stem "-tonh" is used for enclosed objects. When "-tonh" is combined with different gender prefixes, it can result in "daaltonh" which refers to objects enclosed in boxes or "etltonh" which refers to objects enclosed in bags.
Australian Aboriginal languages.
The Dyirbal language is well known for its system of four noun classes, which tend to be divided along the following semantic lines:
The class usually labeled "feminine", for instance, includes the word for fire and nouns relating to fire, as well as all dangerous creatures and phenomena. (This inspired the title of the George Lakoff book "Women, Fire, and Dangerous Things".)
The Ngangikurrunggurr language has noun classes reserved for canines and hunting weapons. The Anindilyakwa language has a noun class for things that reflect light. The Diyari language distinguishes only between female and other objects. Perhaps the most noun classes in any Australian language are found in 
Yanyuwa, which has 16 noun classes, including nouns associated with food, trees and abstractions, in addition to separate classes for men and masculine things, women and feminine things. In the men's dialect, the classes for men and for masculine things have simplified to a single class, marked the same way as the women's dialect marker reserved exclusively for men.
Basque.
In Basque there are two classes, animate and inanimate; however, the only difference is in the declension of locative cases (inessive, locative genitive, allative, terminal allative, ablative and directional ablative). There are a few words with both masculine and feminine forms, generally words for relatives (cousin: lehengusu (m)/lehengusina (f)) or words borrowed from Latin ("king": "errege", from the Latin word "rex"; "queen": "erregina", from "regina"). In names for familiar relatives, where both genders are taken into account, either the words for each gender are put together ("son": "seme"; "daughter": "alaba"; "children"(meaning son(s) and daughter(s)): "seme-alaba(k)") or there is a noun that includes both: "father": "aita"; "mother": "ama"; "parent": "guraso".
Caucasian languages.
Some members of the Northwest Caucasian family, and almost all of the Northeast Caucasian languages, manifest noun class. In the Northeast Caucasian family, only Lezgian, Udi, and Aghul do not have noun classes. Some languages have only two classes, whereas Bats has eight. The most widespread system, however, has four classes: male, female, animate beings and certain objects, and finally a class for the remaining nouns. The Andi language has a noun class reserved for insects.
Among Northwest Caucasian languages, only Abkhaz and Abaza have noun class, making use of a human male/human female/non-human distinction.
In all Caucasian languages that manifest class, it is not marked on the noun itself but on the dependent verbs, adjectives, pronouns and prepositions.
Niger–Congo languages.
Niger–Congo languages can have ten or more noun classes, defined according to non-sexual criteria. Certain nominal classes are reserved for humans. The Fula language has about 26 noun classes (exact number varies slightly by dialect). According to Steven Pinker, the Kivunjo language has 16 noun classes including classes for precise locations and for general locales, classes for clusters or pairs of objects and classes for the objects that come in pairs or clusters, and classes for abstract qualities.
Bantu languages.
According to Carl Meinhof, the Bantu languages have a total of 22 noun classes called nominal classes (this notion was introduced by W. H. J. Bleek). While no single language is known to express all of them, most of them have at least 10 noun classes. For example, by Meinhof's numbering, Shona has 20 classes, Swahili has 15, Sotho has 18 and Ganda has 17.
Additionally, there are polyplural noun classes. A polyplural noun class is a plural class for more than one singular class. For example, Proto-Bantu class 10 contains plurals of class 9 nouns and class 11 nouns, while class 6 contains plurals of class 5 nouns and class 15 nouns. Classes 6 and 10 are inherited as polyplural classes by most surviving Bantu languages, but many languages have developed new polyplural classes that are not widely shared by other languages.
Specialists in Bantu emphasize that there is a clear difference between genders (such as known from Afro-Asiatic and Indo-European) and nominal classes (such as known from Niger–Congo). Languages with nominal classes divide nouns formally on the base of hyperonymic meanings. The category of nominal class replaces not only the category of gender, but also the categories of number and case.
Critics of the Meinhof's approach notice that his numbering system of nominal classes counts singular and plural numbers of the same noun as belonging to separate classes. This seems to them to be inconsistent with the way other languages are traditionally considered, where number is orthogonal to gender (according to the critics, a Meinhof-style analysis would give Ancient Greek 9 genders). If one follows broader linguistic tradition and counts singular and plural as belonging to the same class, then Swahili has 8 or 9 noun classes, Sotho has 11 and Ganda has 10.
The Meinhof numbering tends to be used in scientific works dealing with comparisons of different Bantu languages. For instance, in Swahili the word "rafiki" ‘friend’ belongs to the class 9 and its "plural form" is "marafiki" of the class 6, even if most nouns of the 9 class have the plural of the class 10. For this reason, noun classes are often referred to by combining their singular and plural forms, e.g., "rafiki" would be classified as "9/6", indicating that it takes class 9 in the singular, and class 6 in the plural.
However not all Bantu languages have these exceptions. In Ganda each singular class has a corresponding plural class (apart from one class which has no singular–plural distinction; also some plural classes correspond to more than one singular class) and there are no exceptions as there are in Swahili. For this reason Ganda linguists use the orthogonal numbering system when discussing Ganda grammar (other than in the context of Bantu comparative linguistics), giving the 10 traditional noun classes of that language.
The distinction between genders and nominal classes is blurred still further by Indo-European languages that have nouns that behave like Swahili's "rafiki". Italian, for example, has a group of nouns deriving from Latin neuter nouns that acts as masculine in the singular but feminine in the plural: "il braccio"/"le braccia"; "l'uovo"/"le uova". (These nouns are still placed in a neuter gender of their own by some grammarians.)
Here is a complete list of nominal classes in Swahili:
"Ø-" means no prefix. Note also that some classes are homonymous (esp. 9 and 10). The Proto-Bantu class 12 disappeared in Swahili, class 13 merged with 7, and 14 with 11.
Class prefixes appear also on adjectives and verbs, e.g.:
The class markers which appear on the adjectives and verbs may differ from the noun prefixes: 
In this example, the verbal prefix a- and the pronominal prefix wa- are in concordance with the noun prefix m-: they all express class 1 despite of their different forms.
Zande.
The Zande language distinguishes four noun classes:
There are about 80 inanimate nouns which are in the animate class, including nouns denoting heavenly objects (moon, rainbow), metal objects (hammer, ring), edible plants (sweet potato, pea), and non-metallic objects (whistle, ball). Many of the exceptions have a round shape, and some can be explained by the role they play in Zande mythology.
Noun classes versus grammatical gender.
The term gender, as used by some linguists, refers to a noun-class system composed with 2, 3, or 4 classes, particularly if the classification is semantically based on a distinction between masculine and feminine. Genders are then considered a sub-class of noun classes. Not all linguists recognize a distinction between noun-classes and genders, however, and instead use either the term "gender" or "noun class" for both.
Noun classes versus noun classifiers.
Some languages, such as Japanese, Chinese and the Tai languages, have elaborate systems of particles that nouns based on shape and function, but are free morphemes rather than affixes. Because the classes defined by these classifying words are not generally distinguished in other contexts, there are many linguists who take the view that they do not create noun classes.

</doc>
<doc id="22131" url="https://en.wikipedia.org/wiki?curid=22131" title="Natural gas">
Natural gas

Natural gas is a naturally occurring hydrocarbon gas mixture consisting primarily of methane, but commonly including varying amounts of other higher alkanes, and sometimes a small percentage of carbon dioxide, nitrogen, hydrogen sulfide, or helium. It is formed when layers of decomposing plant and animal matter are exposed to intense heat and pressure supplied by existing under the surface of the Earth over millions of years. The energy that the plants originally obtained from the sun is stored in the form of chemical bonds in the gas.
Natural gas is a fossil fuel used as a source of energy for heating, cooking, and electricity generation. It is also used as fuel for vehicles and as a chemical feedstock in the manufacture of plastics and other commercially important organic chemicals. It is a non-renewable resource.
Natural gas is found in deep underground rock formations or associated with other hydrocarbon reservoirs in coal beds and as methane clathrates. Petroleum is another resource and fossil fuel found in close proximity to, and with natural gas. Most natural gas was created over time by two mechanisms: biogenic and thermogenic. Biogenic gas is created by methanogenic organisms in marshes, bogs, landfills, and shallow sediments. Deeper in the earth, at greater temperature and pressure, thermogenic gas is created from buried organic material.
When gas is associated with petroleum production it may be considered a byproduct and be burnt as flare gas. The World Bank estimates that over 150 billion cubic meters of natural gas are flared or vented annually. Before natural gas can be used as a fuel, it must be processed to remove impurities, including water, to meet the specifications of marketable natural gas. The by-products of this processing include: ethane, propane, butanes, pentanes, and higher molecular weight hydrocarbons, hydrogen sulfide (which may be converted into pure sulfur), carbon dioxide, water vapor, and sometimes helium and nitrogen.
Natural gas is often informally referred to simply as "gas", especially when compared to other energy sources such as oil or coal. However, it is not to be confused with gasoline, especially in North America, where the term gasoline is often shortened in colloquial usage to "gas".
Natural gas was used by the Chinese in about 500 BC (possibly even 1000 BC). They discovered a way to transport gas seeping from the ground in crude pipelines of bamboo to where it was used to boil salt water to extract the salt, in the Ziliujing District of Sichuan. The world's first industrial extraction of natural gas started at Fredonia, New York, USA in 1825. By 2009, 66 trillion cubic meters (or 8%) had been used out of the total 850 trillion cubic meters of estimated remaining recoverable reserves of natural gas. Based on an estimated 2015 world consumption rate of about 3.4 trillion cubic meters of gas per year, the total estimated remaining economically recoverable reserves of natural gas would last 250 years at current consumption rates. An annual increase in usage of 2–3% could result in currently recoverable reserves lasting significantly less, perhaps as few as 80 to 100 years.
Sources.
Natural gas.
In the 19th century, natural gas was usually obtained as a by-product of producing oil, since the small, light gas carbon chains came out of solution as the extracted fluids underwent pressure reduction from the reservoir to the surface, similar to uncapping a soft drink bottle where the carbon dioxide effervesces. Unwanted natural gas was a disposal problem in the active oil fields. If there was not a market for natural gas near the wellhead it was prohibitively expensive to pipe to the end user.
In the 19th century and early 20th century, unwanted gas was usually burned off at oil fields. Today, unwanted gas (or stranded gas without a market) associated with oil extraction often is returned to the reservoir with 'injection' wells while awaiting a possible future market or to repressurize the formation, which can enhance extraction rates from other wells. In regions with a high natural gas demand (such as the US), pipelines are constructed when it is economically feasible to transport gas from a wellsite to an end consumer.
In addition to transporting gas via pipelines for use in power generation, other end uses for natural gas include export as liquefied natural gas (LNG) or conversion of natural gas into other liquid products via gas-to-liquids (GTL) technologies. GTL technologies can convert natural gas into liquids products such as gasoline, diesel or jet fuel. A variety of GTL technologies have been developed, including Fischer–Tropsch (F–T), methanol to gasoline (MTG) and STG+. F–T produces a synthetic crude that can be further refined into finished products, while MTG can produce synthetic gasoline from natural gas. STG+ can produce drop-in gasoline, diesel, jet fuel and aromatic chemicals directly from natural gas via a single-loop process. In 2011, Royal Dutch Shell’s 140,000 barrel per day F–T plant went into operation in Qatar.
Natural gas can be "associated" (found in oil fields), or "non-associated" (isolated in natural gas fields), and is also found in coal beds (as coalbed methane). It sometimes contains a significant amount of ethane, propane, butane, and pentane—heavier hydrocarbons removed for commercial use prior to the methane being sold as a consumer fuel or chemical plant feedstock. Non-hydrocarbons such as carbon dioxide, nitrogen, helium (rarely), and hydrogen sulfide must also be removed before the natural gas can be transported.
Natural gas extracted from oil wells is called casinghead gas (whether or not truly produced up the annulus and through a casinghead outlet) or associated gas. The natural gas industry is extracting an increasing quantity of gas from challenging resource types: sour gas, tight gas, shale gas, and coalbed methane.
There is some disagreement on which country has the largest proven gas reserves. Sources that consider that Russia has by far the largest proven reserves include the US CIA (47.6 trillion cubic meters), the US Energy Information Administration (47.8 tcm), and OPEC (48.7 tcm). However, BP credits Russia with only 32.9 tcm, which would place it in second place, slightly behind Iran (33.1 to 33.8 tcm, depending on the source). With Gazprom, Russia is frequently the world's largest natural gas extractor. Major proven resources (in billion cubic meters) are world 187,300 (2013), Iran 33,600 (2013), Russia 32,900 (2013), Qatar 25,100 (2013), Turkmenistan 17,500 (2013) and the United States 8,500 (2013).
It is estimated that there are about 900 trillion cubic meters of "unconventional" gas such as shale gas, of which 180 trillion may be recoverable. In turn, many studies from MIT, Black & Veatch and the DOE predict that natural gas will account for a larger portion of electricity generation and heat in the future.
The world's largest gas field is the offshore South Pars / North Dome Gas-Condensate field, shared between Iran and Qatar. It is estimated to have 51 trillion cubic meters of natural gas and 50 billion barrels of natural gas condensates.
Because natural gas is not a pure product, as the reservoir pressure drops when non-associated gas is extracted from a field under supercritical (pressure/temperature) conditions, the higher molecular weight components may partially condense upon isothermic depressurizing—an effect called retrograde condensation. The liquid thus formed may get trapped as the pores of the gas reservoir get depleted. One method to deal with this problem is to re-inject dried gas free of condensate to maintain the underground pressure and to allow re-evaporation and extraction of condensates. More frequently, the liquid condenses at the surface, and one of the tasks of the gas plant is to collect this condensate. The resulting liquid is called natural gas liquid (NGL) and has commercial value.
Shale gas.
Shale gas is natural gas produced from shale. Because shale has matrix permeability too low to allow gas to flow in economical quantities, shale gas wells depend on fractures to allow the gas to flow. Early shale gas wells depended on natural fractures through which gas flowed; almost all shale gas wells today require fractures artificially created by hydraulic fracturing. Since 2000, shale gas has become a major source of natural gas in the United States and Canada. Following the success in the United States, shale gas exploration is beginning in countries such as Poland, China, and South Africa. Because of this increase in shale production, the United States is now the number one natural gas producer in the world
Town gas.
Town gas is a flammable gaseous fuel made by the destructive distillation of coal. It contains a variety of calorific gases including hydrogen, carbon monoxide, methane, and other volatile hydrocarbons, together with small quantities of non-calorific gases such as carbon dioxide and nitrogen, and is used in a similar way to natural gas. This is a historical technology and is not usually economically competitive with other sources of fuel gas today. Still, it remains the best option in some specific cases and it may be so into the future.
Most town "gashouses" located in the eastern US in the late 19th and early 20th centuries were simple by-product coke ovens that heated bituminous coal in air-tight chambers. The gas driven off from the coal was collected and distributed through networks of pipes to residences and other buildings where it was used for cooking and lighting. (Gas heating did not come into widespread use until the last half of the 20th century.) The coal tar (or asphalt) that collected in the bottoms of the gashouse ovens was often used for roofing and other waterproofing purposes, and when mixed with sand and gravel was used for paving streets.
Biogas.
Methanogenic archaea are responsible for all biological sources of methane. Some live in symbiotic relationships with other life forms, including termites, ruminants, and cultivated crops. Other sources of methane, the principal component of natural gas, include landfill gas, biogas, and methane hydrate. When methane-rich gases are produced by the anaerobic decay of non-fossil organic matter (biomass), these are referred to as biogas (or natural biogas). Sources of biogas include swamps, marshes, and landfills (see landfill gas), as well as agricultural waste materials such as sewage sludge and manure by way of anaerobic digesters, in addition to enteric fermentation, particularly in cattle. Landfill gas is created by decomposition of waste in landfill sites. Excluding water vapor, about half of landfill gas is methane and most of the rest is carbon dioxide, with small amounts of nitrogen, oxygen, and hydrogen, and variable trace amounts of hydrogen sulfide and siloxanes. If the gas is not removed, the pressure may get so high that it works its way to the surface, causing damage to the landfill structure, unpleasant odor, vegetation die-off, and an explosion hazard. The gas can be vented to the atmosphere, flared or burned to produce electricity or heat. Biogas can also be produced by separating organic materials from waste that otherwise goes to landfills. This method is more efficient than just capturing the landfill gas it produces. Anaerobic lagoons produce biogas from manure, while biogas reactors can be used for manure or plant parts. Like landfill gas, biogas is mostly methane and carbon dioxide, with small amounts of nitrogen, oxygen and hydrogen. However, with the exception of pesticides, there are usually lower levels of contaminants.
Landfill gas cannot be distributed through utility natural gas pipelines unless it is cleaned up to less than 3 per cent , and a few parts per million , because and corrode the pipelines. The presence of will lower the energy level of the gas below requirements for the pipeline. Siloxanes in the gas will form deposits in gas burners and need to be removed prior to entry into any gas distribution or transmission system. Consequently, it may be more economical to burn the gas on site or within a short distance of the landfill using a dedicated pipeline. Water vapor is often removed, even if the gas is burned on site. If low temperatures condense water out of the gas, siloxanes can be lowered as well because they tend to condense out with the water vapor. Other non-methane components may also be removed to meet emission standards, to prevent fouling of the equipment or for environmental considerations. Co-firing landfill gas with natural gas improves combustion, which lowers emissions.
Biogas, and especially landfill gas, are already used in some areas, but their use could be greatly expanded. Experimental systems were being proposed for use in parts of Hertfordshire, UK, and Lyon in France. Using materials that would otherwise generate no income, or even cost money to get rid of, improves the profitability and energy balance of biogas production. Gas generated in sewage treatment plants is commonly used to generate electricity. For example, the Hyperion sewage plant in Los Angeles burns of gas per day to generate power New York City utilizes gas to run equipment in the sewage plants, to generate electricity, and in boilers. Using sewage gas to make electricity is not limited to large cities. The city of Bakersfield, California, uses cogeneration at its sewer plants. California has 242 sewage wastewater treatment plants, 74 of which have installed anaerobic digesters. The total biopower generation from the 74 plants is about 66 MW.
Crystallized natural gas — hydrates.
Huge quantities of natural gas (primarily methane) exist in the form of hydrates under sediment on offshore continental shelves and on land in arctic regions that experience permafrost, such as those in Siberia. Hydrates require a combination of high pressure and low temperature to form.
In 2010, the cost of extracting natural gas from crystallized natural gas was estimated to 100–200 per cent the cost of extracting natural gas from conventional sources, and even higher from offshore deposits.
In 2013, Japan Oil, Gas and Metals National Corporation (JOGMEC) announced that they had recovered commercially relevant quantities of natural gas from methane hydrate.
Natural gas processing.
The image below is a schematic block flow diagram of a typical natural gas processing plant. It shows the various unit processes used to convert raw natural gas into sales gas pipelined to the end user markets.
The block flow diagram also shows how processing of the raw natural gas yields byproduct sulfur, byproduct ethane, and natural gas liquids (NGL) propane, butanes and natural gasoline (denoted as pentanes +).
Depletion.
Natural gas production in the U.S. reached a peak in 1973, and went over a second lower peak in 2001, but recently has peaked again and is continuing to rise.
Uses.
Natural gas is primarily used in the northern hemisphere. North America and Europe are major consumers.
Mid-stream natural gas.
Natural gas flowing in the distribution lines and at the natural gas well head are often used to power natural gas powered engines. These engines rotate compressors to facilitate the natural gas transmission. These compressors are required in the mid-stream line to pressurize and to re-pressurize the natural gas in the transmission line as the gas travels. The natural gas transmission lines extend to the natural gas processing plant or unit which removes the higher molecular weighted natural gas hydrocarbons to produce a British thermal unit (BTU) value between 950 and 1050 BTUs. The processed natural gas may then be used for residential, commercial and industrial uses.
Often mid-stream and well head gases require removal of many of the various hydrocarbon species contained within the natural gas. Some of these gases include heptane, pentane, propane and other hydrocarbons with molecular weights above Methane (CH4) to produce a natural gas fuel which is used to operate the natural gas engines for further pressurized transmission. Typically, natural gas compressors require 950 to 1050 BTU per cubic foot to operate at the natural gas engines rotational name plate specifications.
Several methods are used to remove these higher molecular weighted gases for use at the natural gas engine. A few technologies are as follows:
Power generation.
Natural gas is a major source of electricity generation through the use of cogeneration, gas turbines and steam turbines. Natural gas is also well suited for a combined use in association with renewable energy sources such as wind or solar and for alimenting peak-load power stations functioning in tandem with hydroelectric plants. Most grid peaking power plants and some off-grid engine-generators use natural gas. Particularly high efficiencies can be achieved through combining gas turbines with a steam turbine in combined cycle mode. Natural gas burns more cleanly than other hydrocarbon fuels, such as oil and coal, and produces less carbon dioxide per unit of energy released. For transportation, burning natural gas produces about 30 per cent less carbon dioxide than burning petroleum. For an equivalent amount of heat, burning natural gas produces about 45 per cent less carbon dioxide than burning coal for power. The US Energy Information Administration reports the following emissions in million metric tons of carbon dioxide in the world for 2012:
Coal-fired electric power generation emits around 2,000 pounds of carbon dioxide for every megawatt hour generated, which is almost double the carbon dioxide released by a natural gas-fired electric plant per megawatt hour generated. Because of this higher carbon efficiency of natural gas generation, as the fuel mix in the United States has changed to reduce coal and increase natural gas generation, carbon dioxide emissions have unexpectedly fallen. Those measured in the first quarter of 2012 were the lowest of any recorded for the first quarter of any year since 1992.
Combined cycle power generation using natural gas is currently the cleanest available source of power using hydrocarbon fuels, and this technology is widely and increasingly used as natural gas can be obtained at increasingly reasonable costs. Fuel cell technology may eventually provide cleaner options for converting natural gas into electricity, but as yet it is not price-competitive. Locally produced electricity and heat using natural gas powered Combined Heat and Power plant (CHP or Cogeneration plant) is considered energy efficient and a rapid way to cut carbon emissions. Natural gas power plants are increasing in popularity and generate 22% of the worlds total electricity. Approximately half as much as generated with coal.
Domestic use.
Natural gas dispensed in a residential setting can generate temperatures in excess of 1100 °C (2000 °F) making it a powerful domestic cooking and heating fuel. In much of the developed world it is supplied through pipes to homes, where it is used for many purposes including ranges and ovens, gas-heated clothes dryers, heating/cooling, and central heating. Heaters in homes and other buildings may include boilers, furnaces, and water heaters. Both North America and Europe are major consumers of natural gas. Boilers use low pressure, usually 6 to 7 inches of water (6" to 7" WC), which is about 0.25 psig. The pressures in the supply lines under the streets vary, either utilization pressure (UP, the aforementioned 6" to 7" WC) or elevated pressure (EP), which may be anywhere from 1 psig to 120 psig. Systems using EP have a regulator at the service entrance to step down the pressure to UP. 
In the US Compressed natural gas (CNG) is used in rural homes without connections to piped-in public utility services, or with portable grills. Natural gas is also supplied by independent natural gas suppliers through Natural Gas Choice programs throughout the United States. However, as CNG costs more than LPG, LPG (propane) is the dominant source of rural gas.
Transportation.
CNG is a cleaner and also cheaper alternative to other automobile fuels such as gasoline (petrol) and diesel. By the end of 2012 there were 17.25 million natural gas vehicles worldwide, led by Iran (3.3 million), Pakistan (3.1 million), Argentina (2.18 million), Brazil (1.73 million), India (1.5 million), and China (1.5 million). The energy efficiency is generally equal to that of gasoline engines, but lower compared with modern diesel engines. Gasoline/petrol vehicles converted to run on natural gas suffer because of the low compression ratio of their engines, resulting in a cropping of delivered power while running on natural gas (10%–15%). CNG-specific engines, however, use a higher compression ratio due to this fuel's higher octane number of 120–130.
Fertilizers.
Natural gas is a major feedstock for the production of ammonia, via the Haber process, for use in fertilizer production.
Aviation.
Russian aircraft manufacturer Tupolev is currently running a development program to produce LNG- and hydrogen-powered aircraft. The program has been running since the mid-1970s, and seeks to develop LNG and hydrogen variants of the Tu-204 and Tu-334 passenger aircraft, and also the Tu-330 cargo aircraft. It claims that at current market prices, an LNG-powered aircraft would cost 5,000 roubles (~ US$218/ £112) less to operate per ton, roughly equivalent to 60 per cent, with considerable reductions to carbon monoxide, hydrocarbon and nitrogen oxide emissions.
The advantages of liquid methane as a jet engine fuel are that it has more specific energy than the standard kerosene mixes do and that its low temperature can help cool the air which the engine compresses for greater volumetric efficiency, in effect replacing an intercooler. Alternatively, it can be used to lower the temperature of the exhaust.
Hydrogen.
Natural gas can be used to produce hydrogen, with one common method being the hydrogen reformer. Hydrogen has many applications: it is a primary feedstock for the chemical industry, a hydrogenating agent, an important commodity for oil refineries, and the fuel source in hydrogen vehicles.
Other.
Natural gas is also used in the manufacture of fabrics, glass, steel, plastics, paint, and other products.
Storage and transport.
Because of its low density, it is not easy to store natural gas or to transport it by vehicle. Natural gas pipelines are impractical across oceans. Many existing pipelines in America are close to reaching their capacity, prompting some politicians representing northern states to speak of potential shortages. In Western Europe, the gas pipeline network is already dense. New pipelines are planned or under construction in Eastern Europe and between gas fields in Russia, Near East and Northern Africa and Western Europe. See also List of natural gas pipelines.
LNG carriers transport liquefied natural gas (LNG) across oceans, while tank trucks can carry liquefied or compressed natural gas (CNG) over shorter distances. Sea transport using CNG carrier ships that are now under development may be competitive with LNG transport in specific conditions.
Gas is turned into liquid at a liquefaction plant, and is returned to gas form at regasification plant at the terminal. Shipborne regasification equipment is also used. LNG is the preferred form for long distance, high volume transportation of natural gas, whereas pipeline is preferred for transport for distances up to over land and approximately half that distance offshore.
CNG is transported at high pressure, typically above 200 bars. Compressors and decompression equipment are less capital intensive and may be economical in smaller unit sizes than liquefaction/regasification plants. Natural gas trucks and carriers may transport natural gas directly to end-users, or to distribution points such as pipelines.
In the past, the natural gas which was recovered in the course of recovering petroleum could not be profitably sold, and was simply burned at the oil field in a process known as flaring. Flaring is now illegal in many countries. Additionally, higher demand in the last 20–30 years has made production of gas associated with oil economically viable. As a further option, the gas is now sometimes re- into the formation for enhanced oil recovery by pressure maintenance as well as miscible or immiscible flooding. Conservation, re-injection, or flaring of natural gas associated with oil is primarily dependent on proximity to markets (pipelines), and regulatory restrictions.
A "master gas system" was invented in Saudi Arabia in the late 1970s, ending any necessity for flaring. Satellite observation, however, shows that flaring and venting are still practiced in some gas-extracting countries.
Natural gas is used to generate electricity and heat for desalination. Similarly, some landfills that also discharge methane gases have been set up to capture the methane and generate electricity.
Natural gas is often stored underground inside depleted gas reservoirs from previous gas wells, salt domes, or in tanks as liquefied natural gas. The gas is injected in a time of low demand and extracted when demand picks up. Storage nearby end users helps to meet volatile demands, but such storage may not always be practicable.
With 15 countries accounting for 84 per cent of the worldwide extraction, access to natural gas has become an important issue in international politics, and countries vie for control of pipelines. In the first decade of the 21st century, Gazprom, the state-owned energy company in Russia, engaged in disputes with Ukraine and Belarus over the price of natural gas, which have created concerns that gas deliveries to parts of Europe could be cut off for political reasons. The United States is preparing to export natural gas.
Floating Liquefied Natural Gas (FLNG) is an innovative technology designed to enable the development of offshore gas resources that would otherwise remain untapped because due to environmental or economic factors it is nonviable to develop them via a land-based LNG operation. FLNG technology also provides a number of environmental and economic advantages:
Many gas and oil companies are considering the economic and environmental benefits of Floating Liquefied Natural Gas (FLNG). There are currently projects underway to construct five FLNG facilities. Petronas is close to completion on their FLNG-1 at Daewoo Shipbuilding and Marine Engineering and are underway on their FLNG-2 project at Samsung Heavy Industries. Shell Prelude is due to start production 2017 and the Browse LNG project has completed FEED with final investment decisions expected in mid-2016.
Environmental effects.
Effect of natural gas release.
Natural gas is mainly composed of methane. After release to the atmosphere it is removed by gradual oxidation to carbon dioxide and water by hydroxyl radicals (·OH) formed in the troposphere or stratosphere, giving the overall chemical reaction CH4 + 2O2→ CO2 + 2H2O. While the lifetime of atmospheric methane is relatively short when compared to carbon dioxide, with a half-life of about 7 years, it is more efficient at trapping heat in the atmosphere, so that a given quantity of methane has 84 times the global-warming potential of carbon dioxide over a 20-year period and 28 times over a 100-year period. Natural gas is thus a more potent greenhouse gas than carbon dioxide due to the greater global-warming potential of methane. But because when it is burned, it produces more water than carbon dioxide by mole, in contrast to coal which produces mainly carbon dioxide, it produces only about half the carbon dioxide per kilowatt-hour that coal does. Current estimates by the EPA place global emissions of methane at annually, or 3.2 per cent of global production. Direct emissions of methane represented 14.3 per cent by volume of all global anthropogenic greenhouse gas emissions in 2004.
During extraction, storage, transportation, and distribution, natural gas is known to leak into the atmosphere, particularly during the extraction process. A Cornell University study in 2011 demonstrated that the leak rate of methane may be high enough to jeopardize its global warming advantage over coal. This study was criticized later for its over-estimation of methane leakage values. Preliminary results of some air sampling from airplanes done by the National Oceanic and Atmospheric Administration indicated higher-than-estimated methane releases by gas wells in some areas, but the overall results showed methane emissions in line with previous EPA estimates
Natural gas extraction also releases an isotope of radon, ranging in activity from 5 to 200,000 becquerels per cubic meter of gas.
CO2 emissions.
Natural gas is often described as the cleanest fossil fuel. It produces about 29% and 44% less carbon dioxide per joule delivered than oil and coal respectively, and potentially fewer pollutants than other hydrocarbon fuels. However, in absolute terms, it comprises a substantial percentage of human carbon emissions, and this contribution is projected to grow. According to the IPCC Fourth Assessment Report, in 2004, natural gas produced about 5.3 billion tons a year of CO2 emissions, while coal and oil produced 10.6 and 10.2 billion tons respectively. According to an updated version of the Special Report on Emissions Scenario by 2030, natural gas would be the source of 11 billion tons a year, with coal and oil now 8.4 and 17.2 billion respectively because demand is increasing 1.9 percent a year.
Other pollutants.
Natural gas produces far lower amounts of sulfur dioxide and nitrous oxides than other fossil fuels.
The other pollutants due to natural gas combustion are listed below in pounds per billion BTU:
Safety concerns.
Production.
Some gas fields yield sour gas containing hydrogen sulfide (H2S). This untreated gas is toxic. Amine gas treating, an industrial scale process which removes acidic gaseous components, is often used to remove hydrogen sulfide from natural gas.
Extraction of natural gas (or oil) leads to decrease in pressure in the reservoir. Such decrease in pressure in turn may result in subsidence, sinking of the ground above. Subsidence may affect ecosystems, waterways, sewer and water supply systems, foundations, and so on.
Fracking.
Releasing natural gas from subsurface porous rock formations may be accomplished by a process called hydraulic fracturing or "fracking". It's estimated that hydraulic fracturing will eventually account for nearly 70% of natural gas development in North America. Since the first commercial hydraulic fracturing operation in 1949, approximately one million wells have been hydraulically fractured in the United States. The production of natural gas from hydraulically fractured wells has utilized the technological developments of directional and horizontal drilling, which improved access to natural gas in tight rock formations. Strong growth in the production of unconventional gas from hydraulically fractured wells occurred between 2000-2012.
In hydraulic fracturing, well operators force water mixed with a variety of chemicals through the wellbore casing into the rock. The high pressure water breaks up or "fracks" the rock, which releases gas from the rock formation. Sand and other particles are added to the water as a proppant to keep the fractures in the rock open, thus enabling the gas to flow into the casing and then to the surface. Chemicals are added to the fluid to perform such functions as reducing friction and inhibiting corrosion. After the "frack," oil or gas is extracted and nearly 30 percent to 70 percent of the frack fluid, i.e. the mixture of water, chemicals, sand, etc., flows back to the surface. Many gas-bearing formations also contain water, which will flow up the wellbore to the surface along with the gas, in both hydraulically fractured and non-hydraulically fractured wells. This produced water often has a high content of salt and other dissolved minerals that occur in the formation.
The volume of water used to hydraulically fracture wells varies according to the hydraulic fracturing technique. In the United States, the average volume of water used per hydraulic fracture has been reported as nearly 7,375 gallons for vertical oil and gas wells prior to 1953, nearly 197,000 gallons for vertical oil and gas wells between 2000-2010, and nearly 3 million gallons for horizontal gas wells between 2000-2010.
Determining which fracking technique is appropriate for well productivity depends largely on the properties of the reservoir rock from which to extract oil or gas. If the rock is characterized by low-permeability — which refers to its ability to let substances, i.e. gas, pass through it, then the rock may be considered a source of tight gas. Fracking for shale gas, which is currently also known as a source of unconventional gas, involves drilling a borehole vertically until it reaches a lateral shale rock formation, at which point the drill turns to follow the rock for hundreds or thousands of feet horizontally. In contrast, conventional oil and gas sources are characterized by higher rock permeability, which naturally enables the flow of oil or gas into the wellbore with less intensive hydraulic fracturing techniques than the production of tight gas has required. The decades in development of drilling technology for conventional and unconventional oil & gas production has not only improved access to natural gas in low-permeability reservoir rocks, but also posed significant adverse impacts on environmental and public health.
The U.S. EPA has acknowledged that toxic, carcinogenic chemicals, i.e. benzene and ethylbenzene, have been used as gelling agents in water and chemical mixtures for high volume horizontal fracturing (HVHF). Following the hydraulic fracture in HVHF, the water, chemicals, and frack fluid that return to the well's surface, called flowback or produced water, may contain radioactive materials, heavy metals, natural salts, and hydrocarbons which exist naturally in shale rock formations. Fracking chemicals, radioactive materials, heavy metals, and salts that are removed from the HVHF well by well operators are so difficult to remove from the water they're mixed with, and would so heavily pollute the water cycle, that most of the flowback is either recycled into other fracking operations or injected into deep underground wells, eliminating the water that HVHF required from the hydrologic cycle.
Use.
In order to assist in detecting leaks, a minute amount of odorant is added to the otherwise colorless and almost odorless gas used by consumers. The odor has been compared to the smell of rotten eggs, due to the added tert-Butylthiol (t-butyl mercaptan). Sometimes a related compound, thiophane, may be used in the mixture. Situations in which an odorant that is added to natural gas can be detected by analytical instrumentation, but cannot be properly detected by an observer with a normal sense of smell, have occurred in the natural gas industry. This is caused by odor masking, when one odorant overpowers the sensation of another. As of 2011, the industry is conducting research on the causes of odor masking.
Explosions caused by natural gas leaks occur a few times each year. Individual homes, small businesses and other structures are most frequently affected when an internal leak builds up gas inside the structure. Frequently, the blast is powerful enough to significantly damage a building but leave it standing. In these cases, the people inside tend to have minor to moderate injuries. Occasionally, the gas can collect in high enough quantities to cause a deadly explosion, disintegrating one or more buildings in the process. The gas usually dissipates readily outdoors, but can sometimes collect in dangerous quantities if flow rates are high enough. However, considering the tens of millions of structures that use the fuel, the individual risk of using natural gas is very low.
Natural gas heating systems are a source of carbon monoxide deaths. In 2011, unvented or poorly vented furnaces, space heaters, water heaters and stoves operating on natural gas were blamed in 11 carbon monoxide deaths in the US. Another 22 deaths were attributed to appliances running on liquified petroleum gas, and 17 deaths on gas of unspecified type. Improvements in natural gas furnace designs have greatly reduced CO poisoning concerns. Detectors are also available that warn of carbon monoxide and/or explosive gas (methane, propane, etc.).
Energy content, statistics, and pricing.
Quantities of natural gas are measured in normal cubic meters (corresponding to 0 °C at 101.325 kPa) or in standard cubic feet (corresponding to and 14.73 psia). The gross heat of combustion of 1 m3 of commercial quality natural gas is around 39 MJ (≈10.8 kWh), but this can vary by several percent. This comes to about 49 MJ (≈13.5 kWh) for 1 kg of natural gas (assuming a density of 0.8 kg m−3, an approximate value).
The price of natural gas varies greatly depending on location and type of consumer. In 2007, a price of $7 per 1000 cubic feet (about 25 cents per m3) was typical in the United States. The typical caloric value of natural gas is roughly 1,000 British thermal units (BTU) per cubic foot, depending on gas composition. This corresponds to around $7 per million BTU, or around $7 per gigajoule. In April 2008, the wholesale price was $10 per ($10/MMBTU). The residential price varies from 50% to 300% more than the wholesale price. At the end of 2007, this was $12–$16 per 1000 cubic feet (about 50 cents per m3). Natural gas in the United States is traded as a futures contract on the New York Mercantile Exchange. Each contract is for 10,000 MMBTU (~10,550 gigajoules), or 10 billion BTU. Thus, if the price of gas is $10 per million BTUs on the NYMEX, the contract is worth $100,000.
European Union.
Gas prices for end users vary greatly across the EU. A single European energy market, one of the key objectives of the European Union, should level the prices of gas in all EU member states. Moreover, it would help to resolve supply and global warming issues, as well as strengthen relations with other Mediterranean countries and foster investments in the region.
United States.
In US units, one standard cubic foot of natural gas produces around . The actual heating value when the water formed does not condense is the net heat of combustion and can be as much as 10% less.
In the United States, retail sales are often in units of therms (th); 1 therm = 100,000 BTU. Gas meters measure the volume of gas used, and this is converted to therms by multiplying the volume by the energy content of the gas used during that period, which varies slightly over time. Wholesale transactions are generally done in decatherms (Dth), or in thousand decatherms (MDth), or in million decatherms (MMDth). A million decatherms is roughly a billion cubic feet of natural gas. Gas sales to domestic consumers may be in units of 100 standard cubic feet (scf). The typical annual consumption of a single family residence is 1,000 therms or one RCE.
Canada.
Canada uses metric measure for internal trade of petrochemical products. Consequently, natural gas is sold by the Gigajoule, cubic metre (m3) or thousand cubic metres (E3m3). Distribution infrastructure and meters almost always meter volume (cubic foot or cubic meter). Some jurisdictions, such as Saskatchewan, sell gas by volume only. Other jurisdictions, such as Alberta, gas is sold by the energy content (GJ). In these areas, almost all meters for residential and small commercial customers measure volume (m3 or ft3), and billing statements include a multiplier to convert the volume to energy content of the local gas supply.
A gigajoule (GJ) is a measure approximately equal to half a barrel (250 lbs) of oil, or 1 million BTUs, or 1000 cu ft of gas, or 28 m3 of gas. The energy content of gas supply in Canada can vary from 37 to 43 MJ per m3 depending on gas supply and processing between the wellhead and the customer.
Elsewhere.
In the rest of the world, natural gas is sold in Gigajoule retail units. LNG (liquefied natural gas) and LPG (liquefied petroleum gas) are traded in metric tons or MMBTU as spot deliveries. Long term natural gas distribution contracts are signed in cubic metres, and LNG contracts are in metric tonnes (1,000 kg). The LNG and LPG is transported by specialized transport ships, as the gas is liquified at cryogenic temperatures. The specification of each LNG/LPG cargo will usually contain the energy content, but this information is in general not available to the public.
In the Russian Federation, Gazprom sold approximately 250 billion cubic metres of natural gas in 2008. In 2013 the Group produced 487.4 billion cubic meters of natural and associated gas. Gazprom supplied Europe with 161.5 billion cubic meters of gas in 2013.
In August 2015, possibly the largest natural gas discovery in history was made and notified by an Italian gas company ENI. The energy company indicated that it has unearthed a "supergiant" gas field in the Mediterranean Sea covering about 40 square miles. It was also reported that the gas field could hold a potential 30 trillion cubic feet of natural gas. ENI said that it is about the energy equivalent of 5.5 billion barrels of oil. The field was found in the deep waters off the northern coast of Egypt and ENI claims that it will be the largest ever in the Mediterranean and even the world.
Natural gas as an asset class for institutional investors.
Research conducted by the World Pensions Council (WPC) suggests that large US and Canadian pension funds and Asian and MENA area SWF investors have become particularly active in the fields of natural gas and natural gas infrastructure, a trend started in 2005 by the formation of Scotia Gas Networks in the UK by OMERS and Ontario Teachers' Pension Plan.
Adsorbed natural gas (ANG).
Another way to store natural gas is adsorbing it to the porous solids called sorbents. The best condition for methane storage is at room temperature and atmospheric pressure. The used pressure can be up to 4 MPa (about 40 times atmospheric pressure) for having more storage capacity. The most common sorbent used for ANG is activated carbon (AC). Three main types of activated carbons for ANG are: Activated Carbon Fiber (ACF), Powdered Activated Carbon (PAC), activated carbon monolith.
See also.
General:

</doc>
<doc id="22133" url="https://en.wikipedia.org/wiki?curid=22133" title="Nuclear chain reaction">
Nuclear chain reaction

A nuclear chain reaction occurs when one single nuclear reaction causes an average of one or more subsequent nuclear reactions, thus leading to the possibility of a self-propagating series of these reactions. The specific nuclear reaction may be the fission of heavy isotopes (e.g. 235U). The nuclear chain reaction releases several million times more energy per reaction than any chemical reaction.
History.
Chemical chain reactions were first proposed by German chemist Max Bodenstein in 1913, and were reasonably well understood before nuclear chain reactions were proposed. It was understood that chemical chain reactions were responsible for exponentially increasing rates in reactions, such as produced chemical explosions.
The concept of a nuclear chain reaction was reportedly first hypothesized by Hungarian scientist Leó Szilárd on September 12, 1933. The neutron had been discovered in 1932, shortly before. Szilárd realized that if a nuclear reaction produced neutrons, which then caused further nuclear reactions, the process might be self-perpetuating. Szilárd, however, did not propose fission as the mechanism for his chain reaction, since the fission reaction was not yet discovered or even suspected. Instead, Szilárd proposed using mixtures of lighter known isotopes which produced neutrons in copious amounts. He filed a patent for his idea of a simple nuclear reactor the following year.
In 1936, Szilárd attempted to create a chain reaction using beryllium and indium, but was unsuccessful. After nuclear fission was discovered and proved by Otto Hahn and Fritz Strassmann in December 1938, Szilárd and Enrico Fermi in 1939 searched for, and discovered, neutron multiplication in uranium, proving that a nuclear chain reaction by this mechanism was indeed possible. This discovery prompted the letter from Szilárd and signed by Albert Einstein to President Franklin D. Roosevelt warning of the possibility that Nazi Germany might be attempting to build an atomic bomb.
On December 2, 1942, a team lead by Enrico Fermi produced the first artificial self-sustaining nuclear chain reaction with the Chicago Pile-1 (CP-1) experimental reactor in a racquets court below the bleachers of Stagg Field at the University of Chicago. Fermi's experiments at the University of Chicago were part of Arthur H. Compton's Metallurgical Laboratory of the Manhattan Project; the lab was later renamed Argonne National Laboratory, and tasked with conducting research in harnessing fission for nuclear energy.
In 1956, Paul Kuroda of the University of Arkansas postulated that a natural fission reactor may have once existed. Since nuclear chain reactions only require natural materials (such as water and uranium), it is possible to have these chain reactions occur where there is the right combination of materials within the Earth's crust. Kuroda's prediction was verified with the discovery of evidence of natural self-sustaining nuclear chain reactions in the past at Oklo in Gabon, Africa in September 1972.
Fission chain reaction.
Fission chain reactions occur because of interactions between neutrons and fissile isotopes (such as 235U). The chain reaction requires both the release of neutrons from fissile isotopes undergoing nuclear fission and the subsequent absorption of some of these neutrons in fissile isotopes. When an atom undergoes nuclear fission, a few neutrons (the exact number depends on several factors) are ejected from the reaction. These free neutrons will then interact with the surrounding medium, and if more fissile fuel is present, some may be absorbed and cause more fissions. Thus, the cycle repeats to give a reaction that is self-sustaining.
Nuclear power plants operate by precisely controlling the rate at which nuclear reactions occur, and that control is maintained through the use of several redundant layers of safety measures. Moreover, the materials in a nuclear reactor core and the uranium enrichment level make a nuclear explosion impossible, even if all safety measures failed. On the other hand, nuclear weapons are specifically engineered to produce a reaction that is so fast and intense it cannot be controlled after it has started. When properly designed, this uncontrolled reaction can lead to an explosive energy release.
Nuclear fission fuel.
Nuclear weapons employ high quality, highly enriched fuel exceeding the critical size and geometry (critical mass) necessary in order to obtain an explosive chain reaction. The fuel for energy purposes, such as in a nuclear fission reactor, is very different, usually consisting of a low-enriched oxide material (e.g. UO2).
Fission reaction products.
When a heavy atom undergoes nuclear fission it breaks into two or more fission fragments. Also, several free neutrons, gamma rays, and neutrinos are emitted, and a large amount of energy is released. The sum of the rest masses of the fission fragments and ejected neutrons is less than the sum of the rest masses of the original atom and incident neutron (of course the fission fragments are not at rest). The mass difference is accounted for in the release of energy according to the equation E=Δmc²:
mass of released energy = formula_1
Due to the extremely large value of the speed of light, c, a small decrease in mass is associated with a tremendous release of active energy (for example, the kinetic energy of the fission fragments). This energy (in the form of radiation and heat) carries the missing mass, when it leaves the reaction system (total mass, like total energy, is always conserved). While typical chemical reactions release energies on the order of a few eVs (e.g. the binding energy of the electron to hydrogen is 13.6 eV), nuclear fission reactions typically release energies on the order of hundreds of millions of eVs.
Two typical fission reactions are shown below with average values of energy released and number of neutrons ejected:
Note that these equations are for fissions caused by slow-moving (thermal) neutrons. The average energy released and number of neutrons ejected is a function of the incident neutron speed. Also, note that these equations exclude energy from neutrinos since these subatomic particles are extremely non-reactive and, therefore, rarely deposit their energy in the system.
Timescales of nuclear chain reactions.
Prompt neutron lifetime.
The prompt neutron lifetime, "l", is the average time between the emission of neutrons and either their absorption in the system or their escape from the system. The term lifetime is used because the emission of a neutron is often considered its "birth," and the subsequent absorption is considered its "death." For thermal (slow-neutron) fission reactors, the typical prompt neutron lifetime is on the order of 10−4 seconds, and for fast fission reactors, the prompt neutron lifetime is on the order of 10−7 seconds. These extremely short lifetimes mean that in 1 second, 10,000 to 10,000,000 neutron lifetimes can pass. The "average" (also referred to as the "adjoint unweighted") prompt neutron lifetime takes into account all prompt neutrons regardless of their importance in the reactor core; the "effective" prompt neutron lifetime (referred to as the "adjoint weighted" over space, energy, and angle) refers to a neutron with average importance.
Mean generation time.
The mean generation time, Λ, is the average time from a neutron emission to a capture that results in fission. The mean generation time is different from the prompt neutron lifetime because the mean generation time only includes neutron absorptions that lead to fission reactions (not other absorption reactions). The two times are related by the following formula:
In this formula, k is the effective neutron multiplication factor, described below.
Effective neutron multiplication factor.
The effective neutron multiplication factor, "k", is the average number of neutrons from one fission that cause another fission. The remaining neutrons either are absorbed in non-fission reactions or leave the system without being absorbed. The value of "k" determines how a nuclear chain reaction proceeds:
When describing kinetics and dynamics of nuclear reactors, and also in the practice of reactor operation, the concept of reactivity is used, which characterizes the deflection of reactor from the critical state. ρ=(k-1)/k. InHour is a unit of reactivity of a nuclear reactor.
In a nuclear reactor, "k" will actually oscillate from slightly less than 1 to slightly more than 1, due primarily to thermal effects (as more power is produced, the fuel rods warm and thus expand, lowering their capture ratio, and thus driving "k" lower). This leaves the average value of "k" at exactly 1. Delayed neutrons play an important role in the timing of these oscillations.
In an infinite medium, the multiplication factor may be described by the four factor formula; in a non-infinite medium, the multiplication factor may be described by the six factor formula.
Prompt and delayed supercriticality.
Not all neutrons are emitted as a direct product of fission; some are instead due to the radioactive decay of some of the fission fragments. The neutrons that occur directly from fission are called "prompt neutrons," and the ones that are a result of radioactive decay of fission fragments are called "delayed neutrons." The fraction of neutrons that are delayed is called β, and this fraction is typically less than 1% of all the neutrons in the chain reaction.
The delayed neutrons allow a nuclear reactor to respond several orders of magnitude more slowly than just prompt neutrons would alone. Without delayed neutrons, changes in reaction rates in nuclear reactors would occur at speeds that are too fast for humans to control.
The region of supercriticality between k = 1 and k = 1/(1-β) is known as delayed supercriticality (or delayed criticality). It is in this region that all nuclear power reactors operate. The region of supercriticality for k > 1/(1-β) is known as prompt supercriticality (or prompt criticality), which is the region in which nuclear weapons operate.
The change in k needed to go from critical to prompt critical is defined as a dollar.
Nuclear weapons application of neutron multiplication.
Nuclear fission weapons require a mass of fissile fuel that is prompt supercritical.
For a given mass of fissile material the value of k can be increased by increasing the density. Since the probability per distance traveled for a neutron to collide with a nucleus is proportional to the material density, increasing the density of a fissile material can increase k. This concept is utilized in the implosion method for nuclear weapons. In these devices, the nuclear chain reaction begins after increasing the density of the fissile material with a conventional explosive.
In the gun-type fission weapon two subcritical pieces of fuel are rapidly brought together. The value of k for a combination of two masses is always greater than that of its components. The magnitude of the difference depends on distance, as well as the physical orientation.
The value of k can also be increased by using a neutron reflector surrounding the fissile material
Once the mass of fuel is prompt supercritical, the power increases exponentially. However, the exponential power increase cannot continue for long since k decreases when the amount of fission material that is left decreases (i.e. it is consumed by fissions). Also, the geometry and density are expected to change during detonation since the remaining fission material is torn apart from the explosion.
Predetonation.
Detonation of a nuclear weapon involves bringing fissile material into its optimal supercritical state very rapidly. During part of this process, the assembly is supercritical, but not yet in an optimal state for a chain reaction. Free neutrons, in particular from spontaneous fissions, can cause the device to undergo a preliminary chain reaction that destroys the fissile material before it is ready to produce a large explosion, which is known as predetonation. To keep the probability of predetonation low, the duration of the non-optimal assembly period is minimized and fissile and other materials are used which have low spontaneous fission rates. In fact, the combination of materials has to be such that it is unlikely that there is even a single spontaneous fission during the period of supercritical assembly. In particular, the gun method cannot be used with plutonium (see nuclear weapon design).
Nuclear power plants and control of chain reactions.
Chain reactions naturally give rise to reaction rates that grow (or shrink) exponentially, whereas a nuclear power reactor needs to be able to hold the reaction rate reasonably constant. To maintain this control, the chain reaction criticality must have a slow enough time-scale to permit intervention by additional effects (e.g., mechanical control rods or thermal expansion). Consequently, all nuclear power reactors (even fast-neutron reactors) rely on delayed neutrons for their criticality. An operating nuclear power reactor fluctuates between being slightly subcritical and slightly delayed-supercritical, but must always remain below prompt-critical.
It is impossible for a nuclear power plant to undergo a nuclear chain reaction that results in an explosion of power comparable with a nuclear weapon, but even low-powered explosions due to uncontrolled chain reactions, that would be considered "fizzles" in a bomb, may still cause considerable damage and meltdown in a reactor. For example, the Chernobyl disaster involved a runaway chain reaction but the result was a low-powered steam explosion from the relatively small release of heat, as compared with a bomb. However, the reactor complex was destroyed by the heat, as well as by ordinary burning of the graphite exposed to air. Such steam explosions would be typical of the very diffuse assembly of materials in a nuclear reactor, even under the worst conditions.
In addition, other steps can be taken for safety. For example, power plants licensed in the United States require a negative void coefficient of reactivity (this means that if water is removed from the reactor core, the nuclear reaction will tend to shut down, not increase). This eliminates the possibility of the type of accident that occurred at Chernobyl (which was due to a positive void coefficient). However, nuclear reactors are still capable of causing smaller explosions even after complete shutdown, such as was the case of the Fukushima Daiichi nuclear disaster. In such cases, residual decay heat from the core may cause high temperatures if there is loss of coolant flow, even a day after the chain reaction has been shut down (see SCRAM). This may cause a chemical reaction between water and fuel that produces hydrogen gas which can explode after mixing with air, with severe contamination consequences, since fuel rod material may still be exposed to the atmosphere from this process. However, such explosions do not happen during a chain reaction, but rather as a result of energy from radioactive beta decay, after the fission chain reaction has been stopped.

</doc>
<doc id="22135" url="https://en.wikipedia.org/wiki?curid=22135" title="Nichiren">
Nichiren

Nichiren (日蓮; 16 February 1222 – 13 October 1282), born as , was a Japanese Buddhist priest who lived during the Kamakura period (1185–1333). Nichiren is known for his sole devotion to the "Lotus Sutra", asserting that it was Shakyamuni Buddha's ultimate teachings and was the exclusive method to attain enlightenment.
Nichiren believed that this sutra contained the essence of all of Gautama Buddha's teachings related to the laws of causality, karma, without any distinction to enlightenment. His interpretation of the Lotus Sutra centers on the emphasis on its 16th chapter, the Life Span of the Thus Come One, where he grounds his revelation that the chanting of Nam Myōhō Renge Kyō is the superior practice of Mappo or today's age. He further justifies this practice of chanting Nam Myōhō Renge Kyō by attributing the natural and social calamities of his time to the inability of the Pure Land, Zen, Shingon, Ritsu, and Tendai schools to divinely protect Japan. Nichiren gained the attention of Japan's ruling Hōjō clan when his two, Lotus Sutra-based predictions of foreign invasion and political strife were seemingly actualized by the Mongol invasions of Japan and an attempted coup within the Hōjō clan.
While all Nichiren Buddhist schools regard him as a reincarnation of Visistacaritra or "Jōgyō Bosatsu" (), some schools of Nichiren Buddhism's Nikkō lineages regard him as the Buddha of the Latter day of the Law and for all eternity. Nichiren is well known for his religious remonstration called the "Risshō Ankoku Ron" () ("On Establishing the Correct Teaching for the Security of the Land") now regarded by Japanese historians as a literary classic.
Today, Nichiren Buddhism includes traditional schools such as Nichiren Shōshū, the Nichiren Shū confederation of schools, and modern lay movements such as Kenshokai, Honmon Butsuryū Shū and Soka Gakkai, each claiming their own interpretations of Nichiren's teachings. The fundamental practice shared by all of them is the chanting of Nam Myōhō Renge Kyō.
Life.
Birth.
Nichiren was born on February 16, 1222 in the village of Kominato (today part of the city of Kamogawa), Nagase District, Awa Province (within present-day Chiba Prefecture). Nichiren's father, a fisherman, was Mikuni-no-Tayu Shigetada, also known as Nukina Shigetada Jiro (d. 1258) and his mother was Umegiku-nyo (d. 1267). On his birth, his parents named him which has variously been translated into English as "Splendid Sun" and "Virtuous Sun Boy" among others. The exact site of Nichiren's birth is believed to be submerged off the shore from present-day Kominato-zan Tanjō-ji (小湊山　誕生寺), a temple in Kominato that commemorates Nichiren's birth.
In his own words, Nichiren stated that he was "the son of a chandala family who lived near the sea in Tojo in Awa Province, in the remote countryside of the eastern part of Japan."
Education.
In a letter dated the 6th day of the 9th month of the Kōan Era (1271), Nichiren writes to a disciple, looking back on his life:
Nichiren began his Buddhist study at a nearby temple of the Tendai school, Seichō-ji (清澄寺, also called Kiyosumi-dera), at age 11. He was formally ordained at 16 and took the Buddhist name where "Renchō" means "Lotus Growth". He left Seichō-ji shortly thereafter to study in Kamakura and several years later traveled to western Japan for more in-depth study in the Kyoto–Nara area, where Japan's major centers of Buddhist learning were located. In 1233 he went to Kamakura, where he studied Pure Land Buddhism, a pietistic school that stressed salvation through the invocation of Amitābha (Japanese "Amida"), the Buddha of infinite compassion, under the guidance of a renowned master.
After having persuaded himself that devotion to Amitabha Buddha was not the true Buddhist doctrine, he passed to the study of Zen, which had become popular in Kamakura and Kyōto. He then went to Mount Hiei, the cradle of Tendai, where he felt the original purity of the Tendai doctrine corrupted by the introduction and acceptance of other doctrines, especially Amidism and esoteric Buddhism. To eliminate any possible doubts, Nichiren decided to spend some time at Mount Kōya, the centre of Shingon Buddhism, and also in Nara, Japan's ancient capital, where he studied the Risshū, which emphasized strict adherence to the Vinaya, the code of monastic discipline and ordination. During this time, he became convinced of the pre-eminence of the "Lotus Sutra" and in 1253, returned to Seichō-ji.
Initial teaching.
On April 28, 1253, he expounded the "daimoku" teachings for the first time, marking his "Sho Tempōrin" (初転法輪: "first turning the wheel of the Law"). With this, he proclaimed that devotion and practice based on the "Lotus Sutra" was the correct form of Buddhism for the current time. At the same time he changed his name to Nichiren, "nichi" (日) meaning "sun" and "ren" (蓮) meaning "lotus". This choice, as Nichiren himself explained, was rooted in passages from the "Lotus Sutra".
After making his declaration, which all schools of Nichiren Buddhism regard as marking their foundation (立宗: "risshū"), Nichiren began propagating his teachings in Kamakura, then Japan's de facto capital since it was where the shikken or regent for the shogun and the shogun himself lived and the government was established. He gained a fairly large following there, consisting of both priests and laity. Many of his lay believers came from among the samurai class.
It is claimed that in 1253 Nichiren predicted the Mongol invasions of Japan: a prediction which was validated in 1274. Nichiren viewed his teachings as a method of efficaciously preventing this and other disasters: that the best countermeasure against the degeneracy of the times and its associated disasters was through the activation of Buddha-nature by chanting and the other practices which he advocated.
Treatise (first remonstrance).
Nichiren then engaged in writing, publishing various works including his : "Treatise On Establishing the Correct Teaching for the Peace of the Land", his first major treatise and the first of three remonstrations with government authorities. He felt that it was imperative for "the sovereign to recognize and accept the singly true and correct form of Buddhism" (i.e., 立正: "risshō") as the only way to "achieve peace and prosperity for the land and its people and end their suffering" (i.e., 安国: "ankoku"). This "true and correct form of Buddhism", as Nichiren saw it, entailed regarding the Lotus Sutra as the fullest expression of the Buddha's teachings and putting those teachings into practice. Nichiren thought this could be achieved in Japan by withdrawing lay support so that the deviant monks would be forced to change their ways or revert to laymen to prevent starving.
Based on prophecies made in several sutras, Nichiren attributed the occurrence of the famines, disease, and natural disasters (especially drought, typhoons, and earthquakes) of his day to teachings of Buddhism no longer appropriate for the time.
Nichiren submitted his treatise in July 1260. Though it drew no official response, it prompted a severe backlash, especially from among priests of other Buddhist schools. Nichiren was harassed frequently, several times with force, and often had to change dwellings.
Nichiren was exiled to the Izu Peninsula in 1261, and pardoned in 1263. He was ambushed and nearly killed at Komatsubara in Awa Province in November 1264 by forces led by Lord Tōjō Kagenobu.
Failed execution attempt.
The following several years were marked by successful propagation activities in eastern Japan that generated more resentment among rival priests and government authorities. After one exchange with the influential priest, Ryōkan (良観), Nichiren was summoned for questioning by the authorities in September 1271. He used this as an opportunity to make his second government remonstration, this time to Hei no Saemon (平の左衛門, also called 平頼綱: Taira no Yoritsuna), a powerful police and military figure who issued the summons.
Two days later, on September 12, Hei no Saemon and a group of soldiers abducted Nichiren from his hut at Matsubagayatsu, Kamakura. Their intent was to arrest and behead him. According to Nichiren's account, an astronomical phenomenon — "a brilliant orb as bright as the moon" — over the seaside Tatsunokuchi execution grounds terrified Nichiren's executioners into inaction. The incident is known as the Tatsunokuchi Persecution and regarded as a turning point in Nichiren's lifetime called "Hosshaku kenpon" (発迹顕本), translated as "casting off the transient and revealing the true," or "Outgrowing the provisional and revealing the essential".
Second exile.
Unsure of what to do with Nichiren, Hei no Saemon decided to banish him to Sado, an island in the Sea of Japan known for its particularly severe winters and a place of harsh exile.
This exile, Nichiren's second, lasted about three years and, though harsh and in the long term detrimental to his health, represents one of the most important and productive segments of his life. While on Sado, he won many devoted converts and wrote two of his most important doctrinal treatises, the "Kaimoku Shō" (開目抄: "On the Opening of the Eyes") and the "Kanjin no Honzon Shō" (観心本尊抄: "The Object of Devotion for Observing the Mind") as well as numerous letters and minor treatises whose content containing critical components of his teaching.
Gohonzon.
During his 1272 exile on Sado Nichiren inscribed the first "Gohonzon" (). In addition, more than a hundred Gohonzon images preserved today are attributed to Nichiren, several are prominently known in Mount Minobu grounds, while another one called the Dai-Gohonzon mandala is enshrined at the Taisekiji temple complex in Mount Fuji. 
Return to Kamakura.
Nichiren was pardoned in February 1274 and returned to Kamakura in late March. He was again interviewed by Hei no Saemon, who now was interested in Nichiren's prediction of an invasion by the Mongols. Mongol messengers demanding Japan's fealty had frightened the authorities into believing that Nichiren's prophecy of foreign invasion would materialize (which it later did in October of that year; see Mongol invasions of Japan). Nichiren, however, used the audience as yet another opportunity to remonstrate with the government.
Retirement to Mount Minobu.
With the exception of a few short journeys, Nichiren spent the rest of his life at Minobu, where he and his disciples erected a temple, Kuon-ji (久遠寺), and he continued writing and training his disciples. Two of his works from this period are the "Senji Shō" (撰時抄: "The Selection of the Time") and the "Hōon Shō" (報恩抄: "On Repaying Debts of Gratitude"), which, along with his "Risshō Ankoku Ron" (立正安国論: "On Establishing the Correct Teaching for the Peace of the Land"), "Kaimoku Shō" ("The Opening of the Eyes"), and "Kanjin no Honzon Shō" ("The Object of Devotion for Observing the Mind"), constitute his Five Major Writings. He also inscribed numerous Gohonzon for bestowal upon specific disciples and lay believers. Many of these survive today in the repositories of Nichiren temples such as Taiseki-ji (大石寺) in Fujinomiya, Shizuoka, which has a particularly large collection that is publicly aired once a year in April.
Death.
Nichiren spent his final years writing, inscribing Gohonzon for his disciples and believers, and delivering sermons. In failing health, he was encouraged to travel to hot springs for their medicinal benefits. He left Minobu in the company of several disciples on September 8, 1282.
He arrived ten days later at the residence of Ikegami Munenaka, a lay believer who lived in what is now Ikegami Honmon-ji. On September 25 he delivered his last sermon on the "Risshō Ankoku Ron", and on October 8 he appointed six senior disciples—Nisshō (日昭), Nichirō (日朗), Nikkō (日興), Nikō (日向), Nichiji (日持), and Nitchō (日頂)—to continue leading propagation of his teachings after his death. Due to the arising conflicts which transcribed after his death, Nichiren Shōshū believes that Nichiren designated five senior priests and one successor, Nikko.
On 13 October 1282, Nichiren died in the presence of many disciples and lay believers. His funeral and cremation took place the following day. His disciple Nikkō left Ikegami with Nichiren's ashes on October 21, reaching Minobu on October 25. Nichiren's original tomb is sited, as per his request, at Kuon-ji on Mount Minobu.
Development of Nichiren's teachings.
The Kamakura period of 13th century Japan, in which Nichiren was born - was characterised by natural disasters, internal strife and confusion within Mahayana schools about whether: ""...the world had further entered a period of decline"" referring to the Latter Day of the Law. Nichiren attributed the turmoil in society to the invalid teachings of the Buddhist schools of his time, including the Tendai sect in which he was ordained: ""It is better to be a leper who chants Nam-myōhō-renge-kyō than be a chief abbot of the Tendai school"". Examinations of such breaks and continuities have been useful in illuminating the sources of Nichiren's ideas and to what extent Nichiren's thought is original or derivative of his parent tradition.
Setting out to declare his own teachings of Buddhism, Nichiren started at the age of 32 by denouncing all Mahayana schools of his time and by declaring the correct teaching as the Universal Dharma (Namu-Myōhō-Renge-Kyō) and chanting as the only path for personal and social salvation. At the age of 51, Nichiren inscribed the Object of Veneration in Buddhism, the Gohonzon,""never before known"" as he described it. Other contributions to Buddhism were the teaching of The Five Guides of Propagation, The doctrine of the Three Great Secret Dharmas and the teaching of The Three Proofs for verification of the validity of Buddhist doctrines. There is a difference between Nichiren teachings and almost all schools of Mahayana Buddhism regarding the understanding of the Latter day of the Law, Mappō. Nichiren, on the other hand, believed that the teachings of the Lotus Sutra will flourish for all eternity, and that the Bodhisattvas of the Earth will propagate Buddhism in the future.
Nichiren criticized other Buddhist schools for their manipulations of the populace for political and religious control. Citing Buddhist sutras and commentaries, Nichiren argued that these schools were distorting the Buddhist teachings for their own gain. Nichiren stated his criticism clearly, in his : "Treatise On Establishing the Correct Teaching for the Peace of the Land", his first major treatise and the first of three remonstrations with government authorities.
After Nichiren's death, his teachings were interpreted in different ways. As a result, Nichiren Buddhism encompasses several major branches and schools, each with its own doctrine and set of interpretations of Nichiren's teachings.
Writings.
Some Nichiren schools refer to the entirety of Nichiren's Buddhism as his "lifetime of teaching". Many of his writings still exist in his original hand, some as complete writings and some as fragments. Others survive as copies made by his immediate disciples. His existing works number over 700, including transcriptions of orally delivered lectures, letters of remonstration and illustrations. Today's Nichiren schools can not agree however, which of his writings can be deemed authentic and which are apocryphal. Nichiren declared that women could attain enlightenment, therefore a great number of letters were addressed to female believers. Some schools within Nichiren Buddhism consider this to be a unique feature of Nichiren's teachings and have published separate volumes of those writings.
In addition to treatises written in "kanbun" (漢文), a formal writing style modeled on classical Chinese that was the language of government and learning in contemporary Japan, Nichiren also wrote expositories and letters to disciples and lay followers in mixed-kanji–kana vernacular as well as letters in simple kana for believers who could not read the more-formal styles, particularly children. He is also known for his "kanbun", many of his writings preserved in the libraries of the empire had been lost at the end of the Boshin War.
Some of Nichiren's "kanbun" works, especially the "Risshō Ankoku Ron", are considered exemplary of the "kanbun" style, while many of his letters show unusual empathy and understanding for the down-trodden of his day. Many of his most famous letters were to women believers, whom he often complimented for their in-depth questions about Buddhism while encouraging them in their efforts to attain enlightenment in this lifetime.
Important writings.
The five major writings that are common to all Nichiren Buddhism are:
Nichiren Shōshū and Soka Gakkai revere ten major writings. In addition to the five listed above, they also revere:
Posthumous titles and status in major lineages.
In his writings, Nichiren refers to his identity in a variety of ways, nevertheless always related to the "Lotus Sutra". For example: "I, Nichiren, am the foremost votary of the Lotus Sutra".
Nichiren believed his proselytisation had fulfilled the vows the bodhisattva Viśiṣṭacāritra () gave in the "Lotus Sutra"; Nichiren Shū understands that Nichiren was thus Jōgyō's reincarnation.
After his death, Nichiren has been known by several posthumous names intended to express respect toward him or to represent his position in the history of Buddhism. Most common among these are "Shōnin" 聖人 "saint, sage" and "Daishōnin" "大聖人" "great sage". "Shōnin" is commonly used within Nichiren Shū. "Daishōnin" is the title used by followers of most, but not all, of the schools and temples derived from the Nikkō lineage, most notably Nichiren Shōshū and Soka Gakkai, who regard Nichiren as the Buddha of the Latter Day of the Law.

</doc>
<doc id="22137" url="https://en.wikipedia.org/wiki?curid=22137" title="Nichiren Buddhism">
Nichiren Buddhism

Nichiren Buddhism is a branch of Mahayana Buddhism based on the teachings of the 13th century Japanese monk Nichiren (1222–1282) and belongs to the schools of so-called "Kamakura Buddhism". Nichiren Buddhism is a comprehensive term covering several major schools and many sub-schools, as well as several of Japan's new religions. Its many denominations have in common a focus on the chanting and recital of the Lotus Sutra, which is thought to hold extraordinary power.
Nichiren Buddhism is generally noted for its focus on the Lotus Sutra and an attendant belief that all people have an innate Buddha nature and are therefore inherently capable of attaining enlightenment in their current form and present lifetime. It is also noted for its hardline opposition to any other form of Buddhism, which Nichiren saw as deviating from the Buddhist truth he had discovered.
Formal Nichiren Buddhist temple groups are commonly associated with Nichiren Shoshu and Nichiren Shu, while modern 20th century lay groups vary such as Kenshokai, Shoshinkai and Soka Gakkai International, Risshō Kōsei Kai and various others are also known. 
Founder.
From the age of 16 until 32, Nichiren, originally a monk of Tendai Buddhism, studied in numerous temples in Japan, especially Mt. Hiei (Enryaku-ji) and Mt. Kōya, in his day the major centers of Buddhist study, in the Kyoto–Nara area. He eventually concluded that the highest teachings of Shakyamuni Buddha (563?–483?BC) were to be found in the Lotus Sutra. The mantra he expounded on 28 April 1253, known as the "Daimoku" or "Odaimoku", Namu-Myōhō-Renge-Kyō, expresses his devotion to that body of teachings. During his lifetime, Nichiren stridently maintained that the contemporary teachings of Buddhism taught by other sects, (particularly the Nembutsu, Zen, Shingon, and Ritsu sects) were, to his mind, mistaken in their interpretations of the correct path to enlightenment, and therefore refuted them publicly and vociferously. In doing so, he provoked the ire of the country's rulers and of the priests of the sects he criticized; he was subjected to persecution which included an attempted beheading and at least two exiles.
Some Nichiren schools see the attempted beheading incident as marking a turning point in Nichiren's teaching, since Nichiren began inscribing the Gohonzon and wrote a number of major doctrinal treatises during his subsequent three-year exile on Sado Island in the Japan Sea. After a pardon and his return from exile, Nichiren moved to Mt. Minobu in today's Yamanashi Prefecture, where he and his disciples built a temple, Kuon-ji. Nichiren spent most of the rest of his life here training disciples. 
Basic teachings.
Nichiren Buddhism is based on the Lotus Sutra. Common to most lineages of Nichiren Buddhism is the chanting of "Namu Myōhō Renge Kyō" or "Nam Myōhō Renge Kyō," and veneration of the "Gohonzon." The definition of "Gohonzon" varies between the Nichiren schools.
Nichiren Buddhism expounds the doctrine of the Ten Worlds of life, the Ten Factors of existence, the principle of The Three Thousand Realms in a single moment of life and the teachings of The Three Proofs for verification of the validity of teachings. Most of these teachings are shared and identical in most schools and groups of Nichiren Buddhism. However, different interpretations are found for the doctrine of the "Three Great Secret Dharmas", called also "The Three Great Secret Laws", and Three Jewels.
Nichiren's writings.
Nichiren was a prolific writer. His personal communications and writings to his followers as well as numerous treatises detail his view of the correct form of practice for the "Latter Day of the Law" ("mappō"); lay out his views on other Buddhist schools, particularly those of influence during his lifetime; and elucidate his interpretations of Buddhist teachings that preceded his. These writings are collectively known as "Gosho" ("go" is an honorific prefix designating respect) or "Goibun". Which of these writings, including the "Ongi Kuden" (orally transmitted teachings), are deemed authentic or apocryphal is a matter of debate within the various schools of today's Nichiren Buddhism. One of his most important writings the "Rissho Ankoku Ron", preserved at Shochuzan Hokekyo-ji, is one of the National Treasures of Japan.
Development of Nichiren Buddhism and its major lineages.
Nichiren Buddhism is not a single denomination (see following lists). Nichiren was originally an ordained Tendai priest and is not known to have established a separate Buddhist school. Nevertheless, his teachings led to the formation of different schools within several years after his passing. Before his death Nichiren had named "six senior priests" ("rokurōsō") whom he wanted to transmit his teachings to future generations: Nisshō (日昭), Nichirō (日朗), Nikō (日向), Nitchō (日頂), Nichiji (日持), and Nikkō (日興). Each started a lineage of schools, but Nichiji eventually travelled to the Asian continent (ca. 1295) and was never heard from again, and Nitchō later in life (1302) rejoined and became a follower of Nikkō.
Schools and lineages.
Different interpretations of Nichiren's teachings had led to the establishment of various temples and schools, which however have in common reverence to the two basic doctrines of the chanting and the object of devotion. Although the former five disciples remained loosely affiliated to varying degrees, the last—Nikkō—made a clean break by leaving Kuon-ji in 1289. He had come to the conclusion that Nikō and the other disciples were embarking on heresy and Syncretism of various Buddhist practices that he could not accept. Nikko then went to the base of Mount Fuji where he would establish his own school based on orthodoxy, which would later be known as the Taisekiji temple of Nichiren Shoshu. 
After the passing of Nichiren differences between the various Nichiren schools were relatively minor; nevertheless, the following schools formed around Nichiren's disciples:
In the years following Nichiren's death, his and the temples founded by his disciples remained to a varying degree affiliated. By the 14th century a certain split within the Nichiren Schools occurred though. One differentiates between the so-called Ichi lineage (meaning unity or harmony) and Shoretsu lineage (a contraction of two words meaning superior/inferior).
"The Itchi–Soretsu controversy was of no interest to outsiders, but it kept Nichiren theologians on their toes and forced them to define their positions with more clarity. It did result in the formation of new sub-sects, but these gave impetus to missionary enterprises which expanded Nichiren Buddhism and helped spread it throughout the country." The number of adherents to Nichiren's teachings grew steadily during the 14th and 15th century to the extent that whole communities became followers. By 1400, and only being outnumbered by Zen, Nichiren temples had been founded all over Kyoto and although the various sects of Nichiren Buddhism were administratively independent they met in a council to resolve common problems.
By the 16th century Nichiren Buddhism was no longer on the fringe of religious life and a vast number of Kyoto's inhabitants adhered to Nichiren's teachings. The anarchy resulting from the conflict between the shoguns and the emperor resulted in the attacks by the so-called warrior monks from Mount Hiei. In its aftermath "twenty-one Nichiren temples were destroyed by fire … It was estimated that tens of thousands of Nichiren Buddhists lost their lives"
Some researchers compare early Nichiren Buddhism with early Christianity: "Tamura finds Nichiren’s Buddhism to be broadly comparable with Christianity 'as a religion of prophecy, in its spirit of martyrdom, in its apostolic consciousness, and additionally, in its emphasis upon history'".
Based on the tradition set by Nichiren the relationship between the government, other major Buddhist schools and Nichiren temples remained ambiguous though. The adherents of Nichiren Buddhism who made this aspect of Nichiren teachings a central pillar of their belief were the followers of the so-called Fuju-fuse lineage. Their services were partly held in secret and culminated in the persecution and partly even the execution of its believers in 1668. The majority of official Nichiren temples were "tamed" during the Edo period to the effect that they were subsumed "into a nationwide Buddhist parish system designed to ensure religious peace and eradicate the common enemy, Christianity". In this process, also known as the Danka system, Buddhist temples were generally not only a centre of Buddhist practice and learning, but were forced to carry out administrative functions, thereby also being controlled by the government taming any missionary activities.
During the Meiji Restoration from 1868 onwards and in an attempt to eradicate Buddhism Nichiren temples were forced, just like any other Buddhist school, to focus on funeral and memorial services as their main activity. Therefore, Nichiren-Buddhism remained mainly temple-based. Most Nichiren schools, referring to their establishment, state the founding of their respective head or main temple, for example, Nichiren Shū the year 1281, Nichiren Shōshū the year 1288, and Kempon Hokke Shu the year 1384. However, most of today's Nichren schools did not form until the late 19th and early 20th century as, also legal, religious bodies. A last wave of merges took place in the 1950s. Following the above-mentioned divide between the Ichi lineage and Shoretsu lineage, the most notable division is the one between Nichiren Shū and Nichiren Shōshū. Documents first mentioned and discovered by Taiseki-ji priest Nikkyo in 1488 claimed that Nichiren passed full authority "to Nikkō alone. The original documents have disappeared, but 'true copies' are preserved at Taiseki-ji. Other Nichiren bodies ignore them as forgeries."
At the time the documents may have served to underline Taiseki-ji's supposed superiority amongst Nikkō temples, especially in respect to Ikegami Honmon-ji the site of Nikkō's tomb. In the later context of developments the above-mentioned claims served as a reason on which, what would later become, Nichiren Shōshū based its orthodoxy on Nichiren-Buddhism in general. Even though there had been efforts by temples of the Nikkō lineage in the late 19th century to unify into one single separate Nichiren school the "Kommon-ha", today's Nichiren Shōshū comprises only the Taiseki-ji temple and its dependent temples. It is not identical to the historical Nikkō or Fuji lineage. Parts of the "Kommon-ha", the "Honmon-Shu", eventually became part of Nichren Shu in the 1950s. New religions like Sōka Gakkai, Shōshinkai, and Kenshōkai trace their origins to the Nichiren Shōshū school, most notably amongst those is Sōka Gakkai, which due to its steady growth is regarded today as Japan's largest lay Buddhist organization.
Kuon-ji eventually became the head temple of today's Nichiren Shū, today the largest branch amongst traditional schools, encompassing the schools and temples tracing their origins to Nikō, Nisshō, Nichirō, Nichiji and also Nikkō. The Reiyūkai, Risshō Kōsei Kai, and Nipponzan-Myōhōji-Daisanga stem, in one form or another, from the Kuon-ji lineage.
The Fuji-lineage.
Several temples located near Mount Fuji continue to follow Nichiren Buddhism, commonly referred to as "Fuji-Fusē". The Fuji-lineage is often associated with Nichiren Shoshu Buddhism or organisations formally affiliated with it but is not limited to. 
The Fuji-lineage includes the following temples:
Major Nichiren Buddhist schools and organisations.
The following lists are based on the Japanese Wikipedia article on Nichiren Buddhism.
Major Nichiren Buddhist schools and their head temples.
In alphabetical order (Japanese characters preceded by "ja:" link to articles in the Japanese Wikipedia). 
Major Nichiren Buddhist based movements and lay organisations.
In alphabetical order (Japanese characters preceded by "ja:" link to articles in the Japanese Wikipedia): 
Nationalistic interpretations.
Both Nichiren and his followers have been associated with fervent Japanese nationalism known as Nichirenism not least between the Meiji period and the conclusion of World War II.
The nationalistic interpretation of Nichiren's teachings are to be found mainly within lay Buddhist movements like Kokuchūkai or Kenshōkai, most notable in this context however are the May 15 Incident, the League of Blood Incident and Tanaka Chigaku's Kokuchūkai.

</doc>
<doc id="22141" url="https://en.wikipedia.org/wiki?curid=22141" title="Newport News Shipbuilding">
Newport News Shipbuilding

Newport News Shipbuilding (NNS), a division of Huntington Ingalls Industries, is the largest industrial employer in Virginia, and sole designer, builder and refueler of U.S. Navy aircraft carriers and one of two providers of U.S. Navy submarines. Founded as the Chesapeake Dry Dock and Construction Co. in 1886, Newport News Shipbuilding has built more than 800 ships, including both naval and commercial ships. Located in Newport News, Va., their facilities span more than 550 acres, strategically positioned in one of the great harbors of the East Coast.
The shipyard is a major employer (largest industrial employer in the state of Virginia) not only for the lower Virginia Peninsula, but also portions of Hampton Roads south of the James River and the harbor, portions of the Middle Peninsula region, and even some northeastern counties of North Carolina.
The shipyard is building the aircraft carriers (CVN 78) and the USS "John F. Kennedy" (CVN 79).
In 2013, Newport News Shipbuilding began the deactivation of the first nuclear-powered aircraft carrier, USS Enterprise (CVN-65), which it also built.
Newport News Shipbuilding is the only shipyard to perform refueling and complex overhaul (RCOH) work on Nimitz-class aircraft carriers. The nearly four-year project is performed only once during a carrier's 50-year life and includes refueling of the ship's two nuclear reactors, as well as significant repair, upgrade and modernization work. Newport News Shipbuilding has completed the refueling and complex overhaul of the first four ships of the Nimitz-class (USS Nimitz, USS Dwight D. Eisenhower, USS Carl Vinson and USS Theodore Roosevelt). Today, they are performing this work on the fifth ship in the class, the USS Abraham Lincoln, while also planning for the sixth ship in the class, USS George Washington.
Also under construction at Newport News Shipbuilding are the Virginia-class submarines Indiana (SSN 789) and Washington (SSN 787).
History.
Industrialist Collis P. Huntington (1821–1900) provided crucial funding to complete the Chesapeake and Ohio Railroad (C&O) from Richmond, Virginia to the Ohio River in the early 1870s. Although originally built for general commerce, this C&O rail link to the midwest was soon also being used to transport bituminous coal from the previously isolated coalfields, adjacent to the New River and the Kanawha River in West Virginia. In 1881, the Peninsula Extension of the C&O was built from Richmond down the Virginia Peninsula to reach a new coal pier on Hampton Roads in Warwick County near the small unincorporated community of Newport News Point. However, building the railroad and coal pier was only the first part of Huntington's dreams for Newport News.
The shipyard's early years.
In 1886 he built a shipyard to repair ships servicing this transportation hub. In 1891 Newport News Shipbuilding and Drydock Company delivered its first ship, the tugboat "Dorothy". By 1897 NNS had built three warships for the US Navy: , and .
When Collis died in 1900, his nephew Henry E. Huntington inherited much of his uncle's fortune. He also married Collis' widow Arabella Huntington, and assumed Collis's leadership role with Newport News Shipbuilding and Drydock Company. Under Henry Huntington's leadership, growth continued. 
In 1906 the revolutionary launched a great naval race worldwide. Between 1907 and 1923, Newport News built six of the US Navy's total of 22 dreadnoughts – , , , , and . All but the first were in active service in World War II. In 1907 President Theodore Roosevelt sent the Great White Fleet on its round-the-world voyage. NNS had built seven of its 16 battleships.
In 1914 NNS built SS "Medina" for the Mallory Steamship Company; as she was until 2009 the world's oldest active ocean-faring passenger ship.
Newport News and the shipyard.
In the early years, leaders of the Newport News community and those of the shipyard were virtually interchangeable. Shipyard president Walter A. Post served from March 9, 1911 to Feb. 12, 1912, when he died. Earlier, he had come to the area as one of the builders of the C&O Railway's terminals, and had served as the first mayor of Newport News after it became an independent city in 1896. It was on March 14, 1914 that Albert L. Hopkins, a young New Yorker trained in engineering, succeeded Post as President of the company. In May 1915 while traveling to England on shipyard business, aboard , Albert L. Hopkins tenure and life ended prematurely when that ship was torpedoed and sunk by a German U-boat off Queenstown on the Irish coast. His assistant Fred Gauntlett, was also on board, but was able to swim to safety. Homer Lenoir Ferguson was company vice president when Hopkins died, and assumed the presidency the following August. He saw the company through both world wars, became a noted community leader, and was a co-founder of the Mariners' Museum with Archer Huntington. He served until July 31, 1946, after the second World War had ended on both the European and Pacific fronts.
Just northwest of the shipyard, Hilton Village, one of the first planned communities in the country, was built by the federal government to house shipyard workers in 1918. The planners met with the wives of shipyard workers. Based on their input 14 house plans were designed for the projected 500 English-village-style homes. After the war, in 1922, Henry Huntington acquired it from the government, and helped facilitate the sale of the homes to shipyard employees and other local residents. Three streets there were named after Post, Hopkins, and Ferguson.
Navy orders during and after the First World War.
The "Lusitania" incident was among the events that brought the United States into World War I. Between 1918 and 1920 NNS delivered 25 destroyers, and after the war it began building aircraft carriers. was delivered in 1934, and NNS went on to build and .
Ocean liners.
After the First World War NNS completed a major reconditioning and refurbishment of the ocean liner . Before the war she had been the German liner "Vaterland", but the start of hostilities found her laid up in New York Harbor and she had been seized by the US Government in 1917 and converted into a troopship. War duty and age meant that all wiring, plumbing, and interior layouts were stripped and redesigned while her hull was strengthened and her boilers converted from coal to oil while being refurbished. Virtually a new ship emerged from NNS in 1923, and the SS Leviathan became the flagship of United States Lines.
In 1927 NNS launched the World's first significant turbo-electric ocean liner: Panama Pacific Line's . At the time she was also the largest merchant ship yet built in the USA, although she was a modest size compared with the biggest European liners of her era. NNS launched "California"s sister ships "Virginia" in 1928 and "Pennsylvania" in 1929. NNS followed them by launching two even larger turbo-electric liners for Dollar Steamship Company: the in 1930, followed by her sister in 1931. The SS America was launched in 1939 and entered service with United States lines shortly before World War II but soon returned to the shipyard for conversion to a troopship, USS West Point.
Navy orders before and during the Second World War.
By 1940 the Navy had ordered a battleship, seven more aircraft carriers and four cruisers. During World War II, NNS built ships as part of the U.S. Government's Emergency Shipbuilding Program, and swiftly filled requests for "Liberty ships" that were needed during the war. It founded the North Carolina Shipbuilding Company, an emergency yard on the banks of the Cape Fear River and launched its first Liberty ship before the end of 1941, building 243 ships in all, including 186 Liberties. For its contributions during the war, the Navy awarded the company its "E" pennant for excellence in shipbuilding. NNS ranked 23rd among United States corporations in the value of wartime production contracts.
Post-war ships.
In the post-war years NNS built the famous passenger liner , which set a transatlantic speed record that still stands today. In 1954 NNS, Westinghouse and the Navy developed and built a prototype nuclear reactor for a carrier propulsion system. NNS designed the in 1960. In 1959 NNS launched its first nuclear-powered submarine, as well as the ballistic missile submarine .
In the 1970s, NNS launched two of the largest tankers ever built in the western hemisphere and also constructed three liquefied natural gas carriers – at over 390,000 deadweight tons, the largest ever built in the United States. NNS and Westinghouse Electric Company jointly form Offshore Power Systems to build floating nuclear power plants for Public Service Electric and Gas Company. 
In the 1980s, NNS produced a variety of Navy products, including nuclear aircraft carriers and nuclear attack submarines. Since 1999 the shipyard has produced only warships for the Navy.
Submarine building problems.
In 2007, the US Navy found that workers had used incorrect metal to fuse together pipes and joints on submarines under construction and this could have led to cracking and leaks. In 2009 it was found that bolts and fasteners in weapons-handling systems on four Navy submarines, including , , , and , were installed incorrectly, delaying the launching of the boats whilst the problems were corrected.
Mergers, realignment, and spin-off.
In 1968, Newport News merged with Tenneco Corporation. In 1996, Tenneco initiated a spinoff of Newport News into an independent company (Newport News Shipbuilding). [http://www.northropgrumman.com/heritage/index.html]
On 7 November 2001, Northrop Grumman entered an agreement to purchase Newport News Shipbuilding for a total of $2.6 billion. This acquisition created a $4 billion shipyard called Northrop Grumman Newport News. [http://money.cnn.com/2001/11/08/deals/northrop_newport/index.htm]
On 28 January 2008, Northrop Grumman Corporation realigned its two shipbuilding sectors, Northrop Grumman Newport News and Northrop Grumman Ship Systems, into a single sector called "Northrop Grumman Shipbuilding". [http://www.irconnect.com/noc/press/pages/news_releases.html?d=134293]
On March 15, 2011 Northrop Grumman announced the spin-off of this sector into a separate company, Huntington Ingalls Industries, Inc., and on March 31, began operating as a separate company and publicly trading under the symbol HII on the New York Stock Exchange.
Ships built.
Ships built at the Newport News yard include:

</doc>
<doc id="22145" url="https://en.wikipedia.org/wiki?curid=22145" title="Newton's method">
Newton's method

In numerical analysis, Newton's method (also known as the Newton–Raphson method), named after Isaac Newton and Joseph Raphson, is a method for finding successively better approximations to the roots (or zeroes) of a real-valued function.
The Newton–Raphson method in one variable is implemented as follows:
The method starts with a function defined over the real numbers , the function's derivative , and an initial guess for a root of the function . If the function satisfies the assumptions made in the derivation of the formula and the initial guess is close, then a better approximation is
Geometrically, is the intersection of the -axis and the tangent of the graph of at .
The process is repeated as
until a sufficiently accurate value is reached.
This algorithm is first in the class of Householder's methods, succeeded by Halley's method. The method can also be extended to complex functions and to systems of equations.
Description.
The idea of the method is as follows: one starts with an initial guess which is reasonably close to the true root, then the function is approximated by its tangent line (which can be computed using the tools of calculus), and one computes the "x"-intercept of this tangent line (which is easily done with elementary algebra). This "x"-intercept will typically be a better approximation to the function's root than the original guess, and the method can be iterated.
Suppose "ƒ" : ["a", "b"] → R is a differentiable function defined on the interval ["a", "b"] with values in the real numbers R. The formula for converging on the root can be easily derived. Suppose we have some current approximation "x""n". Then we can derive the formula for a better approximation, "x""n"+1 by referring to the diagram on the right. The equation of the tangent line to the curve "y" = "ƒ"("x") at the point "x=x""n" is
where "ƒ"' denotes the derivative of the function "ƒ".
The "x"-intercept of this line (the value of "x" such that "y"=0) is then used as the next approximation to the root, "x""n"+1. In other words, setting "y" to zero and "x" to "x""n"+1 gives
Solving for "x""n"+1 gives
We start the process off with some arbitrary initial value "x"0. (The closer to the zero, the better. But, in the absence of any intuition about where the zero might lie, a "guess and check" method might narrow the possibilities to a reasonably small interval by appealing to the intermediate value theorem.) The method will usually converge, provided this initial guess is close enough to the unknown zero, and that "ƒ"'("x"0) ≠ 0. Furthermore, for a zero of multiplicity 1, the convergence is at least quadratic (see rate of convergence) in a neighbourhood of the zero, which intuitively means that the number of correct digits roughly at least doubles in every step. More details can be found in the analysis section below.
The Householder's methods are similar but have higher order for even faster convergence.
However, the extra computations required for each step can slow down the overall performance relative to Newton's method, particularly if "f" or its derivatives are computationally expensive to evaluate.
History.
The name "Newton's method" is derived from Isaac Newton's description of a special case of the method in "De analysi per aequationes numero terminorum infinitas" (written in 1669, published in 1711 by William Jones) and in "De metodis fluxionum et serierum infinitarum" (written in 1671, translated and published as "Method of Fluxions" in 1736 by John Colson). However, his method differs substantially from the modern method given above: Newton applies the method only to polynomials. He does not compute the successive approximations formula_7, but computes a sequence of polynomials, and only at the end arrives at an approximation for the root "x". Finally, Newton views the method as purely algebraic and makes no mention of the connection with calculus. Newton may have derived his method from a similar but less precise method by Vieta. The essence of Vieta's method can be found in the work of the Persian mathematician Sharaf al-Din al-Tusi, while his successor Jamshīd al-Kāshī used a form of Newton's method to solve formula_8 to find roots of "N" (Ypma 1995). A special case of Newton's method for calculating square roots was known much earlier and is often called the Babylonian method.
Newton's method was used by 17th-century Japanese mathematician Seki Kōwa to solve single-variable equations, though the connection with calculus was missing.
Newton's method was first published in 1685 in "A Treatise of Algebra both Historical and Practical" by John Wallis. In 1690, Joseph Raphson published a simplified description in "Analysis aequationum universalis". Raphson again viewed Newton's method purely as an algebraic method and restricted its use to polynomials, but he describes the method in terms of the successive approximations "x""n" instead of the more complicated sequence of polynomials used by Newton. Finally, in 1740, Thomas Simpson described Newton's method as an iterative method for solving general nonlinear equations using calculus, essentially giving the description above. In the same publication, Simpson also gives the generalization to systems of two equations and notes that Newton's method can be used for solving optimization problems by setting the gradient to zero.
Arthur Cayley in 1879 in "The Newton-Fourier imaginary problem" was the first to notice the difficulties in generalizing Newton's method to complex roots of polynomials with degree greater than 2 and complex initial values. This opened the way to the study of the theory of iterations of rational functions.
Practical considerations.
Newton's method is an extremely powerful technique—in general the convergence is quadratic: as the method converges on the root, the difference between the root and the approximation is squared (the number of accurate digits roughly doubles) at each step. However, there are some difficulties with the method.
Difficulty in calculating derivative of a function.
Newton's method requires that the derivative be calculated directly. An analytical expression for the derivative may not be easily obtainable and could be expensive to evaluate. In these situations, it may be appropriate to approximate the derivative by using the slope of a line through two nearby points on the function. Using this approximation would result in something like the secant method whose convergence is slower than that of Newton's method.
Failure of the method to converge to the root.
It is important to review the proof of quadratic convergence of Newton's Method before implementing it. Specifically, one should review the assumptions made in the proof. For situations where the method fails to converge, it is because the assumptions made in this proof are not met.
Overshoot.
If the first derivative is not well behaved in the neighborhood of a particular root, the method may overshoot, and diverge from that root. An example of a function with one root, for which the derivative is not well behaved in the neighborhood of the root, is
This is equivalent to using successive over-relaxation. On the other hand, if the multiplicity formula_11 of the root is not known, it is possible to estimate formula_11 after carrying out one or two iterations, and then use that value to increase the rate of convergence.
Analysis.
Suppose that the function "ƒ" has a zero at α, i.e., "ƒ"(α) = 0, and "ƒ" is differentiable in a neighborhood of α.
If "f"  is continuously differentiable and its derivative is nonzero at α, then there exists a neighborhood of α such that for all starting values "x"0 in that neighborhood, the sequence {"x""n"} will converge to α.
If the function is continuously differentiable and its derivative is not 0 at α and it has a second derivative at α then the convergence is quadratic or faster. If the second derivative is not 0 at α then the convergence is merely quadratic. If the third derivative exists and is bounded in a neighborhood of α, then:
where formula_14
If the derivative is 0 at α, then the convergence is usually only linear. Specifically, if "ƒ" is twice continuously differentiable, "ƒ" '("α") = 0 and "ƒ" "("α") ≠ 0, then there exists a neighborhood of α such that for all starting values "x"0 in that neighborhood, the sequence of iterates converges linearly, with rate log10 2 (Süli & Mayers, Exercise 1.6). Alternatively if "ƒ" '("α") = 0 and "ƒ" '("x") ≠ 0 for "x" ≠ α, "x" in a neighborhood "U" of α, α being a zero of multiplicity "r", and if "ƒ" ∈ "C""r"("U") then there exists a neighborhood of α such that for all starting values "x"0 in that neighborhood, the sequence of iterates converges linearly.
However, even linear convergence is not guaranteed in pathological situations.
In practice these results are local, and the neighborhood of convergence is not known in advance. But there are also some results on global convergence: for instance, given a right neighborhood "U+" of α, if "f" is twice differentiable in "U+" and if formula_15, formula_16 in "U+", then, for each "x"0 in "U"+ the sequence "xk" is monotonically decreasing to α.
Proof of quadratic convergence for Newton's iterative method.
According to Taylor's theorem, any function "f"("x") which has a continuous second derivative can be represented by an expansion about a point that is close to a root of f(x). Suppose this root is formula_17 Then the expansion of f(α) about "x""n" is:
where the Lagrange form of the Taylor series expansion remainder is
where ξ"n" is in between "x""n" and formula_17
Since formula_20 is the root, () becomes:
Dividing equation () by formula_21 and rearranging gives
Remembering that "x""n"+1 is defined by
one finds that
That is,
Taking absolute value of both sides gives
Equation () shows that the rate of convergence is quadratic if the following conditions are satisfied:
The term "sufficiently" close in this context means the following:
(a) Taylor approximation is accurate enough such that we can ignore higher order terms,
(b) formula_27
(c) formula_28
Finally, () can be expressed in the following way:
The initial point formula_30 has to be chosen such that conditions 1 through 3 are satisfied, where the third condition requires that formula_31
Basins of attraction.
The basins of attraction—the regions of the real number line such that within each region iteration from any point leads to one particular root—can be infinite in number and arbitrarily small. For example, for the function formula_32, the following initial conditions are in successive basins of attraction:
Failure analysis.
Newton's method is only guaranteed to converge if certain conditions are satisfied. If the assumptions made in the proof of quadratic convergence are met, the method will converge. For the following subsections, failure of the method to converge indicates that the assumptions made in the proof were not met.
Bad starting points.
In some cases the conditions on the function that are necessary for convergence are satisfied, but the point chosen as the initial point is not in the interval where the method converges. This can happen, for example, if the function whose root is sought approaches zero asymptotically as "x" goes to formula_33 or formula_34. In such cases a different method, such as bisection, should be used to obtain a better estimate for the zero to use as an initial point.
Iteration point is stationary.
Consider the function:
It has a maximum at "x" = 0 and solutions of "f"("x") = 0 at "x" = ±1. If we start iterating from the stationary point "x"0 = 0 (where the derivative is zero), "x"1 will be undefined, since the tangent at (0,1) is parallel to the "x"-axis:
The same issue occurs if, instead of the starting point, any iteration point is stationary. Even if the derivative is small but not zero, the next iteration will be a far worse approximation.
Starting point enters a cycle.
For some functions, some starting points may enter an infinite cycle, preventing convergence. Let
and take 0 as the starting point. The first iteration produces 1 and the second iteration returns to 0 so the sequence will alternate between the two without converging to a root. In fact, this 2-cycle is stable: there are neighborhoods around 0 and around 1 from which all points iterate asymptotically to the 2-cycle (and hence not to the root of the function). In general, the behavior of the sequence can be very complex (see Newton fractal).The real solution of this equation is -1.76929235...
Derivative issues.
If the function is not continuously differentiable in a neighborhood of the root then it is possible that Newton's method will always diverge and fail, unless the solution is guessed on the first try.
Derivative does not exist at root.
A simple example of a function where Newton's method diverges is trying to find the cube root of zero. The cube root is continuous and infinitely differentiable, except for "x" = 0, where its derivative is undefined:
For any iteration point "xn", the next iteration point will be:
The algorithm overshoots the solution and lands on the other side of the "y"-axis, farther away than it initially was; applying Newton's method actually doubles the distances from the solution at each iteration.
In fact, the iterations diverge to infinity for every formula_40, where formula_41. In the limiting case of formula_42 (square root), the iterations will alternate indefinitely between points "x"0 and −"x"0, so they do not converge in this case either.
Discontinuous derivative.
If the derivative is not continuous at the root, then convergence may fail to occur in any neighborhood of the root. Consider the function
Its derivative is:
Within any neighborhood of the root, this derivative keeps changing sign as "x" approaches 0 from the right (or from the left) while "f"("x") ≥ "x" − "x"2 > 0 for 0 < "x" < 1.
So "f"("x")/"f"'("x") is unbounded near the root, and Newton's method will diverge almost everywhere in any neighborhood of it, even though:
Non-quadratic convergence.
In some cases the iterates converge but do not converge as quickly as promised. In these cases simpler methods converge just as quickly as Newton's method.
Zero derivative.
If the first derivative is zero at the root, then convergence will not be quadratic. Let
then formula_46 and consequently formula_47. So convergence is not quadratic, even though the function is infinitely differentiable everywhere.
Similar problems occur even when the root is only "nearly" double. For example, let
Then the first few iterates starting at "x"0 = 1 are
1, 0.500250376, 0.251062828, 0.127507934, 0.067671976, 0.041224176, 0.032741218, 0.031642362; it takes six iterations to reach a point where the convergence appears to be quadratic.
No second derivative.
If there is no second derivative at the root, then convergence may fail to be quadratic. Let
Then
And
except when formula_52 where it is undefined. Given formula_53,
which has approximately 4/3 times as many bits of precision as formula_53 has. This is less than the 2 times as many which would be required for quadratic convergence. So the convergence of Newton's method (in this case) is not quadratic, even though: the function is continuously differentiable everywhere; the derivative is not zero at the root; and formula_56 is infinitely differentiable except at the desired root.
Generalizations.
Complex functions.
When dealing with complex functions, Newton's method can be directly applied to find their zeroes. Each zero has a basin of attraction in the complex plane, the set of all starting values that cause the method to converge to that particular zero. These sets can be mapped as in the image shown. For many complex functions, the boundaries of the basins of attraction are fractals.
In some cases there are regions in the complex plane which are not in any of these basins of attraction, meaning the iterates do not converge. For example, if one uses a real initial condition to seek a root of formula_57, all subsequent iterates will be real numbers and so the iterations cannot converge to either root, since both roots are non-real. In this case almost all real initial conditions lead to chaotic behavior, while some initial conditions iterate either to infinity or to repeating cycles of any finite length.
Curt McMullen has shown that for any possible purely iterative algorithm similar to Newton's Method, the algorithm will diverge on some open regions of the complex plane when applied to some polynomial of degree d ≥ 4. However, McMullen gave a generally convergent algorithm for polynomials of degree d = 3.
Nonlinear systems of equations.
k variables, k functions.
One may also use Newton's method to solve systems of "k" (non-linear) equations, which amounts to finding the zeroes of continuously differentiable functions "F" : R"k" → R"k". In the formulation given above, one then has to left multiply with the inverse of the "k"-by-"k" Jacobian matrix "J""F"("x""n") instead of dividing by "f" '("x""n").
Rather than actually computing the inverse of this matrix, one can save time by solving the system of linear equations
for the unknown "x""n"+1 − "x""n".
k variables, m equations, with m > k.
The k-dimensional Newton's method can be used to solve systems of ">k" (non-linear) equations as well if the algorithm uses the generalized inverse of the non-square Jacobian matrix J+ = (JTJ)−1JT instead of the inverse of J. If the nonlinear system has no solution, the method attempts to find a solution in the non-linear least squares sense. See Gauss–Newton algorithm for more information.
Nonlinear equations in a Banach space.
Another generalization is Newton's method to find a root of a functional "F" defined in a Banach space. In this case the formulation is
where formula_60 is the Fréchet derivative computed at formula_61. One needs the Fréchet derivative to be boundedly invertible at each formula_61 in order for the method to be applicable. A condition for existence of and convergence to a root is given by the Newton–Kantorovich theorem.
Nonlinear equations over "p"-adic numbers.
In "p"-adic analysis, the standard method to show a polynomial equation in one variable has a "p"-adic root is Hensel's lemma, which uses the recursion from Newton's method on the "p"-adic numbers. Because of the more stable behavior of addition and multiplication in the "p"-adic numbers compared to the real numbers (specifically, the unit ball in the "p"-adics is a ring), convergence in Hensel's lemma can be guaranteed under much simpler hypotheses than in the classical Newton's method on the real line.
Newton-Fourier method.
The Newton-Fourier method is Joseph Fourier's extension of Newton's method to provide bounds on the absolute error of the root approximation, while still providing quadratic convergence.
Assume that formula_63 is twice continuously differentiable on formula_64 and that formula_65 contains a root in this interval. Assume that formula_66 on this interval (this is the case for instance if formula_67, formula_68, and formula_69, and formula_70 on this interval). This guarantees that there is a unique root on this interval, call it formula_71. If it is concave down instead of concave up then replace formula_63 by formula_73 since they have the same roots.
Let formula_74 be the right endpoint of the interval and let formula_75 be the left endpoint of the interval. Given formula_7, define formula_77, which is just Newton's method as before. Then define formula_78, where the denominator is formula_79 and not formula_80. The iterates formula_7 will be strictly decreasing to the root while the iterates formula_82 will be strictly increasing to the root. Also, formula_83 so that distance between formula_7 and formula_82 decreases quadratically.
Quasi-Newton methods.
When the Jacobian is unavailable or too expensive to compute at every iteration, a Quasi-Newton method can be used.
Applications.
Minimization and maximization problems.
Newton's method can be used to find a minimum or maximum of a function. The derivative is zero at a minimum or maximum, so minima and maxima can be found by applying Newton's method to the derivative. The iteration becomes:
Multiplicative inverses of numbers and power series.
An important application is Newton–Raphson division, which can be used to quickly find the reciprocal of a number, using only multiplication and subtraction.
Finding the reciprocal of "a" amounts to finding the root of the function
Newton's iteration is
Therefore, Newton's iteration needs only two multiplications and one subtraction.
This method is also very efficient to compute the multiplicative inverse of a power series.
Solving transcendental equations.
Many transcendental equations can be solved using Newton's method. Given the equation
with "g(x)" and/or "h(x)" a transcendental function, one writes
The values of "x" that solves the original equation are then the roots of "f(x)", which may be found via Newton's method.
Examples.
Square root of a number.
Consider the problem of finding the square root of a number. Newton's method is one of many methods of computing square roots.
For example, if one wishes to find the square root of 612, this is equivalent to finding the solution to
The function to use in Newton's method is then,
with derivative,
With an initial guess of 10, the sequence given by Newton's method is
where the correct digits are underlined. With only a few iterations one can obtain a solution accurate to many decimal places.
Solution of cos("x") = "x"3.
Consider the problem of finding the positive number "x" with cos("x") = "x"3. We can rephrase that as finding the zero of "f"("x") = cos("x") − "x"3. We have "f"'("x") = −sin("x") − 3"x"2. Since cos("x") ≤ 1 for all "x" and "x"3 > 1 for "x" > 1, we know that our solution lies between 0 and 1. We try a starting value of "x"0 = 0.5. (Note that a starting value of 0 will lead to an undefined result, showing the importance of using a starting point that is close to the solution.)
The correct digits are underlined in the above example. In particular, "x"6 is correct to the number of decimal places given. We see that the number of correct digits after the decimal point increases from 2 (for "x"3) to 5 and 10, illustrating the quadratic convergence.
Pseudocode.
The following is an example of using the Newton's Method to help find a root of a function codice_1 which has derivative codice_2.
The initial guess will be formula_96 and the function will be formula_97 so that formula_98.
Each new iterative of Newton's method will be denoted by codice_3. We will check during the computation whether the denominator (codice_4) becomes too small (smaller than codice_5), which would be the case if formula_99, since otherwise a large amount of error could be introduced.

</doc>
<doc id="22146" url="https://en.wikipedia.org/wiki?curid=22146" title="New Order (band)">
New Order (band)

New Order are an English rock band formed in 1980, currently consisting of founding members Bernard Sumner, Stephen Morris and Gillian Gilbert, alongside newer members Phil Cunningham and Tom Chapman. The band was formed in 1980 by Sumner (vocals, guitars, keyboards and synthesisers), former member Peter Hook (bass and vocals), and Morris (drums, electronic drums, keyboards and synthesizers) – the remaining members of post-punk group Joy Division, following the suicide of vocalist Ian Curtis – with the addition of Gilbert (keyboards, synthesizers and guitars).
By combining post-punk with an increasing influence from electronic dance music, New Order became one of the most critically acclaimed and influential bands of the 1980s. Though the band's early years were shadowed by the legacy and basic sound of Joy Division, their experience of the early 1980s New York City club scene increased their knowledge of dance music and helped them incorporate elements of that style into their work. The band's 1983 hit "Blue Monday", the best-selling 12-inch single of all time, is one example of how the band's sound became increasingly upbeat and electronic.
New Order were the flagship band for Manchester-based independent record label Factory Records. Their unlabelled album sleeves and "non-image" (the band rarely gave interviews and were known for performing short concert sets with no encores) reflected the label's aesthetic of doing whatever the relevant parties wanted to do, including an aversion to including singles as album tracks. Because of the band's dance-rock genre it has a complex discography, with many well-known songs not featured on studio albums or released in a variety of mixes. Throughout their career, the band's records were carefully art-directed by Mancunian designer Peter Saville.
The group disbanded in 1993 to work on individual projects, and reunited in 1998. In 2001, Cunningham (guitars, keyboards and synthesisers) replaced Gilbert, who took a sabbatical from the band because of family commitments. In 2007, Hook left the band over personal conflicts. After Hook's departure, Sumner, Cunningham, and Morris worked on Bad Lieutenant and the band reunited in 2011 without Hook, with Gilbert returning and Chapman replacing Hook on bass. During the band's career and in between lengthy breaks, band members have been involved in several solo projects, such as Sumner's Electronic and Bad Lieutenant; Hook's Monaco and Revenge and Gilbert and Morris' The Other Two. Cunningham was previously a member of Marion and with Sumner, and Chapman was a member of Bad Lieutenant.
In September 2015, the band released their tenth studio album, "Music Complete".
History.
Origins and formation: 1977–1980.
Between 1977 and 1980, Ian Curtis, Peter Hook, Stephen Morris, and Bernard Sumner were members of the post-punk band Joy Division, often featuring heavy production input from producer Martin Hannett. Curtis committed suicide on 18 May 1980, the day before Joy Division were scheduled to depart for their first American tour, and prior to release of the band's second album, "Closer". The rest of the band decided soon after Curtis's death that they would carry on. Prior to his death, the members of Joy Division had agreed not to continue under the Joy Division name should any one member leave. On 29 July 1980, the still unnamed trio debuted live at Manchester's Beach Club. Rob Gretton, the band's manager for over twenty years, is credited for having found the name "New Order" in an article in "The Guardian" entitled "The People's New Order of Kampuchea". The band adopted this name, despite its previous use for ex-Stooge Ron Asheton's band The New Order. The group states that the name New Order (as was also the case with "Joy Division") does not draw a direct line to Nazism or Fascism.
The band rehearsed with each member taking turns on vocals. Sumner ultimately took the role, as he could sing when he wasn't playing his guitar. Wanting to complete the line-up with someone they knew well and whose musical skill and style was compatible with their own, New Order invited Morris's girlfriend, Gillian Gilbert, to join the band in early October 1980, as keyboardist and guitarist. Gilbert's membership was suggested by Gretton. Gilbert's first live performance with New Order occurred at The Squat in Manchester on 25 October 1980.
"Movement": 1981–1982.
The initial release as New Order was the single "Ceremony", backed with "In a Lonely Place". These two songs were written in the weeks before Curtis took his own life. With the release of "Movement" in November 1981, New Order initially started on a similar route as their previous incarnation, performing dark, melodic songs, albeit with an increased use of synthesisers. The band viewed the period as a low point, as they were still reeling from Curtis' death. Hook commented that the only positive thing to come out of the "Movement" sessions was that producer Martin Hannett had showed the band how to use a mixing board, which allowed them to produce records by themselves from then on. More recently, Hook indicated a change of heart: "I think "Movement" gets a raw deal in general really – for me, when you consider the circumstances in which it was written, it is a fantastic record."
New Order visited New York City again in 1981, where the band were introduced to post-disco, freestyle and electro. The band had taken to listening to Italian disco to cheer themselves up, while Morris taught himself drum programming. The singles that followed, "Everything's Gone Green" and "Temptation", saw a change in direction toward dance music.
The Haçienda, Factory Records' own nightclub (largely funded by New Order) opened in May 1982 in Manchester and was even issued a Factory catalogue number: FAC51. The opening of UK's first ever superclub was marked by a nearly 23-minute instrumental piece originally entitled "Prime 5 8 6", but released 15 years later as "Video 5 8 6". Composed primarily by Sumner and Morris, "Prime 5 8 6"/"Video 5 8 6" was an early version of "5 8 6" that contained rhythm elements that would later surface on "Blue Monday" and "Ultraviolence".
"Power, Corruption & Lies": 1983–1984.
"Power, Corruption & Lies", released in May 1983, was a synthesiser-based outing and a dramatic change in sound from Joy Division and the preceding album, although the band had been hinting at the increased use of technology during the music-making process for a number of years then, including their work as Joy Division. Starting from what earlier singles had hinted, this was where the band had found their footing, mixing early techno music with their earlier guitar-based sound and showing the strong influence of acts like Kraftwerk and Giorgio Moroder. Even further in this direction was the electronically sequenced, four-on-the-floor single "Blue Monday". Inspired by Klein & MBO's "Dirty Talk" and Sylvester's disco classic, "You Make Me Feel (Mighty Real)", "Blue Monday" became the best-selling independent 12" single of all time in the UK; however, (much to the chagrin of the buying public) it was not on the track list of "Power, Corruption & Lies". This resulted in a sticker being applied to unsold copies of "Power, Corruption & Lies" album saying, "DOES NOT CONTAIN BLUE MONDAY". (It was included on the cassette format in some countries, such as Australia and New Zealand.) "Blue Monday" is now included on the 2008 collector's edition of "Power, Corruption & Lies".
The 1983 single "Confusion" firmly established the group as a dance music force, inspiring many musicians in subsequent years. In 1984 they followed the largely synthesised single "Thieves Like Us" with the heavy guitar-drum-bass rumble of "Murder", a not-too-distant cousin of "Ecstasy" from the "Power, Corruption & Lies" album.
"Low-Life", "Brotherhood", and "Substance": 1985–1987.
1985's "Low-Life" refined and sometimes mixed the two styles, brandishing "The Perfect Kiss"—the video for which was filmed by Jonathan Demme—and "Sub-culture". In February 1986, the soundtrack album to "Pretty in Pink" featuring "Shellshock" was released on A&M Records. An instrumental version of "Thieves Like Us" and the instrumental "Elegia" appeared in the film but were not on the soundtrack album. Later that summer, New Order headlined a line-up that included the Smiths, the Fall, and A Certain Ratio during the Festival of the Tenth Summer at Manchester's G-Mex.
"Brotherhood" (1986) divided the two approaches onto separate album sides. The album notably featured "Bizarre Love Triangle" and "Angel Dust" (of which a remixed instrumental version is available on the UK "True Faith" CD video single, under the title "Evil Dust"), a track which marries a synth break beat with "Low-Life"-era guitar effects. While New Order toured North America with friends Echo & the Bunnymen, the summer of 1987 saw the release of the compilation "Substance", which featured the new single "True Faith". "Substance" was an important album in collecting the group's 12-inch singles onto CD for the first time and featured new versions of "Temptation" and "Confusion"—referred to as "Temptation '87" and "Confusion '87". A second disc featured several of the B-sides from the singles on the first disc, as well as additional A-sides "Procession" and "Murder". The single, "True Faith", with its surreal video, became a hit on MTV and the band's first American top 40 hit. The single's B-side, "1963"—originally planned on being the A-side until the group's label convinced them to release "True Faith" instead—would later be released as a single in its own right several years later, with two new versions.
In December 1987, the band released a further single, "Touched by the Hand of God", with a Katherine Bigelow-directed video parodying glam-metal. The single reached number 20 on the UK Singles Chart and number 1 in the UK Independent Singles chart, but would not appear on album until the 1994 compilation "The Best of New Order".
"Technique", "Republic" and first break-up: 1988–1993.
By this time, the group was heavily influenced by the Balearic sounds of Ibiza making their way into the Hacienda. Partly recorded at Mediterranean Sound studios on Ibiza, "Technique" was released in February 1989. The album entered the charts at number one in the UK and contained a mix of the acid house influence (as on "Fine Time", which is the opening track on the album) and a more traditional rock sound on others (such as the single "Run 2"). The album is a blend of occasionally upbeat, accessible music coupled with blunt, poignant lyrics. During the summer of 1989, New Order supported "Technique" by touring with Public Image Ltd, Throwing Muses and The Sugarcubes across the United States and Canada in what was the press dubbed the "Monsters of Alternative Rock" tour. Around this time, several band members decided to begin side projects including Electronic (Sumner with Johnny Marr) and Revenge (Hook with Davyth Hicks). Morris and Gilbert also began to work on outside TV theme production work.
In 1990, New Order recorded the official song of the England national football team's 1990 World Cup campaign, "World in Motion", under the ad-hoc band name EnglandNewOrder. The song, co-written with comedian Keith Allen, was a number one UK hit. The song was originally announced as being called "E for England" but the Football Association vetoed the title, realising that this was a reference to ecstasy a drug heavily associated with the band. (Allen claimed that his original draft lyrics ran "E is for England, England starts with E / We'll all be smiling when we're in Italy.") The recording also featured chanting from members of the England team and Allen and a guest rap from left winger John Barnes. It was again produced by Stephen Hague, who the band chose to produce their next album.
Their next album "Republic" was shadowed by the collapse of their label Factory Records. New Order never had a formal contract with Factory, which is unusual for any major group. (This was in fact the label's standard practice until the mid-1980s. According to Factory's co-founder Tony Wilson, "All our bands are free to fuck off whenever they please.") Because of this, the group (rather than Factory Records) legally owned all their own recorded material. This has often been cited, not least by Wilson himself, as the main reason London Records' 1992 offer to buy the ailing label fell through. However, the group signed with London, as did Morris and Gilbert separately for their side project The Other Two, which had been preparing a debut album intended to be released on Factory.
"Republic", released around the world in 1993, was the band's first album release since parting company with the now-defunct Factory Records. The release spawned the singles "Regret"—their highest-charting single in the US—"Ruined in a Day", "World", and "Spooky".
Following the release of "Republic", the band put New Order on hold while each member continued on with their own side-projects, with The Other Two's debut album released in 1993 after the band had finished touring. In 1994, a second singles collection was released, entitled "The Best of New Order". It featured all of the band's singles since "Substance" as well as a few extra tracks: "Vanishing Point" (from 1989's "Technique"), "The Perfect Kiss", "Thieves Like Us", "Shellshock", and new recordings of "True Faith", "Bizarre Love Triangle", "1963" and "Round & Round". The new versions of "True Faith" and "1963" – the latter with a yet newer, more guitar-oriented version produced by Arthur Baker – were released as singles to promote the album. In the US, the track listing was altered to set it apart from "Substance" as well as the UK release of "The Best of New Order" which had been available months prior. This collection was followed by a remix album, "The Rest of New Order", featuring a selection of old remixes and newly commissioned mixes of classic New Order tracks. Some versions contained an extra disc/cassette composed entirely of remixes of "Blue Monday". "Blue Monday" was released as a single for a third time to promote the collection.
Reformation and "Get Ready": 1998–2003.
The group reconvened in 1998 at the suggestion of Rob Gretton. Nearly five years had passed since they had last seen each other. Sumner said, "We decided before we agreed to doing any gig, to have a meeting, and if anyone had any grudges to bear, to iron them out." By the second meeting everyone agreed to continue playing, scheduling their reunion gig for the Phoenix Festival that same year. In addition to rarer songs, New Order also decided to begin playing Joy Division songs again. When the Phoenix Festival was cancelled due to low ticket sales, New Order instead played the last night of that year's Reading Festival.
Their 2001 release "Get Ready" largely departed from their more electronic style and focused on more guitar oriented music. According to Sumner, ""Get Ready" was guitar-heavy simply because we felt that we'd left that instrument alone for a long time." Longtime fan Billy Corgan of The Smashing Pumpkins played guitar and sang back-up on the track "Turn My Way", and in 2001 toured with the band on dates in the UK, US, and Japan for a short period of time. Phil Cunningham (formerly of Marion) joined the band in a live capacity, deputising for Gilbert who declined to tour in favour of caring for her and Morris' children. Primal Scream's Bobby Gillespie provided vocals on the track "Rock the Shack". Singles from the album included "Crystal", "60 Miles an Hour" and "Someone Like You".
In 2002, "Q" featured New Order on their list of the "50 Bands to See Before You Die", although this was as part of a sub-list of "5 Bands That Could Go Either Way". Both New Order and Joy Division were portrayed in the Michael Winterbottom film "24 Hour Party People", depicting the rise and fall of Factory Records as seen through the eyes of label founder Tony Wilson. Cameos by Wilson himself, along with Mark E. Smith of The Fall and former members of Happy Mondays and Inspiral Carpets, lent a degree of legitimacy to the proceedings. The film touched on some of Factory's other artists, including Happy Mondays and The Durutti Column. The soundtrack featured the new track "Here to Stay", produced by the Chemical Brothers, which was released as a single. The single's music video highlighted scenes taken from the film.
"Waiting for the Sirens' Call", "Singles" and second break-up: 2004–2007.
The band released a new album on 27 March 2005, entitled "Waiting for the Sirens' Call", their first with new member Phil Cunningham. Cunningham replaced Gilbert (now married to Morris) so she could look after their children. Singles from this album were "Krafty", "Jetstream" (which features guest vocals by Ana Matronic from Scissor Sisters), and the title track. At the 2005 NME Awards, New Order and Joy Division received the award for "Godlike Geniuses" (for lifetime achievement). Previous winners include Ozzy Osbourne, The Clash, and Happy Mondays. In 2006 the album track "Guilt Is a Useless Emotion" was nominated for a Grammy Award in the category of Best Dance Recording.
In the autumn of 2005, the group released another greatest hits compilation, in the form of "Singles". The two-disc release was an updated version of the "Substance" collection and contained every single released from their 1981 debut all the way through to "Waiting for the Sirens' Call". However, unlike "Substance", which focused almost exclusively on the 12" versions of the group's singles, "Singles" collected the 7" versions, many of which (like "Ceremony", "Temptation" and "Confusion") had never been released on CD. The album was accompanied by a two-disc DVD set, entitled "Item", that collected the extended UK version of "NewOrderStory" with a DVD of all New Order music videos as well as two newly commissioned videos for "Temptation '87" and "Ceremony".
The "New Order: Live in Glasgow" DVD was recorded at the Glasgow Academy in 2006 and features 18 tracks, including 4 Joy Division songs. Next to that, the release also contains a bonus disc of footage from the band's personal archive including 1980s footage from Glastonbury, Rome, Cork, Rotterdam and Toronto.
In 2006, the band played several one-off live dates as well as short tours in the UK, Brazil and Argentina. After their Buenos Aires show in November 2006, Peter Hook suggested that the band should stop touring. In early May 2007, Hook was interviewed by British radio station XFM — originally to talk about his contribution to the debut album of Jane's Addiction singer Perry Farrell's new band Satellite Party — and stated that "Me and Bernard aren't working together." Further complicating the news, NewOrderOnline, a website with support from New Order management, reported that according to "a source close to the band", "The news about the split is false... New Order still exists despite what said … Peter Hook can leave the band, but this doesn't mean the end of New Order." However, Sumner revealed in 2009 that he no longer wished to make music as New Order.
Reunion with new line-up, "Lost Sirens" and "Music Complete": 2011–present.
In September 2011, the band announced that they would perform for the first time since 2006, at the Ancienne Belgique, Brussels on 17 October and at the Bataclan, Paris on 18 October. The band's line-up included keyboardist Gillian Gilbert, who returned to the band after a ten-year break, and Bad Lieutenant bassist Tom Chapman in place of Peter Hook. They played subsequent shows in London and South America in December.
In December 2011, New Order released "Live at the London Troxy", a live album from their performance of 10 December 2011 at The Troxy in London. This release featured the new lineup and their first show in London in over five years.
They continued to tour throughout 2012, including a short tour of New Zealand and Australia in February/March. They played at the 'T in the Park' festival in Scotland on 3 and 4 July 2012 and at the EXIT Festival in Novi Sad Serbia on 13 July 2012. New Order performed at Hyde Park with Blur and The Specials to celebrate the 2012 Summer Olympics closing ceremony.
In December 2012 it was announced that "Lost Sirens" would be released in the United Kingdom on 14 January 2013. "Lost Sirens" is an eight-track album of tracks left out of "Waiting for the Sirens' Call". The album was discussed by Gillian Gilbert in a Brazilian interview to promote the band’s appearance in São Paulo. She acknowledged issues with former member Peter Hook, and stated there was "a lot going on behind the scenes on the copyright" delaying the release.
The band debuted their first newly-written song since the "Waiting for the Sirens' Call" sessions, titled "Singularity", during Lollapalooza Chile in March 2014. In July, the group toured North America, where they debuted the song "Plastic". On 2 September it was announced that the band decided to release their new album through Mute Records. The New Order catalogue remains with Warner Music.
On 22 September 2015 the band released a new album, "Music Complete", their first without Peter Hook. The album was produced mostly by the band themselves, except "Singularity" and "Unlearn This Hatred", both produced by Tom Rowlands, while "Superheated" features additional production by Stuart Price. The album was released on CD, regular and limited-edition double clear LP, and an 8-piece deluxe vinyl box set, containing the double clear LP as well as extended versions of the 11 tracks on 6 different colored vinyl. All formats were available as of the initial release date, except the box set, which was released on 20 November 2015. The extended versions of all tracks, originally exclusive to the deluxe vinyl box set, have been compiled into a new version of the album titled "Complete Music". "Complete Music" is to be released on CD and digital formats on 13th May 2016.
In November 2015, Peter Hook sued Bernard Sumner, Stephen Morris and Gillian Gilbert. In an objection, he claimed that they set up a new company behind his back and it has generated an income of £7.8 million in four years while he received only a fraction of that. The three members insisted they had treated Mr. Hook fairly and that his stake in the band's royalties was reasonable. The judge ruled that there was "at least a reasonable prospect" of Mr. Hook proving that he was not getting a fair share of royalties and other income. He was willing to hear the case but urged the parties to come to an agreement rather than suffer legal costs of around £900,000.
Other projects.
In 1988, Bernard Sumner teamed up with former Smiths guitarist Johnny Marr to form the group Electronic, also enlisting the help of Neil Tennant and Chris Lowe of the Pet Shop Boys. Electronic regrouped in 1996 for "Raise the Pressure", which also featured Karl Bartos (formerly of Kraftwerk). The project's third album "Twisted Tenderness" was released in 1999 after which the band dissolved.
In June 2009, Bernard Sumner formed a new band called Bad Lieutenant with Phil Cunningham (guitar) and Jake Evans (guitar and vocals). Their album "Never Cry Another Tear" was released on 5 October 2009. In addition to Cunningham and Evans the album also features appearances by Stephen Morris (drums), Jack Mitchell (drums), Tom Chapman (bass) and Alex James (bass). The live band included Morris on drums and Tom Chapman on bass.
Hook has been involved with several other projects. In the 1990s, Hook recorded with Killing Joke with a view to joining the band. However, original bassist Martin 'Youth' Glover instead returned to the band. In 1995 he toured with The Durutti Column. He has recorded one album with the band Revenge with Davyth Hicks and Chris Jones and two with Monaco (both as bassist, keyboardist and lead vocalist) with David Potts. Monaco scored a club and alternative radio hit with "What Do You Want From Me?" in 1997. Hook also formed a band called Freebass with fellow bass players Mani (The Stone Roses) and Andy Rourke (ex-The Smiths) and vocalist Gary Briggs, which was active from 2007 to 2010. He also contributed to Perry Farrell's Satellite Party. Hook's current band Peter Hook and The Light is touring Joy Division and New Order albums in their entirety.
In 1990 Gilbert and Morris formed their own band, The Other Two. The Other Two released its first single "Tasty Fish" in 1991 and released two albums, "The Other Two & You" in 1993 and "Super Highways" in 1999. They have also been involved in scoring television soundtracks. In 2007, Gilbert and Morris remixed two tracks for the Nine Inch Nails remixes album "Year Zero Remixed".
BeMusic.
"BeMusic" was a name the band used for their publishing company (the LP label for "Movement" says "B Music" in large letters, though using an italic ß for the letter B). All four members of the band used the name for production work for other artists' recordings between 1982 and 1985.
The first BeMusic credit was for Peter Hook producing Stockholm Monsters in 1982. Other artists with producer or musician credit for "BeMusic" were 52nd Street, Section 25, Marcel King, Quando Quango, Paul Haig, Thick Pigeon, Nyam Nyam and Life.
Their production work as BeMusic was collected on two LTM Recordings compilation CDs, "Cool As Ice: The BeMusic Productions" and "Twice As Nice" (which also included production work by Donald Johnson, of A Certain Ratio, and Arthur Baker).
Sound.
New Order's music mixes rock with dance music, as can be seen on signature tracks such as "True Faith" and "Temptation". This synthesis laid down the groundwork for dance-rock groups of today. The group's album art earned them the status of icons in the alternative community, and has shown considerable longevity. The band are also regarded as the first alternative dance music group with their fusion of "used icy, gloomy post-punk with Kraftwerk-style synth-pop" and were also labeled as synthpop, post-punk, new wave, and dance-rock.
They have heavily influenced techno, rock, and pop musicians including Pet Shop Boys, The Killers and Moby, and were themselves influenced by the likes of David Bowie, Neu!, Kraftwerk, Cabaret Voltaire and Giorgio Moroder. They have also significantly influenced electro, freestyle and house. New Order's Kraftwerk influence was acknowledged by their single "Krafty", which had cover art referencing "Autobahn".
Bassist Peter Hook contributed to New Order's sound by developing an idiosyncratic bass guitar technique. He often used the bass as a lead instrument, playing melodies on the high strings with a signature heavy chorus effect, leaving the "actual" basslines to keyboards or sequencers. This has often been cited as a defining characteristic of the New Order sound.
Drummer Stephen Morris plays a mixture of acoustic and electronic drums, and in many cases plays along seamlessly with sequenced parts. All the band members could and did switch instruments throughout gigs, as evidenced on Jonathan Demme's video for "The Perfect Kiss" and the concert videos "Taras Shevchenko" (recorded in New York, November 1981) and "Pumped Full of Drugs" (Tokyo, May 1985). During such live gigs, Sumner alternated between guitar, keyboards, melodica and (on the track "Confusion") bass; Gilbert switched between keyboards and guitar, Morris between drums and keyboards, and Hook played both bass and electronic drums. "Taras Shevchenko" is also notable for the fact all four members of the group have left the stage before the final song, "Temptation", comes to a complete end.
Reputation.
Both New Order and Joy Division were among the most successful artists on the Factory Records label, run by Granada television personality Tony Wilson, and partnered with Factory in the financing of the Manchester club The Haçienda. The band rarely gave interviews in the 1980s, later ascribing this to not wanting to discuss Ian Curtis. This, along with the Peter Saville sleeve designs and the tendency to give short performances with no encores, gave New Order a reputation as standoffish. The band became more open in the '90s; for example, the aforementioned "NewOrderStory" (and in particular the longer UK version) featured extensive personal interviews. Speaking in 2009, fellow synthpop musician Phil Oakey described New Order's slow-burn career as cult musicians as being unusually prolonged and effective: “If you want to make a lot of money out of pop, be number 3 a lot. Like New Order did. Or The Cure. Because when you're number 1 you're everybody's; nobody really cares about you any more." Despite this, the band have commented on the unplanned nature of their career and the considerable expense lost in supporting the Haçienda.
Cover artwork.
Almost all New Order recordings bear minimalist packaging, art directed by Peter Saville. The group's record sleeves bucked the 1980s trend by rarely showing the band members (with the exception of the "Low-Life" album) or even providing basic information such as the band name or title of the release. Song names were often hidden within the shrink wrapped package, either on the disc itself (such as the "Blue Monday" single), on an inconspicuous part of an inner sleeve ("The Perfect Kiss" single), or written in a cryptic colour code invented by Saville ("Power, Corruption & Lies"). Saville said his intention was to sell the band as a "mass-produced secret" of sorts, and that the minimalist style was enough to allow fans to identify the band's products without explicit labelling. Saville frequently sent the artwork straight to the printer, unreviewed by either the band or the label.
Band members.
<br>

</doc>
<doc id="22148" url="https://en.wikipedia.org/wiki?curid=22148" title="Niccolò Fontana Tartaglia">
Niccolò Fontana Tartaglia

Niccolò Fontana Tartaglia (; 1499/1500 in Brescia – 13 December 1557 in Venice) was an Italian mathematician, engineer (designing fortifications), a surveyor (of topography, seeking the best means of defense or offense) and a bookkeeper from the then-Republic of Venice (now part of Italy). He published many books, including the first Italian translations of Archimedes and Euclid, and an acclaimed compilation of mathematics. Tartaglia was the first to apply mathematics to the investigation of the paths of cannonballs, known as ballistics, in his Nova Scientia, “A New Science;” his work was later partially validated and partially superseded by Galileo's studies on falling bodies. He also published a treatise on retrieving sunken ships.
Personal life.
Niccolò Fontana was the son of Michele Fontana, a dispatch rider who travelled to neighboring towns to deliver mail. But in 1506, Michele was murdered by robbers, and Niccolo, his two siblings, and his mother were left impoverished. Niccolò experienced further tragedy in 1512 when the King Louis XII's troops invaded Brescia during the War of the League of Cambrai against Venice. The militia of Brescia defended their city for seven days. When the French finally broke through, they took their revenge by massacring the inhabitants of Brescia. By the end of battle, over 45,000 residents were killed. During the massacre, Niccolò and his family sought sanctuary in the local cathedral. But the French entered and a soldier sliced Niccolò's jaw and palate with a saber and left him for dead. His mother nursed him back to health but the young boy would never recover the power of speech, prompting the nickname "Tartaglia" ("stammerer"). After this he would never shave, and grew a beard to camouflage his scars.
There is a story that Tartaglia learned only half the alphabet from a private tutor before funds ran out, and he had to learn the rest by himself. Be that as it may, he was essentially self-taught. He and his contemporaries, working outside the academies, were responsible for the spread of classical works in modern languages among the educated middle class.
Major works.
His edition of Euclid in 1543, the first translation of the "Elements" into any modern European language, was especially significant. For two centuries Euclid had been taught from two Latin translations taken from an Arabic source; these contained errors in Book V, the Eudoxian theory of proportion, which rendered it unusable. Tartaglia's edition was based on Zamberti's Latin translation of an uncorrupted Greek text, and rendered Book V correctly. He also wrote the first modern and useful commentary on the theory. Later, the theory was an essential tool for Galileo, just as it had been for Archimedes.
However, his best known work is his treatise "General Trattato di numeri, et misure" published in Venice 1556–1560. This has been called the "best" treatise on arithmetic that appeared in the sixteenth century. Not only does Tartaglia have complete discussions of numerical operations and the commercial rules used by Italian arithmeticians in this work, but he also discusses the life of the people, the customs of merchants and the efforts made to improve arithmetic in the 16th century.
Solution to cubic equations.
Tartaglia is perhaps best known today for his conflicts with Gerolamo Cardano. Cardano cajoled Tartaglia into revealing his solution to the cubic equations, by promising not to publish them. Tartaglia divulged the secrets of the solutions of three different forms of the cubic equation in verse. Several years later, Cardano happened to see unpublished work by Scipione del Ferro who independently came up with the same solution as Tartaglia. As the unpublished work was dated before Tartaglia's, Cardano decided his promise could be broken and included Tartaglia's solution in his next publication. Even though Cardano credited his discovery, Tartaglia was extremely upset and a famous public challenge match resulted between himself and Cardano's student, Ludovico Ferrari. Widespread stories that Tartaglia devoted the rest of his life to ruining Cardano, however, appear to be completely fabricated. Mathematical historians now credit both Cardano and Tartaglia with the formula to solve cubic equations, referring to it as the "Cardano–Tartaglia formula".
Volume of a tetrahedron.
Tartaglia is also known for having given an expression (Tartaglia's formula) for the volume of a tetrahedron (including any irregular tetrahedra) as the Cayley–Menger determinant of the distance values measured pairwise between its four corners:
where "d" "ij" is the distance between vertices "i" and "j". This is a generalization of Heron's formula for the area of a triangle.

</doc>
<doc id="22149" url="https://en.wikipedia.org/wiki?curid=22149" title="Nagarjuna">
Nagarjuna

Nāgārjuna (c. 150 – c. 250 CE) is widely considered one of the most important Buddhist philosophers after Gautama Buddha. Along with his disciple Āryadeva, he is considered to be the founder of the Madhyamaka school of Mahāyāna Buddhism. Nāgārjuna is also credited with developing the philosophy of the Prajñāpāramitā sūtras and, in some sources, with having revealed these scriptures in the world, having recovered them from the nāgas (snake-people). Furthermore, he is traditionally supposed to have written several treatises on rasayana as well as serving a term as the head of Nālandā.
History.
Very little is reliably known of the life of Nāgārjuna, since the surviving accounts were written in Chinese and Tibetan centuries after his death. According to some accounts, Nāgārjuna was originally from South India. Some scholars believe that Nāgārjuna was an advisor to a king of the Satavahana dynasty. Archaeological evidence at Amarāvatī indicates that if this is true, the king may have been Yajña Śrī Śātakarṇi, who ruled between 167 and 196 CE. On the basis of this association, Nāgārjuna is conventionally placed at around 150–250 CE.
According to a 4th/5th-century biography translated by Kumārajīva, Nāgārjuna was born into a Brahmin family in Vidarbha (a region of Maharashtra) and later became a Buddhist.
Some sources claim that in his later years, Nāgārjuna lived on the mountain of Śrīparvata near the city that would later be called Nāgārjunakoṇḍa ("Hill of Nāgārjuna"). The ruins of Nāgārjunakoṇḍa are located in Guntur district, Andhra Pradesh. The Caitika and Bahuśrutīya nikāyas are known to have had monasteries in Nāgārjunakoṇḍa.
Writings.
There exist a number of influential texts attributed to Nāgārjuna though, as there are many pseudepigrapha attributed to him, lively controversy exists over which are his authentic works. The only work that all scholars agree is Nagarjuna's is the "Mūlamadhyamakakārikā" (Fundamental Verses on the Middle Way), which contains the essentials of his thought in twenty-seven chapters.
According to one view, that of Christian Lindtner, the works definitely written by Nagarjuna are:
Buston considers the first six to be the main treatises of Nagarjuna, while according to Taaranaatha only the first five are the works of Nagarjuna. TRV Murti considers Ratnaavali, Pratitya Samutpaada Hridaya and Sutra Samuccaya to be works of Nagarjuna as the first two are quoted profusely by Chandrakirti and the third by Shantideva.
In addition to works mentioned above, several others are attributed to
Nāgārjuna. There is an ongoing, lively controversy over which of those
works are authentic. Contemporary research suggest that these works belong
to a significantly later period, either to late 8th or early 9th century CE,
and hence can not be authentic works of Nāgārjuna.
However, several works considered important in esoteric Buddhism are
attributed to Nāgārjuna and his disciples by traditional historians
like Tāranātha from 17th century Tibet. These historians try to account
for chronological difficulties with various theories. For example, a
propagation of later writings via mystical revelation. For a useful
summary of this tradition, see Wedemeyer 2007.
Lindtner considers that the "Māhaprajñāparamitopadeśa" "Commentary on the Great Perfection of Wisdom" is not a genuine work of Nāgārjuna. This work is only attested in a Chinese translation by Kumārajīva.There is much discussion as to whether this is a work of Nāgārjuna, or someone else. Étienne Lamotte, who translated one third of the work into French, felt that it was the work of a North Indian bhikṣu of the Sarvāstivāda school who later became a convert to the Mahayana. The Chinese scholar-monk Yin Shun felt that it was the work of a South Indian and that Nāgārjuna was quite possibly the author. These two views are not necessarily in opposition and a South Indian Nāgārjuna could well have studied the northern Sarvāstivāda. Neither of the two felt that it was composed by Kumārajīva, which others have suggested.
Philosophy.
From studying his writings, it is clear that Nāgārjuna was conversant with many of the Śrāvaka philosophies and with the Mahāyāna tradition. However, determining Nāgārjuna's affiliation with a specific nikāya is difficult, considering much of this material has been lost. If the most commonly accepted attribution of texts (that of Christian Lindtner) holds, then he was clearly a Māhayānist, but his philosophy holds assiduously to the Śrāvaka "Tripiṭaka", and while he does make explicit references to Mahāyāna texts, he is always careful to stay within the parameters set out by the Śrāvaka canon.
Nagarjuna may have arrived at his positions from a desire to achieve a consistent exegesis of the Buddha's doctrine as recorded in the āgamas. In the eyes of Nagarjuna, the Buddha was not merely a forerunner, but the very founder of the Madhyamaka system. David Kalupahana sees Nagarjuna as a successor to Moggaliputta-Tissa in being a champion of the middle-way and a reviver of the original philosophical ideals of the Buddha.
Nagarjuna assumes a knowledge of the definitions of the sixteen categories as given in the Nyaya Sutras and wrote a treatise on the pramanas where he reduced the syllogism of five members into one of three. In the Vigrahavyavartani Karika, Nagarjuna criticizes the Nyaya theory of pramanas (means of knowledge) 
Nagarjuna was fully acquainted with the classical Samkhya and even the Vaiseshika. 
Sunyata.
Nāgārjuna's major thematic focus is the concept of śūnyatā, or "emptiness," which brings together other key Buddhist doctrines, particularly anātman "not-self" and pratītyasamutpāda "dependent origination", to refute the metaphysics of some of his contemporaries. For Nāgārjuna, as for the Buddha in the early texts, it is not merely sentient beings that are "selfless" or non-substantial; all phenomena (dhammas) are without any svabhāva, literally "own-being", "self-nature", or "inherent existence" and thus without any underlying essence. They are "empty" of being independently existent; thus the heterodox theories of svabhāva circulating at the time were refuted on the basis of the doctrines of early Buddhism. This is so because all things arise always dependently: not by their own power, but by depending on conditions leading to their coming into existence, as opposed to being.
Nagarjuna means by real any entity which has a nature of its own (svabhāva), which is not produced by causes (akrtaka), which is not dependant on anything else (paratra nirapeksha). 
Chapter 24 verse 14 of the Mūlamadhyamakakārikā provides one of Nagarjuna's most famous quotations on emptiness and co-arising:
As part of his analysis of the emptiness of phenomena in the Mūlamadhyamakakārikā, Nagarjuna critiques svabhāva in several different concepts. He discusses the problems of positing any sort of inherent essence to causation, movement, change and personal identity. Nagarjuna makes use of the Indian logical tool of the tetralemma to attack any essentialist conceptions. Nagarjuna’s logical analysis is based on four basic propositions:
To say that all things are 'empty' is to deny any kind of ontological foundation, therefore Nagarjuna's view is often seen as a kind of ontological anti-foundationalism or a metaphysical anti-realism.
Understanding the nature of the emptiness of phenomena is simply a means to an end, which is nirvana. Thus Nagarjuna's philosophical project is ultimately a soteriological one meant to correct our everyday cognitive processes which mistakenly posits svabhāva on the flow of experience.
Some scholars such as Fyodor Shcherbatskoy and T.R.V. Murti held that Nagarjuna was the inventor of the Shunyata doctrine, however, more recent work by scholars such as Choong Mun-keat, Yin Shun and Dhammajothi Thero has argued that Nagarjuna was not an innovator by putting forth this theory, but that, in the words of Shi Huifeng, "the connection between emptiness and dependent origination is not an innovation or creation of Nāgārjuna."
Two truths.
Nāgārjuna was also instrumental in the development of the two truths doctrine, which claims that there are two levels of truth in Buddhist teaching, the ultimate truth ("paramārtha satya") and the conventional or superficial truth ("saṃvṛtisatya"). The ultimate truth to Nagarjuna is the truth that everything is empty of essence, this includes emptiness itself ('the emptiness of emptiness'). While some (Murti, 1955) have interpreted this by positing Nagarjuna as a Neo-Kantian and thus making ultimate truth a metaphysical noumenon or an "ineffable ultimate that transcends the capacities of discursive reason", others such as Mark Siderits and Jay Garfield have argued that Nagarjuna's view is that "the ultimate truth is that there is no ultimate truth" (Siderits) and that Nagarjuna is a "semantic anti-dualist" who posits that there are only conventional truths. Hence according to Garfield:
Suppose that we take a conventional entity, such as a table. We analyze it to demonstrate its emptiness, finding that there is no table apart from its parts […]. So we conclude that it is empty. But now let us analyze that emptiness […]. What do we find? Nothing at all but the table’s lack of inherent existence. […]. To see the table as empty […] is to see the table as conventional, as dependent.
In articulating this notion in the "Mūlamadhyamakakārikā", Nāgārjuna drew on an early source in the "Kaccānagotta Sutta", which distinguishes definitive meaning ("nītārtha") from interpretable meaning ("neyārtha"):
The version linked to is the one found in the nikayas, and is slightly different from the one found in the "Samyuktagama". Both contain the concept of teaching via the middle between the extremes of existence and non-existence. Nagarjuna does not make reference to "everything" when he quotes the agamic text in his "Mūlamadhyamakakārikā".
Causality.
Jay L. Garfield describes that Nāgārjuna approached causality from the four noble truths and dependent origination. Nāgārjuna distinguished two dependent origination views in a causal process, that which causes effects and that which causes conditions. This is predicated in the two truth doctrine, as conventional truth and ultimate truth held together, in which both are empty in existence. The distinction between effects and conditions is controversial. In Nāgārjuna's approach, cause means an event or state that has power to bring an effect. Conditions, refer to proliferating causes that bring a further event, state or process; without a metaphysical commitment to an occult connection between explaining and explanans. He argues nonexistent causes and various existing conditions. The argument draws from unreal causal power. Things conventional exist and are ultimately nonexistent to rest in the middle way in both causal existence and nonexistence as casual emptiness within the Mūlamadhyamakakārikā doctrine. Although seeming strange to Westerners, this is seen as an attack on a reified view of causality.
Relativity.
Nagarjuna also taught the idea of relativity; in the Ratnāvalī, he gives the example that shortness exists only in relation to the idea of length. The determination of a thing or object is only possible in relation to other things or objects, especially by way of contrast. He held that the relationship between the ideas of "short" and "long" is not due to intrinsic nature (svabhāva). This idea is also found in the Pali Nikāyas and Chinese Āgamas, in which the idea of relativity is expressed similarly: "That which is the element of light ... is seen to exist on account of relation to darkness; that which is the element of good is seen to exist on account of bad; that which is the element of space is seen to exist on account of form."
Nagarjuna as Ayurvedic physician.
According to Frank John Ninivaggi, Nagarjuna was also a practitioner of Ayurveda. First described in the Sanskrit medical treatise "Sushruta Samhita", of which he was the compiler of the redaction, many of his conceptualisations, such as his descriptions of the circulatory system and blood tissue (described as rakta dhātu) and his pioneering work on the therapeutic value of specially treated minerals knowns as "bhasmas", which earned him the title of the "father of iatrochemistry".
Iconography.
Nāgārjuna is often depicted in composite form comprising human and nāga characteristics. Often the nāga-aspect forms a canopy crowning and shielding his human head. The notion of the naga is found throughout Indian religious culture, and typically signifies an intelligent serpent or dragon, who is responsible for the rains, lakes and other bodies of water. In Buddhism, it is a synonym for a realised arhat, or wise person in general.
English translations.
Mūlamadhyamakakārikā.
The "Mūlamadhyamakakārikā" is Nagarjuna's best-known work. It is "not only a grand commentary on the Buddha's discourse to Kaccayana, the only discourse cited by name, but also a detailed and careful analysis of most of the important discourses included in the Nikayas and the agamas, especially those of the "Atthakavagga" of the "Sutta-nipata".
In the "Mūlamadhyamakakārikā", "ll experienced phenomena are empty ("sunya"). This did not mean that they are not experienced and, therefore, non-existent; only that they are devoid of a permanent and eternal substance ("svabhava"). Since they are experienced, they are not mere names ("prajnapti")."

</doc>
<doc id="22151" url="https://en.wikipedia.org/wiki?curid=22151" title="Nuclear reactor">
Nuclear reactor

A nuclear reactor, formerly known as an atomic pile, is a device used to initiate and control a sustained nuclear chain reaction. Nuclear reactors are used at nuclear power plants for electricity generation and in propulsion of ships. Heat from nuclear fission is passed to a working fluid (water or gas), which runs through steam turbines. These either drive a ship's propellers or turn electrical generators. Nuclear generated steam in principle can be used for industrial process heat or for district heating. Some reactors are used to produce isotopes for medical and industrial use, or for production of weapons-grade plutonium. Some are run only for research. Today there are about 450 nuclear power reactors that are used to generate electricity in about 30 countries around the world.
Mechanism.
Just as conventional power-stations generate electricity by harnessing the thermal energy released from burning fossil fuels, nuclear reactors convert the energy released by controlled nuclear fission into thermal energy for further conversion to mechanical or electrical forms.
Fission.
When a large fissile atomic nucleus such as uranium-235 or plutonium-239 absorbs a neutron, it may undergo nuclear fission. The heavy nucleus splits into two or more lighter nuclei, (the fission products), releasing kinetic energy, gamma radiation, and free neutrons. A portion of these neutrons may later be absorbed by other fissile atoms and trigger further fission events, which release more neutrons, and so on. This is known as a nuclear chain reaction.
To control such a nuclear chain reaction, neutron poisons and neutron moderators can change the portion of neutrons that will go on to cause more fission. Nuclear reactors generally have automatic and manual systems to shut the fission reaction down if monitoring detects unsafe conditions.
Commonly-used moderators include regular (light) water (in 74.8% of the world's reactors), solid graphite (20% of reactors) and heavy water (5% of reactors). Some experimental types of reactor have used beryllium, and hydrocarbons have been suggested as another possibility.
Heat generation.
The reactor core generates heat in a number of ways:
A kilogram of uranium-235 (U-235) converted via nuclear processes releases approximately three million times more energy than a kilogram of coal burned conventionally (7.2 × 1013 joules per kilogram of uranium-235 versus 2.4 × 107 joules per kilogram of coal).
Cooling.
A nuclear reactor coolant — usually water but sometimes a gas or a liquid metal (like liquid sodium) or molten salt — is circulated past the reactor core to absorb the heat that it generates. The heat is carried away from the reactor and is then used to generate steam. Most reactor systems employ a cooling system that is physically separated from the water that will be boiled to produce pressurized steam for the turbines, like the pressurized water reactor. However, in some reactors the water for the steam turbines is boiled directly by the reactor core; for example the boiling water reactor.
Reactivity control.
The power output of the reactor is adjusted by controlling how many neutrons are able to create more fissions.
Control rods that are made of a neutron poison are used to absorb neutrons. Absorbing more neutrons in a control rod means that there are fewer neutrons available to cause fission, so pushing the control rod deeper into the reactor will reduce its power output, and extracting the control rod will increase it.
At the first level of control in all nuclear reactors, a process of delayed neutron emission by a number of neutron-rich fission isotopes is an important physical process. These delayed neutrons account for about 0.65% of the total neutrons produced in fission, with the remainder (termed "prompt neutrons") released immediately upon fission. The fission products which produce delayed neutrons have half lives for their decay by neutron emission that range from milliseconds to as long as several minutes, and so considerable time is required to determine exactly when a reactor reaches the critical point. Keeping the reactor in the zone of chain-reactivity where delayed neutrons are "necessary" to achieve a critical mass state allows mechanical devices or human operators to control a chain reaction in "real time"; otherwise the time between achievement of criticality and nuclear meltdown as a result of an exponential power surge from the normal nuclear chain reaction, would be too short to allow for intervention. This last stage, where delayed neutrons are no longer required to maintain criticality, is known as the prompt critical point. There is a scale for describing criticality in numerical form, in which bare criticality is known as "zero dollars" and the prompt critical point is "one dollar", and other points in the process interpolated in cents.
In some reactors, the coolant also acts as a neutron moderator. A moderator increases the power of the reactor by causing the fast neutrons that are released from fission to lose energy and become thermal neutrons. Thermal neutrons are more likely than fast neutrons to cause fission. If the coolant is a moderator, then temperature changes can affect the density of the coolant/moderator and therefore change power output. A higher temperature coolant would be less dense, and therefore a less effective moderator.
In other reactors the coolant acts as a poison by absorbing neutrons in the same way that the control rods do. In these reactors power output can be increased by heating the coolant, which makes it a less dense poison. Nuclear reactors generally have automatic and manual systems to scram the reactor in an emergency shut down. These systems insert large amounts of poison (often boron in the form of boric acid) into the reactor to shut the fission reaction down if unsafe conditions are detected or anticipated.
Most types of reactors are sensitive to a process variously known as xenon poisoning, or the iodine pit. The common fission product Xenon-135 produced in the fission process acts as a neutron poison that absorbs neutrons and therefore tends to shut the reactor down. Xenon-135 accumulation can be controlled by keeping power levels high enough to destroy it by neutron absorption as fast as it is produced. Fission also produces iodine-135, which in turn decays (with a half-life of 6.57 hours) to new xenon-135. When the reactor is shut down, iodine-135 continues to decay to xenon-135, making restarting the reactor more difficult for a day or two, as the xenon-135 decays into cesium-135, which is not nearly as poisonous as xenon-135, with a half-life of 9.2 hours. This temporary state is the "iodine pit." If the reactor has sufficient extra reactivity capacity, it can be restarted. As the extra xenon-135 is transmuted to xenon-136, which is much less a neutron poison, within a few hours the reactor experiences a "xenon burnoff (power) transient". Control rods must be further inserted to replace the neutron absorption of the lost xenon-135. Failure to properly follow such a procedure was a key step in the Chernobyl disaster.
Reactors used in nuclear marine propulsion (especially nuclear submarines) often cannot be run at continuous power around the clock in the same way that land-based power reactors are normally run, and in addition often need to have a very long core life without refueling. For this reason many designs use highly enriched uranium but incorporate burnable neutron poison in the fuel rods. This allows the reactor to be constructed with an excess of fissionable material, which is nevertheless made relatively safe early in the reactor's fuel burn-cycle by the presence of the neutron-absorbing material which is later replaced by normally produced long-lived neutron poisons (far longer-lived than xenon-135) which gradually accumulate over the fuel load's operating life.
Electrical power generation.
The energy released in the fission process generates heat, some of which can be converted into usable energy. A common method of harnessing this thermal energy is to use it to boil water to produce pressurized steam which will then drive a steam turbine that turns an alternator and generates electricity.
Early reactors.
The neutron was discovered in 1932. The concept of a nuclear chain reaction brought about by nuclear reactions mediated by neutrons was first realized shortly thereafter, by Hungarian scientist Leó Szilárd, in 1933. He filed a patent for his idea of a simple reactor the following year while working at the Admiralty in London. However, Szilárd's idea did not incorporate the idea of nuclear fission as a neutron source, since that process was not yet discovered. Szilárd's ideas for nuclear reactors using neutron-mediated nuclear chain reactions in light elements proved unworkable.
Inspiration for a new type of reactor using uranium came from the discovery by Lise Meitner, Fritz Strassmann and Otto Hahn in 1938 that bombardment of uranium with neutrons (provided by an alpha-on-beryllium fusion reaction, a "neutron howitzer") produced a barium residue, which they reasoned was created by the fissioning of the uranium nuclei. Subsequent studies in early 1939 (one of them by Szilárd and Fermi) revealed that several neutrons were also released during the fissioning, making available the opportunity for the nuclear chain reaction that Szilárd had envisioned six years previously.
On 2 August 1939 Albert Einstein signed a letter to President Franklin D. Roosevelt (written by Szilárd) suggesting that the discovery of uranium's fission could lead to the development of "extremely powerful bombs of a new type", giving impetus to the study of reactors and fission. Szilárd and Einstein knew each other well and had worked together years previously, but Einstein had never thought about this possibility for nuclear energy until Szilard reported it to him, at the beginning of his quest to produce the Einstein-Szilárd letter to alert the U.S. government.
Shortly after, Hitler's Germany invaded Poland in 1939, starting World War II in Europe. The U.S. was not yet officially at war, but in October, when the Einstein-Szilárd letter was delivered to him, Roosevelt commented that the purpose of doing the research was to make sure "the Nazis don't blow us up." The U.S. nuclear project followed, although with some delay as there remained skepticism (some of it from Fermi) and also little action from the small number of officials in the government who were initially charged with moving the project forward.
The following year the U.S. Government received the Frisch–Peierls memorandum from the UK, which stated that the amount of uranium needed for a chain reaction was far lower than had previously been thought. The memorandum was a product of the MAUD Committee, which was working on the UK atomic bomb project, known as Tube Alloys, later to be subsumed within the Manhattan Project.
Eventually, the first artificial nuclear reactor, Chicago Pile-1, was constructed at the University of Chicago, by a team led by Enrico Fermi, in late 1942. By this time, the program had been pressured for a year by U.S. entry into the war. The Chicago Pile achieved criticality on 2 December 1942 at 3:25 PM. The reactor support structure was made of wood, which supported a pile (hence the name) of graphite blocks, embedded in which was natural uranium-oxide 'pseudospheres' or 'briquettes'.
Soon after the Chicago Pile, the U.S. military developed a number of nuclear reactors for the Manhattan Project starting in 1943. The primary purpose for the largest reactors (located at the Hanford Site in Washington state), was the mass production of plutonium for nuclear weapons. Fermi and Szilard applied for a patent on reactors on 19 December 1944. Its issuance was delayed for 10 years because of wartime secrecy.
"World's first nuclear power plant" is the claim made by signs at the site of the EBR-I, which is now a museum near Arco, Idaho. Originally called "Chicago Pile-4", it was carried out under the direction of Walter Zinn for Argonne National Laboratory. This experimental LMFBR operated by the U.S. Atomic Energy Commission produced 0.8 kW in a test on 20 December 1951 and 100 kW (electrical) the following day, having a design output of 200 kW (electrical).
Besides the military uses of nuclear reactors, there were political reasons to pursue civilian use of atomic energy. U.S. President Dwight Eisenhower made his famous Atoms for Peace speech to the UN General Assembly on 8 December 1953. This diplomacy led to the dissemination of reactor technology to U.S. institutions and worldwide.
The first nuclear power plant built for civil purposes was the AM-1 Obninsk Nuclear Power Plant, launched on 27 June 1954 in the Soviet Union. It produced around 5 MW (electrical).
After World War II, the U.S. military sought other uses for nuclear reactor technology. Research by the Army and the Air Force never came to fruition; however, the U.S. Navy succeeded when they steamed the USS "Nautilus" (SSN-571) on nuclear power 17 January 1955.
The first commercial nuclear power station, Calder Hall in Sellafield, England was opened in 1956 with an initial capacity of 50 MW (later 200 MW).
The first portable nuclear reactor "Alco PM-2A" used to generate electrical power (2 MW) for Camp Century from 1960.
Components.
The key components common to most types of nuclear power plants are:
Reactor types.
Classifications.
Nuclear Reactors are classified by several methods; a brief outline of these classification methods is provided.
Classification by type of nuclear reaction.
Nuclear fission.
All commercial power reactors are based on nuclear fission. They generally use uranium and its product plutonium as nuclear fuel, though a thorium fuel cycle is also possible. Fission reactors can be divided roughly into two classes, depending on the energy of the neutrons that sustain the fission chain reaction:
Nuclear fusion.
Fusion power is an experimental technology, generally with hydrogen as fuel. While not suitable for power production, Farnsworth-Hirsch fusors are used to produce neutron radiation.
Classification by moderator material.
Used by thermal reactors:
Classification by generation.
In 2003, the French Commissariat à l'Énergie Atomique (CEA) was the first to refer to "Gen II" types in Nucleonics Week.
The first mentioning of "Gen III" was in 2000, in conjunction with the launch of the Generation IV International Forum (GIF) plans.
"Gen IV" was named in 2000, by the United States Department of Energy (DOE) for developing new plant types.
Future and developing technologies.
Advanced reactors.
More than a dozen advanced reactor designs are in various stages of development. Some are evolutionary from the PWR, BWR and PHWR designs above, some are more radical departures. The former include the advanced boiling water reactor (ABWR), two of which are now operating with others under construction, and the planned passively safe Economic Simplified Boiling Water Reactor (ESBWR) and AP1000 units (see Nuclear Power 2010 Program).
Generation IV reactors.
Generation IV reactors are a set of theoretical nuclear reactor designs currently being researched. These designs are generally not expected to be available for commercial construction before 2030. Current reactors in operation around the world are generally considered second- or third-generation systems, with the first-generation systems having been retired some time ago. Research into these reactor types was officially started by the Generation IV International Forum (GIF) based on eight technology goals. The primary goals being to improve nuclear safety, improve proliferation resistance, minimize waste and natural resource utilization, and to decrease the cost to build and run such plants.
Generation V+ reactors.
Generation V reactors are designs which are theoretically possible, but which are not being actively considered or researched at present. Though such reactors could be built with current or near term technology, they trigger little interest for reasons of economics, practicality, or safety.
Fusion reactors.
Controlled nuclear fusion could in principle be used in fusion power plants to produce power without the complexities of handling actinides, but significant scientific and technical obstacles remain. Several fusion reactors have been built, but only recently reactors have been able to release more energy than the amount of energy used in the process. Despite research having started in the 1950s, no commercial fusion reactor is expected before 2050. The ITER project is currently leading the effort to harness fusion power.
Nuclear fuel cycle.
Thermal reactors generally depend on refined and enriched uranium. Some nuclear reactors can operate with a mixture of plutonium and uranium (see MOX). The process by which uranium ore is mined, processed, enriched, used, possibly reprocessed and disposed of is known as the nuclear fuel cycle.
Under 1% of the uranium found in nature is the easily fissionable U-235 isotope and as a result most reactor designs require enriched fuel.
Enrichment involves increasing the percentage of U-235 and is usually done by means of gaseous diffusion or gas centrifuge. The enriched result is then converted into uranium dioxide powder, which is pressed and fired into pellet form. These pellets are stacked into tubes which are then sealed and called fuel rods. Many of these fuel rods are used in each nuclear reactor.
Most BWR and PWR commercial reactors use uranium enriched to about 4% U-235, and some commercial reactors with a high neutron economy do not require the fuel to be enriched at all (that is, they can use natural uranium). According to the International Atomic Energy Agency there are at least 100 research reactors in the world fueled by highly enriched (weapons-grade/90% enrichment uranium). Theft risk of this fuel (potentially used in the production of a nuclear weapon) has led to campaigns advocating conversion of this type of reactor to low-enrichment uranium (which poses less threat of proliferation).
Fissile U-235 and non-fissile but fissionable and fertile U-238 are both used in the fission process. U-235 is fissionable by thermal (i.e. slow-moving) neutrons. A thermal neutron is one which is moving about the same speed as the atoms around it. Since all atoms vibrate proportionally to their absolute temperature, a thermal neutron has the best opportunity to fission U-235 when it is moving at this same vibrational speed. On the other hand, U-238 is more likely to capture a neutron when the neutron is moving very fast. This U-239 atom will soon decay into plutonium-239, which is another fuel. Pu-239 is a viable fuel and must be accounted for even when a highly enriched uranium fuel is used. Plutonium fissions will dominate the U-235 fissions in some reactors, especially after the initial loading of U-235 is spent. Plutonium is fissionable with both fast and thermal neutrons, which make it ideal for either nuclear reactors or nuclear bombs.
Most reactor designs in existence are thermal reactors and typically use water as a neutron moderator (moderator means that it slows down the neutron to a thermal speed) and as a coolant. But in a fast breeder reactor, some other kind of coolant is used which will not moderate or slow the neutrons down much. This enables fast neutrons to dominate, which can effectively be used to constantly replenish the fuel supply. By merely placing cheap unenriched uranium into such a core, the non-fissionable U-238 will be turned into Pu-239, "breeding" fuel.
In thorium fuel cycle thorium-232 absorbs a neutron in either a fast or thermal reactor. The thorium-233 beta decays to protactinium-233 and then to uranium-233, which in turn is used as fuel. Hence, like uranium-238, thorium-232 is a fertile material.
Fueling of nuclear reactors.
The amount of energy in the reservoir of nuclear fuel is frequently expressed in terms of "full-power days," which is the number of 24-hour periods (days) a reactor is scheduled for operation at full power output for the generation of heat energy. The number of full-power days in a reactor's operating cycle (between refueling outage times) is related to the amount of fissile uranium-235 (U-235) contained in the fuel assemblies at the beginning of the cycle. A higher percentage of U-235 in the core at the beginning of a cycle will permit the reactor to be run for a greater number of full-power days.
At the end of the operating cycle, the fuel in some of the assemblies is "spent" and is discharged and replaced with new (fresh) fuel assemblies, although in practice it is the buildup of reaction poisons in nuclear fuel that determines the lifetime of nuclear fuel in a reactor. Long before all possible fission has taken place, the buildup of long-lived neutron absorbing fission byproducts impedes the chain reaction. The fraction of the reactor's fuel core replaced during refueling is typically one-fourth for a boiling-water reactor and one-third for a pressurized-water reactor. The disposition and storage of this spent fuel is one of the most challenging aspects of the operation of a commercial nuclear power plant. This nuclear waste is highly radioactive and its toxicity presents a danger for thousands of years.
Not all reactors need to be shut down for refueling; for example, pebble bed reactors, RBMK reactors, molten salt reactors, Magnox, AGR and CANDU reactors allow fuel to be shifted through the reactor while it is running. In a CANDU reactor, this also allows individual fuel elements to be situated within the reactor core that are best suited to the amount of U-235 in the fuel element.
The amount of energy extracted from nuclear fuel is called its burnup, which is expressed in terms of the heat energy produced per initial unit of fuel weight. Burn up is commonly expressed as megawatt days thermal per metric ton of initial heavy metal.
Safety.
Nuclear safety covers the actions taken to prevent nuclear and radiation accidents or to limit their consequences. The nuclear power industry has improved the safety and performance of reactors, and has proposed new safer (but generally untested) reactor designs but there is no guarantee that the reactors will be designed, built and operated correctly. Mistakes do occur and the designers of reactors at Fukushima in Japan did not anticipate that a tsunami generated by an earthquake would disable the backup systems that were supposed to stabilize the reactor after the earthquake, despite multiple warnings by the NRG and the Japanese nuclear safety administration. According to UBS AG, the Fukushima I nuclear accidents have cast doubt on whether even an advanced economy like Japan can master nuclear safety. Catastrophic scenarios involving terrorist attacks are also conceivable. An interdisciplinary team from MIT has estimated that given the expected growth of nuclear power from 2005–2055, at least four serious nuclear accidents would be expected in that period.
Accidents.
Some serious nuclear and radiation accidents have occurred. Nuclear power plant accidents include the SL-1 accident (1961), the Three Mile Island accident (1979), Chernobyl disaster (1986), and the Fukushima Daiichi nuclear disaster (2011). Nuclear-powered submarine mishaps include the K-19 reactor accident (1961), the K-27 reactor accident (1968), and the K-431 reactor accident (1985).
Nuclear reactors have been launched into Earth orbit at least 34 times. A number of incidents connected with the unmanned nuclear-reactor-powered Soviet RORSAT radar satellite program resulted in spent nuclear fuel re-entering the Earth's atmosphere from orbit.
Natural nuclear reactors.
Although nuclear fission reactors are often thought of as being solely a product of modern technology, the first nuclear fission reactors were in fact naturally occurring. A natural nuclear fission reactor can occur under certain circumstances that mimic the conditions in a constructed reactor. Fifteen natural fission reactors have so far been found in three separate ore deposits at the Oklo uranium mine in Gabon, West Africa. First discovered in 1972 by French physicist Francis Perrin, they are collectively known as the Oklo Fossil Reactors. Self-sustaining nuclear fission reactions took place in these reactors approximately 1.5 billion years ago, and ran for a few hundred thousand years, averaging 100 kW of power output during that time. The concept of a natural nuclear reactor was theorized as early as 1956 by Paul Kuroda at the University of Arkansas.
Such reactors can no longer form on Earth: radioactive decay over this immense time span has reduced the proportion of U-235 in naturally occurring uranium to below the amount required to sustain a chain reaction.
The natural nuclear reactors formed when a uranium-rich mineral deposit became inundated with groundwater that acted as a neutron moderator, and a strong chain reaction took place. The water moderator would boil away as the reaction increased, slowing it back down again and preventing a meltdown. The fission reaction was sustained for hundreds of thousands of years.
These natural reactors are extensively studied by scientists interested in geologic radioactive waste disposal. They offer a case study of how radioactive isotopes migrate through the Earth's crust. This is a significant area of controversy as opponents of geologic waste disposal fear that isotopes from stored waste could end up in water supplies or be carried into the environment.

</doc>
