<doc id="21869" url="https://en.wikipedia.org/wiki?curid=21869" title="Neutron star">
Neutron star

A neutron star is a type of compact star. Neutron stars are the smallest and densest stars known to exist in the Universe. With a radius of only about 11–11.5 km (7 miles), they can, however, have a mass of about twice that of the Sun. They can result from the gravitational collapse of a massive star that produces a supernova. Neutron stars are composed almost entirely of neutrons, which are subatomic particles with no net electrical charge and with slightly larger mass than protons. They are supported against further collapse by quantum degeneracy pressure due to the phenomenon described by the Pauli exclusion principle. Neutron stars are very hot and typically have a surface temperature around . They are so dense that a normal-sized matchbox containing neutron-star material would have a mass of approximately 5 trillion tons, or 1000 km3 of Earth rock. They have strong magnetic fields, between 108 and 1015 times as strong as that of Earth. The gravitational field at the star's surface is about 2×1011 times stronger than on Earth.
Neutron stars rotate, and can emit beams of electromagnetic radiation that are detected as pulsars. Indeed, the discovery of pulsars in 1967 first suggested that neutron stars exist. The radiation from pulsars is thought to be primarily ejected from regions near their magnetic poles. If their magnetic poles do not coincide with rotational axis of the star, it will lead to pulsations of radiation towards Earth when their magnetic poles point towards Earth during their rotation. The rotation of neutron stars can be very rapid; up to 716 times a second has been detected, which is approximately 43,000 revolutions per minute, giving a linear speed at the surface on the order of .
There are thought to be around 100 million neutron stars in the Milky Way, a figure obtained by estimating the number of stars that have gone supernova. However, most are old and cold, and neutron stars can only be easily detected in certain instances, such as if they are a pulsar or part of a binary system. Non-rotating and non-accreting neutron stars are virtually undetectable; however, the "Hubble Space Telescope" has observed one thermally radiating neutron star, called RX J185635-3754. Gamma-ray bursts may be produced from rapidly rotating high-mass stars that collapse to form a neutron star, or from the merger of binary neutron stars. Soft gamma repeaters are conjectured to be a type of neutron star known as a magnetars, or alternatively neutron stars with fossil disks around them.
Formation.
Any main-sequence star with an initial mass of above has the potential to become a neutron star. As the star evolves away from the main sequence, subsequent nuclear burning produces an iron-rich core. When all nuclear fuel in the core has been exhausted, the core must be supported by degeneracy pressure alone. Further deposits of mass from shell burning cause the core to exceed the Chandrasekhar limit. Electron-degeneracy pressure is overcome and the core collapses further, sending temperatures soaring to over . At these temperatures, photodisintegration (the breaking up of iron nuclei into alpha particles by high-energy gamma rays) occurs. As the temperature climbs even higher, electrons and protons combine to form neutrons via electron capture, releasing a flood of neutrinos. When densities reach nuclear density of , neutron degeneracy pressure halts the contraction. The infalling outer atmosphere of the star is halted and flung outwards by a flux of neutrinos created in the creation of the neutrons, becoming a Type II or Type Ib supernova. The remnant left is a neutron star. If the remnant has a mass greater than about , it collapses further to become a black hole. Other neutron stars are formed within close binaries.
As the core of a massive star is compressed during a Type II, Type Ib or Type Ic supernova, and collapses into a neutron star, it retains most of its angular momentum. Because it has only a tiny fraction of its parent's radius (and therefore its moment of inertia is sharply reduced), a neutron star is formed with very high rotation speed, and then gradually slows down. Neutron stars are known that have rotation periods from about 1.4 ms to 30 s. The neutron star's density also gives it very high surface gravity, with typical values ranging from 1012 to 1013 m/s2 (more than 1011 times that of Earth). One measure of such immense gravity is the fact that neutron stars have an escape velocity ranging from 100,000 km/s to 150,000 km/s, that is, from a third to half the speed of light. Matter falling onto the surface of a neutron star would be accelerated to tremendous speed by the star's gravity. The force of impact would likely destroy the object's component atoms, rendering all its matter identical, in most respects, to the rest of the star.
Properties.
Mass and temperature.
A neutron star has a mass of at least 1.1 and perhaps up to 3 solar masses (). The maximum observed mass of neutron stars is about PSR J0348+0432. But in general, compact stars of less than (the Chandrasekhar limit) are white dwarfs, whereas compact stars with a mass between and (the Tolman–Oppenheimer–Volkoff limit) should be neutron stars. Between and , hypothetical intermediate-mass stars such as quark stars and electroweak stars have been proposed, but none have been shown to exist. Beyond the star will overcome the neutron degeneracy pressure and gravitational collapse will usually occur to produce a black hole, though the smallest observed mass of a stellar black hole is about .
The temperature inside a newly formed neutron star is from around 1011 to 1012 kelvin. However, the huge number of neutrinos it emits carry away so much energy that the temperature falls within a few years to around 106 kelvin. Even at 1 million kelvin, most of the light generated by a neutron star is in X-rays.
Density and pressure.
Neutron stars have overall densities of to ( to times the density of the Sun), which is comparable to the approximate density of an atomic nucleus of . The neutron star's density varies from about in the crust—increasing with depth—to about or (denser than an atomic nucleus) deeper inside. A neutron star is so dense that one teaspoon (5 milliliters) of its material would have a mass over (that is 1100 tonnes per 1 nanolitre), about 900 times the mass of the Great Pyramid of Giza.
The equations of state of matter at such high densities are not precisely known because of the theoretical and empirical difficulties; see quantum gravity.
The pressure increases from 3×1033 to 1.6×1035 Pa from the inner crust to the center.
Giant nucleus.
A neutron star has some of the properties of an atomic nucleus, including density (within an order of magnitude) and being composed of nucleons. In popular scientific writing, neutron stars are therefore sometimes described as giant nuclei. However, in other respects, neutron stars and atomic nuclei are quite different. In particular, a nucleus is held together by the strong interaction, whereas a neutron star is held together by gravity, and thus the density and structure of neutron stars is more variable. It is generally more useful to consider such objects as stars.
Magnetic field.
Neutron stars have strong magnetic fields. The magnetic field strength on the surface of neutron stars have been estimated at least to have the range of 108 to 1015 gauss (104 to 1011 tesla). In comparison, the magnitude at Earth's surface ranges from 25 to 65 microteslas (0.25 to 0.65 gauss), making the field at least 108 times as strong as that of Earth. Variations in magnetic field strengths are most likely the main factor that allows different types of neutron stars to be distinguished by their spectra, and explains the periodicity of pulsars. The neutron stars known as magnetars have the strongest magnetic fields, in the range of 108 to 1011 tesla, and have become the widely accepted hypothesis for neutron star types soft gamma repeaters (SGRs) and anomalous X-ray pulsars (AXPs).
The origins of the strong magnetic field are as yet unclear. One hypothesis is that of "flux freezing", or conservation of the original magnetic flux takes place during the formation of the neutron star. If an object has a certain magnetic flux over its surface area, and that area shrinks to a smaller area, but the magnetic flux is conserved, then the magnetic field would correspondingly increase. Likewise, a collapsing star begins with a much larger surface area than the resulting neutron star, and conservation of magnetic flux would result in a far stronger magnetic field. However, this simple explanation does not fully explain magnetic field strengths of neutron stars.
Gravity and equation of state.
The gravitational field at the star's surface is about 2 times stronger than on Earth. Such a strong gravitational field acts as a gravitational lens and bends the radiation emitted by the star such that parts of the normally invisible rear surface become visible.
If the radius of the neutron star is formula_1 or less, then the photons may be trapped in an orbit, thus making the whole surface of that neutron star visible, along with destabilizing orbits at that and less than that of the radius.
A fraction of the mass of a star that collapses to form a neutron star is released in the supernova explosion from which it forms (from the law of mass-energy equivalence, ). The energy comes from the gravitational binding energy of a neutron star.
Hence, the gravitational force of a typical neutron star is such that if an object were to fall from a height of one meter, it would only take one microsecond to hit the surface of the neutron star, and would do so at around 2000 kilometers per second, or 7.2 million kilometers per hour.
Because of the enormous gravity, time dilation between a neutron star and Earth is significant. For example, eight years could pass on the surface of a neutron star, yet ten years would have passed on Earth.
Neutron star relativistic equations of state describe the relation of radius vs. mass for various models. The most likely radii for a given neutron star mass are bracketed by models AP4 (smallest radius) and MS2 (largest radius). BE is the ratio of gravitational binding energy mass equivalent to the observed neutron star gravitational mass of "M" kilograms with radius "R" meters,
Given current values
and star masses "M" commonly reported as multiples of one solar mass,
then the relativistic fractional binding energy of a neutron star is
A neutron star would not be more compact than 10,970 meters radius (AP4 model). Its mass fraction gravitational binding energy would then be 0.187, −18.7% (exothermic). This is not near 0.6/2 = 0.3, −30%.
The equation of state for a neutron star is still not known. It is assumed that it differs significantly from that of a white dwarf, whose equation of state is that of a degenerate gas that can be described in close agreement with special relativity. However, with a neutron star the increased effects of general relativity can no longer be ignored. Several equations of state have been proposed (FPS, UU, APR, L, SLy, and others) and current research is still attempting to constrain the theories to make predictions of neutron star matter. This means that the relation between density and mass is not fully known, and this causes uncertainties in radius estimates. For example, a neutron star could have a radius of 10.7, 11.1, 12.1 or 15.1 kilometres (for EOS FPS, UU, APR or L respectively).
Structure.
Current understanding of the structure of neutron stars is defined by existing mathematical models, but it might be possible to infer some details through studies of neutron-star oscillations. Asteroseismology, a study applied to ordinary stars, can reveal the inner structure of neutron stars by analyzing observed spectra of stellar oscillations.
Current models indicate that matter at the surface of a neutron star is composed of ordinary atomic nuclei crushed into a solid lattice with a sea of electrons flowing through the gaps between them. It is possible that the nuclei at the surface are iron, due to iron's high binding energy per nucleon. It is also possible that heavy elements, such as iron, simply sink beneath the surface, leaving only light nuclei like helium and hydrogen. If the surface temperature exceeds 106 kelvin (as in the case of a young pulsar), the surface should be fluid instead of the solid phase that might exist in cooler neutron stars (temperature <106 kelvin).
The "atmosphere" of a neutron star is hypothesized to be at most several micrometers thick, and its dynamic is fully controlled by the star's magnetic field. Below the atmosphere one encounters a solid "crust". This crust is extremely hard and very smooth (with maximum surface irregularities of ~5 mm), due to the extreme gravitational field. The expected hierarchy of phases of nuclear matter in the inner crust has been characterized as nuclear pasta.
Proceeding inward, one encounters nuclei with ever increasing numbers of neutrons; such nuclei would decay quickly on Earth, but are kept stable by tremendous pressures. As this process continues at increasing depths, the neutron drip becomes overwhelming, and the concentration of free neutrons increases rapidly. In that region, there are nuclei, free electrons, and free neutrons. The nuclei become increasingly small (gravity and pressure overwhelming the strong force) until the core is reached, by definition the point where mostly neutrons exist.
The composition of the superdense matter in the core remains uncertain. One model describes the core as superfluid neutron-degenerate matter (mostly neutrons, with some protons and electrons). More exotic forms of matter are possible, including degenerate strange matter (containing strange quarks in addition to up and down quarks), matter containing high-energy pions and kaons in addition to neutrons, or ultra-dense quark-degenerate matter.
Radiation.
Pulsars.
Neutron stars are detected from their electromagnetic radiation. Neutron stars are usually observed to "pulse" radio waves and other radiation, and neutron stars observed with pulses are called pulsars. Their radiation is believed to be caused by particle acceleration near their magnetic poles, which need not be aligned with the rotation axis of the star. Through mechanisms not yet entirely understood, these particles produce coherent beams of radio emission. External viewers see these beams as pulses of radiation whenever the magnetic pole sweeps past the line of sight. The pulses come at the same rate as the rotation of the neutron star, and thus appear periodic.
Non-pulsating neutron stars.
In addition to pulsars, neutron stars have also been identified with no apparent periodicity of their radiation. This seems to be the case for x-ray sources known as Central Compact Objects in Supernova remnants (CCOs in SNRs), which are thought to be young, radio-quiet Isolated Neutron Stars.
Spectra.
In addition to radio emissions, neutron stars have also been identified in other parts of the electromagnetic spectrum. This includes visible light (including near infrared and ultraviolet), x-rays and gamma rays. Pulsars observed in x-rays are known as x-ray pulsars, while those identified in visible light as optical pulsars. The majority of neutron stars detected, including those identified in optical, x-ray and gamma rays, also emit radio waves; the Crab Pulsar produces electromagnetic emissions across the spectrum. However, there exist neutron stars called radio-quiet neutron stars, with no radio emissions detected.
Rotation.
Neutron stars rotate extremely rapidly after their formation due to the conservation of angular momentum; like spinning ice skaters pulling in their arms, the slow rotation of the original star's core speeds up as it shrinks. A newborn neutron star can rotate many times a second.
Spin down.
Over time, neutron stars slow, as their rotating magnetic fields in effect radiate energy associated with the rotation; older neutron stars may take several seconds for each revolution. This is called "spin down". The rate at which a neutron star slows its rotation is usually constant and very small.
The periodic time (P) is the rotational period, the time for one rotation of a neutron star. The spin-down rate, the rate of slowing of rotation, is then given the symbol formula_9 (or Pdot), the negative derivative of P with respect to time. It is defined as periodic time decrease per unit time; it is a dimensionless quantity, but can be given the units of s·s−1 (seconds per second).
The spin-down rate (Pdot) of neutron stars usually falls within the range of 10−22 to 10−9 s·s−1, with the shorter period (or faster rotating) observable neutron stars usually having smaller Pdot. However, as a neutron star ages, the neutron star slows (P increases) and the rate of slowing decreases (Pdot decreases), until the rate of rotation becomes too slow to power the radio emission mechanism, and the star disappears from view.
P and Pdot allow minimum magnetic fields of neutron stars to be estimated. P and Pdot can be also used to calculate the "characteristic age" of a pulsar, but gives an estimate which is somewhat larger than the true age when it is applied to young pulsars.
P and Pdot can also be combined with neutron star's moment of inertia to estimate a quantity called "spin-down luminosity", which is given the symbol formula_10. It is not the measured luminosity, but rather the calculated loss rate of rotational energy that would manifest itself as radiation. For neutron stars where the spin-down luminosity equals the actual luminosity, the neutron stars are said to be "rotation powered". The observed luminosity of the Crab Pulsar is comparable to the spin-down luminosity, supporting the model that rotational kinetic energy powers the radiation from it. With neutron stars such as magnetars, where the actual luminosity exceeds the spin-down luminosity by about a factor of one hundred, it is assumed that the luminosity is powered by magnetic dissipation rather than rotation powered.
P and Pdot can also be plotted for neutron stars to create a P-Pdot diagram. It encodes a tremendous amount of information about the pulsar population and its properties, and has been likened to the Hertzsprung–Russell diagram in its importance for neutron stars.
Spin up.
Neutron star rotational speeds can increase, a process known as spin up. Sometimes neutron stars absorbs orbiting matter from companion stars, increasing the rotation rate and reshaping the neutron star into an oblate spheroid. This causes an increase in the rate of rotation of the star of over a hundred times per second in the case of millisecond pulsars.
The most rapidly rotating neutron star currently known, PSR J1748-2446ad, rotates at 716 rotations per second. However, a recent paper reported the detection of an X-ray burst oscillation, which provides an indirect measure of spin, of 1122 Hz from the neutron star XTE J1739-285, suggesting 1122 rotations a second. However, at present, this signal has only been seen once, and should be regarded as tentative until confirmed in another burst from that star.
Glitches and starquakes.
Sometimes a neutron star will undergo a glitch, a sudden small increase of its rotational speed or spin up of the neutron star. Glitches are thought to be the effect of a starquake — as the rotation of the star slows, its shape becomes more spherical. Due to the stiffness of the "neutron" crust, this happens as discrete events when the crust ruptures, creating a starquake similar to tectonic earthquakes. After the starquake, the star will have a smaller equatorial radius, and because angular momentum is conserved, its rotational speed has increased.
Starquakes occurring in magnetars, with a resulting glitch, is the leading hypothesis for the gamma-ray sources known as soft gamma repeaters. 
Recent work, however, suggests that a starquake would not release sufficient energy for a neutron star glitch; it has been suggested that glitches may instead be caused by transitions of vortices in the superfluid core of the star from one metastable energy state to a lower one thereby releasing energy that appears as an increase in the rotation rate.
"Anti-glitches".
An "anti-glitch", a sudden small decrease in rotational speed, or spin down, of a neutron star has also been reported. It occurred in a magnetar, that in one case produced an X-ray luminosity increase of a factor of 20, and a significant spin-down rate change. Current neutron star models do not predict this behavior. If the cause was internal, it suggests differential rotation of solid outer crust and the superfluid component of the inner of the magnetar's structure.
Population and distances.
At present, there are about 2000 known neutron stars in the Milky Way and the Magellanic Clouds, the majority of which have been detected as radio pulsars. Neutron stars are mostly concentrated along the disk of the Milky Way although the spread perpendicular to the disk is large because the supernova explosion process can impart high translational speeds (400 km/s) to the newly formed neutron star.
Some of the closest neutron stars are RX J1856.5-3754 about 400 light years away and PSR J0108-1431 at about 424 light years. RX J1856.5-3754 is a member of a close group of neutron stars called The Magnificent Seven. Another nearby neutron star that was detected transiting the backdrop of the constellation Ursa Minor has been nicknamed Calvera by its Canadian and American discoverers, after the villain in the 1960 film "The Magnificent Seven". This rapidly moving object was discovered using the ROSAT/Bright Source Catalog.
Binary neutron star systems.
About 5% of all known neutron stars are members of a binary system. The formation and evolution scenario of binary neutron stars is a rather exotic and complicated process. The companion stars may be either ordinary stars, white dwarfs or other neutron stars. According to modern theories of binary evolution it is expected that neutron stars also exist in binary systems with black hole companions. Such binaries are expected to be prime sources for the emission of detectable gravitational waves. Neutron stars in binary systems often emit X-rays, caused when material (gas) is pulled from a companion star and heated as it accretes onto the surface of the neutron star. Material from the outer layers of a (bloated) companion star is sucked towards the neutron star as a result of its very strong gravitational field. As a result of this process, binary neutron stars may also collapse into black holes if the accretion of mass takes place under extreme conditions. It has been proposed that the coalescence of binary neutron stars may be responsible for producing short gamma-ray bursts.
Neutron star collision and nucleosynthesis.
It has been suggested that gold and other heavy elements are created from the collision of neutron stars. Such events may also be responsible for the production of all chemical elements beyond iron, as opposed to the supernova nucleosynthesis theory.
History of discoveries.
In 1934, Walter Baade and Fritz Zwicky proposed the existence of neutron stars, only a year after the discovery of the neutron by Sir James Chadwick. In seeking an explanation for the origin of a supernova, they tentatively proposed that in supernova explosions ordinary stars are turned into stars that consist of extremely closely packed neutrons that they called neutron stars. Baade and Zwicky correctly proposed at that time that the release of the gravitational binding energy of the neutron stars powers the supernova: "In the supernova process, mass in bulk is annihilated". Neutron stars were thought to be too faint to be detectable and little work was done on them until November 1967, when Franco Pacini (1939–2012) pointed out that if the neutron stars were spinning and had large magnetic fields, then electromagnetic waves would be emitted. Unbeknown to him, radio astronomer Antony Hewish and his research assistant Jocelyn Bell at Cambridge were shortly to detect radio pulses from stars that are now believed to be highly magnetized, rapidly spinning neutron stars, known as pulsars.
In 1965, Antony Hewish and Samuel Okoye discovered "an unusual source of high radio brightness temperature in the Crab Nebula". This source turned out to be the Crab Pulsar that resulted from the great supernova of 1054.
In 1967, Iosif Shklovsky examined the X-ray and optical observations of Scorpius X-1 and correctly concluded that the radiation comes from a neutron star at the stage of accretion.
In 1967, Jocelyn Bell Burnell and Antony Hewish discovered regular radio pulses from PSR B1919+21. This pulsar was later interpreted as an isolated, rotating neutron star. The energy source of the pulsar is the rotational energy of the neutron star. The majority of known neutron stars (about 2000, as of 2010) have been discovered as pulsars, emitting regular radio pulses.
In 1971, Riccardo Giacconi, Herbert Gursky, Ed Kellogg, R. Levinson, E. Schreier, and H. Tananbaum discovered 4.8 second pulsations in an X-ray source in the constellation Centaurus, Cen X-3. They interpreted this as resulting from a rotating hot neutron star. The energy source is gravitational and results from a rain of gas falling onto the surface of the neutron star from a companion star or the interstellar medium.
In 1974, Antony Hewish was awarded the Nobel Prize in Physics "for his decisive role in the discovery of pulsars" without Jocelyn Bell who shared in the discovery.
In 1974, Joseph Taylor and Russell Hulse discovered the first binary pulsar, PSR B1913+16, which consists of two neutron stars (one seen as a pulsar) orbiting around their center of mass. Einstein's general theory of relativity predicts that massive objects in short binary orbits should emit gravitational waves, and thus that their orbit should decay with time. This was indeed observed, precisely as general relativity predicts, and in 1993, Taylor and Hulse were awarded the Nobel Prize in Physics for this discovery.
In 1982, Don Backer and colleagues discovered the first millisecond pulsar, PSR B1937+21. This objects spins 642 times per second, a value that placed fundamental constraints on the mass and radius of neutron stars. Many millisecond pulsars were later discovered, but PSR B1937+21 remained the fastest-spinning known pulsar for 24 years, until PSR J1748-2446ad (which spins more than 700 times a second) was discovered.
In 2003, Marta Burgay and colleagues discovered the first double neutron star system where both components are detectable as pulsars, PSR J0737-3039. The discovery of this system allows a total of 5 different tests of general relativity, some of these with unprecedented precision.
In 2010, Paul Demorest and colleagues measured the mass of the millisecond pulsar PSR J1614–2230 to be , using Shapiro delay. This was substantially higher than any previously measured neutron star mass (, see PSR J1903+0327), and places strong constraints on the interior composition of neutron stars.
In 2013, John Antoniadis and colleagues measured the mass of PSR J0348+0432 to be , using white dwarf spectroscopy. This confirmed the existence of such massive stars using a different method. Furthermore, this allowed, for the first time, a test of general relativity using such
a massive neutron star.

</doc>
<doc id="21871" url="https://en.wikipedia.org/wiki?curid=21871" title="Nassau, Bahamas">
Nassau, Bahamas

Nassau is the capital, largest city, and commercial centre of the Commonwealth of the Bahamas. The city has a population of 248,948 (2010 census), 70 percent of the entire population of the Bahamas (353,658). Lynden Pindling International Airport, the major airport for the Bahamas, is located about west of Nassau city centre, and has daily flights to major cities in the United States, the Caribbean, Canada, and the United Kingdom. The city is located on the island of New Providence, which functions much like a business district. Nassau is the site of the House of Assembly and various judicial departments and was considered historically to be a stronghold of pirates. The city was named in honour of William III of England, Prince of Orange-Nassau.
Nassau's modern growth began in the late eighteenth century, with the influx of thousands of American Loyalists and their slaves to the Bahamas following the American Revolutionary War. Many of them settled in Nassau (then and still the commerce capital of the Bahamas) and eventually came to outnumber the original inhabitants.
As the population of Nassau grew, so did its populated areas. Today the city dominates the entire island and its satellite, Paradise Island. However, until the post-Second World War era, the outer suburbs scarcely existed. Most of New Providence was uncultivated bush until Loyalists were resettled there following the American Revolutionary War; they established several plantations, such as Clifton and Tusculum. Slaves were imported as labour.
After the British abolished the international slave trade in 1807, they resettled thousands of Africans liberated from slave ships by the Royal Navy on New Providence (at Adelaide Village and Gambier Village), along with other islands such as Grand Bahama, Exuma, Abaco and Inagua. In addition, slaves freed from American ships, such as the Creole case in 1841, were allowed to settle here. The largest concentration of Africans historically lived in the "Over-the-Hill" suburbs of Grants Town and Bain Town to the south of the city of Nassau, while most of the inhabitants of European descent lived on the island's northern coastal ridges.
History.
Nassau was formerly known as Charles Town; it was burned to the ground by the Spanish in 1684. Rebuilt, and renamed to Nassau in 1695 under Governor Nicholas Trott in honour of the Dutch Stadtholder ("stadhouder" in Dutch) and later also King of England, Scotland and Ireland, William III from the Dutch House of Orange-Nassau. The name Nassau derives from the House of Nassau and ultimately from the town of Nassau, Rhineland-Palatinate in Germany. Due to a lack of effective Governors (after Trott), Nassau fell on hard times. In 1703 Spanish and French allied forces briefly occupied Nassau.
From 1703 to 1718 there was no governor in the colony and by 1713, the sparsely settled Bahamas had become a pirate haven. The Governor of Bermuda stated that there were over 1,000 pirates in Nassau and that they outnumbered the mere hundred inhabitants of the town. They proclaimed Nassau a pirate republic, establishing themselves as "governors." Examples of pirates that used Nassau as their base are Charles Vane, Thomas Barrow, Benjamin Hornigold, Calico Jack Rackham, Anne Bonny, Mary Read, and the infamous Edward Teach, known as "Blackbeard".
In 1718, the British sought to regain control of the islands and appointed Captain Woodes Rogers as Royal governor. He successfully clamped down on the pirates, reformed the civil administration, and restored commerce. Rogers cleaned up Nassau and rebuilt the fort, using his own wealth to try to overcome problems. In 1720 the Spanish made an unsuccessful attempt to capture Nassau.
During the wars in the Thirteen Colonies, Nassau experienced an economic boom. With funds from privateering, a new fort, street lights and over 2300 sumptuous houses were built and Nassau was extended. In addition to this, mosquito breeding swamps were filled.
In 1776 the Battle of Nassau resulted in a brief occupation by American Continental Marines during the American War of Independence, where the Marines staged their first amphibious raid on Fort Montague after attempting to sneak up on Fort Nassau. In 1778 after an overnight invasion, American raiders led by Captain Rathburn, left with ships, gunpowder and military stores after stopping in Nassau for only two days. In 1782 Spain captured Nassau for the last time when Don Juan de Cagigal, governor-general of Cuba, attacked New Providence with 5000 men. Andrew Deveaux, an American Loyalist who resettled on the island, set forth to recapture Nassau with 220 men and 150 muskets to face a force of 600 trained soldiers. Deveaux forced the Spanish to surrender on April 17, 1783, without a single shot fired.
Lord Dunmore governed the colony from 1787 to 1796. He oversaw the construction of Fort Charlotte and Fort Fincastle in Nassau.
During the American Civil War, Nassau served as a port for blockade runners making their way to and from ports along the southern Atlantic Coast for continued trade with the Confederacy.
In the 1920s and 1930s Nassau profited from Prohibition in the United States.
Geography.
Located on New Providence Island, Nassau has an attractive harbour, a colourful blend of old world and colonial architecture, and a busy port. The tropical climate and natural beauty of the Bahamas have made Nassau a popular tourist destination.
Nassau developed directly behind the port area. New Providence provides 200 km² of relatively flat and low-lying land intersected by low ridges (none of which restricted settlement). In the centre of the island there are several shallow lakes that are tidally connected.
The city's proximity to the United States (290 km east-southeast of Miami, Florida) has contributed to its popularity as a holiday resort, especially after the United States imposed a ban on travel to Cuba in 1963. The Atlantis resort on nearby Paradise Island accounts for more tourist arrivals to the city than any other hotel property. The mega-resort employs over 6,000 Bahamians, and is the largest employer outside government.
Climate.
Nassau features a tropical monsoon climate with relatively consistent temperatures throughout the course of the year. Summertime temperatures reach about 32 degrees Celsius (90 degrees Fahrenheit) and the winter months have daytime temperatures between , rarely falling below .
Urban development.
During the 19th century, Nassau became urbanized, attracting rural residents. Growth since the 1950s has been outwards from the town. The 1788 heart of Nassau was just a few blocks of buildings between Government House and the harbour, but the town gradually expanded east to Malcolm's Park, south to Wulff Road, and west to Nassau Street. Grants Town and Bain Town south of the city became the main residential areas for those of African descent, and until about 30 years ago was the most populous part of the city.
Those of European descent built houses along the shore, east as far as Fort Montagu, west as far as Saunders Beach, and along the ridge edging the city. During the 20th century, the city spread east to Village Road and west to Fort Charlotte and Oakes Field. This semicircle of residential development was the main area of settlement until after the Second World War, and marks a distinct phase in the city's expansion, the outer boundary to this zone being the effective limit of the continuous built-up area. The wealthier residents continued to spread east (to East End Point) and West (to Lyford Cay).
In the last 40 years, residential development has been quite different. It has consisted mainly of planned middle-income sub-divisions. Since the 1960s, government has sponsored low-cost housing developments at Yellow Elder, Elizabeth Estates, and Pinewood Gardens, in the outer ring.
Downtown.
Downtown is the hub for all activities in Nassau. Thousands of people visit daily, to shop, dine, sightsee and to enjoy the tropical climate of the city. While the busiest part of Downtown is the Bay Street thoroughfare and the Woodes Rogers Walk, located across the street from the port and parallel to Bay, the area extends for several blocks in each direction. It starts at West Bay, around the Junkanoo Beach area. A few hotels and restaurants are located on West Bay.
The next landmark is the British Colonial Hotel, which marks the beginning of Bay Street proper. Pirates of Nassau Museum is just across from the British Colonial Hilton. The next few blocks of Bay Street are wall-to-wall boutiques, with a few restaurants and clubs interspersed throughout the retailers.
Famous historical landmarks are also in the vicinity, including Vendue House, Christ Church Cathedral, and the Nassau Public Library. Although the tourist part of Downtown peters out after about seven blocks, smaller, more local stores are found all the way down Bay Street. At this point, Bay Street becomes East Bay.
The new Straw Market is also a very busy place on a regular day. After the fire in 2001 it has been rebuilt to a new, more modern look. It consists of four sections that lead to Nassau Harbour in the back. Also in that area are many jewelry shops and bars. A next soon to be tourist hub is Pompey Square.
Cable Beach.
Cable Beach is recognised as the hotel district of Nassau. Five enormous hotels—two of which are all-inclusive—are located on this strip. The area is also known for its dining, the Crystal Palace Casino, and the golden sands of Cable Beach. Most of the area's restaurants are located either in the hotels or across the street. There is little to no nightlife. There is a bit of shopping, most of it located in the Wyndham. The commercial future of Cable Beach is being re-imagined with the development of Baha Mar, a resort and casino project that will bring more than 2,000 hotel rooms and the largest gaming and convention facility in the Caribbean to this section of New Providence Island, but the project has stalled at over 90 percent completion and the developers have declared bankruptcy.
Demographics.
Nassau has a population of 126,500 females and 121,800 males and is home to 59,707 households with an average family size of 4.15 according to the 2000 census. Nassau's large population (at least in relation to the remainder of the Bahamas) is the result of waves of immigration from the Family Islands to the capital. Consequently, this has led to the decline in the population of the lesser developed islands and the rapid growth of Nassau.
Transport.
Air.
Lynden Pindling International Airport (formerly Nassau International Airport) is located from Nassau.
New Providence Airport on Paradise Island was closed in 1999 with runway removed and integrated into the resort on the island.
Water.
Ferrys provide water travel around Nassau to the surrounding islands, namely Paradise Island. Prince George Wharf is the main port in the city that serves cruise ships with ports of call in Nassau. Transportation and shipping around the Family Islands is primarily through mailboats based at Potters Cay. International shipping is done through the Arawak Port Department on Arawak Cay. High speed excursions to Exuma, Spanish Wells and Harbour Island are available daily.
Roads.
Public jitney buses and taxis provide transport in and around Nassau. Rental cars are also available in the city and at the airport.
Major roads in Nassau include:
There are no controlled access highways in Nassau. Both Tonique Williams Darling Highway and Sir Milo Butler Highway are major roadways.
Vehicles in Nassau drive on the left side like in Britain, but many vehicles are imported from the United States with left hand steering wheel.
Culture.
UNESCO Creative Cities Network.
Nassau has been recognized as a part of the UNESCO Creative Cities Network as a city of Crafts and Folk Art. It is one of only two Caribbean cities to receive this honor.
Junkanoo.
The city's chief festival is Junkanoo, an energetic, colourful street parade of brightly costumed people dancing to the rhythmic accompaniment of cowbells, drums and whistles. The word 'Junkanoo' is named after the founder 'John Kanoo'. The celebration occurs on December 26 and January 1, beginning in the early hours of the morning (1:00 a.m.) and ending around 10 a.m.
In popular culture.
Nassau was featured as an important location in several movies, including the Beatles film "Help!" and the James Bond films "Thunderball", (1965) and "Never Say Never Again", (a remake of "Thunderball") (1983) and also for part of the action in "Casino Royale" (2006). In 1981, it was used as a location for the ocean scene (in the film portrayed as being in Greece) in "For Your Eyes Only." Several other late 20th and 21st century movies have been set here, including "After the Sunset", "Into the Blue" (2005), and "Flipper" (1996). It hosted the Miss Universe 2009 pageant. "Black Sails (TV series)". Nassau was featured as a primary location in the 2013 video game "."
Twin towns – Sister cities.
Nassau has six sister cities worldwide:

</doc>
<doc id="21873" url="https://en.wikipedia.org/wiki?curid=21873" title="Nastassja Kinski">
Nastassja Kinski

Nastassja Aglaia Kinski (born 24 January 1961) is a German actress and former model who has appeared in more than sixty films in Europe and the United States. She enjoyed her worldwide breakthrough with "Stay As You Are" (1978), then came to global prominence with her Golden Globe Award-winning performance as the title character in the Roman Polanski–directed film "Tess" (1979). Other notable films in which she acted include the erotic horror "Cat People" (1982), two Wim Wenders dramas "Paris, Texas" (1984) and "Faraway, So Close!" (1993), and "An American Rhapsody" (2001). She is the daughter of the actor Klaus Kinski.
Early life.
Kinski was born in Berlin as Nastassja Aglaia Nakszynski. She is the daughter of the German actor Klaus Kinski and his wife, actress Ruth Brigitte Tocki. She is of part Polish descent. Kinski has two half-siblings; Pola and Nikolai Kinski. Her parents divorced in 1968. After the age of ten, Kinski rarely saw her father. Her mother struggled financially to support them. They eventually lived in a commune in Munich.
In a 1999 interview, Kinski denied that her father had sexually molested her as a child, but said he had abused her "in other ways." In 2013, when interviewed about the allegations of sexual abuse made by her half-sister Pola Kinski, she confirmed that he tried with her, but did not succeed. She said:
Career.
Kinski began working as a model as a teenager in Germany. Actress Lisa Kreuzer of the German New Wave helped get her the role of the dumb "Mignon" in Wim Wenders film "The Wrong Move". In 1976, while still a teenager, Kinski had her first two major roles: in Wolfgang Petersen's feature-film length episode "Reifezeugnis" of the German TV crime series "Tatort." Next she appeared in the British horror film "To the Devil a Daughter" (1976), produced by Hammer Film Productions. In regards to her early films, Kinski has stated that she felt exploited by the industry. In an interview with "W" magazine she said, "If I had had somebody to protect me or if I had felt more secure about myself, I would not have accepted certain things. Nudity things. And inside it was just tearing me apart."
In 1978, Kinski starred in the Italian romance "Stay As You Are" ("Così come sei") with Marcello Mastroianni, gaining her recognition in the United States after New Line Cinema released it there in December 1979. "Time" magazine wrote that she was "simply ravishing, genuinely sexy and high-spirited without being painfully aggressive about it." The film also received a major international release from Columbia Pictures.
Kinski met the director Roman Polanski at a party in 1976. He urged her to study method acting with Lee Strasberg in the United States and she was offered the title role in Polanski's upcoming film, "Tess" (1979). In 1978, Kinski undergone extensive preparation for the portrayal of an English peasant girl, which included acquiring a Dorset accent through elocution studies: 
The film was nominated for six awards, including Best Picture, at the 53rd Academy Awards and won three.
In 1981, Richard Avedon photographed Kinski with a Burmese python coiled around her nude body. The image, which first appeared in the October 1981 issue of US Vogue, was released as a poster and became a best-seller, further confirming her status as a sex symbol.
In 1982, she starred in Francis Ford Coppola's romantic musical "One from the Heart," her first film made in the United States. "Texas Monthly" described her as acting "as a Felliniesque circus performer to represent the twinkling evanescence of Eros." The film failed at the box office and was a major loss for Coppola's new Zoetrope Studios. That year, she was also in the erotic horror movie "Cat People". Dudley Moore's comedy "Unfaithfully Yours" and an adaptation of John Irving's "The Hotel New Hampshire" followed in 1984.
Kinski reteamed with Wenders for the 1984 film "Paris, Texas". One of her most acclaimed films to date, it won the top award at the Cannes Film Festival. Throughout the 1980s, Kinski split her time between Europe and the United States, making "Moon in the Gutter" (1983), "Harem" (1985) and "Torrents of Spring" (1989) in Europe, and "Exposed" (1983), "Maria's Lovers" (1984) and "Revolution" (1985) in the United States.
During the 1990s, Kinski appeared in a number of American films including the action movie "Terminal Velocity", opposite Charlie Sheen; the Mike Figgis 1997 adultery tale "One Night Stand"; "Your Friends & Neighbors" (1998); John Landis' "Susan's Plan" (1998); and "The Lost Son" (1999).
Her most recent films include David Lynch's "Inland Empire" (2006) and Rotimi Rainwater's "Sugar" (2013).
In 2016, she competed in the German Let's Dance show.
Personal life.
Relationships.
In 1976, when Kinski was 15, she reportedly began a romantic relationship with then 43-year-old director Roman Polanski. In a 1999 Guardian interview, the newspaper reports her saying there was categorically no affair and that she said "There was a flirtation. There could have been a seduction, but there was not. He had respect for me."
Marriage and children.
In the mid-1980s Kinski met the Egyptian filmmaker Ibrahim Moussa. They married on 10 September 1984. They have two children together; a son Aljosha (born 1984), and daughter Sonja Kinski (born 1986), who works as a model and actress. The marriage was dissolved in 1992. From 1992 until 1995 Kinski lived with musician Quincy Jones, though she kept her own apartment on Hilgard Avenue, near UCLA, at the time. In 1993 they had a daughter, Kenya Julia Miambi Sarah Jones.
Health.
In 2001, Kinski stated in an interview for the "The Daily Telegraph" she was affected by the sleep disorder narcolepsy.

</doc>
<doc id="21875" url="https://en.wikipedia.org/wiki?curid=21875" title="Nuremberg trials">
Nuremberg trials

The Nuremberg trials (German: "die Nürnberger Prozesse") were a series of military tribunals, held by the Allied forces after World War II, which were most notable for the prosecution of prominent members of the political, military, and economic leadership of Nazi Germany who planned, carried out, or otherwise participated in The Holocaust and other war crimes. The trials were held in the city of Nuremberg, Germany.
The first, and best known of these trials, described as "the greatest trial in history" by Norman Birkett, one of the British judges who presided over it, was the trial of the major war criminals before the International Military Tribunal (IMT). Held between 20 November 1945 and 1 October 1946, the Tribunal was given the task of trying 23 of the most important political and military leaders of the Third Reich, though one of the defendants, Martin Bormann, was tried "in absentia", while another, Robert Ley, committed suicide within a week of the trial's commencement.
Not included were Adolf Hitler, Heinrich Himmler, and Joseph Goebbels, all of whom had committed suicide in the spring of 1945, well before the indictment was signed. Reinhard Heydrich also also not included, as he was assassinated in 1942.
The second set of trials of lesser war criminals was conducted under Control Council Law No. 10 at the U.S. Nuremberg Military Tribunals (NMT), which included the Doctors' Trial and the Judges' Trial. This article primarily deals with the IMT; see Subsequent Nuremberg Trials for details on the NMT (the second set of trials).
Origin.
A precedent for trying those accused of war crimes had been set at the end of World War I in the Leipzig War Crimes Trials held in May to July 1921 before the "Reichsgericht" (German Supreme Court) in Leipzig, although these had been on a very limited scale and largely regarded as ineffectual. At the beginning of 1940, the Polish government-in-exile asked the British and French governments to condemn the German invasion of their country. The British initially declined to do so; however, in April 1940, a joint British-French-Polish declaration was issued. Relatively bland because of Anglo-French reservations, it proclaimed the trio's "desire to make a formal and public protest to the conscience of the world against the action of the German government whom they must hold responsible for these crimes which cannot remain unpunished."
Three-and-a-half years later, the stated intention to punish the Germans was much more trenchant. On 1 November 1943, the Soviet Union, the United Kingdom and the United States published their "Declaration on German Atrocities in Occupied Europe", which gave a "full warning" that, when the Nazis were defeated, the Allies would "pursue them to the uttermost ends of the earth ... in order that justice may be done. ... The above declaration is without prejudice to the case of the major war criminals whose offences have no particular geographical location and who will be punished by a joint decision of the Government of the Allies." This Allied intention to dispense justice was reiterated at the Yalta Conference and at Berlin in 1945.
British War Cabinet documents, released on 2 January 2006, showed that as early as December 1944, the Cabinet had discussed their policy for the punishment of the leading Nazis if captured. British Prime Minister Winston Churchill had then advocated a policy of summary execution in some circumstances, with the use of an Act of Attainder to circumvent legal obstacles, being dissuaded from this only by talks with US and Soviet leaders later in the war.
In late 1943, during the Tripartite Dinner Meeting at the Tehran Conference, the Soviet leader, Joseph Stalin, proposed executing 50,000–100,000 German staff officers. US President Franklin D. Roosevelt joked that perhaps 49,000 would do. Churchill, believing them to be serious, denounced the idea of "the cold blooded execution of soldiers who fought for their country" and that he'd rather be "taken out in the courtyard and shot" himself than partake in any such action. However, he also stated that war criminals must pay for their crimes and that in accordance with the Moscow Document which he himself had written, they should be tried at the places where the crimes were committed. Churchill was vigorously opposed to executions "for political purposes." According to the minutes of a Roosevelt-Stalin meeting at Yalta, on 4 February 1945, at the Livadia Palace, President Roosevelt "said that he had been very much struck by the extent of German destruction in the Crimea and therefore he was more bloodthirsty in regard to the Germans than he had been a year ago, and he hoped that Marshal Stalin would again propose a toast to the execution of 50,000 officers of the German Army."
US Secretary of the Treasury Henry Morgenthau, Jr. suggested a plan for the total denazification of Germany; this was known as the Morgenthau Plan. The plan advocated the forced de-industrialisation of Germany and the summary execution of so-called "arch-criminals", i.e. the major war criminals. Roosevelt initially supported this plan, and managed to convince Churchill to support it in a less drastic form. Later, details were leaked to the public, generating widespread protest. Roosevelt, aware of strong public disapproval, abandoned the plan, but did not adopt an alternative position on the matter. The demise of the Morgenthau Plan created the need for an alternative method of dealing with the Nazi leadership. The plan for the "Trial of European War Criminals" was drafted by Secretary of War Henry L. Stimson and the War Department. Following Roosevelt's death in April 1945, the new president, Harry S. Truman, gave strong approval for a judicial process. After a series of negotiations between Britain, the US, Soviet Union and France, details of the trial were worked out. The trials were to commence on 20 November 1945, in the Bavarian city of Nuremberg.
Creation of the courts.
On 20 April 1942, representatives from the nine countries occupied by Germany met in London to draft the "Inter-Allied Resolution on German War Crimes". At the meetings in Tehran (1943), Yalta (1945) and Potsdam (1945), the three major wartime powers, the United Kingdom, United States, and the Soviet Union, agreed on the format of punishment for those responsible for war crimes during World War II. France was also awarded a place on the tribunal. The legal basis for the trial was established by the London Charter, which was agreed upon by the four so-called Great Powers on 8 August 1945, and which restricted the trial to "punishment of the major war criminals of the European Axis countries"
Some 200 German war crimes defendants were tried at Nuremberg, and 1,600 others were tried under the traditional channels of military justice. The legal basis for the jurisdiction of the court was that defined by the Instrument of Surrender of Germany. Political authority for Germany had been transferred to the Allied Control Council which, having sovereign power over Germany, could choose to punish violations of international law and the laws of war. Because the court was limited to violations of the laws of war, it did not have jurisdiction over crimes that took place before the outbreak of war on 1 September 1939.
Location.
Leipzig and Luxembourg were briefly considered as the location for the trial. The Soviet Union had wanted the trials to take place in Berlin, as the capital city of the 'fascist conspirators', but Nuremberg was chosen as the site for two reasons, with the first one having been the decisive factor:
As a compromise with the Soviets, it was agreed that while the location of the trial would be Nuremberg, Berlin would be the official home of the Tribunal authorities. It was also agreed that France would become the permanent seat of the IMT and that the first trial (several were planned) would take place in Nuremberg. and Thomas J. Dodd, plus young US Army interpreter Richard Sonnenfeldt. Assisting Shawcross were Major Sir David Maxwell-Fyfe and Sir John Wheeler-Bennett. Mervyn Griffith-Jones, who was later to become famous as the chief prosecutor in the "Lady Chatterley's Lover" obscenity trial, was also on Shawcross's team. Shawcross also recruited a young barrister, Anthony Marreco, who was the son of a friend of his, to help the British team with the heavy workload.
Defense counsel.
The vast majority of the defense attorneys were German lawyers. These included Georg Fröschmann, Heinz Fritz (Hans Fritzsche), Otto Kranzbühler (Karl Dönitz), Otto Pannenbecker (Wilhelm Frick), Alfred Thoma (Alfred Rosenberg), Kurt Kauffmann (Ernst Kaltenbrunner), Hans Laternser (general staff and high command), Franz Exner (Alfred Jodl), Alfred Seidl (Hans Frank), Otto Stahmer (Hermann Göring), Walter Ballas (Gustav Krupp von Bohlen und Halbach), Hans Flächsner (Albert Speer), Günther von Rohrscheidt (Rudolf Heß), Egon Kubuschok (Franz von Papen), Robert Servatius (Fritz Sauckel), Fritz Sauter (Joachim von Ribbentrop), Walther Funk (Baldur von Schirach), Hanns Marx (Julius Streicher), Otto Nelte (Wilhelm Keitel), and Herbert Kraus / Rudolph Dix (both working for Hjalmar Schacht). The main counsels were supported by a total of 70 assistants, clerks and lawyers. The defense counsel witnesses included several men who took part in the war crimes during World War II, such as Rudolf Höss. The men testifying for the defense hoped to receive more lenient sentences. All of the men testifying on behalf of the defense were found guilty on several counts.
Trial.
The International Military Tribunal was opened on November 19, 1945, in the Palace of Justice in Nuremberg. The first session was presided over by the Soviet judge, Nikitchenko. The prosecution entered indictments against 24 major war criminals and seven organizations – the leadership of the Nazi party, the Reich Cabinet, the Schutzstaffel (SS), Sicherheitsdienst (SD), the Gestapo, the Sturmabteilung (SA) and the "General Staff and High Command", comprising several categories of senior military officers. These organizations were to be declared "criminal" if found guilty.
The indictments were for:
The 24 accused were, with respect to each charge, either indicted but not convicted (I), indicted and found guilty (G), or not charged (—), as listed below by defendant, charge, and eventual outcome:
Intelligence tests and psychiatric assessments.
The Rorschach test was administered to the defendants, along with the Thematic Apperception Test and a German adaptation of the Wechsler-Bellevue Intelligence Test. All were above average intelligence, several considerably.
Throughout the trials, specifically between January and July 1946, the defendants and a number of witnesses were interviewed by American psychiatrist Leon Goldensohn. His notes detailing the demeanor and comments of the defendants survive; they were edited into book form and published in 2004.
Overview of the trial.
The accusers were successful in unveiling the background of developments leading to the outbreak of World War II, which cost at least 40 million lives in Europe alone, as well as the extent of the atrocities committed in the name of the Hitler regime. Twelve of the accused were sentenced to death, seven received prison sentences (ranging from 10 years to life in prison), three were acquitted, and two were not charged.
Executions.
The death sentences were carried out on 16 October 1946 by hanging using the standard drop method instead of long drop. The U.S. army denied claims that the drop length was too short which caused the condemned to die slowly from strangulation instead of quickly from a broken neck. But evidence remains that some of the condemned men died agonizingly slowly, struggling for 14 to 28 minutes before finally choking to death. The executioner was John C. Woods. Woods had hanged 34 U.S. soldiers during the war, botching several of them. The executions took place in the gymnasium of the court building (demolished in 1983).
Although the rumor has long persisted that the bodies were taken to Dachau and burned there, they were actually incinerated in a crematorium in Munich, and the ashes scattered over the river Isar. The French judges suggested that the military condemned (Göring, Keitel and Jodl) be shot by a firing squad, as is standard for military courts-martial, but this was opposed by Biddle and the Soviet judges, who argued that the military officers had violated their military ethos and were not worthy of death by being shot, which was considered to be more dignified. The prisoners sentenced to incarceration were transferred to Spandau Prison in 1947.
Of the 12 defendants sentenced to death by hanging, two were not hanged: Martin Bormann was convicted in absentia (he had been, unknown to the Allies, killed while trying to escape from Berlin in May 1945), and Hermann Göring committed suicide the night before the execution. The remaining 10 defendants sentenced to death were hanged.
Nuremberg principles.
The definition of what constitutes a war crime is described by the Nuremberg principles, a set of guidelines document which was created as a result of the trial. The medical experiments conducted by German doctors and prosecuted in the so-called Doctors' Trial led to the creation of the Nuremberg Code to control future trials involving human subjects, a set of research ethics principles for human experimentation.
Of the indicted organizations the following were found not to be criminal:
Subsidiary and related trials.
The American authorities conducted subsequent Nuremberg Trials in their occupied zone.
Other trials conducted after the Nuremberg Trials include the following:
American role in the trial.
While Sir Geoffrey Lawrence of Britain was the judge chosen as president of the court, the most prominent of the judges at trial arguably was his American counterpart, Francis Biddle. Prior to the trial, Biddle had been Attorney General of the United States but had been asked to resign by Truman earlier in 1945.
Some accounts argue that Truman had appointed Biddle as the main American judge for the trial as an apology for asking for his resignation. Ironically, Biddle was known during his time as Attorney General for opposing the idea of prosecuting Nazi leaders for crimes committed before the beginning of the war, even sending out a memorandum on January 5, 1945 on the subject. The note also expressed Biddle's opinion that instead of proceeding with the original plan for prosecuting entire organizations, there should simply be more trials that would prosecute specific offenders.
Biddle soon changed his mind, as he approved a modified version of the plan on January 21, 1945, likely due to time constraints, since the trial would be one of the main issues discussed at Yalta. At trial, the Nuremberg tribunal ruled that any member of an organization convicted of war crimes, such as the SS or Gestapo, who had joined after 1939 would be considered a war criminal. Biddle managed to convince the other judges to make an exemption for any member who was drafted or had no knowledge of the crimes being committed by these organizations.
Justice Robert H. Jackson played an important role in not only the trial itself, but also in the creation of the International Military Tribunal, as he led the American delegation to London that, in the summer of 1945, argued in favour of prosecuting the Nazi leadership as a criminal conspiracy. According to Airey Neave, Jackson was also the one behind the prosecution's decision to include membership in any of the six criminal organizations in the indictments at the trial, though the IMT rejected this on the grounds that it was wholly without precedent in either international law or the domestic laws of any of the Allies. Jackson also attempted to have Alfried Krupp be tried in place of his father, Gustav, and even suggested that Alfried volunteer to be tried in his father's place. Both proposals were rejected by the IMT, particularly by Lawrence and Biddle, and some sources indicate that this resulted in Jackson being viewed unfavourably by the latter.
Thomas Dodd was a prosecutor for the United States. There was an immense amount of evidence backing the prosecutors' case, especially since meticulous records of the Nazis' actions had been kept. There were records taken in by the prosecutors that had signatures from specific Nazis signing for everything from stationery supplies to Zyklon B gas, which was used to kill the inmates of the deathcamps. Thomas Dodd showed a series of pictures to the courtroom after reading through the documents of crimes committed by the defendants. The showing consisted of pictures displaying the atrocities performed by the defendants. The pictures had been gathered when the inmates were liberated from the concentration camps.
Henry Gerecke, a Lutheran pastor, was sent to minister to the Nazi defendants.
Legacy.
The Tribunal is celebrated for establishing that "rimes against international law are committed by men, not by abstract entities, and only by punishing individuals who commit such crimes can the provisions of international law be enforced." The creation of the IMT was followed by trials of lesser Nazi officials and the trials of Nazi doctors, who performed experiments on people in prison camps. It served as the model for the International Military Tribunal for the Far East which tried Japanese officials for crimes against peace and against humanity. It also served as the model for the Eichmann trial and for present-day courts at The Hague, for trying crimes committed during the Balkan wars of the early 1990s, and at Arusha, for trying the people responsible for the genocide in Rwanda.
The Nuremberg trials had a great influence on the development of international criminal law. The Conclusions of the Nuremberg trials served as models for:
The International Law Commission, acting on the request of the United Nations General Assembly, produced in 1950 the report "Principles of International Law Recognized in the Charter of the Nürnberg Tribunal and in the Judgement of the Tribunal" (Yearbook of the International Law Commission, 1950, vol. II). See Nuremberg Principles.
The influence of the tribunal can also be seen in the proposals for a permanent international criminal court, and the drafting of international criminal codes, later prepared by the International Law Commission.
Tourists can visit courtroom 600 on days when no trial is on. A permanent exhibition has been dedicated to the trials. 
Establishment of a permanent International Criminal Court.
The Nuremberg trials initiated a movement for the prompt establishment of a permanent international criminal court, eventually leading over fifty years later to the adoption of the Statute of the International Criminal Court. This movement was brought about because during the trials, there were conflicting court methods between the German court system and the U.S. court system. The crime of conspiracy was unheard of in the civil law systems of the Continent. Therefore, the German defense found it unfair to charge the defendants with conspiracy to commit crimes, while the judges from common-law countries were used to doing so.
"It was the first successful international criminal court, and has since played a pivotal role in the development of international criminal law and international institutions” (Fichtelberg 5).
Criticism.
Critics of the Nuremberg trials argued that the charges against the defendants were only defined as "crimes" after they were committed and that therefore the trial was invalid as a form of "victors' justice". The alleged double standards associated with putative victor's justice are also evident from the indictment of German defendants for conspiracy to commit aggression against Poland in 1939, while no one from the Soviet Union was charged for being part of the same conspiracy. As Biddiss observed, "the Nuremberg Trial continues to haunt us. ... It is a question also of the weaknesses and strengths of the proceedings themselves."
Quincy Wright, writing eighteen months after the conclusion of the IMT, explained the opposition to the Tribunal thus:
Chief Justice of the United States Supreme Court Harlan Fiske Stone called the Nuremberg trials a fraud. "(Chief U.S. prosecutor) Jackson is away conducting his high-grade lynching party in Nuremberg," he wrote. "I don't mind what he does to the Nazis, but I hate to see the pretense that he is running a court and proceeding according to common law. This is a little too sanctimonious a fraud to meet my old-fashioned ideas."
Jackson, in a letter discussing the weaknesses of the trial, in October 1945 told U.S. President Harry S. Truman that the Allies themselves "have done or are doing some of the very things we are prosecuting the Germans for. The French are so violating the Geneva Convention in the treatment of prisoners of war that our command is taking back prisoners sent to them. We are prosecuting plunder and our Allies are practising it. We say aggressive war is a crime and one of our allies asserts sovereignty over the Baltic States based on no title except conquest."
Associate Supreme Court Justice William O. Douglas charged that the Allies were guilty of "substituting power for principle" at Nuremberg. "I thought at the time and still think that the Nuremberg trials were unprincipled," he wrote. "Law was created "ex post facto" to suit the passion and clamor of the time."
U.S. Deputy Chief Counsel Abraham Pomerantz resigned in protest at the low caliber of the judges assigned to try the industrial war criminals such as those at I.G. Farben.
Many Germans who agreed with the idea of punishment for war crimes, admitted trepidation concerning the trials. A contemporary German jurist said:
The validity of the court has been questioned on a number of grounds:
In an editorial at the time "The Economist", a British weekly newspaper, criticised the hypocrisy of both Britain and France for supporting the expulsion of the Soviet Union from the League of Nations over its unprovoked attack against Finland in 1939 and for six years later cooperating with the USSR as a respected equal at Nuremberg. It also criticised the allies for their own double-standard at the Nuremberg Trials: "nor should the Western world console itself that the Russians alone stand condemned at the bar of the Allies' own justice. ... Among crimes against humanity stands the offence of the indiscriminate bombing of civilian populations. Can the Americans who dropped the atom bomb and the British who destroyed the cities of western Germany plead 'not guilty' on this count? Crimes against humanity also include the mass expulsion of populations. Can the Anglo-Saxon leaders who at Potsdam condoned the expulsion of millions of Germans from their homes hold themselves completely innocent? ... The nations sitting in judgement have so clearly proclaimed themselves exempt from the law which they have administered."
Legitimacy.
One criticism that was made of the IMT was that some treaties were not binding on the Axis powers because they were not signatories. This was addressed in the judgment relating to war crimes and crimes against humanity, which contains an expansion of customary law: "the Convention Hague 1907 expressly stated that it was an attempt 'to revise the general laws and customs of war,' which it thus recognised to be then existing, but by 1939 these rules laid down in the Convention were recognised by all civilised nations, and were regarded as being declaratory of the laws and customs of war which are referred to in Article 6 (b) of the Charter."
Introduction of extempore simultaneous interpretation.
The Nuremberg Trials employed four official languages: English, German, French, and Russian. In order to address the complex linguistic issues that clouded over the proceedings, interpretation and translation departments had to be established. However, it was feared that consecutive interpretation would slow down the proceedings significantly. What is therefore unique in both the Nuremberg tribunals and history of the interpretation profession was the introduction of an entirely new technique, extempore simultaneous interpretation. This technique of interpretation requires the interpreter to listen to a speaker in a source (or passive) language and orally translate that speech into another language in real time, that is, simultaneously, through headsets and microphones. Interpreters were split into four sections, one for each official language, with three interpreters per section working from the other three languages into the fourth (their mother tongue). For instance, the English booth consisted of three interpreters, one working from German into English, one working from French, and one from Russian, etc. Defendants who did not speak any of the four official languages were provided with consecutive court interpreters. Some of the languages heard over the course of the proceedings included Yiddish, Hungarian, Czech, Ukrainian, and Polish.
The equipment used to establish this system was provided by IBM, and included an elaborate setup of cables which were hooked up to headsets and single earphones directly from the four interpreting booths (often referred to as "the aquarium"). Four channels existed for each working language, as well as a root channel for the proceedings without interpretation. Switching of channels was controlled by a setup at each table in which the listener merely had to turn a dial in order to switch between languages. People tripping over the floor-laid cables often led to the headsets getting disconnected, with several hours at a time sometimes being taken in order to repair the problem and continue on with the trials.
Interpreters were recruited and examined by the respective countries in which the official languages were spoken: US, UK, France, the Soviet Union, Germany, Switzerland, and Austria, as well as in special cases Belgium and the Netherlands. Many were former translators, army personnel, and linguists, some were experienced consecutive interpreters, others were ordinary individuals and even recent secondary school-graduates who led international lives in multilingual environments. It was, and still is believed, that the qualities that made the best interpreters were not just a perfect understanding of two or more languages, but more importantly a broad sense of culture, encyclopædic knowledge, inquisitiveness, as well as a naturally calm disposition.
With the simultaneous technique being extremely new, interpreters practically trained themselves, but many could not handle the pressure or the psychological strain. Many often had to be replaced, many returned to the translation department, and many left. Serious doubts were given as to whether interpretation provided a fair trial for the defendants, particularly because of fears of mistranslation and errors made on transcripts. The translation department had to also deal with the overwhelming problem of being understaffed and overburdened with an influx of documents that could not be kept up with. More often than not, interpreters were stuck in a session without having proper documents in front of them and were relied upon to do sight translation or double translation of texts, causing further problems and extensive criticism. Other problems that arose included complaints from lawyers and other legal professionals with regard to questioning and cross-examination. Legal professionals were most often appalled at the slower speed at which they had to conduct their task because of the extended time required for interpreters to do an interpretation properly. Also, a number of interpreters were noted for protesting the idea of using vulgar language reflected in the proceeds, especially if it referenced Jews or the conditions of the Nazi concentration camps. Bilingual/trilingual members who attended the trials picked up quickly on this aspect of character and were equally quick to file complaints.
Yet, despite the extensive trial and error, without the interpretation system the trials would not have been possible and in turn revolutionized the way multilingual issues were addressed in tribunals and conferences. A number of the interpreters following the trials were immediately recruited into the newly formed United Nations, while others returned to their ordinary lives, pursued other careers, or worked freelance. Outside the boundaries of the trials, many interpreters continued their positions on weekends interpreting for dinners, private meetings between judges, and excursions between delegates. Others worked as investigators or editors, or aided the translation department when they could, often using it as an opportunity to sharpen their skills and to correct poor interpretations on transcripts before they were available for public record.
For further reference, a book titled "The Origins of Simultaneous Interpretation: The Nuremberg Trial", written by interpreter Francesca Gaiba, was published by the University of Ottawa Press in 1998.
Today, all major international organizations, as well as any conference or government that uses more than one official language, uses extempore simultaneous interpretation. Notable bodies include the Parliament of Kosovo with three official languages, the Parliament of Canada with two official languages, the Parliament of South Africa with eleven official languages, the European Union with twenty-four official languages, and the United Nations with six official working languages.
References.
Citations.
Avalon Project.
These citations refer to documents at 

</doc>
<doc id="21876" url="https://en.wikipedia.org/wiki?curid=21876" title="Natasha Stott Despoja">
Natasha Stott Despoja

Natasha Jessica Stott Despoja AM (born 9 September 1969) is Australia's Ambassador for Women and Girls. A former politician and former leader of the Australian Democrats, she was a Democrats senator for South Australia from 1995 to 2008. Stott Despoja was appointed to the Senate at the age of 26, and until Sarah Hanson-Young was elected in 2007, was previously the youngest woman to sit in the Parliament of Australia.
Early life.
Stott Despoja was born in Adelaide, the daughter of Shirley Stott Despoja, an Australian-born journalist with English heritage, and Mario Despoja, an immigrant from Croatia (then Yugoslavia). She was educated at Stradbroke Primary and Pembroke School and, later, the University of Adelaide where she graduated with a Bachelor of Arts degree in 1991. She was active in student politics, becoming president of the Students' Association of the University of Adelaide (SAUA) and serving as state women's officer for the National Union of Students in South Australia. She then worked as a political adviser and researcher to Democrat senators John Coulter (SA) and Cheryl Kernot (Qld).
Personal life.
Stott Despoja married former Liberal party advisor, Ian Smith. Her husband is considered to be one of Australia's most influential political lobbyists, is the founder of consultancy Bespoke Approach and has been described by "The Power Index" as "an unabashed Tory".
Career.
On 29 November 1995, Stott Despoja was appointed to the casual vacancy created by the resignation of Coulter due to ill-health. She completed the remainder of Coulter's term and was re-elected at the 1996 election and 2001 election.
Stott Despoja was elected to the party's deputy leadership in 1997, under Meg Lees. At the time, she was party spokesperson for parliamentary portfolios including Science and Technology, Attorney General, Higher Education, IT, Employment and Youth Affairs.
During the passage of the Goods and Services Tax (GST) legislation in 1999, Stott Despoja, along with Andrew Bartlett, split from the party's other senators by opposing the package, which had been negotiated by Lees and prime minister John Howard. She said that she refused to break promises made by the party during the election. The party had gone to the election stating that they would work with whichever party formed government to improve their tax package. The Australian Democrats traditionally permitted parliamentary representatives to cast a conscience vote on any issue but, on this occasion, close numbers in the Senate placed greater pressure than usual on the dissenters.
In 1999, she was appointed a Global Leader for Tomorrow by the World Economic Forum (WEF).
Parliamentary leadership and deposition.
Stott Despoja was elected leader on 6 April 2001, replacing Meg Lees, who resigned from the party in July 2002. Further public criticism and disputes between Democrat senators resulted in Stott Despoja's resignation as leader on 21 August 2002, following presentation by four of her six colleagues (those who had earlier enabled the passage of the GST) with a ten-point 'reform' agenda proposed by John Cherry. She announced her resignation in a speech to the Senate, concluding with a "pledge to bring the party back home to the members again", and referring to her reluctance over colleagues' attitude towards her.
She was replaced as leader by Bartlett following a membership ballot interval during which Brian Greig acted in the position.
In 2004, Stott Despoja took 11 weeks' leave from the Senate following the birth of her first child before returning to full duties as Democrat spokesperson on, inter alia, Higher Education, Status of Women, and Work and Family.
During her political career she also introduced 24 Private Member's Bills on issues including paid maternity leave, the Republic, genetic privacy, stem cells, captioning and same sex marriage. Stott Despoja regularly attends the Sydney Gay and Lesbian Mardi Gras.
Retirement from Parliament.
On 22 October 2006, after undergoing emergency surgery for an ectopic pregnancy, she announced that she would not be contesting the 2007 election to extend her term beyond 30 June 2008. She was the Australian Democrats' longest-serving senator. Her retirement coincided with the ending of her party's federal parliamentary representation; the Democrats' support had collapsed after 2002 and they won no seats at the 2004 and 2007 half-senate elections.
On 13 June 2011, Stott Despoja was named a Member of the Order of Australia for service to the Parliament of Australia, particularly as a Senator for South Australia, through leadership roles with the Australian Democrats, to education, and as a role model for women.
Later activities.
She is a regular commentator in "The Advertiser", a casual host on ABC 891 radio and is the Thursday night guest panellist on Channel 10's "The Project". She was previously a columnist for the Australian business news website "Business Spectator".
Stott Despoja is an Honorary Visiting Research Fellow at The University of Adelaide. Each year, she teaches winter school at The University of Adelaide with former Foreign Minister, Alexander Downer, 'The Practice of Politics'.
Currently Stott Despoja is a board member of non-profit organisations the South Australian Museum and the Museum of Australian Democracy (MOAD). In June 2013, she retired from the Advertising Standards Board. She was a deputy-chair at beyondblue (Australia's national depression initiative) until she took on the role of ambassador for women and girls. As of 21 July 2015, Stott Despoja is a Patron of the Burnet Institute (Australia's largest virology and communicable disease research institute) and was a board member from 2008 to 2013.
She is an Ambassador for Ovarian Cancer Australia (OCA), The Orangutan Project (TOP); secondbite; and the HIV/AIDS anti-stigma campaign, ENUF, (along with her husband Ian Smith). She is on the Advisory Panel of the Australian Privacy Foundation (APF).
In the past few years, Stott Despoja has also been an election observer for the US-based National Democratic Institute (NDI) in Nigeria (2011); has visited Burkina Faso for Oxfam (2012); and has been to Laos (2011) and Burma (2013) with The Burnet Institute.
In July 2013, Stott Despoja was named Chair of the Foundation to Prevent Violence against women and their children, a joint initiative of the Victorian and Commonwealth Governments which will be based in Melbourne. The foundation aims to educate the community by building partnerships with business, philanthropic organisations and government.
In December 2013, Australian Foreign Minister Julie Bishop announced the appointment of Stott Despoja as Australia's new ambassador for women and girls.
Stott Despoja was mentioned in June 2014 as a possible replacement for Kevin Scarce as the next Governor of South Australia, however Hieu Van Le was chosen.

</doc>
<doc id="21881" url="https://en.wikipedia.org/wiki?curid=21881" title="Nuremberg Code">
Nuremberg Code

The Nuremberg Code is a set of research ethics principles for human experimentation set as a result of the Subsequent Nuremberg Trials at the end of the Second World War.
Background.
On August 20, 1947, the judges delivered their verdict in the "Doctors' Trial" against Karl Brandt and 22 others. These trials focused on doctors involved in the human experiments in concentration camps. The suspects were involved in over 3,500,000 sterilizations of German citizens. 
The trials began on December 9, 1946 in Nuremberg, Germany and were led exclusively by the United States. Harry Truman approved these trials in January 1946.
Most of the suspects escaped punishment for their crimes. Several of the accused argued that their experiments differed little from pre-war ones and that there was no law that differentiated between legal and illegal experiments.
In May of the same year, Dr. Leo Alexander had submitted to the Counsel for War Crimes six points defining legitimate medical research. The trial verdict adopted these points and added an extra four. The ten points constituted the "Nuremberg Code". Although the legal force of the document was not established and it was not incorporated directly into either the American or German law, the Nuremberg Code and the related Declaration of Helsinki are the basis for the Code of Federal Regulations Title 45 Part 46, which are the regulations issued by the United States Department of Health and Human Services governing federally funded human subjects research in the United States.
The Nuremberg code includes such principles as informed consent and absence of coercion; properly formulated scientific experimentation; and beneficence towards experiment participants.
The ten points of the Nuremberg Code.
These are:

</doc>
<doc id="21885" url="https://en.wikipedia.org/wiki?curid=21885" title="Nim">
Nim

Variants of Nim have been played since ancient times. The game is said to have originated in China—it closely resembles the Chinese game of "Tsyan-shizi", or "picking stones"—but the origin is uncertain; the earliest European references to Nim are from the beginning of the 16th century. Its current name was coined by Charles L. Bouton of Harvard University, who also developed the complete theory of the game in 1901, but the origins of the name were never fully explained. The name is probably derived from German "nimm" meaning "take ", or the obsolete English verb "nim" of the same meaning.
Nim can be played as a "misère" game, in which the player to take the last object loses. Nim can also be played as a "normal play" game, which means that the person who makes the last move (i.e., who takes the last object) wins. This is called normal play because most games follow this convention, even though Nim usually does not.
Normal play Nim (or more precisely the system of nimbers) is fundamental to the Sprague–Grundy theorem, which essentially says that in normal play every impartial game is equivalent to a Nim heap that yields the same outcome when played in parallel with other normal play impartial games (see disjunctive sum).
While all normal play impartial games can be assigned a Nim value, that is not the case under the misère convention. Only tame games can be played using the same strategy as misère nim.
A version of Nim is played—and has symbolic importance—in the French New Wave film "Last Year at Marienbad" (1961).
At the 1940 New York World's Fair Westinghouse displayed a machine, the Nimatron, that played Nim. It was also one of the first ever electronic computerized games. Ferranti built a Nim playing computer which was displayed at the Festival of Britain in 1951. In 1952 Herbert Koppel, Eugene Grant and Howard Bailer, engineers from the W. L. Maxon Corporation, developed a machine weighing 50 pounds which played Nim against a human opponent and regularly won. A Nim Playing Machine has been described made from TinkerToy.
Nim is a special case of a poset game where the poset consists of disjoint chains (the heaps).
Game play and illustration.
The normal game is between two players and played with three heaps of any number of objects. The two players alternate taking any number of objects from any single one of the heaps. The goal is to be the last to take an object. In misère play, the goal is instead to ensure that the opponent is forced to take the last remaining object.
The following example game is played between fictional players Bob and Alice who start with heaps of three, four and five objects.
Winning positions.
The practical strategy to win at the game of "Nim" is for a player to get the other into one of the following positions, and every successive turn afterwards they should be able to make one of the lower positions. Only the last move changes between misere and normal play.
Mathematical theory.
Nim has been mathematically solved for any number of initial heaps and objects, and there is an easily calculated way to determine which player will win and what winning moves are open to that player. In a game that starts with heaps of three, four, and five, the first player will win with optimal play, whether the misère or normal play convention is followed.
The key to the theory of the game is the binary digital sum of the heap sizes, that is, the sum (in binary) neglecting all carries from one digit to another. This operation is also known as "exclusive or" (xor) or "vector addition over GF(2)". Within combinatorial game theory it is usually called the nim-sum, as it will be called here. The nim-sum of "x" and "y" is written "x" ⊕ "y" to distinguish it from the ordinary sum, "x" + "y". An example of the calculation with heaps of size 3, 4, and 5 is as follows:
An equivalent procedure, which is often easier to perform mentally, is to express the heap sizes as sums of distinct powers of 2, cancel pairs of equal powers, and then add what's left:
In normal play, the winning strategy is to finish every move with a nim-sum of 0. This is always possible if the nim-sum is not zero before the move. If the nim-sum is zero, then the next player will lose if the other player does not make a mistake. To find out which move to make, let X be the nim-sum of all the heap sizes. Find a heap where the nim-sum of X and heap-size is less than the heap-size - the winning strategy is to play in such a heap, reducing that heap to the nim-sum of its original size with X. In the example above, taking the nim-sum of the sizes is X = 3 ⊕ 4 ⊕ 5 = 2. The nim-sums of the heap sizes A=3, B=4, and C=5 with X=2 are
The only heap that is reduced is heap A, so the winning move is to reduce the size of heap A to 1 (by removing two objects).
As a particular simple case, if there are only two heaps left, the strategy is to reduce the number of objects in the bigger heap to make the heaps equal. After that, no matter what move your opponent makes, you can make the same move on the other heap, guaranteeing that you take the last object.
When played as a misère game, Nim strategy is different only when the normal play move would leave no heap of size two or larger. In that case, the correct move is to leave an odd number of heaps of size one (in normal play, the correct move would be to leave an even number of such heaps).
In a misère game with heaps of sizes three, four and five, the strategy would be applied like this:
The previous strategy for a misère game can be easily implemented (for example in Python, below).
Proof of the winning formula.
The soundness of the optimal strategy described above was demonstrated by C. Bouton.
Theorem. In a normal Nim game, the player making the first move has a winning strategy if and only if the nim-sum of the sizes of the heaps is nonzero. Otherwise, the second player has a winning strategy.
"Proof:" Notice that the nim-sum (⊕) obeys the usual associative and commutative laws of addition (+) and also satisfies an additional property, "x" ⊕ "x" = 0 (technically speaking, that the nonnegative integers under ⊕ form an Abelian group of exponent 2).
Let "x"1, ..., "xn" be the sizes of the heaps before a move, and "y"1, ..., "yn" the corresponding sizes after a move. Let "s" = "x"1 ⊕ ... ⊕ "xn" and "t" = "y"1 ⊕ ... ⊕ "yn". If the move was in heap "k", we have "xi" = "yi" for all "i" ≠ "k", and "xk" > "yk". By the properties of ⊕ mentioned above, we have
The theorem follows by induction on the length of the game from these two lemmas.
Lemma 1. If "s" = 0, then "t" ≠ 0 no matter what move is made.
"Proof:" If there is no possible move, then the lemma is vacuously true (and the first player loses the normal play game by definition). Otherwise, any move in heap "k" will produce "t" = "xk" ⊕ "yk" from (*). This number is nonzero, since "xk" ≠ "yk".
Lemma 2. If "s" ≠ 0, it is possible to make a move so that "t" = 0.
"Proof:" Let "d" be the position of the leftmost (most significant) nonzero bit in the binary representation of "s", and choose "k" such that the "d"th bit of "xk" is also nonzero. (Such a "k" must exist, since otherwise the "d"th bit of "s" would be 0.)
Then letting "yk" = "s" ⊕ "xk", we claim that "yk" < "xk": all bits to the left of "d" are the same in "xk" and "yk", bit "d" decreases from 1 to 0 (decreasing the value by 2"d"), and any change in the remaining bits will amount to at most 2"d"−1. The first player can thus make a move by taking "xk" − "yk" objects from heap "k", then
The modification for misère play is demonstrated by noting that the modification first arises in a position that has only one heap of size 2 or more. Notice that in such a position "s" ≠ 0, therefore this situation has to arise when it is the turn of the player following the winning strategy. The normal play strategy is for the player to reduce this to size 0 or 1, leaving an even number of heaps with size 1, and the misère strategy is to do the opposite. From that point on, all moves are forced.
Variations.
Dividing natural number.
Give any natural number "n", the two people can divide "n" by a prime power () which is a factor of "n" (except 1), the person who gets 1 wins (or loses).
If formula_1, where formula_2 is the "k"-th prime, then it is a Nim game with "k" groups of stones, and the "r"-th groups has formula_3 stones.
If the divisor changes to "a power of squarefree numbers" () except 1, it is Wythoff's game.
The divisor can also change to "a divisor of "m"" for fixed "m", where "m" is a divisor of "n". ("m" should be divisible by all of the prime factors of "n" and should be less than "n")
Of course, you can choose a set of allowed divisors. For example, {2, 3, 4, 12, 15, 20, 24, 25, 30, 32, 36}.
The subtraction game "S"(1, 2, . . ., "k").
In another game which is commonly known as Nim (but is better called the subtraction game "S" (1,2...,"k")), an upper bound is imposed on the number of objects that can be removed in a turn. Instead of removing arbitrarily many objects, a player can only remove 1 or 2 or ... or "k" at a time. This game is commonly played in practice with only one heap (for instance with "k" = 3 in the game "Thai 21" on , where it appeared as an Immunity Challenge).
Bouton's analysis carries over easily to the general multiple-heap version of this game. The only difference is that as a first step, before computing the Nim-sums, we must reduce the sizes of the heaps modulo "k" + 1. If this makes all the heaps of size zero (in misère play), the winning move is to take "k" objects from one of the heaps. In particular, in ideal play from a single heap of "n" objects, the second player can win if and only if
This follows from calculating the nim-sequence of "S"(1,2...,"k"),
from which the strategy above follows by the Sprague–Grundy theorem.
The 21 game.
The game "21" is played as a misère game with any number of players who take turns saying a number. The first player says "1" and each player in turn increases the number by 1, 2, or 3, but may not exceed 21; the player forced to say "21" loses. This can be modeled as a subtraction game with a heap of 21–"n" objects. The winning strategy for the two-player version of this game is to always say a multiple of 4; it is then guaranteed that the other player will ultimately have to say 21 – so in the standard version where the first player opens with "1", they start with a losing move.
The 21 game can also be played with different numbers, like "Add at most 5; lose on 34".
A sample game of 21 in which the second player follows the winning strategy:
The 100 game.
A similar version is the "100 game": two players start from 0 and alternatively add a number from 1 to 10 to the sum. The player who reaches 100 wins. The winning strategy is to reach a number in which the digits are subsequent (e.g. 01, 12, 23, 34...) and control the game by jumping through all the numbers of this sequence. Once reached 89, the opponent has lost (he can only tell numbers from 90 to 99, and the next answer can in any case be 100).
A multiple-heap rule.
In another variation of Nim, besides removing any number of objects from a single heap, one is permitted to remove the same number of objects from each heap.
Circular Nim.
Yet another variation of Nim is 'Circular Nim', where any number of objects are placed in a circle, and two players alternately remove one, two or three adjacent objects. For example, starting with a circle of ten objects,
three objects are taken in the first move
_ . . . . . . . _ _
then another three
_ . _ _ _ . . . _ _
then one
_ . _ _ _ . . _ _ _
but then three objects cannot be taken out in one move.
Grundy's game.
In Grundy's game, another variation of Nim, a number of objects are placed in an initial heap, and two players alternately divide a heap into two nonempty heaps of different sizes. Thus, six objects may be divided into piles of 5+1 or 4+2, but not 3+3. Grundy's game can be played as either misère or normal play.
Greedy Nim.
"Greedy Nim" is a variation where the players are restricted to choosing stones from only the largest pile. It is a finite impartial game. "Greedy Nim Misère" has the same rules as Greedy Nim, but here the last player able to make a move loses
Let the largest number of stones in a pile be "m", the second largest number of stones in a pile be "n". Let "p""m" be the number of piles having "m" stones, "p""n" be the number of piles having "n" stones. Then there is a theorem that game positions with "p""m" even are "P" positions.
Thus there exists a move to a state where "p""m" is even. Conversely, if "p""m" is even, if any move is possible ("p""m" ≠ 0) then it must take the game to a state where "p""m" is odd. The final position of the game is even ("p""m" = 0). Hence each position of the game with "p""m" even must be a "P" position.
Index-"k" Nim.
A generalization of multi-heap Nim was called "Nimformula_5" or "index-"k" Nim by E. H. Moore, who analyzed it in 1910. In index-"k" Nim, instead of removing objects from only one heap, players can remove objects from at least one but up to "k" different heaps. The number of elements that may be removed from each heap may be either arbitrary, or limited to at most "r" elements, like in the "subtraction game" above.
The winning strategy is as follows: Like in ordinary multi-heap Nim, one considers the binary representation of the heap sizes (or heap sizes modulo "r" + 1). In ordinary Nim one forms the XOR-sum (or sum modulo 2) of each binary digit, and the winning strategy is to make each XOR sum zero. In the generalization to index-"k" Nim, one forms the sum of each binary digit modulo "k" + 1.
Again the winning strategy is to move such that this sum is zero for every digit. Indeed, the value thus computed is zero for the final position, and given a configuration of heaps for which this value is zero, any change of at most "k" heaps will make the value non-zero. Conversely, given a configuration with non-zero value, one can always take from at most "k" heaps, carefully chosen, so that the value will become zero.
Building Nim.
Building Nim is a variant of Nim where the two players first construct the game of Nim. Given "n" stones and "s" empty piles, the players alternate turns placing exactly one stone into a pile of their choice. Once all the stones are placed, a game of Nim begins, starting with the next player that would move. This game is denoted "BN(n,s)".

</doc>
<doc id="21886" url="https://en.wikipedia.org/wiki?curid=21886" title="Ninon de l'Enclos">
Ninon de l'Enclos

Anne "Ninon" de l'Enclos also spelled Ninon de Lenclos and Ninon de Lanclos (10 November 1620 – 17 October 1705) was a French author, courtesan, freethinker, and patron of the arts.
Early life.
Born Anne de Lenclos in Paris on 10 November 1620, she was nicknamed "Ninon" by her father at an early age. In 1632 her father was exiled from France after a duel, and when her mother died ten years later the unmarried Ninon entered a convent, only to leave the next year.
For the remainder of her life, she was determined to remain unmarried and independent.
Life as a courtesan and author.
Returning to Paris, she became a popular figure in the salons, and her own drawing room became a centre for the discussion and consumption of the literary arts. In her early thirties she was responsible for encouraging the young Molière, and when she died she left money for the son of her accountant, a nine-year-old named François Marie Arouet, later to become known as Voltaire, so he could buy books.
It was during this period that her life as a courtesan began. Ninon took a succession of notable and wealthy lovers, including the king's cousin the Great Condé, Gaston de Coligny, and François, duc de La Rochefoucauld. These men did not support her, however; she prided herself on her independent income. "Ninon always had crowds of adorers but never more than one lover at a time, and when she tired of the present occupier, she said so frankly and took another. Yet such was the authority of this wanton, that no man dared fall out with his successful rival; he was only too happy to be allowed to visit as a familiar friend," Saint-Simon wrote. In 1652, Ninon took up with Louis de Mornay, the marquis de Villarceaux, by whom she had a son, also named Louis. She lived with the marquis until 1655, when she returned to Paris. When she would not return to him, the marquis fell into a fever; to console him, Ninon cut her hair and sent the shorn locks to him, starting a vogue for bobbed hair "à la Ninon". 
This life (not as acceptable in those days as it would become in later years) and her opinions on organized religion caused her some trouble, and she was imprisoned in the Madelonnettes Convent in 1656 at the behest of Anne of Austria, Queen of France and regent for her son Louis XIV. Not long after, however, she was visited by Christina, former queen of Sweden. Impressed, Christina wrote to Cardinal Mazarin on Ninon's behalf and arranged for her release.
In response, as an author she defended the possibility of living a good life in the absence of religion, notably in 1659's "La coquette vengée" ("The Flirt Avenged"). She was also noted for her wit; among her numerous sayings and quips are "Much more genius is needed to make love than to command armies" and "We should take care to lay in a stock of provisions, but not of pleasures: these should be gathered day by day." A picture of Ninon, under the name of Damo, was sketched in Mlle de Scudéry's "Clélie" (1654–1661).
Starting in the late 1660s she retired from her courtesan lifestyle and concentrated more on her literary friends – from 1667, she hosted her gatherings at "l'hôtel Sagonne", which was considered "the" location of the salon of Ninon de l'Enclos despite other locales in the past. During this time she was a friend of Jean Racine, the great French playwright. Later she would become a close friend with the devout Françoise d'Aubigné, better known as Madame de Maintenon, the lady-in-waiting who would later become the second wife of Louis XIV. Saint-Simon wrote that "The lady did not like her to be mentioned in her presence, but dared not disown her, and wrote cordial letters to her from time to time, to the day of her death". Ninon eventually died at the age of 84, as a very wealthy woman. To the end, she "was convinced that she had no soul, and never abandoned that conviction, not even in advanced old age, not even at the hour of her death." 
Influence.
Ninon de l'Enclos is a relatively obscure figure in the English-speaking world, but is much better known in France where her name is synonymous with wit and beauty. Saint-Simon noted "Ninon made friends among the great in every walk of life, had wit and intelligence enough to keep them, and, what is more, to keep them friendly with one another."
Dorothy Parker wrote the poem "Ninon De L'Enclos On Her Last Birthday" and also referenced Ninon in another of her poems, "Words Of Comfort To Be Scratched On A Mirror", writing, "Ninon was ever the chatter of France." 

</doc>
<doc id="21888" url="https://en.wikipedia.org/wiki?curid=21888" title="National Institute of Standards and Technology">
National Institute of Standards and Technology

The National Institute of Standards and Technology (NIST), known between 1901 and 1988 as the National Bureau of Standards (NBS), is a measurement standards laboratory, also known as a National Metrological Institute (NMI), which is a non-regulatory agency of the United States Department of Commerce. The institute's official mission is to:
NIST had an operating budget for fiscal year 2007 (October 1, 2006-September 30, 2007) of about $843.3 million. NIST's 2009 budget was $992 million, and it also received $610 million as part of the American Recovery and Reinvestment Act. NIST employs about 2,900 scientists, engineers, technicians, and support and administrative personnel. About 1,800 NIST associates (guest researchers and engineers from American companies and foreign countries) complement the staff. In addition, NIST partners with 1,400 manufacturing specialists and staff at nearly 350 affiliated centers around the country. NIST publishes the Handbook 44 that provides the "Specifications, tolerances, and other technical requirements for weighing and measuring devices".
History.
Initial mandate.
In 1821, John Quincy Adams stated, "Weights and measures may be ranked among the necessities of life to every individual of human society", but this had long been understood. The Articles of Confederation, ratified by the colonies in 1781, contained the clause, "The United States in Congress assembled shall also have the sole and exclusive right and power of regulating the alloy and value of coin struck by their own authority, or by that of the respective states—fixing the standards of weights and measures throughout the United States". Article 1, section 8, of the Constitution of the United States (1789), transferred this power to Congress; "The Congress shall have power...To coin money, regulate the value thereof, and of foreign coin, and fix the standard of weights and measures".
In January 1790 President George Washington, in his first annual message to Congress stated that, "Uniformity in the currency, weights, and measures of the United States is an object of great importance, and will, I am persuaded, be duly attended to", and ordered Secretary of State Thomas Jefferson to prepare a plan for Establishing Uniformity in the Coinage, Weights, and Measures of the United States, afterwards referred to as the Jefferson report. On October 25, 1791, Washington appealed a third time to Congress, "A uniformity of the weights and measures of the country is among the important objects submitted to you by the Constitution and if it can be derived from a standard at once invariable and universal, must be no less honorable to the public council than conducive to the public convenience", but it was not until 1838 that a uniform set of standards was worked out.
History.
From 1830 until 1901, the role of overseeing weights and measures was carried out by the Office of Standard Weights and Measures, which was part of the United States Department of the Treasury. In 1901, in response to a bill proposed by Congressman James H. Southard (R, Ohio), the National Bureau of Standards was founded with the mandate to provide standard weights and measures, and to serve as the national physical laboratory for the United States. (Southard had previously sponsored a bill for metric conversion of the United States.) 
President Theodore Roosevelt appointed Samuel W. Stratton as the first director. The budget for the first year of operation was $40,000. The Bureau took custody of the copies of the kilogram and meter bars that were the standards for U.S. measures, and set up a program to provide metrology services for United States scientific and commercial users. A laboratory site was constructed in Washington, D.C., and instruments were acquired from the national physical laboratories of Europe. In addition to weights and measures, the Bureau developed instruments for electrical units and for measurement of light. In 1905 a meeting was called that would be the first "National Conference on Weights and Measures".
Initially conceived as purely a metrology agency, the Bureau of Standards was directed by Herbert Hoover to set up divisions to develop commercial standards for materials and products.page 133 Some of these standards were for products intended for government use, but product standards also affected private-sector consumption. Quality standards were developed for products including some types of clothing, automobile brake systems and headlamps, antifreeze, and electrical safety. During World War I, the Bureau worked on multiple problems related to war production, even operating its own facility to produce optical glass when European supplies were cut off. Between the wars, Harry Diamond of the Bureau developed a blind approach radio aircraft landing system. During the Second World War, military research and development was carried out, including development of radio propagation forecast methods, the proximity fuze and the guided bomb.
In 1948, financed by the Air Force, the Bureau began design and construction of SEAC, the Standards Eastern Automatic Computer. The computer went into operation in May 1950 using a combination of vacuum tubes and solid-state diode logic. About the same time the Standards Western Automatic Computer, was built at the Los Angeles office of the NBS and used for research there. A mobile version, DYSEAC, was built for the Signal Corps in 1954.
The "National Bureau of Standards" became the National Institute of Standards and Technology in 1988.
Metric system.
The Congress of 1866 legalized the use of the metric system through the passage of U.S. code 1952 Ed., Title 15, Ch 6, sections 204 and 205. On May 20, 1875, 17 out of 20 countries signed a document known as the "Metric Convention" or the "Treaty of the Meter", which established the International Bureau of Weights and Measures under the control of an international committee elected by the General Conference on Weights and Measures.
Organization.
NIST is headquartered in Gaithersburg, Maryland, and operates a facility in Boulder, Colorado. NIST's activities are organized into laboratory programs and extramural programs. Effective October 1, 2010, NIST was realigned by reducing the number of NIST laboratory units from ten to six. NIST Laboratories include:
Extramural programs include:
NIST also operates a neutron science user facility: the NIST Center for Neutron Research (NCNR). The NCNR provides scientists access to a variety of neutron scattering instruments, which they use in many research fields (materials science, fuel cells, biotechnology, etc.).
The SURF III Synchrotron Ultraviolet Radiation Facility is a source of synchrotron radiation, in continuous operation since 1961. SURF III now serves as the U.S. national standard for source-based radiometry throughout the generalized optical spectrum. All NASA-borne, extreme-ultraviolet observation instruments have been calibrated at SURF since the 1970s, and SURF is used for measurement and characterization of systems for extreme ultraviolet lithography.
The Center for Nanoscale Science and Technology (CNST) performs research in nanotechnology, both through internal research efforts and by running a user-accessible cleanroom nanomanufacturing facility. This "NanoFab" is equipped with tools for lithographic patterning and imaging (e.g., electron microscopes and atomic force microscopes).
Committees.
NIST has seven standing committees:
Projects.
Measurements and standards.
As part of its mission, NIST supplies industry, academia, government, and other users with over 1,300 Standard Reference Materials (SRMs). These artifacts are certified as having specific characteristics or component content, used as calibration standards for measuring equipment and procedures, quality control benchmarks for industrial processes, and experimental control samples.
"Handbook 44".
NIST publishes the "Handbook 44" each year after the annual meeting of the National Conference on Weights and Measures (NCWM). Each edition is developed through cooperation of the Committee on Specifications and Tolerances of the NCWM and the Weights and Measures Division (WMD) of the NIST. The purpose of the book is a partial fulfillment of the statutory responsibility for "cooperation with the states in securing uniformity of weights and measures laws and methods of inspection".
NIST has been publishing various forms of what is now the "Handbook 44" since 1918 and began publication under the current name in 1949. The 2010 edition conforms to the concept of the primary use of the SI (metric) measurements recommended by the Omnibus Foreign Trade and Competitiveness Act of 1988.
Homeland security.
NIST is currently developing government-wide identification card standards for federal employees and contractors to prevent unauthorized persons from gaining access to government buildings and computer systems.
NIST developed Advanced Encryption Standard based on work starting in the 1970s.
World Trade Center Collapse Investigation.
In 2002 the National Construction Safety Team Act mandated NIST to conduct an investigation into the collapse of the World Trade Center buildings 1 and 2 and the 47-story 7 World Trade Center. The "World Trade Center Collapse Investigation", directed by lead investigator Shyam Sunder, covered three aspects, including a technical building and fire safety investigation to study the factors contributing to the probable cause of the collapses of the WTC Towers (WTC 1 and 2) and WTC 7. NIST also established a research and development program to provide the technical basis for improved building and fire codes, standards, and practices, and a dissemination and technical assistance program to engage leaders of the construction and building community in implementing proposed changes to practices, standards, and codes. NIST also is providing practical guidance and tools to better prepare facility owners, contractors, architects, engineers, emergency responders, and regulatory authorities to respond to future disasters. The investigation portion of the response plan was completed with the release of the final report on 7 World Trade Center on November 20, 2008. The final report on the WTC Towers—including 30 recommendations for improving building and occupant safety—was released on October 26, 2005.
Election technology.
NIST works in conjunction with the Technical Guidelines Development Committee of the Election Assistance Commission to develop the Voluntary Voting System Guidelines for voting machines and other election technology.
People.
Four scientific researchers at NIST have been awarded Nobel Prizes for work in physics: William D. Phillips in 1997, Eric A. Cornell in 2001, John L. Hall in 2005 and David J. Wineland in 2012, which is the largest number for any U.S. government laboratory. All four were recognized for their work related to laser cooling of atoms, which is directly related to the development and advancement of the atomic clock. In 2011 Dan Shechtman was awarded the Nobel Prize in chemistry for his work on quasicrystals in the Metallurgy Division from 1982 to 1984. In addition, John Cahn was awarded the 2011 Kyoto Prize for Materials Science. Other notable people who have worked at NIST include:
Directors.
Since 1989, the director of NIST has been a Schedule-C Presidential appointee and is confirmed by the United States Senate, and since that year the average tenure of NIST directors has fallen from 11 years to 2 years in duration. Since the 2011 reorganization of NIST, the director also holds the title of Undersecretary of Commerce for Technology. Fifteen individuals have officially held the position (in addition to three "acting" directors who served on a temporary basis ). They are:
Controversy.
"The Guardian" and the "New York Times" reported that NIST allowed the National Security Agency (NSA) to insert a cryptographically secure pseudorandom number generator called Dual EC DRBG into NIST standard SP 800-90 that had a backdoor that the NSA can use to covertly decrypt material that was encrypted using this pseudorandom number generator. Both papers report that the NSA worked covertly to get its own version of SP 800-90 approved for worldwide use in 2006. The leaked document states that "eventually, NSA became the sole editor". The reports confirm suspicions and technical grounds publicly raised by cryptographers in 2007 that the EC-DRBG could contain an asymmetric backdoor (perhaps placed in the standard by NSA).
NIST responded to the allegations, stating that "NIST works to publish the strongest cryptographic standards possible" and that it uses "a transparent, public process to rigorously vet our recommended standards". The agency stated that "there has been some confusion about the standards development process and the role of different organizations in it...The National Security Agency (NSA) participates in the NIST cryptography process because of its recognized expertise. NIST is also required by statute to consult with the NSA." Recognizing the concerns expressed, the agency reopened the public comment period for the SP800-90 publications, promising that "if vulnerabilities are found in these or any other NIST standards, we will work with the cryptographic community to address them as quickly as possible”.

</doc>
<doc id="21891" url="https://en.wikipedia.org/wiki?curid=21891" title="NATO reporting name">
NATO reporting name

NATO reporting names are code names for military equipment of Russia, China, and, historically, the former Eastern Bloc (Soviet Union and other nations of the Warsaw Pact). They provide unambiguous and easily understood English words in a uniform manner in place of the original designations, which either may have been unknown to the Western world at the time or easily confused codes.
NATO maintains lists of the names. The assignment of the names for the Russian and Chinese aircraft was once managed by the five-nation Air Standardization Coordinating Committee (ASCC) (now called the Air and Space Interoperability Council, or ASIC, which includes representatives of Australia, Canada, New Zealand, the United Kingdom, and the United States), but that is no longer the case.
U.S. variations.
The United States Department of Defense expands on the NATO reporting names in some cases. NATO refers to surface-to-air missile systems mounted on ships or submarines with the same names as the corresponding land-based systems, but the US DoD assigns a different series of numbers with a different suffix (i.e., SA-N- vs. SA-) for these systems. The names are kept the same as a convenience. Where there is no corresponding system, a new name is devised. Some US DoD nomenclature is included in the following pages and is noted as such.
Soviet nicknames.
The Soviet Union did not always assign official “popular names” to its aircraft, but unofficial nicknames were common as in any air force. Generally, Soviet pilots did not use the NATO names, preferring a different, Russian, nickname. An exception was that Soviet airmen appreciated the MiG-29's codename 'Fulcrum', as an indication of its pivotal role in Soviet air defence. Hundreds of names had to be chosen so the names covered a wide variety of subjects and include some obscure words.
Nomenclature.
To reduce the risk of confusion, unusual or made-up names were allocated, the idea being that the names chosen would be unlikely to occur in normal conversation, and be easier to memorise. For fixed-wing aircraft, single-syllable words denoted piston-prop and turboprop, while multiple-syllable words denoted jets. Bombers had names starting with the letter "B" and names like "Badger" (2 syllables: jet), "Bear" (single syllable: propeller), and "Blackjack" were used. “Frogfoot,” the reporting name for the Sukhoi Su-25, references the aircraft’s close air support role. Transports had names starting with "C" (as in “cargo”), which resulted in names like "Condor" or "Candid".
A fictional NATO reporting name "Firefox" for a fictional "MiG-31" appears in the novel "Firefox" and subsequent movie. The real MiG-31 from 1979 was assigned the reporting name "Foxhound".
Lists of NATO reporting names.
Missiles.
The initial letter of the name indicated the use of that equipment.
Aircraft.
The first letter indicates the type of aircraft, like "B"ear for a bomber aircraft, or "F"ulcrum for a fighter aircraft.
For fixed-wing aircraft, one syllable names were used for propeller-powered craft (turboprops included), while two-syllable names indicated jet engines.

</doc>
<doc id="21892" url="https://en.wikipedia.org/wiki?curid=21892" title="List of NATO reporting names for surface-to-surface missiles">
List of NATO reporting names for surface-to-surface missiles

NATO reporting name for SS series surface-to-surface missiles, with Soviet designations:
US DoD designations for SS-N series naval surface-to-surface missiles (fired from ships and submarines), with Soviet designations:
"See also": NATO reporting name

</doc>
<doc id="21893" url="https://en.wikipedia.org/wiki?curid=21893" title="List of NATO reporting names for air-to-air missiles">
List of NATO reporting names for air-to-air missiles

NATO reporting name for AA series air-to-air missiles, with Soviet designations:
"See also": NATO reporting name

</doc>
<doc id="21894" url="https://en.wikipedia.org/wiki?curid=21894" title="List of NATO reporting names for air-to-surface missiles">
List of NATO reporting names for air-to-surface missiles

NATO reporting name for AS series air-to-surface missiles, with Soviet designations:
Note: the Soviet / Russian designation is a Cyrillic letter "Х", which is translated as "Kh" or "H". Also, sometimes a combination ("complex") of a missile with its aircraft is marked with a letter "K" (for example, a missile Kh-22 with an aircraft is a "complex K-22"). The Cyrillic "X" (read "Kh") in the designation of Soviet ASMs is in fact a Latin "X" ("ecs") for Xperimental, as used by the design bureau. With passing time, however, this was ignored and used in Soviet/Russian as well as foreign literature as the Cyrillic Kh.
"See also": NATO reporting name

</doc>
<doc id="21895" url="https://en.wikipedia.org/wiki?curid=21895" title="List of NATO reporting names for anti-tank missiles">
List of NATO reporting names for anti-tank missiles

NATO reporting name for AT series anti-tank guided missiles, with Soviet designations:
"See also:" NATO reporting name, List of anti-tank guided missiles

</doc>
<doc id="21896" url="https://en.wikipedia.org/wiki?curid=21896" title="List of NATO reporting names for surface-to-air missiles">
List of NATO reporting names for surface-to-air missiles

NATO reporting name for SA series surface-to-air missiles, with Soviet designations:
U.S. DoD designations for SA-N series naval surface-to-air missiles, with Soviet designations. Note that these are not standard NATO names, NATO uses the regular SA series for naval SAMS also, however the US DoD refers to them by these names:
"See also": NATO reporting name

</doc>
<doc id="21897" url="https://en.wikipedia.org/wiki?curid=21897" title="List of NATO reporting names for bomber aircraft">
List of NATO reporting names for bomber aircraft

This is a list of NATO reporting name/ASCC names for bombers, with Soviet designations:

</doc>
<doc id="21898" url="https://en.wikipedia.org/wiki?curid=21898" title="List of NATO reporting names for fighter aircraft">
List of NATO reporting names for fighter aircraft

NATO reporting name/ASCC names for fighters, with Soviet, Russian and Chinese designations.

</doc>
<doc id="21899" url="https://en.wikipedia.org/wiki?curid=21899" title="List of NATO reporting names for helicopters">
List of NATO reporting names for helicopters

Helicopters, NATO/ASCC names:

</doc>
<doc id="21900" url="https://en.wikipedia.org/wiki?curid=21900" title="List of NATO reporting names for transport aircraft">
List of NATO reporting names for transport aircraft

NATO reporting name/ASCC names for transport aircraft and their Soviet, Russian and Chinese designations:
See also.
NATO reporting name

</doc>
<doc id="21901" url="https://en.wikipedia.org/wiki?curid=21901" title="List of NATO reporting names for miscellaneous aircraft">
List of NATO reporting names for miscellaneous aircraft

NATO reporting name/Air Standardization Coordinating Committee (ASCC) names for miscellaneous aircraft, with Soviet designations, sorted by reporting name:
NATO reporting name/ASCC names for miscellaneous aircraft, with Soviet designations, sorted by Soviet designation:

</doc>
<doc id="21904" url="https://en.wikipedia.org/wiki?curid=21904" title="List of NATO reporting names for submarines">
List of NATO reporting names for submarines

This is a list of NATO reporting names for submarines, with Russian and Soviet Navy designations. The names are often derived from the NATO phonetic alphabet.

</doc>
<doc id="21907" url="https://en.wikipedia.org/wiki?curid=21907" title="Seven Laws of Noah">
Seven Laws of Noah

The Seven Laws of Noah ( "Sheva Mitsvot Bne Noah"), also referred to as the Noahide Laws or the Noachide Laws (from the English transliteration of the Hebrew pronunciation of "Noah"), are a set of imperatives which, according to the Talmud, were given by God as a binding set of laws for the "children of Noah" – that is, all of humanity.
Accordingly, any non-Jew who adheres to these laws because they were given by Moses is regarded as a "righteous gentile", and is assured of a place in the world to come ( "Olam Haba"), the final reward of the righteous.
The seven Noahide laws as traditionally enumerated are:
According to the Talmud, the rabbis agree that the seven laws were given to the sons of Noah. However, they disagree on precisely which laws were given to Adam and Eve. Six of the seven laws are exegetically derived from passages in Genesis, with the seventh being the establishing of courts.
Sources.
Torah.
According to the Genesis flood narrative, a deluge covered the whole world, killing every surface-dwelling creature except Noah, his wife, his sons and their wives, and the animals taken aboard Noah's Ark. According to this, all modern humans are descendants of Noah, thus the name Noahide Laws in reference to laws that apply to all of humanity. After the flood, God sealed a covenant with Noah with the following admonitions ():
Book of Jubilees.
The Book of Jubilees, generally dated to the 2nd century BCE, may include an early reference to Noahide Law at verses 7:20–28:
Acts 15.
The Jewish Encyclopedia article on Saul of Tarsus states:
The article "New Testament" states:
The Apostolic Decree of the Council of Jerusalem resolved this early Christian dispute by commending that gentiles obey Noahide law () rather than to live under the same dictates as Torah-observant Jews and be circumcised (cf. , ).
Tosefta.
The earliest complete rabbinic version of the seven laws can be found in the Tosefta where they are listed as follows.
Seven commandments were commanded of the sons of Noah:
Halakha and the Seven Laws.
Talmud.
According to the Talmud, the Noahide Laws apply to all humanity through humankind's descent from one paternal ancestor, the head of the only family to survive The Flood, who in Hebrew tradition is called Noah. In Judaism, בני נח "B'nei Noah" (Hebrew, "Descendants of Noah", "Children of Noah") refers to all of humankind. The Talmud also states: "Righteous people of all nations have a share in the world to come". Any non-Jew who lives according to these laws is regarded as one of "the righteous among the gentiles".
The rabbis agree that the seven laws were given to the sons of Noah. However, they disagree on precisely which laws were given to Adam and Eve. Six of the seven laws are exegetically derived from passages in Genesis. The Talmud adds extra laws beyond the seven listed in the Tosefta which are attributed to different rabbis, such as the grafting of trees and sorcery among others, Ulla going so far as to make a list of 30 laws. The Talmud expands the scope of the seven laws to cover about 100 of the 613 mitzvoth.
Punishment.
In practice Jewish law makes it very difficult to apply the death penalty. No record exists of a gentile having been put to death for violating the seven laws. Some of the categories of capital punishment recorded in the Talmud are recorded as having never have been carried out. It is thought that the rabbis included discussion of them in anticipation of the coming messianic age.
The Talmud lists the punishment for blaspheming the Ineffable Name of God as death. The sons of Noah are to be executed by decapitation for most crimes, considered one of the lightest capital punishments, by stoning if he has intercourse with a Jewish betrothed woman, or by strangulation if the Jewish woman has completed the marriage ceremonies, but had not yet consummated the marriage. In Jewish law the only form of blasphemy which is punishable by death is blaspheming the Ineffable Name . Some Talmudic rabbis held that only those offences for which a Jew would be executed, are forbidden to gentiles. The Talmudic rabbis discuss which offences and sub-offences are capital offences and which are merely forbidden.
Maimonides states that anyone who does not accept the seven laws is to be executed. As God compelled the world to follow these laws. However, for the other prohibitions such as the grafting of trees and bestiality he holds that the sons of Noah are not to be executed. Maimonides adds a universalism lacking from earlier Jewish sources. The Talmud differs from Maimonides in that it handles the seven laws as enforceable by Jewish authorities on non-Jews living within a Jewish nation. Nahmanides disagrees with Maimonides reasoning. He limits the obligation of enforcing the seven laws to non-Jewish authorities taking the matter out of Jewish hands. The Tosafot seems to agree with Nahmanides reasoning. According to some opinions, punishment is the same whether the individual transgresses with knowledge of the law or is ignorant of the law.
Subdividing the Seven Laws.
Various rabbinic sources have different positions on the way the seven laws are to be subdivided in categories. Maimonides', in his Mishneh Torah, included the grafting of trees. Like the Talmud he interpreted the prohibition against homicide as including a prohibition against abortion. Rabbi David ben Solomon ibn Abi Zimra, a commentator on Maimonides, expressed surprise that he left out castration and sorcery which were also listed in the Talmud.
In Chullin 92a-b Ulla say that here are 30 laws which the sons of Noah took upon themselves. However he only lists three, namely the three that the Gentiles follow: not to create a Ketubah between males, not to sell carrion in the market and to respect the Torah. The rest of the laws are not listed. Talmud commentator Rashi remarks on this that he does not know the other Commandments that are referred to. Though the authorities seem to take it for granted that Ulla's thirty commandments included the original seven, an additional thirty laws is also possible from the reading. Two different lists of the 30 laws exist. Both lists include an additional twenty-three mitzvot which are subdivisions or extensions of the seven laws. One from the 16th-century work "Asarah Maamarot" by Rabbi Menahem Azariah da Fano and a second from the 10th century Samuel ben Hofni which was recently published from his Judeo-Arabic writings after having been found in the Cairo Geniza. Rabbi Zvi Hirsch Chajes suggests Menahem Azariah of Fano enumerated commandments are not related to the first seven, nor based on Scripture, but instead were passed down by oral tradition.
The 10th-century Rabbi Saadia Gaon added tithes and levirate marriage. The 11th-century Rav Nissim Gaon included "listening to God's Voice", "knowing God" and "serving God" besides going on to say that all religious acts which can be understood through human reasoning are obligatory upon Jew and Gentile alike. The 14th-century Rabbi Nissim ben Reuben Gerondi added the commandment of charity.
Ger toshav (resident alien).
In earlier times, a Gentile living in the Land of Israel who accepted the Seven Laws in front of a rabbinical court was known as a "ger toshav" (literally stranger/resident). The regulations regarding Jewish-Gentile relations are modified in the case of a "ger toshav". Jewish law only allows the official acceptance of a "ger toshav" as a resident in the Land of Israel during a time when the Year of Jubilee ("yovel") is in effect.
Contemporary status.
Historically, some rabbinic opinions consider non-Jews not only not obliged to adhere to all the remaining laws of the Torah, but actually forbidden to observe them.
Noahide law differs radically from Roman law for gentiles ("Jus Gentium"), if only because the latter was enforceable judicial policy. Rabbinic Judaism has never adjudicated any cases under Noahide law, Jewish scholars disagree about whether Noahide law is a functional part of Halakha ("Jewish law").
Some modern views hold that penalties are a detail of the Noahide Laws and that Noahides themselves must determine the details of their own laws for themselves. According to this school of thought – see N. Rakover, "Law and the Noahides" (1998); M. Dallen, "The Rainbow Covenant" (2003) – the Noahide Laws offer mankind a set of absolute values and a framework for righteousness and justice, while the detailed laws that are currently on the books of the world's states and nations are presumptively valid.
In recent years, the term "Noahide" has come to refer to non-Jews who strive to live in accord with the seven Noahide Laws; the terms "observant Noahide" or "Torah-centered Noahides" would be more precise but these are infrequently used. Support for the use of "Noahide" in this sense can be found with the Ritva, who uses the term "Son of Noah" to refer to a Gentile who keeps the seven laws, but is not a Ger Toshav. The rainbow, referring to the Noahide or First Covenant (Genesis 9), is the symbol of many organized Noahide groups, following .
Maimonides.
The Jewish scholar Maimonides (12th century) held that Gentiles may have a part in the world to come just by observing Noahide law and accepts them as given by Moses. Such children of Noah become the status of "Chasidei Umot HaOlam" - Pious People of the World, and are different than children of Noah who only keep the seven laws out of moral/ethical reasoning alone. He writes in his book of laws:"
Some later editions of the Mishneh Torah differ by one letter and read "Nor one of their wise men." The later reading is narrower. Spinoza read Maimonides as using nor and accused him of being narrow and particularistic. Other philosophers such as Hermann Cohen and Moses Mendelssohn have used more inclusive interpretations of the passage by Maimonides.
In either reading, Maimonides appears to exclude philosophical Noahides from being Righteous Gentiles. Thus Maimonides wants to emphasis that a truly Righteous Gentile follows the seven laws because they are divinely revealed and thus are followed out of obedience to God.
Christianity and the Noahide Laws.
The Apostolic Decree recorded in Acts 15 is commonly seen as a parallel to Noahide Law; however, some modern scholars dispute the connection between Acts 15 and Noahide Law, the content of Noahide Law, the historical reliability of the Acts of the Apostles, and the nature of Biblical law in Christianity. The Apostolic Decree is still observed by Eastern Orthodoxy and includes some food restrictions.
The only Noahide law that is not part of the standard moral teaching of mainstream Christianity is the prohibition against eating the flesh of an animal while it is still alive. Many interpret Acts and the Pauline Epistles as making void the dietary laws found in the Torah and known by Noah ( and ). This claim is disputed by many Christians, including the Ethiopian Orthodox Tewahedo Church, the Seventh-day Adventist Church, the Church of God (Seventh Day).
The 18th-century rabbi Jacob Emden proposed that Jesus, and Paul after him, intended to convert the gentiles to the Noahide laws while calling on the Jews to keep the full Law of Moses.
Chabad movement.
Maimonides stated that God commanded Moses to compel the world to accept these seven commandments. In 1983 Rabbi Menachem M. Schneerson urged his followers to actively engage in activities to inform non-Jews about these seven commandments, which had not been done in previous generations.
Sefer Sheva Mitzvot Hashem.
After Rabbi Schneerson started his Noahide Campaign in the 1980s, a codification of the exact obligations of the Gentiles in the spirit of the classical Shulchan Aruch was needed. In 2005, Rabbi Moshe Weiner of Jerusalem accepted to produce an in-depth codification of the Noahide precepts. The work is called "Sefer Sheva Mitzvot HaShem", (The Book of Seven Divine Commandments) published 2008/2009. As it was approved by both of the then presiding chief rabbis of Israel (Rabbi Shlomo Moshe Amar and Rabbi Yonah Metzger) as well as by other Hasidic and non-Hasidic halachic authorities, it can claim an authoritative character and is referred as a "Shulchan Aruch" for Gentiles at many places.
Public recognition.
United States.
In 1987 President Ronald Reagan signed a proclamation speaking of "the historical tradition of ethical values and principles, which have been the bedrock of society from the dawn of civilization when they were known as the Seven Noahide Laws, transmitted through God to Moses on Mount Sinai", and in 1991, Congress stated in the preamble to the 1991 bill that established Education Day in honor of the birthday of rabbi Menachem Mendel Schneerson, the leader of the Chabad movement:
Israeli Druze.
In January 2004, Sheikh Mowafak Tarif, the spiritual leader of Israeli Druze, signed a declaration, which called on non-Jews living in Israel to observe the Noahide Laws. He was joined by the mayor of Shefa-'Amr.
Further reading.
The second edition now online at: http://www.scribd.com/my_document_collections/3551340

</doc>
<doc id="21911" url="https://en.wikipedia.org/wiki?curid=21911" title="Naturism">
Naturism

Naturism, or nudism, is a cultural and political movement practicing, advocating and defending social nudity, most but not all of which takes place on private property. The term may also refer to a lifestyle based on personal, family and/or social nudism.
Definition.
According to the XIV Congress of the International Naturist Federation (Agde, France, 1974), naturism is:
Several other terms ("social nudity", "public nudity", "skinny dipping", "sunning", and "clothes-free") have been proposed as alternative terms for naturism, but none has found the same widespread public acceptance as the older terms "naturism" and (in much of the United States) "nudism".
People interested in social nudity can attend clothes-free beaches and other types of ad-hoc nudist events. At these venues, participants generally need not belong to a naturist club.
Many contemporary naturists and naturist organisations feel that the practice of social nudity should be asexual. For various social, cultural, and historical reasons the lay public, the media, and many contemporary naturists and their organisations often oversimplify the relationship between naturism and sexuality. Current research has begun to explore this complex relationship.
The International Naturist Federation explains:
The usage and definition of these terms varies geographically and historically. Though in the United States, naturism and nudism have the same meaning, in Britain there is a clear distinction.
Nudism is the "act of being naked", while naturism is a "lifestyle" which at various times embraced nature, environment, respect for others, self-respect, crafts, healthy eating, vegetarianism, teetotalism, non-smoking, yoga, physical exercise and pacifism as well as nudity.
In naturist parlance, "textile" or "textilist" is a non-naturist person, non-naturist behaviour or non-naturist facilities. e.g. "the textile beach starts at the flag", "they are a mixed couple – he is naturist, she is textile". "Textile" is the predominant term used in the UK ('textilist' is unknown in British naturist magazines including "H&E naturist"), although some naturists avoid it due to perceived negative or derogatory connotations. "Textilist" is said to be used interchangeably, but no dictionary definition to this effect exists, nor are there any equivalent examples of use in mainstream literature such as those for "textile". "Clothing optional" and "nude optional" (US specific) describe a policy or a venue that allows or encourages nudity but tolerates the wearing of clothes. The opposite is "clothing compulsory"; that is, prohibiting nudity. Adjectival phrases "clothes free" and "clothing free" prescribe where naturism is permitted in an otherwise textile environment, or define the preferred state of a naturist.
The social nudity movement includes a large range of variants including "naturism", "nudism", "Freikörperkultur (FKK)", the "free beach movement" as well as generalized "public lands/public nudity" advocacy. There is a large amount of shared history and common themes, issues and philosophy, but differences between these separate movements remain contentious.
Types of naturism.
Naturism is practised in many ways: Marc Alain Descamps, in his study written in French, classified the types as: individual nudism, nudism within family, nudism in the wild, social nudism. Additionally, militant nudism, including campaigning or extreme naturists, is sometimes considered a separate category.
Personal and family nudity.
Many people are often nude in the privacy of their home or garden, either alone or with members of the family. This may be occasional nudity or as a naturist lifestyle. There are differences of opinion as to whether, and if so to what extent, parents should appear naked in front of their children, and whether children should be nude within the home in the view of their family as well as visitors. This has attracted a great deal of academic study.
A United States study by Alfred Kinsey (1948–1953) found that 75% of the participants stated that there was never nudity in the home when they were growing up, 5% of the participants said that there was "seldom" nudity in the home, 3% said "often", and 17% said that it was "usual". The study found that there was no significant difference between what was reported by men and by women with respect to frequency of nudity in the home.
Gordon and Schroeder in 1995 reported that parental nudity varies considerably from family to family. They say that "there is nothing inherently wrong with bathing with children or otherwise appearing naked in front of them", noting that doing so may provide an opportunity for parents to provide important information. They note that by ages 5 to 6 children begin to develop a sense of modesty, and recommend to parents who wish to be sensitive to their children's wishes that they limit such activities from that age onwards.
Barbara Bonner in 1999 cautioned against nudity in the home if children exhibit sexual play of a type that is considered problematic.
In a 1995 review of the literature, Paul Okami concluded that there was no reliable evidence linking exposure to parental nudity to any negative effect. Three years later, his team finished an 18-year longitudinal study that showed that, if anything, such exposure was associated with slight beneficial effects, particularly for boys.
Social nudism.
The rhetoric of the nudism and anti-nudism movements emphasizes freedom from many of the normal constraints which regulate human interaction in nudist settings, although for different reasons. Using data from French and German beaches, this hypothesis was tested using five different indicators. Little significant variation between nudists and non-nudists within French and German settings is found in their patterns of interactional spacing, while more significant main effects for differences of cultures are found regardless of nudity status. As a subculture, nudists would appear to differ from nonnudists only in their propensity to like to sunbathe in the nude. Their nude status would appear to have none of the de-inhibiting effects often attributed to nudism. By contrast, clear cultural differences between German and French cultures are shown consistent with Hall's high-low context distinction and the Francoeurs' hot-cool sexuality continuum.
Naturist facilities.
At naturist organised events or venues clothing is usually optional, except by swimming pools or sunbathing lawns where complete nudity is expected, weather permitting. This rule is sometimes a source of controversy among some naturists. Staff at a naturist facility are usually required to be clothed due to health and safety regulations.
Facilities for naturists are classified in various ways. A landed or members' naturist club is one that owns its own facilities, while non-landed (or travel) clubs meet at various locations, such as private residences, swimming pools, hot springs, landed clubs and resorts, and rented facilities. Landed clubs can be run by members on democratic lines or by one or more owners who make the rules. In either case, they can determine membership criteria and the obligations of members. This usually involves sharing work necessary to maintain or develop the site.
Some clubs have stricter entrance requirements than some traditional 'country clubs', including the requirement to supply references, a sponsoring member, a trial membership, committee approval and/or, criminal background checks. UK clubs are now required to have child-protection policies in place, and designated child-protection officers. Many clubs promote frequent social activities.
The international naturist organizations were mainly composed of representatives of landed clubs. Nudist colony is no longer a favored term, but it is used by naturists as a term of derision for landed clubs that have rigid non-inclusive membership criteria, and in meta-data on naturist websites.
A holiday centre is a facility that specializes in providing apartments, chalets and camping pitches for visiting holidaymakers. The center is run commercially, and visitors are not members and have no say in the management. Most holiday centers expect visitors to hold an INF card, that is, be a member of their national organization, but some have relaxed this restriction, relying on the carrying of a trade card. Holiday centers can be quite small, just a couple of hectares or large occupying over 300 hectares. In a large holiday centre there will be swimming pools, sports pitches, an entertainment program, kids' clubs, restaurants and supermarkets. Some holiday centres allow regular visitors to purchase their own chalets, and generations of the same families will visit each year. Holiday centres are more tolerant of clothing than members-only clubs; total nudity is usually compulsory in the swimming pools and may be expected on the beaches, while on the football pitches, or in the restaurants in the evening, it is rare.
A naturist resort is, to a European, an essentially urban development where naturism is the norm. Cap d'Agde in France, naturist village Charco del Palo on Lanzarote, Canary Islands, Vera Playa in Spain and Vritomartis in Greece are examples. Some residents use these resorts as a year-round home.
In US usage, a naturist resort can mean a holiday centre.
Freikörperkultur (FKK) literally translated as 'free body culture' is the name for the general movement in Germany. The abbreviation is widely recognised all over Europe and often found on informal signs indicating the direction to a remote naturist beach.
Nude beaches.
Clothing is optional at nude beaches (or "free beaches"). A feature of bathing on a nude beach is the anonymity it offers, with membership of a club not being required, nor detailed application processes, nor pre-booking of visits.
In some European countries, such as Denmark, all beaches are clothing optional, while in others like Germany there are naturist sunbathing areas in public parks, e.g., in Munich and Berlin. Beaches in some holiday destinations, such as Crete, are also clothing-optional, except some central urban beaches. There are two centrally located clothes-optional beaches in Barcelona.
Naturism and sports.
Naturism encourages a healthy life style, and many naturist clubs at times organize and encourage members to take part in local and international sport events and competitions. The German Association for Free Body Culture (DFK) promotes recreational sports and is a member of the German Olympic Sport Federation (DOSB).
Festival naturism.
From Woodstock to Edinburgh, and Nambassa in the southern hemisphere communal nudity is commonly recorded at music and counterculture festivals.
The series of 1970s Nambassa hippie festivals held in New Zealand is a further example of non sexualized naturism. Of the 75,000 patrons who attended the 1979 Nambassa 3 day counterculture Festival an estimated 35% of festival attendees spontaneously chose to remove their clothing, preferring complete or part nudity.
History.
Nudity in social contexts has been practised in various forms by many cultures at all time periods. In Western society nowadays, social nudity is most frequently encountered in the contexts of bathing, swimming and in saunas, whether in single-sex groups, within the family or with mixed-sex friends, but throughout history and in many tropical cultures until now, nudity is a norm at many sports events and competitions.
It is difficult to nominate exactly when naturism started as a movement. The word 'naturism' was used for the first time in 1778 by a French-speaking Belgian, Jean Baptiste Luc Planchon (1734–1781), and was advocated as a means of improving the 'l’hygiène de vie' (natural style of life) and health.
The earliest known naturist club in the "western" sense of the word was established in British India in 1891. The 'Fellowship of the Naked Trust' was founded by Charles Edward Gordon Crawford, a widower, who was a District and Sessions Judge for the Bombay Civil Service. The commune was based in Matheran and had just three members at the beginning; Crawford and two sons of an Anglican missionary, Andrew and Kellogg Calderwood.
The commune fell apart when Crawford was transferred to Ratnagiri; he died soon after in 1894.
In 1902, a series of philosophical papers was published in Germany by Dr. Heinrich Pudor, under the pseudonym Heinrich Scham, who coined the term "Nacktkultur". In 1906 he went on to write a three volume treatise with his new term as its title, which discussed the benefits of nudity in co-education and advocated participating in sports while being free of cumbersome clothing. Richard Ungewitter ("Nacktheit", 1906, "Nackt", 1908, etc.) proposed that combining physical fitness, sunlight, and fresh air bathing, and then adding the nudist philosophy, contributed to mental and psychological fitness, good health, and an improved moral-life view. Major promoters of these ideas included Adolf Koch and Hans Suren. Germany published the first journal of nudism between 1902 and 1932.
The wide publication of those papers and others, contributed to an explosive worldwide growth of nudism, in which nudists participated in various social, recreational, and physical fitness activities in the nude. The first organized club for nudists on a large scale, "Freilichtpark" (Free-Light Park), was opened near Hamburg in 1903 by Paul Zimmerman.
In 1919, German doctor Kurt Huldschinsky discovered that exposure to sunlight helped to cure rickets in many children, causing sunlight to be associated with improved health.
Naturism became a more widespread phenomenon in the 1920s, in Germany, the United Kingdom, France and other European countries and spread to the United States where it became established in the 1930s.
By 1951, the national federations united to form the International Naturist Federation or INF. Some naturists preferred not to join clubs, and after 1945, pressure was put to designate beaches for naturist use.
From the middle of the 20th century, with changing leisure patterns, commercial organisations began opening holiday resorts to attract naturists who expected the same – or better – standards of comfort and amenity offered to non-naturists. More recently, naturist holiday options have expanded to include cruises.
Philosophy.
Naturism had many different philosophical sources and means many things to different people. There is no one definition. In 1974, the INF defined naturism as:
At one end of the spectrum are the nudists who just enjoy a nude life style, and at the other are the naturists, who have deeply held beliefs and see communal nudity as just one of many important principles.
The naturist philosophy has several sources, many of which can be traced back to early 20th century health and fitness philosophies in Germany and England, although the concepts of returning to nature and creating equality have much deeper roots.
Naturist ideals.
Individuals have formed naturist groups for a variety of specific purposes. It is generally agreed by naturist organisations that eroticism and blatant sexuality have no place in naturism and are, in fact, antithetical to its ideals. Reasons that have at times been given:
Naturism and the romantics.
Walt Whitman American writer, A Sun-bathed Nakedness:
Henry David Thoreau, "In wildness is the preservation of the world.", Walking:
Naturism was part of a literary movement in the late 1800s (see the writings of André Gide) which also influenced the art movements of the time specifically Henri Matisse and other Fauve painters. This movement was based on the French concept of joie de vivre, the idea of revelling freely in physical sensations and direct experiences and a spontaneous approach to life.
Naturism for health.
Sunlight has been shown to be beneficial in some skin conditions and enables the body to make vitamin D, but with the increased awareness of skin cancer, wearing of sunscreen is now part of the culture.
Naturism in Europe.
Finland.
In Finnish culture, nudism is considered to be a relatively normal way to live. It is not uncommon to see entire families spending time together naked. Families may be naked while bathing in a sauna, swimming in a pool, or playing on a beach, and it's not unusual to see children playing naked in a kindergarten or family yard for example. Nudity as a whole is considered less taboo than many other countries.
France.
In 1903 la "Revue des deux mondes" published a report on German naturism and S. Gay created a naturist community at Bois-Fourgon. In 1907, supported by his superiors, Abbé Legrée encouraged the students at his catholic college to bathe nude on the rocky beaches near Marseille.
Marcel Kienné de Mongeot is credited with starting naturism in France in 1920. His family had suffered from tuberculosis, and he saw naturism as a cure and a continuation of the traditions of the ancient Greeks. In 1926, he started the magazine "Vivre intégralement" (later called "Vivre") and the first French naturist club, "Sparta Club" at Garambouville, near Evreux. The court action that he initiated, established that nudism was legal on private property that was fenced and screened.
Drs. André and Gaston Durville bought a 70 hectare site on the Île du Levant where they established the village of Héliopolis. The village was open to the public. In 1925 Dr François Fougerat de David de Lastours wrote a thesis on heliotherapy. and in that year opened the "Club gymnique de France". In 1936, the naturist movement was officially recognised.
Albert and Christine Lecocq were active members of many of these clubs, but after disagreements left and In 1944 Albert and Christine Lecocq founded the "Club du Soleil" with members in 84 cities. In 1948 they founded the FFN, in 1949 they started the magazine, "Vie au Soleil" and in 1950 opened the CHM Montalivet, the world's first naturist holiday centre where the INF was formed.
The Quartier Naturiste at Agde offers a different form of social nudity. Euronat is the largest holiday centre (335ha) situated 10 km north of Montalivet. Naturism employs more than 3000 people, and is estimated to be worth 250 million Euro to the French economy. France is represented on the INF by the FFN.
Germany.
German naturism was part of the Lebensreform movement and the Wandervogel youth movement of 1896, from Steglitz, Berlin which promoted ideas of fitness and vigour. At the same time doctors of the Natural Healing Movement were using heliotherapy, treating diseases such as TB, rheumatism and scrofula with exposure to sunlight.
Nacktkultur, a term coined in 1903 by Heinrich Pudor, flourished. Nacktkultur connected nudity, vegetarianism and social reform. It was practised in a network of 200 members clubs. The movement gained prominence in the 1920s as offering a health giving life-style with Utopian ideals. Germany published the first naturist journal between 1902 and 1932.
It became politicised by radical socialists who believed it would lead to classlessness and a breaking down of society. It became associated with pacificism.
In 1926, Adolf Koch established a school of naturism in Berlin; encouraging a mixing of the sexes, open air exercises, and a programme of "sexual hygiene". In 1929, the Berlin school hosted the first International Congress on Nudity.
During the National Socialist "Gleichschaltung" era, all naturist clubs had to register with the "Reichsbund für Leibesübungen", which meant excluding Jews and Communists. Also, they had to keep all activities hidden in the countryside where there was little chance of being seen by others. The status as a West German "sports federation" member gave the clubs rights and privileges (e.g. tax exemptions) so the naturist clubs remained in the federation after the war had ended.
After the war, East Germans were free to practice naturism, chiefly at beaches rather than clubs (private organizations being regarded as potentially subversive). Naturism became a large element in DDR politics. The "Proletarische Freikörperkulturbewegung" subsection of the Workers Sports Organisation had 60,000 members.
Today, following reunification there are many clubs, parks and beaches open to naturists.
though nudity has become less common in the former eastern zone. Germans are typically the most commonly seen foreigners at nude beaches in France and around Europe.
Poland.
First reported naturist society was established in 1897 in Grudziądz. In pre-war and post-war Poland, naturism was practised in closed and secluded areas. Reported places for naturism were Zaleszczyki (in today's Ukraine) and Otwock. Under the communism regime, Poland's naturism became unofficial and was practiced mostly by the artistic boheme near Krynica Morska, Międzyzdroje and Dębki.
In the early 1980s naturism became popular mostly due to increased interest in media. As the pop song "Chałupy Welcome To" (about the naturist beach in Chałupy, featuring beach nudity in the clip) became the 1985 summer hit in Poland, the nude seaside locations like Chałupy or Rowy became known to an average Polish sunbather. Polish Naturist Society was formed and after the number of lawsuits, naturism became tolerated in selected "unofficial" beaches and distant spots.
In today's Poland naturism is practiced in number of the seaside and inland beaches. Most Polish beaches are actually clothes-optional rather than naturist. Among the most popular locations are Międzydroje-Lubiewo, Grzybowo, Rowy, Dębki, Gdańsk-Stogi and Piaski. The most popular inland locations include Warsaw (Wał Miedzeszyński), Kazimierz Dolny and Kryspinów near Kraków. In the winter season, naturism is practiced by organized groups in Warsaw and Tri-City. Public naturist events are held bi-monthly in Poznań-Koziegłowy and Łódź waterpark.
Portugal.
Naturism in Portugal had its first historical record around 1920, linked to the Portuguese Naturist Society, of which the anarcho-syndicalist José Peralta was a prominent member. Nudity was already being practiced on Costa da Caparica beaches. With the beginning of the New State authoritarian regime in the 1930s, the naturist movement was limited to vegetarian and alternative medicines, since nudity was banned and associated to the crime of "indecency". Only after the end of the New State regime in 1974 (April, 25th) the activities linked to the practice of nudity were resumed.
The "Federação Portuguesa de Naturismo" (Portuguese Naturist Federation) or FPN was founded on the March 1st, 1977, at a meeting in Lisbon.
At the present, there are seven official naturist beaches in Portugal. Besides these, there are several dozens of beaches were the practice of naturism is common. There are also several naturist campings and resorts.
Spain.
Public nudity on the beach is not illegal in Spain. Topless sunbathing is possible on beaches in front of smaller villages. 
United Kingdom.
In the United Kingdom, the first official nudist club was established in Wickford, Essex in 1924. According to Michael Farrar, writing for British Naturism the club adopted the name "Moonella Group" from the name of the owner of the ground, "Moonella", and called its site The Camp. Moonella, who was still living in 1965 but whose identity remains to be discovered, had inherited a house with land in 1923 and made it available to certain members of the New Gymnosophy Society. This society had been founded a few years before by H.C. Booth, M.H. Sorensen and Rex Wellbye under the name of the English Gymnosophical Society. It met for discussions at the Minerva Cafe at 144 High Holborn in London, the headquarters of the Women's Freedom League. Those who were permitted to join the Moonella Group were carefully selected, and the club was run by an "aristocracy" of the original members, all of whom had "club names" to preserve their anonymity. The club closed in 1926 because of building on adjacent land.
By 1943 there were a number of these so-called "sun clubs" and together they formed the British Sun Bathers Association or BSBA. In 1954 a group of clubs unhappy with the way the BSBA was being run split off to form the Federation of British Sun Clubs or FBSC. In 1961, the BSBA Annual Conference agreed that the term nudist was inappropriate and should be discarded in favour of naturist. The two organisations rivalled each other before eventually coming together again in 1964 as the Central Council for British Naturism or CCBN. This organisation structure has remained much the same but it is now called British Naturism which is often abbreviated to BN. BN is currently converting to a company limited by guarantee.
The first official nude beach was opened at Fairlight Glen in Covehurst Bay near Hastings in 1978 (not to be confused with Fairlight Cove, which is 2 km to the east) followed later by the beaches at Brighton and Fraisthorpe. Bridlington opened in April 1980.
Naturism in North America.
Canada.
In Canada, individuals around the country became interested in nudism, skinny-dipping, and physical culture in the early part of the 20th century. After 1940 they had their own Canadian magazine, "Sunbathing & Health", which occasionally carried local news. Canadians had scattered groups in several cities during the 1930s and 1940s, and some of these groups attracted enough interest to form clubs on private land. The most significant clubs were the Van Tan Club, formed in 1939, and continues today in North Vancouver, BC., and, in Ontario, the Sun Air Club.
Canadians who served in the military during the Second World War met like-minded souls from across the country, and often visited clubs while in Europe. They were a ready pool of recruits for post-war organizers. A few years later, the wave of post-war immigration brought many Europeans with their own extensive experience, and they not only swelled the ranks of membership, but often formed their own clubs, helping to expand nudism from coast to coast.
Most of those clubs united in the Canadian Sunbathing Association, which affiliated with the American Sunbathing Association in 1954. Several disagreements between eastern and western members of the CSA resulted in the breakup of CSA into the Western Canadian Sunbathing Association (WCSA) and the Eastern Canadian Sunbathing Association (ECSA) in 1960. The ECSA endured much in-fighting over the next decade and a half, leading to its official demise in 1978. The WCSA continues today as the American Association for Nude Recreation – Western Canadian Region (www.aanr-wc.com), a region of the American Association for Nude Recreation (AANR) which itself was formerly known as the ASA.
In 1977 the Fédération québécoise de naturisme (FQN) was founded in Quebec, by Michel Vaïs, who had experienced European naturism at Montalivet. In 1985 the Federation of Canadian Naturists (FCN) was formed with the support of the FQN. In 1988 the FQN and FCN formed the FQN-FCN Union as the official Canadian representative in the International Naturist Federation (INF).
United States.
In 1925, Katherine and Herman Shoshinki were familiar with nudism from Germany from 1918 to 1923. Kurt Barthel founded the American League for Physical Culture in 1929 and organized the first nudist event. In about 1930 they organized the American Gymnosophical Association. Barthel founded America's first official nudist camp, Sky Farm in New Jersey, in May, 1932. Around 1932, AGA established the Rock Lodge Club as a nudist facility in Stockholm, New Jersey and Ilsley Boone, a Dutch Reformed minister, formed the Christian naturism movement. Naturism began expanding nationwide. Nudism venues were teetotal until 1970,
The American Association for Nude Recreation (AANR) is the national naturist organization. Arnd Krüger compared nudists in Germany and the United States and came to the conclusion that in Germany the racial aspects ("Zuchtwahl") were important for the breakthrough (e.g. the Commanding General of the Army served as patron for nudists events), while in the U.S. nudism was far more commercial and had thus more difficulties. The AANR withdrew from the INF in 2010.
In 2009, a campaign to promote Nudism in the United States occurred with an effort by AANR to record the largest simultaneous Skinny Dip at several U.S. Clubs and beaches, occurring on July 11 of that year.
In 2010, A new organization formed called Young Naturists and Nudists America which is mostly focused around the younger generation as well as social issues, such as body image.
In 2014, an organization called Unconstitutional Arkansas was created to highlight the unconstitutionality of laws that prohibit or impede nudism. The organization uses Arkansas law § 5-68-204 as a case study, but claims all anti-nudism laws infringe the constitutional right to assemble.
Naturism in Asia.
Overall, public nudity in Asia is not tolerated although some traditional, cultural or religious nudity has survived the introduction of Western moral values against nudity, such as the Jain Digambara monks in India, hot springs in Taiwan and Japan and some traditional tribes in Papua. Nudism and naked recreation is slowly developing in some countries, mainly Indonesia (Bali) and Thailand. Nudists meet on the internet (e.g. Bareskinasia.com) and organize activities in remote or private locations. Several nudists also have their own blogs.
Indonesia.
In the seventies, nudity on Bali's remote and deserted beaches was common but with the massive growth of tourism, these beaches have disappeared. In 2002 nudity was declared illegal on Petitenget Beach, the last beach in Seminyak that tolerated discreet nudity. Individuals began to practice nudity in private villas and resorts, first for gay men only at the Laki Uma Villa and in 2004 the first adult-only nudist resort for both genders, Bali au Naturel, opened its doors and expanded from 3 to 15 rooms and added from two more swimming pools.
Nepal.
Nudism is considered taboo in Nepal. Although there are no laws governing nudism, people may be detained, arrested and fined for public nudity. Nevertheless, many Hindu male sages practice nudism and they are not legally detained. Nudist sages can be seen in Pashupatinath.
Thailand.
Nudism has been successfully introduced in Pattaya (Chan Resort and more recently La Sala Villa), and several other small nudist resorts have been created all over Thailand. A gay hotel and sauna (Sansuk Hotel) located in Pattaya now also authorizes nudity in and around the swimming pool.
Issues in social nudity.
Naturism addresses, challenges and explores a myriad of sometimes taboo subjects: stereotypes and mores relating to the nude appearance of the human body, mixed sex nudity, personal space, human sexuality, gymnophobia, modesty, physical attractiveness, vanity, objectification, exploitation and consent. It can thus be controversial. Descamps assembled a list of criticisms of naturism: it is too cold; normal bodies look ugly—it is only for the physically beautiful; it is too embarrassing; it is against the laws of nature, against the law, or against religion; "nudism makes me think of sex"; it is for primitive people or animals.
Naturism can sometimes contain aspects of eroticism, although the debate about this is often simplified and seen negatively in the media and the public mind and by many modern naturists and naturist organisations. Historically the experience and discussion of erotic feelings during naturist activities such as dance and gymnastics played an important part in early Germanic naturism and formed part of its 'positive' connection with nature. However, it was when naturism arrived in the more sexually conservative cultures of the UK and the United States that the expression and discussion of eroticism within naturism became frowned upon.
Smith states This statement is in response to the quote "The world of naturism is in trouble. Membership is falling, and fewer young people than ever are getting involved. Has the great nude adventure run its course? "
Smith and King pose the following points in their 2009 peer reviewed paper "Naturism and Sexuality:broadening our approach to sexual wellbeing "
Issues for the naturist community.
Many countries and states have laws which adversely affect naturists. Oftentimes, these laws are intended to address "indecent exposure", but are so broadly written that they criminalize ordinary, non-sexual nudity. Some laws, however, specifically target naturism. For example, in Arkansas in the United States, not only is nudism illegal (even on private property), it is a crime to "promote" or "advocate" (i.e. express a favourable opinion about) nudism.
Any social group is said to go through four phases:
forming, storming, norming, performing, wrote Bruce Tuckman in 1965. In this context one can understand some of the current pressures on various aspects of naturism:
Naturist and nudist magazines.
Magazines published by, for or purportedly about naturists can be grouped:
Magazines in the second and, occasionally, third grouping feature naturist editorial and advertising, while some naturists argue over which magazines belonged in which of these categories – these views may change as publishers and editors change. Many clubs and groups have benefitted from magazines which, while not exclusively or even predominantly naturist in character, made naturist information available to many who would not otherwise have been aware of it. (These days, the information and advertising provided online, and the wide availability of free online porn, has meant the disappearance of old-style 'skin' magazines presenting significant glamour content masquerading as or alongside naturist content. Naturist magazines have to appeal strongly to naturists to succeed – they cannot sit on the fence between naturism and glamour.)
Some naturists still feel that the worthwhile editorial content in some magazines is not a fair balance for the disapproved-of photographic content.
Naturist and nudist photography, films and videos.
Some naturist clubs have been willing to allow filming by the media on their grounds, though content that proved not to be of genuine naturism can end up being parodied by the media as the norm.
Some commercial 'naturist' DVDs are dominated by imagery of naked children. Such material can be marketed in ways that appear to appeal directly to paedophile inclinations, and ownership of these DVDs (and their earlier video cassette incarnations) has resulted in successful British prosecutions for possession of indecent images of children. One case was appealed, unsuccessfully, to the European Court of Human Rights. The precedents set by the court cases mean that possession in Britain of any naturist image of a child is, potentially, grounds for prosecution.
Photo shoots, including major high-profile works by Spencer Tunick, are done on public places including beaches.

</doc>
<doc id="21916" url="https://en.wikipedia.org/wiki?curid=21916" title="Nordea">
Nordea

Nordea Bank AB, commonly referred to as Nordea, is a Swedish financial services group operating in Northern Europe. The bank is the result of the successive mergers and acquisitions of the Finnish, Danish, Norwegian and Swedish banks of Merita Bank, Unibank, Kreditkassen (Christiania Bank) and Nordbanken that took place between 1997 and 2000. The Baltic countries and Poland are today also considered part of the home market. The largest share holder of Nordea is Sampo, a Finnish insurance company with around 20% of the shares. Nordea is listed on the Copenhagen Stock Exchange, Helsinki Stock Exchange and Stockholm Stock Exchange.
Nordea is headquartered from Stockholm and has more than 1,400 branches. The bank is present in 19 countries around the world, operating through full service branches, subsidiaries and representative offices.
The international corporate banking division has branches in Germany (Frankfurt), United Kingdom (London), Singapore, China (Shanghai) and in the United States (New York). Nordea International private banking has its headquarters in Luxembourg with branches in Switzerland (Zurich) and Singapore. Nordea also has representative offices in Brazil (São Paulo) and China (Beijing). 
Nordea currently serves 11 million private and 700,000 active corporate customers. The group also operates an internet bank, which has more than 5.9 million online customers doing more than 260 million payments per year.
History.
Nordea is the result of the successive mergers and acquisitions of the Swedish, Finnish, Danish and Norwegian banks of Nordbanken, Merita Bank, Unibank and Kreditkassen (Christiania Bank) that took place between 1997 and 2000. The name Nordea comes from the Swedish bank Nordbanken, which was based on PK-banken (Post och Kreditbanken; owned by Swedish state) which in 1990 purchased the smaller private bank Nordbanken, and picked up that name. PK-banken was formed in 1974 at a merger between Postbanken (formed 1884) and Sveriges Kreditbank (formed 1923), both state owned. Merita Bank was a 1995 merger of the former main rivals in Finland, the originally Svecoman Union Bank of Finland ("Suomen Yhdyspankki") founded in 1842 and the Fennoman National Share Bank ("Kansallis-Osake-Pankki") founded in 1889.
The private Nordbanken was formed in 1986 at a merger between two smaller private local banks, Uplandsbanken and Sundsvallsbanken. In 1991 the Swedish banking crisis, resulting from deregulated markets and a housing price bubble, forced the government to nationalise Nordbanken for 64 billion kronor. Bad debts were transferred to the asset-management companies Securum and Retriva which sold off the assets.
Ownership.
Nordea is owned by:
Nordea Markets.
Nordea Markets is the international markets operation of Nordea. It handles a broad range of investment banking products and services including fixed income, currencies, commodities, equities, debt capital markets, and corporate finance. It also supplies advisory services and internationally acknowledged economic research and analysis.
There are approximately 2,200 employees including Financial Risk Control and Capital Markets Services. Its main operational centres are in Copenhagen (also the main trading floor), Helsinki, Oslo and Stockholm, and with regional offices also in Estonia, Latvia, Lithuania, Poland, Russia, Singapore and USA.
The organisation's stated aim is to provide rapid, easy access to market and trading facilities and a strong local presence to its customers in all its regions. It operates with a mission statement of "Making it possible" and a vision statement of "A great European, capital markets and investment banking organisation, acknowledged for its people, creating superior value for customers and shareholders".
Online theft.
In 2007 Nordea was the subject of an online phishing scam. The amount of money involved was "between seven and eight million SEK". The theft was perpetrated by targeting Nordea customers with phishing emails containing a trojan horse, that was especially made for this robbery. Apparently these emails were sent out over a period of 15 months. According to Nordea, at least 250 people had unwittingly installed the trojan. The thieves evaded detection by limiting their transfers to small sums. Nordea has refunded all the victims and has implemented a new security system, Chip Authentication Program
Panama document leak.
The largest financial group in the Nordic region, Nordea has despite warnings from the Swedish Financial Supervisory Authority (FI) been active in infamous tax havens according to the Panama papers.
The Nordea section in Luxemburg has in the years 2004-2014 founded nearly 400 offshore companies in Panama and the British Virgin Islands for their customers.
The Swedish Financial Supervisory Authority (FI) has pointed out that there's "serious deficiencies" in how Nordea monitors money laundering and has given the bank two warnings. In 2015 Nordea had to pay the largest possible fine - over 5 miljon EUR.
In 2012 Nordea asked Mossack Fonseca to change documents retroactively so that three Danish customers power of attorney documents had been in force since 2010.
The director for Nordea Private banking Thorben Sanders admits that before 2009 they didn't screen for customers that tried to evade tax. "In the end of 2009 we decided that our bank shall not be a means of tax evasion" says Thorben Sanders.
As a consequence of the leaked documents the Swedish Financial Supervisory Authority (FI) stated on 4th April 2016 that they had started an investigation into the conduct of Nordea, the largest financial group in the Nordic region. The Swedish minister of Finance Magdalena Andersson characterized the conduct of Nordea as "a crime" and "totally unacceptable"
Other Swedish banks are present in the documents but Nordea occurs 10,902 times and the bank with second most matches occurs with 764 matches.
The Prime Minister of Sweden Löfven said in 2016 that he is very critical to the conduct of the large bank Nordea, and their role and says "Â- They are on the list of shame too".
Awards.
Euromoney financial magazine named Nordea the "best provider of private banking services in the Nordic and Baltic region" each year from 2008 to 2014.

</doc>
<doc id="21918" url="https://en.wikipedia.org/wiki?curid=21918" title="Normal subgroup">
Normal subgroup

In abstract algebra, a normal subgroup is a subgroup which is invariant under conjugation by members of the group of which it is a part. In other words, a subgroup "H" of a group "G" is normal in "G" if and only if "gH" = "Hg" for all "g" in "G", i.e., the sets of left and right cosets coincide. Normal subgroups (and "only" normal subgroups) can be used to construct quotient groups from a given group.
Évariste Galois was the first to realize the importance of the existence of normal subgroups.
Definitions.
A subgroup "N" of a group "G" is called a normal subgroup if it is invariant under conjugation; that is, for each element "n" in "N" and each "g" in "G", the element "gng"−1 is still in "N". We write
For any subgroup, the following conditions are equivalent to normality. Therefore, any one of them may be taken as the definition:
The last condition accounts for some of the importance of normal subgroups; they are a way to internally classify all homomorphisms defined on a group. For example, a non-identity finite group is simple if and only if it is isomorphic to all of its non-identity homomorphic images, a finite group is perfect if and only if it has no normal subgroups of prime index, and a group is imperfect if and only if the derived subgroup is not supplemented by any proper normal subgroup.
Properties.
Lattice of normal subgroups.
The normal subgroups of a group "G" form a lattice under subset inclusion with least element {"e"} and greatest element "G". Given two normal subgroups "N" and "M" in "G", meet is defined as
and join is defined as 
The lattice is complete and modular.
Normal subgroups and homomorphisms.
If "N" is normal subgroup, we can define a multiplication on cosets by
This turns the set of cosets into a group called the quotient group "G/N". There is a natural homomorphism "f": "G" → "G/N" given by "f"("a") = "aN". The image "f"("N") consists only of the identity element of "G/N", the coset "eN" = "N".
In general, a group homomorphism "f": "G" → "H" sends subgroups of "G" to subgroups of "H". Also, the preimage of any subgroup of "H" is a subgroup of "G". We call the preimage of the trivial group {"e"} in "H" the kernel of the homomorphism and denote it by ker("f"). As it turns out, the kernel is always normal and the image "f"("G") of "G" is always isomorphic to "G"/ker("f") (the first isomorphism theorem). In fact, this correspondence is a bijection between the set of all quotient groups "G"/"N" of "G" and the set of all homomorphic images of "G" (up to isomorphism). It is also easy to see that the kernel of the quotient map, "f": "G" → "G/N", is "N" itself, so we have shown that the normal subgroups are precisely the kernels of homomorphisms with domain "G".

</doc>
<doc id="21919" url="https://en.wikipedia.org/wiki?curid=21919" title="Munkar and Nakir">
Munkar and Nakir

Munkar and Nakir () (English translation: "The Denied and The Denier") in Islamic eschatology, are angels who test the faith of the dead in their graves.
Muslims believe that, after death, a person's soul passes through a stage called barzakh, where it exists in the grave (even if the person's body was destroyed, the soul will still rest in the earth near their place of death). The questioning will begin when the funeral is over and the last person of the funeral congregation has stepped 40 steps away from the grave. Nakir and Munkar prop the deceased soul upright in the grave and ask three questions: "Who is your Lord? Who is your Prophet? What is your religion?". A righteous believer will respond correctly, saying that their Lord is Allah, that Muhammad is their prophet and that their religion is Islam. If the deceased answers correctly, the time spent awaiting the resurrection is pleasant. Those who do not answer as described above are chastised until the day of judgment.
These angels are described as having solid black eyes, having a shoulder span measured in miles, and carrying hammers "so large, that if all of mankind tried at once to move them a single inch, they would fail". When they speak, tongues of fire come from their mouths. If one answers their questions incorrectly, one is beaten every day, other than Friday, until Allah gives permission for the beating to stop.
Muslims believe that a person will correctly answer the questions not by remembering the answers before death (compare with the Egyptian Book of the Dead) but by their iman and deeds such as salat and shahadah (the Islamic profession of faith).
Munkar is sometimes transliterated as Monkir.

</doc>
<doc id="21920" url="https://en.wikipedia.org/wiki?curid=21920" title="Napalm">
Napalm

Napalm is a flammable liquid used in warfare. It is a mixture of a gelling agent, and either petroleum or a similar fuel. It was initially used as an incendiary device against buildings and later primarily as an anti-personnel weapon, as it sticks to skin and causes severe burns when on fire. Napalm was developed in 1942 in a secret laboratory at Harvard University, by a team led by chemist Louis Fieser. Its first recorded use was in the European theatre of war during World War II. It was used extensively by the US in incendiary attacks on Japanese cities in World War II as well as during the Korean War and Vietnam War.
"Napalm" is a combination of the names of two of the constituents of the thickening/gelling agent: co-precipitated aluminium salts of naphthenic and palmitic acids. ""Napalm B"" is the more modern version of napalm and, although distinctly different in its chemical composition, is often referred to simply as "napalm".
Forms.
Napalm was used in flamethrowers, bombs and tanks in World War II. It is believed to have been formulated to burn at a specific rate and to adhere to surfaces to increase its stopping power. During combustion, napalm rapidly deoxygenates the available air and generates large amounts of carbon monoxide and carbon dioxide.
Alternative compositions exist for different uses, e.g. triethylaluminium, a pyrophoric compound that aids ignition.
Development.
Use of fire in warfare has a long history. Greek fire, also described as "sticky fire" (πῦρ κολλητικόν, "pýr kolletikón"), is believed to have had a petroleum base. The development of napalm was precipitated by the use of jellied gasoline mixtures by the Allied forces during World War II. Latex, used in these early forms of incendiary devices, became scarce in the Pacific Theater of Operations, since natural rubber was almost impossible to obtain after the Japanese army captured the rubber plantations in Malaya, Indonesia, Vietnam, and Thailand.
This shortage of natural rubber prompted chemists at US companies such as Du Pont and Standard Oil, and researchers at Harvard University, to develop factory-made alternatives—artificial rubber for all uses, including vehicle tires, tank tracks, gaskets, hoses, medical supplies and rain clothing. A team of chemists led by Louis Fieser at Harvard University was the first to develop synthetic napalm, during 1942. "The production of napalm was first entrusted to Nuodex Products, and by the middle of April 1942 they had developed a brown, dry powder that was not sticky by itself, but when mixed with gasoline turned into an extremely sticky and inflammable substance." One of Fieser's colleagues suggested adding phosphorus to the mix which increased the "ability to penetrate deeply...into the musculature, where it would continue to burn day after day."
On 4 July 1942, the first test occurred on the football field near the Harvard Business School. Tests under operational conditions were carried out at Jefferson Proving Ground on condemned farm buildings, and subsequently at Dugway Proving Ground on buildings designed and constructed to represent those to be found in German and Japanese towns. This new mixture of chemicals was widely used in the Second World War in incendiary bombs and in flamethrowers.
From 1965 to 1969, the Dow Chemical Company manufactured napalm B for the American armed forces. After news reports of napalm B's deadly and disfiguring effects were published, Dow Chemical experienced boycotts of its products, and its recruiters for new chemists, chemical engineers, etc., graduating from college were subject to campus boycotts. The management of the company decided that its "first obligation was the government." Meanwhile, napalm B became a symbol for the Vietnam War.
Military use.
Napalm was first employed in incendiary bombs and went on to be used as fuel for flamethrowers.
The first recorded strategic use of napalm incendiary bombs occurred in an attack by the US Army Air Force on Berlin on 6 March 1944, using American AN-M76 incendiary bombs with PT-1 (Pyrogel) filler. The first known tactical operation was by De Havilland D.H.98 Mosquito FB Mk.VIs of No. 140 Wing RAF, Second Tactical Air Force on 14 July 1944, which also employed the AN-M76 incendiary in a reprisal attack on the 17th SS Panzergrenadier Division „Götz von Berlichingen“ in Bonneuil-Matours. Soldiers of this Waffen SS unit had captured and then killed a British SAS prisoner-of-war, Lt. Tomos Stephens, taking part in Operation Bulbasket, and seven local Resistance fighters. Although it was not known at the time of the air strike, 31 other POWs from the same SAS unit, and an American airman who had joined up with the SAS unit, had also been executed.
Further use of napalm by American forces occurred in the Pacific Theater of Operations, where in 1944 and 1945, napalm was used as a tactical weapon against Japanese bunkers, pillboxes, tunnels, and other fortifications, especially on Saipan, Iwo Jima, the Philippines, and Okinawa, where deeply dug-in Japanese troops refused to surrender. Napalm bombs were dropped by aviators of the U.S. Navy, the United States Army Air Forces, and the U.S. Marine Corps in support of their ground troops.
Then, when the U.S. Army Air Forces on the Marianas Islands ran out of conventional thermite incendiary bombs for their B-29 Superfortresses to drop on Japanese cities, its top commanders, such as General Curtis LeMay, turned to napalm bombs to continue fire raids on the large Japanese cities.
In the European Theater of Operations napalm was used by American forces
Napalm B was also used during the Greek Civil War between the Greek Army and Communist rebels. During 1949, the last year of the war, the United States increased its military aid to the Greek Government by introducing a new weapon to finish off the war: napalm B. The first napalm attack in Greece took place on the mountain of Grammos, which was the stronghold of the Communist rebels.
Napalm B was also widely used by the United Nations military forces during the Korean War. These Allied ground forces in Korea were frequently outnumbered, and often greatly, by their Chinese and North Korean attackers, but the U.S. Air Force and the U.S. Navy naval aviators had control of the air over nearly all of the Korean Peninsula. Hence, close air support of the ground troops along the border between North Korea and South Korea was vital, and the American and other U.N. aviators turned to napalm B as an important weapon for defending against communist ground attacks. Napalm was used most notably during the defense of "Outpost Harry" in South Korea during the night of June 10–11, 1953.
Napalm B became an intrinsic element of U.S. military action during the Vietnam War as forces increasingly employed its widespread tactical as well as psychological effects. Reportedly about 388,000 tons of U.S. napalm bombs were dropped in the region between 1963 and 1973, compared to 32,357 tons used over three years in the Korean War, and 16,500 tons dropped on Japan in 1945.
The U.S. Air Force and U.S. Navy used napalm with great effect against all kinds of targets to include troops, tanks, buildings, jungles, and even railroad tunnels. The effect was not always purely physical as napalm had psychological effects on the enemy as well.
Other uses include: by France during the First Indochina War (1946–1954), the Algerian War (1954–1962), the Portuguese Colonial War (1961–1974), The Six-Day War by Israel (1967), in Nigeria (1969), India and Pakistan (1965 and 1971), Turkey during the Battle of Tylliria in Cyprus in 1964 and again during the invasion of Cyprus (1974), by Morocco during the Western Sahara War (1975–1991), Iran (1980–88), Egypt (1973), Iraq (1980–88, 1991), Angola (1993), Yugoslavia (1991-1996), and by Argentina (1982).
Effects on people.
""Napalm is the most terrible pain you can imagine," said Kim Phúc, a napalm bombing survivor known from a famous Vietnam War photograph. "Water boils at 100 degrees Celsius (212°F). Napalm generates temperatures of 800 to 1,200 degrees Celsius (1,500-2,200°F).""
When used as a part of an incendiary weapon, napalm can cause severe burns (ranging from superficial to subdermal), asphyxiation, unconsciousness, and death. In this implementation, napalm fires can create an atmosphere of greater than 20% carbon monoxide and firestorms with self-perpetuating winds of up to . One of the main anti-personnel features of napalm is that it sticks to human skin, with no practical method for removal of the burning substance.
Napalm is effective against dug-in enemy personnel. The burning incendiary composition flows into foxholes, trenches and bunkers, and drainage and irrigation ditches and other improvised troop shelters. Even people in undamaged shelters can be killed by hyperthermia, radiant heat, dehydration, suffocation, smoke exposure, or carbon monoxide poisoning.
One firebomb released from a low-flying plane can damage an area of .
International law.
International law does not specifically prohibit the use of napalm or other incendiaries against military targets, but use against civilian populations was banned by the United Nations Convention on Certain Conventional Weapons (CCW) in 1980. Protocol III of the CCW restricts the use of all incendiary weapons, but a number of countries have not acceded to all of the protocols of the CCW. According to the Stockholm International Peace Research Institute (SIPRI), countries are considered a party to the convention, which entered into force as international law in December 1983, as long as they ratify at least two of the five protocols. The United States signed it approximately 25 years after the General Assembly adopted it, on 21 Jan 2009: President Barack Obama's first full day in office. Their ratification, however, is subject to a reservation that says it can disregard the treaty at its discretion if doing so would save civilian lives.

</doc>
<doc id="21921" url="https://en.wikipedia.org/wiki?curid=21921" title="Northern Crusades">
Northern Crusades

The Northern Crusades or Baltic Crusades were crusades undertaken by the Christian kings of Denmark, Poland and Sweden, the German Livonian and Teutonic military orders, and their allies against the pagan peoples of Northern Europe around the southern and eastern shores of the Baltic Sea. Swedish and German Catholic campaigns against Russian Eastern Orthodox Christians are also sometimes considered part of the Northern Crusades.
Some of these wars were called crusades during the Middle Ages, but others, including most of the Swedish ones, were first dubbed crusades by 19th-century romantic nationalist historians. The East Baltic world was transformed by military conquest: first the Livs, Latgallians and Estonians, then the Semigallians, Curonians, Prussians and Finns proper, Tavastians and Karelians underwent defeat, forced baptism, military occupation and sometimes extermination by groups of Danes, Germans and Swedes.
Background.
The official starting point for the Northern Crusades was Pope Celestine III's call in 1193; but the Christian kingdoms of Scandinavia, Poland and the Holy Roman Empire had begun moving to subjugate their pagan neighbors even earlier. The non-Christian people who were objects of the campaigns at various dates included:
Armed conflict between the Baltic Finns, Balts and Slavs who dwelt by the Baltic shores and their Saxon and Danish neighbors to the north and south had been common for several centuries before the crusade. The previous battles had largely been caused by attempts to destroy castles and sea trade routes and gain economic advantage in the region, and the crusade basically continued this pattern of conflict, albeit now inspired and prescribed by the Pope and undertaken by Papal knights and armed monks.
Wendish Crusade.
The campaigns started with the 1147 Wendish Crusade against the Polabian Slavs (or "Wends") of what is now northern and eastern Germany. The crusade occurred parallel to the Second Crusade to the Holy Land, and continued irregularly until the 16th century.
Livonian Crusade.
By the 12th century, the peoples inhabiting the lands now known as Estonia, Latvia and Lithuania formed a pagan wedge between increasingly powerful rival Christian states – the Orthodox Church to their east and the Catholic Church to their west. The difference in creeds was one of the reasons they had not yet been effectively converted. During a period of more than 150 years leading up to the arrival of German crusaders in the region, Estonia was attacked thirteen times by Russian principalities, and by Denmark and Sweden as well. Estonians for their part made raids upon Denmark and Sweden. There were peaceful attempts by some Catholics to convert the Estonians, starting with missions dispatched by Adalbert, Archbishop of Bremen in 1045-1072. However, these peaceful efforts seem to have had only limited success.
Campaign against the Livonians (1198–1212).
Moving in the wake of German merchants who were now following the old trading routes of the Vikings, a monk named Meinhard landed at the mouth of the Daugava river in present-day Latvia in 1180 and was made bishop in 1186. Pope Celestine III proclaimed a crusade against the Baltic heathens in 1195, which was reiterated by Pope Innocent III and a crusading expedition led by Meinhard's successor, Bishop Berthold of Hanover, landed in Livonia (part of present-day Latvia, surrounding the Gulf of Riga) in 1198. Although the crusaders won their first battle, Bishop Berthold was mortally wounded and the crusaders were repulsed.
In 1199, Albert of Buxhoeveden was appointed by the Archbishop Hartwig II of Bremen to Christianise the Baltic countries. By the time Albert died 30 years later, the conquest and formal Christianisation of present-day Estonia and northern Latvia was complete. Albert began his task by touring the Empire, preaching a Crusade against the Baltic countries, and was assisted in this by a Papal Bull which declared that fighting against the Baltic heathens was of the same rank as participating in a crusade to the Holy Land. Although he landed in the mouth of the Daugava in 1200 with only 23 ships and 500 soldiers, the bishop's efforts ensured that a constant flow of recruits followed. The first crusaders usually arrived to fight during the spring and returned to their homes in the autumn. To ensure a permanent military presence, the Livonian Brothers of the Sword were founded in 1202. The founding by Bishop Albert of the market at Riga in 1201 attracted citizens from the Empire and economic prosperity ensued. At Albert's request, Pope Innocent III dedicated the Baltic countries to the Virgin Mary to popularize recruitment to his army and the name "Mary's Land" has survived up to modern times. This is noticeable in one of the names given to Livonia at the time, Terra Mariana (Land of Mary).
In 1206, the crusaders subdued the Livonian stronghold in Turaida on the right bank of Gauja River, the ancient trading route to the Northwestern Rus. In order to gain control over the left bank of Gauja, the stone castle was built in Sigulda before 1210. By 1211, the Livonian province of Metsepole (now Limbaži district) and the mixed Livonian-Latgallian inhabited county of Idumea (now Straupe) was converted to the Roman Catholic faith. The last battle against the Livonians was the siege of Satezele hillfort near to Sigulda in 1212. The Livonians, who had been paying tribute to the East Slavic Principality of Polotsk, had at first considered the Germans as useful allies. The first prominent Livonian to be christened was their leader Caupo of Turaida. As the German grip tightened, the Livonians rebelled against the crusaders and the christened chief, but were put down. Caupo of Turaida remained an ally of the crusaders until his death in the Battle of St. Matthew's Day in 1217.
The German crusaders enlisted newly baptised Livonian warriors to participate in their campaigns against Latgallians and Selonians (1208–1209), Estonians (1208–1227) and against Semigallians, Samogitians and Curonians (1219–1290).
Campaign against the Latgallians and Selonians (1208–1224).
After the subjugation of the Livonians the crusaders turned their attention to the Latgallian principalities to the east, along the Gauja and Daugava rivers. The military alliance in 1208 and later conversion from Greek Orthodoxy to Roman Catholicism of the Principality of Tālava was the only peaceful subjugation of the Baltic tribes during the Nordic crusades. The ruler of Tālava, Tālivaldis ("Talibaldus de Tolowa"), became the most loyal ally of German crusaders against the Estonians, and he died a Catholic martyr in 1215. The war against the Latgallian and Selonian countries along the Daugava waterway started in 1208 by occupation of the Orthodox Principality of Koknese and the Selonian hillfort of Sēlpils. The campaign continued in 1209 with an attack on the Orthodox Principality of Jersika (known as "Lettia"), accused by crusaders of being in alliance with Lithuanian pagans. After defeat the king of Jersika, Visvaldis, became the vassal of the Bishop of Livonia and received part of his country (Southern Latgale) as a fiefdom. The Selonian stronghold of Sēlpils was briefly the seat of a Selonian diocese (1218–1226), and then came under the rule of the Livonian Order. Only in 1224, with the division of Tālava and Adzele counties between the Bishop of Rīga and the Order of the Swordbearers, did Latgallian countries finally became the possession of German conquerors. The territory of the former Principality of Jersika was divided by the Bishop of Rīga and the Livonian Order in 1239.
Campaign against the Estonians (1208–1224).
By 1208, the Germans were strong enough to begin operations against the Estonians, who were at that time divided into eight major and several smaller counties led by elders with limited co-operation between them. In 1208-27, war parties of the different sides rampaged through the Livonian, Northern Latgallian, and Estonian counties, with Livonians and Latgallians normally as allies of the Crusaders, and the Principalities of Polotsk and Pskov appearing as allies of different sides at different times. Hill forts, which were the key centres of Estonian counties, were besieged and captured a number of times. A truce between the war-weary sides was established for three years (1213–1215) and proved generally more favourable to the Germans, who consolidated their political position, while the Estonians were unable to develop their system of loose alliances into a centralised state. The Livonian leader Kaupo was killed in battle near Viljandi (Fellin) on 21 September 1217, but the battle was a crushing defeat for the Estonians, whose leader Lembitu was also killed. Since 1211, his name had come to the attention of the German chroniclers as a notable Estonian elder, and he had become the central figure of the Estonian resistance.
The Christian kingdoms of Denmark and Sweden were also greedy for conquests on the Eastern shores of the Baltic. While the Swedes made only one failed foray into western Estonia in 1220, the Danish Fleet headed by King Valdemar II of Denmark had landed at the Estonian town of Lindanisse (present-day Tallinn) in 1219. After the Battle of Lyndanisse the Danes established a fortress, which was besieged by Estonians in 1220 and 1223, but held out. Eventually, the whole of northern Estonia came under Danish control.
Wars against Saaremaa (1206–61).
The last Estonian county to hold out against the invaders was the island county of Saaremaa, whose war fleets had raided Denmark and Sweden during the years of fighting against the German crusaders.
In 1206, a Danish army led by king Valdemar II and Andreas, the Bishop of Lund landed on Saaremaa and attempted to establish a stronghold without success. In 1216 the Livonian Brothers of the Sword and the bishop Theodorich joined forces and invaded Saaremaa over the frozen sea. In return the Oeselians raided the territories in Latvia that were under German rule the following spring. In 1220, the Swedish army led by king John I of Sweden and the bishop Karl of Linköping conquered Lihula in Rotalia in Western Estonia. Oeselians attacked the Swedish stronghold the same year, conquered it and killed the entire Swedish garrison including the Bishop of Linköping.
In 1222, the Danish king Valdemar II attempted the second conquest of Saaremaa, this time establishing a stone fortress housing a strong garrison. The Danish stronghold was besieged and surrendered within five days, the Danish garrison returned to Revel, leaving bishop Albert of Riga's brother Theodoric, and few others, behind as hostages for peace. The castle was razed to the ground by the Oeselians.
A 20,000 strong army under Papal legate William of Modena crossed the frozen sea while the Saaremaa fleet was icebound, in January 1227. After the surrender of two major Oeselian strongholds, Muhu and Valjala, the Oeselians formally accepted Christianity.
In 1236, after the defeat of the Livonian Brothers of the Sword in the Battle of Saule, military action on Saaremaa broke out again. In 1261, warfare continued as the Oeselians had once more renounced Christianity and killed all the Germans on the island. A peace treaty was signed after the united forces of the Livonian Order, the Bishopric of Ösel-Wiek, and Danish Estonia, including mainland Estonians and Latvians, defeated the Oeselians by conquering their stronghold at Kaarma. Soon thereafter, the Livonian Order established a stone fort at Pöide.
Wars against the Curonians and Semigallians (1201–90).
Although the Curonians had attacked Riga in 1201 and 1210, Albert of Buxhoeveden, considering Courland a tributary of Valdemar II of Denmark, had been reluctant to conduct a large scale campaign against them. After Albert's death in 1229, the crusaders secured the peaceful submission of Vanemane (a county with a mixed Livonian, Oselian, and Curonian population in the northeastern part of Courland) by treaty in 1230. In the same year the papal vice-legat Baldouin of Alnea annulled this agreement and concluded an agreement with the ruler of Bandava in the central Courland Lamekins ("Lammechinus rex"), delivering his kingdom into the hands of the papacy. Baldouin became the popes's delegate in Courland and bishop of Semigallia; however, the Germans complained about him to the Roman Curia, and in 1234 Pope Gregory IX removed Baldouin as his delegate.
After their decisive defeat in the Battle of Saule by the Samogitians and Semigallians, the remnants of the Swordbrothers were reorganized in 1237 as a subdivision of the Teutonic Order, and became known as the Livonian Order. In 1242, under the leadership of the master of the Livonian Order Andrew of Groningen, the crusaders began the military conquest of Courland. They defeated the Curonians as far south as Embūte, near the contemporary border with Lithuania, and founded their main fortress at Kuldīga. In 1245 Pope Innocent IV allotted two thirds of conquered Courland to the Livonian Order, and one third to the Bishopric of Courland.
At the Battle of Durbe in 1260 a force of Samogitians and Curonians overpowered the united forces of the Livonian and Teutonic Orders; over the following years, however, the Crusaders gradually subjugated the Curonians, and in 1267 concluded the peace treaty stipulating the obligations and the rights of their defeated rivals. The unconquered southern parts of their territories (Ceklis and Megava) were united under the rule of the Grand Duchy of Lithuania.
The conquest of Semigallian counties started in 1219 when crusaders from Rīga occupied Mežotne, the major port on the Lielupe waterway, and founded the Bishopric of Semigallia. After several unsuccessful campaigns against the pagan Semigallian duke Viestards and his Samogitian kinsfolk, the Roman Curia decided in 1251 to abolish the Bishopric of Semigallia, and divided its territories between the Bishopric of Rīga and the Order of Livonia. In 1265 a stone castle was built at Jelgava, on the Lielupe, and became the main military base for crusader attacks against the Semigallians. In 1271 the capital hillfort of Tērvete was conquered, but Semigallians under the Duke Nameisis rebelled in 1279, and the Lithuanians under Traidenis defeated Livonian Order forces in the Battle of Aizkraukle. Duke Nameisis' warriors unsuccessfully attacked Rīga in 1280, in response to which around 14,000 crusaders besieged Turaida castle in 1281. To conquer the remaining Semigallian hillforts the Order's master Villekin of Endorpe built a castle called "Heiligenberg" right next to the Tērvete castle in 1287. The same year the Semigallians made another attempt to conquer Rīga, but again failed to take it. On their return home Livonian knights attacked them, but were defeated at the Battle of Garoza, in which the Orders' master Villekin and at least 35 knights lost their lives. The new master of the Order Cuno of Haciginstein organised the last campaigns against the Semigallians in 1289 and 1290; the hillforts of Dobele, Rakte and Sidarbe were conquered and most of the Semigallian warriors joined the Samogitian and Lithuanian forces.
Prussia and Lithuania.
Campaigns of Konrad of Masovia.
Konrad I, the Polish Duke of Masovia, unsuccessfully attempted to conquer pagan Prussia in crusades in 1219 and 1222. Taking the advice of the first Bishop of Prussia, Christian of Oliva, Konrad founded the crusading Order of Dobrzyń (or "Dobrin") in 1220. However, this order was largely ineffective, and Konrad's campaigns against the Old Prussians were answered by incursions into the already captured territory of Culmerland (Chełmno Land). Subjected to constant Prussian counter-raids, Konrad wanted to stabilize the north of the Duchy of Masovia in this fight over border area of Chełmno Land. Masovia had only been conquered in the 10th century and native Prussians, Yotvingians, and Lithuanians were still living in the territory, where no settled borders existed. His military weakness led Konrad to invite the Teutonic Knights to Prussia.
Teutonic Order.
The Northern Crusades provided a rationale for the growth and expansion of the Teutonic Order of German crusading knights which had been founded in Palestine at the end of the 12th century. Due to Muslim successes in the Holy Land, the Order sought new missions in Europe. Duke Konrad I of Masovia in west-central Poland appealed to the Knights to defend his borders and subdue the pagan Baltic Prussians in 1226. After the subjugation of the Prussians, the Teutonic Knights fought against the Grand Duchy of Lithuania.
When the Livonian knights were crushed by Samogitians in the Battle of Saule in 1236, coinciding with a series of revolts in Estonia, the Livonian Order was inherited by the Teutonic Order, allowing the Teutonic Knights to exercise political control over large territories in the Baltic region. Mindaugas, the King of Lithuania, was baptised together with his wife after his coronation in 1253, hoping that this would help stop the Crusaders' attacks, which it did not. The Teutonic Knights failed to subdue pagan Lithuania, which officially converted to (Catholic) Christianity in 1386 on the marriage of Grand Duke Jogaila to the 11-year-old Queen Jadwiga of Poland. However, even after the country was officially converted, the crusades continued up until the Battle of Grunwald in 1410, when the Lithuanians and Poles, helped by the Tatars, Moldovans and the Czechs, defeated the Teutonic knights.
The Teutonic Order's attempts to conquer Orthodox Russia (particularly the Republics of Pskov and Novgorod), an enterprise endorsed by Pope Gregory IX, can also be considered as a part of the Northern Crusades. One of the major blows for the idea of the conquest of Russia was the Battle of the Ice in 1242. With or without the Pope's blessing, Sweden also undertook several crusades against Orthodox Novgorod.

</doc>
<doc id="21922" url="https://en.wikipedia.org/wiki?curid=21922" title="Neoteny">
Neoteny

Neoteny ( 
or ), also called juvenilization, is one of the two ways by which paedomorphism can arise. Paedomorphism or paedomorphosis is the retention by adults of traits previously seen only in the young, and is a subject studied in the field of developmental biology. Neoteny is found in modern humans. Paedomorphism can also be the retention of larval traits which is commonly studied in salamanders. In neoteny, the physiological (or somatic) development of an organism (typically an animal) is slowed or delayed. In contrast, in progenesis, sexual development occurs faster. Both processes result in paedomorphism, a type of heterochrony. Ultimately this process results in the retention, in the adults of a species, of juvenile physical characteristics well into maturity and pedogenesis (paedogenesis), or reproduction in a neotenized state.
Neoteny is one of three dimensions of heterochrony, or the change in timing of developmental events: acceleration (faster) vs. neoteny (slower), hypermorphosis (further) vs. progenesis (not as far), and predisplacement (begins earlier) vs. postdisplacement (begins later).
The word "neoteny" is borrowed from the German "Neotenie", the latter constructed from the Greek νέος ("neos", "young") and τείνειν ("teínein", "to extend"). The adjective form of the word is either "neotenic" or "neotenous". For the opposite of "neotenic", different authorities use either "gerontomorphic" or "peramorphic".
In humans.
Neotenic traits in humans.
Various sources identify the following:
"In humans, neoteny is manifested in the resemblance of many physiological features of a human to a late-stage foetal chimpanzee. These foetal characteristics include hair on the head, a globular skull, ear shape, vertical plane face, absence of penal bone (baculum) in foetal male chimpanzees, the vagina pointing forward in foetal ape, the presence of hymen in neonate ape, and the structure of the foot. ‘These and many other features’, Bednarik says, ‘define the anatomical relationship between ape and man as the latter’s neoteny’"</ref>
Human evolution.
Many prominent evolutionary theorists propose that neoteny has been a key feature in human evolution. Stephen Jay Gould believed that the "evolutionary story" of humans is one where we have been "retaining to adulthood the originally juvenile features of our ancestors". J. B. S. Haldane mirrors Gould's hypothesis by stating a "major evolutionary trend in human beings" is "greater prolongation of childhood and retardation of maturity." Delbert D. Thiessen said that "neoteny becomes more apparent as early primates evolved into later forms" and that primates have been "evolving toward flat face." However, in light of some groups using arguments based around neoteny to support racism, Gould also argued "that the whole enterprise of ranking groups by degree of neoteny is fundamentally unjustified" (Gould, 1996, pg. 150).
Doug Jones, a visiting scholar in anthropology at Cornell University, said that human evolution's trend toward neoteny may have been caused by sexual selection in human evolution for neotenous facial traits in women by men with the resulting neoteny in male faces being a "by-product" of sexual selection for neotenous female faces. Jones said that this type of sexual selection "likely" had a major role in human evolution once a larger proportion of women lived past the age of menopause. This increasing proportion of women who were too old to reproduce resulted in a greater variance in fecundity in the population of women, and it resulted in a greater sexual selection for indicators of youthful fecundity in women by men.
Ashley Montagu said that the fetalized pithecanthropine represented by the juvenile Mojokerto skull and the fetalized australopithecine represented by the juvenile Australopithecus africanus skull would have had skulls with a closer resemblance to those of modern humans than to those of the adult forms of their own species. Montagu further listed the roundness of the skull, thinness of the skull bones, lack of brow ridges, lack of sagittal crests, form of the teeth, relative size of the brain and form of the brain as ways in which the juvenile skulls of these human ancestors resemble the skulls of adult modern humans. Montagu said that the retention of these juvenile characteristics of the skull into adulthood by australopithecine or pithecanthropine could have been a way that a modern type of human could have evolved earlier than what actually happened in human evolution.
Stanley Greenspan and Stuart G. Shanker proposed a theory in "The First Idea" of psychological development in which neoteny is seen as crucial for the "development of species-typical capacities" that depend upon a long period of attachment to caregivers for the opportunities to engage in and develop their capacity for emotional communication. Because of the importance of facial expression in the process of interactive signaling, neotenous features, such as hair loss, allow for more efficient and rapid communication of socially important messages that are based on facially expressive emotional signaling.
Other theorists have argued that neoteny has not been the main cause of human evolution, because humans only retain some juvenile traits, while relinquishing others. For example, the high leg-to-body ratio (long legs) of adult humans as opposed to human infants shows that there is not a holistic trend in humans towards neoteny when compared to the other great apes. Andrew Arthur Abbie agrees, citing the gerontomorphic fleshy human nose and long human legs as contradicting the neoteny hominid evolution hypothesis, although he does believe humans are generally neotenous. Brian K. Hall also cites the long legs of humans as a peramorphic trait, which is in sharp contrast to neoteny.
On the balance, an all or nothing approach could be regarded as pointless, with a combination of heterochronic processes being more likely and more reasonable (Vrba, 1996).
Growth pattern of children.
Desmond Collins who was an Extension Lecturer of Archaeology at London University said that the lengthened youth period of humans is part of neoteny.
Physical anthropologist Barry Bogin said that the pattern of children's growth may intentionally increase the duration of their cuteness. Bogin said that the human brain reaches adult size when the body is only 40 percent complete, when "dental maturation is only 58 percent complete" and when "reproductive maturation is only 10 percent complete". Bogin said that this allometry of human growth allows children to have a "superficially infantile" appearance (large skull, small face, small body and sexual underdevelopment) longer than in other "mammalian species". Bogin said that this cute appearance causes a "nurturing" and "care-giving" response in "older individuals".
Neotenous features elicit help.
The Multiple Fitness Model proposes that the qualities that make babies appear cute to adults additionally look "desirable" to adults when they see other adults. Neotenous features in adult females may help elicit more resource investment and nurturing from adult males. Likewise, neotenous features in adult males may similarly help elicit more resource investment and nurturing from adult females in addition to possibly making neotenous adult males appear less threatening and possibly making neotenous adult males more able to elicit resources from "other resource-rich people". Therefore, it could be adaptive for adult females to be attracted to adult males that have "some" neotenous traits.
Caroline F. Keating et al. tested the hypothesis that adult male and female faces with more neotenous features would elicit more help than adult male and female faces with less neotenous features. Keating et al. digitally modified photographs of faces of African-Americans and European Americans to make them appear more or less neotenous by either enlarging or decreasing the size of their eyes and lips. Keating et al. said that the more neotenous white male, white female and black female faces elicited more help from people in the United States and Kenya, but the difference in help from people in the United States and Kenya for more neotenous black male faces was not significantly different from less neotenous black male faces.
Brain.
Helmuth Nyborg said that a testable hypothesis can be made using his General Trait Covariance-Androgen/Estrogen (GTC-A/E) model with regards to "neoteny". Nyborg said that the hypothesis is that "feminized", slower maturing, "neotenic" "androtypes" will differ from "masculinized", faster maturing "androtypes" by having bigger brains, more fragile skulls, bigger hips, narrower shoulders, less physical strength, live in cities (as opposed to living in the countryside) and by receiving higher performance scores on ability tests. Nyborg said that if the predictions made by this hypothesis are true, then the "material basis" of the differences would be "explained". Nyborg said that some ecological situations would favor the survival and reproduction of the "masculinized," faster maturing "androtypes" due to their "sheer brutal force" while other ecological situations would favor the survival and reproduction of the "feminized," slower maturing, "neotenic" "androtypes" due to their "subtle tactics."
Aldo Poiani who is an evolutionary ecologist at Monash University, Australia, said that he agrees that neoteny in humans may have become "accelerated" through "two-way sexual selection" whereby females have been choosing smart males as mates and males have been choosing smart females as mates.
Neoteny has been important to human evolution, because it has increased the maturation period and the size of the human brain. Two to three million years ago, there was an "incomplete segmental duplication of ancestral SRGAP2" gene in the ancestors of humans. This new gene, SRGAC2, slowed spine maturation and allowed for more neuronal migration. As a result, the dendrite spines increased in number and length, and they became "more complex". This accounts for the greater synaptic densities in humans when compared to other primates and rodents.
Somel et al. said that 48% of the genes that affect the development of the prefrontal cortex change with age differently between humans and chimpanzees. Somel et al. said that there is a "significant excess of genes" related to the development of the prefrontal cortex that show "neotenic expression in humans" relative to chimpanzees and rhesus macaques. Somel et al. said that this difference was in accordance with the neoteny hypothesis of human evolution.
Dr. Bruce Charlton, a Newcastle University psychology professor, said what looks like immaturity — or in his terms, the "retention of youthful attitudes and behaviors into later adulthood" — is actually a valuable developmental characteristic, which he calls psychological neoteny. In fact, the ability of an adult human to learn is considered a neotenous trait.
Between sexes.
Ashley Montagu said that the following neotenous traits are in women when compared to men: more delicate skeleton, smoother ligament attachments, smaller mastoid processes, reduced brow ridges, more forward tilt of the head, narrower joints, less hairy, retention of fetal body hair, smaller body size, more backward tilt of pelvis, greater longevity, lower basal metabolism, faster heartbeat, greater extension of development periods, higher pitched voice and larger tear ducts.
A 2007 book about forensic anthropology said that the post-pubescent "female skull tends to retain its more pedomorphic features" when compared to the post-pubescent male skull.
Attractive women's faces.
In a cross-cultural study, more neotenized female faces were the most attractive to men while less neotenized female faces were the least attractive to men, regardless of the females' actual age. Using a panel of Asian, Hispanic and White judges, Michael R. Cunningham found that the Asian, Hispanic and white female faces found most attractive were those that had "neonate large eyes, greater distance between eyes, and small noses" and his study led him to conclude that "large eyes" were the most "effective" of the "neonate cues". Cunningham also said that "shiny" hair may be indicative of "neonate vitality".
Cunningham said that there was a "difference" in the preferences of Asian and White judges. Cunningham said that Asian judges preferred women with "less mature faces" and smaller mouths than the White judges. Cunningham hypothesized that this difference in preference may stem from "ethnocentrism" since "Asian faces possess those qualities", so Cunningham re-analyzed the data with "11 Asian targets excluded" and he concluded that "ethnocentrism was not a primary determinant of Asian preferences." Using a panel of Blacks and Whites as judges, Cunningham said that more neotenous faces were perceived as having both higher "femininity" and "sociability".
In contrast, Cunningham said that faces that were "low in neoteny" were judged as "intimidating". Upon analyzing the results of his study Cunningham concluded that preference for "neonate features may display the least cross-cultural variability" in terms of "attractiveness ratings". In a study of Italian women who have won beauty competitions, the study said that the women had faces characterized by more "babyness" traits compared to the "normal" women used as a reference. In a study of sixty Caucasian female faces, the average facial composite of the fifteen faces considered most attractive differed from the facial composite of the whole by having a reduced lower facial region, a thinner jaw, and a higher forehead.
Doug Jones, a visiting scholar in anthropology at Cornell University, said that there is cross-cultural evidence for preference for facial neoteny in women, because of sexual selection for the appearance of youthful fecundity in women by men. Jones said that men are more concerned about women's sexual attractiveness than women are concerned about men's sexual attractiveness. Jones said that this greater concern over female attractiveness is unusual among animals, because it is usually the females that are more concerned with the male's sexual attractiveness in other species. Jones said that this anomalous case in humans is due to women living past their reproductive years and due to women having their reproductive capacity diminish with age, resulting in the adaption in men to be selective against physical traits of age that indicate lessening female fecundity. Jones said that the neoteny in women's faces may be a "by-product" of men's attraction to indicators of "youthful fecundity" in "adult females".
A similar study was conducted on the attractiveness of males with the subject of the skull and its application in human morphology. Paul Wehr and team (2001) utilized psychology and evolutionary biology to understand selection on facial features. Averageness has been a result of stabilizing selection whereas facial paedomorphosis or juvenile traits are a result of directional selection (Wehr, 2001). It is necessary at this point to define several terms to put them into practical time and space, as they pertain to this argument. The idea of directional selection as defined by Bergstrom and Dugatkin (2012) is when a single phenotypic trait is driven by selection toward fixation in a population (Bergstrom and Dugatkin, p. 218). In contrast, stabilizing selection is defined as being a scenario wherein both alleles are driven toward fixation in a population (or polymorphic, both alleles reaching equilibrium at a fixation) (Bergstrom and Dugatkin, p. 221). To compare the effects of directional and stabilizing selection on facial paedomorphosis Wehr used graphic morphing to alter appearances to make faces appear more or less juvenile. The results concluded that the effect of averageness was preferred nearly twice over juvenile trait characteristics which indicates that stabilizing selection influences facial preference, and averageness was found more attractive than the retention of juvenile facial characteristics (Wehr, 2001). This follows the conclusions of the other study presented previously. It was perplexing to find that women tend to prefer the average facial features over the juvenile, because in animals the females tend to drive sexual selection by female choice and the Red Queen hypothesis. Some may hypothesize this is because in humans women tend to focus on social features including education, job status, family background, humor, and courtships. Experiments have found males tend to focus on the attractiveness of women, whereas women focus of overall quality and verbal interactions.
Because men generally exhibit uniform preference for neotenous women's faces, Elia (2013) questioned if women's varying preferences for neotenous men's faces could "help determine" the range of facial neoteny in humans.
Between races and among primates.
Stephen Jay Gould objected to the ranking of races as more or less neotenous, but Gould argued that if one used the terms set forth by 1920s proponents of racial neoteny, "Asians" are "clearly" the most neotenized human race.
Ashley Montagu said that the "Mongoloid skull, whether Chinese or Japanese" is the most neotenized human skull, and Montagu added that "Chinese peoples" are "perhaps" the best representatives of neoteny out of the Mongoloids. Montagu further said that the "European" skull was less neotenized than the Mongoloid, with the "Australian Aborigine" skull less neotenized than the European and the Neanderthal skull even less neotenized than the Australian Aborigine skull. Montagu said that humans have more neotenized skulls than "Australopithecus" and gorillas.
Delbert D. Thiessen said that "Homo sapiens" are more neotenized than "Homo erectus", "Homo erectus" was more neotenized than "Australopithecus", Great Apes are more neotenized than Old World monkeys and Old World monkeys are more neotenized than New World monkeys.
Nancy Lynn Barrickman said that Brian T. Shea concluded by multivariate analysis that Bonobos are more neotenized than the common chimpanzee, taking into account such features as the proportionately long torso length of the Bonobo. Ashley Montagu said that part of the differences seen in the morphology of "modernlike types of man" can be attributed to different rates of "neotenous mutations" in their early populations.
San people.
Neoteny has also been a subject of study for anthropologists engaging in racial classification. While the practice, like the articles cited below, is largely outmoded, the researcher's work sheds light on how neoteny has been used to claim racial superiority, by showing that the San were a less physically developed, childlike race. This research could then be used to demonstrate why the "Bushmen" were technologically or culturally 'backwards', and it is clear how such arguments feed on and into the racist logic of Apartheid.
Ashley Montagu said that the San have the following neotenous traits relative to Caucasoids: large brain, light skin pigment, less hairy, round-headed, bulging forehead, small cranial sinuses, flat roof of the nose, small face, small mastoid processes, wide eye separation, median eye fold, short stature and horizontal penis.
M. R. Drennan of the Department of Anatomy, University of Cape Town, said that the Bushman's skull retains infantile morphological characteristics into adulthood that are only transiently present in the juvenile forms of other races. Drennan further said that the common description of an infant's skull from anatomy textbooks "epitomizes" the characteristics of the Bushman's skull.
Phillip V. Tobias of the Department of Anatomy, University of Witwatersrand, said that there are two phenotypical patterns in occipital curvature of "African crania": one for "Negroes" and one for Bushmen. Tobias said that the skulls of Bushmen retain strongly curved occiputs from youth into adulthood, but the curved occiputs of "Negroes" skulls start to flatten when their first permanent teeth erupt. Tobias said that this flattening process in "Negroes" continues until their occiputs have flattened as adults. Tobias said that there are "infantile" features in the cranial morphology of Bushmen.
Marina L. Sardi of the anthropological division at the University of La Plata, Argentina, and Fernando V. Ramírez Rozzi said South African adults have neotenized relative facial heights and nose shapes in comparison to European adults, because "Europeans" develop relatively taller faces and relatively taller and narrower noses as they mature whereas "South Africans" do not undergo this ontogenic change as they mature. However, the relative length of both the tibia and the femur to the torso becomes greater in South Africans as they mature to a greater extent than in Europeans, so the relatively shorter legs of European adults are neotenous in comparison to the greater limb-to-torso ratio of South African adults.
Frederick S. Hulse said that either natural selection or genetic drift has caused "pedomorphic qualities" to develop in the Bushmen.
In the mid-twentieth century, anthropologist Earnest Hooton, paleontologist Robert Broom and anthropologist Raymond Dart all believed that the Khoikhoi were descended from Asians, but this viewpoint slowly lost favor to the idea that the apparent "Mongoloid" traits of the San had a "pedomorphic" explanation.
The descriptor "Bushmanoid", meaning like a Bushman, is used to describe prehistoric African skulls if the skulls appear "pedomorphic" due to having a rounded and smooth cranial vault and a face that is proportionately small.
African pygmies.
Michael L. McKinney, professor in the Ecology & Evolutionary Biology Department of the University of Tennessee, said that the "slower growth" of the "African pygmy" is a case of "neoteny".
Europeans.
Frederick S. Hulse said that "...modern Europeans are, on average, distinctly less pedomorphic than are most non-Europeans...".
Richard Jantz and Lee Meadows Jantz who are both directors at the Forensic Anthropology Center at the University of Tennessee said white American skulls of both sexes have become less neotenous since the mid-1800s.
Aboriginal Australians.
Frederick S. Hulse said that aboriginal Australians have retained "similar" "skeletal characteristics" to those "which most men possessed in earlier times" (gerontomorphic characteristics) that are "contrary" to the "pedomorphic qualities" which the Bushmen have evolved.
Mongoloids.
Ashley Montagu said, "The Mongoloid skull has proceeded further than in any other people." "The Mongoloid skull, whether Chinese or Japanese, has been rather more neotenized than the Caucasoid or European." "The female skull, it will be noted, is more pedomorphic in all human populations than the male skull."
Ashley Montagu said, "the skeleton of the classic Mongoloid type is very delicately made, even down to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact the Mongoloid presents so many physical traits which are associated with the late fetus or young infant that he has been called a fetalized, infantilized or pedomorphic type. Those who have carefully observed young babies may recall that the root of the nose is frequently flat or low as in Mongoloids, and that an internal epicanthic fold in such instances is usually present. The smaller number of individual head hairs and the marked hairlessness of the remainder of the body are infantile traits, as are likewise the small mastoid processes, the shallow fossa into which the jawbone fits (the mandibular fossa), the rather stocky build, the large brain-pan and brain, lack of brow ridges, and quite a number of other characters."
Richard Grossinger said, "The intuition that advanced human development was pedomorphic rather than recapitulationary and accelerated was disturbing to many Eurocentric nineteenth century anthropologists." "If juvenilization was the characteristic for advanced status, then it was clear that the Mongoloid races were more deeply fetalized in most respects and thus capable of the greatest development."
Stephen Oppenheimer said, "An interesting hypothesis put forward by paleontologist Stephen Jay Gould many years ago was that the package of the Mongoloid anatomical changes could be explained by the phenomenon of neoteny, whereby an infantile or childlike body form is preserved in adult life. Neoteny in hominids is still one of the simplest explanations of how we developed a disproportionately large brain so rapidly over the past few million years. The relatively large brain and the forward rotation of the skull on the spinal column, and body hair loss, both characteristic of humans, are found in foetal chimps. Gould suggested a mild intensification of neoteny in Mongoloids, in whom it has been given the name pedomorphy. Such a mechanism is likely to involve only a few controller genes and could therefore happen over a relatively short evolutionary period. It would also explain how the counterintuitive retroussé up at the end nose and relative loss of facial hair got into the package." "ecrease unnecessary muscle bulk, less tooth mass, thinner bones and smaller physical size; ...this follows the selective adaptive model of Mongoloid evolution."
Paul Storm of the Naturalis Biodiversity Center, Netherlands, said that in Australasia there are two types of cranial morphologies—the "Sunda" (Mongoloid) and "Sahul" (Australoid) types. Storm said that the "Sunda" (Mongoloid) type includes Chinese and Javanese people, and he said that the "Sahul" (Australoid) type includes Papuans and Australian aborigines. Storm said that the "Sunda" (Mongoloid) type has a flat face with high cheek bones, and Storm said that this "flat face" of the Chinese and Javanese is known as the "mongoloid face". Storm further said that the "Sunda" (Mongoloid) type has a more rounded skull, "feminine (juvenile) characters", a "retention of juvenile characters" and a limited outgrowth of superstructures such as the supraorbital region. Storm said that "Sunda" (Mongoloid) skulls resemble female skulls more than "Sahul" (Australoid) skulls resemble female skulls. Storm said that the skulls of "Asian" males ("Chinese and Javanese") have "more feminine characteristics", and he said that they have "many feminine characters in contrast with Australians".
Paul Storm said that Asia contained humans with "generalized" cranial morphology, but between 20,000 BP and 12,000 BP this generalized type disappeared as a new type emerged. This new type had a flatter face with more pronounced cheekbones, a more rounded head, reduced sexual dimorphism (male skulls started to resemble female skulls), a reduction of supestructures such as the supraorbital region and an increased "retention of juvenile characters". Storm said that this new type of skull that emerged is called the "Proto-Sunda" (Proto-Mongoloid) type, and it is distinguished from the "Sunda" (Mongoloid) type by being more "robust". Storm said that the "Mongoloid" or "Asian" type of skull developed relatively fast during a population bottleneck in Asia that happened during the Late Pleistocene or Early Holocene through a microevolutionary trend that involved a "continuation of neoteny and gracilisation trends". Due to different courses of evolution, Storm said that these two types of skulls, the "Sunda" (Mongoloid) type and the "Sahul" (Australoid) type, are now clearly recognizable at the present time.
Andrew Arthur Abbie who was an anatomist and anthropologist at the University of Adelaide talked about leg-to-torso length being related to neoteny. Abbie said that women normally have shorter legs than men, and he said that shorter legs are the normal condition in some ethnic groups such as Mongoloids. Abbie said that Mongoloids of whom he listed the people of "China, Japan and the Americas" have proportionately larger heads and shorter legs than Europeans, and he said that this is a case of "paedomorphism". Abbie said that aboriginal Australians and some African ethnic groups such as the "Negro", the "Hottentot" and the "Nubian" peoples have proportionately longer legs than Europeans, and he said that this is a case of "gerontomorphism". Abbie said that ethnic groups with proportionately shorter legs than Europeans are relatively "paedomorphic" in terms of leg-to-torso ratios when compared to Europeans, and he said that ethnic groups with proportionately longer legs than Europeans are relatively "gerontomorphic" in terms of leg-to-torso ratios when compared to Europeans.
William Ernest Castle said that the difference in limb proportions between the relatively short-limbed "Chiriguan" amerindian and the relatively long-limbed "Dinka negro" is the "same" as the difference in limb proportions between "boy and man". He said that there could be an ontogenic cause that produces "long-continued growth" in populations that characteristically have relatively longer limbs, and he said that the differences in height between the races could be due to "interruptions at different stages of the general growth process".
Leonard Halford Dudley Buxton who taught physical anthropology at Oxford University said that in the "Yellow man" the depression of the nose is below the nasion rather than at the place where the nasal bones meet the frontal bone like in the "European races". Buxton said that in the "Yellow man" the nasal bones form a wider angle rather than the narrower angle of the "European races". Buxton said that these features of the nose of the "Yellow man" make it "flatter" and "not unlike that found in European children". Buxton said that "Yellow men" have the "Mongolian fold", and Buxton said that this "fold occurs occasionally in European children, and sometimes even in adults". Buxton said that the presence of the "Mongolian fold" in "Yellow men" is possibly due to the shape of the nose of "Yellow men" that "in some cases resemble that of European children".
Negroids.
Ashley Montagu said that Negroids have the following neotenous traits relative to Caucasoids: flattish nose, flat roof of the nose, small ears, narrower joints, frontal skull eminences, later closure of the premaxillary sutures, less hairy, longer eyelashes and cruciform pattern of the lower second and third molars.
Specific neotenies.
Populations with a history of dairy farming have evolved to be lactose tolerant in adulthood whereas other populations generally lose the ability to break down lactose as they grow into adults.
Down syndrome.
Down syndrome neotenizes the brain and body. Down syndrome is characterized by decelerated maturation (neoteny), incomplete morphogenesis (vestigia) and atavisms.
He notes both the physical neoteny of people with Down syndrome: "round in shape," "bowed legs which tend to be short," "slanty eyes," a "long tongue" and "short fingers," and their mental neoteny: "unsexual," "playful," "affectionate," "mischievous" and "imitative".
Neoteny in dogs.
When the role of dogs expanded from just being working dogs to also being companion dogs, humans started selective breeding dogs for morphological neoteny, and this selective breeding for "neoteny or paedomorphism" had the effect of enhancing the bond between humans and dogs. Humans bred dogs to have more "juvenile physical traits" as adults such as short snouts and wide-set eyes which are associated with puppies, because people usually consider these traits to be more attractive. Some breeds of dogs with short snouts and broad heads such as the Komondor, Saint Bernard and Maremma Sheepdog are more morphologically neotenous than other breeds of dogs.Cavalier King Charles spaniels are an example of selection for neoteny, because they exhibit large eyes, pendant-shaped ears and compact feet, giving them a morphology similar to puppies as adults.
A study that used 310 wolf skulls and over 700 dog skulls representing 100 breeds, concluded that the evolution of dog skulls can generally not be described by heterochronic processes such as neoteny although some pedomorphic dog breeds have skulls that resemble the skulls of juvenile wolves. Moreover, a lot of cranial variation exists between the skulls of different pedomorphic dog breeds.
Neoteny in other species.
Neoteny is seen more in domesticated animals like dogs and mice. Neoteny has been observed in many other species. Neoteny in amphibians seems to be the most widely studied aside from humans; many examples of neoteny in amphibians stem from studies done mainly on salamanders. There is also a general prevalence of increased neoteny within domesticated animals like dogs. Neoteny has also been noted in species similar to humans, like chimpanzees. The neotenous traits in chimpanzees that resemble those within humans may give some insight into the evolutionary history of humans. What can be gathered from many studies on neoteny is that organisms with similar lineages tend to neotenize similar features, meaning they retain related features from the juvenile form into adulthood. Finally, there are two main reasons for the occurrence of neoteny: it can either be a result of the benefit of retaining juvenile characteristics due to an environment that favors those characteristics over the adult form, or the retention of juvenile characteristics leads to greater survival because those characteristics are less costly in terms of energy expenditure.
It is important to note the difference between partial and full neoteny when looking at other species in order to distinguish between juvenile traits that are only advantageous in the short term and traits that provide a benefit throughout the organism’s life; this might then provide some insight into the cause of neoteny in those species. Partial neoteny is the retention of the larval form beyond the usual age of maturation with the possibility of the development of sexual organs progenesis, but eventually the organism still matures into the adult form; this can be seen in "Lithobates clamitans". Full neoteny is seen in "Ambystoma tigrinum". This species is part of a larger group, perrenobranchiates, which remain in their larval form for the duration of their life. This means that they are capable of reproducing and they do not mature into adult forms. The species "Lithobates clamitans" exhibits partial neoteny when it delays its maturation through the winter season because it is not advantageous for it to metamorphose into the adult form until there are more resources available since it can find those resources much more easily in the larval form. This would fall under both of the main causes of neoteny; the energy required to survive in the winter as a newly formed adult is too costly, so the organism exhibits neotenous characteristics until a time when it is capable of better survival as an adult. "Ambystoma tigrinum" retains its neotenous features for a similar reason, however the retention is permanent due to the lack of resources available throughout its lifetime. This is another example of an environmental cause of neoteny in that the species retains juvenile characteristics because the environment limits the ability of the organism to fully come into its adult form. A few species of birds show partial neoteny. A couple examples of such species are "Chiroxiphia linearis" and "Chiroxiphia caudata". The males of both species retain their juvenile plumage into adulthood, but they eventually lose it once they are fully mature. In certain species of birds the retention of juvenile plumage is often linked to the molting times within each species. In order to ensure there is no overlap between the molting and mating times, the birds may show partial neoteny in regards to their plumage so that the males do not attain their bright adult plumage before the females are prepared to mate. In this instance, neoteny is present because there is no need for the males to molt early and it would be a waste of energy for them to try to mate when the females are not yet prepared.
Neoteny is seen more in domesticated animals like dogs and mice. This is because there are more resources available, less competition for those resources, and with the lowered competition the animals expend less energy obtaining those resources. This allows them to mature and reproduce more quickly than their wild counterparts. The environment that domesticated animals are raised in determines whether or not neoteny is present in those animals. Evolutionary neoteny can arise in a species when those conditions occur, and a species becomes sexually mature ahead of its "normal development". Another explanation for the neoteny in domesticated animals can be the selection for certain behavioral characteristics. Behavior is linked to genetics which therefore means that when a behavioral trait is selected for, a physical trait may also be selected for due to mechanisms like linkage disequilibrium. Often, juvenile behaviors are selected for in order to more easily domesticate a species; aggressiveness in certain species comes with adulthood when there is a need to compete for resources. If there is no need for competition, then there is no need for aggression. Selecting for juvenile behavioral characteristics can lead to neoteny in physical characteristics because, for example, with the reduced need for behaviors like aggression there is no need for developed traits that would help in that area. Traits that may become neotenized due to decreased aggression may be a shorter muzzle and smaller general size among the domesticated individuals. Some common neotenous physical traits in domesticated animals (mainly dogs, pigs, ferrets, cats, and even foxes) include: floppy ears, changes in reproductive cycle, curly tails, piebald coloration, fewer or shortened vertebra, large eyes, rounded forehead, large ears, and shortened muzzle.
Neoteny is commonly seen in flightless insects like the females in the order Strepsiptera. The flightless trait in insects has evolved many separate times; environments that may have contributed to the separate evolution of this trait are: high altitudes, isolation on islands, and insects that reside in colder climates. These environmental factors may be responsible for the flightless trait, because in these situations it would be disadvantageous to have a population that is more dispersed, so flightlessness would be favored due to the boundaries it poses to dispersal. Also, in cooler temperatures heat is lost more rapidly through wings, thus the circumstance favors flightlessness. Another couple of main points to note about insects are that the females in certain groups become sexually mature without metamorphosing into adulthood, and some insects which grow up in certain conditions do not ever develop wings. Flightlessness in some female insects has been linked to higher fecundity, this would increase the fitness of the individual because the female is producing more offspring and therefore passing on more of her genes. In those instances, neoteny occurs because it is more advantageous for the females to remain flightless in order to conserve energy which thereby increases their fecundity. Aphids are a great example of insects that may never develop wings due to their environmental setting. If resources are abundant there is no need to grow wings and disperse. When the nutrition of a host plant is abundant aphids may not grow wings and stay there for the duration of their life, however if the resources become diminished the offspring may develop wings in order to disperse to other host plants.
Two common environments that tend to favor neoteny are high-altitude and cool environments because neotenous individuals have a higher fitness than those that metamorphose into the adult form. This is because the energy required for metamorphosis is too costly for the individual’s fitness, also the conditions favor neoteny due to the ability of neotenous individuals to utilize the available resources more easily. This trend can be seen in the comparison of salamander species of lower and higher altitudes. The neotenous individuals have higher survivorship as well as higher fecundity than the salamanders that had gone to the adult form in the higher altitude and cooler environment. Insects in cooler environments tend to show neoteny in flight because wings have a high surface area and lose heat quickly, thus it is not advantageous for insects in that environment to metamorphose into adults.
Many species of salamander, and amphibians in general, are known to have neotenized characteristics because of the environment they live in. The axolotl is a species of salamander that retains its juvenile aquatic form throughout adulthood, which is an excellent example of full neoteny. Gills are a common juvenile characteristic in amphibians that are kept after maturation; an example of this would be a comparison of the tiger salamander and the rough-skinned newt, both of which retain gills into adulthood. These species are better able to survive when they retain certain juvenile features, like gills, that allow them access to both aquatic and land environments.
Pygmy chimpanzees (bonobos) share many physical characteristics with humans. A prime example are their neotenous skulls. The shape of their skull does not change into adulthood; it only increases in size. This is due to sexual dimorphism and an evolutionary change in timing of development. Juveniles became sexually mature before their bodies had fully developed into adulthood, and due to some selective advantage the neotenic structure of the skull remained in later generations.
More examples of neoteny can be seen in these other species:
1. Species in which energy costs result in neoteny
2. Species in which the environmental conditions cause neoteny

</doc>
<doc id="21923" url="https://en.wikipedia.org/wiki?curid=21923" title="National Rail">
National Rail

In Great Britain, National Rail is the trading name licensed for use by the Association of Train Operating Companies (ATOC), an unincorporated association whose membership consists of the passenger train operating companies (TOCs) of Great Britain that run the passenger services previously provided by the British Railways Board, from 1965 using the brand name British Rail). National Rail generally does not include services that do not have a BR history; this distinction is important because National Rail services share a ticketing structure and inter-availability that do not necessarily extend to other services. The name and the accompanying double arrow symbol are the intellectual property of the Secretary of State for Transport.
The National Rail (NR) logo was introduced by ATOC in 1999, and was used on the Great Britain public timetable for the first time in the edition valid from 26 September in that year. Rules for its use are set out in the Corporate Identity Style Guidelines published by ATOC, available on its website. The NR title is sometimes described as a "brand". As it was used by British Rail, the single operator before franchising, its use also maintains continuity and public familiarity; and it avoids the need to replace signage.
National Rail and Network Rail.
"National" Rail should not be confused with "Network Rail". National Rail is a title used to promote passenger railway services, and providing some harmonisation for passengers (e.g. tickets to all London Terminals), while Network Rail is the organisation owning and managing most of the fixed assets (tracks, signals etc.) of the railway network.
The two networks are generally coincident where passenger services are run. Most major Network Rail lines carry freight traffic and some lines are freight only. There are some scheduled passenger services on their own privately managed, non-Network Rail lines, for example Heathrow Express which also partly runs on Network Rail track and the London Underground also overlaps with Network Rail in places.
Train operating companies (TOCs).
About twenty privately owned train operating companies, each franchised for a defined term by government, operate passenger trains on the main rail network in Great Britain. ATOC is the trade association representing the TOCs and provides core services, including the provision of the National Rail Enquiries service. It also runs Rail Settlement Plan, which allocates ticket revenue to the various TOCs, and Rail Staff Travel, which manages travel facilities for railway staff. It does not compile the national timetable, which is the joint responsibility of the Office of Rail Regulation (allocation of paths) and Network Rail (timetable production and publication).
Design and marketing.
Since the privatisation of British Rail there is no longer a single approach to design on railways in Great Britain. The look and feel of signage, liveries and marketing material is largely the preserve of the individual TOCs.
However, National Rail continues to use BR's famous double-arrow symbol, designed by Gerald Burney of the Design Research Unit. It has been incorporated in the National Rail logotype and is displayed on tickets, the National Rail website and other publicity. The trademark rights to the double arrow symbol remain state-owned, being vested in the Secretary of State for Transport.
The double arrow was already prescribed for indicating a "railway station".
The lettering used in the National Rail logotype is a modified form of the typeface Sassoon Bold. Some train operating companies continue to use the former British Rail Rail Alphabet lettering to varying degrees in station signage, although its use is no longer universal; however it remains compulsory (under Railway Group Standards) for safety signage in trackside areas and is still common (although not universal) on rolling stock.
It is a common misconception that Rail Alphabet was also used for printed material, but with the exception of logos ("British Rail", etc.) this has never been the case. The British Rail typefaces of choice from 1965 were Helvetica and Univers, with others (particularly Frutiger) coming into use during the sectorisation period after 1983. TOCs may use what they like: examples include Futura (Stagecoach Group), Helvetica (FirstGroup and National Express), Frutiger (Arriva Trains Wales), Bliss (CrossCountry, an Arriva franchise but not branded as such), and a modified version of Precious by London Midland.
Although TOCs compete against each other for franchises, and for passengers on routes where more than one TOC operates, the strapline used with the National Rail logo is 'Britain's train companies working together'.
Other passenger rail operators in Great Britain.
Several conurbations have their own metro or tram systems, most of which are not part of National Rail. These include the London Underground, Docklands Light Railway, Blackpool Tramway, London Tramlink, Glasgow Subway, Tyne and Wear Metro, Manchester Metrolink, Sheffield Supertram, Midland Metro and Nottingham Express Transit. On the other hand, the largely self-contained Merseyrail system is part of the National Rail network, and urban rail networks around Birmingham, Cardiff, Glasgow and West Yorkshire consist entirely of National Rail services.
London Overground (LO) is a hybrid: its services are operated via a concession awarded by Transport for London, and are branded accordingly, but until 2010 all its routes used infrastructure owned by Network Rail. LO now also possesses some infrastructure in its own right, following the reopening of the former East London line of London Underground as the East London Railway of LO. Since all the previous LO routes were operated by National Rail franchise Silverlink until November 2007, they have continued to be shown in the National Rail timetable and are still considered to be a part of National Rail.
Heathrow Express and Eurostar are also not part of the National Rail network despite sharing of stations and routes (Heathrow Express and Heathrow Connect only). Northern Ireland Railways were never part of British Rail, which was always confined to Great Britain, and therefore are not part of the National Rail network.
There are many privately owned or heritage railways in Great Britain which are not part of the National Rail network and mostly operate for heritage or pleasure purposes rather than as public transport.
Ticketing.
National Rail services have a common ticketing structure inherited from British Rail. Through tickets are available between any pair of stations on the network, and can be bought from any station ticket office. Most tickets are inter-available between the services of all operators on routes appropriate to the journey being made. Operators on some routes offer operator-specific tickets that are cheaper than the inter-available ones.
Through tickets involving Heathrow Express and London Underground are also available. Oyster pay-as-you-go can be used on National Rail in Greater London from 2 January 2010.
Passengers without a valid ticket boarding a train at a station where ticket-buying facilities are available are required to pay the full Open Single or Return fare. On some services penalty fares apply - a ticketless passenger may be charged the greater of £20 or twice the full single fare to the next stop. Penalty Fares can be collected only by authorised Revenue Protection Inspectors, not by ordinary Guards.
National Rail distributes a number of technical manuals on which travel on the railways in Great Britain is based, such as the National Rail Conditions of Carriage, via their website.
Timetables and websites.
Pocket timetables for individual operators or routes are available free at staffed stations. A complete National Rail Timetable with up to 3,000 pages was also available for purchase, but the last hard copy edition was published in May 2007. Complete timetables are still available in printed form from TSO (The Stationery Office) and also an independent publisher.
A digital version of the full timetable is available as a pdf (portable document format) file without charge on the Network Rail website. The National Rail Enquiries website, run by ATOC, includes a real-time journey planner, fares and live departure information.

</doc>
<doc id="21926" url="https://en.wikipedia.org/wiki?curid=21926" title="Naked singularity">
Naked singularity

In general relativity, a naked singularity is a gravitational singularity without an event horizon. In a black hole, the singularity is completely enclosed by a boundary known as the event horizon, inside which the gravitational force of the singularity is so strong that light cannot escape. Hence, objects inside the event horizon—including the singularity itself—cannot be directly observed. A naked singularity, by contrast, is observable from the outside.
The theoretical existence of naked singularities is important because their existence would mean that it would be possible to observe the collapse of an object to "infinite density". It would also cause foundational problems for general relativity, because general relativity cannot make predictions about the future evolution of space-time near a singularity. In generic black holes, this is not a problem, as an outside viewer cannot observe the space-time within the event horizon.
Some research has suggested that if loop quantum gravity is correct, then naked singularities could exist in nature, implying that the cosmic censorship hypothesis does not hold. Numerical calculations and some other arguments have also hinted at this possibility.
No naked singularities have been identified.
Predicted formation.
From concepts drawn of rotating black holes, it is shown that a singularity, spinning rapidly, can become a ring-shaped object. This results in two event horizons, as well as an ergosphere, which draw closer together as the spin of the singularity increases. When the outer and inner event horizons merge, they shrink toward the rotating singularity and eventually expose it to the rest of the universe.
A singularity rotating fast enough might be created by the collapse of dust or by a supernova of a fast-spinning star. Studies of pulsars and some computer simulations (Choptuik, 1997) have been performed.
This is an example of a mathematical difficulty (divergence to infinity of the density) which reveals a more profound problem in our understanding of the relevant physics involved in the process. A workable theory of quantum gravity should be able to solve problems such as these. 
Metrics.
Disappearing event horizons exist in the Kerr metric, which is a spinning black hole in a vacuum. Specifically, if the angular momentum is high enough, the event horizons could disappear. Transforming the Kerr metric to Boyer–Lindquist coordinates, it can be shown that the formula_1 coordinate (which is not the radius) of the event horizon is
formula_2,
where formula_3, and formula_4. In this case, "event horizons disappear" means when the solutions are complex for formula_5, or formula_6,
where formula_3, and formula_8. Of the three possible cases for the relative values of formula_9 and formula_10, the case where formula_11 causes both formula_5 to be complex. This means the metric is regular for all positive values of formula_1, or in other words, the singularity has no event horizon.
See Kerr–Newman metric for a spinning, charged ring singularity.
Effects.
A naked singularity could allow scientists to observe an infinitely dense material, which would under normal circumstances be impossible by the cosmic censorship hypothesis. Without an event horizon of any kind, some speculate that naked singularities could actually emit light.
Cosmic censorship hypothesis.
The cosmic censorship hypothesis says that a naked singularity cannot arise in our universe from realistic initial conditions.

</doc>
<doc id="21927" url="https://en.wikipedia.org/wiki?curid=21927" title="National Party of Australia">
National Party of Australia

The National Party of Australia (also known as The Nationals or simply, The Nats) is an Australian political party. Traditionally representing graziers, farmers, and rural voters generally, it began as the Country Party in 1920 at a federal level. It would later briefly adopt the name National Country Party in 1975, before adopting their current name in 1982. 
Federally, and in New South Wales, and to an extent in Victoria and historically in Western Australia, it has, in government, been the minor party in a centre-right Coalition with the Liberal Party of Australia, and its leader has usually served as Deputy Prime Minister. In Opposition the Coalition was usually maintained, but otherwise still generally continued to work in co-operation with the Liberal Party of Australia (and their predecessors the Nationalist Party of Australia and United Australia Party). In Queensland however, they were the senior coalition party between 1925 and 2008, after which they merged with the junior Liberal Party of Australia to form the Liberal National Party (LNP).
The current federal leader and Deputy Prime Minister is Barnaby Joyce, with Fiona Nash as the current federal deputy leader. Both were elected in a party-room ballot on 11 February 2016, following the retirement of former leader and Deputy Prime Minister Warren Truss and the elevation of former deputy leader Joyce.
History.
The Country Party was formally founded in 1913 in Western Australia, and nationally in 1920 from a number of state-based parties such as the Victorian Farmers' Union (VFU) and the Farmers and Settlers Party of New South Wales. Australia's first Country Party was founded in 1912 by Harry J. Stephens, editor of The Farmer & Settler, but under fierce opposition from rival newspapers, failed to gain momentum.
The VFU won a seat in the House of Representatives in 1918, and at the 1919 federal election the state-based country parties won seats in New South Wales, Victoria and Western Australia. They also began to win seats in the state parliaments. In 1920 the Country Party was established as a national party led by William McWilliams from Tasmania. In his first speech as leader, McWilliams laid out the principles of the new party, stating "we crave no alliance, we spurn no support but we intend drastic action to secure closer attention to the needs of primary producers" McWilliams was deposed as party leader in favour of Dr Earle Page in April 1921 following instances where McWilliams voted against the party line. McWilliams would later leave the Country Party to sit as an Independent.
According to historian B. D. Graham (1959), the graziers who operated the sheep stations were politically conservative. They disliked the Labor party, which represented their workers, and feared that Labor governments would pass unfavorable legislation and listen to foreigners and Communists. The graziers were satisfied with the marketing organisation of their industry, opposed any change in land tenure and labour relations, and advocated lower tariffs, low freight rates, and low taxes. On the other hand, Graham reports, the small farmers, not the graziers, founded the Country party. The farmers advocated government intervention in the market through price support schemes and marketing pools. The graziers often politically and financially supported the Country party, which in turn made the Country party more conservative.
At the 1922 election, it won enough seats to deny the Nationalists an overall majority, and was the Nationalists' only realistic coalition partner. However, Page let it be known that his party would not serve under Hughes, and forced his resignation. Page then entered negotiations with the Nationalists' new leader, Stanley Bruce, for a coalition government. Page's terms were stiff—five seats in a Cabinet of 11, including the Treasurer portfolio and the second rank in the ministry for himself. Nonetheless, Bruce readily agreed, and the "Bruce-Page Ministry" was formed—thus beginning the tradition of the party's leader ranking second in Coalition cabinets.
Page remained dominant in the party until 1939 and briefly served as an interim Prime Minister between the death of Joseph Lyons and the election of Robert Menzies as his successor, but Page's refusal to serve under Menzies led to his resignation as leader. The coalition was re-formed under Archie Cameron in 1940, and continued until October 1941 despite the election of Arthur Fadden as leader after the 1940 Election. Fadden was well regarded within conservative circles and proved to be a loyal deputy to Menzies in the difficult circumstances of 1941. When Menzies was forced to resign as Prime Minister, the UAP was so bereft of leadership that Fadden briefly succeeded him (despite the Country Party being the junior partner in the governing coalition). However, the two independents who had been propping up the government rejected Fadden's budget and brought the government down. Fadden stood down in favour of Labor leader John Curtin.
The Fadden-led Coalition made almost no headway against Curtin, and was severely defeated in the 1943 election. After that loss, Fadden became deputy Leader of the Opposition under Menzies, a role that continued after Menzies folded the UAP into the Liberal Party of Australia in 1944. Fadden remained a loyal partner of Menzies, though he was still keen to assert the independence of his party. Indeed, in the lead up to the 1949 federal election, Fadden played a key role in the defeat of the Chifley Labor government, frequently making inflammatory claims about the "socialist" nature of the Labor Party, which Menzies could then "clarify" or repudiate as he saw fit, thus appearing more "moderate". In 1949, Fadden became Treasurer in the second Menzies government and remained so until his retirement in 1958. His successful partnership with Menzies was one of the elements that sustained the coalition, which remained in office until 1972 (Menzies himself retired in 1966).
Fadden's successor, Trade Minister John McEwen, took the then unusual step of declining to serve as Treasurer, believing he could better ensure that the interests of Australian primary producers were safeguarded. Accordingly, McEwen personally supervised the signing of the first post-war trade treaty with Japan, new trade agreements with New Zealand and Britain, and Australia's first trade agreement with the USSR (1965). In addition to this he insisted on developing an all encompassing system of tariff protection that would encourage the development of those secondary industries that would "value add" Australia's primary produce. His success in this endeavour is sometimes dubbed "McEwenism". This was the period of the Country Party's greatest power, as was demonstrated in 1962 when McEwen was able to insist that Menzies sack a Liberal Minister who claimed that Britain's entry into the European Economic Community was unlikely to severely impact on the Australian economy as a whole.
Menzies retired in 1966 and was succeeded by Harold Holt. McEwen thus became the longest-tenured member of the government, with the informal right to veto government policy. The most significant instance that McEwen exercised this came when Holt disappeared in December 1967. John Gorton became the new Liberal Prime Minister in January 1968. McEwen was sworn in as an interim Prime Minister pending the election of the new Liberal leader. Logically, the Liberals' deputy leader, William McMahon, should have succeeded Holt. However, McMahon was a staunch free-trader, and there were also rumors that he was homosexual. As a result, McEwen told the Liberals that he and his party would not serve under McMahon. McMahon stood down in favour of John Gorton. It would be only after McEwen announced his retirement that MacMahon would be able to successfully challenge Gorton for the Liberal leadership. McEwen's reputation for political toughness led to him being nicknamed "Black Jack" by his allies and enemies alike.
At the state level, from 1957 to 1989, the Country Party under Frank Nicklin and Joh Bjelke-Petersen dominated governments in Queensland—the last six of those years ruling in its own right, without the Liberals. It also took part in governments in New South Wales, Victoria, and Western Australia.
However, successive electoral redistributions after 1964 indicated that the Country Party was losing ground electorally to the Liberals as the rural population declined, and the nature of some parliamentary seats on the urban/rural fringe changed. A proposed merger with the Democratic Labor Party (DLP) under the banner of "National Alliance" was rejected when it failed to find favour with voters at the 1974 state election.
Also in 1974, the Northern Territory members of the party joined with its Liberal party members to form the independent Country Liberal Party. This party continues to represent both parent parties in that territory. A separate party, the Joh-inspired NT Nationals, competed in the 1987 election with former Chief Minister Ian Tuxworth winning his seat of Barkly by a small margin. However, this splinter group were not endorsed by the national executive and soon disappeared from the political scene.
Countrymindedness.
"Countrymindedness" was a slogan that summed up the ideology of the Country Party from 1920 through the early 1970s. It was an ideology that was physiocratic, populist, and decentralist; it fostered rural solidarity and justified demands for government subsidies. "Countrymindedness" grew out of the failure of the country areas to participate in the rapid economic and population expansions that occurred after 1890. The growth of the ideology into urban areas came as most country people migrated to jobs in the cities. Its decline was due mainly to the reduction of real and psychological differences between country and city brought about by the postwar expansion of the Australian urban population and to the increased affluence and technological changes that accompanied it.
National Country Party, and National Party.
In 1975 the Country Party changed its name to the National Country Party as part of a strategy to expand into urban areas. This had some success in Queensland under Joh Bjelke-Petersen, but nowhere else. In Western Australia, the party briefly walked out of the coalition agreement in Western Australia in May 1975, returning within the month. However, the party split in two over the decision and other factors in late 1978, with a new National Party forming and becoming independent, holding three seats in the Western Australian lower house, while the National Country Party remained in coalition and also held three seats. They reconciled after the Burke Labor government came to power in 1983.
The 1980s were dominated by the feud between Bjelke-Petersen and the federal party leadership. Bjelke-Petersen briefly triumphed in 1987, forcing the Nationals to tear up the Coalition agreement and support his bid to become Prime Minister. The "Joh for Canberra" campaign backfired spectacularly when a large number of three-cornered contests allowed Labor to win a third term under Bob Hawke. It also proved to be the Queensland Nationals' last hurrah; Bjelke-Petersen was forced into retirement a few months after the federal election, and his party was heavily defeated in 1989. The Nationals experienced difficulties in the late 1990s from two fronts – firstly from the Liberal Party, who were winning seats on the basis that the Nationals were not seen to be a sufficiently separate party, and from the One Nation Party riding a swell of rural discontent with many of the policies such as multiculturalism and gun control embraced by all of the major parties. The rise of Labor in formerly safe National-held areas in rural Queensland, particularly on the coast, has been the biggest threat to the Queensland Nationals.
State parties.
Queensland.
Queensland is the only state in which the Nationals have consistently been the stronger coalition partner. The Nationals were the senior partner in the non-Labor Coalition from 1925 until the Coalition was broken in 1983. At the 1983 state election, the Nationals under Joh Bjelke-Petersen came up one seat short of a majority, but later gained a majority when two Liberal members crossed the floor to join the Nationals. The Nationals then governed in their own right until 1989.
The continued success of the Australian Labor Party at a state level has put pressure on the Nationals' links with the Liberal Party, their traditional coalition partner. In most states, the Coalition agreement is not in force when the parties are in opposition, allowing the two parties greater freedom of action.
In Queensland the National Party merged with the Liberal Party forming the Liberal National Party (LNP) in 2008. The LNP led by Lawrence Springborg went on to lose the March 2009 election to Anna Bligh's Australian Labor Party. However, in the Queensland state election, 2012, the LNP defeated the Labor Party in a landslide, but lost government in 2015.
South Australia.
In South Australia, for the first time in the Nationals' history, in 2002 the single Nationals member in the House of Assembly entered the Rann Labor Government as a Minister forming an informal coalition between the two parties. Since the 2010 South Australian State election, the Nationals in South Australia have no representative in either the House of Assembly or the Upper House or at a Federal level. There existed a distinctly different Country Party in South Australia which merged with the Liberal Federation to become the Liberal and Country League in 1932.
Western Australia.
Western Australia's National Party chose to assert its independence after an acrimonious co-habitation with the Liberals on the 2005 campaign trail. Unlike its New South Wales and Queensland counterparts, the WA party had decided to oppose Liberal candidates in the 2008 election. The party aimed to hold the balance of power in the state "as an independent conservative party" ready to negotiate with the Liberals or Labor to form a minority government. After the election, the Nationals negotiated an agreement to form a government with the Liberals and an independent MP, though not described as a "traditional coalition" due to the reduced cabinet collective responsibility of National cabinet members.
Western Australia's one-vote-one-value reforms will cut the number of rural seats in the state assembly to reflect the rural population level: this, coupled with the Liberals' strength in country areas has put the Nationals under significant pressure.
Victoria.
The Nationals were stung in early 2006, when their only Victorian senator, Julian McGauran, defected to the Liberals and created a serious rift between the Nationals and the Liberals. Several commentators believed that changing demographics and unfavourable preference deals would demolish the Nationals at the state election that year, but they went on to enjoy considerable success by winning two extra lower house seats. The Nationals were in a coalition government with the Liberals at a State level in Victoria until their defeat at the 2014 election. Following the election, the ABC reported that the coalition parties would "review" whether to continue their joint working arrangement into opposition. However, both outgoing Nationals leader Peter Ryan and incoming Liberal leader Matthew Guy indicated they felt the coalition should continue.
Political role.
The Nationals see their main role as giving a voice to Australians who live outside the country's metropolitan areas.
Traditionally, the leader of the National Party serves as Deputy Prime Minister when the Coalition is in government. This tradition dates back to the creation of the office in 1968.
The National Party's support base and membership are closely associated with the agricultural community. Historically anti-union, the party has vacillated between state support for primary industries ("agrarian socialism") and free agricultural trade and has opposed tariff protection for Australia's manufacturing and service industries. This vacillation prompted those opposed to the policies of the Nationals to joke that its real aim was to "capitalise its gains and socialise its losses!". It is usually pro-mining, pro-development, and anti-environmentalist.
The Nationals vote is in decline and its traditional supporters are turning instead to prominent independents such as Bob Katter, Tony Windsor and Peter Andren in Federal Parliament and similar independents in the Parliaments of New South Wales, Queensland and Victoria, many of whom are former members of the National Party. In fact at the 2004 Federal election, National Party candidates received fewer first preference votes than the Australian Greens.
Demographic changes are not helping, with fewer people living and employed on the land or in small towns, the continued growth of the larger provincial centres, and, in some cases, the arrival of left-leaning "city refugees" in rural areas. The Liberals have also gained support as the differences between the coalition partners on a federal level have become invisible. This was highlighted in January 2006, when Nationals Senator Julian McGauran defected to the Liberals, saying that there was "no longer any real distinguishing policy or philosophical difference".
In Queensland, Nationals leader Lawrence Springborg advocated merger of the National and Liberal parties at a state level in order to present a more effective opposition to the Labor Party. Previously this plan had been dismissed by the Queensland branch of the Liberal party, but the idea received in-principle support from the Liberals. Federal leader Mark Vaile stated the Nationals will not merge with the Liberal Party at a federal level. The plan was opposed by key Queensland Senators Ron Boswell and Barnaby Joyce, and was scuttled in 2006. After suffering defeat in the 2006 Queensland poll, Lawrence Springborg was replaced by Jeff Seeney, who indicated he was not interested in merging with the Liberal Party until the issue is seriously raised at a Federal level.
Support for the Nationals in the 2006 Victorian state election was considerable with the party picking up two extra seats in the Lower House to maintain its total representation of 11 sitting members (two Upper House seats were lost, mostly due to a change from preferential to proportional representation). This success can be attributed to a more assertive National Party image (a differentation to that of the Liberals) and the growing popularity of state and federal Nationals identities such as Joyce.
In September 2008, Joyce replaced CLP Senator and Nationals deputy leader Nigel Scullion as leader of the Nationals in the Senate, and stated that his party in the upper house would no longer necessarily vote with their Liberal counterparts in the upper house, which opened up another possible avenue for the Rudd Labor Government to get legislation through.
Liberal/National merger.
Merger plans came to a head in May 2008, when the Queensland state Liberal Party gave an announcement not to wait for a federal blueprint but instead to merge immediately. The new party, the Liberal National Party, was founded in July 2008.
Parliamentary leaders.
State and Territory Parliaments.
1 In the Northern Territory, the Nationals do not endorse their own candidates. Instead, the Country Liberal Party is their preferred party in the Territory.
2 Queensland is represented by the Liberal National Party of Queensland. This party is the result of a merger of the Queensland Division of the Liberal Party and the Queensland National Party to contest elections as a single party.
The National Party does not stand candidates in Tasmania or the Australian Capital Territory.

</doc>
<doc id="21930" url="https://en.wikipedia.org/wiki?curid=21930" title="Northern blot">
Northern blot

The northern blot is a technique used in molecular biology research to study gene expression by detection of RNA (or isolated mRNA) in a sample.
With northern blotting it is possible to observe cellular control over structure and function by determining the particular gene expression rates during differentiation and morphogenesis, as well as in abnormal or diseased conditions. Northern blotting involves the use of electrophoresis to separate RNA samples by size, and detection with a hybridization probe complementary to part of or the entire target sequence. The term 'northern blot' actually refers specifically to the capillary transfer of RNA from the electrophoresis gel to the blotting membrane. However, the entire process is commonly referred to as northern blotting. The northern blot technique was developed in 1977 by James Alwine, David Kemp, and George Stark at Stanford University. Northern blotting takes its name from its similarity to the first blotting technique, the Southern blot, named for biologist Edwin Southern. The major difference is that RNA, rather than DNA, is analyzed in the northern blot.
Procedure.
A general blotting procedure starts with extraction of total RNA from a homogenized tissue sample or from cells. Eukaryotic mRNA can then be isolated through the use of oligo (dT) cellulose chromatography to isolate only those RNAs with a poly(A) tail. RNA samples are then separated by gel electrophoresis. Since the gels are fragile and the probes are unable to enter the matrix, the RNA samples, now separated by size, are transferred to a nylon membrane through a capillary or vacuum blotting system. A nylon membrane with a positive charge is the most effective for use in northern blotting since the negatively charged nucleic acids have a high affinity for them. The transfer buffer used for the blotting usually contains formamide because it lowers the annealing temperature of the probe-RNA interaction, thus eliminating the need for high temperatures, which could cause RNA degradation. Once the RNA has been transferred to the membrane, it is immobilized through covalent linkage to the membrane by UV light or heat. After a probe has been labeled, it is hybridized to the RNA on the membrane. Experimental conditions that can affect the efficiency and specificity of hybridization include ionic strength, viscosity, duplex length, mismatched base pairs, and base composition. The membrane is washed to ensure that the probe has bound specifically and to prevent background signals from arising. The hybrid signals are then detected by X-ray film and can be quantified by densitometry. To create controls for comparison in a northern blot samples not displaying the gene product of interest can be used after determination by microarrays or RT-PCR.
Gels.
The RNA samples are most commonly separated on agarose gels containing formaldehyde as a denaturing agent for the RNA to limit secondary structure. The gels can be stained with ethidium bromide (EtBr) and viewed under UV light to observe the quality and quantity of RNA before blotting. Polyacrylamide gel electrophoeresis with urea can also be used in RNA separation but it is most commonly used for fragmented RNA or microRNAs. An RNA ladder is often run alongside the samples on an electrophoresis gel to observe the size of fragments obtained but in total RNA samples the ribosomal subunits can act as size markers. Since the large ribosomal subunit is 28S (approximately 5kb) and the small ribosomal subunit is 18S (approximately 2kb) two prominent bands appear on the gel, the larger at close to twice the intensity of the smaller.
Probes.
Probes for northern blotting are composed of nucleic acids with a complementary sequence to all or part of the RNA of interest, they can be DNA, RNA, or oligonucleotides with a minimum of 25 complementary bases to the target sequence. RNA probes (riboprobes) that are transcribed in vitro are able to withstand more rigorous washing steps preventing some of the background noise. Commonly cDNA is created with labelled primers for the RNA sequence of interest to act as the probe in the northern blot. The probes must be labelled either with radioactive isotopes (32P) or with chemiluminescence in which alkaline phosphatase or horseradish peroxidase (HRP) break down chemiluminescent substrates producing a detectable emission of light. The chemiluminescent labelling can occur in two ways: either the probe is attached to the enzyme, or the probe is labelled with a ligand (e.g. biotin) for which the ligand (e.g., avidin or streptavidin) is attached to the enzyme (e.g. HRP). X-ray film can detect both the radioactive and chemiluminescent signals and many researchers prefer the chemiluminescent signals because they are faster, more sensitive, and reduce the health hazards that go along with radioactive labels. The same membrane can be probed up to five times without a significant loss of the target RNA.
Applications.
Northern blotting allows one to observe a particular gene's expression pattern between tissues, organs, developmental stages, environmental stress levels, pathogen infection, and over the course of treatment. The technique has been used to show overexpression of oncogenes and downregulation of tumor-suppressor genes in cancerous cells when compared to 'normal' tissue, as well as the gene expression in the rejection of transplanted organs. If an upregulated gene is observed by an abundance of mRNA on the northern blot the sample can then be sequenced to determine if the gene is known to researchers or if it is a novel finding. The expression patterns obtained under given conditions can provide insight into the function of that gene. Since the RNA is first separated by size, if only one probe type is used variance in the level of each band on the membrane can provide insight into the size of the product, suggesting alternative splice products of the same gene or repetitive sequence motifs. The variance in size of a gene product can also indicate deletions or errors in transcript processing. By altering the probe target used along the known sequence it is possible to determine which region of the RNA is missing.
BlotBase is an online database publishing northern blots. BlotBase has over 700 published northern blots of human and mouse samples, in over 650 genes across more than 25 different tissue types. Northern blots can be searched by a blot ID, paper reference, gene identifier, or by tissue. The results of a search provide the blot ID, species, tissue, gene, expression level, blot image (if available), and links to the publication that the work originated from. This new database provides sharing of information between members of the science community that was not previously seen in northern blotting as it was in sequence analysis, genome determination, protein structure, etc.
Advantages and disadvantages.
Analysis of gene expression can be done by several different methods including RT-PCR, RNase protection assays, microarrays, RNA-Seq, serial analysis of gene expression (SAGE), as well as northern blotting. Microarrays are quite commonly used and are usually consistent with data obtained from northern blots; however, at times northern blotting is able to detect small changes in gene expression that microarrays cannot. The advantage that microarrays have over northern blots is that thousands of genes can be visualized at a time, while northern blotting is usually looking at one or a small number of genes.
A problem in northern blotting is often sample degradation by RNases (both endogenous to the sample and through environmental contamination), which can be avoided by proper sterilization of glassware and the use of RNase inhibitors such as DEPC (diethylpyrocarbonate). The chemicals used in most northern blots can be a risk to the researcher, since formaldehyde, radioactive material, ethidium bromide, DEPC, and UV light are all harmful under certain exposures. Compared to RT-PCR, northern blotting has a low sensitivity, but it also has a high specificity, which is important to reduce false positive results.
The advantages of using northern blotting include the detection of RNA size, the observation of alternate splice products, the use of probes with partial homology, the quality and quantity of RNA can be measured on the gel prior to blotting, and the membranes can be stored and reprobed for years after blotting.
Reverse northern blot.
Researchers occasionally use a variant of the procedure known as the reverse northern blot. In this procedure, the substrate nucleic acid (that is affixed to the membrane) is a collection of isolated DNA fragments, and the probe is RNA extracted from a tissue and radioactively labelled.
The use of DNA microarrays that have come into widespread use in the late 1990s and early 2000s is more akin to the reverse procedure, in that they involve the use of isolated DNA fragments affixed to a substrate, and hybridization with a probe made from cellular RNA. Thus the reverse procedure, though originally uncommon, enabled northern analysis to evolve into gene expression profiling, in which many (possibly all) of the genes in an organism may have their expression monitored.

</doc>
<doc id="21932" url="https://en.wikipedia.org/wiki?curid=21932" title="Narrow-gauge railway">
Narrow-gauge railway

A narrow-gauge railway (or narrow-gauge railroad) is a railway with a track gauge narrower than the of standard gauge railways. Most existing narrow gauge railways are between and .
Since narrow-gauge railways are usually built with smaller radius curves, smaller structure gauges, lighter rails, etc., they can be substantially less costly to build, equip, and operate than standard gauge or broad gauge railways, particularly in mountainous or difficult terrain. The lower costs of narrow-gauge railways mean they are often built to serve industries and communities where the traffic potential would not justify the cost of building a standard or broad gauge line.
Narrow-gauge railways also have specialized use in mines and other environments where a very small structure gauge makes a very small loading gauge necessary. Narrow-gauge railways also have more general applications. Nonindustrial narrow-gauge mountain railways are or were common in the Rocky Mountains of the United States and the Pacific Cordillera of Canada, in Mexico, Switzerland, the former Yugoslavia, Greece, India, and Costa Rica. In some countries, narrow gauge is the standard, like the gauge in Japan, Indonesia, Taiwan, New Zealand, South Africa, the Australian states of Queensland and Tasmania, and the in Malaysia and Thailand.
Many narrow-gauge street tramways are used, particularly in Europe, where tramways are common.
History.
The earliest recorded railway is shown in the "De re metallica" of 1556, which shows a mine in Bohemia with a railway of about gauge. During the 16th century, railways were mainly restricted to hand-pushed narrow gauge lines in mines throughout Europe. During the 17th century, mine railways were extended to provide transportation above ground. These lines were industrial, connecting mines with nearby transportation points, usually canals or other waterways. These railways were usually built to the same narrow gauge as the mine railways from which they developed.
The world's first steam locomotive on rails, built in 1802 by Richard Trevithick for the Coalbrookdale Company, ran on a plateway. During the 1820s and 1830s, a number of industrial narrow gauge railways in the United Kingdom used steam locomotives. In 1842, the first narrow gauge steam locomotive outside the UK was built for the gauge Antwerp-Ghent Railway in Belgium. The first use of steam locomotives on a public, passenger-carrying narrow gauge railway came in 1865 when the Ffestiniog Railway introduced its passenger service, after receiving its first locomotives two years prior.
Historically, many narrow gauge railways were built as part of specific industrial enterprises and were primarily industrial railways rather than general carriers. Some common uses for these industrial narrow gauge railways were mining, logging, construction, tunnelling, quarrying, and the conveying of agricultural products. Extensive narrow gauge networks were constructed in many parts of the world for these purposes. For example, mountain logging operations in the 19th century often used narrow gauge railways to transport logs from mill sites to market. Significant sugarcane railways still operate in Cuba, Fiji, Java, the Philippines, and Queensland. Narrow gauge railway equipment remains in common use for the construction of tunnels.
Extensive narrow gauge railway systems served the front-line trenches of both sides in World War I. They were a short-lived military application, and after the end of the war, the surplus equipment from these created a small boom in narrow gauge railway building in Europe.
Advantages.
Narrow gauge railways usually cost less to build because they are usually lighter in construction, using smaller cars and locomotives (smaller loading gauge), as well as smaller bridges, smaller tunnels (smaller structure gauge) and tighter curves. Narrow gauge is thus often used in mountainous terrain, where the savings in civil engineering work can be substantial. It is also used in sparsely populated areas where the potential demand is too low for broader gauge railways to be economically viable. This is the case in some of Australia and most of Southern Africa, where extremely poor soils have led to population densities too low for standard gauge to be viable.
For temporary railways that will be removed after short-term use, such as for construction, the logging industry, the mining industry, or large-scale construction projects, especially in confined spaces, such as the Channel Tunnel, a narrow gauge railway is substantially cheaper and easier to install and remove. The use of such railways has almost vanished due to the capabilities of modern trucks.
In many countries, narrow gauge railways were built as "feeder" or "branch" lines to feed traffic to more important standard gauge lines, due to their lower construction costs. The choice was often not between a narrow gauge railway and a standard gauge one, but between a narrow gauge railway and none at all.
Disadvantages.
Narrow gauge railways cannot interchange rolling stock such as freight and passenger cars freely with the standard gauge or broad gauge railways with which they link, and the transfers of passengers and freight require time-consuming manual labour or substantial capital expenditure. Some bulk commodities, such as coal, ore, and gravel, can be mechanically transshipped, but this still incurs time penalties and the equipment required for the transfer is often complex to maintain.
Also in times of peak demand, it is very difficult to move rolling stock to where it is needed when a break of gauge exists, so enough rolling stock must be available to meet a narrow gauge railways' own peak demand, which might be much more than needed by equivalent standard gauge railways, and the surplus equipment generated no cash flow during periods of low demand.
Solutions to these problems of transshipment are bogie exchange between cars, a rollbock system, variable gauge, dual gauge, or even gauge conversion. European standard gauge trains normally use buffers and chain couplers, which do not allow such tight curves, a main reason to have narrow gauge. Therefore, narrow gauge trains normally use other couplers, which makes bogie exchange meaningless.
Another problem for narrow gauge railways was that they lacked the physical space to grow: their cheap construction meant they were engineered only for their initial traffic demands. While a standard or broad gauge railway could more easily be upgraded to handle heavier, faster traffic, many narrow gauge railways were impractical to improve. Speeds and loads hauled could not increase, so traffic density was significantly limited. In the case of Queensland, Australia, the Queensland Rail passenger network has nearly reached its capacity due to the narrow gauge and an ever increasing population, as such, new lines are to be built, thus negating the original cost savings.
Successful railways.
The heavy duty narrow gauge railways in Australia (e.g. Queensland), South Africa, and New Zealand show that if the track is built to a heavy-duty standard, performance almost as good as a standard gauge line is possible. Some 200-car trains operate on the Sishen-Saldanha railway in South Africa, and high-speed tilt-trains in Queensland. Another example of a heavy-duty narrow gauge line is EFVM in Brazil. gauge, it has over-100-pound rail () and a loading gauge almost as large as US nonexcess-height lines. It has multiple locomotives and 200+ car trains. In South Africa and New Zealand, the loading gauge is similar to the restricted British loading gauge, and in New Zealand some British Rail Mark 2 carriages have been rebuilt with new bogies for use by Tranz Scenic (Wellington-Palmerston North service), Tranz Metro (Wellington-Masterton service), and Transdev Auckland (Auckland suburban services).
Fastest trains.
The reduced stability of narrow gauge means its trains cannot run at the same high speeds as on broader gauges, unless the tracks are aligned with greater precision . In Japan and Queensland, recent permanent way improvements have allowed trains on gauge tracks to run at and faster. Queensland Rail's tilt train is currently the fastest train in Australia and the fastest gauge train in the world, setting a record at 210 km/h. A special gauge railcar was built for the Otavi Mining and Railway Company with a design speed of 137 km/h.
Compare these speeds with standard gauge or broad gauge trains which can run at up to . The contrast is most evident in Japan, home of the Shinkansen, a network of standard gauge lines built solely for high-speed rail in a country where narrow gauge is the predominant standard.
Curve radius is also important for high speeds: narrow gauge railways tend to have sharper curves, which limits the speed at which a vehicle can safely proceed along the track.
Costs.
Many engineers considered the cost of a railway varies with some power of the gauge, so the narrower gauge the cheaper it might be. This applied also to different narrow gauges, such as a proposed line in Papua using either or .
Nomenclature.
In general, a narrow gauge railway has a track gauge less than standard gauge. However, due to historical and local circumstances, the definition of a narrow gauge railway can be different.
Gauges used.
Many narrow gauges are in use or formerly used between gauge and gauge. They fall into several broad categories:
Scotch gauge.
Scotch gauge was the name given to a track gauge, that was adopted by early 19th-century railways mainly in the Lanarkshire area of Scotland. Also lines were constructed. Both gauges were eventually converted to standard gauge.
Three foot, six inch gauge railways.
Similar gauges are:
Metre gauge and Italian metre gauge railways.
Metre gauge is the system of narrow gauge railways and tramways with a track gauge of . It has installations of around .
As a result of Italian law, track gauges in Italy were defined from the centres of each rail, rather than the inside edges of the rails. This gauge was measured between the edges of the rails and is known as Italian metre gauge
Three foot, 900 mm, and Swedish three foot (891 mm) gauge railways.
Three foot gauge railways have a track gauge of and are generally found throughout North and South America, as well as Ireland and the Isle of Man.
, Bosnian gauge, and two foot six inch gauge railways.
The Imperial gauge railways were generally constructed in the former British colonies, such as the Kelani Valley Line (now ) in Sri Lanka.
These lightweight lines can be built at a substantial cost saving over medium or standard gauge railways, but are generally restricted in their carrying capacity. The majority of these lines were built in mountainous areas, the majority for carrying mineral traffic from mines to ports or standard gauge railways.
Two foot (610 mm), 600 mm, and similar gauges.
Gauges: , , , and 
Minimum gauge railways.
Gauges below were rare, but did exist. In Britain, Sir Arthur Heywood developed gauge estate railways, while in France Decauville produced a range of industrial railways running on and tracks, most commonly in restricted environments such as underground mine railways, parks and farms. Several gauge railways were built in Britain to serve ammunition depots and other military facilities, particularly during World War I.

</doc>
<doc id="21933" url="https://en.wikipedia.org/wiki?curid=21933" title="Neutron activation analysis">
Neutron activation analysis

Neutron activation analysis (NAA) is a nuclear process used for determining the concentrations of elements in a vast amount of materials. NAA allows discrete sampling of elements as it disregards the chemical form of a sample, and focuses solely on its nucleus. The method is based on neutron activation and therefore requires a source of neutrons. The sample is bombarded with neutrons, causing the elements to form radioactive isotopes. The radioactive emissions and radioactive decay paths for each element are well known. Using this information, it is possible to study spectra of the emissions of the radioactive sample, and determine the concentrations of the elements within it. A particular advantage of this technique is that it does not destroy the sample, and thus has been used for analysis of works of art and historical artifacts. NAA can also be used to determine the activity of a radioactive sample.
If NAA is conducted directly on irradiated samples it is termed Instrumental Neutron Activation Analysis (INAA). In some cases irradiated samples are subjected to chemical separation to remove interfering species or to concentrate the radioisotope of interest, this technique is known as Radiochemical Neutron Activation Analysis (RNAA).
NAA can perform non-destructive analyses on solids, liquids, suspensions, slurries, and gases with no or minimal preparation. Due to the penetrating nature of incident neutrons and resultant gamma rays, the technique provides a true bulk analysis. As different radioisotopes have different half-lives, counting can be delayed to allow interfering species to decay eliminating interference. Until the introduction of ICP-AES and PIXE, NAA was the standard analytical method for performing multi-element analyses with minimum detection limits in the sub-ppm range. Accuracy of NAA is in the region of 5%, and relative precision is often better than 0.1%. There are two noteworthy drawbacks to the use of NAA; even though the technique is essentially non-destructive, the irradiated sample will remain radioactive for many years after the initial analysis, requiring handling and disposal protocols for low-level to medium-level radioactive material; also, the number of suitable activation nuclear reactors is declining; with a lack of irradiation facilities, the technique has declined in popularity and become more expensive.
Overview.
Neutron activation analysis is a sensitive multi-element analytical technique used for both qualitative and quantitative analysis of major, minor, trace and rare elements. NAA was discovered in 1936 by Hevesy and Levi, who found that samples containing certain rare earth elements became highly radioactive after exposure to a source of neutrons. This observation led to the use of induced radioactivity for the identification of elements. NAA is significantly different from other spectroscopic analytical techniques in that it is based not on electronic transitions but on nuclear transitions. To carry out an NAA analysis, the specimen is placed into a suitable irradiation facility and bombarded with neutrons. This creates artificial radioisotopes of the elements present. Following irradiation, the artificial radioisotopes decay with emission of particles or, more importantly gamma rays, which are characteristic of the element from which they were emitted.
For the NAA procedure to be successful, the specimen or sample must be selected carefully. In many cases small objects can be irradiated and analysed intact without the need of sampling. But, more commonly, a small sample is taken, usually by drilling in an inconspicuous place. About 50 mg (one-twentieth of a gram) is a sufficient sample, so damage to the object is minimised. It is often good practice to remove two samples using two different drill bits made of different materials. This will reveal any contamination of the sample from the drill bit material itself. The sample is then encapsulated in a vial made of either high purity linear polyethylene or quartz. These sample vials come in many shapes and sizes to accommodate many specimen types. The sample and a standard are then packaged and irradiated in a suitable reactor at a constant, known neutron flux. A typical reactor used for activation uses uranium fission, providing a high neutron flux and the highest available sensitivities for most elements. The neutron flux from such a reactor is in the order of 1012 neutrons cm−2 s−1. The type of neutrons generated are of relatively low kinetic energy (KE), typically less than 0.5 eV. These neutrons are termed thermal neutrons. Upon irradiation, a thermal neutron interacts with the target nucleus via a non-elastic collision, causing neutron capture. This collision forms a compound nucleus which is in an excited state. The excitation energy within the compound nucleus is formed from the binding energy of the thermal neutron with the target nucleus. This excited state is unfavourable and the compound nucleus will almost instantaneously de-excite (transmutate) into a more stable configuration through the emission of a prompt particle and one or more characteristic prompt gamma photons. In most cases, this more stable configuration yields a radioactive nucleus. The newly formed radioactive nucleus now decays by the emission of both particles and one or more characteristic delayed gamma photons. This decay process is at a much slower rate than the initial de-excitation and is dependent on the unique half-life of the radioactive nucleus. These unique half-lives are dependent upon the particular radioactive species and can range from fractions of a second to several years. Once irradiated, the sample is left for a specific decay period, then placed into a detector, which will measure the nuclear decay according to either the emitted particles, or more commonly, the emitted gamma rays.
Variations.
NAA can vary according to a number of experimental parameters. The kinetic energy of the neutrons used for irradiation will be a major experimental parameter. The above description is of activation by slow neutrons, slow neutrons are fully moderated within the reactor and have KE <0.5 eV. Medium KE neutrons may also be used for activation, these neutrons have been only partially moderated and have KE of 0.5 eV to 0.5 MeV, and are termed epithermal neutrons. Activation with epithermal neutrons is known as Epithermal NAA (ENAA). High KE neutrons are sometimes used for activation, these neutrons are unmoderated and consist of primary fission neutrons. High KE or fast neutrons have a KE >0.5 MeV. Activation with fast neutrons is termed Fast NAA (FNAA).
Another major experimental parameter is whether nuclear decay products (gamma rays or particles) are measured during neutron irradiation (prompt gamma), or at some time after irradiation (delayed gamma). PGNAA is generally performed by using a neutron stream tapped off the nuclear reactor via a beam port. Neutron fluxes from beam ports are the order of 106 times weaker than inside a reactor. This is somewhat compensated for by placing the detector very close to the sample reducing the loss in sensitivity due to low flux. PGNAA is generally applied to elements with extremely high neutron capture cross-sections; elements which decay too rapidly to be measured by DGNAA; elements that produce only stable isotopes; or elements with weak decay gamma ray intensities. PGNAA is characterised by short irradiation times and short decay times, often in the order of seconds and minutes.
DGNAA is applicable to the vast majority of elements that form artificial radioisotopes. DG analyses are often performed over days, weeks or even months. This improves sensitivity for long-lived radionuclides as it allows short-lived radionuclide to decay, effectively eliminating interference. DGNAA is characterised by long irradiation times and long decay times, often in the order of hours, weeks or longer.
Neutron sources.
a range of different sources can be used:
Reactors.
Some reactors are used for the neutron irradiation of samples for radioisotope production for a range of purposes. The sample can be placed in an irradiation container which is then placed in the reactor; if epithermal neutrons are required for the irradiation then cadmium can be used to filter out the thermal neutrons.
Fusors.
A relatively simple Farnsworth–Hirsch fusor can be used to generate neutrons for NAA experiments. The advantages of this kind of apparatus is that it is compact, often benchtop-sized, and that it can simply be turned off and on. A disadvantage is that this type of source will not produce the neutron flux that can be obtained using a reactor.
Isotope sources.
For many workers in the field a reactor is an item which is too expensive, instead it is common to use a neutron source which uses a combination of an alpha emitter and beryllium. These sources tend to be much weaker than reactors.
Gas discharge tubes.
These can be used to create pulses of neutrons, they have been used for some activation work where the decay of the target isotope is very rapid. For instance in oil wells.
Detectors.
There are a number of detector types and configurations used in NAA. Most are designed to detect the emitted gamma radiation. The most common types of gamma detectors encountered in NAA are the gas ionisation type, scintillation type and the semiconductor type. Of these the scintillation and semiconductor type are the most widely employed. There are two detector configurations utilised, they are the planar detector, used for PGNAA and the well detector, used for DGNAA. The planar detector has a flat, large collection surface area and can be placed close to the sample. The well detector ‘surrounds’ the sample with a large collection surface area.
Scintillation-type detectors use a radiation-sensitive crystal, most commonly thallium-doped sodium iodide (NaI(Tl)), which emits light when struck by gamma photons. These detectors have excellent sensitivity and stability, and a reasonable resolution.
Semiconductor detectors utilise the semiconducting element germanium. The germanium is processed to form a p-i-n (positive-intrinsic-negative) diode, and when cooled to ~77 K by liquid nitrogen to reduce dark current and detector noise, produces a signal which is proportional to the photon energy of the incoming radiation. There are two types of germanium detector, the lithium-drifted germanium or Ge(Li) (pronounced ‘jelly’), and the high-purity germanium or HPGe.
The semiconducting element silicon may also be used but germanium is preferred, as its higher atomic number makes it more efficient at stopping and detecting high energy gamma rays. Both Ge(Li) and HPGe detectors have excellent sensitivity and resolution, but Ge(Li) detectors are unstable at room temperature, with the lithium drifting into the intrinsic region ruining the detector. The development of undrifted high purity germanium has overcome this problem.
Particle detectors can also be used to detect the emission of alpha (α) and beta (β) particles which often accompany the emission of a gamma photon but are less favourable, as these particles are only emitted from the surface of the sample and are often absorbed or attenuated by atmospheric gases requiring expensive vacuum conditions to be effectively detected. Gamma rays, however, are not absorbed or attenuated by atmospheric gases, and can also escape from deep within the sample with minimal absorption.
Analytical capabilities.
NAA can detect up to 74 elements depending upon the experimental procedure, with minimum detection limits ranging from 0.1 to 1x106 ng g−1 depending on element under investigation. Heavier elements have larger nuclei, therefore they have a larger neutron capture cross-section and are more likely to be activated. Some nuclei can capture a number of neutrons and remain relatively stable, not undergoing transmutation or decay for many months or even years. Other nuclei decay instantaneously or form only stable isotopes and can only be identified by PGNAA.
Applications.
Neutron Activation Analysis has a wide variety of applications including within the fields of archaeology, soil science, geology, forensics, and the semiconductor industry. Forensically, hairs subjected to a detailed forensic neutron analysis to determine whether they had sourced from the same individuals was first used in the trial of John Norman Collins.
Archaeologists use NAA in order to determine the elements that comprise certain artifacts. This technique is used because it is nondestructive and it can relate an artifact to its source by its chemical signature. This method has proven to be very successful at determining trade routes, particularly for obsidian, with the ability of NAA to distinguish between chemical compositions. In agricultural processes, the movement of fertilizers and pesticides is influenced by surface and subsurface movement as it infiltrates the water supplies. In order to track the distribution of the fertilizers and pesticides, bromide ions in various forms are used as tracers that move freely with the flow of water while having minimal interaction with the soil. Neutron activation analysis is used to measure bromide so that extraction is not necessary for analysis. NAA is used in geology to aid in researching the processes that formed the rocks through the analysis of the rare earth elements and trace elements. It also assists in locating ore deposits and tracking certain elements. Neutron activation analysis is also used to create standards in the semiconductor industry. Semiconductors require a high level of purity, with contamination significantly reducing the quality of the semiconductor. NAA is used to detect trace impurities and establish contamination standards, because it involves limited sample handling and high sensitivity.

</doc>
<doc id="21935" url="https://en.wikipedia.org/wiki?curid=21935" title="Non-deterministic Turing machine">
Non-deterministic Turing machine

In theoretical computer science, a Turing machine is a theoretical machine that is used in thought experiments to examine the abilities and limitations of computers.
In essence, a Turing machine is imagined to be a simple computer that reads and writes symbols one at a time on an endless tape by strictly following a set of rules. It determines what action it should perform next according to its internal "state" and "what symbol it currently sees". An example of one of a Turing Machine's rules might thus be: "If you are in state 2 and you see an 'A', change it to 'B' and move left."
In a deterministic Turing machine, the set of rules prescribes at most one action to be performed for any given situation. By contrast, a non-deterministic Turing machine (NTM) may have a set of rules that prescribes more than one action for a given situation. For example, a non-deterministic Turing machine may have both "If you are in state 2 and you see an 'A', change it to a 'B' and move left" and "If you are in state 2 and you see an 'A', change it to a 'C' and move right" in its rule set.
A deterministic Turing machine (DTM) has a "transition function" that, for a given state and symbol under the tape head, specifies three things: 
For example, an X on the tape in state 3 might make the DTM write a Y on the tape, move the head one position to the right, and switch to state 5.
A non-deterministic Turing machine (NTM) differs in that the state and tape symbol no longer "uniquely" specify these things; rather, many different actions may apply for the same combination of state and symbol. For example, an X on the tape in state 3 might now allow the NTM to write a Y, move right, and switch to state 5, "or" to write an X, move left, and stay in state 3.
Definition.
A non-deterministic Turing machine can be formally defined as a 6-tuple formula_1, where
The difference with a standard (deterministic) Turing machine is that for those, the transition relation is a function (the transition function).
Configurations and the "yields" relation on configurations, which describes the possible actions of the Turing machine given any possible contents of the tape, are as for standard Turing machines, except that the "yields" relation is no longer single-valued. The notion of string acceptance is unchanged: a non-deterministic Turing machine accepts a string if, when the machine is started on the configuration in which the tape head is on the first character of the string (if any), and the tape is all blank otherwise, at least one of the machine's possible computations from that configuration puts the machine into a state in formula_10. (If the machine is deterministic, the possible computations are the prefixes of a single, possibly infinite, path.)
Resolution of multiple rules.
How does the NTM "know" which of these actions it should take? There are two ways of looking at it. One is to say that the machine is the "luckiest possible guesser"; it always picks a transition that eventually leads to an accepting state, if there is such a transition. The other is to imagine that the machine "branches" into many copies, each of which follows one of the possible transitions. Whereas a DTM has a single "computation path" that it follows, an NTM has a "computation tree". If at least one branch of the tree halts with an "accept" condition, we say that the NTM accepts the input.
Equivalence with DTMs.
In particular, nondeterministic Turing machines are equivalent with deterministic Turing machines. This equivalency refers to what can be computed, as opposed to how quickly.
NTMs effectively include DTMs as special cases, so it is immediately clear that DTMs are not more powerful. It might seem that NTMs are more powerful than DTMs, since they can allow trees of possible computations arising from the same initial configuration, accepting a string if any one branch in the tree accepts it.
However, it is possible to simulate NTMs with DTMs: One approach is to use a DTM of which the configurations represent multiple configurations of the NTM, and the DTM's operation consists of visiting each of them in turn, executing a single step at each visit, and spawning new configurations whenever the transition relation defines multiple continuations.
Another construction simulates NTMs with 3-tape DTMs, of which the first tape always holds the original input string, the second is used to simulate a particular computation of the NTM, and the third encodes a path in the NTM's computation tree. The 3-tape DTMs are easily simulated with a normal single-tape DTM.
In this construction, the resulting DTM effectively performs a breadth-first search of the NTM's computation tree, visiting all possible computations of the NTM in order of increasing length until it finds an accepting one. Therefore, the length of an accepting computation of the DTM is, in general, exponential in the length of the shortest accepting computation of the NTM. This is considered to be a general property of simulations of NTMs by DTMs; the most famous unresolved question in computer science, the P = NP problem, is related to this issue.
Bounded non-determinism.
An NTM has the property of bounded non-determinism, "i.e.", if an NTM always halts on a given input tape "T" then it halts in a bounded number of steps, and therefore can only have a bounded number of possible configurations.
Comparison with quantum computers.
It is a common misconception that quantum computers are NTMs. It is believed but has not been proven that the power of quantum computers is incomparable to that of NTMs. That is, problems likely exist that an NTM could efficiently solve that a quantum computer cannot. A likely example of problems solvable by NTMs but not by quantum computers in polynomial time are NP-complete problems.

</doc>
<doc id="21937" url="https://en.wikipedia.org/wiki?curid=21937" title="Nitrogen narcosis">
Nitrogen narcosis

Narcosis while diving (also known as nitrogen narcosis, inert gas narcosis, raptures of the deep, Martini effect), is a reversible alteration in consciousness that occurs while diving at depth. It is caused by the anesthetic effect of certain gases at high pressure. The Greek word "ναρκωσις" (narcosis) is derived from "narke", "temporary decline or loss of senses and movement, numbness", a term used by Homer and Hippocrates. Narcosis produces a state similar to drunkenness (alcohol intoxication), or nitrous oxide inhalation. It can occur during shallow dives, but does not usually become noticeable at depths less than .
Except for helium and probably neon, all gases that can be breathed have a narcotic effect, although widely varying in degree. The effect is consistently greater for gases with a higher lipid solubility, and there is good evidence that the two properties are mechanistically related. As depth increases, the mental impairment may become hazardous. Divers can learn to cope with some of the effects of narcosis, but it is impossible to develop a tolerance. Narcosis affects all divers, although susceptibility varies widely from dive to dive, and between individuals.
Narcosis may be completely reversed in a few minutes by ascending to a shallower depth, with no long-term effects. Thus narcosis while diving in open water rarely develops into a serious problem as long as the divers are aware of its symptoms, and are able to ascend to manage it. Diving beyond is generally considered outside the scope of recreational diving. Below these depths, as narcosis and oxygen toxicity become critical risk factors, specialist training is required in the use of various helium-containing gas mixtures such as trimix or heliox. These mixtures prevent narcosis by replacing some of the breathing gas with non-narcotic helium.
Classification.
Narcosis results from breathing gases under elevated pressure, and may be classified by the principal gas involved. The noble gases, except helium and probably neon, as well as nitrogen, oxygen and hydrogen cause a decrement in mental function, but their effect on psychomotor function (processes affecting the coordination of sensory or cognitive processes and motor activity) varies widely. The effects of carbon dioxide consistently result in a diminution of mental and psychomotor function. The noble gases argon, krypton, and xenon are more narcotic than nitrogen at a given pressure, and xenon has so much anesthetic activity that it is a usable anesthetic at 80% concentration and normal atmospheric pressure. Xenon has historically been too expensive to be used very much in practice, but it has been successfully used for surgical operations, and xenon anesthesia systems are still being proposed and designed.
Signs and symptoms.
Due to its perception-altering effects, the onset of narcosis may be hard to recognize. At its most benign, narcosis results in relief of anxiety – a feeling of tranquility and mastery of the environment. These effects are essentially identical to various concentrations of nitrous oxide. They also resemble (though not as closely) the effects of alcohol or marijuana and the familiar benzodiazepine drugs such as diazepam and alprazolam. Such effects are not harmful unless they cause some immediate danger to go unrecognized and unaddressed. Once stabilized, the effects generally remain the same at a given depth, only worsening if the diver ventures deeper.
The most dangerous aspects of narcosis are the impairment of judgement, multi-tasking and coordination, and the loss of decision-making ability and focus. Other effects include vertigo and visual or auditory disturbances. The syndrome may cause exhilaration, giddiness, extreme anxiety, depression, or paranoia, depending on the individual diver and the diver's medical or personal history. When more serious, the diver may feel overconfident, disregarding normal safe diving practices.
The relation of depth to narcosis is sometimes informally known as "Martini's law", the idea that narcosis results in the feeling of one martini for every below depth. Professional divers use such a calculation only as a rough guide to give new divers a metaphor, comparing a situation they may be more familiar with.
Reported signs and symptoms are summarized against typical depths in meters and feet of sea water in the following table:
Causes.
The cause of narcosis is related to the increased solubility of gases in body tissues, as a result of the elevated pressures at depth (Henry's law). Modern theories have suggested that inert gases dissolving in the lipid bilayer of cell membranes cause narcosis. More recently, researchers have been looking at neurotransmitter receptor protein mechanisms as a possible cause of narcosis. The breathing gas mix entering the diver's lungs will have the same pressure as the surrounding water, known as the ambient pressure. After any change of depth, the pressure of gases in the blood passing through the brain catches up with ambient pressure within a minute or two, which results in a delayed narcotic effect after descending to a new depth. Rapid compression potentiates narcosis owing to carbon dioxide retention.
A divers' cognition may be affected on dives as shallow as , but the changes are not usually noticeable. There is no reliable method to predict the depth at which narcosis becomes noticeable, or the severity of the effect on an individual diver, as it may vary from dive to dive even on the same day.
Significant impairment due to narcosis is an increasing risk below depths of about , corresponding to an ambient pressure of about . Most sport scuba training organizations recommend depths of no more than because of the risk of narcosis. When breathing air at depths of  – an ambient pressure of about  – narcosis in most divers leads to hallucinations, loss of memory, and unconsciousness. A number of divers have died in attempts to set air depth records below . Because of these incidents, "Guinness World Records" no longer reports on this figure.
Narcosis has been compared with altitude sickness insofar as its variability (though not its symptoms); its effects depend on many factors, with variations between individuals. Thermal cold, stress, heavy work, fatigue, and carbon dioxide retention all increase the risk and severity of narcosis. Carbon dioxide has a high narcotic potential and also causes increased blood flow to the brain, increasing the effects of other gases. Increased risk of narcosis results from increasing the amount of carbon dioxide retained through heavy exercise, shallow or skip breathing, or because of poor gas exchange in the lungs.
Narcosis is known to be additive to even minimal alcohol intoxication, and also to the effects of other drugs such as marijuana (which is more likely than alcohol to have effects that last into a day of abstinence from use). Other sedative and analgesic drugs, such as opiate narcotics and benzodiazepines, add to narcosis.
Mechanism.
The precise mechanism is not well understood, but it appears to be the direct effect of gas dissolving into nerve membranes and causing temporary disruption in nerve transmissions. While the effect was first observed with air, other gases including argon, krypton and hydrogen cause very similar effects at higher than atmospheric pressure. Some of these effects may be due to antagonism at NMDA receptors and potentiation of GABAA receptors, similar to the mechanism of nonpolar anesthetics such diethyl ether or ethylene. However, their reproduction by the very chemically inactive gas argon makes them unlikely to be a strictly chemical bonding to receptors in the usual sense of a chemical bond. An indirect physical effect – such as a change in membrane volume – would therefore be needed to affect the ligand-gated ion channels of nerve cells. Trudell "et al." have suggested non-chemical binding due to the attractive van der Waals force between proteins and inert gases.
Similar to the mechanism of ethanol's effect, the increase of gas dissolved in nerve cell membranes may cause altered ion permeability properties of the neural cells' lipid bilayers. The partial pressure of a gas required to cause a measured degree of impairment correlates well with the lipid solubility of the gas: the greater the solubility, the less partial pressure is needed.
An early theory, the Meyer-Overton hypothesis, suggested that narcosis happens when the gas penetrates the lipids of the brain's nerve cells, causing direct mechanical interference with the transmission of signals from one nerve cell to another. More recently, specific types of chemically gated receptors in nerve cells have been identified as being involved with anesthesia and narcosis. However, the basic and most general underlying idea, that nerve transmission is altered in many diffuse areas of the brain as a result of gas molecules dissolved in the nerve cells' fatty membranes, remains largely unchallenged.
Management and diagnosis.
The management of narcosis is simply to ascend to shallower depths; the effects then disappear within minutes. In the event of complications or other conditions being present, ascending is always the correct initial response. Should problems remain, then it is necessary to abort the dive. The decompression schedule can still be followed unless other conditions require emergency assistance.
The symptoms of narcosis may be caused by other factors during a dive: ear problems causing disorientation or nausea; early signs of oxygen toxicity causing visual disturbances; or hypothermia causing rapid breathing and shivering. Nevertheless, the presence of any of these symptoms should imply narcosis. Alleviation of the effects upon ascending to a shallower depth will confirm the diagnosis. Given the setting, other likely conditions do not produce reversible effects. In the rare event of misdiagnosis when another condition is causing the symptoms, the initial management – ascending closer to the surface – is still essential.
Prevention.
The most straightforward way to avoid nitrogen narcosis is for a diver to limit the depth of dives. Since narcosis becomes more severe as depth increases, a diver keeping to shallower depths can avoid serious narcosis. Most recreational dive schools will only certify basic divers to depths of , and at these depths narcosis does not present a significant risk. Further training is normally required for certification up to on air, and this training should include a discussion of narcosis, its effects, and cure. Some diver training agencies offer specialized training to prepare recreational divers to go to depths of , often consisting of further theory and some practice in deep dives under close supervision. Scuba organizations that train for diving beyond recreational depths, may forbid diving with gases that cause too much narcosis at depth in the average diver, and strongly encourage the use of other breathing gas mixes containing helium in place of some or all of the nitrogen in air – such as trimix and heliox – because helium has no narcotic potential. The use of these gases forms part of technical diving and requires further training and certification.
While the individual diver cannot predict exactly at what depth the onset of narcosis will occur on a given day, the first symptoms of narcosis for any given diver are often more predictable and personal. For example, one diver may have trouble with eye focus (close accommodation for middle-aged divers), another may experience feelings of euphoria, and another feelings of claustrophobia. Some divers report that they have hearing changes, and that the sound their exhaled bubbles make becomes different. Specialist training may help divers to identify these personal onset signs, which may then be used as a signal to ascend to avoid the narcosis, although severe narcosis may interfere with the judgement necessary to take preventive action.
Deep dives should be made only after a gradual training to test the individual diver's sensitivity to increasing depths, with careful supervision and logging of reactions. Diving organizations such as Global Underwater Explorers (GUE) emphasize that such sessions are for the purpose of gaining experience in recognizing the onset symptoms of narcosis for an individual, which are somewhat more repeatable than for the average group of divers. Scientific evidence does not show that a diver can train to overcome any measure of narcosis at a given depth or become tolerant of it.
Equivalent narcotic depth (END) is a commonly used way of expressing the narcotic effect of different breathing gases. The National Oceanic and Atmospheric Administration (NOAA) Diving Manual now states that oxygen and nitrogen should be considered equally narcotic. Standard tables, based on relative lipid solubilities, list conversion factors for narcotic effect of other gases. For example, hydrogen at a given pressure has a narcotic effect equivalent to nitrogen at 0.55 times that pressure, so in principle it should be usable at more than twice the depth. Argon, however, has 2.33 times the narcotic effect of nitrogen, and is a poor choice as a breathing gas for diving (it is used as a drysuit inflation gas, owing to its low thermal conductivity). Some gases have other dangerous effects when breathed at pressure; for example, high-pressure oxygen can lead to oxygen toxicity. Although helium is the least intoxicating of the breathing gases, at greater depths it can cause high pressure nervous syndrome, a still mysterious but apparently unrelated phenomenon. Inert gas narcosis is only one factor influencing the choice of gas mixture; the risks of decompression sickness and oxygen toxicity, cost, and other factors are also important.
Because of similar and additive effects, divers should avoid sedating medications and drugs, such as marijuana and alcohol before any dive. A hangover, combined with the reduced physical capacity that goes with it, makes nitrogen narcosis more likely. Experts recommend total abstinence from alcohol for at least 12 hours before diving, and longer for other drugs. Abstinence time needed for marijuana is unknown, but owing to the much longer half-life of the active agent of this drug in the body, it is likely to be longer than for alcohol.
Prognosis and epidemiology.
Narcosis is potentially one of the most dangerous conditions to affect the scuba diver below about . Except for occasional amnesia of events at depth, the effects of narcosis are entirely removed on ascent and therefore pose no problem in themselves, even for repeated, chronic or acute exposure. Nevertheless, the severity of narcosis is unpredictable and it can be fatal while diving, as the result of illogical behavior in a dangerous environment.
Tests have shown that all divers are affected by nitrogen narcosis, though some experience lesser effects than others. Even though it is possible that some divers can manage better than others because of learning to cope with the subjective impairment, the underlying behavioral effects remain. These effects are particularly dangerous because a diver may feel they are not experiencing narcosis, yet still be affected by it.
History.
French researcher Victor T. Junod was the first to describe symptoms of narcosis in 1834, noting "the functions of the brain are activated, imagination is lively, thoughts have a peculiar charm and, in some persons, symptoms of intoxication are present." Junod suggested that narcosis resulted from pressure causing increased blood flow and hence stimulating nerve centers. Walter Moxon (1836–1886), a prominent Victorian physician, hypothesized in 1881 that pressure forced blood to inaccessible parts of the body and the stagnant blood then resulted in emotional changes. The first report of anesthetic potency being related to lipid solubility was published by Hans H. Meyer in 1899, entitled "Zur Theorie der Alkoholnarkose". Two years later a similar theory was published independently by Charles Ernest Overton. What became known as the Meyer-Overton Hypothesis may be illustrated by a graph comparing narcotic potency with solubility in oil.
In 1939, Albert R. Behnke and O. D. Yarborough demonstrated that gases other than nitrogen also could cause narcosis. For an inert gas the narcotic potency was found to be proportional to its lipid solubility. As hydrogen has only 0.55 the solubility of nitrogen, deep diving experiments using hydrox were conducted by Arne Zetterström between 1943 and 1945. Jacques-Yves Cousteau in 1953 famously described it as "l’ivresse des grandes profondeurs" or the "rapture of the deep".
Further research into the possible mechanisms of narcosis by anesthetic action led to the "minimum alveolar concentration" concept in 1965. This measures the relative concentration of different gases required to prevent motor response in 50% of subjects in response to stimulus, and shows similar results for anesthetic potency as the measurements of lipid solubility. The (NOAA) Diving Manual was revised to recommend treating oxygen as if it were as narcotic as nitrogen, following research by Christian J. Lambertsen "et al." in 1977 and 1978.

</doc>
<doc id="21938" url="https://en.wikipedia.org/wiki?curid=21938" title="Neoproterozoic">
Neoproterozoic

The Neoproterozoic Era is the unit of geologic time from .
It is the last era of the Proterozoic Eon and Precambrian Supereon; it is subdivided into the Tonian, Cryogenian, and Ediacaran Periods. It is preceded by the Mesoproterozoic era and succeeded by the Paleozoic era.
The most severe glaciation known in the geologic record occurred during the Cryogenian, when ice sheets reached the equator and formed a possible "Snowball Earth".
The earliest fossils of multicellular life are found in the Ediacaran, including the earliest animals.
According to Rino and co-workers, the sum of the continental crust formed in the Pan-African orogeny and the Grenville orogeny makes the Neoproterozoic the period of Earth's history that has produced most continental crust.
Geology.
At the onset of the Neoproterozoic the supercontinent Rodinia, which had assembled during the late Mesoproterozoic, straddled the equator. During the Tonian, rifting commenced which broke Rodinia into a number of individual land masses.
Possibly as a consequence of the low-latitude position of most continents, several large-scale glacial events occurred during the Neoproterozoic Era including the Sturtian and Marinoan glaciations of the Cryogenian.
These glaciations are believed to have been so severe that there were ice sheets at the equator—a state known as the "Snowball Earth".
Subdivisions.
Russian geologists divide the Neoproterozoic of Siberia into the Baikalian from 850 to 650 Ma (loosely equivalent to the Cryogenian), which follows the Mayanian, from 1000 to 850 Ma, then the Aimchanian.
Paleobiology.
The idea of the Neoproterozoic Era was introduced in the 1960s. Nineteenth-century paleontologists set the start of multicelled life at the first appearance of hard-shelled animals called trilobites and archeocyathid sponges. This set the beginning of the Cambrian period. In the early 20th century, paleontologists started finding fossils of multicellular animals that predated the start of the Cambrian. A complex fauna was found in South West Africa in the 1920s but was inaccurately dated. Another fauna was found in South Australia in the 1940s but was not thoroughly examined until the late 1950s. Other possible early fossils were found in Russia, England, Canada, and elsewhere (see Ediacaran biota). Some were determined to be pseudofossils, but others were revealed to be members of rather complex biotas that are still poorly understood. At least 25 regions worldwide yielded metazoan fossils older than the classical Cambrian boundary.
A few of the early animals appear possibly to be ancestors of modern animals. Most fall into ambiguous groups of frond-like organisms; discoids that might be holdfasts for stalked organisms ("medusoids"); mattress-like forms; small calcareous tubes; and armored animals of unknown provenance.
These were most commonly known as Vendian biota until the formal naming of the Period, and are currently known as Ediacaran biota. Most were soft bodied. The relationships, if any, to modern forms are obscure. Some paleontologists relate many or most of these forms to modern animals. Others acknowledge a few possible or even likely relationships but feel that most of the Ediacaran forms are representatives of unknown animal types. 
In addition to Ediacaran biota, two other types of biota were discovered in China (the Doushantuo Formation and Hainan Formation).
Terminal period.
The nomenclature for the terminal period of the Neoproterozoic has been unstable. Russian and Nordic geologists referred to the last period of the Neoproterozoic as the Vendian, while Chinese geologists referred to it as the Sinian, and most Australians and North Americans used the name Ediacaran.
However, in 2004, the International Union of Geological Sciences ratified the Ediacaran age to be a geological age of the Neoproterozoic, ranging from to million years ago. The Ediacaran boundaries are the only Precambrian boundaries defined by biologic Global Boundary Stratotype Section and Points, rather than the absolute Global Standard Stratigraphic Ages.

</doc>
<doc id="21939" url="https://en.wikipedia.org/wiki?curid=21939" title="National Security Agency">
National Security Agency

The National Security Agency (NSA) is an intelligence organization of the United States government, responsible for global monitoring, collection, and processing of information and data for foreign intelligence and counterintelligence purposes – a discipline known as signals intelligence (SIGINT). NSA is concurrently charged with protection of U.S. government communications and information systems against penetration and network warfare. Although many of NSA's programs rely on "passive" electronic collection, the agency is authorized to accomplish its mission through active clandestine means, among which are physically bugging electronic systems and allegedly engaging in sabotage through subversive software. Moreover, NSA maintains physical presence in a large number of countries across the globe, where its Special Collection Service (SCS) inserts eavesdropping devices in difficult-to-reach places. SCS collection tactics allegedly encompass "close surveillance, burglary, wiretapping, breaking and entering".
Unlike the Defense Intelligence Agency (DIA) and the Central Intelligence Agency (CIA), both of which specialize primarily in foreign human espionage, NSA does not unilaterally conduct human-source intelligence gathering, despite often being portrayed so in popular culture. Instead, NSA is entrusted with assistance to and coordination of SIGINT elements at other government organizations, which are prevented by law from engaging in such activities without the approval of the NSA via the Defense Secretary. As part of these streamlining responsibilities, the agency has a co-located organization called the Central Security Service (CSS), which was created to facilitate cooperation between NSA and other U.S. military cryptanalysis components. Additionally, the NSA Director simultaneously serves as the Commander of the United States Cyber Command and as Chief of the Central Security Service.
Originating as a unit to decipher coded communications in World War II, it was officially formed as the NSA by Harry S. Truman in 1952. Since then, it has become one of the largest U.S. intelligence organizations in terms of personnel and budget, operating as part of the Department of Defense and simultaneously reporting to the Director of National Intelligence.
NSA surveillance has been a matter of political controversy on several occasions, such as its spying on anti-Vietnam war leaders or economic espionage. In 2013, the extent of some of the NSA's secret surveillance programs was revealed to the public by Edward Snowden. According to the leaked documents, the NSA intercepts the communications of over a billion people worldwide, many of whom are American citizens, and tracks the movement of hundreds of millions of people using cellphones. Internationally, research has pointed to the NSA's ability to surveil the domestic internet traffic of foreign countries through "boomerang routing".
History.
Army predecessor.
The origins of the National Security Agency can be traced back to April 28, 1917, three weeks after the U.S. Congress declared war on Germany in World War I. A code and cipher decryption unit was established as the Cable and Telegraph Section which was also known as the "Cipher Bureau and Military Intelligence Branch, Section 8" (MI-8). It was headquartered in Washington, D.C. and was part of the war effort under the executive branch without direct Congressional authorization. During the course of the war it was relocated in the army's organizational chart several times. On July 5, 1917, Herbert O. Yardley was assigned to head the unit. At that point, the unit consisted of Yardley and two civilian clerks. It absorbed the navy's cryptoanalysis functions in July 1918. World War I ended on November 11, 1918, and MI-8 moved to New York City on May 20, 1919, where it continued intelligence activities as the Code Compilation Company under the direction of Yardley.
Black Chamber.
MI-8 also operated the so-called "Black Chamber". The Black Chamber was located on East 37th Street in Manhattan. Its purpose was to crack the communications codes of foreign governments. Jointly supported by the State Department and the War Department, the chamber persuaded Western Union, the largest U.S. telegram company, to allow government officials to monitor private communications passing through the company's wires.
Other "Black Chambers" were also found in Europe. They were established by the French and British governments to read the letters of targeted individuals, employing a variety of techniques to surreptitiously open, copy, and reseal correspondence before forwarding it to unsuspecting recipients.
Despite the American Black Chamber's initial successes, it was shut down in 1929 by U.S. Secretary of State Henry L. Stimson, who defended his decision by stating: "Gentlemen do not read each other's mail".
World War II and its aftermath.
During World War II, the Signal Security Agency (SSA) was created to intercept and decipher the communications of the Axis powers. When the war ended, the SSA was reorganized as the Army Security Agency (ASA), and it was placed under the leadership of the Director of Military Intelligence.
On May 20, 1949, all cryptologic activities were centralized under a national organization called the Armed Forces Security Agency (AFSA). This organization was originally established within the U.S. Department of Defense under the command of the Joint Chiefs of Staff. The AFSA was tasked to direct Department of Defense communications and electronic intelligence activities, except those of U.S. military intelligence units. However, the AFSA was unable to centralize communications intelligence and failed to coordinate with civilian agencies that shared its interests such as the Department of State, Central Intelligence Agency (CIA) and the Federal Bureau of Investigation (FBI). In December 1951, President Harry S. Truman ordered a panel to investigate how AFSA had failed to achieve its goals. The results of the investigation led to improvements and its redesignation as the National Security Agency.
The agency was formally established by Truman in a memorandum of October 24, 1952, that revised National Security Council Intelligence Directive (NSCID) 9. Since President Truman's memo was a classified document, the existence of the NSA was not known to the public at that time. Due to its ultra-secrecy the U.S. intelligence community referred to the NSA as "No Such Agency".
Vietnam War.
In the 1960s, the NSA played a key role in expanding America's commitment to the Vietnam War by providing evidence of a North Vietnamese attack on the American destroyer during the Gulf of Tonkin incident.
A secret operation code-named "MINARET" was set up by the NSA to monitor the phone communications of Senators Frank Church and Howard Baker, as well as major civil rights leaders including Dr. Martin Luther King, and prominent U.S. journalists and athletes who criticized the Vietnam War. However the project turned out to be controversial, and an internal review by the NSA concluded that its Minaret program was "disreputable if not outright illegal."
Church Committee hearings.
In the aftermath of the Watergate Scandal, a congressional hearing in 1975 led by Sen. Frank Church revealed that the NSA, in collaboration with Britain's SIGINT intelligence agency Government Communications Headquarters (GCHQ), had routinely intercepted the international communications of prominent anti-Vietnam war leaders such as Jane Fonda and Dr. Benjamin Spock. Following the resignation of President Richard Nixon, there were several investigations of suspected misuse of FBI, CIA and NSA facilities. Senator Frank Church uncovered previously unknown activity, such as a CIA plot (ordered by the administration of President John F. Kennedy) to assassinate Fidel Castro. The investigation also uncovered NSA's wiretaps on targeted American citizens.
After the Church Committee hearings, the Foreign Intelligence Surveillance Act of 1978 was passed into law. This was designed to limit the practice of mass surveillance in the United States.
From 1980s to 1990s.
In 1986, the NSA intercepted the communications of the Libyan government during the immediate aftermath of the Berlin discotheque bombing. The White House asserted that the NSA interception had provided "irrefutable" evidence that Libya was behind the bombing, which U.S. President Ronald Reagan cited as a justification for the 1986 United States bombing of Libya.
In 1999, a multi-year investigation by the European Parliament highlighted the NSA's role in economic espionage in a report entitled 'Development of Surveillance Technology and Risk of Abuse of Economic Information'. That year, the NSA founded the NSA Hall of Honor, a memorial at the National Cryptologic Museum in Fort Meade, Maryland. The memorial is a, "tribute to the pioneers and heroes who have made significant and long-lasting contributions to American cryptology". NSA employees must be retired for more than fifteen years to qualify for the memorial.
NSA's infrastructure deteriorated in the 1990s as defense budget cuts resulted in maintenance deferrals. On January 24, 2000, NSA headquarters suffered a total network outage for three days caused by an overloaded network. Incoming traffic was successfully stored on agency servers, but it could not be directed and processed. The agency carried out emergency repairs at a cost of $3 million to get the system running again. (Some incoming traffic was also directed instead to Britain's GCHQ for the time being.) Director Michael Hayden called the outage a "wake-up call" for the need to invest in the agency's infrastructure.
War on Terror.
In the aftermath of the September 11 attacks, the NSA created new IT systems to deal with the flood of information from new technologies like the internet and cellphones. ThinThread contained advanced data mining capabilities. It also had a 'privacy mechanism'; surveillance was stored encrypted; decryption required a warrant. The research done under this program may have contributed to the technology used in later systems. ThinThread was cancelled when Michael Hayden chose Trailblazer, which did not include ThinThread's privacy system.
Trailblazer Project ramped up in 2002. SAIC, Boeing, CSC, IBM, and Litton worked on it. Some NSA whistleblowers complained internally about major problems surrounding Trailblazer. This led to investigations by Congress and the NSA and DoD Inspectors General. The project was cancelled in early 2004; it was late, over budget, and didn't do what it was supposed to do. The Baltimore Sun ran articles about this in 2006–07. The government then raided the whistleblowers' houses. One of them, Thomas Drake, was charged with violating in 2010 in an unusual use of espionage law. He and his defenders claim that he was actually being persecuted for challenging the Trailblazer Project. In 2011, all 10 original charges against Drake were dropped.
Turbulence started in 2005. It was developed in small, inexpensive 'test' pieces rather than one grand plan like Trailblazer. It also included offensive cyber-warfare capabilities, like injecting malware into remote computers. Congress criticized Turbulence in 2007 for having similar bureaucratic problems as Trailblazer. It was to be a realization of information processing at higher speeds in cyberspace.
Global surveillance disclosures.
The massive extent of the NSA's spying, both foreign and domestic, was revealed to the public in a series of detailed disclosures of internal NSA documents beginning in June 2013. Most of the disclosures were leaked by former NSA contractor, Edward Snowden.
Scope of surveillance.
It was revealed that the NSA intercepts telephone and internet communications of over a billion people worldwide, seeking information on terrorism as well as foreign politics, economics and "commercial secrets". In a declassified document it was revealed that 17,835 phone lines were on an improperly permitted "alert list" from 2006 to 2009 in breach of compliance, which tagged these phone lines for daily monitoring. Eleven percent of these monitored phone lines met the agency's legal standard for "reasonably articulable suspicion" (RAS).
A dedicated unit of the NSA locates targets for the CIA for extrajudicial assassination in the Middle East. The NSA has also spied extensively on the European Union, the United Nations and numerous governments including allies and trading partners in Europe, South America and Asia.
The NSA tracks the locations of hundreds of millions of cellphones per day, allowing them to map people's movements and relationships in detail. It reportedly has access to all communications made via Google, Microsoft, Facebook, Yahoo, YouTube, AOL, Skype, Apple and Paltalk, and collects hundreds of millions of contact lists from personal email and instant messaging accounts each year. It has also managed to weaken much of the encryption used on the Internet (by collaborating with, coercing or otherwise infiltrating numerous technology companies), so that the majority of Internet privacy is now vulnerable to the NSA and other attackers.
Domestically, the NSA collects and stores metadata records of phone calls, including over 120 million US Verizon subscribers, as well as internet communications, relying on a secret interpretation of the Patriot Act whereby the entirety of US communications may be considered "relevant" to a terrorism investigation if it is expected that even a tiny minority may relate to terrorism. The NSA supplies foreign intercepts to the DEA, IRS and other law enforcement agencies, who use these to initiate criminal investigations. Federal agents are then instructed to "recreate" the investigative trail via parallel construction.
The NSA also spies on influential Muslims to obtain information that could be used to discredit them, such as their use of pornography. The targets, both domestic and abroad, are not suspected of any crime but hold religious or political views deemed "radical" by the NSA.
According to a report in "The Washington Post" in July 2014, relying on information provided by Snowden, 90% of those placed under surveillance in the U.S. are ordinary Americans, and are not the intended targets. The newspaper said it had examined documents including emails, text messages, and online accounts that support the claim.
Legal accountability.
Despite President Obama's claims that these programs have congressional oversight, members of Congress were unaware of the existence of these NSA programs or the secret interpretation of the Patriot Act, and have consistently been denied access to basic information about them. Obama has also claimed that there are legal checks in place to prevent inappropriate access of data and that there have been no examples of abuse; however, the secret FISC court charged with regulating the NSA's activities is, according to its chief judge, incapable of investigating or verifying how often the NSA breaks even its own secret rules.
It has since been reported that the NSA violated its own rules on data access thousands of times a year, many of these violations involving large-scale data interceptions; and that NSA officers have even used data intercepts to spy on love interests. The NSA has "generally disregarded the special rules for disseminating United States person information" by illegally sharing its intercepts with other law enforcement agencies. A March 2009 opinion of the FISC court, released by court order, states that protocols restricting data queries had been "so frequently and systemically violated that it can be fairly said that this critical element of the overall ... regime has never functioned effectively." In 2011 the same court noted that the "volume and nature" of the NSA's bulk foreign internet intercepts was "fundamentally different from what the court had been led to believe". Email contact lists (including those of US citizens) are collected at numerous foreign locations to work around the illegality of doing so on US soil.
Legal opinions on the NSA's bulk collection program have differed. In mid-December 2013, U.S. District Court Judge Richard Leon ruled that the "almost-Orwellian" program likely violates the Constitution, and wrote, "I cannot imagine a more 'indiscriminate' and 'arbitrary invasion' than this systematic and high-tech collection and retention of personal data on virtually every single citizen for purposes of querying and analyzing it without prior judicial approval. Surely, such a program infringes on 'that degree of privacy' that the Founders enshrined in the Fourth Amendment. Indeed, I have little doubt that the author of our Constitution, James Madison, who cautioned us to beware 'the abridgement of freedom of the people by gradual and silent encroachments by those in power,' would be aghast."
Later that month, U.S. District Judge William Pauley ruled that the NSA's collection of telephone records is legal and valuable in the fight against terrorism. In his opinion, he wrote, "a bulk telephony metadata collection program a wide net that could find and isolate gossamer contacts among suspected terrorists in an ocean of seemingly disconnected data" and noted that a similar collection of data prior to 9/11 might have prevented the attack.
An October 2014 United Nations report condemned mass surveillance by the United States and other countries as violating multiple international treaties and conventions that guarantee core privacy rights.
Official responses.
On March 20, 2013 the Director of National Intelligence, Lieutenant General James Clapper, testified before Congress that the NSA does not wittingly collect any kind of data on millions or hundreds of millions of Americans, but he retracted this in June after details of the PRISM program were published, and stated instead that meta-data of phone and internet traffic are collected, but no actual message contents. This was corroborated by the NSA Director, General Keith Alexander, before it was revealed that the XKeyscore program collects the contents of millions of emails from US citizens without warrant, as well as "nearly everything a user does on the Internet". Alexander later admitted that "content" is collected, but stated that it is simply stored and never analyzed or searched unless there is "a nexus to al-Qaida or other terrorist groups".
Regarding the necessity of these NSA programs, Alexander stated on June 27 that the NSA's bulk phone and Internet intercepts had been instrumental in preventing 54 terrorist "events", including 13 in the US, and in all but one of these cases had provided the initial tip to "unravel the threat stream". On July 31 NSA Deputy Director John Inglis conceded to the Senate that these intercepts had not been vital in stopping any terrorist attacks, but were "close" to vital in identifying and convicting four San Diego men for sending US$8,930 to Al-Shabaab, a militia that conducts terrorism in Somalia.
The U.S. government has aggressively sought to dismiss and challenge Fourth Amendment cases raised against it, and has granted retroactive immunity to ISPs and telecoms participating in domestic surveillance.
The U.S. military has acknowledged blocking access to parts of "The Guardian" website for thousands of defense personnel across the country, and blocking the entire "Guardian" website for personnel stationed throughout Afghanistan, the Middle East, and South Asia.
Organizational structure.
The NSA is led by the Director of the National Security Agency (DIRNSA), who also serves as Chief of the Central Security Service (CHCSS) and Commander of the United States Cyber Command (USCYBERCOM) and is the highest-ranking military official of these organizations. He is assisted by a Deputy Director, who is the highest-ranking civilian within the NSA/CSS.
NSA also has an Inspector General, head of the Office of the Inspector General (OIG), a General Counsel, head of the Office of the General Counsel (OGC) and a Director of Compliance, who is head of the Office of the Director of Compliance (ODOC).
Unlike other intelligence organizations such as CIA or DIA, NSA has always been particularly reticent concerning its internal organizational structure.
As of the mid-1990s, the National Security Agency was organized into five Directorates:
Each of these directorates consisted of several groups or elements, designated by a letter. There were for example the A Group, which was responsible for all SIGINT operations against the Soviet Union and Eastern Europe, and G Group, which was responsible for SIGINT related to all non-communist countries. These groups were divided in units designated by an additional number, like unit A5 for breaking Soviet codes, and G6, being the office for the Middle East, North Africa, Cuba, Central and South America.
Structure.
, NSA has about a dozen directorates, which are designated by a letter, although not all of them are publicly known. The directorates are divided in divisions and units starting with the letter of the parent directorate, followed by a number for the division, the sub-unit or a sub-sub-unit.
The main elements of the organizational structure of the NSA are:
In the year 2000, a leadership team was formed, consisting of the Director, the Deputy Director and the Directors of the Signals Intelligence (SID), the Information Assurance (IAD) and the Technical Directorate (TD). The chiefs of other main NSA divisions became associate directors of the senior leadership team.
After president George W. Bush initiated the President's Surveillance Program (PSP) in 2001, the NSA created a 24-hour Metadata Analysis Center (MAC), followed in 2004 by the Advanced Analysis Division (AAD), with the mission of analyzing content, internet metadata and telephone metadata. Both units were part of the Signals Intelligence Directorate.
A 2016 proposal would combine the Signals Intelligence Directorate with the Information Assurance Directorate into a Directorate of Operations.
Watch centers.
The NSA maintains at least two watch centers:
Employees.
The number of NSA employees is officially classified but there are several sources providing estimates.
In 1961, NSA had 59,000 military and civilian employees, which grew to 93,067 in 1969, of which 19,300 worked at the headquarters at Fort Meade. In the early 1980s NSA had roughly 50,000 military and civilian personnel. By 1989 this number had grown again to 75,000, of which 25,000 worked at the NSA headquarters. Between 1990 and 1995 the NSA's budget and workforce were cut by one third, which led to a substantial loss of experience.
In 2012, the NSA said more than 30,000 employees worked at Ft. Meade and other facilities. In 2012, John C. Inglis, the deputy director, said that the total number of NSA employees is "somewhere between 37,000 and one billion" as a joke, and stated that the agency is "probably the biggest employer of introverts." In 2013 "Der Spiegel" stated that the NSA had 40,000 employees. More widely, it has been described as the world's largest single employer of mathematicians. Some NSA employees form part of the workforce of the National Reconnaissance Office (NRO), the agency that provides the NSA with satellite signals intelligence.
As of 2013 about 1,000 system administrators work for the NSA.
Security issues.
The NSA received criticism early on in 1960 after two agents had defected to the Soviet Union. Investigations by the House Un-American Activities Committee and a special subcommittee of the House Armed Services Committee revealed severe cases of ignorance in personnel security regulations, prompting the former personnel director and the director of security to step down and leading to the adoption of stricter security practices. Nonetheless, security breaches reoccurred only a year later when in an issue of "Izvestia" of July 23, 1963, a former NSA employee published several cryptologic secrets.
The very same day, an NSA clerk-messenger committed suicide as ongoing investigations disclosed that he had sold secret information to the Soviets on a regular basis. The reluctance of Congressional houses to look into these affairs had prompted a journalist to write "If a similar series of tragic blunders occurred in any ordinary agency of Government an aroused public would insist that those responsible be officially censured, demoted, or fired." David Kahn criticized the NSA's tactics of concealing its doings as smug and the Congress' blind faith in the agency's right-doing as shortsighted, and pointed out the necessity of surveillance by the Congress to prevent abuse of power.
Edward Snowden's leaking of PRISM in 2013 caused the NSA to institute a "two-man rule" where two system administrators are required to be present when one accesses certain sensitive information. Snowden claims he suggested such a rule in 2009.
Polygraphing.
The NSA conducts polygraph tests of employees. For new employees, the tests are meant to discover enemy spies who are applying to the NSA and to uncover any information that could make an applicant pliant to coercion. As part of the latter, historically "EPQs" or "embarrassing personal questions" about sexual behavior had been included in the NSA polygraph. The NSA also conducts five-year periodic reinvestigation polygraphs of employees, focusing on counterintelligence programs. In addition the NSA conducts aperiodic polygraph investigations in order to find spies and leakers; those who refuse to take them may receive "termination of employment", according to a 1982 memorandum from the director of the NSA.
There are also "special access examination" polygraphs for employees who wish to work in highly sensitive areas, and those polygraphs cover counterintelligence questions and some questions about behavior. NSA's brochure states that the average test length is between two and four hours. A 1983 report of the Office of Technology Assessment stated that "It appears that the NSA Security Agency (and possibly CIA) use the polygraph not to determine deception or truthfulness per se, but as a technique of interrogation to encourage admissions." Sometimes applicants in the polygraph process confess to committing felonies such as murder, rape, and selling of illegal drugs. Between 1974 and 1979, of the 20,511 job applicants who took polygraph tests, 695 (3.4%) confessed to previous felony crimes; almost all of those crimes had been undetected.
In 2010 the NSA produced a video explaining its polygraph process. The video, ten minutes long, is titled "The Truth About the Polygraph" and was posted to the website of the Defense Security Service. Jeff Stein of "The Washington Post" said that the video portrays "various applicants, or actors playing them – it's not clear – describing everything bad they had heard about the test, the implication being that none of it is true." AntiPolygraph.org argues that the NSA-produced video omits some information about the polygraph process; it produced a video responding to the NSA video. George Maschke, the founder of the website, accused the NSA polygraph video of being "Orwellian".
After Edward Snowden revealed his identity in 2013, the NSA began requiring polygraphing of employees once per quarter.
Arbitrary firing.
The number of exemptions from legal requirements has been criticized. When in 1964 the Congress was hearing a bill giving the director of the NSA the power to fire at will any employee, the "Washington Post" wrote: "This is the very definition of arbitrariness. It means that an employee could be discharged and disgraced on the basis of anonymous allegations without the slightest opportunity to defend himself." Yet, the bill was accepted by an overwhelming majority.
Insignia and memorials.
The heraldic insignia of NSA consists of an eagle inside a circle, grasping a key in its talons. The eagle represents the agency's national mission. Its breast features a shield with bands of red and white, taken from the Great Seal of the United States and representing Congress. The key is taken from the emblem of Saint Peter and represents security.
When the NSA was created, the agency had no emblem and used that of the Department of Defense. The agency adopted its first of two emblems in 1963. The current NSA insignia has been in use since 1965, when then-Director, LTG Marshall S. Carter (USA) ordered the creation of a device to represent the agency.
The NSA's flag consists of the agency's seal on a light blue background.
Crews associated with NSA missions have been involved in a number of dangerous and deadly situations. The USS "Liberty" incident in 1967 and USS "Pueblo" incident in 1968 are examples of the losses endured during the Cold War.
The National Security Agency/Central Security Service Cryptologic Memorial honors and remembers the fallen personnel, both military and civilian, of these intelligence missions. It is made of black granite, and has 171 names carved into it, . It is located at NSA headquarters. A tradition of declassifying the stories of the fallen was begun in 2001.
NSANet (NSA's intranet).
NSANet stands for National Security Agency Network and is the official NSA intranet. It is a classified network, for information up to the level of TS/SCI to support the use and sharing of intelligence data between NSA and the signals intelligence agencies of the four other nations of the Five Eyes partnership. The management of NSANet has been delegated to the Central Security Service Texas (CSSTEXAS).
NSANet is a highly secured computer network consisting of fiber-optic and satellite communication channels which are almost completely separated from the public internet. The network allows NSA personnel and civilian and military intelligence analysts anywhere in the world to have access to the agency's systems and databases. This access is tightly controlled and monitored. For example, every keystroke is logged, activities are audited at random and downloading and printing of documents from NSANet are recorded.
In 1998, NSANet, along with NIPRNET and SIPRNET, had "significant problems with poor search capabilities, unorganized data and old information". In 2004, the network was reported to have used over twenty commercial off-the-shelf operating systems. Some universities that do highly sensitive research are allowed to connect to it.
The thousands of Top Secret internal NSA documents that were taken by Edward Snowden in 2013 were stored in "a file-sharing location on the NSA's intranet site" so they could easily be read online by NSA personnel. Everyone with a TS/SCI-clearance had access to these documents and as a system administrator, Snowden was responsible for moving accidentally misplaced highly sensitive documents to more secure storage locations.
National Computer Security Center.
The DoD Computer Security Center was founded in 1981 and renamed the National Computer Security Center (NCSC) in 1985. NCSC was responsible for computer security throughout the federal government. NCSC was part of NSA, and during the late 1980s and the 1990s, NSA and NCSC published Trusted Computer System Evaluation Criteria in a six-foot high Rainbow Series of books that detailed trusted computing and network platform specifications. The Rainbow books were replaced by the Common Criteria, however, in the early 2000s.
On July 18, 2013, Greenwald said that Snowden held "detailed blueprints of how the NSA does what they do", thereby sparking fresh controversy.
Facilities.
Headquarters.
Headquarters for the National Security Agency is located at in Fort George G. Meade, Maryland, although it is separate from other compounds and agencies that are based within this same military installation. Ft. Meade is about southwest of Baltimore, and northeast of Washington, DC. The NSA has its own exit off Maryland Route 295 South labeled "NSA Employees Only". The exit may only be used by people with the proper clearances, and security vehicles parked along the road guard the entrance.
NSA is the largest employer in the U.S. state of Maryland, and two-thirds of its personnel work at Ft. Meade. Built on of Ft. Meade's , the site has 1,300 buildings and an estimated 18,000 parking spaces.
The main NSA headquarters and operations building is what James Bamford, author of "Body of Secrets", describes as "a modern boxy structure" that appears similar to "any stylish office building." The building is covered with one-way dark glass, which is lined with copper shielding in order to prevent espionage by trapping in signals and sounds. It contains , or more than , of floor space; Bamford said that the U.S. Capitol "could easily fit inside it four times over."
The facility has over 100 watchposts, one of them being the visitor control center, a two-story area that serves as the entrance. At the entrance, a white pentagonal structure, visitor badges are issued to visitors and security clearances of employees are checked. The visitor center includes a painting of the NSA seal.
The OPS2A building, the tallest building in the NSA complex and the location of much of the agency's operations directorate, is accessible from the visitor center. Bamford described it as a "dark glass Rubik's Cube". The facility's "red corridor" houses non-security operations such as concessions and the drug store. The name refers to the "red badge" which is worn by someone without a security clearance. The NSA headquarters includes a cafeteria, a credit union, ticket counters for airlines and entertainment, a barbershop, and a bank. NSA headquarters has its own post office, fire department, and police force.
The employees at the NSA headquarters reside in various places in the Baltimore-Washington area, including Annapolis, Baltimore, and Columbia in Maryland and the District of Columbia, including the Georgetown community.
Power consumption.
Following a major power outage in 2000, in 2003 and in follow-ups through 2007, "The Baltimore Sun" reported that the NSA was at risk of electrical overload because of insufficient internal electrical infrastructure at Fort Meade to support the amount of equipment being installed. This problem was apparently recognized in the 1990s but not made a priority, and "now the agency's ability to keep its operations going is threatened."
Baltimore Gas & Electric (BGE, now Constellation Energy) provided NSA with 65 to 75 megawatts at Ft. Meade in 2007, and expected that an increase of 10 to 15 megawatts would be needed later that year. In 2011, NSA at Ft. Meade was Maryland's largest consumer of power. In 2007, as BGE's largest customer, NSA bought as much electricity as Annapolis, the capital city of Maryland.
One estimate put the potential for power consumption by the new Utah Data Center at 40 million per year.
History of headquarters.
When the agency was established, its headquarters and cryptographic center were in the Naval Security Station in Washington, D.C.. The COMINT functions were located in Arlington Hall in Northern Virginia, which served as the headquarters of the U.S. Army's cryptographic operations. Because the Soviet Union had detonated a nuclear bomb and because the facilities were crowded, the federal government wanted to move several agencies, including the AFSA/NSA. A planning committee considered Fort Knox, but Fort Meade, Maryland, was ultimately chosen as NSA headquarters because it was far enough away from Washington, D.C. in case of a nuclear strike and was close enough so its employees would not have to move their families.
Construction of additional buildings began after the agency occupied buildings at Ft. Meade in the late 1950s, which they soon outgrew. In 1963 the new headquarters building, nine stories tall, opened. NSA workers referred to the building as the "Headquarters Building" and since the NSA management occupied the top floor, workers used "Ninth Floor" to refer to their leaders. COMSEC remained in Washington, D.C., until its new building was completed in 1968. In September 1986, the Operations 2A and 2B buildings, both copper-shielded to prevent eavesdropping, opened with a dedication by President Ronald Reagan. The four NSA buildings became known as the "Big Four." The NSA director moved to 2B when it opened.
Fort Meade shooting.
On March 30, 2015, shortly before 9 am, a stolen sports utility vehicle approached an NSA police vehicle blocking the road near the gate of Fort Meade, after it was told to leave the area. NSA officers fired on the SUV, killing the 27-year-old driver, Ricky Hall (a transgender person also known as Mya), and seriously injuring his 20-year-old male passenger. An NSA officer's arm was injured when Hall subsequently crashed into his vehicle.
The two, dressed in women's clothing after a night of partying at a motel with the man they'd stolen the SUV from that morning, "attempted to drive a vehicle into the National Security Agency portion of the installation without authorization", according to an NSA statement. FBI spokeswoman Amy Thoreson said the incident is not believed to be related to terrorism. In June 2015 the FBI closed its investigation into the incident and federal prosecutors have declined to bring charges against anyone involved.
An anonymous police official told "The Washington Post", "This was not a deliberate attempt to breach the security of NSA. This was not a planned attack." The two are believed to have made a wrong turn off the highway, while fleeing from the motel after stealing the vehicle. A small amount of cocaine was found in the SUV. A local CBS reporter initially said a gun was found, but her later revision does not. Dozens of journalists were corralled into a parking lot blocks away from the scene, and were barred from photographing the area.
Computing.
In 1995, "The Baltimore Sun" reported that the NSA is the owner of the single largest group of supercomputers.
NSA held a groundbreaking ceremony at Ft. Meade in May 2013 for its High Performance Computing Center 2, expected to open in 2016. Called Site M, the center has a 150 megawatt power substation, 14 administrative buildings and 10 parking garages. It cost 3.2 billion and covers . The center is and initially uses 60 megawatts of electricity.
Increments II and III are expected to be completed by 2030, and would quadruple the space, covering with 60 buildings and 40 parking garages. Defense contractors are also establishing or expanding cybersecurity facilities near the NSA and around the Washington metropolitan area.
Other U.S. facilities.
As of 2012, NSA collected intelligence from four geostationary satellites. Satellite receivers were at Roaring Creek Station in Catawissa, Pennsylvania and Salt Creek Station in Arbuckle, California. It operated ten to twenty taps on U.S. telecom switches. NSA had installations in several U.S. states and from them observed intercepts from Europe, the Middle East, North Africa, Latin America, and Asia.
NSA had facilities at Friendship Annex (FANX) in Linthicum, Maryland, which is a 20 to 25-minute drive from Ft. Meade; the Aerospace Data Facility at Buckley Air Force Base in Aurora outside Denver, Colorado; NSA Texas in the Texas Cryptology Center at Lackland Air Force Base in San Antonio, Texas; NSA Georgia at Fort Gordon in Augusta, Georgia; NSA Hawaii in Honolulu; the Multiprogram Research Facility in Oak Ridge, Tennessee, and elsewhere.
On January 6, 2011 a groundbreaking ceremony was held to begin construction on NSA's first Comprehensive National Cyber-security Initiative (CNCI) Data Center, known as the "Utah Data Center" for short. The $1.5B data center is being built at Camp Williams, Utah, located south of Salt Lake City, and will help support the agency's National Cyber-security Initiative. It is expected to be operational by September 2013.
In 2009, to protect its assets and to access more electricity, NSA sought to decentralize and expand its existing facilities in Ft. Meade and Menwith Hill, the latter expansion expected to be completed by 2015.
The "Yakima Herald-Republic" cited Bamford, saying that many of NSA's bases for its Echelon program were a legacy system, using outdated, 1990s technology. In 2004, NSA closed its operations at Bad Aibling Station (Field Station 81) in Bad Aibling, Germany. In 2012, NSA began to move some of its operations at Yakima Research Station, Yakima Training Center, in Washington state to Colorado, planning to leave Yakima closed. As of 2013, NSA also intended to close operations at Sugar Grove, West Virginia.
International stations.
Following the signing in 1946–1956 of the UKUSA Agreement between the United States, United Kingdom, Canada, Australia and New Zealand, who then cooperated on signals intelligence and ECHELON, NSA stations were built at GCHQ Bude in Morwenstow, United Kingdom; Geraldton, Pine Gap and Shoal Bay, Australia; Leitrim and Ottawa, Canada; Misawa, Japan; and Waihopai and Tangimoana, New Zealand.
NSA operates RAF Menwith Hill in North Yorkshire, United Kingdom, which was, according to BBC News in 2007, the largest electronic monitoring station in the world. Planned in 1954, and opened in 1960, the base covered in 1999.
The agency's European Cryptologic Center (ECC), with 240 employees in 2011, is headquartered at a US military compound in Griesheim, near Frankfurt in Germany. A 2011 NSA report indicates that the ECC is responsible for the "largest analysis and productivity in Europe" and focusses on various priorities, including Africa, Europe, the Middle East and counterterrorism operations.
In 2013, a new Consolidated Intelligence Center, also to be used by NSA, is being built at the headquarters of the United States Army Europe in Wiesbaden, Germany. NSA's partnership with Bundesnachrichtendienst (BND), the German foreign intelligence service, was confirmed by BND president Gerhard Schindler.
Thailand.
Thailand is a "3rd party partner" of the NSA along with nine other nations. These are non-English-speaking countries that have made security agreements for the exchange of SIGINT raw material and end product reports.
Thailand is the site of at least two US SIGINT collection stations. One is at the US Embassy in Bangkok, a joint NSA-CIA Special Collection Service (SCS) unit. It presumably eavesdrops on foreign embassies, governmental communications, and other targets of opportunity.
The second installation is a FORNSAT (foreign satellite interception) station in the Thai city of Khon Kaen. It is codenamed INDRA, but has also been referred to as LEMONWOOD. The station is approximately 40 ha (100 acres) in size and consists of a large 3,700–4,600 m2 (40,000–50,000 ft2) operations building on the west side of the ops compound and four radome-enclosed parabolic antennas. Possibly two of the radome-enclosed antennas are used for SATCOM intercept and two antennas used for relaying the intercepted material back to NSA. There is also a PUSHER-type circularly-disposed antenna array (CDAA) array just north of the ops compound.
NSA activated Khon Kaen in October 1979. Its mission was to eavesdrop on the radio traffic of Chinese army and air force units in southern China, especially in and around the city of Kunming in Yunnan Province. Back in the late 1970s the base consisted only of a small CDAA antenna array that was remote-controlled via satellite from the NSA listening post at Kunia, Hawaii, and a small force of civilian contractors from Bendix Field Engineering Corp. who job it was to keep the antenna array and satellite relay facilities up and running 24/7.
According to the papers of the late General William Odom, the INDRA facility was upgraded in 1986 with a new British-made PUSHER CDAA antenna as part of an overall upgrade of NSA and Thai SIGINT facilities whose objective was to spy on the neighboring communist nations of Vietnam, Laos, and Cambodia.
The base apparently fell into disrepair in the 1990s as China and Vietnam became more friendly towards the US, and by 2002 archived satellite imagery showed that the PUSHER CDAA antenna had been torn down, perhaps indicating that the base had been closed. At some point in the period since 9/11, the Khon Kaen base was reactivated and expanded to include a sizeable SATCOM intercept mission. It is likely that the NSA presence at Khon Kaen is relatively small, and that most of the work is done by civilian contractors.
Mission.
NSA's eavesdropping mission includes radio broadcasting, both from various organizations and individuals, the Internet, telephone calls, and other intercepted forms of communication. Its secure communications mission includes military, diplomatic, and all other sensitive, confidential or secret government communications.
According to the "Washington Post", "day, collection systems at the National Security Agency intercept and store 1.7 billion e-mails, phone calls and other types of communications. The NSA sorts a fraction of those into 70 separate databases."
Because of its listening task, NSA/CSS has been heavily involved in cryptanalytic research, continuing the work of predecessor agencies which had broken many World War II codes and ciphers (see, for instance, Purple, Venona project, and JN-25).
In 2004, NSA Central Security Service and the National Cyber Security Division of the Department of Homeland Security (DHS) agreed to expand NSA Centers of Academic Excellence in Information Assurance Education Program.
As part of the National Security Presidential Directive 54/Homeland Security Presidential Directive 23 (NSPD 54), signed on January 8, 2008 by President Bush, the NSA became the lead agency to monitor and protect all of the federal government's computer networks from cyber-terrorism.
Operations.
Operations by the National Security Agency can be divided in three types:
Collection overseas.
Echelon.
Echelon was created in the incubator of the Cold War. Today it is a legacy system, and several NSA stations are closing.
NSA/CSS, in combination with the equivalent agencies in the United Kingdom (Government Communications Headquarters), Canada (Communications Security Establishment), Australia (Defence Signals Directorate), and New Zealand (Government Communications Security Bureau), otherwise known as the UKUSA group, was reported to be in command of the operation of the so-called ECHELON system. Its capabilities were suspected to include the ability to monitor a large proportion of the world's transmitted civilian telephone, fax and data traffic.
During the early 1970s, the first of what became more than eight large satellite communications dishes were installed at Menwith Hill. Investigative journalist Duncan Campbell reported in 1988 on the ECHELON surveillance program, an extension of the UKUSA Agreement on global signals intelligence SIGINT, and detailed how the eavesdropping operations worked. In November 3, 1999 the BBC reported that they had confirmation from the Australian Government of the existence of a powerful "global spying network" code-named Echelon, that could "eavesdrop on every single phone call, fax or e-mail, anywhere on the planet" with Britain and the United States as the chief protagonists. They confirmed that Menwith Hill was "linked directly to the headquarters of the US National Security Agency (NSA) at Fort Meade in Maryland".
NSA's United States Signals Intelligence Directive 18 (USSID 18) strictly prohibited the interception or collection of information about "... U.S. persons, entities, corporations or organizations..." without explicit written legal permission from the United States Attorney General when the subject is located abroad, or the Foreign Intelligence Surveillance Court when within U.S. borders. Alleged Echelon-related activities, including its use for motives other than national security, including political and industrial espionage, received criticism from countries outside the UKUSA alliance.
Other SIGINT operations overseas.
The NSA is also involved in planning to blackmail people with "SEXINT", intelligence gained about a potential target's sexual activity and preferences. Those targeted had not committed any apparent crime nor were charged with one.
In order to support its facial recognition program, the NSA is intercepting "millions of images per day".
The Real Time Regional Gateway is a data collection program introduced in 2005 in Iraq by NSA during the Iraq War that consisted of gathering all electronic communication, storing it, then searching and otherwise analyzing it. It was effective in providing information about Iraqi insurgents who had eluded less comprehensive techniques. This "collect it all" strategy introduced by NSA director, Keith B. Alexander, is believed by Glenn Greenwald of "The Guardian" to be the model for the comprehensive world-wide mass archiving of communications which NSA is engaged in as of 2013.
BoundlessInformant.
Edward Snowden revealed in June 2013 that between February 8 and March 8, 2013, the NSA collected about 124.8 billion telephone data items and 97.1 billion computer data items throughout the world, as was displayed in charts from an internal NSA tool codenamed Boundless Informant. It was reported that some of these data reflected eavesdropping on citizens in countries like Germany, Spain and France.
BoundlessInformant employs big data databases, cloud computing technology, and Free and Open Source Software (FOSS) to analyze data collected worldwide by the NSA.
Bypassing encryption.
In 2013, reporters uncovered a secret memo that claims the NSA created and pushed for the adoption of the Dual_EC_DRBG encryption standard that contained built-in vulnerabilities in 2006 to the United States National Institute of Standards and Technology (NIST), and the International Organization for Standardization (aka ISO). This memo appears to give credence to previous speculation by cryptographers at Microsoft Research. Edward Snowden claims that the NSA often bypasses encryption altogether by lifting information before it is encrypted or after it is decrypted.
XKeyscore rules (as specified in a file xkeyscorerules100.txt, sourced by German TV stations NDR and WDR, who claim to have excerpts from its source code) reveal that the NSA tracks users of privacy-enhancing software tools, including Tor, the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) in Cambridge, Massachusetts, and readers of the "Linux Journal".
Domestic activity.
NSA's mission, as set forth in Executive Order 12333 in 1981, is to collect information that constitutes "foreign intelligence or counterintelligence" while "not" "acquiring information concerning the domestic activities of United States persons". NSA has declared that it relies on the FBI to collect information on foreign intelligence activities within the borders of the United States, while confining its own activities within the United States to the embassies and missions of foreign nations.
The appearance of a 'Domestic Surveillance Directorate' of the NSA was soon exposed as a hoax in 2013.
NSA's domestic surveillance activities are limited by the requirements imposed by the Fourth Amendment to the U.S. Constitution. The Foreign Intelligence Surveillance Court for example held in October 2011, citing multiple Supreme Court precedents, that the Fourth Amendment prohibitions against unreasonable searches and seizures applies to the contents of all communications, whatever the means, because "a person's private communications are akin to personal papers." However, these protections do not apply to non-U.S. persons located outside of U.S. borders, so the NSA's foreign surveillance efforts are subject to far fewer limitations under U.S. law. The specific requirements for domestic surveillance operations are contained in the Foreign Intelligence Surveillance Act of 1978 (FISA), which does not extend protection to non-U.S. citizens located outside of U.S. territory.
George W. Bush administration.
George W. Bush, president during the 9/11 terrorist attacks, approved the Patriot Act shortly after the attacks to take anti-terrorist security measures. Title 1, 2, and 9 specifically authorized measures that would be taken by the NSA. These titles granted enhanced domestic security against terrorism, surveillance procedures, and improved intelligence, respectively. On March 10th, 2004, there was a debate between President Bush and White House Counsel Alberto Gonzales, Attorney General John Ashcroft, and Acting Attorney General James Comey. The Attorney Generals were unsure if the NSA’s programs could be considered constitutional. They threatened to resign over the matter, but ultimately the NSA’s programs continued. On March 11th, 2004, President Bush signed a new authorization for mass surveillance of Internet records, in addition to the surveillance of phone records.This allowed the president to be able to override laws such as the Foreign Intelligence Surveillance Act, which protected civilians from mass surveillance. In addition to this, President Bush also signed that the measures of mass surveillance were also retroactively in place.
Warrantless wiretaps.
On December 16, 2005, "The New York Times" reported that, under White House pressure and with an executive order from President George W. Bush, the National Security Agency, in an attempt to thwart terrorism, had been tapping phone calls made to persons outside the country, without obtaining warrants from the United States Foreign Intelligence Surveillance Court, a secret court created for that purpose under the Foreign Intelligence Surveillance Act (FISA).
One such surveillance program, authorized by the U.S. Signals Intelligence Directive 18 of President George Bush, was the Highlander Project undertaken for the National Security Agency by the U.S. Army 513th Military Intelligence Brigade. NSA relayed telephone (including cell phone) conversations obtained from ground, airborne, and satellite monitoring stations to various U.S. Army Signal Intelligence Officers, including the 201st Military Intelligence Battalion. Conversations of citizens of the U.S. were intercepted, along with those of other nations.
Proponents of the surveillance program claim that the President has executive authority to order such action, arguing that laws such as FISA are overridden by the President's Constitutional powers. In addition, some argued that FISA was implicitly overridden by a subsequent statute, the Authorization for Use of Military Force, although the Supreme Court's ruling in Hamdan v. Rumsfeld deprecates this view. In the August 2006 case "ACLU v. NSA", U.S. District Court Judge Anna Diggs Taylor concluded that NSA's warrantless surveillance program was both illegal and unconstitutional. On July 6, 2007 the 6th Circuit Court of Appeals vacated the decision on the grounds that the ACLU lacked standing to bring the suit.
On January 17, 2006, the Center for Constitutional Rights filed a lawsuit, CCR v. Bush, against the George W. Bush Presidency. The lawsuit challenged the National Security Agency's (NSA's) surveillance of people within the U.S., including the interception of CCR emails without securing a warrant first.
In September 2008, the Electronic Frontier Foundation (EFF) filed a class action lawsuit against the NSA and several high-ranking officials of the Bush administration, charging an "illegal and unconstitutional program of dragnet communications surveillance," based on documentation provided by former AT&T technician Mark Klein.
As a result of the USA Freedom Act passed by Congress in June 2015, the NSA had to shut down its bulk phone surveillance program on November 29 of the same year. The USA Freedom Act forbids the NSA to collect metadata and content of phone calls unless it has a warrant for terrorism investigation. In that case the agency has to ask the telecom companies for the record, which will only be kept for six months.
AT&T Internet monitoring.
In May 2006, Mark Klein, a former AT&T employee, alleged that his company had cooperated with NSA in installing Narus hardware to replace the FBI Carnivore program, to monitor network communications including traffic between American citizens.
Data mining.
NSA was reported in 2008 to use its computing capability to analyze "transactional" data that it regularly acquires from other government agencies, which gather it under their own jurisdictional authorities. As part of this effort, NSA now monitors huge volumes of records of domestic email data, web addresses from Internet searches, bank transfers, credit-card transactions, travel records, and telephone data, according to current and former intelligence officials interviewed by "The Wall Street Journal". The sender, recipient, and subject line of emails can be included, but the content of the messages or of phone calls are not.
A 2013 advisory group for the Obama administration, seeking to reform NSA spying programs following the revelations of documents released by Edward J. Snowden. mentioned in 'Recommendation 30' on page 37, "...that the National Security Council staff should manage an interagency process to review on a regular basis the activities of the US Government regarding attacks that exploit a previously unknown vulnerability in a computer application." Retired cyber security expert Richard A. Clarke was a group member and stated on April 11 that NSA had no advance knowledge of Heartbleed.
Illegally obtained evidence.
In August 2013 it was revealed that a 2005 IRS training document showed that NSA intelligence intercepts and wiretaps, both foreign and domestic, were being supplied to the Drug Enforcement Administration (DEA) and Internal Revenue Service (IRS) and were illegally used to launch criminal investigations of US citizens. Law enforcement agents were directed to conceal how the investigations began and recreate an apparently legal investigative trail by re-obtaining the same evidence by other means.
Barack Obama Administration.
In the months leading to April 2009, the NSA intercepted the communications of American citizens, including a Congressman, although the Justice Department believed that the interception was unintentional. The Justice Department then took action to correct the issues and bring the program into compliance with existing laws. United States Attorney General Eric Holder resumed the program according to his understanding of the Foreign Intelligence Surveillance Act amendment of 2008, without explaining what had occurred.
Polls conducted in June 2013 found divided results among Americans regarding NSA's secret data collection. Rasmussen Reports found that 59% of Americans disapprove, Gallup found that 53% disapprove, and Pew found that 56% are in favor of NSA data collection.
Section 215 metadata collection.
On April 25, 2013, the NSA obtained a court order requiring Verizon's Business Network Services to provide metadata on all calls in its system to the NSA "on an ongoing daily basis" for a three-month period, as reported by "The Guardian" on June 6, 2013. This information includes "the numbers of both parties on a call ... location data, call duration, unique identifiers, and the time and duration of all calls" but not "contents of the conversation itself". The order relies on the so-called "business records" provision of the Patriot Act.
In August 2013, following the Snowden leaks, new details about the NSA's data mining activity were revealed. Reportedly, the majority of emails into or out of the United States are captured at "selected communications links" and automatically analyzed for keywords or other "selectors". Emails that do not match are deleted.
The utility of such a massive metadata collection in preventing terrorist attacks is disputed. Many studies reveal the dragnet like system to be ineffective. One such report, released by the New America Foundation concluded that after an analysis of 225 terrorism cases, the NSA "had no discernible impact on preventing acts of terrorism."
Defenders of the program say that while metadata alone can't provide all the information necessary to prevent an attack, it assures the ability to "connect the dots" between suspect foreign numbers and domestic numbers with a speed only the NSA's software is capable of. One benefit of this is quickly being able to determine the difference between suspicious activity and real threats. As an example, NSA director General Keith Alexander mentioned at the annual Cybersecurity Summit in 2013, that metadata analysis of domestic phone call records after the Boston Marathon bombing helped determine that another attack in New York was baseless.
In addition to doubts about its effectiveness, many people argue that the collection of metadata is an unconstitutional invasion of privacy. , the collection process remains legal and grounded in the ruling from Smith v. Maryland (1979). A prominent opponent of the data collection and its legality is U.S. District Judge Richard J. Leon, who issued a report in 2013 in which he stated:
"I cannot imagine a more 'indiscriminate' and 'arbitrary invasion' than this systematic and high tech collection and retention of personal data on virtually every single citizen for purposes of querying and analyzing it without prior judicial approval...Surely, such a program infringes on 'that degree of privacy' that the founders enshrined in the Fourth Amendment".
The PRISM program.
Under the PRISM program, which started in 2007, NSA gathers internet communications from foreign targets from nine major U.S. internet-based communication service providers: Microsoft, Yahoo, Google, Facebook, PalTalk, AOL, Skype, YouTube and Apple. Data gathered include email, video and voice chat, videos, photos, VoIP chats such as Skype, and file transfers.
June 2015 - WikiLeaks: Industrial espionage.
In June 2015, Wikileaks published documents, which showed that NSA spied on French companies.
July 2015 - WikiLeaks: Espionage against German federal ministries.
In July 2015, WikiLeaks published documents, which showed that NSA spied on federal German ministries since 1990s.
Prevented terrorist attacks.
According to former NSA director General Keith Alexander, in September 2009 the NSA prevented Najibullah Zazi and his friends from carrying out a terrorist attack. The NSA tagged Zazi as a possible threat because he was contacting people affiliated with terrorist activity through emails, which the NSA was able to obtain through one of PRISM's dragnets. The NSA tipped off the FBI, which began a program called Operation High-Rise. Operation High-Rise discovered that Zazi was planning to suicide bomb the New York City Subway. Zazi called off the attacks after receiving a tip about law-enforcement inquiries and was later arrested.
Hacking operations.
Besides the more traditional ways of eavesdropping in order to collect signals intelligence, NSA is also engaged in hacking computers, smartphones and their networks. These operations are conducted by the Tailored Access Operations (TAO) division.
Suspected responsibility for hacking operations by the Equation Group.
The espionage group named the Equation Group, described by discoverers Kaspersky Labs as one of the most advanced (if not the most advanced) in the world as of 2015, and connected to over 500 malware infections in at least 42 countries over many years, is suspected of being a part of NSA. The group's known espionage methods have been documented to include interdiction (interception of legitimate CDs sent by a scientific conference organizer by mail), and the "unprecedented" ability to infect and be transmitted through the hard drive firmware of several of the major hard drive manufacturers, and create and use hidden disk areas and virtual disk systems for its purposes, a feat demanding access to the manufacturer's source code of each to achieve. The methods used to deploy the tools demonstrated "surgical precision", going so far as to exclude specific countries by IP and allow targeting of specific usernames on discussion forums. The techniques and knowledge used by the Equation Group are considered in summary to be "out of the reach of most advanced threat groups in the world except group.
Software backdoors.
Linux kernel.
Linus Torvalds, the founder of Linux kernel, joked during a LinuxCon keynote on September 18, 2013 that the NSA, who are the founder of SELinux, wanted a backdoor in the kernel. However, later, Linus' father, a Member of the European Parliament (MEP), revealed that the NSA actually did this. 
Microsoft Windows.
codice_1 was a variable name discovered in Microsoft's Windows NT 4 Service Pack 5 (which had been released unstripped of its symbolic debugging data) in August 1999 by Andrew D. Fernandes of Cryptonym Corporation. That variable contained a 1024-bit public key.
IBM Notes.
IBM Notes was the first widely adopted software product to use public key cryptography for client–server and server–server authentication and for encryption of data. Until US laws regulating encryption were changed in 2000, IBM and Lotus were prohibited from exporting versions of Notes that supported symmetric encryption keys that were longer than 40 bits. In 1997, Lotus negotiated an agreement with the NSA that allowed export of a version that supported stronger keys with 64 bits, but 24 of the bits were encrypted with a special key and included in the message to provide a "workload reduction factor" for the NSA. This strengthened the protection for users of Notes outside the US against private-sector industrial espionage, but not against spying by the US government.
Boomerang routing.
While it is assumed that foreign transmissions terminating in the U.S. (such as a non-U.S. citizen accessing a U.S. website) subject non-U.S. citizens to NSA surveillance, recent research into boomerang routing has raised new concerns about the NSA's ability to surveil the domestic internet traffic of foreign countries. Boomerang routing occurs when an internet transmission that originates and terminates in a single country transits another. Research at the University of Toronto has suggested that approximately 25% of Canadian domestic traffic may be subject to NSA surveillance activities as a result of the boomerang routing of Canadian internet service providers.
Hardware implanting.
A document included in NSA files released with Glenn Greenwald's book "No Place to Hide" details how the agency's Tailored Access Operations (TAO) and other NSA units gain access to hardware. They intercept routers, servers and other network hardware being shipped to organizations targeted for surveillance and install covert implant firmware onto them before they are delivered. This was described by an NSA manager as "some of the most productive operations in TAO because they preposition access points into hard target networks around the world."
Computers seized by the NSA due to interdiction are often modified with a physical device known as Cottonmouth Cottonmouth is a device that can be inserted in the USB port of a computer in order to establish remote access to the targeted machine. According to NSA's Tailored Access Operations (TAO) group implant catalog, after implanting Cottonmouth, the NSA can establish Bridging (networking) "that allows the NSA to load exploit software onto modified computers as well as allowing the NSA to relay commands and data between hardware and software implants."
Role in scientific research and development.
NSA has been involved in debates about public policy, both indirectly as a behind-the-scenes adviser to other departments, and directly during and after Vice Admiral Bobby Ray Inman's directorship. NSA was a major player in the debates of the 1990s regarding the export of cryptography in the United States. Restrictions on export were reduced but not eliminated in 1996.
Its secure government communications work has involved the NSA in numerous technology areas, including the design of specialized communications hardware and software, production of dedicated semiconductors (at the Ft. Meade chip fabrication plant), and advanced cryptography research. For 50 years, NSA designed and built most of its computer equipment in-house, but from the 1990s until about 2003 (when the U.S. Congress curtailed the practice), the agency contracted with the private sector in the fields of research and equipment.
Data Encryption Standard.
NSA was embroiled in some minor controversy concerning its involvement in the creation of the Data Encryption Standard (DES), a standard and public block cipher algorithm used by the U.S. government and banking community. During the development of DES by IBM in the 1970s, NSA recommended changes to some details of the design. There was suspicion that these changes had weakened the algorithm sufficiently to enable the agency to eavesdrop if required, including speculation that a critical component—the so-called S-boxes—had been altered to insert a "backdoor" and that the reduction in key length might have made it feasible for NSA to discover DES keys using massive computing power. It has since been observed that the S-boxes in DES are particularly resilient against differential cryptanalysis, a technique which was not publicly discovered until the late 1980s, but which was known to the IBM DES team.
The United States Senate Select Committee on Intelligence reviewed NSA's involvement, and concluded that while the agency had provided some assistance, it had not tampered with the design. In late 2009 NSA declassified information stating that "NSA worked closely with IBM to strengthen the algorithm against all except brute force attacks and to strengthen substitution tables, called S-boxes. Conversely, NSA tried to convince IBM to reduce the length of the key from 64 to 48 bits. Ultimately they compromised on a 56-bit key."
Advanced Encryption Standard.
The involvement of NSA in the selection of a successor to Data Encryption Standard (DES), the Advanced Encryption Standard (AES), was limited to hardware performance testing (see AES competition). NSA has subsequently certified AES for protection of classified information () when used in NSA-approved systems.
NSA encryption systems.
The NSA is responsible for the encryption-related components in these legacy systems:
The NSA oversees encryption in following systems which are in use today:
The NSA has specified Suite A and Suite B cryptographic algorithm suites to be used in U.S. government systems; the Suite B algorithms are a subset of those previously specified by NIST and are expected to serve for most information protection purposes, while the Suite A algorithms are secret and are intended for especially high levels of protection.
SHA.
The widely used SHA-1 and SHA-2 hash functions were designed by NSA. SHA-1 is a slight modification of the weaker SHA-0 algorithm, also designed by NSA in 1993. This small modification was suggested by NSA two years later, with no justification other than the fact that it provides additional security. An attack for SHA-0 that does not apply to the revised algorithm was indeed found between 1998 and 2005 by academic cryptographers. Because of weaknesses and key length restrictions in SHA-1, NIST deprecates its use for digital signatures, and approves only the newer SHA-2 algorithms for such applications from 2013 on.
A new hash standard, SHA-3, has recently been selected through the competition concluded October 2, 2012 with the selection of Keccak as the algorithm. The process to select SHA-3 was similar to the one held in choosing the AES, but some doubts have been cast over it, since fundamental modifications have been made to Keccak in order to turn it into a standard. These changes potentially undermine the cryptanalysis performed during the competition and reduce the security levels of the algorithm.
Dual_EC_DRBG random number generator.
NSA promoted the inclusion of a random number generator called Dual_EC_DRBG in the U.S. National Institute of Standards and Technology's 2007 guidelines. This led to speculation of a backdoor which would allow NSA access to data encrypted by systems using that pseudo random number generator.
This is now deemed to be plausible based on the fact that the output of the next iterations of the PRNG can provably be determined if the relation between two internal elliptic curve points is known. Both NIST and RSA are now officially recommending against the use of this PRNG.
Clipper chip.
Because of concerns that widespread use of strong cryptography would hamper government use of wiretaps, NSA proposed the concept of key escrow in 1993 and introduced the Clipper chip that would offer stronger protection than DES but would allow access to encrypted data by authorized law enforcement officials. The proposal was strongly opposed and key escrow requirements ultimately went nowhere. However, NSA's Fortezza hardware-based encryption cards, created for the Clipper project, are still used within government, and NSA ultimately declassified and published the design of the Skipjack cipher used on the cards.
Perfect Citizen.
Perfect Citizen is a program to perform vulnerability assessment by the NSA on U.S. critical infrastructure. It was originally reported to be a program to develop a system of sensors to detect cyber attacks on critical infrastructure computer networks in both the private and public sector through a network monitoring system named "Einstein". It is funded by the Comprehensive National Cybersecurity Initiative and thus far Raytheon has received a contract for up to $100 million for the initial stage.
Academic research.
NSA has invested many millions of dollars in academic research under grant code prefix "MDA904", resulting in over 3,000 papers (as of 2007-10-11). NSA/CSS has, at times, attempted to restrict the publication of academic research into cryptography; for example, the Khufu and Khafre block ciphers were voluntarily withheld in response to an NSA request to do so. In response to a FOIA lawsuit, in 2013 the NSA released the 643-page research paper titled, "Untangling the Web: A Guide to Internet Research, " written and compiled by NSA employees to assist other NSA workers in searching for information of interest to the agency on the public Internet.
Patents.
NSA has the ability to file for a patent from the U.S. Patent and Trademark Office under gag order. Unlike normal patents, these are not revealed to the public and do not expire. However, if the Patent Office receives an application for an identical patent from a third party, they will reveal NSA's patent and officially grant it to NSA for the full term on that date.
One of NSA's published patents describes a method of geographically locating an individual computer site in an Internet-like network, based on the latency of multiple network connections. Although no public patent exists, NSA is reported to have used a similar locating technology called trilateralization that allows real-time tracking of an individual's location, including altitude from ground level, using data obtained from cellphone towers.
Legality.
In the United States, at least since 2001, there has been legal controversy over what signal intelligence can be used for and how much freedom the National Security Agency has to use signal intelligence. The government has made, in 2015, slight changes in how it uses and collects certain types of data, specifically phone records. President Barack Obama has asked lawyers and his national security team to look at the tactics that are being used by the NSA. President Obama made a speech on January 17, 2014 where he defended the national security measures, including the NSA, and their intentions for keeping the country safe through surveillance. He said that it is difficult to determine where the line should be drawn between what is too much surveillance and how much is needed for national security because technology is ever changing and evolving. Therefore, the laws cannot keep up with the rapid advancements.
President Obama did make some changes to national security regulations and how much data can be collected and surveyed. The first thing he added, was more presidential directive and oversight so that privacy and basic rights are not violated. The president would look over requests on behalf of American citizens to make sure that their personal privacy is not violated by the data that is being requested. Secondly, surveillance tactics and procedures are becoming more public, including over 40 rulings of the FISC that have been declassified. Thirdly, further protections are being placed on activities that are justified under Section 702, such as the ability to retain, search and use data collected in investigations, which allows the NSA to monitor and intercept interaction of targets overseas. Finally, national security letters, which are secret requests for information that the FBI uses in their investigations, are becoming less secretive. The secrecy of the information requested will not be indefinite and will terminate after a set time if future secrecy is not required. Concerning the bulk surveillance of American's phone records, President Obama also ordered a transition from bulk surveillance under Section 215 to a new policy that will eliminate unnecessary bulk collection of metadata.
As of May 7, 2015, the U.S. Court of Appeals for the Second Circuit ruled that the interpretation of Section 215 of the Patriot Act was wrong and that the NSA program that has been collecting Americans' phone records in bulk is illegal. It stated that Section 215 cannot be clearly interpreted to allow government to collect national phone data and, as a result, expired on June 1, 2015. This ruling "is the first time a higher-level court in the regular judicial system has reviewed the N.S.A. phone records program." The new bill getting passed later in May taking its place is known as the U.S.A. Freedom Act, which will enable the NSA to continue hunting for terrorists by analyzing telephone links between callers but "keep the bulk phone records in the hands of phone companies." This would give phone companies the freedom to dispose the records in an 18-month period. The White House argued that this new ruling validated President Obama's support of the government being extracted from bulk data collection and giving power to the telecommunications companies.
Previously, the NSA paid billions of dollars to telecommunications companies in order to collect data from them. While companies such as Google and Yahoo! claim that they do not provide "direct access" from their servers to the NSA unless under a court order, the NSA had access to emails, phone calls and cellular data users. With this new ruling, telecommunications companies would not provide the NSA with bulk information. The companies would allow the disposal of data in every 18 months, which is arguably putting the telecommunications companies at a higher advantage.
This ruling made the collecting of phone records illegal, but it did not rule on Section 215's constitutionality. Senate Majority Leader Mitch McConnell has already put forth a new bill to re-authorize the Patriot Act. Defenders of this surveillance program are claiming that judges who sit on the Foreign Intelligence Surveillance Court (FISC) had ruled 37 times that this kind of collection of data is, in fact, lawful. The FISC is the court specifically mandated to grant surveillance orders in the name of foreign intelligence. The new ruling made by the Second District Court of Appeals now retroactively dismisses the findings of the FISC on this program.

</doc>
<doc id="21944" url="https://en.wikipedia.org/wiki?curid=21944" title="Nervous system">
Nervous system

The nervous system is the part of an animal's body that coordinates its voluntary and involuntary actions and transmits signals to and from different parts of its body. Nervous tissue first arose in wormlike organisms about 550 to 600 million years ago. In vertebrate species it consists of two main parts, the central nervous system (CNS) and the peripheral nervous system (PNS). The CNS contains the brain and spinal cord. The PNS consists mainly of nerves, which are enclosed bundles of the long fibers or axons, that connect the CNS to every other part of the body. Nerves that transmit signals from the brain are called "motor" or "efferent" nerves, while those nerves that transmit information from the body to the CNS are called "sensory" or "afferent". Most nerves serve both functions and are called "mixed" nerves. The PNS is divided into a) somatic and b) autonomic nervous system, and c) the enteric nervous system. Somatic nerves mediate voluntary movement. The autonomic nervous system is further subdivided into the sympathetic and the parasympathetic nervous systems. The sympathetic nervous system is activated in cases of emergencies to mobilize energy, while the parasympathetic nervous system is activated when organisms are in a relaxed state. The enteric nervous system functions to control the gastrointestinal system. Both autonomic and enteric nervous systems function involuntarily. Nerves that exit from the cranium are called cranial nerves while those exiting from the spinal cord are called spinal nerves.
At the cellular level, the nervous system is defined by the presence of a special type of cell, called the neuron, also known as a "nerve cell". Neurons have special structures that allow them to send signals rapidly and precisely to other cells. They send these signals in the form of electrochemical waves traveling along thin fibers called axons, which cause chemicals called neurotransmitters to be released at junctions called synapses. A cell that receives a synaptic signal from a neuron may be excited, inhibited, or otherwise modulated. The connections between neurons can form neural circuits and also neural networks that generate an organism's perception of the world and determine its behavior. Along with neurons, the nervous system contains other specialized cells called glial cells (or simply glia), which provide structural and metabolic support.
Nervous systems are found in most multicellular animals, but vary greatly in complexity. The only multicellular animals that have no nervous system at all are sponges, placozoans, and mesozoans, which have very simple body plans. The nervous systems of the radially symmetric organisms ctenophores (comb jellies) and cnidarians (which include anemones, hydras, corals and jellyfish) consist of a diffuse nerve net. All other animal species, with the exception of a few types of worm, have a nervous system containing a brain, a central cord (or two cords running in parallel), and nerves radiating from the brain and central cord. The size of the nervous system ranges from a few hundred cells in the simplest worms, to around 300 billion cells in African elephants.
The central nervous system functions to send signals from one cell to others, or from one part of the body to others and to receive feedback. Malfunction of the nervous system can occur as a result of genetic defects, physical damage due to trauma or toxicity, infection or simply of ageing. The medical specialty of neurology studies disorders of the nervous system and looks for interventions that can prevent or treat them. In the peripheral nervous system, the most common problem is the failure of nerve conduction, which can be due to different causes including diabetic neuropathy and demyelinating disorders such as multiple sclerosis and amyotrophic lateral sclerosis.
Neuroscience is the field of science that focuses on the study of the nervous system.
Structure.
The nervous system derives its name from nerves, which are cylindrical bundles of fibers (the axons of neurons), that emanate from the brain and spinal cord, and branch repeatedly to innervate every part of the body. Nerves are large enough to have been recognized by the ancient Egyptians, Greeks, and Romans, but their internal structure was not understood until it became possible to examine them using a microscope. 
"It is difficult to believe that until approximately year
1900 it was not known that neurons are the basic
units of the brain (Santiago Ramón y Cajal|). Equally surprising is the fact that the concept of chemical transmission in the brain was not known until around 1930 (Henry Hallett Dale ) and (Otto Loewi ). We began to understand the basic electrical phenomenon that neurons use in order to communicate among themselves, the action potential, in the decade of 1950 (Alan Lloyd Hodgkin, Huxley Andrew Huxley and John Eccles). It was in the decade of 1960 that we became aware of how basic neuronal networks code stimuli and thus basic concepts are possible (David H. Hubel, and Torsten Wiesel). The molecular revolution swept across US universities in the decade of 1980. It was in the decade of 1990 that molecular mechanisms of behavioral phenomena became widely known (Eric Richard Kandel)." A microscopic examination shows that nerves consist primarily of axons, along with different membranes that wrap around them and segregate them into fascicles. The neurons that give rise to nerves do not lie entirely within the nerves themselves—their cell bodies reside within the brain, spinal cord, or peripheral ganglia.
All animals more advanced than sponges have nervous systems. However, even sponges, unicellular animals, and non-animals such as slime molds have cell-to-cell signalling mechanisms that are precursors to those of neurons. In radially symmetric animals such as the jellyfish and hydra, the nervous system consists of a nerve net, a diffuse network of isolated cells. In bilaterian animals, which make up the great majority of existing species, the nervous system has a common structure that originated early in the Ediacaran period, over 550 million years ago.
Cells.
The nervous system contains two main categories or types of cells: neurons and glial cells.
Neurons.
The nervous system is defined by the presence of a special type of cell—the neuron (sometimes called "neurone" or "nerve cell"). Neurons can be distinguished from other cells in a number of ways, but their most fundamental property is that they communicate with other cells via synapses, which are membrane-to-membrane junctions containing molecular machinery that allows rapid transmission of signals, either electrical or chemical. Many types of neuron possess an axon, a protoplasmic protrusion that can extend to distant parts of the body and make thousands of synaptic contacts. Axons frequently travel through the body in bundles called nerves.
Even in the nervous system of a single species such as humans, hundreds of different types of neurons exist, with a wide variety of morphologies and functions. These include sensory neurons that transmute physical stimuli such as light and sound into neural signals, and motor neurons that transmute neural signals into activation of muscles or glands; however in many species the great majority of neurons participate in the formation of centralized structures (the brain and ganglia) and they receive all of their input from other neurons and send their output to other neurons.
Glial cells.
Glial cells (named from the Greek for "glue") are non-neuronal cells that provide support and nutrition, maintain homeostasis, form myelin, and participate in signal transmission in the nervous system. In the human brain, it is estimated that the total number of glia roughly equals the number of neurons, although the proportions vary in different brain areas. Among the most important functions of glial cells are to support neurons and hold them in place; to supply nutrients to neurons; to insulate neurons electrically; to destroy pathogens and remove dead neurons; and to provide guidance cues directing the axons of neurons to their targets. A very important type of glial cell (oligodendrocytes in the central nervous system, and Schwann cells in the peripheral nervous system) generates layers of a fatty substance called myelin that wraps around axons and provides electrical insulation which allows them to transmit action potentials much more rapidly and efficiently.
Anatomy in vertebrates.
The nervous system of vertebrates (including humans) is divided into the central nervous system (CNS) and the peripheral nervous system (PNS).
The (CNS) is the major division, and consists of the brain and the spinal cord. The spinal canal contains the spinal cord, while the cranial cavity contains the brain. The CNS is enclosed and protected by the meninges, a three-layered system of membranes, including a tough, leathery outer layer called the dura mater. The brain is also protected by the skull, and the spinal cord by the vertebrae.
The peripheral nervous system (PNS) is a collective term for the nervous system structures that do not lie within the CNS. The large majority of the axon bundles called nerves are considered to belong to the PNS, even when the cell bodies of the neurons to which they belong reside within the brain or spinal cord. The PNS is divided into somatic and visceral parts. The somatic part consists of the nerves that innervate the skin, joints, and muscles. The cell bodies of somatic sensory neurons lie in dorsal root ganglia of the spinal cord. The visceral part, also known as the autonomic nervous system, contains neurons that innervate the internal organs, blood vessels, and glands. The autonomic nervous system itself consists of two parts: the sympathetic nervous system and the parasympathetic nervous system. Some authors also include sensory neurons whose cell bodies lie in the periphery (for senses such as hearing) as part of the PNS; others, however, omit them.
The vertebrate nervous system can also be divided into areas called grey matter ("gray matter" in American spelling) and white matter. Grey matter (which is only grey in preserved tissue, and is better described as pink or light brown in living tissue) contains a high proportion of cell bodies of neurons. White matter is composed mainly of myelinated axons, and takes its color from the myelin. White matter includes all of the nerves, and much of the interior of the brain and spinal cord. Grey matter is found in clusters of neurons in the brain and spinal cord, and in cortical layers that line their surfaces. There is an anatomical convention that a cluster of neurons in the brain or spinal cord is called a nucleus, whereas a cluster of neurons in the periphery is called a ganglion. There are, however, a few exceptions to this rule, notably including the part of the forebrain called the basal ganglia.
Comparative anatomy and evolution.
Neural precursors in sponges.
Sponges have no cells connected to each other by synaptic junctions, that is, no neurons, and therefore no nervous system. They do, however, have homologs of many genes that play key roles in synaptic function. Recent studies have shown that sponge cells express a group of proteins that cluster together to form a structure resembling a postsynaptic density (the signal-receiving part of a synapse). However, the function of this structure is currently unclear. Although sponge cells do not show synaptic transmission, they do communicate with each other via calcium waves and other impulses, which mediate some simple actions such as whole-body contraction.
Radiata.
Jellyfish, comb jellies, and related animals have diffuse nerve nets rather than a central nervous system. In most jellyfish the nerve net is spread more or less evenly across the body; in comb jellies it is concentrated near the mouth. The nerve nets consist of sensory neurons, which pick up chemical, tactile, and visual signals; motor neurons, which can activate contractions of the body wall; and intermediate neurons, which detect patterns of activity in the sensory neurons and, in response, send signals to groups of motor neurons. In some cases groups of intermediate neurons are clustered into discrete ganglia.
The development of the nervous system in radiata is relatively unstructured. Unlike bilaterians, radiata only have two primordial cell layers, endoderm and ectoderm. Neurons are generated from a special set of ectodermal precursor cells, which also serve as precursors for every other ectodermal cell type.
Bilateria.
The vast majority of existing animals are bilaterians, meaning animals with left and right sides that are approximate mirror images of each other. All bilateria are thought to have descended from a common wormlike ancestor that appeared in the Ediacaran period, 550–600 million years ago. The fundamental bilaterian body form is a tube with a hollow gut cavity running from mouth to anus, and a nerve cord with an enlargement (a "ganglion") for each body segment, with an especially large ganglion at the front, called the "brain".
Even mammals, including humans, show the segmented bilaterian body plan at the level of the nervous system. The spinal cord contains a series of segmental ganglia, each giving rise to motor and sensory nerves that innervate a portion of the body surface and underlying musculature. On the limbs, the layout of the innervation pattern is complex, but on the trunk it gives rise to a series of narrow bands. The top three segments belong to the brain, giving rise to the forebrain, midbrain, and hindbrain.
Bilaterians can be divided, based on events that occur very early in embryonic development, into two groups (superphyla) called protostomes and deuterostomes. Deuterostomes include vertebrates as well as echinoderms, hemichordates (mainly acorn worms), and Xenoturbellidans. Protostomes, the more diverse group, include arthropods, molluscs, and numerous types of worms. There is a basic difference between the two groups in the placement of the nervous system within the body: protostomes possess a nerve cord on the ventral (usually bottom) side of the body, whereas in deuterostomes the nerve cord is on the dorsal (usually top) side. In fact, numerous aspects of the body are inverted between the two groups, including the expression patterns of several genes that show dorsal-to-ventral gradients. Most anatomists now consider that the bodies of protostomes and deuterostomes are "flipped over" with respect to each other, a hypothesis that was first proposed by Geoffroy Saint-Hilaire for insects in comparison to vertebrates. Thus insects, for example, have nerve cords that run along the ventral midline of the body, while all vertebrates have spinal cords that run along the dorsal midline.
Worms.
Worms are the simplest bilaterian animals, and reveal the basic structure of the bilaterian nervous system in the most straightforward way. As an example, earthworms have dual nerve cords running along the length of the body and merging at the tail and the mouth. These nerve cords are connected by transverse nerves like the rungs of a ladder. These transverse nerves help coordinate the two sides of the animal. Two ganglia at the head end function similar to a simple brain. Photoreceptors on the animal's eyespots provide sensory information on light and dark.
The nervous system of one very small roundworm, the nematode "Caenorhabditis elegans", has been completely mapped out in a connectome including its synapses. Every neuron and its cellular lineage has been recorded and most, if not all, of the neural connections are known. In this species, the nervous system is sexually dimorphic; the nervous systems of the two sexes, males and female hermaphrodites, have different numbers of neurons and groups of neurons that perform sex-specific functions. In "C. elegans", males have exactly 383 neurons, while hermaphrodites have exactly 302 neurons.
Arthropods.
Arthropods, such as insects and crustaceans, have a nervous system made up of a series of ganglia, connected by a ventral nerve cord made up of two parallel connectives running along the length of the belly. Typically, each body segment has one ganglion on each side, though some ganglia are fused to form the brain and other large ganglia. The head segment contains the brain, also known as the supraesophageal ganglion. In the insect nervous system, the brain is anatomically divided into the protocerebrum, deutocerebrum, and tritocerebrum. Immediately behind the brain is the subesophageal ganglion, which is composed of three pairs of fused ganglia. It controls the mouthparts, the salivary glands and certain muscles. Many arthropods have well-developed sensory organs, including compound eyes for vision and antennae for olfaction and pheromone sensation. The sensory information from these organs is processed by the brain.
In insects, many neurons have cell bodies that are positioned at the edge of the brain and are electrically passive—the cell bodies serve only to provide metabolic support and do not participate in signalling. A protoplasmic fiber runs from the cell body and branches profusely, with some parts transmitting signals and other parts receiving signals. Thus, most parts of the insect brain have passive cell bodies arranged around the periphery, while the neural signal processing takes place in a tangle of protoplasmic fibers called neuropil, in the interior.
"Identified" neurons.
A neuron is called "identified" if it has properties that distinguish it from every other neuron in the same animal—properties such as location, neurotransmitter, gene expression pattern, and connectivity—and if every individual organism belonging to the same species has one and only one neuron with the same set of properties. In vertebrate nervous systems very few neurons are "identified" in this sense—in humans, there are believed to be none—but in simpler nervous systems, some or all neurons may be thus unique. In the roundworm "C. elegans", whose nervous system is the most thoroughly described of any animal's, every neuron in the body is uniquely identifiable, with the same location and the same connections in every individual worm. One notable consequence of this fact is that the form of the "C. elegans" nervous system is completely specified by the genome, with no experience-dependent plasticity.
The brains of many molluscs and insects also contain substantial numbers of identified neurons. In vertebrates, the best known identified neurons are the gigantic Mauthner cells of fish. Every fish has two Mauthner cells, located in the bottom part of the brainstem, one on the left side and one on the right. Each Mauthner cell has an axon that crosses over, innervating neurons at the same brain level and then travelling down through the spinal cord, making numerous connections as it goes. The synapses generated by a Mauthner cell are so powerful that a single action potential gives rise to a major behavioral response: within milliseconds the fish curves its body into a C-shape, then straightens, thereby propelling itself rapidly forward. Functionally this is a fast escape response, triggered most easily by a strong sound wave or pressure wave impinging on the lateral line organ of the fish. Mauthner cells are not the only identified neurons in fish—there are about 20 more types, including pairs of "Mauthner cell analogs" in each spinal segmental nucleus. Although a Mauthner cell is capable of bringing about an escape response individually, in the context of ordinary behavior other types of cells usually contribute to shaping the amplitude and direction of the response.
Mauthner cells have been described as command neurons. A command neuron is a special type of identified neuron, defined as a neuron that is capable of driving a specific behavior individually. Such neurons appear most commonly in the fast escape systems of various species—the squid giant axon and squid giant synapse, used for pioneering experiments in neurophysiology because of their enormous size, both participate in the fast escape circuit of the squid. The concept of a command neuron has, however, become controversial, because of studies showing that some neurons that initially appeared to fit the description were really only capable of evoking a response in a limited set of circumstances.
Function.
At the most basic level, the function of the nervous system is to send signals from one cell to others, or from one part of the body to others. There are multiple ways that a cell can send signals to other cells. One is by releasing chemicals called hormones into the internal circulation, so that they can diffuse to distant sites. In contrast to this "broadcast" mode of signaling, the nervous system provides "point-to-point" signals—neurons project their axons to specific target areas and make synaptic connections with specific target cells. Thus, neural signaling is capable of a much higher level of specificity than hormonal signaling. It is also much faster: the fastest nerve signals travel at speeds that exceed 100 meters per second.
At a more integrative level, the primary function of the nervous system is to control the body. It does this by extracting information from the environment using sensory receptors, sending signals that encode this information into the central nervous system, processing the information to determine an appropriate response, and sending output signals to muscles or glands to activate the response. The evolution of a complex nervous system has made it possible for various animal species to have advanced perception abilities such as vision, complex social interactions, rapid coordination of organ systems, and integrated processing of concurrent signals. In humans, the sophistication of the nervous system makes it possible to have language, abstract representation of concepts, transmission of culture, and many other features of human society that would not exist without the human brain.
Neurons and synapses.
Most neurons send signals via their axons, although some types are capable of dendrite-to-dendrite communication. (In fact, the types of neurons called amacrine cells have no axons, and communicate only via their dendrites.) Neural signals propagate along an axon in the form of electrochemical waves called action potentials, which produce cell-to-cell signals at points where axon terminals make synaptic contact with other cells.
Synapses may be electrical or chemical. Electrical synapses make direct electrical connections between neurons, but chemical synapses are much more common, and much more diverse in function. At a chemical synapse, the cell that sends signals is called presynaptic, and the cell that receives signals is called postsynaptic. Both the presynaptic and postsynaptic areas are full of molecular machinery that carries out the signalling process. The presynaptic area contains large numbers of tiny spherical vessels called synaptic vesicles, packed with neurotransmitter chemicals. When the presynaptic terminal is electrically stimulated, an array of molecules embedded in the membrane are activated, and cause the contents of the vesicles to be released into the narrow space between the presynaptic and postsynaptic membranes, called the synaptic cleft. The neurotransmitter then binds to receptors embedded in the postsynaptic membrane, causing them to enter an activated state. Depending on the type of receptor, the resulting effect on the postsynaptic cell may be excitatory, inhibitory, or modulatory in more complex ways. For example, release of the neurotransmitter acetylcholine at a synaptic contact between a motor neuron and a muscle cell induces rapid contraction of the muscle cell. The entire synaptic transmission process takes only a fraction of a millisecond, although the effects on the postsynaptic cell may last much longer (even indefinitely, in cases where the synaptic signal leads to the formation of a memory trace).
There are literally hundreds of different types of synapses. In fact, there are over a hundred known neurotransmitters, and many of them have multiple types of receptors. Many synapses use more than one neurotransmitter—a common arrangement is for a synapse to use one fast-acting small-molecule neurotransmitter such as glutamate or GABA, along with one or more peptide neurotransmitters that play slower-acting modulatory roles. Molecular neuroscientists generally divide receptors into two broad groups: chemically gated ion channels and second messenger systems. When a chemically gated ion channel is activated, it forms a passage that allow specific types of ion to flow across the membrane. Depending on the type of ion, the effect on the target cell may be excitatory or inhibitory. When a second messenger system is activated, it starts a cascade of molecular interactions inside the target cell, which may ultimately produce a wide variety of complex effects, such as increasing or decreasing the sensitivity of the cell to stimuli, or even altering gene transcription.
According to a rule called Dale's principle, which has only a few known exceptions, a neuron releases the same neurotransmitters at all of its synapses. This does not mean, though, that a neuron exerts the same effect on all of its targets, because the effect of a synapse depends not on the neurotransmitter, but on the receptors that it activates. Because different targets can (and frequently do) use different types of receptors, it is possible for a neuron to have excitatory effects on one set of target cells, inhibitory effects on others, and complex modulatory effects on others still. Nevertheless, it happens that the two most widely used neurotransmitters, glutamate and GABA, each have largely consistent effects. Glutamate has several widely occurring types of receptors, but all of them are excitatory or modulatory. Similarly, GABA has several widely occurring receptor types, but all of them are inhibitory. Because of this consistency, glutamatergic cells are frequently referred to as "excitatory neurons", and GABAergic cells as "inhibitory neurons". Strictly speaking this is an abuse of terminology—it is the receptors that are excitatory and inhibitory, not the neurons—but it is commonly seen even in scholarly publications.
One very important subset of synapses are capable of forming memory traces by means of long-lasting activity-dependent changes in synaptic strength. The best-known form of neural memory is a process called long-term potentiation (abbreviated LTP), which operates at synapses that use the neurotransmitter glutamate acting on a special type of receptor known as the NMDA receptor. The NMDA receptor has an "associative" property: if the two cells involved in the synapse are both activated at approximately the same time, a channel opens that permits calcium to flow into the target cell. The calcium entry initiates a second messenger cascade that ultimately leads to an increase in the number of glutamate receptors in the target cell, thereby increasing the effective strength of the synapse. This change in strength can last for weeks or longer. Since the discovery of LTP in 1973, many other types of synaptic memory traces have been found, involving increases or decreases in synaptic strength that are induced by varying conditions, and last for variable periods of time. The reward system, that reinforces desired behaviour for example, depends on a variant form of LTP that is conditioned on an extra input coming from a reward-signalling pathway that uses dopamine as neurotransmitter. All these forms of synaptic modifiability, taken collectively, give rise to neural plasticity, that is, to a capability for the nervous system to adapt itself to variations in the environment.
Neural circuits and systems.
The basic neuronal function of sending signals to other cells includes a capability for neurons to exchange signals with each other. Networks formed by interconnected groups of neurons are capable of a wide variety of functions, including feature detection, pattern generation and timing, and there are seen to be countless types of information processing possible. Warren McCulloch and Walter Pitts showed in 1943 that even artificial neural networks formed from a greatly simplified mathematical abstraction of a neuron are capable of universal computation. 
Historically, for many years the predominant view of the function of the nervous system was as a stimulus-response associator. In this conception, neural processing begins with stimuli that activate sensory neurons, producing signals that propagate through chains of connections in the spinal cord and brain, giving rise eventually to activation of motor neurons and thereby to muscle contraction, i.e., to overt responses. Descartes believed that all of the behaviors of animals, and most of the behaviors of humans, could be explained in terms of stimulus-response circuits, although he also believed that higher cognitive functions such as language were not capable of being explained mechanistically. Charles Sherrington, in his influential 1906 book "The Integrative Action of the Nervous System", developed the concept of stimulus-response mechanisms in much more detail, and Behaviorism, the school of thought that dominated Psychology through the middle of the 20th century, attempted to explain every aspect of human behavior in stimulus-response terms.
However, experimental studies of electrophysiology, beginning in the early 20th century and reaching high productivity by the 1940s, showed that the nervous system contains many mechanisms for generating patterns of activity intrinsically, without requiring an external stimulus. Neurons were found to be capable of producing regular sequences of action potentials, or sequences of bursts, even in complete isolation. When intrinsically active neurons are connected to each other in complex circuits, the possibilities for generating intricate temporal patterns become far more extensive. A modern conception views the function of the nervous system partly in terms of stimulus-response chains, and partly in terms of intrinsically generated activity patterns—both types of activity interact with each other to generate the full repertoire of behavior.
Reflexes and other stimulus-response circuits.
The simplest type of neural circuit is a reflex arc, which begins with a sensory input and ends with a motor output, passing through a sequence of neurons connected in series. This can be shown in the "withdrawal reflex" causing a hand to jerk back after a hot stove is touched. The circuit begins with sensory receptors in the skin that are activated by harmful levels of heat: a special type of molecular structure embedded in the membrane causes heat to change the electrical field across the membrane. If the change in electrical potential is large enough to pass the given threshold, it evokes an action potential, which is transmitted along the axon of the receptor cell, into the spinal cord. There the axon makes excitatory synaptic contacts with other cells, some of which project (send axonal output) to the same region of the spinal cord, others projecting into the brain. One target is a set of spinal interneurons that project to motor neurons controlling the arm muscles. The interneurons excite the motor neurons, and if the excitation is strong enough, some of the motor neurons generate action potentials, which travel down their axons to the point where they make excitatory synaptic contacts with muscle cells. The excitatory signals induce contraction of the muscle cells, which causes the joint angles in the arm to change, pulling the arm away.
In reality, this straightforward schema is subject to numerous complications. Although for the simplest reflexes there are short neural paths from sensory neuron to motor neuron, there are also other nearby neurons that participate in the circuit and modulate the response. Furthermore, there are projections from the brain to the spinal cord that are capable of enhancing or inhibiting the reflex.
Although the simplest reflexes may be mediated by circuits lying entirely within the spinal cord, more complex responses rely on signal processing in the brain. For example, when an object in the periphery of the visual field moves, and a person looks toward it many stages of signal processing are initiated. The initial sensory response, in the retina of the eye, and the final motor response, in the oculomotor nuclei of the brain stem, are not all that different from those in a simple reflex, but the intermediate stages are completely different. Instead of a one or two step chain of processing, the visual signals pass through perhaps a dozen stages of integration, involving the thalamus, cerebral cortex, basal ganglia, superior colliculus, cerebellum, and several brainstem nuclei. These areas perform signal-processing functions that include feature detection, perceptual analysis, memory recall, decision-making, and motor planning.
Feature detection is the ability to extract biologically relevant information from combinations of sensory signals. In the visual system, for example, sensory receptors in the retina of the eye are only individually capable of detecting "points of light" in the outside world. Second-level visual neurons receive input from groups of primary receptors, higher-level neurons receive input from groups of second-level neurons, and so on, forming a hierarchy of processing stages. At each stage, important information is extracted from the signal ensemble and unimportant information is discarded. By the end of the process, input signals representing "points of light" have been transformed into a neural representation of objects in the surrounding world and their properties. The most sophisticated sensory processing occurs inside the brain, but complex feature extraction also takes place in the spinal cord and in peripheral sensory organs such as the retina.
Intrinsic pattern generation.
Although stimulus-response mechanisms are the easiest to understand, the nervous system is also capable of controlling the body in ways that do not require an external stimulus, by means of internally generated rhythms of activity. Because of the variety of voltage-sensitive ion channels that can be embedded in the membrane of a neuron, many types of neurons are capable, even in isolation, of generating rhythmic sequences of action potentials, or rhythmic alternations between high-rate bursting and quiescence. When neurons that are intrinsically rhythmic are connected to each other by excitatory or inhibitory synapses, the resulting networks are capable of a wide variety of dynamical behaviors, including attractor dynamics, periodicity, and even chaos. A network of neurons that uses its internal structure to generate temporally structured output, without requiring a corresponding temporally structured stimulus, is called a central pattern generator.
Internal pattern generation operates on a wide range of time scales, from milliseconds to hours or longer. One of the most important types of temporal pattern is circadian rhythmicity—that is, rhythmicity with a period of approximately 24 hours. All animals that have been studied show circadian fluctuations in neural activity, which control circadian alternations in behavior such as the sleep-wake cycle. Experimental studies dating from the 1990s have shown that circadian rhythms are generated by a "genetic clock" consisting of a special set of genes whose expression level rises and falls over the course of the day. Animals as diverse as insects and vertebrates share a similar genetic clock system. The circadian clock is influenced by light but continues to operate even when light levels are held constant and no other external time-of-day cues are available. The clock genes are expressed in many parts of the nervous system as well as many peripheral organs, but in mammals all of these "tissue clocks" are kept in synchrony by signals that emanate from a master timekeeper in a tiny part of the brain called the suprachiasmatic nucleus.
Mirror neurons.
A mirror neuron is a neuron that fires both when an animal acts and when the animal observes the same action performed by another. Thus, the neuron "mirrors" the behavior of the other, as though the observer were itself acting. Such neurons have been directly observed in primate species. Birds have been shown to have imitative resonance behaviors and neurological evidence suggests the presence of some form of mirroring system. In humans, brain activity consistent with that of mirror neurons has been found in the premotor cortex, the supplementary motor area, the primary somatosensory cortex and the inferior parietal cortex. The function of the mirror system is a subject of much speculation. Many researchers in cognitive neuroscience and cognitive psychology consider that this system provides the physiological mechanism for the perception/action coupling (see the common coding theory). They argue that mirror neurons may be important for understanding the actions of other people, and for learning new skills by imitation. Some researchers also speculate that mirror systems may simulate observed actions, and thus contribute to theory of mind skills, while others relate mirror neurons to language abilities. However, to date, no widely accepted neural or computational models have been put forward to describe how mirror neuron activity supports cognitive functions such as imitation. There are neuroscientists who caution that the claims being made for the role of mirror neurons are not supported by adequate research.
Development.
In vertebrates, landmarks of embryonic neural development include the birth and differentiation of neurons from stem cell precursors, the migration of immature neurons from their birthplaces in the embryo to their final positions, outgrowth of axons from neurons and guidance of the motile growth cone through the embryo towards postsynaptic partners, the generation of synapses between these axons and their postsynaptic partners, and finally the lifelong changes in synapses which are thought to underlie learning and memory.
All bilaterian animals at an early stage of development form a gastrula, which is polarized, with one end called the animal pole and the other the vegetal pole. The gastrula has the shape of a disk with three layers of cells, an inner layer called the endoderm, which gives rise to the lining of most internal organs, a middle layer called the mesoderm, which gives rise to the bones and muscles, and an outer layer called the ectoderm, which gives rise to the skin and nervous system.
In vertebrates, the first sign of the nervous system is the appearance of a thin strip of cells along the center of the back, called the neural plate. The inner portion of the neural plate (along the midline) is destined to become the central nervous system (CNS), the outer portion the peripheral nervous system (PNS). As development proceeds, a fold called the neural groove appears along the midline. This fold deepens, and then closes up at the top. At this point the future CNS appears as a cylindrical structure called the neural tube, whereas the future PNS appears as two strips of tissue called the neural crest, running lengthwise above the neural tube. The sequence of stages from neural plate to neural tube and neural crest is known as neurulation.
In the early 20th century, a set of famous experiments by Hans Spemann and Hilde Mangold showed that the formation of nervous tissue is "induced" by signals from a group of mesodermal cells called the "organizer region". For decades, though, the nature of the induction process defeated every attempt to figure it out, until finally it was resolved by genetic approaches in the 1990s. Induction of neural tissue requires inhibition of the gene for a so-called bone morphogenetic protein, or BMP. Specifically the protein BMP4 appears to be involved. Two proteins called Noggin and Chordin, both secreted by the mesoderm, are capable of inhibiting BMP4 and thereby inducing ectoderm to turn into neural tissue. It appears that a similar molecular mechanism is involved for widely disparate types of animals, including arthropods as well as vertebrates. In some animals, however, another type of molecule called Fibroblast Growth Factor or FGF may also play an important role in induction.
Induction of neural tissues causes formation of neural precursor cells, called neuroblasts. In drosophila, neuroblasts divide asymmetrically, so that one product is a "ganglion mother cell" (GMC), and the other is a neuroblast. A GMC divides once, to give rise to either a pair of neurons or a pair of glial cells. In all, a neuroblast is capable of generating an indefinite number of neurons or glia.
As shown in a 2008 study, one factor common to all bilateral organisms (including humans) is a family of secreted signaling molecules called neurotrophins which regulate the growth and survival of neurons. Zhu et al. identified DNT1, the first neurotrophin found in flies. DNT1 shares structural similarity with all known neurotrophins and is a key factor in the fate of neurons in Drosophila. Because neurotrophins have now been identified in both vertebrate and invertebrates, this evidence suggests that neurotrophins were present in an ancestor common to bilateral organisms and may represent a common mechanism for nervous system formation.
Pathology.
The central nervous system is protected by major physical and chemical barriers. Physically, the brain and spinal cord are surrounded by tough meningeal membranes, and enclosed in the bones of the skull and spinal vertebrae, which combine to form a strong physical shield. Chemically, the brain and spinal cord are isolated by the so-called blood–brain barrier, which prevents most types of chemicals from moving from the bloodstream into the interior of the CNS. These protections make the CNS less susceptible in many ways than the PNS; the flip side, however, is that damage to the CNS tends to have more serious consequences.
Although nerves tend to lie deep under the skin except in a few places such as the ulnar nerve near the elbow joint, they are still relatively exposed to physical damage, which can cause pain, loss of sensation, or loss of muscle control. Damage to nerves can also be caused by swelling or bruises at places where a nerve passes through a tight bony channel, as happens in carpal tunnel syndrome. If a nerve is completely transected, it will often regenerate, but for long nerves this process may take months to complete. In addition to physical damage, peripheral neuropathy may be caused by many other medical problems, including genetic conditions, metabolic conditions such as diabetes, inflammatory conditions such as Guillain–Barré syndrome, vitamin deficiency, infectious diseases such as leprosy or shingles, or poisoning by toxins such as heavy metals. Many cases have no cause that can be identified, and are referred to as idiopathic. It is also possible for nerves to lose function temporarily, resulting in numbness as stiffness—common causes include mechanical pressure, a drop in temperature, or chemical interactions with local anesthetic drugs such as lidocaine.
Physical damage to the spinal cord may result in loss of sensation or movement. If an injury to the spine produces nothing worse than swelling, the symptoms may be transient, but if nerve fibers in the spine are actually destroyed, the loss of function is usually permanent. Experimental studies have shown that spinal nerve fibers attempt to regrow in the same way as nerve fibers, but in the spinal cord, tissue destruction usually produces scar tissue that cannot be penetrated by the regrowing nerves.

</doc>
<doc id="21946" url="https://en.wikipedia.org/wiki?curid=21946" title="Nutcracker">
Nutcracker

A nutcracker is a tool designed to open nuts by cracking their shells. There are many designs, including levers, screws, and ratchets. A well-known type portrays a person whose mouth forms the jaws of the nutcracker, though many of these are meant for decorative use.
Functional.
Nuts were historically opened using a hammer and anvil, often made of stone. Some nuts such as walnuts can also be opened by hand, by holding the nut in the palm of the hand and applying pressure with the other palm or thumb, or using another nut.
Manufacturers produce modern functional nutcrackers usually somewhat resembling pliers, but with the pivot point at the end beyond the nut, rather than in the middle. These are also used for cracking the shells of crab and lobster to make the meat inside available for eating. Hinged lever nutcrackers, often called a "pair of nutcrackers", may date back to Ancient Greece. By the 14th century in Europe, nutcrackers were documented in England, including in the "Canterbury Tales", and in France. The lever design may derive from blacksmiths' pincers. Materials included metals such as silver, cast-iron and bronze, and wood including boxwood, especially those from France and Italy. More rarely, porcelain was used. Many of the wooden carved nutcrackers were in the form of people and animals.
During the Victorian era, fruit and nuts were presented at dinner and ornate and often silver-plated nutcrackers were produced to accompany them on the dinner table. Nuts have long been a popular choice for desserts, particularly throughout Europe. The nutcrackers were placed on dining tables to serve as a fun and entertaining center of conversation while diners awaited their final course. At one time, nutcrackers were actually made of metals such as brass, and it was not until the 1800s in Germany that the popularity of wooden ones began to spread.
The late 19th century saw two shifts in nutcracker production: the rise in figurative and decorative designs, particularly from the Alps where they were sold as souvenirs, and a switch to industrial manufacture, including availability in mail-order catalogues, rather than artisan production. After the 1960s, the availability of pre-shelled nuts led to a decline in ownership of nutcrackers and a fall in the tradition of nuts being put in children's Christmas stockings.
Alternative designs.
In the 17th century, screw nutcrackers were introduced that applied more gradual pressure to the shell, some like a vise. The spring-jointed nutcracker was patented by Henry Quackenbush in 1913. A ratchet design, similar to a car jack, that gradually increases pressure on the shell to avoid damaging the kernel inside is used by the Crackerjack, patented in 1947 by Cuthbert Leslie Rimes of Morley, Leeds and exhibited at the Festival of Britain. Unshelled nuts are still popular in China, where a key device is inserted into the crack in walnuts, pecans, and macadamias and twisted to open the shell.
Decorative.
Nutcrackers in the form of wood carvings of a soldier, knight, king, or other profession have existed since at least the 15th century. Figurative nutcrackers are a good luck symbol in Germany, and a folk tale recounts that a puppet-maker won a nutcracking challenge by creating a doll with a mouth for a lever to crack the nuts. These nutcrackers portray a person with a large mouth which the operator opens by lifting a lever in the back of the figurine. Originally one could insert a nut in the big-toothed mouth, press down and thereby crack the nut. Modern nutcrackers in this style serve mostly for decoration, mainly at Christmas time, a season of which they have long been a traditional symbol. The ballet "The Nutcracker" derives its name from this festive holiday decoration.
The carving of nutcrackers—as well as of religious figures and of cribs—developed as a cottage industry in forested rural areas of Germany. The most famous nutcracker carvings come from Sonneberg in Thuringia (also a center of dollmaking) and as part of the industry of wooden toymaking in the Ore Mountains. Wood-carving usually provided the only income for the people living there. Today the travel industry supplements their income by bringing visitors to the remote areas. Carvings by famous names like Junghanel, Klaus Mertens, Karl, Olaf Kolbe, Petersen, Christian Ulbricht and especially the Steinbach nutcrackers have become collectors' items.
Decorative nutcrackers became popular in the United States after the Second World War, following the first US production of "The Nutcracker" ballet in 1940 and the exposure of US soldiers to the dolls during the war. In the United States, few of the decorative nutcrackers are now functional, though expensive working designs are still available. Many of the woodworkers in Germany were in Erzgebirge, in the Soviet zone after the end of the war, and they mass-produced poorly-made designs for the US market. With the increase in pre-shelled nuts the need for functionality was also lessened. After the 1980s, Chinese and Taiwanese imports that copied the traditional German designs took over. The recreated "Bavarian village" of Leavenworth, Washington, features a nutcracker museum. Many other materials also serve to make decorated nutcrackers, such as porcelain, silver, and brass; the museum displays samples. The United States Postal Service (USPS) issued four stamps in October 2008 with custom-made nutcrackers made by Richmond, Virginia artist Glenn Crider.
Other uses.
Some artists, among them the multi-instrumentalist Mike Oldfield, have used the sound nutcrackers make in music.
In animals.
Many animals shell nuts to eat them, including using tools. Parrots use their beaks as natural nutcrackers, in much the same way smaller birds crack seeds. In this case, the pivot point stands opposite the nut, at the jaw.

</doc>
<doc id="21949" url="https://en.wikipedia.org/wiki?curid=21949" title="Nicolai Abildgaard">
Nicolai Abildgaard

Nicolai Abraham Abildgaard (September 11, 1743 – June 4, 1809) was a Danish neoclassical and royal history painter, sculptor, architect, and professor of painting, mythology, and anatomy at the New Royal Danish Academy of Art in Copenhagen, Denmark. Many of his works were in the royal Christiansborg Palace (some destroyed by fire 1794), Fredensborg Palace, and Levetzau Palace at Amalienborg.
Abildgaard had studied at the Academy from 1764 to 1767, then worked there as apprentice, and moved to Rome in 1772–1777, where he studied sculpture, architecture, decoration, frescoes (at Palazzo Farnese) and murals. He returned to the Academy in Copenhagen, promoted to professor in 1778, and elected as Academy Director during 1789–1791 and 1801–1809. He was also assigned as a royal artist/decorator during 1780 to 1805. Abildgaard was married twice, in 1781 and 1803.
Life.
Nicolai Abraham Abildgaard was born on September 11, 1743 in Copenhagen, Denmark, as the son of Søren Abildgaard, an antiquarian draughtsman of repute, and Anne Margrethe Bastholm.
Training as an artist.
He was trained by a painting master before he joined the New Royal Danish Academy of Art ("Det Kongelige Danske Kunstakademi") in Copenhagen, where he studied under the guidance of Johan Edvard Mandelberg and Johannes Wiedewelt. He won a series of medallions at the Academy for his brilliance from 1764 to 1767. The large gold medallion from the Academy won in 1767 included a travel stipend, which he waited five years to receive. He assisted Professor Mandelberg of the Academy as an apprentice around 1769 and for painting decorations for the royal palace at Fredensborg. These paintings are classical, influenced by French classical artists such as Claude Lorrain and Nicolas Poussin. Mandelberg had studied in Paris under François Boucher.
Student travels.
Although artists of that time used to travel to Paris for further studies, but he chose to travel to Rome where he stayed from 1772 to 1777. He took a side trip to Naples in 1776 with Jens Juel. His ambitions focused in the genre of history painting. While in Rome, he studied Annibale Carracci's frescoes at the Palazzo Farnese and the paintings of Rafael, Titian, and Michelangelo. In addition he studied various other artistic disciplines (sculpture, architecture, decoration, wall paintings) and developed his knowledge of mythology, antiquities, anatomy, and perspective.
In the company of Swedish sculptor Johan Tobias Sergel and painter Johann Heinrich Füssli, he began to move away from the classicism he had learned at the Academy. He developed an appreciation for the literature of Shakespeare, Homer, and Ossian (the legendary Gaelic poet). He worked with themes from Greek as well as Norse mythology, which placed him at the forefront of Nordic romanticism.
He left Rome in June 1777 with the hope of becoming professor at the Academy in Copenhagen. He stopped for a stay in Paris and arrived in Denmark in December of the same year.
An academic and artistic career.
Very soon after joining the academy he was honored with the designation of Professor in 1778. He worked as an academic painter of the neoclassical school. From 1777 to 1794, he was very productive as an artist in addition to his role at the school. He taught painting, mythology, and anatomy at the school. He produced not only monumental works, but also smaller pieces such as vignettes and illustrations. He designed Old Norse costumes. He illustrated the works of Socrates and Ossian. Additionally he did some sculpting, etching, and authoring. He was interested in all manners of mythological, biblical, and literary allusion.
He taught some famous painters, including Asmus Jacob Carstens, sculptor Bertel Thorvaldsen, and painters J. L. Lund and Christoffer Wilhelm Eckersberg; later both of them took over his position as professor at the Academy after his death. Eckersberg, referred to as the ""Father of Danish painting,"" went on to lay the foundation for the period of art known as the Golden Age of Danish Painting, as professor at the same Academy.
Around 1780 as royal historical painter, Abildgaard was requested by the Danish government to paint large monumental pieces, a history of Denmark, to decorate the entirety of the Knights' Room ("Riddersal)" at Christiansborg Palace. It was a prestigious and lucrative assignment. The paintings combined not only historical depictions, but also allegorical and mythological elements that glorified and flattered the government. The door pieces depicted, in allegory, four historical periods in Europe's history. Abilgaard used pictorial allegory like ideograms, to communicate ideas and transmit messages through symbols to a refined public who was initiated into this form of symbology. Abildgaard's professor Johan Edvard Mandelberg supplied the decorations to the room.
Abildgaard married Anna Maria Oxholm on March 23, 1781.
He made a failed attempt to be elected to the post of Academy Director in 1787 and was unanimously elected to the post two years later, serving as director during the period 1789–1791. He had the reputation for being a tyrant and for taking as many of the academy's monumental assignments as possible for himself.
Abilgaard was also known as a religious freethinker and an advocate of political reform. In spite of his service to (and in his artwork the glorification of) the government, he was hardly a great supporter of the monarchy or of the state church. He supported the emancipation of the farmers and participated in the collection of monies for the Freedom Monument ("Frihedsstøtten") in 1792. He contributed a design for the monument, as well as for two of the reliefs at its base. He got caught into controversies at the end of the 18th century because of his controversial statements and satirical drawings. He was inspired by the French Revolution, and in 1789–1790 he tried to incorporate these revolutionary ideals into the Knights' Room at Christiansborg Palace. However, the King rejected his designs.
His showdowns with the establishment culminated in 1794, when his allegorical painting "Jupiter Weighs the Fate of Mankind" ("Jupiter vejer menneskenes skæbne") was exhibited at the Salon. He was politically isolated and cut out of the public debate by censors.
The fire at Christiansborg Palace, in February 1794, also had a dampening effect on his career, for seven of the ten monumental paintings of the grandiose project were destroyed in that accident. The project was stopped and so were his earnings.
However, after that devastating fire accident, he started getting decorative assignments and also got the opportunity to practice as an architect. He decorated the Levetzau Palace (now known as Christian VIII's Palace) at Amalienborg (1794–1798), recently occupied home of King Christian VII of Denmark's half-brother Frederik. His protégé Bertel Thorvaldsen headed the sculptural efforts.
He also planned for rebuilding the Christiansborg Palace, but he could not get the assignment. 
At the start of the 19th century, his interest in painting was restored when he painted four scenes from Terence's comedy "Andria." This coincided with his second marriage in 1803 to Juliane Marie Ottesen, which was a very happy situation for the aging Abilgaard. He had two sons and a daughter from the marriage. He bought a lovely little place in the country for the family, "Spurveskjul" ("Sparrow Hideaway").
In 1804 he received a commission for a series of painting for the throne room in the new palace, but disagreements between the artist and the crown prince put a halt to this project. He continued, however, to provide the court with designs for furniture and room decorations.
He was once again selected to serve as the Academy's director from 1801 until his death in 1809, at Frederiksdal. Nicolai Abraham Abildgaard is buried in Copenhagen's Assistens Cemetery.
Works.
Though Nicolai Abildgaard won immense fame in his own generation and helped lead the way to the period of art known as the Golden Age of Danish Painting, his works are scarcely known outside of Denmark. He was a cold theorist, inspired not by nature but by art. His style was classical, though with a romantic trend. He had a keen sense of color. As a technical painter, he attained remarkable success, his tone being very harmonious and even, but the effect to a viewer's eye is rarely interesting. A portrait of him painted by Jens Juel was made into a medallion by his friend Johan Tobias Sergel. August Vilhelm Saabye sculpted a statue of him in 1868, based on contemporary portraits.

</doc>
