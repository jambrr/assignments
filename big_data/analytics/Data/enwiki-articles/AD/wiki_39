<doc id="20864" url="https://en.wikipedia.org/wiki?curid=20864" title="Margaret Mitchell">
Margaret Mitchell

Margaret Munnerlyn Mitchell (November 8, 1900 – August 16, 1949) was an American author and journalist. One novel by Mitchell was published during her lifetime, the American Civil War-era novel, "Gone with the Wind", for which she won the National Book Award for Most Distinguished Novel of 1936
and the Pulitzer Prize for Fiction in 1937. In more recent years, a collection of Mitchell's girlhood writings and a novella she wrote as a teenager, "Lost Laysen", have been published. A collection of articles written by Mitchell for "The Atlanta Journal" was republished in book form.
Family history.
Margaret Mitchell was a Southerner and a lifelong resident and native of Atlanta, Georgia. She was born in 1900 into a wealthy and politically prominent family. Her father, Eugene Muse Mitchell, was an attorney, and her mother, Mary Isabel "May Belle" (or "Maybelle") Stephens, was a suffragist. She had two brothers, Russell Stephens Mitchell, who died in infancy in 1894, and Alexander Stephens Mitchell, born in 1896.
Mitchell's family on her father's side were descendants of Thomas Mitchell, originally of Aberdeenshire, Scotland, who settled in Wilkes County, Georgia in 1777, and served in the American Revolutionary War. Her grandfather, Russell Crawford Mitchell, of Atlanta, enlisted in the Confederate States Army on June 24, 1861 and served in Hood's Texas Brigade. He was severely wounded at the Battle of Sharpsburg, demoted for 'inefficiency,' and detailed as a nurse in Atlanta. After the Civil War, he made a large fortune supplying lumber for the rapid rebuilding of Atlanta. Russell Mitchell had thirteen children from two wives; the eldest was Eugene, who graduated from the University of Georgia Law School.
Mitchell's maternal great-grandfather Philip Fitzgerald emigrated from Ireland, and eventually settled on a slaveholding plantation near Jonesboro, Georgia, where he had one son and seven daughters with his wife, Elenor. Mitchell's grandparents, married in 1863, were Annie Fitzgerald and John Stephens, who had also emigrated from Ireland and was a Captain in the Confederate States Army. John Stephens was a prosperous real estate developer after the Civil War and one of the founders of the Gate City Street Railroad (1881), a mule-drawn Atlanta trolley system. John and Annie Stephens had twelve children together; the seventh child was May Belle Stephens, who married Eugene Mitchell. May Belle Stephens had studied at the Bellevue Convent in Quebec and completed her education at the Atlanta Female Institute.
The "Atlanta Constitution" reported that May Belle Stephens and Eugene Mitchell were married at the Jackson Street mansion of the bride's parents on November 8, 1892:
...the maid of honor, Miss Annie Stephens, was as pretty as a French pastel, in a directoire costume of yellow satin with a long coat of green velvet sleeves, and a vest of gold brocade...The bride was a fair vision of youthful loveliness in her robe of exquisite ivory white and satin...her slippers were white satin wrought with pearls...an elegant supper was served. The dining room was decked in white and green, illuminated with numberless candles in silver candles and awards...The bride's gift from her father was an elegant house and lot...At 11 o'clock Mrs. Mitchell donned a pretty going-away gown of green English cloth with its jaunty velvet hat to match and bid goodbye to her friends.
Early influences.
Margaret Mitchell spent her early childhood on Jackson Hill, east of downtown Atlanta. Her family lived near her grandmother, Annie Stephens, in a Victorian house painted bright red with yellow trim. Mrs. Stephens had been a widow for several years prior to Margaret's birth; Captain John Stephens died in 1896. After his death, she inherited property on Jackson Street where Margaret's family lived.
Grandmother Annie Stephens was quite a character, both vulgar and a tyrant. After gaining control of her father Philip Fitzgerald's money after he died, she splurged on her younger daughters, including Margaret's mother, and sent them to finishing school in the north. There they learned that Irish Americans were not treated as equal to other immigrants, and that it was shameful to be a daughter of an Irishman. Margaret's relationship with her grandmother would become quarrelsome in later years as she entered adulthood. However, for Margaret, her grandmother was a great source of "eye-witness information" about the Civil War and Reconstruction in Atlanta prior to her death in 1934.
Girlhood on Jackson Hill.
In an accident that was traumatic for her mother although she was unharmed, when little Margaret was about three years old, her dress caught fire on an iron grate. Fearing it would happen again, her mother began dressing her in boys' pants, and she was nicknamed "Jimmy", the name of a character in the comic strip, "Little Jimmy". Her brother insisted she would have to be a boy named Jimmy to play with him. Having no sisters to play with, Margaret said she was a boy named Jimmy until she was fourteen.
Stephens Mitchell said his sister was a tomboy who would happily play with dolls occasionally, and she liked to ride her Texas plains pony. As a little girl, Margaret went riding every afternoon with a Confederate veteran and a young lady of "beau-age".
Margaret was raised in an era when children were "seen and not heard". She was not allowed to express her personality by running and screaming on Sunday afternoons while her family was visiting relatives. Her mother would swat her with a hairbrush or a slipper as a form of discipline.
May Belle Mitchell was "hissing blood curdling threats" to her daughter to make her behave the evening she took her to a women's suffrage rally led by Carrie Chapman Catt. Margaret sat on a platform wearing a Votes-for-Women banner blowing kisses to the gentlemen while her mother gave an impassioned speech. She was nineteen years old when the Nineteenth Amendment was ratified, which gave women the right to vote.
May Belle Mitchell was president of the Atlanta Woman's Suffrage League (1915), chairwoman of press publicity for the Georgia Mothers' Congress and Parent Teacher Association, a member of the Pioneer Society, the Atlanta Woman's Club, and several church and literary societies.
Margaret's father was not in favor of corporal punishment in school. During his tenure as president of the educational board (1911–1912), corporal punishment in the public schools was abolished. Reportedly, Eugene Mitchell received a whipping on the first day he attended school and the mental impression of the threshing lasted far longer than the physical marks.
Jackson Hill was an old, affluent part of the city. At the bottom of Jackson Hill was an area of African American homes and businesses called "Darktown". The mayhem of the Atlanta Race Riot occurred over four days in September 1906 when Mitchell was five years old. Local newspapers alleged that several white women had been assaulted by black men, prompting an angry mob of 10,000 to assemble in the streets.
Eugene Mitchell went to bed early the night the rioting began, but was awakened by the sounds of gunshots. The following morning he learned 16 Negroes had been killed. He wrote to his wife that rioters attempted to kill every Negro in sight. As the rioting continued, rumors ran wild Negroes would burn Jackson Hill. At Margaret's suggestion, her father, who did not own a gun, stood guard with a sword.
Though she and her family were unharmed, Margaret was able to recall the terror she felt during the riot twenty years later. Mitchell grew up in a Southern culture where the threat of black on white rape incited mob violence, and in this world, white Georgians lived in fear of the "black beast rapist".
Soon after the riot, Margaret's family decided to move away from Jackson Hill. In 1912, they moved to the east side of Peachtree Street just north of Seventeenth Street in Atlanta. Past the nearest neighbor's house was forest and beyond it the Chattahoochee River. Mitchell's former Jackson Hill home was destroyed in the Great Atlanta Fire of 1917.
The South (of her imagination).
While "the South" exists as a geographical region of the United States, it is also said to exist as "a place of the imagination" of writers. An image of "the South" was fixed in Mitchell's imagination when at six years old her mother took her on a buggy tour through ruined plantations and "Sherman's sentinels", the brick and stone chimneys that remained after William Tecumseh Sherman's "March and torch" through Georgia. Mitchell would later recall what her mother had said to her:
She talked about the world those people had lived in, such a secure world, and how it had exploded beneath them. And she told me that my world was going to explode under me, someday, and God help me if I didn't have some weapon to meet the new world.
From an imagination cultivated in her youth, Margaret Mitchell's defensive weapon would become her writing.
Mitchell said she heard Civil War stories from her relatives when she was growing up:
On Sunday afternoons when we went calling on the older generation of relatives, those who had been active in the Sixties, I sat on the bony knees of veterans and the fat slippery laps of great aunts and heard them talk.
On summer vacations, she visited her maternal great-aunts, Mary Ellen ("Mamie") Fitzgerald and Sarah ("Sis") Fitzgerald, who still lived at her great-grandparents' plantation home in Jonesboro. Mamie had been twenty-one years old and Sis was thirteen when the Civil War began.
An avid reader.
An avid reader, young Margaret read "boys' stories" by G.A. Henty, the Tom Swift series, and the Rover Boys series by Edward Stratemeyer. Her mother read Mary Johnston's novels to her before she could read. They both wept reading Johnston's "The Long Roll" (1911) and "Cease Firing" (1912). Between the "scream of shells, the mighty onrush of charges, the grim and grisly aftermath of war", "Cease Firing" is a romance novel involving the courtship of a Confederate soldier and a Louisiana plantation belle with Civil War illustrations by N. C. Wyeth. She also read the plays of William Shakespeare, and novels by Charles Dickens and Sir Walter Scott.
Mitchell's two favorite children's books were by author Edith Nesbit: "Five Children and It" (1902) and "The Phoenix and the Carpet" (1904). She kept both on her bookshelf even as an adult and gave them as gifts.
Young storyteller.
An imaginative writer from a precocious age, Margaret Mitchell began with stories about animals, then progressed to fairy tales and adventure stories. She fashioned book covers for her stories, bound the tablet paper pages together and added her own artwork. At age eleven she gave a name to her publishing enterprise: "Urchin Publishing Co." Later her stories were written in notebooks. May Belle Mitchell kept her daughter's stories in white enamel bread boxes and several boxes of her stories were stored in the house by the time Margaret went off to college.
"Margaret" is a character riding a galloping pony in "The Little Pioneers", and plays "Cowboys and Indians" in "When We Were Shipwrecked".
Romantic love and honor emerged as themes of abiding interest for Mitchell in "The Knight and the Lady" (ca. 1909), in which a "good knight" and a "bad knight" duel for the hand of the lady. In "The Arrow Brave and the Deer Maiden" (ca. 1913), a half-white Indian brave, Jack, must withstand the pain inflicted upon him to uphold his honor and win the girl. The same themes were treated with increasing artistry in "Lost Laysen", the novella Mitchell wrote as a teenager in 1916, and, with much greater sophistication, in Mitchell's last known novel, "Gone with the Wind", which she began in 1926.
In her pre-teens, Mitchell also wrote stories set in foreign locations, such as "The Greaser" (1913), a cowboy story set in Mexico. In 1913 she wrote two stories with Civil War settings; one includes her notation that "237 pages are in this book".
School years.
While the Great War carried on in Europe (1914–1918), Margaret Mitchell attended Atlanta's Washington Seminary (now The Westminster Schools), a "fashionable" private girls' school with an enrollment of over 300 students. She was very active in the Drama Club. Mitchell played the male characters: Nick Bottom in Shakespeare's "A Midsummer Night's Dream" and Launcelot Gobbo in Shakespeare's "The Merchant of Venice", among others. She wrote a play about snobbish college girls that she acted in as well. She also joined the Literary Club and had two stories published in the yearbook: "Little Sister" and "Sergeant Terry". Ten-year-old "Peggy" is the heroine in "Little Sister". She hears her older sister being raped and shoots the rapist:
Coldly, dispassionately she viewed him, the chill steel of the gun giving her confidence. She must not miss now—she would not miss—and she did not.
Mitchell received encouragement from her English teacher, Mrs. Paisley, who recognized her writing talent. A demanding teacher, Paisley told her she had ability if she worked hard and would not be careless in constructing sentences. A sentence, she said, must be "complete, concise and coherent".
Mitchell read the books of Thomas Dixon, Jr., and in 1916, when the silent film, "The Birth of a Nation", was showing in Atlanta, she dramatized Dixon's "The Traitor: A Story of the Fall of the Invisible Empire" (1907). As both playwright and actress, she took the role of Steve Hoyle. For the production, she made a Ku Klux Klan costume from a white crepe dress and wore a boy's wig. (Note: Dixon rewrote "The Traitor" as "The Black Hood" (1924) and Steve Hoyle was renamed George Wilkes.)
During her years at Washington Seminary, Mitchell's brother, Stephens, was away studying at Harvard College (1915–1917), and he left in May 1917 to enlist in the army, about a month after the U.S. declared war on Germany. He set sail for France in April 1918, participated in engagements in the Lagny and Marbache sectors, then returned to Georgia in October as a training instructor. While Margaret and her mother were in New York in September 1918 preparing for Margaret to attend college, Stephens wired his father that he was safe after his ship had been torpedoed en route to New York from France.
Stephens Mitchell thought college was the "ruination of girls". However, May Belle Mitchell placed a high value on education for women and she wanted her daughter's future accomplishments to come from using her mind. She saw education as Margaret's weapon and "the key to survival". The classical college education she desired for her daughter was one that was on par with men's colleges, and this type of education was available only at northern schools. Her mother chose Smith College in Northampton, Massachusetts for Margaret because she considered it to be the best women's college in the United States.
Upon graduating from Washington Seminary in June 1918, Mitchell fell in love with a Harvard graduate, a young army lieutenant, Clifford West Henry, who was chief bayonet instructor at Camp Gordon from May 10 until the time he set sail for France on July 17. Henry was "slightly effeminate", "ineffectual", and "rather effete-looking" with "homosexual tendencies", according to biographer Anne Edwards. Before departing for France, he gave Mitchell an engagement ring.
On September 14, while she was enrolled at Smith College, Henry was mortally wounded in action in France and died on October 17. As Henry waited in the Verdun trenches, shortly before being wounded, he composed a poem on a leaf torn from his field notebook, found later among his effects. The last stanza of Lieutenant Clifford W. Henry's poem follows:
Henry repeatedly advanced in front of the platoon he commanded, drawing machine-gun fire so that the German nests could be located and wiped out by his men. Although wounded in the leg in this effort, his death was the result of shrapnel wounds from an air bomb dropped by a German plane. He was awarded the French "Croix de guerre avec palme" for his acts of heroism. From the President of the United States, the Commander in Chief of the United States Armed Forces, he was presented with the Distinguished Service Cross and an Oak Leaf Cluster in lieu of a second Distinguished Service Cross.
Clifford Henry was the great love of Margaret Mitchell's life, according to her brother. In a letter to a friend (A. Edee, March 26, 1920), Mitchell wrote of Clifford that she had a "memory of a love that had in it no trace of physical passion".
Mitchell had vague aspirations of a career in psychiatry, but her future was derailed by an event that killed over fifty million people worldwide, the 1918 flu pandemic. On January 25, 1919, her mother, May Belle Mitchell, succumbed to pneumonia from the "Spanish flu". Mitchell arrived home from college a day after her mother had died. Knowing her death was imminent, May Belle Mitchell wrote her daughter a brief letter and advised her:
Give of yourself with both hands and overflowing heart, but give only the excess after you have lived your own life.
An average student at Smith College, Mitchell did not excel in any area of academics. She held a low estimation of her writing abilities. Even though her English professor had praised her work, she felt the praise was undue. After finishing her freshman year at Smith, Mitchell returned to Atlanta to take over the household for her father and never returned to college. In October 1919, while regaining her strength after an appendectomy, she confided to a friend that giving up college and her dreams of a "journalistic career" to keep house and take her mother's place in society meant "giving up all the worthwhile things that counted for—nothing!"
Marriage.
Margaret began using the name "Peggy" at Washington Seminary, and the abbreviated form "Peg" at Smith College when she found an icon for herself in the mythological winged horse, "Pegasus", that inspires poets. Peggy made her Atlanta society debut in the 1920 winter season. In the "gin and jazz style" of the times, she did her "flapping" in the 1920s. At a 1921 Atlanta debutante charity ball, she performed an Apache dance. The dance included a kiss with her male partner that shocked Atlanta "high society". The Apache and the Tango were scandalous dances for their elements of eroticism, the latter popularized in a 1921 silent film, "The Four Horsemen of the Apocalypse", that made its lead actor, Rudolph Valentino, a sex symbol for his ability to Tango.
Mitchell was, in her own words, an "unscrupulous flirt". She found herself engaged to five men, but maintained that she neither lied to or misled any of them. A local gossip columnist, who wrote under the name Polly Peachtree, described Mitchell's love life in a 1922 column:
...she has in her brief life, perhaps, had more men really, truly 'dead in love' with her, more honest-to-goodness suitors than almost any other girl in Atlanta.
In April 1922, Mitchell was seeing two men almost daily; one was Berrien “Red” Upshaw, whom she is thought to have met in 1917 at a dance hosted by the parents of one of her friends, and the other, Upshaw's roommate and friend, John R. Marsh, a copy editor from Kentucky who worked for the Associated Press. Upshaw was an Atlanta boy, a few months younger than Mitchell, whose family moved to Raleigh, North Carolina in 1916. In 1919 he was appointed to the United States Naval Academy, but resigned for academic deficiencies on January 5, 1920. He was readmitted in May, then 19 years old, and spent two months at sea before resigning a second time on September 1, 1920. Unsuccessful in his educational pursuits and with no job, in 1922 Upshaw earned money bootlegging alcohol out of the Georgia mountains.
Although her family disapproved, Peggy and Red married on September 2, 1922, and the best man at their wedding was John Marsh, who would become her second husband. The couple resided at the Mitchell home with her father. By December the marriage to Upshaw had dissolved and he left. Mitchell suffered physical and emotional abuse, the result of Upshaw's alcoholism and violent temper. Upshaw agreed to an uncontested divorce after John Marsh gave him a loan and Mitchell agreed not to press assault charges against him. Upshaw and Mitchell were divorced on October 16, 1924.
On July 4, 1925, 24-year-old Margaret Mitchell and 29-year-old John Marsh were married in the Unitarian-Universalist Church. The Marshes made their home at the Crescent Apartments in Atlanta, taking occupancy of Apt. 1, which they affectionately named "The Dump" (now the Margaret Mitchell House & Museum).
Reporter for "The Atlanta Journal".
While still legally married to Upshaw and needing income for herself, Mitchell got a job writing feature articles for "The Atlanta Journal Sunday Magazine". She received almost no encouragement from her family or "society" to pursue a career in journalism, and had no prior newspaper experience. Medora Field Perkerson, who hired Mitchell said:
There had been some skepticism on the Atlanta Journal Magazine staff when Peggy came to work as a reporter. Debutantes slept late in those days and didn't go in for jobs.
Her first story, "Atlanta Girl Sees Italian Revolution", by Margaret Mitchell Upshaw, appeared on December 31, 1922. She wrote on a wide range of topics, from fashions to Confederate generals and King Tut. In an article that appeared on July 1, 1923, "Valentino Declares He Isn't a Sheik", she interviewed celebrity actor Rudolph Valentino, referring to him as "Sheik" from his film role. Less thrilled by his looks than his "chief charm", his "low, husky voice with a soft, sibilant accent", she described his face as "swarthy":
His face was swarthy, so brown that his white teeth flashed in startling contrast to his skin; his eyes—tired, bored, but courteous.
Mitchell was quite thrilled when Valentino took her in his arms and carried her inside from the rooftop of the Georgian Terrace Hotel.
Many of her stories were vividly descriptive. In an article titled, "Bridesmaid of Eighty-Seven Recalls Mittie Roosevelt's Wedding", she wrote of a white-columned mansion in which lived the last surviving bridesmaid at Theodore Roosevelt's mother's wedding:
The tall white columns glimpsed through the dark green of cedar foliage, the wide veranda encircling the house, the stately silence engendered by the century-old oaks evoke memories of Thomas Nelson Page's "On Virginia". The atmosphere of dignity, ease, and courtesy that was the soul of the Old South breathes from this old mansion...
In another article, "Georgia's Empress and Women Soldiers", she wrote short sketches of four notable Georgia women. One was the first woman to serve in the United States Senate, Rebecca Latimer Felton, a suffragist who held white supremacist views. The other women were: Nancy Hart, Lucy Mathilda Kenny (also known as Private Bill Thompson of the Confederate States Army) and Mary Musgrove. The article generated mail and controversy from her readers. Mitchell received criticism for depicting "strong women who did not fit the accepted standards of femininity."
Mitchell's journalism career, which began in 1922, came to an end less than four years later; her last article appeared on May 9, 1926. Several months after marrying John Marsh, Mitchell quit due to an ankle injury that would not heal properly and chose to become a full-time wife. During the time Mitchell worked for the "Atlanta Journal", she wrote 129 feature articles, 85 news stories, and several book reviews.
Interest in erotica.
Mitchell began collecting erotica from book shops in New York City while in her twenties. She and her friends were flamboyant in 1925. The newlywed Marshes and their social group were interested in "all forms of sexual expression". Mitchell discussed her interest in "dirty" book shops and sexually explicit prose in letters to a friend, Harvey Smith. Smith noted her favorite reads were "Fanny Hill", "The Perfumed Garden" and "".
Mitchell developed an appreciation for the works of Southern writer James Branch Cabell, and his 1919 classic, "Jurgen, A Comedy of Justice". She read books about sexology, and took particular interest in the case studies of Havelock Ellis, a British physician who studied human sexuality. During this period in which Mitchell was reading pornography and sexology, she was also writing "Gone with the Wind".
Novelist.
Early works.
"Lost Laysen".
Mitchell wrote a romance novella, "Lost Laysen", when she was fifteen years old (1916). She gave "Lost Laysen", which she had written in two notebooks, to a boyfriend, Henry Love Angel. He died in 1945 and the novella remained undiscovered among some letters she had written to him until 1994. The novella was published in 1996, eighty years after it was written, and became a "New York Times" Best Seller.
In "Lost Laysen", Mitchell explores the dynamics of three male characters and their relationship to the only female character, Courtenay Ross, a strong-willed American missionary to the South Pacific island of Laysen. The narrator of the tale is Billy Duncan, "a rough, hardened soldier of fortune", who is frequently involved in fights that leave him near death. Courtenay quickly observes Duncan's hard-muscled body as he works shirtless aboard a ship called "Caliban". Courtenay's suitor is Douglas Steele, an athletic man who apparently believes Courtenay is helpless without him. He follows Courtenay to Laysen to protect her from perceived foreign savages. The third male character is the rich, powerful yet villainous Juan Mardo. He leers at Courtenay and makes rude comments of a sexual nature, in Japanese nonetheless. Mardo provokes Duncan and Steele, and each feels he must defend Courtenay's honor. Ultimately Courtenay defends her own honor rather than submit to shame.
In a gender reversal, the woman writer (Mitchell) narrates "Lost Laysen" through a heroic male character, Billy Duncan. Mitchell's half-breed
antagonist, Juan Mardo, lurks in the shadows of the story and has no dialogue. The reader learns of Mardo's evil intentions through Duncan:
They were saying that Juan Mardo had his eye on you—and intended to have you—any way he could get you!
Mardo's desires are similar to those of Rhett Butler in his ardent pursuit of Scarlett O'Hara in Mitchell's epic novel, "Gone with the Wind". Rhett tells Scarlett:
I always intended having you, one way or another.
The "other way" is rape. In "Lost Laysen" the male seducer is replaced with the male rapist.
"The Big Four".
In Mitchell's teenage years, she is known to have written a 400-page novel about girls in a boarding school, "The Big Four". The novel is thought to be lost; Mitchell destroyed some of her manuscripts herself and others were destroyed after her death.
'"Ropa Carmagin".
In the 1920s Mitchell completed a novelette, '"Ropa Carmagin", about a Southern white girl who loves a biracial man. Mitchell submitted the manuscript to Macmillan Publishers in 1935 along with her manuscript for "Gone with the Wind". The novelette was rejected; Macmillan thought the story was too short for book form.
Final work.
Writing "Gone with the Wind".
In May 1926, after Mitchell had left her job at the "Atlanta Journal" and was recovering at home from her ankle injury, she wrote a society column for the "Sunday Magazine", "Elizabeth Bennet's Gossip", which she continued to write until August. Meanwhile, her husband was growing weary of lugging armloads of books home from the library to keep his wife's mind occupied while she hobbled around the house; he emphatically suggested that she write her own book instead:
For God's sake, Peggy, can't you write a book instead of reading thousands of them?
To aid her in her literary endeavors, John Marsh brought home a Remington Portable No. 3 typewriter (c. 1928). For the next three years Mitchell worked exclusively on writing a Civil War-era novel whose heroine was named Pansy O'Hara (prior to publication Pansy was changed to Scarlett). She used parts of the manuscript to prop up a wobbly couch.
World War II.
During World War II, Margaret Mitchell was a volunteer for the American Red Cross and she raised money for the war effort by selling war bonds. She was active in Home Defense, sewed hospital gowns and put patches on trousers. Her personal attention, however, was devoted to writing letters to men in uniform—soldiers, sailors and marines, sending them humor, encouragement, and her sympathy.
The USS "Atlanta" (CL-51) was an anti-aircraft ship of the United States Navy sponsored by Margaret Mitchell and used in the naval Battle of Midway and the Eastern Solomons. The ship was struck and sunk in night surface action on November 13, 1942 during the Naval Battle of Guadalcanal.
Mitchell sponsored a second cruiser named after the city of Atlanta, USS "Atlanta" (CL-104). On February 6, 1944, she christened "Atlanta" in Camden, New Jersey. "Atlanta" was operating off the coast of Honshū when the Japanese surrendered on August 15, 1945. It was sunk during an explosive test off San Clemente Island on October 1, 1970.
Death.
Margaret Mitchell was struck by a speeding automobile as she crossed Peachtree Street at 13th Street in Atlanta with her husband, John Marsh, while on her way to see the movie "A Canterbury Tale" on the evening of August 11, 1949. She died at Grady Hospital five days later without fully regaining consciousness.
The driver, Hugh Gravitt, was an off-duty taxi driver who was driving his personal vehicle when he struck Mitchell. After the accident, Gravitt was arrested for drunken driving and released on a $5,450 bond until Mitchell's death.
Gravitt was originally charged with drunken driving, speeding, and driving on the wrong side of the road. He was convicted of involuntary manslaughter in November 1949 and sentenced to 18 months in jail. He served almost 11 months. Gravitt died in 1994 at the age of 73.
Legacy.
Perhaps the most enduring legacy of "Gone with the Wind" is that people worldwide would incorrectly think it was the true story of the Old South and how it was changed by the American Civil War and Reconstruction. The film version of the novel "amplified this effect". Scholars of the period have written in recent years about the negative effects the novel has had on race relations by its resurrection of Lost Cause mythology.

</doc>
<doc id="20866" url="https://en.wikipedia.org/wiki?curid=20866" title="Metamorphosis">
Metamorphosis

Metamorphosis is a biological process by which an animal physically develops after birth or hatching, involving a conspicuous and relatively abrupt change in the animal's body structure through cell growth and differentiation. Some insects, fishes, amphibians, mollusks, crustaceans, cnidarians, echinoderms and tunicates undergo metamorphosis, which is often accompanied by a change of nutrition source or behavior. Animals can be divided into species that undergo complete metamorphosis ("holometaboly"), incomplete metamorphosis ("hemimetaboly"), or no metamorphosis ("ametaboly").
Scientific usage of the term is technically precise, and is not applied to general aspects of cell growth, including rapid growth spurts. References to "metamorphosis" in mammals are imprecise and only colloquial, but historically idealist ideas of transformation and monadology, as in Goethe's "Metamorphosis of Plants", have influenced the development of ideas of evolution.
Etymology.
The word "metamorphosis" derives from Greek , "transformation, transforming", from ('), "change" and ('), "form".
Insect metamorphosis.
All three forms of metamorphosis can be found in the diversity of insects, including no metamorphosis ("ametaboly"), incomplete or partial metamorphosis ("hemimetaboly"), and complete metamorphosis ("holometaboly"). While ametabolous insects show very little difference between larval and adult forms (also known as "direct development"), both hemimetabolous and holometabolous insects have significant morphological and behavioral differences between larval and adult forms, the most significant being the inclusion, in holometabolus organisms, of a pupal or resting stage between the larval and adult forms.
Development and terminology.
In hemimetabolous insects, immature stages are called nymphs. Development proceeds in repeated stages of growth and ecdysis (moulting); these stages are called instars. The juvenile forms closely resemble adults, but are smaller and lack adult features such as wings and genitalia. The size and morphological differences between nymphs in different instars are small, often just differences in body proportions and the number of segments; in later instars, external wing buds form.
In holometabolous insects, immature stages are called larvae, and differ markedly from adults. Insects which undergo holometabolism pass through a larval stage, then enter an inactive state called pupa (called a "chrysalis" in butterfly species), and finally emerge as adults.
Evolution.
The earliest insect forms showed direct development (ametaboly), and the evolution of metamorphosis in insects is thought to have fuelled their dramatic radiation (1,2). Some early ametabolous "true insects" are still present today, such as bristletails and silverfish. Hemimetabolous insects include cockroaches, grasshoppers, dragonflies, and true bugs. Phylogenetically, all insects in the Pterygota undergo a marked change in form, texture and physical appearance from immature stage to adult. These insects either have hemimetabolous development, and undergo an incomplete or partial metamorphosis, or holometabolous development, which undergo a complete metamorphosis, including a pupal or resting stage between the larval and adult forms.
A number of hypotheses have been proposed to explain the evolution of holometaboly from hemimetaboly, mostly centering on whether or not the intermediate hemimetabolous forms are homologous to pupal form of holometabolous forms.
More recently, scientific attention has turned to characterizing the mechanistic basis of metamorphosis in terms of its hormonal control, by characterizing spatial and temporal patterns of hormone expression relative to metamorphosis in a wide range of insects.
Other.
According to recent research, adult "Manduca sexta" is able to retain behavior learned as a caterpillar. Another caterpillar, the Ornate Moth caterpillar, is able to carry toxins that it acquires from its diet through metamorphosis and into adulthood, where the toxins still serve for protection against predators.
Many observations have indicated that programmed cell death plays a considerable role during physiological processes of multicellular organisms, particularly during embryogenesis and metamorphosis.
Hormonal control.
Insect growth and metamorphosis are controlled by hormones synthesized by endocrine glands near the front of the body (anterior). Neurosecretory cells in an insect's brain secrete a hormone, the prothoracicotropic hormone (PTTH) that activates prothoracic glands, which secrete a second hormone, usually Ecdysone (an ecdysteroid), that induces ecdysis.
PTTH also stimulates the corpora allata, a retrocerebral organ, to produce juvenile hormone (JH), which prevents the development of adult characteristics during ecdysis. In holometabolous insects, molts between larval instars have a high level of JH, the moult to the pupal stage has a low level of JH, and the final, or imaginal, molt has no JH present at all. Experiments on firebugs have also shown how JH can affect the number of nymph instar stages in hemimetabolous insects.
Amphibian metamorphosis.
In typical amphibian development, eggs are laid in water and larvae are adapted to an aquatic lifestyle. Frogs, toads, and newts all hatch from the eggs as larvae with external gills but it will take some while for the amphibians to interact outside with pulmonary respiration. Afterwards, newt larvae start a predatory lifestyle, while tadpoles mostly scrape food off surfaces with their horny tooth ridges.
Metamorphosis in amphibians is regulated by thyroxin concentration in the blood, which stimulates metamorphosis, and prolactin, which counteracts its effect. Specific events are dependent on threshold values for different tissues. Because most embryonic development is outside the parental body, development is subject to many adaptations due to specific ecological circumstances. For this reason tadpoles can have horny ridges for teeth, whiskers, and fins. They also make use of the lateral line organ. After metamorphosis, these organs become redundant and will be resorbed by controlled cell death, called apoptosis. The amount of adaptation to specific ecological circumstances is remarkable, with many discoveries still being made.
Frogs and toads.
With frogs and toads, the external gills of the newly hatched tadpole are covered with a gill sac after a few days, and lungs are quickly formed. Front legs are formed under the gill sac, and hindlegs are visible a few days later. Following that there is usually a longer stage during which the tadpole lives off a vegetarian diet. Tadpoles use a relatively long, spiral‐shaped gut to digest that diet.
Rapid changes in the body can then be observed as the lifestyle of the frog changes completely. The spiral‐shaped mouth with horny tooth ridges is resorbed together with the spiral gut. The animal develops a big jaw, and its gills disappear along with its gill sac. Eyes and legs grow quickly, a tongue is formed, and all this is accompanied by associated changes in the neural networks (development of stereoscopic vision, loss of the lateral line system, etc.) All this can happen in about a day, so it is truly a metamorphosis. It is not until a few days later that the tail is reabsorbed, due to the higher thyroxin concentrations required for tail resorption.
Salamanders.
Salamander development is highly diverse; some species go through a dramatic reorganization when transitioning from aquatic larvae to terrestrial adults, while others, such as the Axolotl, display paedomorphosis and never develop into terrestrial adults. Within the genus "Ambystoma", species have evolved to be paedomorphic several times, and paedomorphosis and complete development can both occur in some species.
Newts.
In newts, there is no true metamorphosis because newt larvae already feed as predators and continue doing so as adults. Newts' gills are never covered by a gill sac and will be resorbed only just before the animal leaves the water. Just as in tadpoles, their lungs are functional early, but newts use them less frequently than tadpoles. Newts often have an aquatic phase in spring and summer, and a land phase in winter. For adaptation to a water phase, prolactin is the required hormone, and for adaptation to the land phase, thyroxin. External gills do not return in subsequent aquatic phases because these are completely absorbed upon leaving the water for the first time.
Caecilians.
Basal caecilians such as "Ichthyophis" go through a metamorphosis in which aquatic larva transition into fossorial adults, which involves a loss of the lateral line. More recently diverged caecilians (the Teresomata) do not undergo an ontogenetic niche shift of this sort and are in general fossorial throughout their lives. Thus, most caecilians do not undergo an anuran-like metamorphosis.
Metamorphosis in fish.
Some fish, both bony fish (Osteichthyes) and jawless fish (Agnatha), undergo metamorphosis. Fish metamorphosis is typically under strong control by the thyroid hormone.
Examples among the non-bony fish include the lamprey. Among the bony fish, mechanisms are varied.
The salmon is diadromous, meaning that it changes from a freshwater to a saltwater lifestyle.
Many species of flatfish begin their life bilaterally symmetrical, with an eye on either side of the body; but one eye moves to join the other side of the fish - which becomes the upper side - in the adult form.
The European eel has a number of metamorphoses, from the larval stage to the leptocephalus stage, then a quick metamorphosis to glass eel at the edge of the continental shelf (8 days for the Japanese eel), two months at the border of fresh and salt water where the glass eel undergoes a quick metamorphosis into elver, then a long stage of growth followed by a more gradual metamorphosis to the migrating phase. In the pre-adult freshwater stage, the eel also has phenotypic plasticity because fish-eating eels develop very wide mandibles, making the head look blunt. Leptocephali are common, occurring in all Elopomorpha (Tarpon- and eel-like fish).
Most other bony fish undergo metamorphosis from embryo to larva (fry) and then to the juvenile stage during absorption of the yolk sac, because after that phase the individual needs to be able to feed for itself.

</doc>
<doc id="20869" url="https://en.wikipedia.org/wiki?curid=20869" title="Monoamine oxidase inhibitor">
Monoamine oxidase inhibitor

Monoamine oxidase inhibitors (MAOIs) are chemicals which inhibit the activity of the monoamine oxidase enzyme family. They have a long history of use as medications prescribed for the treatment of depression. They are particularly effective in treating atypical depression. They are also used in the treatment of Parkinson's disease and several other disorders.
Because of potentially lethal dietary and drug interactions, monoamine oxidase inhibitors have historically been reserved as a last line of treatment, used only when other classes of antidepressant drugs (for example selective serotonin reuptake inhibitors and tricyclic antidepressants) have failed. New research into MAOIs indicates that much of the concern over their dangerous dietary side effects stems from misconceptions and misinformation, and that despite proven effectiveness of this class of drugs, it is underutilized and misunderstood in the medical profession. 
New research also questions the validity of the perceived severity of dietary reactions, which has historically been based on outdated research.
However this research also notes that many practitioners have a poor understanding of drug interactions, and 'drug interactions can be serious, and concomitant medication use must be stringently overseen' as they 'can cause a dangerous or fatal serotonin syndrome/ toxicity'.
Indications.
Newer MAOIs such as selegiline (typically used in the treatment of Parkinson's disease) and the reversible MAOI moclobemide provide a safer alternative and are now sometimes used as first-line therapy.
MAOIs have been found to be effective in the treatment of panic disorder with agoraphobia, social phobia, atypical depression or mixed anxiety and depression, bulimia, and post-traumatic stress disorder, as well as borderline personality disorder. MAOIs appear to be particularly effective in the management of bipolar depression according to a recent retrospective-analysis. There are reports of MAOI efficacy in obsessive-compulsive disorder (OCD), trichotillomania, dysmorphophobia, and avoidant personality disorder, but these reports are from uncontrolled case reports.
MAOIs can also be used in the treatment of Parkinson's disease by targeting MAO-B in particular (therefore affecting dopaminergic neurons), as well as providing an alternative for migraine prophylaxis. Inhibition of both MAO-A and MAO-B is used in the treatment of clinical depression and anxiety.
MAOIs appear to be particularly indicated for outpatients with dysthymia complicated by panic disorder or hysteroid dysphoria, which involves repeated episodes of depressed mood in response to feeling rejected.
Mechanism of action.
MAOIs act by inhibiting the activity of monoamine oxidase, thus preventing the breakdown of monoamine neurotransmitters and thereby increasing their availability. There are two isoforms of monoamine oxidase, MAO-A and MAO-B. MAO-A preferentially deaminates serotonin, melatonin, epinephrine, and norepinephrine. MAO-B preferentially deaminates phenethylamine and certain other trace amines; in contrast, MAO-A preferentially deaminates other trace amines, like tyramine, whereas dopamine is equally deaminated by both types.
Reversibility.
The early MAOIs covalently bound to the monoamine oxidase enzymes, thus inhibiting them irreversibly; the bound enzyme could not function and thus enzyme activity was blocked until the cell made new enzymes. The enzymes turn over approximately every two weeks. A few newer MAOIs, a notable one being moclobemide, are reversible, meaning that they are able to detach from the enzyme to facilitate usual catabolism of the substrate. The level of inhibition in this way is governed by the concentrations of the substrate and the MAOI.
Harmaline found in "Peganum harmala", "Banisteriopsis caapi", and "Passiflora incarnata" is a reversible inhibitor of monoamine oxidase A (RIMA).
Selectivity.
In addition to reversibility, MAOIs differ by their selectivity of the MAO receptor. Some MAOIs inhibit both MAO-A and MAO-B equally, other MAOIs have been developed to target one over the other.
MAO-A inhibition reduces the breakdown of primarily serotonin, norepinephrine, and dopamine; selective inhibition of MAO-A allows for tyramine to be metabolised via MAO-B. Agents that act on serotonin if taken with another serotonin-enhancing agent may result in a potentially fatal interaction called serotonin syndrome or with irreversible and unselective inhibitors (such as older MAOIs), of MAO a hypertensive crisis as a result of tyramine food interactions is particularly problematic with older MAOIs. Tyramine is broken down by MAO-A and MAO-B, therefore inhibiting this action may result in its excessive build-up, so diet must be monitored for tyramine intake.
MAO-B inhibition reduces the breakdown mainly of dopamine and phenethylamine so there are no dietary restrictions associated with this. MAO-B would also metabolize tyramine, as the only differences between dopamine, phenethylamine, and tyramine are two phenylhydroxyl groups on carbons 3 and 4. The 4-OH would not be a steric hindrance to MAO-B on tyramine. Two MAO-Bi drugs, selegiline and rasagiline have been approved by the FDA without dietary restrictions, except in high-dosage treatment, wherein they lose their selectivity.
Dangers.
Hypertensive Crisis & Tyramine.
Patients taking MAOIs generally need to change their diets to limit or avoid foods and beverages containing tyramine. If large amounts of tyramine are consumed, they may suffer hypertensive crisis, which can be fatal. Examples of foods and beverages with potentially high levels of tyramine include liver and fermented substances, such as alcoholic beverages and aged cheeses. (See a List of foods containing tyramine).
Tyramine leads to hypertensive crisis by increasing the release of norepinephrine (NE), which causes blood vessels to constrict (through binding to alpha-1 adrenergic receptors). Ordinarily, MAO-A would destroy the excess NE. When MAO-A is inhibited, though, NE levels get too high, leading to dangerous increases in blood pressure.
Of note, no dietary modifications are needed when taking a reversible inhibitor of MAO-A (i.e., moclobemide) or low doses of selective MAO-B inhibitors (e.g., selegiline 6 mg/24 hours transdermal patch).
Drug Interactions.
The most significant risk associated with the use of MAOIs is the potential for interactions with over-the-counter and prescription medicines, illicit drugs or medications, and some dietary supplements (e.g., St. John's wort, tryptophan). It is vital that a doctor supervise such combinations to avoid adverse reactions. For this reason, many users carry an MAOI-card, which lets emergency medical personnel know what drugs to avoid. (E.g., adrenaline dosage should be reduced by 75%, and duration is extended.)
Tryptophan supplements should not be consumed with MAOIs as the potentially fatal serotonin syndrome may result.
MAOIs should not be combined with other psychoactive substances (antidepressants, painkillers, stimulants, both legal and illegal etc.) except under expert care. Certain combinations can cause lethal reactions, common examples including SSRIs, tricyclics, MDMA, meperidine, tramadol, and dextromethorphan. Agents with actions on epinephrine, norepinephrine, or dopamine must be administered at much lower doses due to potentiation and prolonged effect.
Nicotine, the substance most implicated in tobacco addiction, has been shown to have "relatively weak" addictive properties when administered alone. The addictive potential increases dramatically after co-administration of an MAOI, which specifically causes sensitization of the locomotor response in rats, a measure of addictive potential. This may be reflected in the difficulty of smoking cessation, as tobacco contains naturally-occurring MAOI compounds in addition to the nicotine.
Withdrawal.
Antidepressants including MAOIs have some dependence-producing effects, the most notable one being a withdrawal syndrome, which may be severe especially if MAOIs are discontinued abruptly or overly rapidly. However, the dependence-producing potential of MAOIs or antidepressants in general is not as significant as benzodiazepines. Withdrawal symptoms can be managed by a gradual reduction in dosage over a period of weeks, months or years to minimize or prevent withdrawal symptoms.
MAOIs, as with any antidepressant medications, do not alter the course of the disorder, so it is possible that discontinuation can return the patient to the pre-treatment state.
This consideration greatly complicates switching a patient between a MAOI and a SSRI, because it is necessary to clear the system completely of one drug before starting another. If one also tapers dosage gradually, the result is that for weeks a depressed patient will have to bear the depression without chemical help during the drug-free interval. This may be preferable to risking the effects of an interaction between the two drugs, but it is often not easy for the patient.
Listing of interactions.
The MAOIs are infamous for their numerous drug interactions, including the following kinds of substances:
Such substances that can react with MAOIs include:
History.
MAOIs started off due to the serendipitous discovery that iproniazid was a weak MAO inhibitor (MAOI). Originally intended for the treatment of tuberculosis, in 1952, iproniazid antidepressant properties were discovered when researchers noted that the depressed patients given iproniazid experienced a relief of their depression. Subsequent in vitro work led to the discovery that it inhibited MAO and eventually to the monoamine theory of depression. MAOIs became widely used as antidepressants in the early 1950s. The discovery of the 2 isoenzymes of MAO has led to the development of selective MAOIs that may have a more favorable side-effect profile.
The older MAOIs' heyday was mostly between the years 1957 and 1970. The initial popularity of the 'classic' non-selective irreversible MAO inhibitors began to wane due to their serious interactions with sympathomimetic drugs and tyramine-containing foods that could lead to dangerous hypertensive emergencies. As a result, the use by medical practitioners of these older MAOIs declined. When scientists discovered that there are two different MAO enzymes (MAO-A and MAO-B), they developed selective compounds for MAO-B, (for example, selegiline, which is used for Parkinson's disease), to reduce the side-effects and serious interactions. Further improvement occurred with the development of compounds (moclobemide and toloxatone) that not only are selective but cause reversible MAO-A inhibition and a reduction in dietary and drug interactions. Moclobemide, was the first reversible inhibitor of MAO-A to enter widespread clinical practice.
A transdermal patch form of the MAOI selegiline, called Emsam, was approved for use in depression by the Food and Drug Administration in the United States on February 28, 2006.
List of MAO inhibiting drugs.
Marketed drugs.
Linezolid is an antibiotic drug with weak MAO-inhibiting activity.
Methylene blue, the antidote indicated for drug-induced methemoglobinemia, among a plethora of other off-label uses, is a highly potent, reversible MAO inhibitor.

</doc>
<doc id="20872" url="https://en.wikipedia.org/wiki?curid=20872" title="Mother Superior">
Mother Superior

A mother superior is an abbess, prioress or other nun in charge of a Christian religious order or congregation, a convent or house of women under vows.
Mother superior may also refer to:

</doc>
<doc id="20874" url="https://en.wikipedia.org/wiki?curid=20874" title="Mycology">
Mycology

Mycology is the branch of biology concerned with the study of fungi, including their genetic and biochemical properties, their taxonomy and their use to humans as a source for tinder, medicine, food, and entheogens, as well as their dangers, such as poisoning or infection. A biologist specializing in mycology is called a mycologist.
From mycology arose the field of phytopathology, the study of plant diseases, and the two disciplines remain closely related because the vast majority of "plant" pathogens are fungi.
Historically, mycology was a branch of botany because, although fungi are evolutionarily more closely related to animals than to plants, this was not recognized until a few decades ago. Pioneer "mycologists" included Elias Magnus Fries, Christian Hendrik Persoon, Anton de Bary, and Lewis David von Schweinitz.
Many fungi produce toxins, antibiotics, and other secondary metabolites. For example, the cosmopolitan (worldwide) genus "Fusarium" and their toxins associated with fatal outbreaks of alimentary toxic aleukia in humans were extensively studied by Abraham Joffe.
Fungi are fundamental for life on earth in their roles as symbionts, e.g. in the form of mycorrhizae, insect symbionts, and lichens. Many fungi are able to break down complex organic biomolecules such as lignin, the more durable component of wood, and pollutants such as xenobiotics, petroleum, and polycyclic aromatic hydrocarbons. By decomposing these molecules, fungi play a critical role in the global carbon cycle.
Fungi and other organisms traditionally recognized as fungi, such as oomycetes and myxomycetes (slime molds), often are economically and socially important, as some cause diseases of animals (such as histoplasmosis) as well as plants (such as Dutch elm disease and Rice blast).
Field meetings to find interesting species of fungi are known as 'forays', after the first such meeting organized by the Woolhope Naturalists' Field Club in 1868 and entitled "A foray among the funguses"["sic"].
Some fungi can cause disease in humans or other organisms. The study of pathogenic fungi is referred to as medical mycology.
History.
It is presumed that humans started collecting mushrooms as food in Prehistoric times. Mushrooms were first written about in the works of Euripides (480-406 B.C.). The Greek philosopher Theophrastos of Eressos (371-288 B.C.) was perhaps the first to try to systematically classify plants; mushrooms were considered to be plants missing certain organs. It was later Pliny the elder (23–79 A.D.), who wrote about truffles in his encyclopedia Naturalis historia. The word "mycology" comes from the Greek: μύκης ("mukēs"), meaning "fungus" and the suffix ("-logia"), meaning "study".
The Middle Ages saw little advancement in the body of knowledge about fungi. Rather, the invention of the printing press allowed some authors to disseminate superstitions and misconceptions about the fungi that had been perpetuated by the classical authors.
The start of the modern age of mycology begins with Pier Antonio Micheli's 1737 publication of "Nova plantarum genera". Published in Florence, this seminal work laid the foundations for the systematic classification of grasses, mosses and fungi. The term "mycology" and the complementary "mycologist" were first used in 1836 by M.J. Berkeley.
Medical mycology.
For centuries, certain mushrooms have been documented as a folk medicine in China, Japan, and Russia. Although the use of mushrooms in folk medicine is centered largely on the Asian continent, people in other parts of the world like the Middle East, Poland, and Belarus have been documented using mushrooms for medicinal purposes. Certain mushrooms, especially polypores like Reishi were thought to be able to benefit a wide variety of health ailments. Medicinal mushroom research in the United States is currently active, with studies taking place at City of Hope National Medical Center, as well as the Memorial Sloan–Kettering Cancer Center.
Current research focuses on mushrooms that may have hypoglycemic activity, anti-cancer activity, anti-pathogenic activity, and immune system-enhancing activity. Recent research has found that the oyster mushroom naturally contains the cholesterol-lowering drug lovastatin, mushrooms produce large amounts of vitamin D when exposed to UV light, and that certain fungi may be a future source of taxol. To date, penicillin, lovastatin, ciclosporin, griseofulvin, cephalosporin, ergometrine, and statins are the most famous pharmaceuticals that have been isolated from the fungi kingdom.

</doc>
<doc id="20875" url="https://en.wikipedia.org/wiki?curid=20875" title="Melancholia">
Melancholia

Black bile (, '), also lugubriousness, from the Latin "lugere", to mourn; moroseness, from the Latin "morosus", self-willed, fastidious habit; wistfulness, from old English "wist": intent, or saturnine'", was a concept in ancient and pre-modern medicine. Melancholy was one of the four temperaments matching the four humours. In the 19th century, "melancholia" could be physical as well as mental, and melancholic conditions were classified as such by their common cause rather than by their properties.
History.
The name "melancholia" comes from the old medical belief of the four humours: disease or ailment being caused by an imbalance in one or other of the four basic bodily liquids, or humours. Personality types were similarly determined by the dominant humor in a particular person. According to Hippocrates and subsequent tradition, melancholia was caused by an excess of black bile, hence the name, which means "black bile", from Ancient Greek μέλας ("melas"), "dark, black", and χολή ("kholé"), "bile"; a person whose constitution tended to have a preponderance of black bile had a "melancholic" disposition. In the complex elaboration of humorist theory, it was associated with the earth from the Four Elements, the season of autumn, the spleen as the originating organ and cold and dry as related qualities. In astrology it showed the influence of Saturn, hence the related adjective "saturnine".
Melancholia was described as a distinct disease with particular mental and physical symptoms in the 5th and 4th centuries BC. Hippocrates, in his "Aphorisms", characterized all "fears and despondencies, if they last a long time" as being symptomatic of melancholia. When a patient could not be cured of the disease it was thought that the melancholia was a result of demonic possession.
In his study of French and Burgundian courtly culture, Johan Huizinga noted that "at the close of the Middle Ages, a sombre melancholy weighs on people's souls." In chronicles, poems, sermons, even in legal documents, an immense sadness, a note of despair and a fashionable sense of suffering and deliquescence at the approaching end of times, suffuses court poets and chroniclers alike: Huizinga quotes instances in the ballads of Eustache Deschamps, "monotonous and gloomy variations of the same dismal theme", and in Georges Chastellain's prologue to his Burgundian chronicle, and in the late fifteenth-century poetry of Jean Meschinot. Ideas of reflection and the workings of imagination are blended in the term "merencolie", embodying for contemporaries "a tendency", observes Huizinga, "to identify all serious occupation of the mind with sadness".
Painters were considered by Vasari and other writers to be especially prone to melancholy by the nature of their work, sometimes with good effects for their art in increased sensitivity and use of fantasy. Among those of his contemporaries so characterised by Vasari were Pontormo and Parmigianino, but he does not use the term of Michelangelo, who used it, perhaps not very seriously, of himself. A famous allegorical engraving by Albrecht Dürer is entitled "Melencolia I". This engraving has been interpreted as portraying melancholia as the state of waiting for inspiration to strike, and not necessarily as a depressive affliction. Amongst other allegorical symbols, the picture includes a magic square and a truncated rhombohedron. The image in turn inspired a passage in "The City of Dreadful Night" by James Thomson (B.V.), and, a few years later, a sonnet by Edward Dowden.
The most extended treatment of melancholia comes from Robert Burton, whose "The Anatomy of Melancholy" (1621) treats the subject from both a literary and a medical perspective. Burton wrote in the 17th century that music and dance were critical in treating mental illness, especially melancholia.
In the Encyclopédie of Diderot and d'Alembert, the causes of melancholia are stated to be similar to those that cause Mania: "grief, pains of the spirit, passions, as well as all the love and sexual appetites that go unsatisfied."
Art movement.
During the later 16th and early 17th centuries, a curious cultural and literary cult of melancholia arose in England. In an influential 1964 essay in Apollo, art historian Roy Strong traced the origins of this fashionable melancholy to the thought of the popular Neoplatonist and humanist Marsilio Ficino (1433–1499), who replaced the medieval notion of melancholia with something new: 
"The Anatomy of Melancholy" ("The Anatomy of Melancholy, What it is: With all the Kinds, Causes, Symptomes, Prognostickes, and Several Cures of it... Philosophically, Medicinally, Historically, Opened and Cut Up") by Burton, was first published in 1621 and remains a defining literary monument to the fashion. Another major English author who made extensive expression upon being of an melancholic disposition is Sir Thomas Browne in his Religio Medici (1643).
"Night-Thoughts" ("The Complaint: or, Night-Thoughts on Life, Death, & Immortality"), a long poem in blank verse by Edward Young was published in nine parts (or "nights") between 1742 and 1745, and hugely popular in several languages. It had a considerable influence on early Romantics in England, France and Germany. William Blake was commissioned to illustrate a later edition.
In the visual arts, this fashionable intellectual melancholy occurs frequently in portraiture of the era, with sitters posed in the form of "the lover, with his crossed arms and floppy hat over his eyes, and the scholar, sitting with his head resting on his hand"—descriptions drawn from the frontispiece to the 1638 edition of Burton's "Anatomy", which shows just such by-then stock characters. These portraits were often set out of doors where Nature provides "the most suitable background for spiritual contemplation" or in a gloomy interior.
In music, the post-Elizabethan cult of melancholia is associated with John Dowland, whose motto was "Semper Dowland, semper dolens" ("Always Dowland, always mourning"). The melancholy man, known to contemporaries as a "malcontent", is epitomized by Shakespeare's Prince Hamlet, the "Melancholy Dane".
A similar phenomenon, though not under the same name, occurred during the German Sturm und Drang movement, with such works as "The Sorrows of Young Werther" by Goethe or in Romanticism with works such as "Ode on Melancholy" by John Keats or in Symbolism with works such as "Isle of the Dead" by Arnold Böcklin. In the 20th century, much of the counterculture of modernism was fueled by comparable alienation and a sense of purposelessness called "anomie"; earlier artistic preoccupation with death has gone under the rubric of memento mori. The medieval condition of acedia ("acedie" in English) and the Romantic Weltschmerz were similar concepts, most likely to affect the intellectual.

</doc>
<doc id="20876" url="https://en.wikipedia.org/wiki?curid=20876" title="Mimosa">
Mimosa

Mimosa is a genus of about 400 species of herbs and shrubs, in the subfamily Mimosoideae of the legume family Fabaceae. The generic name is derived from the Greek word ("mimos"), an "actor" or "mime," and the feminine suffix -"osa", "resembling", suggesting its 'sensitive leaves' which seem to 'mimic conscious life'.
Two species in the genus are especially notable. One is "Mimosa pudica", because of the way it folds its leaves when touched or exposed to heat. It is native to southern Central and South America but is widely cultivated elsewhere for its curiosity value, both as a houseplant in temperate areas, and outdoors in the tropics. Outdoor cultivation has led to weedy invasion in some areas, notably Hawaii. The other is "Mimosa tenuiflora", which is best known for its use in shamanic ayahuasca brews due to the psychedelic drug dimethyltryptamine found in its root bark.
Taxonomy.
The taxonomy of the genus "Mimosa" has had a tortuous history, having gone through periods of splitting and lumping, ultimately accumulating over 3,000 names, many of which have either been synonymized under other species or transferred to other genera. In part due to these changing circumscriptions, the name "Mimosa" has also been applied to several other related species with similar pinnate or bipinnate leaves, but are now classified in other genera. The most common examples of this are "Albizia julibrissin" (silk tree) and "Acacia dealbata" (wattle).
Description.
Members of this genus are among the few plants capable of rapid movement; examples outside of "Mimosa" include the telegraph plant, Aldrovanda, some species of Drosera and the famous venus flytrap. The leaves of the Mimosa pudica close quickly when touched. Some mimosas raise their leaves in day and lower them at night, and experiments done by Jacques d'Ortous de Mairan on mimosas in 1729 provided the first evidence of biological clocks. 
"Mimosa" can be distinguished from the large related genera, "Acacia" and "Albizia", since its flowers have 10 or fewer stamens. Note that, botanically, what appears to be a single globular flower is actually a cluster of many individual ones. Mimosa contains some level of heptanoic acid.
Species.
There are about 400 species including:

</doc>
<doc id="20878" url="https://en.wikipedia.org/wiki?curid=20878" title="Martini">
Martini

Martini may refer to:

</doc>
<doc id="20879" url="https://en.wikipedia.org/wiki?curid=20879" title="Manhattan (cocktail)">
Manhattan (cocktail)

A Manhattan is a cocktail made with whiskey, sweet vermouth, and bitters. Commonly used whiskeys include rye (the traditional choice), Canadian whisky, bourbon, blended whiskey, and Tennessee whiskey. The cocktail is often stirred and strained into a cocktail glass, where it is garnished with a Maraschino cherry with a stem. A Manhattan can also be served on the rocks in a lowball glass. The whiskey-based Manhattan is one of five cocktails named for one of New York City's five boroughs, but is perhaps most closely related to the Brooklyn cocktail, a mix utilizing dry vermouth and Maraschino liqueur in place of the Manhattan's sweet vermouth, as well as Amer Picon in place of the Manhattan's traditional bitters.
The Manhattan is one of six basic drinks listed in David A. Embury's classic "The Fine Art of Mixing Drinks".
Origin and history.
A popular history suggests that the drink originated at the Manhattan Club in New York City in the early 1870s, where it was invented by Dr. Iain Marshall for a banquet hosted by Jennie Jerome (Lady Randolph Churchill, mother of Winston) in honor of presidential candidate Samuel J. Tilden. The success of the banquet made the drink fashionable, later prompting several people to request the drink by referring to the name of the club where it originated—"the "Manhattan" cocktail". However, Lady Randolph was in France at the time and pregnant, so the story is likely a fiction.
However, there are prior references to various similar cocktail recipes called "Manhattan" and served in the Manhattan area. By one account it was invented in the 1860s by a bartender named Black at a bar on Broadway near Houston Street.
The original "Manhattan cocktail" was a mix of "American Whiskey, Italian Vermouth and Angostura bitters". During Prohibition (1920–1933) Canadian whisky was primarily used because it was available.
An early record of the cocktail can be found in William Schmidt's "The Flowing Bowl", published in 1891. In it, he details a drink containing 2 dashes of gum (gomme syrup), 2 dashes of bitters, 1 dash of absinthe, 2/3 portion of whiskey and 1/3 portion of vermouth.
The same cocktail appears listed as a "Tennessee Cocktail" in "Shake 'em Up!" by V. Elliott and P. Strong, copyright 1930 (p. 39): "Two parts of whiskey, one part of Italian Vermouth and a dash of bitters poured over ice and stirred vigorously."
Traditions.
On the small North Frisian island of Föhr, the Manhattan cocktail is a standard drink at almost every cafe restaurant, and "get together" of locals. The story goes, that many of the people of Föhr emigrated to Manhattan during deep sea fishing trips, took a liking to the drink, and brought it back to Föhr with them. The drink is usually mixed 1 part (the 'perfect' is said to be half white/half red) vermouth to 2 parts whiskey, with a dash of bitters, served ice cold, in an ice cold glass, or with ice and a cherry garnish.
There is a mistaken belief that Manhattans are always stirred and never shaken, primarily to avoid persistent foaming. However such foaming now indicates either dirty equipment or less than premium quality ingredients. Traditions for both preparations go back to the late 1800s.
Variations.
Traditional views insist that a Manhattan be made with American rye whiskey. However, more often than not, it is made with bourbon or Canadian whisky. The Manhattan is subject to considerable variation and innovation, and is often a way for the best bartenders to show off their creativity. Some shake the ingredients with ice in a cocktail shaker instead of stirring it, creating a froth on the surface of the drink. Angostura is the classic bitters, but orange bitters, Peychaud's Bitters, may be used. Some make their own bitters and syrups, substitute comparable digestifs in place of vermouth, specialize in local or rare whiskeys, or use other exotic ingredients. A lemon peel may be used as garnish. Some add juice from the cherry jar or Maraschino liqueur to the cocktail for additional sweetness and color.
Originally, bitters were considered an integral part of any cocktail, as the ingredient that differentiated a cocktail from a sling. Over time, those definitions of "cocktail" and "sling" have become archaic, as "sling" has fallen out of general use (other than in certain drink names), and "cocktail" can mean any drink that resembles a martini, or simply any mixed drink.
The following are other variations on the classic Manhattan:

</doc>
<doc id="20880" url="https://en.wikipedia.org/wiki?curid=20880" title="Mira">
Mira

Mira (, also known as Omicron Ceti, ο Ceti, ο Cet) is a red giant star estimated 200–400 light years away in the constellation Cetus. Mira is a binary star, consisting of the red giant Mira A along with Mira B. Mira A is also an oscillating variable star and was the first non-supernova variable star discovered, with the possible exception of Algol. Mira is the brightest periodic variable in the sky that is not visible to the naked eye for part of its cycle. Its distance is uncertain; pre-Hipparcos estimates centered on 220 light-years; while Hipparcos data from the 2007 reduction suggest a distance of 299 light-years, with a margin of error of 11%.
Observation history.
Evidence that the variability of Mira was known in ancient China, Babylon or Greece is at best only circumstantial. What is certain is that the variability of Mira was recorded by the astronomer David Fabricius beginning on August 3, 1596. Observing what he thought was the planet Mercury (later identified as Jupiter), he needed a reference star for comparing positions and picked a previously unremarked third-magnitude star nearby. By August 21, however, it had increased in brightness by one magnitude, then by October had faded from view. Fabricius assumed it was a nova, but then saw it again on February 16, 1609.
In 1638 Johannes Holwarda determined a period of the star's reappearances, eleven months; he is often credited with the discovery of Mira's variability. Johannes Hevelius was observing it at the same time and named it "Mira" (meaning "wonderful" or "astonishing," in Latin) in his "Historiola Mirae Stellae" (1662), for it acted like no other known star. Ismail Bouillaud then estimated its period at 333 days, less than one day off the modern value of 332 days. This is likely to be not only perfectly forgivable, but also quite accurate; Mira is known to vary slightly in period, and may even be slowly changing over time. The star is estimated to be a 6-billion-year-old red giant.
There is considerable speculation as to whether Mira had been observed prior to Fabricius. Certainly Algol's history (known for certain as a variable only in 1667, but with legends and such dating back to antiquity showing that it had been observed with suspicion for millennia) suggests that Mira might have been known too. Karl Manitius, a modern translator of Hipparchus' "Commentary on Aratus", has suggested that certain lines from that second-century text may be about Mira. The other pre-telescopic Western catalogs of Ptolemy, al-Sufi, Ulugh Beg, and Tycho Brahe turn up no mentions, even as a regular star. There are three observations from Chinese and Korean archives, in 1596, 1070, and the same year when Hipparchus would have made his observation (134 BC) that are suggestive, but the Chinese practice of pinning down observations no more precisely than within a given Chinese constellation makes it difficult to be sure.
System.
Mira is a binary star system that consists of a red giant (Mira A) undergoing mass loss and a high temperature white dwarf companion (Mira B) that is accreting mass from the primary. Such an arrangement of stars is known as a symbiotic system and this is the closest such symbiotic pair to the Sun. Examination of this system by the Chandra X-ray Observatory shows a direct mass exchange along a bridge of matter from the primary to the white dwarf. The two stars are currently separated by about 70 astronomical units.
Component A.
Mira A is currently an asymptotic giant branch (AGB) star, in the thermally pulsing AGB phase. Each pulse lasts a decade or more, and an amount of time on the order of 10,000 years passes between each pulse. With every pulse cycle Mira increases in luminosity and the pulses grow stronger. This is also causing dynamic instability in Mira, resulting in dramatic changes in luminosity and size over shorter, irregular time periods.
The overall shape of Mira A has been observed to change, exhibiting pronounced departures from symmetry. These appear to be caused by bright spots on the surface that evolve their shape on time scales of 3–14 months. Observations of Mira A in the ultraviolet band by the Hubble Space Telescope have shown a plume-like feature pointing toward the companion star.
Variability.
Mira A is a well-known example of a category of variable stars known as Mira variables, which are named after it. The 6–7,000 known stars of this class are all red giants whose surfaces oscillate in such a way as to increase and decrease in brightness over periods ranging from about 80 to more than 1,000 days.
In the particular case of Mira, its increases in brightness take it up to about magnitude 3.5 on average, placing it among the brighter stars in the Cetus constellation. Individual cycles vary too; well-attested maxima go as high as magnitude 2.0 in brightness and as low as 4.9, a range almost 15 times in brightness, and there are historical suggestions that the real spread may be three times this or more. Minima range much less, and have historically been between 8.6 and 10.1, a factor of four times in luminosity. The total swing in brightness from absolute maximum to absolute minimum (two events which did not occur on the same cycle) is 1,700 times. Interestingly, since Mira emits the vast majority of its radiation in the infrared, its variability in that band is only about two magnitudes. The shape of its light curve is of an increase over about 100 days, and a return twice as long.
Contemporary approximate maxima for Mira:
From northern temperate latitudes, Mira is generally not visible between late March and June due to its proximity to the Sun. This means that at times several years can pass without it appearing as a naked-eye object.
Mass loss.
Ultra-violet studies of Mira by NASA's Galaxy Evolution Explorer (GALEX) space telescope have revealed that it sheds a trail of material from the outer envelope, leaving a tail 13 light-years in length, formed over tens of thousands of years. It is thought that a hot bow-wave of compressed plasma/gas is the cause of the tail; the bow-wave is a result of the interaction of the stellar wind from Mira A with gas in interstellar space, through which Mira is moving at an extremely high speed of 130 kilometres/second (291,000 miles per hour). The tail consists of material stripped from the head of the bow-wave, which is also visible in ultra-violet observations. Mira's bow-shock will eventually evolve into a planetary nebula, the form of which will be considerably affected by the motion through the interstellar medium (ISM).
Component B.
The companion star was resolved by the Hubble Space Telescope in 1995, when it was 70 astronomical units from the primary; results were announced in 1997. The HST ultraviolet images and later X-ray images by the Chandra space telescope show a spiral of gas rising off Mira in the direction of Mira B. The companion's orbital period around Mira is approximately 400 years.
In 2007, observations showed a protoplanetary disc around the companion, Mira B. This disc is being accreted from material in the solar wind from Mira and could eventually form new planets. These observations also hinted that the companion was a main sequence star of around 0.7 solar masses and spectral type K, instead of a white dwarf as originally thought. However, in 2010 further research indicated that Mira B is in fact a white dwarf.

</doc>
<doc id="20881" url="https://en.wikipedia.org/wiki?curid=20881" title="MV Virginian (T-AK 9205)">
MV Virginian (T-AK 9205)

MV "Virginian" (T-AK 9205), formerly named the MV "Strong Virginian" (T-AKR-9205), is a combination container, heavy lift, and roll-on/roll-off ship. Owned and operated by Sealift Incorporated of Oyster Bay, New York, the ship is one of seventeen containerroll-on/roll-off ships in use by the Military Sealift Command, and one of 28 ships assigned to that organization's Sealift Program Office. The ship was previously known as the MV "Saint Magnus" and the MV "Jolly Indaco".
Cargo equipment.
The ship has one large cargo hold with a tween deck that can be set at three different heights. It has a single 800-ton derrick for heavy-lift use. In addition it has a single traveling gantry crane fitted with dual portal cranes, both of which are rated at 75 metric tons independently, and can be operated together for lifts up to 150 metric tons. For roll-on/roll-off (roro) cargo, the ship has two trailer elevators and roro ramps.
History.
Built as "Saint Magnus" at Bremer Vulkan, Bremen, Germany in 1984, "Virginian" spent her first years in the commercial shipping service. Ironically, the ship that would later be known for carrying military supplies to the Middle East was accidentally hit by an Exocet missile while off-loading commercial cargo in Iraq in 1986. In these early years, the ship was also renamed "Jolly Indaco".
MSC first chartered the ship, then known as MV "Strong Virginian", in 1992. For the next five years, a 500-bed fleet hospital was prepositioned aboard the ship as she carried out a variety of missions for the Department of Defense. Some of its jobs during this time included delivering equipment and supplies to Africa as part of Operation Restore Hope, transporting a bio-safety lab from Inchon, Korea, to Jakarta, Indonesia, and ferrying harbor tugs used by the U.S. Navy from Diego Garcia to Guam and back.
On March 14, 1997, the United States Department of Defense announced a new charter for the "Strong Virginian". This contract, number N00033-97-C-3007, was a $23,592,099 time charter contract from the Military Sealift Command to operator Van Ommeren Shipping (USA), Inc., of Stamford, Connectucut. Under the contract, the "Strong Virginian" was to be used in the prepositioning of United States Army cargo in the Indian Ocean at the island of Diego Garcia. The contract included options which could have brought the cumulative value up to US$47,992,099 and was to expire by March 1999. This contract was competitively procured with 250 proposals solicited and four offers received.
Virginian was chartered again in 1998 and, for the next four years, the ship was used to support the U.S. Army. Virginian delivered combat craft, tugboats and barges and other elements of the Army's port opening packages. These packages are used to give the military access to rarely used ports in areas vital to U.S. military operations. On September 30, 2002, the ship was released from MSC service and returned to its owner.
Sealift Incorporated bought the ship from Van Ommeren Shipping USA, Inc. taking delivery on June 10, 2003. At that point, Sealift renamed the ship the "Virginian". Between November 2002 and May 2006, the "Virginian" completed 21 missions for the U.S. military, delivering almost , or nearly 30 football fields, of cargo.
On October 16, 2007 the United States Department of Defense announced that it awarded contract N00033-08-C-5500 to Sealift Incorporated. This was a $10,614,000 firm-fixed-price contract plus reimbursables for the "Virginian". The ship was contracted to carry containers laden with ammunition to support the global war on terrorism and the United States Central Command. The contract includes options, which, if exercised, would bring the cumulative value of this contract to $39,814,000. If options are exercised, work may continue through October 2011. This contract was competitively procured via Federal Business Opportunities and the Military Sealift Command websites, with more than 200 proposals solicited and three offers received. The U.S. Navy’s Military Sealift Command is the contracting authority.
The ship was sold for scrap in August 2012 in Singapore and was recycled in Bangladesh that same month.

</doc>
<doc id="20882" url="https://en.wikipedia.org/wiki?curid=20882" title="Mon">
Mon

Mon or Møn may refer to:မန်

</doc>
<doc id="20883" url="https://en.wikipedia.org/wiki?curid=20883" title="Mojito">
Mojito

Mojito (; ) is a traditional Cuban highball.
Traditionally, a mojito is a cocktail that consists of five ingredients: white rum, sugar (traditionally sugar cane juice), lime juice, sparkling water, and mint. The original Cuban recipe uses spearmint or yerba buena, a mint variety very popular on the island. Its combination of sweetness, refreshing citrus, and mint flavors is intended to complement the potent kick of the rum, and has made this clear highball a popular summer drink. The cocktail has a relatively low alcohol content (about 10 percent alcohol by volume).
When preparing a mojito, lime juice is added to sugar (or syrup) and mint leaves. The mixture is then gently mashed with a muddler. The mint leaves should only be bruised to release the essential oils and should not be shredded. Then rum is added and the mixture is briefly stirred to dissolve the sugar and to lift the mint leaves up from the bottom for better presentation. Finally, the drink is topped with crushed ice and sparkling soda water. Mint leaves and lime wedges are used to garnish the glass.
The mojito is one of the most famous rum-based highballs. There are several versions of the mojito.
History.
Havana, Cuba, is the birthplace of the Mojito, although the exact origin of this classic cocktail is the subject of debate. One story traces the Mojito to a similar 16th century drink known as "El Drake", after Francis Drake. In 1586, after his successful raid at Cartagena de Indias Drake's ships sailed towards Havana but there was an epidemic of dysentery and scurvy on board. It was known that the local South American Indians had remedies for various tropical illnesses; so a small boarding party went ashore on Cuba and came back with ingredients for a medicine which was effective. The ingredients were aguardiente de caña (a crude form of rum, translates as "fire water" from sugar cane) added with local tropical ingredients; lime, sugarcane juice and mint. Drinking lime juice in itself would have been a great help in staving off scurvy and dysentery. Tafia/Rum was used as soon as it became widely available to the British (ca. 1650). Mint, lime and sugar were also helpful in hiding the harsh taste of this spirit. While this drink was not called a Mojito at this time, it was still the original combination of these ingredients.
Some historians contend that African slaves who worked in the Cuban sugar cane fields during the 19th century were instrumental in the cocktail's origin. Guarapo, the sugar cane juice often used in Mojitos, was a popular drink amongst the slaves who helped coin the name of the sweet nectar. It never originally contained lime juice.
There are several theories behind the origin of the name Mojito; one such theory holds that name relates to mojo, a Cuban seasoning made from lime and used to flavour dishes. Another theory is that the name Mojito is simply a derivative of "mojadito" (Spanish for "a little wet") or simply the diminutive of "mojado" ("wet"). Due to the vast influence of immigration from the Canary Islands, the term probably came from the mojo creole marinades adapted in Cuba using citrus vs traditional Isleno types.
The Mojito has routinely been presented as a favorite drink of author Ernest Hemingway. It has also often been said that Ernest Hemingway made the bar called La Bodeguita del Medio famous as he became one of its regulars and wrote "My mojito in La Bodeguita, My daiquiri in El Floridita." This expression in English can be read on the wall of the bar today, handwritten and signed in his name, although Hemingway biographers have expressed doubts about such patronage and about the author's taste for mojitos. La Bodeguita del Medio is more known for their food rather than drink.
A report created in 2014 states that the Mojito is now the most popular cocktail in Britain. 

</doc>
<doc id="20886" url="https://en.wikipedia.org/wiki?curid=20886" title="Mohammed Zahir Shah">
Mohammed Zahir Shah

Mohammed Zahir Shah (Pashto: محمد ظاهرشاه, Dari: محمد ظاهر شاه; October 15, 1914 – July 23, 2007) was the last King of Afghanistan, reigning for four decades, from 1933 until he was ousted by a coup in 1973. Following his return from exile, he was given the title 'Father of the Nation' in 2002, which he held until his death.
Family background and early life.
Zahir Shah was born on 16 October 1914, in Kabul, Afghanistan. He was the son of Mohammed Nadir Shah, a senior member of the muhamadzai royal family and commander in chief of the Afghan army under former king Amanullah Khan. Nadir Shah assumed the throne after the execution of Habibullah Ghazi on 10 October 1929. Mohammed Zahir's father, son of Sardar Mohammad Yusuf Khan, was born in Dehradun, British India, his family having been exiled following the Second Anglo-Afghan War. Nadir Shah was a descendant of Sardar Sultan Mohammed Khan Telai, half-brother of Amir Dost Mohammad Khan. His grandfather Mohammad Yahya Khan (father in law of Amir Yaqub Khan) was in charge of the negotiations with the British leading to the Treaty of Gandamak. After the British invasion following the killing of Sir Louis Cavagnari in 1879, Yaqub Khan, Yahya Khan and his sons, Princes Mohammad Yusuf Khan and Mohammad Asef Khan, were seized by the British and transferred under custody to the British Raj, where they forcibly remained until the two princes were invited back to Afghanistan by Emir Abdur Rahman Khan in the last year of his reign (1901). During the reign of Amir Habibullah they received the title of Companions of the King (Musahiban).
Zahir Shah was educated in a special class for princes at Habibia High School in Kabul. He continued his education in France where his father had been sent as a diplomatic envoy, studying at the Pasteur Institute and the University of Montpellier. When he returned to Afghanistan he helped his father and uncles restore order and reassert government control during a period of lawlessness in the country. He was later enrolled at an Infantry School and appointed a privy counsellor. Zahir Shah served in the government positions of deputy war minister and minister of education. Zahir Shah was fluent in Pashto, Persian, and French.
The last king of Afghanistan.
Zahir Khan was proclaimed King (Shah) on 8 November 1933 at the age of 19, after the assassination of his father Mohammed Nadir Shah. Following his ascension to the throne he was given the regnal title ""He who puts his trust in God, follower of the firm religion of Islam"". For the first thirty years he did not effectively rule, ceding power to his paternal uncles, Mohammad Hashim Khan and Shah Mahmud Khan. This period fostered a growth in Afghanistan's relations with the international community as in 1934, Afghanistan joined the League of Nations while also receiving formal recognition from the United States. By the end of the 1930s, agreements on foreign assistance and trade had been reached with many countries, most notably Germany, Italy, and Japan.
Zahir Shah provided aid, weapons and Afghan fighters to the Uighur and Kirghiz Muslim rebels who had established the First East Turkestan Republic. The aid was not capable of saving the First East Turkestan Republic, as the Afghan, Uighur and Kirghiz forces were defeated in 1934 by the Chinese Muslim 36th Division (National Revolutionary Army) led by General Ma Zhancang at the Battle of Kashgar and Battle of Yarkand. All the Afghan volunteers were killed by the Chinese Muslim troops, who then abolished the First East Turkestan Republic, and reestablished Chinese government control over the area.
Following the end of the Second World War, Zahir Shah recognised the need for the modernisation of Afghanistan and recruited a number of foreign advisers to assist with the process. During his reign a number of potential advances and reforms were derailed as a result of factionalism and political infighting.
Zahir Shah was able to govern on his own in 1963 and despite the factionalism and political infighting a new constitution was introduced in 1964 which turned Afghanistan into a modern democratic state by introducing free elections, a parliament, civil rights, women's rights and universal suffrage. "AlMutawakkil 'ala Allah Muhammad Zhahir Shah" which means "The leaner on Allah, Muhammad Zhahir Shah". The title "AlMutawakkil 'ala Allah", "The leaner on Allah" is taken from the Quran, Sura 8, verse 61.
By the time he returned to Afghanistan in the twenty-first century, his rule was characterized by a lengthy span of peace, but with no significant progress.
Exile.
In 1973, while Zahir Shah was in Italy, undergoing eye surgery as well as therapy for lumbago, his cousin and former Prime Minister Mohammed Daoud Khan staged a coup d'état and established a republican government. As a former prime minister, Daoud Khan had been forced to resign by Zahir Shah a decade earlier. In August 1974, Zahir Shah abdicated rather than risk an all-out civil war.
Zahir Shah lived in exile in Italy for twenty-nine years in a villa in the affluent community of Olgiata on Via Cassia, north of Rome where he spent his time playing golf and chess, as well as tending to his garden. He was barred from returning to Afghanistan during Soviet-backed Communist rule in the late 1970s. In 1983 during the Soviet war in Afghanistan, Zahir Shah was cautiously involved in plans to head a government in exile. Ultimately these plans failed because he could not reach a consensus with the powerful Islamist factions.
In 1991, Zahir Shah survived an attempt on his life by a knife-wielding assassin masquerading as a Portuguese journalist.
Return to Afghan politics.
After the soviet withdrawal from Afghanistan and the defeat of Najibullah's soviet client government a majority of the various Mujaheddin groups favored a return of King Zahir Shah. However, the ISI of Pakistan feared Zahir Shahs Position on the Durand Line issue. Therefore, the official ISI policy was to push one of the most violent Mujaheddin commanders Gulbuddin Hekmatyar as the new leader of radical Islamist government. This position proved to be fatal for Afghanistan and it triggered a brutal civil war. Zahir Shah would not return to the country for another decade.
In April 2002, while the country was no longer under Taliban rule, Zahir Shah returned to Afghanistan to open the Loya Jirga, which met in June 2002. After the fall of the Taliban, there were open calls for a return to the monarchy. Zahir Shah himself let it be known that he would accept whatever responsibility was placed on him by the Loya Jirga. However he was obliged to publicly step aside at the behest of the United States as many of delegates to the Loya Jirga were prepared to vote for Zahir Shah and block the US-backed Hamid Karzai. While he was prepared to become head of state he made it known that it would not necessarily be as monarch: "I will accept the responsibility of head of state if that is what the Loya Jirga demands of me, but I have no intention to restore the monarchy. I do not care about the title of king. The people call me Baba and I prefer this title." He was given the title "Father of the Nation" in the current Constitution of Afghanistan symbolizing his role in Afghanistan's history as a symbol of national unity. The title of the 'Father of the Nation' dissolved with his death.
Hamid Karzai, a prominent figure from the Pashtun Popalzai clan, became the president of Afghanistan and Zahir Shah's relatives and supporters were provided with key posts in the transitional government. Zahir Shah moved back into his old palace. In an October 2002 visit to France, he slipped in a bathroom, bruising his ribs, and on 21 June 2003, while in France for a medical check-up, he broke his femur.
On 3 February 2004, Zahir was flown from Kabul to New Delhi, India, for medical treatment after complaining of an intestinal problem. He was hospitalized for two weeks and remained in New Delhi under observation. On 18 May 2004, he was brought to a hospital in the United Arab Emirates because of nose bleeding caused by heat.
Zahir Shah attended the 7 December 2004 swearing-in of Hamid Karzai as President of Afghanistan. In his final years, he was frail and required a microphone pinned to his collar so that his faint voice could be heard. In January 2007, Zahir was reported to be seriously ill and bedridden.
Death.
On 23 July 2007, he died in the compound of the presidential palace in Kabul after prolonged illness. His death was announced on national television by President Karzai. His funeral was held on 24 July. It began on the premises of the presidential palace, where political figures and dignitaries paid their respects; his coffin was then taken to a mosque before being moved to the royal mausoleum on Maranjan Hill.
Family.
He married his first cousin Humaira Begum (1918–2002) on 7 November 1931 in Kabul. They had six sons and two daughters:
In January 2009 an article by Ahmad Majidyar of the American Enterprise Institute included one of his grandsons, Mustafa Zahir, on a list of fifteen possible candidates in the 2009 Afghan Presidential election.
However Mostafa Zaher did not become a candidate.

</doc>
<doc id="20889" url="https://en.wikipedia.org/wiki?curid=20889" title="Miso">
Miso

Typically, miso is salty, but its flavor and aroma depend on various factors in the ingredients and fermentation process. Different varieties of miso have been described as salty, sweet, earthy, fruity, and savory. The traditional Chinese analogue of miso is known as dòujiàng (豆酱).
History.
The origin of the miso of Japan is not completely clear. 
In the Kamakura era (1192–1333), a common meal was made up of a bowl of rice, some dried fish, a serving of miso, and a fresh vegetable. Until the Muromachi era (1337 to 1573), miso was made without grinding the soybeans, somewhat like "nattō". In the Muromachi era, Buddhist monks discovered that soybeans could be ground into a paste, spawning new cooking methods using miso to flavor other foods. In medieval times, the word "temaemiso", meaning home-made miso, appeared. Miso production is a relatively simple process, so home-made versions spread throughout Japan. Miso was used as military provisions during the Sengoku era and making miso was an important economic activity for "daimyo"s of that era.
During the Edo period (1603–1868), miso was also called "hishio" (醤) and "kuki" (豆支) and various types of miso that fit with each local climate and culture emerged throughout Japan.
These days, miso is produced industrially in large quantities and traditional home-made miso has become a rarity. In recent years, many new types of miso have appeared. For example, ones with added soup stocks or calcium, or reduced salt for health, etc. are available
Flavor.
The taste, aroma, texture, and appearance of miso all vary by region and season. Other important variables that contribute to the flavor of a particular miso include temperature, duration of fermentation, salt content, variety of "kōji", and fermenting vessel. The most common flavor categories of miso are:
Although white and red ("shiromiso" and "akamiso") are the most common types of misos available, different varieties may be preferred in particular regions of Japan. In the eastern Kantō region that includes Tokyo, the darker brownish "akamiso" is popular while in the western Kansai region encompassing Osaka, Kyoto, and Kobe the lighter "shiromiso" is preferred.
Ingredients.
The ingredients used to produce miso may include any mix of soybeans, barley, rice, buckwheat, millet, rye, wheat, hemp seed, and cycad, among others. Lately, producers in other countries have also begun selling miso made from chickpeas, corn, azuki beans, amaranth, and quinoa. Fermentation time ranges from as little as five days to several years. The wide variety of Japanese miso is difficult to classify, but is commonly done by grain type, color, taste, and background.
Many regions have their own specific variation on the miso standard. For example, the soybeans used in Sendai miso are much more coarsely mashed than in normal soy miso.
Miso made with rice such as "shinshu" and "shiro" are called "kome" miso.
Types.
Types of miso are divided by their main ingredients.
Storage and preparation.
Miso typically comes as a paste in a sealed container requiring refrigeration after opening. Natural miso is a living food containing many beneficial microorganisms such as "Tetragenococcus halophilus" which can be killed by overcooking. For this reason, the miso should be added to soups or other foods being prepared just before they are removed from the heat. Using miso without any cooking may be even better. Outside Japan, a popular practice is to only add miso to foods that have cooled to preserve "kōjikin" cultures in miso. Nonetheless, miso and soy foods play a large role in the Japanese diet, and many cooked miso dishes are popular.
Usage.
Miso is a part of many Japanese-style meals. It most commonly appears as the main ingredient of miso soup, which is eaten daily by much of the Japanese population. The pairing of plain rice and miso soup is considered a fundamental unit of Japanese cuisine. This pairing is the basis of a traditional Japanese breakfast.
Miso is used in many other types of soup and soup-like dishes, including some kinds of" ramen, udon, nabe", and" imoni". Generally, such dishes have the title "miso" prefixed to their name (for example, "miso-udon"), and have a heavier, earthier flavor and aroma compared to other Japanese soups that are not miso-based.
Many traditional confections use a sweet, thick miso glaze, such as "mochidango". Miso-glazed treats are strongly associated with Japanese festivals, although they are available year-round at supermarkets. The consistency of miso glaze ranges from thick and taffy-like to thin and drippy.
Soy miso is used to make a type of pickle called "misozuke". These pickles are typically made from cucumber, daikon, "hakusai" (Chinese cabbage), or eggplant, and are sweeter and less salty than the standard Japanese salt pickle.
Other foods with miso as an ingredient include:
Nutrition and health.
Claims that miso is high in vitamin B12 have been contradicted in some studies.
Some experts suggest that miso is a source of "Lactobacillus acidophilus". Miso is relatively high in salt which can contribute to increased blood pressure in the small percentage of the population with sodium-sensitive prehypertension or hypertension.

</doc>
<doc id="20890" url="https://en.wikipedia.org/wiki?curid=20890" title="Malcolm I of Scotland">
Malcolm I of Scotland

__NOTOC__
Máel Coluim mac Domnaill (anglicised Malcolm I) (c. 900–954) was king of Scots (before 943 – 954), becoming king when his cousin Causantín mac Áeda abdicated to become a monk. He was the son of Domnall mac Causantín.
Since his father was known to have died in the year 900, Malcolm must have been born no later than 901. By the 940s, he was no longer a young man, and may have become impatient in awaiting the throne. Willingly or not—the 11th-century "Prophecy of Berchán", a verse history in the form of a supposed prophecy, states that it was not a voluntary decision that Constantine II abdicated in 943 and entered a monastery, leaving the kingdom to Malcolm.
Seven years later, the "Chronicle of the Kings of Alba" says:[Malcolm I] plundered the English as far as the River Tees, and he seized a multitude of people and many herds of cattle: and the Scots called this the raid of Albidosorum, that is, Nainndisi. But others say that Constantine made this raid, asking of the king, Malcolm, that the kingship should be given to him for a week's time, so that he could visit the English. In fact, it was Malcolm who made the raid, but Constantine incited him, as I have said. Woolf suggests that the association of Constantine with the raid is a late addition, one derived from a now-lost saga or poem.
He died in the shield wall next to his men.
In 945, Edmund I of England, having expelled Amlaíb Cuaran (Olaf Sihtricsson) from Northumbria, devastated Cumbria and blinded two sons of Domnall mac Eógain, king of Strathclyde. It is said that he then "let" or "commended" Strathclyde to Máel Coluim in return for an alliance. What is to be understood by "let" or "commended" is unclear, but it may well mean that Máel Coluim had been the overlord of Strathclyde and that Edmund recognised this while taking lands in southern Cumbria for himself.
The Chronicle of the Kings of Alba says that Máel Coluim took an army into Moray "and slew Cellach". Cellach is not named in the surviving genealogies of the rulers of Moray, and his identity is unknown.
Máel Coluim appears to have kept his agreement with the late English king, which may have been renewed with the new king, Edmund having been murdered in 946 and succeeded by his brother Edred. Eric Bloodaxe took York in 948, before being driven out by Edred, and when Amlaíb Cuaran again took York in 949–950, Máel Coluim raided Northumbria as far south as the Tees taking "a multitude of people and many herds of cattle" according to the Chronicle. The Annals of Ulster for 952 report a battle between "the men of Alba and the Britons Strathclyde and the English" against the foreigners, i.e. the Northmen or the Norse-Gaels. This battle is not reported by the Anglo-Saxon Chronicle, and it is unclear whether it should be related to the expulsion of Amlaíb Cuaran from York or the return of Eric Bloodaxe.
The Annals of Ulster report that Máel Coluim was killed in 954. Other sources place this most probably in the Mearns, either at Fetteresso following the Chronicle, or at Dunnottar following the Prophecy of Berchán. He was buried on Iona. Máel Coluim's sons Dub and Cináed were later kings.
Further reading.
"For primary sources see also " External links "below."

</doc>
<doc id="20892" url="https://en.wikipedia.org/wiki?curid=20892" title="Malcolm III of Scotland">
Malcolm III of Scotland

Malcolm (Gaelic: "Máel Coluim"; c. 1031 – 13 November 1093) was King of Scots from 1058 to 1093. He was later nicknamed Canmore ("ceann mòr") in Scottish Gaelic, "Great Chief". (Ceann = leader, "head" state. Mòr = pre-eminent, great, "big".) Malcolm's long reign, lasting 35 years, preceded the beginning of the Scoto-Norman age. He is the historical equivalent of the character of the same name in Shakespeare's "Macbeth".
Malcolm's kingdom did not extend over the full territory of modern Scotland: the north and west of Scotland remained in Scandinavian, Norse-Gael and Gaelic control, and the areas under the control of the Kings of Scots did not advance much beyond the limits set by Malcolm II until the 12th century. Malcolm III fought a succession of wars against the Kingdom of England, which may have had as their goal the conquest of the English earldom of Northumbria. These wars did not result in any significant advances southwards. Malcolm's main achievement is to have continued a line which would rule Scotland for many years, although his role as "founder of a dynasty" has more to do with the propaganda of his youngest son David, and his descendants, than with any historical reality.
Malcolm's second wife, Margaret of Wessex, was eventually canonized and is Scotland's only royal saint. Malcolm himself gained no reputation for piety; with the notable exception of Dunfermline Abbey, he is not definitely associated with major religious establishments or ecclesiastical reforms.
Background.
Malcolm's father Duncan I became king in late 1034, on the death of Malcolm II, Duncan's maternal grandfather and Malcolm's great-grandfather. According to John of Fordun, whose account is the original source of part at least of William Shakespeare's "Macbeth", Malcolm's mother was a niece of Siward, Earl of Northumbria, but an earlier king-list gives her the Gaelic name Suthen. Other sources claim that either a daughter or niece would have been too young to fit the timeline, thus the likely relative would have been Siward's own sister Sybil, which may have translated into Gaelic as Suthen.
Duncan's reign was not successful and he was killed by Macbeth on 15 August 1040. Although Shakespeare's "Macbeth" presents Malcolm as a grown man and his father as an old one, it appears that Duncan was still young in 1040, and Malcolm and his brother Donalbane were children. Malcolm's family did attempt to overthrow Macbeth in 1045, but Malcolm's grandfather Crínán of Dunkeld was killed in the attempt.
Soon after the death of Duncan his two young sons were sent away for greater safety—exactly where is the subject of debate. According to one version, Malcolm (then aged about nine) was sent to England, and his younger brother Donalbane was sent to the Isles. Based on Fordun's account, it was assumed that Malcolm passed most of Macbeth's seventeen-year reign in the Kingdom of England at the court of Edward the Confessor.
According to an alternative version, Malcolm's mother took both sons into exile at the court of Thorfinn Sigurdsson, Earl of Orkney, an enemy of Macbeth's family, and perhaps Duncan's kinsman by marriage.
An English invasion in 1054, with Siward, Earl of Northumbria in command, had as its goal the installation of one "Máel Coluim, son of the King of the Cumbrians". This Máel Coluim has traditionally been identified with the later Malcolm III. This interpretation derives from the "Chronicle" attributed to the 14th-century chronicler of Scotland, John of Fordun, as well as from earlier sources such as William of Malmesbury. The latter reported that Macbeth was killed in the battle by Siward, but it is known that Macbeth outlived Siward by two years. A. A. M. Duncan argued in 2002 that, using the "Anglo-Saxon Chronicle" entry as their source, later writers innocently misidentified "Máel Coluim" with the later Scottish king of the same name. Duncan's argument has been supported by several subsequent historians specialising in the era, such as Richard Oram, Dauvit Broun and Alex Woolf. It has also been suggested that Máel Coluim may have been a son of Owen the Bald, British king of Strathclyde perhaps by a daughter of Malcolm II, King of Scotland.
In 1057 various chroniclers report the death of Macbeth at Malcolm's hand, on 15 August 1057 at Lumphanan in Aberdeenshire. Macbeth was succeeded by his stepson Lulach, who was crowned at Scone, probably on 8 September 1057. Lulach was killed by Malcolm, "by treachery", near Huntly on 23 April 1058. After this, Malcolm became king, perhaps being inaugurated on 25 April 1058, although only John of Fordun reports this.
Malcolm and Ingibiorg.
If Orderic Vitalis is to be relied upon, one of Malcolm's earliest actions as king may have been to travel south to the court of Edward the Confessor in 1059 to arrange a marriage with Edward's kinswoman Margaret, who had arrived in England two years before from Hungary. If he did visit the English court, he was the first reigning king of Scots to do so in more than eighty years. If a marriage agreement was made in 1059, it was not kept, and this may explain the Scots invasion of Northumbria in 1061 when Lindisfarne was plundered. Equally, Malcolm's raids in Northumbria may have been related to the disputed "Kingdom of the Cumbrians", reestablished by Earl Siward in 1054, which was under Malcolm's control by 1070.
The Orkneyinga saga reports that Malcolm married the widow of Thorfinn Sigurdsson, Ingibiorg, a daughter of Finn Arnesson. Although Ingibiorg is generally assumed to have died shortly before 1070, it is possible that she died much earlier, around 1058. The "Orkneyinga Saga" records that Malcolm and Ingibiorg had a son, Duncan II (Donnchad mac Maíl Coluim), who was later king. Some Medieval commentators, following William of Malmesbury, claimed that Duncan was illegitimate, but this claim is propaganda reflecting the need of Malcolm's descendants by Margaret to undermine the claims of Duncan's descendants, the Meic Uilleim. Malcolm's son Domnall, whose death is reported in 1085, is not mentioned by the author of the "Orkneyinga Saga". He is assumed to have been born to Ingibiorg.
Malcolm's marriage to Ingibiorg secured him peace in the north and west. The "Heimskringla" tells that her father Finn had been an adviser to Harald Hardraade and, after falling out with Harald, was then made an Earl by Sweyn Estridsson, King of Denmark, which may have been another recommendation for the match. Malcolm enjoyed a peaceful relationship with the Earldom of Orkney, ruled jointly by his stepsons, Paul and Erlend Thorfinnsson. The "Orkneyinga Saga" reports strife with Norway but this is probably misplaced as it associates this with Magnus Barefoot, who became king of Norway only in 1093, the year of Malcolm's death.
Malcolm and Margaret.
Although he had given sanctuary to Tostig Godwinson when the Northumbrians drove him out, Malcolm was not directly involved in the ill-fated invasion of England by Harald Hardraade and Tostig in 1066, which ended in defeat and death at the battle of Stamford Bridge. In 1068, he granted asylum to a group of English exiles fleeing from William of Normandy, among them Agatha, widow of Edward the Confessor's nephew Edward the Exile, and her children: Edgar Ætheling and his sisters Margaret and Cristina. They were accompanied by Gospatric, Earl of Northumbria. The exiles were disappointed, however, if they had expected immediate assistance from the Scots.
In 1069 the exiles returned to England, to join a spreading revolt in the north. Even though Gospatric and Siward's son Waltheof submitted by the end of the year, the arrival of a Danish army under Sweyn Estridsson seemed to ensure that William's position remained weak. Malcolm decided on war, and took his army south into Cumbria and across the Pennines, wasting Teesdale and Cleveland then marching north, loaded with loot, to Wearmouth. There Malcolm met Edgar and his family, who were invited to return with him, but did not. As Sweyn had by now been bought off with a large Danegeld, Malcolm took his army home. In reprisal, William sent Gospatric to raid Scotland through Cumbria. In return, the Scots fleet raided the Northumbrian coast where Gospatric's possessions were concentrated. Late in the year, perhaps shipwrecked on their way to a European exile, Edgar and his family again arrived in Scotland, this time to remain. By the end of 1070, Malcolm had married Edgar's sister Margaret of Wessex, the future Saint Margaret of Scotland.
The naming of their children represented a break with the traditional Scots regal names such as Malcolm, Cináed and Áed. The point of naming Margaret's sons—Edward after her father Edward the Exile, Edmund for her grandfather Edmund Ironside, Ethelred for her great-grandfather Ethelred the Unready and Edgar for her great-great-grandfather Edgar and her brother, briefly the elected king, Edgar Ætheling—was unlikely to be missed in England, where William of Normandy's grasp on power was far from secure. Whether the adoption of the classical Alexander for the future Alexander I of Scotland (either for Pope Alexander II or for Alexander the Great) and the biblical David for the future David I of Scotland represented a recognition that William of Normandy would not be easily removed, or was due to the repetition of Anglo-Saxon royal name—another Edmund had preceded Edgar—is not known. Margaret also gave Malcolm two daughters, Edith, who married Henry I of England, and Mary, who married Eustace III of Boulogne.
In 1072, with the Harrying of the North completed and his position again secure, William of Normandy came north with an army and a fleet. Malcolm met William at Abernethy and, in the words of the "Anglo-Saxon Chronicle" "became his man" and handed over his eldest son Duncan as a hostage and arranged peace between William and Edgar. Accepting the overlordship of the king of the English was no novelty, as previous kings had done so without result. The same was true of Malcolm; his agreement with the English king was followed by further raids into Northumbria, which led to further trouble in the earldom and the killing of Bishop William Walcher at Gateshead. In 1080, William sent his son Robert Curthose north with an army while his brother Odo punished the Northumbrians. Malcolm again made peace, and this time kept it for over a decade.
Malcolm faced little recorded internal opposition, with the exception of Lulach's son Máel Snechtai. In an unusual entry, for the "Anglo-Saxon Chronicle" contains little on Scotland, it says that in 1078:
Whatever provoked this strife, Máel Snechtai survived until 1085.
Malcolm and William Rufus.
When William Rufus became king of England after his father's death, Malcolm did not intervene in the rebellions by supporters of Robert Curthose which followed. In 1091, William Rufus confiscated Edgar Ætheling's lands in England, and Edgar fled north to Scotland. In May, Malcolm marched south, not to raid and take slaves and plunder, but to besiege Newcastle, built by Robert Curthose in 1080. This appears to have been an attempt to advance the frontier south from the River Tweed to the River Tees. The threat was enough to bring the English king back from Normandy, where he had been fighting Robert Curthose. In September, learning of William Rufus's approaching army, Malcolm withdrew north and the English followed. Unlike in 1072, Malcolm was prepared to fight, but a peace was arranged by Edgar Ætheling and Robert Curthose whereby Malcolm again acknowledged the overlordship of the English king.
In 1092, the peace began to break down. Based on the idea that the Scots controlled much of modern Cumbria, it had been supposed that William Rufus's new castle at Carlisle and his settlement of English peasants in the surrounds was the cause. It is unlikely that Malcolm controlled Cumbria, and the dispute instead concerned the estates granted to Malcolm by William Rufus's father in 1072 for his maintenance when visiting England. Malcolm sent messengers to discuss the question and William Rufus agreed to a meeting. Malcolm travelled south to Gloucester, stopping at Wilton Abbey to visit his daughter Edith and sister-in-law Cristina. Malcolm arrived there on 24 August 1093 to find that William Rufus refused to negotiate, insisting that the dispute be judged by the English barons. This Malcolm refused to accept, and returned immediately to Scotland.
It does not appear that William Rufus intended to provoke a war, but, as the "Anglo-Saxon Chronicle" reports, war came:
Malcolm was accompanied by Edward, his eldest son by Margaret and probable heir-designate (or tánaiste), and by Edgar. Even by the standards of the time, the ravaging of Northumbria by the Scots was seen as harsh.
Death.
While marching north again, Malcolm was ambushed by Robert de Mowbray, Earl of Northumbria, whose lands he had devastated, near Alnwick on 13 November 1093. There he was killed by Arkil Morel, steward of Bamburgh Castle. The conflict became known as the Battle of Alnwick. Edward was mortally wounded in the same fight. Margaret, it is said, died soon after receiving the news of their deaths from Edgar. The Annals of Ulster say:
Malcolm's body was taken to Tynemouth Priory for burial. The king's body was sent north for reburial, in the reign of his son Alexander, at Dunfermline Abbey, or possibly Iona.
On 19 June 1250, following the canonisation of Malcolm's wife Margaret by Pope Innocent IV, Margaret's remains were disinterred and placed in a reliquary. Tradition has it that as the reliquary was carried to the high altar of Dunfermline Abbey, past Malcolm's grave, it became too heavy to move. As a result, Malcolm's remains were also disinterred, and buried next to Margaret beside the altar.
Issue.
Malcolm and Ingibiorg had three sons:
Malcolm and Margaret had eight children, six sons and two daughters:
Depictions in fiction.
Malcolm appears in William Shakespeare’s "Macbeth" as Malcolm. He is the son of King Duncan and heir to the throne. He first appears in the second scene where he is talking to a sergeant, with Duncan. The sergeant tells them how the battle was won thanks to Macbeth. Then Ross comes and Duncan decides that Macbeth should take the title of Thane of Cawdor. Then he later appears in Act 1.4 talking about the execution of the former Thane of Cawdor. Macbeth then enters and they congratulate him on his victory. He later appears in Macbeth’s castle as a guest. When his father is killed he is suspected of the murder so he escapes to England. He later makes an appearance in Act 4.3, where he talks to Macduff about Macbeth and what to do. They both decide to start a war against him. In Act 5.4 he is seen in Dunsinane getting ready for war. He orders the troops to hide behind branches and slowly advance towards the castle. In Act 5.8 he watches the battle against Macbeth and Macduff with Siward and Ross. When eventually Macbeth is killed, Malcolm takes over as king.
The married life of Malcolm III and Margaret has been the subject of two historical novels: "A Goodly Pearl" (1905) by Mary H. Debenham, and "Malcolm Canmore's Pearl" (1907) by Agnes Grant Hay. Both focus on court life in Dunfermline, and the Margaret helping introduce Anglo-Saxon culture in Scotland. The latter novel covers events to 1093, ending with Malcolm's death.
Canmore appears in the third and fourth episodes of the four-part series "City of Stone" in Disney's "Gargoyles", as an antagonist of Macbeth. After witnessing his father Duncan's death, the young Canmore swears revenge on both Macbeth and his gargoyle ally, Demona. After reaching adulthood, he overthrows Macbeth with English allies. Canmore is also the ancestor of the Hunters, a family of vigilantes who hunt Demona through the centuries. Canmore was voiced in the series by J.D. Daniels as a boy and Neil Dickson as an adult.
Ancestry.
Ancestors of Malcolm III of Scotland 

</doc>
<doc id="20894" url="https://en.wikipedia.org/wiki?curid=20894" title="Maximum transmission unit">
Maximum transmission unit

In computer networking, the maximum transmission unit (MTU) of a communications protocol of a layer is the size (in bytes or octets) of the largest protocol data unit that the layer can pass onwards. MTU parameters usually appear in association with a communications interface (NIC, serial port, etc.). Standards (Ethernet, for example) can fix the size of an MTU; or systems (such as point-to-point serial links) may decide MTU at connect time.
A larger MTU brings greater efficiency because each network packet carries more user data while protocol overheads, such as headers or underlying per-packet delays, remain fixed; the resulting higher efficiency means an improvement in bulk protocol throughput. A larger MTU also means processing of fewer packets for the same amount of data. In some systems, per-packet-processing can be a critical performance limitation.
However, this gain is not without a downside. Large packets occupy a slow link for more time than a smaller packet, causing greater delays to subsequent packets, and increasing lag and minimum latency. For example, a 1500-byte packet, the largest allowed by Ethernet at the network layer (and hence over most of the Internet), ties up a 14.4k modem for about one second.
Large packets are also problematic in the presence of communications errors. Corruption of a single bit in a packet requires that the entire packet be retransmitted. At a given bit error rate, larger packets are more likely to be corrupt. Their greater payload makes retransmissions of larger packets take longer. Despite the negative effects on retransmission duration, large packets can still have a net positive effect on end-to-end TCP performance.
Table of MTUs of common media.
Note: the MTUs in this section are given as the maximum size of an IP packet that can be transmitted without fragmentation - including IP headers but excluding headers from lower levels in the protocol stack. The MTU must not be confused with the minimum datagram size that all hosts must be prepared to accept, which has a value of 576 bytes for IPv4 and of 1280 bytes for IPv6. It must also not be confused with the size of the physically transmitted "frame". In the case of an Ethernet frame this adds an overhead of 18 bytes, or 22 bytes with an IEEE 802.1Q tag for VLAN or quality of service.
IP (Internet protocol).
DARPA designed the Internet protocol suite to work over many different networking technologies, each of which may use packets of different size. While a host will know the MTU of its own interface and possibly that of its peers (from initial handshakes), it will not initially know the lowest MTU in a chain of links to other peers. Another potential problem is that higher-level protocols may create packets larger than a particular link supports.
To get around this issue, IPv4 allows fragmentation: dividing the datagram into pieces, each small enough to pass over the single link that is being fragmented for, using the MTU parameter configured for that interface. This fragmentation process takes place at the IP layer (OSI layer 3) and marks the packets it fragments as such, so that the IP layer of the destination host knows it should reassemble the packets into the original datagram. This method implies a number of possible drawbacks:
The Internet Protocol requires that hosts must be able to process IP datagrams of at least 576 bytes (for IPv4) or 1280 bytes (for IPv6). However, this does not preclude Data Link Layers with an MTU smaller than IP's minimum MTU from conveying IP data. For example, according to IPv6's specification, if a particular Data Link Layer physically cannot deliver an IP datagram of 1280 bytes in a single frame, then the link layer must provide its own fragmentation and reassembly mechanism, separate from IP's own fragmentation mechanism, to ensure that a 1280-byte IP datagram can be delivered, intact, to the IP layer.
Path MTU Discovery.
The Internet Protocol defines the "Path MTU" of an Internet transmission path as the smallest MTU of any of the IP hops of the "path" between a source and destination. Put another way, the path MTU is the largest packet size that can traverse this path without suffering fragmentation.
RFC 1191 (IPv4) and RFC 1981 (IPv6) describe "Path MTU Discovery", a technique for determining the path MTU between two IP hosts. It works by setting the DF (Don't Fragment) option in the IP headers of outgoing packets. Any device along the path whose MTU is smaller than the packet will drop such packets and send back an ICMP "Destination Unreachable (Datagram Too Big)" message containing its MTU. This information allows the source host to reduce its assumed path MTU appropriately. The process repeats until the MTU becomes small enough to traverse the entire path without fragmentation.
Unfortunately, increasing numbers of networks drop ICMP traffic (for example, to prevent denial-of-service attacks), which prevents path MTU discovery from working. One often detects such blocking in the cases where a connection works for low-volume data but hangs as soon as a host sends a large block of data. For example, with IRC a connecting client might see the initial messages up to and including the initial ping (sent by the server as an anti-spoofing measure), but get no response after that. This is because the large set of welcome messages are sent out in packets bigger than the real MTU. Also, in an IP network, the path from the source address to the destination address often gets modified dynamically, in response to various events (load-balancing, congestion, outages, etc.) - this could result in the path MTU changing (sometimes repeatedly) during a transmission, which may introduce further packet drops before the host finds a new reliable MTU.
Most Ethernet LANs use an MTU of 1500 bytes (modern LANs can use Jumbo frames, allowing for an MTU up to 9000 bytes); however, border protocols like PPPoE will reduce this. The difference between the MTU seen by end-nodes (e.g. 1500) and the Path MTU causes Path MTU Discovery to come into effect, with the possible result of making some sites behind badly configured firewalls unreachable. One can possibly work around this, depending on which part of the network one controls; for example one can change the MSS (maximum segment size) in the initial packet that sets up the TCP connection at one's firewall.
RFC 4821, Packetization Layer Path MTU Discovery, describes a Path MTU Discovery technique which responds more robustly to ICMP filtering.
MTU in other standards.
The G.hn standard, developed by ITU-T, provides a high-speed (up to 1 Gigabit/s) local area network using existing home wiring (power lines, phone lines and coaxial cables). The G.hn Data Link Layer accepts data frames of up to 214 bytes (16384 bytes). In order to avoid the problem of long data-frames taking up the medium for long periods of time, G.hn defines a procedure for segmentation that divides the data frame into smaller segments.
Disruption.
The transmission of a packet on a physical network segment that is larger than the segment's MTU is known as "jabber". This is almost always caused by faulty devices. Many network switches have a built-in capability to detect when a device is jabbering and block it until it resumes proper operation.

</doc>
<doc id="20895" url="https://en.wikipedia.org/wiki?curid=20895" title="MV Buffalo Soldier (T-AK-9301)">
MV Buffalo Soldier (T-AK-9301)

MV "Buffalo Soldier" (T-AK-9301) is a roll-on/roll-off ship, formerly of the French Government Line (now merged into CMA CGM). She was sold and reflagged US, renamed to honor Buffalo Soldiers, and chartered by the United States Navy Military Sealift Command as a Maritime Prepositioning ship serving at Diego Garcia laden with U.S. Air Force munitions. She is self-sustaining, that is, she can unload herself, an asset in harbors with little or no infrastructure. Her 120-long-ton capacity roll-on/roll-off ramp accommodates tracked and wheeled vehicles of every description. While she is not currently in service with MSC, ships with her general characteristics are designated "Buffalo Soldier" class, fleet designation AK 2222.

</doc>
<doc id="20897" url="https://en.wikipedia.org/wiki?curid=20897" title="Mount Baker">
Mount Baker

Mount Baker (Lummi: "Qwú’mə Kwəlshéːn"; Nooksack: "Kw’eq Smaenit" or "Kwelshán"), also known as Koma Kulshan or simply Kulshan, is an active glaciated andesitic stratovolcano in the Cascade Volcanic Arc and the North Cascades of Washington in the United States. Mount Baker has the second-most thermally active crater in the Cascade Range after Mount Saint Helens. About due east of the city of Bellingham, Whatcom County, Mount Baker is the youngest volcano in the Mount Baker volcanic field. While volcanism has persisted here for some 1.5 million years, the current glaciated cone is likely no more than 140,000 years old, and possibly no older than 80-90,000 years. Older volcanic edifices have mostly eroded away due to glaciation.
After Mount Rainier, Mount Baker is the most heavily glaciated of the Cascade Range volcanoes; the volume of snow and ice on Mount Baker, is greater than that of all the other Cascades volcanoes (except Rainier) combined. It is also one of the snowiest places in the world; in 1999, Mount Baker Ski Area, located to the northeast, set the world record for recorded snowfall in a single season—.
At , it is the third-highest mountain in Washington State and the fifth-highest in the Cascade Range, if Little Tahoma Peak, a subpeak of Mount Rainier, and Shastina, a subpeak of Mount Shasta, are not counted. Located in the Mount Baker Wilderness, it is visible from much of Greater Victoria, Nanaimo, British Columbia, Greater Vancouver, and, to the south, from Seattle (and on clear days Tacoma) in Washington.
Indigenous natives have known the mountain for thousands of years, but the first written record of the mountain is from the Spanish. 
Spanish explorer Gonzalo Lopez de Haro mapped it in 1790 as the "Gran Montaña del Carmelo", "Great Mount Carmel". The explorer George Vancouver renamed the mountain for 3rd Lieutenant Joseph Baker of HMS "Discovery", who saw it on April 30, 1792.
History.
Mount Baker was well-known to indigenous people of the Pacific Northwest. Indigenous names for the mountain include Koma Kulshan or Kulshan (Lummi, "qwú’mə", "white sentinel", "i.e." "mountain", and "kwəlshé:n", "puncture wound", "i.e." "crater"); Quck Sam-ik (Nooksack: "kw’eq sámit", "white mountain"); Kobah (Skagit: "qwúbə’", "white sentinel", i.e. "mountain"); and Tukullum or Nahcullum (in the language of the unidentified "Koma tribe"). 
In 1790, Manuel Quimper of the Spanish Navy set sail from Nootka, a temporary settlement on Vancouver Island, with orders to explore the newly discovered Strait of Juan de Fuca. Accompanying Quimper was first-pilot Gonzalo Lopez de Haro, who drew detailed charts during the six-week expedition. Although Quimper's journal of the voyage does not refer to the mountain, one of Haro's manuscript charts includes a sketch of Mount Baker. The Spanish named the snowy volcano "La Gran Montana del Carmelo", as it reminded them of the white-clad monks of the Carmelite Monastery.
The British explorer George Vancouver left England a year later. His mission was to survey the northwest coast of America. Vancouver and his crew reached the Pacific Northwest coast in 1792. While anchored in Dungeness Bay on the south shore of the Strait of Juan de Fuca, third lieutenant Joseph Baker made an observation of Mount Baker, which Vancouver recorded in his journal:
Six years later, the official narrative of this voyage was published, including the first printed reference to the mountain. By the mid-1850s, Mount Baker was a well-known feature on the horizon to the explorers and fur traders who traveled in the Puget Sound region. Isaac I. Stevens, the first governor of Washington Territory, wrote about Mount Baker in 1853:
Climbing history.
First ascent.
Edmund Thomas Coleman, an Englishman who resided in Victoria, British Columbia, Canada and a veteran of the Alps, made the first attempt to ascend the mountain in 1866. He chose a route via the Skagit River, but was forced to turn back when local Native Americans refused him passage.
Later that same year, Coleman recruited Whatcom County settlers Edward Eldridge, John Bennett and John Tennant to aid him in his second attempt to scale the mountain. After approaching via the North Fork of the Nooksack River, the party navigated through what is now known as Coleman Glacier and ascended to within several hundred feet of the summit before turning back in the face of an "overhanging cornice of ice" and threatening weather. Coleman later returned to the mountain after two years. At 4:00 p.m. on August 17, 1868, Coleman, Eldridge, Tennant and two new companions (David Ogilvy and Thomas Stratton) scaled the summit via the Middle Fork Nooksack River, Marmot Ridge, Coleman Glacier, and the north margin of the Roman Wall.
Geology.
The present-day cone of Mount Baker is relatively young; it is perhaps less than 100,000 years old. The volcano sits atop a similar older volcanic cone called Black Buttes, which was active between 500,000 and 300,000 years ago. Much of Mount Baker's earlier geological record eroded away during the last ice age (which culminated 15,000–20,000 years ago), by thick ice sheets that filled the valleys and surrounded the volcano. In the last 14,000 years, the area around the mountain has been largely ice-free, but the mountain itself remains heavily covered with snow and ice.
Isolated ridges of lava and hydrothermally altered rock, especially in the area of Sherman Crater, are exposed between glaciers on the upper flanks of the volcano; the lower flanks are steep and heavily vegetated. Volcanic rocks of Mount Baker and Black Buttes rest on a foundation of non-volcanic rocks.
Deposits recording the last 14,000 years at Mount Baker indicate that Mount Baker has not had highly explosive eruptions like those of other volcanoes in the Cascade Volcanic Arc, such as Mount St. Helens, Mount Meager or Glacier Peak, nor has it erupted frequently. During this period, four episodes of magmatic eruptive activity have been recently recognized.
Magmatic eruptions have produced tephra, pyroclastic flows, and lava flows from summit vents and the Schriebers Meadow cinder cone. The most destructive and most frequent events at Mount Baker have been lahars or debris flows and debris avalanches; many, if not most, of these were not related to magmatic eruptions but may have been induced by magma intrusion, steam eruptions, earthquakes, gravitational instability, or possibly even heavy rainfall.
Eruptive history.
Early history.
Research beginning in the late 1990s shows that Mount Baker is the youngest of several volcanic centers in the area and one of the youngest volcanoes in the Cascade Range. The Pliocene Hannegan caldera is preserved northeast of Mount Baker Volcanic activity in the Mount Baker volcanic field began more than one million years ago, but many of the earliest lava and tephra deposits have been removed by glacial erosion. The pale-colored rocks northeast of the modern volcano mark the site of the ancient (1.15 million years old) Kulshan caldera that collapsed after an enormous ash eruption one million years ago. Subsequently, eruptions in the Mount Baker area have produced cones and lava flows of andesite, the rock that constitutes much of other Cascade Range volcanoes such as Rainier, Adams, and Hood. From about 900,000 years ago to the present, numerous andesitic volcanic centers in the area have come and disappeared through glacial erosion. The largest of these cones is the Black Buttes edifice, active between 500,000 and 300,000 years ago and formerly bigger than today's Mount Baker.
Modern craters and cone.
Mount Baker was built from stacks of lava and volcanic breccia prior to the end of the last glacial period, which ended about 15,000 years ago. There are two craters on the mountain. Ice-filled Carmelo Crater is under the summit ice dome. This crater is the source for the last cone-building eruptions
The highest point of Mount Baker, Grant Peak, is on the exposed southeast rim of Carmelo Crater, which is a small pile of andesitic scoria lying on top of a stack of lava flows just below. Carmelo Crater is deeply dissected on its south side by the younger Sherman Crater. This crater is south of the summit, and its ice-covered floor is below the summit ice dome. This crater is the site of all Holocene eruptive activity. Hundreds of fumaroles vent gases, primarily , , and .
Lava flows from the summit vent erupted between 30,000 and 10,000 years ago and, during the final stages of edifice construction, blocky pyroclastic flows entered the volcano's southeastern drainages. An eruption from Sherman Crater 6,600 years ago erupted a blanket of ash that extended more than to the east. Today, sulfurous gases reach the surface via two fumarole pathways: Dorr Fumarole, northeast of the summit; and Sherman Crater, south of the summit. Both are sites of hydrothermal alteration, converting lavas to weak, white-to-yellow clays; sulfur is a common mineral around these fumaroles. At Sherman Crater, collapses of this weakened rock generated lahars in the 1840s.
Mazama Park eruptive period: 6,600 years ago.
Approximately 6,600 years ago, a series of discrete events culminated in the largest tephra-producing eruption in post-glacial time at Mount Baker. This is the last episode of undoubted magmatic activity preserved in the geologic record. First, the largest collapse in the history of the volcano occurred from the Roman Wall and transformed into a lahar that was over deep in the upper reaches of the Middle Fork of the Nooksack River. It was at least deep downstream from the volcano. At that time the Nooksack River is believed to have drained north into the Fraser River; it is therefore unlikely that this lahar reached Bellingham Bay. Next, a small hydrovolcanic eruption occurred at Sherman Crater, triggering a second collapse of the flank just east of the Roman Wall. That collapse also became a lahar that mainly followed the course of the first lahar for at least , and also spilled into tributaries of the Baker River. Finally, an eruption cloud deposited ash as far as downwind to the northeast and east.
Historical activity.
Several eruptions occurred from Sherman Crater during the 19th century; they were witnessed from the Bellingham area. A possible eruption was seen in June 1792 during the Spanish expedition of Dionisio Alcalá Galiano and Cayetano Valdés. Their report read, in part:
In 1843, explorers reported a widespread layer of newly fallen rock fragments "like a snowfall" and that the forest was "on fire for miles around". It is highly unlikely that these fires were caused by ashfall, however, as charred material is not found with deposits of this fine-grained volcanic ash, which was almost certainly cooled in the atmosphere before falling. Rivers south of the volcano were reportedly clogged with ash, and Native Americans reported that many salmon perished. Reports of flooding on the Skagit River from the eruption are, however, probably greatly exaggerated. A short time later, two collapses of the east side of Sherman Crater produced two lahars, the first and larger of which flowed into the natural Baker Lake, increasing its level by at least . The location of the 19th-century lake is now covered by waters of the modern dam-impounded Baker Lake. Similar but lower level hydrovolcanic activity at Sherman Crater continued intermittently for several decades afterward. On 26 November 1860, passengers who were traveling by steamer from New Westminster to Victoria reported that Mount Baker was "puffing out large volumes of smoke, which upon breaking, rolled down the snow-covered sides of the mountain, forming a pleasing effect of light and shade." In 1891, about of rock fell producing a lahar that traveled more than and covered .
Activity in the 20th century decreased from the 19th century. Numerous small debris avalanches fell from Sherman Peak and descended the Boulder Glacier; a large one occurred on July 27, 2007. In early March 1975, a dramatic increase in fumarolic activity and snow melt in the Sherman Crater area raised concern that an eruption might be imminent. Heat flow increased more than tenfold. Additional monitoring equipment was installed and several geophysical surveys were conducted to try to detect the movement of magma. The increased thermal activity prompted public officials and Puget Power to temporarily close public access to the popular Baker Lake recreation area and to lower the reservoir's water level by . If those actions had not been taken, significant avalanches of debris from the Sherman Crater area could have swept directly into the reservoir, triggering a disastrous wave that could have caused human fatalities and damage to the reservoir. Other than the increased heat flow, few anomalies were recorded during the geophysical surveys, nor were any other precursory activities observed that would indicate that magma was moving up into the volcano. Several small lahars formed from material ejected onto the surrounding glaciers and acidic water was discharged into Baker Lake for many months.
Activity gradually declined over the next two years but stabilized at a higher level than before 1975. The increased level of fumarolic activity has continued at Mount Baker since 1975, but no other changes suggest that magma movement is involved.
Current research at Mount Baker.
A considerable amount of research has been done at Mount Baker over the past decade, and it is now among the most-studied of the Cascade volcanoes. Recent and ongoing projects include gravimetric and GPS-based geodetic monitoring, fumarole gas sampling, tephra distribution mapping, new interpretations of the Schriebers Meadow lava flow, and hazards analyses. Mapping of Carmelo and Sherman craters, and interpretations of the eruptive history, continues, as well. The Mount Baker Volcano Research Center maintains an online archive of abstracts of this work, and an extensive references list, as well as photos.
Glaciers and hydrology.
There are ten main glaciers on the mountain. The Coleman Glacier is the largest; it has a surface area of . The other large glaciers—which have areas greater than —are Roosevelt Glacier, Mazama Glacier, Park Glacier, Boulder Glacier, Easton Glacier and Deming Glacier. All retreated during the first half of the century, advanced from 1950–1975 and have been retreating increasingly rapidly since 1980.
Mount Baker is drained on the north by streams that flow into the North Fork Nooksack River, on the west by the Middle Fork Nooksack River, and on the southeast and east by tributaries of the Baker River. Lake Shannon and Baker Lake are the largest nearby bodies of water, formed by two dams on the Baker River.
U.S. Navy.
Two ammunition ships of the United States Navy (traditionally named for volcanoes) have been named after the mountain. The first was USS "Mount Baker" (AE-4), which was commissioned from 1941 to 1947 and from 1951 to 1969. In 1972, the Navy commissioned USS "Mount Baker" (AE-34). It was decommissioned in 1996 and placed in service with the Military Sealift Command as USNS "Mount Baker" (T-AE-34). She was scrapped in 2012.

</doc>
<doc id="20898" url="https://en.wikipedia.org/wiki?curid=20898" title="Strategic sealift ships">
Strategic sealift ships

Strategic sealift ships are part of the United States Military Sealift Command's (MSC) prepositioning program. There are currently 49 ships in the program, strategically positioned around the globe to support the Army, Navy, Air Force, Marine Corps and Defense Logistics Agency. Most are named after Medal of Honor recipients from the service they support. The ships are assigned to two Military Prepositioning Ship (MPS) squadrons located in the Mediterranean, the Indian Ocean at Diego Garcia and the Western Pacific Ocean at Guam and Saipan. 
The MPS ships in each squadron have sufficient equipment, supplies and ammunition to support a Marine Air-Ground Task Force for 30 days. The MPS ships are self-sustaining, with cranes to unload at sea or pierside. MSC chartered the first two ship classes in the MPS role (the "Corporal Louis J. Hauge Jr." and "Sergeant Matej Kocak" classes) from civilian shipping lines and converted them. Later ships were purpose-built.
Ships.
"Sergeant Matej Kocak" class.
The "Sergeant Matej Kocak" Class, the second class of MPS ships chartered by MSC, also gained 157 feet (48 m) amidships and a helicopter deck after conversion. These ships, delivered to MSC in the mid-1980s, built at Sun Shipbuilding & Drydock Co., Chester, Pennsylvania and converted at National Steel and Shipbuilding Company, San Diego. They were previously owned by Waterman Steamship Corporation but recently sold to MSC and now operated by Keystone Shipping Co.
"2nd Lieutenant John P. Bobo" class.
The "2nd Lieutenant John P. Bobo" class ships are new construction ships delivered to MSC in the mid-1980s from General Dynamics Quincy Shipbuilding Division, Quincy, Mass. They were owned by American Overseas Marine (AMSEA) but have been recently sold to MSC and are now operated by Crowley Technical Management.
Large, medium-speed roll-on/roll-off ships.
"Watson" class.
The of LMSR built at National Steel and Shipbuilding Company in San Diego
Activated Ready Reserve Force ships.
The following are part of the National Defense Reserve Fleet but have been activated and are pre-positioned.
"Wright" class.
Dedicated to USMC aviation logistics support.
Former ships.
"Corporal Louis J. Hauge Jr." class.
Named for Medal of Honor recipient Louis J. Hauge Jr. USMC, the "Corporal Louis J. Hauge Jr." class is the original class of MPS ships chartered by Military Sealift Command. The five ships are Maersk Line ships converted by Bethlehem Steel. During conversion, the ships gained an additional 157 feet (48 m) amidships and a helicopter landing pad, among other things. They have since been returned to Maersk for commercial use and are no longer part of the MPS program.

</doc>
<doc id="20900" url="https://en.wikipedia.org/wiki?curid=20900" title="Mathias Rust">
Mathias Rust

Mathias Rust (born 1 June 1968) is a German aviator known for his illegal landing near Red Square in Moscow on 28 May 1987. An amateur pilot, he flew from Helsinki, Finland to Moscow, being tracked several times by Soviet air defense and interceptors. The Soviet fighters never received permission to shoot him down, and several times he was mistaken for a friendly aircraft. He landed on Vasilevsky Descent next to Red Square near the Kremlin in the capital of the Soviet Union.
Rust said he wanted to create an "imaginary bridge" to the East, and he has claimed that his flight was intended to reduce tension and suspicion between the two Cold War sides. Rust's flight through a supposedly impregnable air defense system had great effect on the Soviet military and led to the dismissal of many senior officers, including Minister of Defense Marshal of the Soviet Union Sergei Sokolov and the Commander-in-Chief of the Soviet Air Defence Forces, former World War II fighter ace pilot Chief Marshal Alexander Koldunov. The incident aided Mikhail Gorbachev in the implementation of his reforms, by allowing him to dismiss numerous military officials opposed to him.
Flight profile.
Rust, aged 18, was an inexperienced pilot, with about 50 hours of flying experience at the time of his flight. On 13 May 1987, Rust left Uetersen near Hamburg and his home town Wedel in his rented Reims Cessna F172P D-ECJB, which was modified by removing some of the seats and replacing them with auxiliary fuel tanks. He spent the next two weeks traveling across Northern Europe, visiting the Faroe islands, spending a week in Iceland, and then visiting Bergen on his way back. He was later quoted as saying that he had the idea of attempting to reach Moscow even before the departure, and he saw the trip to Iceland (where he visited Hofdi House, the site of unsuccessful talks between the United States and the Soviet Union in October 1986) as a way to test his piloting skills.
In the morning of 28 May 1987, Rust refueled at Helsinki-Malmi Airport. He told air traffic control that he was going to Stockholm, and took off at 12:21 p.m. However, immediately after his final communication with traffic control he turned his plane to the east. Air controllers tried to contact him as he was moving around the busy Helsinki–Moscow route, but Rust turned off all communications equipment aboard.
Rust disappeared from the Finnish air traffic radar near Sipoo. Control personnel presumed an emergency and a rescue effort was organized, including a Finnish Border Guard patrol boat. They found an oil patch near the place where Rust disappeared from radar and performed an underwater search with no results. Rust was later fined about €77,500 ($105,000 USD) for this effort. The origin of the oil patch remains unknown.
Rust crossed the Baltic coastline over Estonia and turned towards Moscow. At 14:29 he appeared on Soviet Air Defense (PVO) radar and, after failure to reply to an IFF signal, was assigned combat number 8255. Three SAM divisions tracked him for some time, but failed to obtain permission to launch at him. All air defenses were brought to readiness and two interceptors were sent to investigate. At 14:48 near the city of Gdov one of the pilots observed a white sport plane similar to a Yakovlev Yak-12 and asked for permission to engage, but was denied.
The fighters lost contact with Rust soon after this. While they were being directed back to him he disappeared from radar near Staraya Russa. West German magazine "Bunte" speculated that he might have landed there for some time, citing that he changed his clothes somewhere during his flight and that he took too much time to fly to Moscow considering his plane's speed and the weather conditions.
Air defense re-established contact with Rust's plane several times but confusion followed all of these events. The PVO system had shortly before been divided into several districts, which simplified management but created additional overhead for tracking officers at the districts' borders. The local air regiment near Pskov was on maneuvers and, due to inexperienced pilots' tendency to forget correct IFF designator settings, local control officers assigned all traffic in the area friendly status, including Rust.
Near Torzhok there was a similar situation, as increased air traffic was created by a rescue effort for an air crash the previous day. Rust, flying a slow propeller-driven aircraft, was confused with one of the helicopters taking part in the rescue. He was spotted several more times and given false friendly recognition twice. Rust was considered as a domestic training plane defying regulations, and was issued least priority.
Around 7:00 p.m. Rust appeared above downtown Moscow. He had initially intended to land in the Kremlin, but changed his mind: he reasoned that landing inside, hidden by the Kremlin walls, would have allowed the KGB to simply arrest him and deny the incident. Therefore, he changed his landing spot to Red Square. Heavy pedestrian traffic did not allow him to land there either, so after circling about the square one more time, he was able to land on a bridge by St. Basil's Cathedral. A later inquiry found that trolleybus wires normally strung over the bridge—which would have incidentally prevented his landing there—had been removed for maintenance that very morning, and were replaced the day after. After taxiing past the cathedral he stopped about from the square, where he was greeted by curious passersby and was asked for autographs. When asked where he was from, he replied "Germany" making the bystanders think he was from East Germany; but when he said West Germany, they were surprised. A British doctor videotaped Rust circling over Red Square and landing on the bridge. Rust was arrested two hours later.
Aftermath.
Rust's trial began in Moscow on 2 September 1987. He was sentenced to four years in a general-regime labor camp for hooliganism, for disregard of aviation laws, and for breaching the Soviet border. He was never transferred to a labor camp, however, and instead served his time at the high security Lefortovo temporary detention facility in Moscow. Two months later, Reagan and Gorbachev agreed to sign a treaty to eliminate intermediate-range nuclear weapons in Europe, and the Supreme Soviet ordered Rust to be released in August 1988 as a goodwill gesture to the West.
Rust's return to Germany on 3 August 1988 was accompanied by huge media attention, but he did not talk to the assembled journalists; his family had sold the exclusive rights to the story to the German magazine "Stern" for DM 100,000. He reported that he had been treated well in the Soviet prison. Journalists described him as "psychologically unstable and unworldly in a dangerous manner".
William E. Odom, former director of the U.S. National Security Agency and author of "The Collapse of the Soviet Military", says that Rust's flight irreparably damaged the reputation of the Soviet military. This enabled Gorbachev to remove many of the strongest opponents to his reforms. Minister of Defense Sergei Sokolov and the head of the Soviet Air Defence Forces Alexander Koldunov were dismissed along with hundreds of other officers. This was the biggest turnover in the Soviet military since Stalin's purges 50 years earlier.
Rust's rented Reims Cessna F172P (serial # F17202087), registered "D-ECJB", was sold to Japan where it was exhibited for several years. In 2008 it was returned to Germany and was placed in the Deutsches Technikmuseum in Berlin.
Later life.
While doing his obligatory community service ("Zivildienst") in a West German hospital in 1989, Rust stabbed a female co-worker who had rejected him. The victim barely survived. He was convicted of attempted manslaughter and sentenced to two and a half years in prison, but was released after 15 months. Since then he has lived a fragmented life, describing himself as a "bit of an oddball." After being released from court, he converted to Hinduism in 1996 to become engaged to a daughter of an Indian tea merchant. In 2001, he was convicted of stealing a cashmere pullover and ordered to pay a fine of DM 10,000, which was later reduced to DM 600. A further brush with the law came in 2005, when he was convicted of fraud and had to pay €1,500 for stolen goods. In 2009 Rust described himself as a professional poker player. Most recently, in 2012, he described himself as an analyst at a Zurich-based investment bank.
Peace activism.
In October 2015, "The Hindu" published an interview with Mathias Rust to mark the 25th anniversary of German reunification. Mathias Rust surmised that institutional failures in Western countries to preserve moral standards and uphold the primacy of democratic ideals was creating mistrust between peoples and governments. Pointing to the genesis of a New Cold War between Russia and the Western powers, Mathias Rust suggested that India should tread with caution and avoid entanglement: “India will be better served if it follows a policy of neutrality while interacting with EU member countries as the big European powers at present are following the foreign policy of the U.S. unquestioningly”. Mathias Rust drew attention to the "casus belli" which is fuelling Euroscepticism: “Governments have been dominated by the corporate entities and citizens have ceased to matter in public policy”.
In popular culture.
Because Rust's flight seemed as a blow to the authority of the Soviet regime, it was the source of numerous jokes and urban legends. For a while after the incident, Red Square was jokingly referred to by Muscovites as Sheremetyevo-3 (Sheremetyevo-1 and -2 being the two terminals at Moscow's main international airport). At the end of 1987, the police radio code used by law enforcement officers in Moscow was allegedly updated to include a code for an aircraft landing.
Shortly after the incident, SubLogic, the original publishers of the "Flight Simulator" franchise, issued a scenery disk that expanded the original program's coverage area to include the Eastern Bloc. A challenge in the expansion pack was to land in Red Square as Rust had just done.
In the media.
Following the 20th anniversary of his flight on 28 May 2007, the international media interviewed Rust about the flight and its aftermath.
"The Washington Post" and "Bild" both have online editions of their interviews. The most comprehensive televised interview available online is produced by the Danish Broadcasting Corporation. In their interview "Rust in Red Square", recorded in May 2007, Rust gives a full account of the flight in English.

</doc>
<doc id="20901" url="https://en.wikipedia.org/wiki?curid=20901" title="Malware">
Malware

Malware, short for malicious software, is any software used to disrupt computer operations, gather sensitive information, gain access to private computer systems, or display unwanted advertising. Malicious software was called computer virus before the term malware was coined in 1990 by Yisrael Radai. The first category of malware propagation concerns parasitic software fragments that attach themselves to some existing executable content. The fragment may be machine code that infects some existing application, utility, or system program, or even the code used to boot a computer system. Malware is defined by its malicious intent, acting against the requirements of the computer user, and does not include software that causes unintentional harm due to some deficiency. The term "badware" is sometimes used, and applied to both true (malicious) malware and unintentionally harmful software.
Malware may be stealthy, intended to steal information or spy on computer users for an extended period without their knowledge, as for example Regin, or it may be designed to cause harm, often as sabotage (e.g., Stuxnet), or to extort payment (CryptoLocker). 'Malware' is an umbrella term used to refer to a variety of forms of hostile or intrusive software, including computer viruses, worms, trojan horses, ransomware, spyware, adware, scareware, and other malicious programs. It can take the form of executable code, scripts, active content, and other software. Malware is often disguised as, or embedded in, non-malicious files. the majority of active malware threats were worms or trojans rather than viruses.
In law, malware is sometimes known as a computer contaminant, as in the legal codes of several U.S. states.
Spyware or other malware is sometimes found embedded in programs supplied officially by companies, e.g., downloadable from websites, that appear useful or attractive, but may have, for example, additional hidden tracking functionality that gathers marketing statistics. An example of such software, which was described as illegitimate, is the Sony rootkit, a Trojan embedded into CDs sold by Sony, which silently installed and concealed itself on purchasers' computers with the intention of preventing illicit copying; it also reported on users' listening habits, and unintentionally created vulnerabilities that were exploited by unrelated malware.
Software such as anti-virus, anti-malware, and firewalls are used to protect against activity identified as malicious, and to recover from attacks.
Purposes.
Many early infectious programs, including the first Internet Worm, were written as experiments or pranks. Today, malware is used by both black hat hackers and governments, to steal personal, financial, or business information.
Malware is sometimes used broadly against government or corporate websites to gather guarded information, or to disrupt their operation in general. However, malware is often used against individuals to gain information such as personal identification numbers or details, bank or credit card numbers, and passwords. Left unguarded, personal and networked computers can be at considerable risk against these threats. (These are most frequently defended against by various types of firewall, anti-virus software, and network hardware).
Since the rise of widespread broadband Internet access, malicious software has more frequently been designed for profit. Since 2003, the majority of widespread viruses and worms have been designed to take control of users' computers for illicit purposes. Infected "zombie computers" are used to send email spam, to host contraband data such as child pornography, or to engage in distributed denial-of-service attacks as a form of extortion.
Programs designed to monitor users' web browsing, display unsolicited advertisements, or redirect affiliate marketing revenues are called spyware. Spyware programs do not spread like viruses; instead they are generally installed by exploiting security holes. They can also be hidden and packaged together with unrelated user-installed software.
Ransomware affects an infected computer in some way, and demands payment to reverse the damage. For example, programs such as CryptoLocker encrypt files securely, and only decrypt them on payment of a substantial sum of money.
Some malware is used to generate money by click fraud, making it appear that the computer user has clicked an advertising link on a site, generating a payment from the advertiser. It was estimated in 2012 that about 60 to 70% of all active malware used some kind of click fraud, and 22% of all ad-clicks were fraudulent.
Malware is usually used for criminal purposes, but can be used for sabotage, often without direct benefit to the perpetrators. One example of sabotage was Stuxnet, used to destroy very specific industrial equipment. There have been politically motivated attacks that have spread over and shut down large computer networks, including massive deletion of files and corruption of master boot records, described as "computer killing". Such attacks were made on Sony Pictures Entertainment (25 November 2014, using malware known as Shamoon or W32.Disttrack) and Saudi Aramco (August 2012).
Proliferation.
Preliminary results from Symantec published in 2008 suggested that "the release rate of malicious code and other unwanted programs may be exceeding that of legitimate software applications." According to F-Secure, "As much malware produced in 2007 as in the previous 20 years altogether." Malware's most common pathway from criminals to users is through the Internet: primarily by e-mail and the World Wide Web.
The prevalence of malware as a vehicle for Internet crime, along with the challenge of anti-malware software to keep up with the continuous stream of new malware, has seen the adoption of a new mindset for individuals and businesses using the Internet. With the amount of malware currently being distributed, some percentage of computers are currently assumed to be infected. For businesses, especially those that sell mainly over the Internet, this means they need to find a way to operate despite security concerns. The result is a greater emphasis on back-office protection designed to protect against advanced malware operating on customers' computers. A 2013 Webroot study shows that 64% of companies allow remote access to servers for 25% to 100% of their workforce and that companies with more than 25% of their employees accessing servers remotely have higher rates of malware threats.
On 29 March 2010, Symantec Corporation named Shaoxing, China, as the world's malware capital. A 2011 study from the University of California, Berkeley, and the Madrid Institute for Advanced Studies published an article in "Software Development Technologies", examining how entrepreneurial hackers are helping enable the spread of malware by offering access to computers for a price. Microsoft reported in May 2011 that one in every 14 downloads from the Internet may now contain malware code. Social media, and Facebook in particular, are seeing a rise in the number of tactics used to spread malware to computers.
A 2014 study found that malware is being increasingly aimed at mobile devices such as smartphones as they increase in popularity.
Infectious malware: viruses and worms.
The best-known types of malware, viruses and worms, are known for the manner in which they spread, rather than any specific types of behavior. The term "computer virus" is used for a program that embeds itself in some other executable software (including the operating system itself) on the target system without the user's consent and when that is run causes the virus to spread to other executables. On the other hand, a "worm" is a stand-alone malware program that "actively" transmits itself over a network to infect other computers. These definitions lead to the observation that a virus requires the user to run an infected program or operating system for the virus to spread, whereas a worm spreads itself.
Concealment: Viruses, trojan horses, rootkits, backdoors and evasion.
These categories are not mutually exclusive, so malware may use multiple techniques. This section only applies to malware designed to operate undetected, not sabotage and ransomware.
Viruses.
A computer program usually hidden within another seemingly innocuous program that produces copies of itself and inserts them into other programs or files, and that usually performs a malicious action (such as destroying data).
Trojan horses.
In computing, Trojan horse, or Trojan, is any malicious computer program which misrepresents itself to appear useful, routine, or interesting in order to persuade a victim to install it. The term is derived from the Ancient Greek story of the wooden horse that was used to help Greek troops invade the city of Troy by stealth.
Trojans are generally spread by some form of social engineering, for example where a user is duped into executing an e-mail attachment disguised to be unsuspicious, (e.g., a routine form to be filled in), or by drive-by download. Although their payload can be anything, many moderns forms act as a backdoor, contacting a controller which can then have unauthorized access to the affected computer. While Trojans and backdoors are not easily detectable by themselves, computers may appear to run slower due to heavy processor or network usage.
Unlike computer viruses and worms, Trojans generally do not attempt to inject themselves into other files or otherwise propagate themselves.
Rootkits.
Once a malicious program is installed on a system, it is essential that it stays concealed, to avoid detection. Software packages known as "rootkits" allow this concealment, by modifying the host's operating system so that the malware is hidden from the user. Rootkits can prevent a malicious process from being visible in the system's list of processes, or keep its files from being read.
Some malicious programs contain routines to defend against removal, not merely to hide themselves. An early example of this behavior is recorded in the Jargon File tale of a pair of programs infesting a Xerox CP-V time sharing system:
Backdoors.
A backdoor is a method of bypassing normal authentication procedures, usually over a connection to a network such as the Internet. Once a system has been compromised, one or more backdoors may be installed in order to allow access in the future, invisibly to the user.
The idea has often been suggested that computer manufacturers preinstall backdoors on their systems to provide technical support for customers, but this has never been reliably verified. It was reported in 2014 that US government agencies had been diverting computers purchased by those considered "targets" to secret workshops where software or hardware permitting remote access by the agency was installed, considered to be among the most productive operations to obtain access to networks around the world. Backdoors may be installed by Trojan horses, worms, implants, or other methods.
Evasion.
Since the beginning of 2015, a sizable portion of malware utilizes a combination of many techniques designed to avoid detection and analysis.
Nowadays, one of the most sophisticated and stealthy ways of evasion is the use information hiding techniques, namely Stegomalware.
Vulnerability to malware.
Security defects in software.
Malware exploits security defects (security bugs or vulnerabilities) in the design of the operating system, in applications (such as browsers, e.g. older versions of Microsoft Internet Explorer supported by Windows XP), or in vulnerable versions of browser plugins such as Adobe Flash Player, Adobe Acrobat or Reader, or Java SE. Sometimes even installing new versions of such plugins does not automatically uninstall old versions. Security advisories from plug-in providers announce security-related updates. Common vulnerabilities are assigned CVE IDs and listed in the US National Vulnerability Database. Secunia PSI is an example of software, free for personal use, that will check a PC for vulnerable out-of-date software, and attempt to update it.
Malware authors target bugs, or loopholes, to exploit. A common method is exploitation of a buffer overrun vulnerability, where software designed to store data in a specified region of memory does not prevent more data than the buffer can accommodate being supplied. Malware may provide data that overflows the buffer, with malicious executable code or data after the end; when this payload is accessed it does what the attacker, not the legitimate software, determines.
Insecure design or user error.
Early PCs had to be booted from floppy disks; when built-in hard drives became common the operating system was normally started from them, but it was possible to boot from another boot device if available, such as a floppy disk, CD-ROM, DVD-ROM, USB flash drive or network. It was common to configure the computer to boot from one of these devices when available. Normally none would be available; the user would intentionally insert, say, a CD into the optical drive to boot the computer in some special way, for example to install an operating system. Even without booting, computers can be configured to execute software on some media as soon as they become available, e.g. to autorun a CD or USB device when inserted.
Malicious software distributors would trick the user into booting or running from an infected device or medium; for example, a virus could make an infected computer add autorunnable code to any USB stick plugged into it; anyone who then attached the stick to another computer set to autorun from USB would in turn become infected, and also pass on the infection in the same way. More generally, any device that plugs into a USB port-—"including gadgets like lights, fans, speakers, toys, even a digital microscope"—can be used to spread malware. Devices can be infected during manufacturing or supply if quality control is inadequate.
This form of infection can largely be avoided by setting up computers by default to boot from the internal hard drive, if available, and not to autorun from devices. Intentional booting from another device is always possible by pressing certain keys during boot.
Older email software would automatically open HTML email containing potentially malicious JavaScript code; users may also execute disguised malicious email attachments and infected executable files supplied in other ways.
Over-privileged users and over-privileged code.
In computing, privilege refers to how much a user or program is allowed to modify a system. In poorly designed computer systems, both users and programs can be assigned more privileges than they should be, and malware can take advantage of this. The two ways that malware does this is through overprivileged users and overprivileged code.
Some systems allow all users to modify their internal structures, and such users today would be considered over-privileged users. This was the standard operating procedure for early microcomputer and home computer systems, where there was no distinction between an "administrator" or "root", and a regular user of the system. In some systems, non-administrator users are over-privileged by design, in the sense that they are allowed to modify internal structures of the system. In some environments, users are over-privileged because they have been inappropriately granted administrator or equivalent status.
Some systems allow code executed by a user to access all rights of that user, which is known as over-privileged code. This was also standard operating procedure for early microcomputer and home computer systems. Malware, running as over-privileged code, can use this privilege to subvert the system. Almost all currently popular operating systems, and also many scripting applications allow code too many privileges, usually in the sense that when a user executes code, the system allows that code all rights of that user. This makes users vulnerable to malware in the form of e-mail attachments, which may or may not be disguised.
Anti-malware strategies.
As malware attacks become more frequent, attention has begun to shift from viruses and spyware protection, to malware protection, and programs that have been specifically developed to combat malware. (Other preventive and recovery measures, such as backup and recovery methods, are mentioned in the computer virus article).
Anti-virus and anti-malware software.
A specific component of anti-virus and anti-malware software, commonly referred to as an on-access or real-time scanner, hooks deep into the operating system's core or kernel and functions in a manner similar to how certain malware itself would attempt to operate, though with the user's informed permission for protecting the system. Any time the operating system accesses a file, the on-access scanner checks if the file is a 'legitimate' file or not. If the file is identified as malware by the scanner, the access operation will be stopped, the file will be dealt with by the scanner in a pre-defined way (how the anti-virus program was configured during/post installation), and the user will be notified. This may have a considerable performance impact on the operating system, though the degree of impact is dependent on how well the scanner was programmed. The goal is to stop any operations the malware may attempt on the system before they occur, including activities which might exploit bugs or trigger unexpected operating system behavior.
Anti-malware programs can combat malware in two ways:
Real-time protection from malware works identically to real-time antivirus protection: the software scans disk files at download time, and blocks the activity of components known to represent malware. In some cases, it may also intercept attempts to install start-up items or to modify browser settings. Because many malware components are installed as a result of browser exploits or user error, using security software (some of which are anti-malware, though many are not) to "sandbox" browsers (essentially isolate the browser from the computer and hence any malware induced change) can also be effective in helping to restrict any damage done.
Examples of Microsoft Windows antivirus and anti-malware software include the optional Microsoft Security Essentials (for Windows XP, Vista, and Windows 7) for real-time protection, the Windows Malicious Software Removal Tool (now included with Windows (Security) Updates on "Patch Tuesday", the second Tuesday of each month), and Windows Defender (an optional download in the case of Windows XP, incorporating MSE functionality in the case of Windows 8 and later). Additionally, several capable antivirus software programs are available for free download from the Internet (usually restricted to non-commercial use). Tests found some free programs to be competitive with commercial ones. Microsoft's System File Checker can be used to check for and repair corrupted system files.
Some viruses disable System Restore and other important Windows tools such as Task Manager and Command Prompt. Many such viruses can be removed by rebooting the computer, entering Windows safe mode with networking, and then using system tools or Microsoft Safety Scanner.
Hardware implants can be of any type, so there can be no general way to detect them.
Website security scans.
As malware also harms the compromised websites (by breaking reputation, blacklisting in search engines, etc.), some websites offer vulnerability scanning.
Such scans check the website, detect malware, may note outdated software, and may report known security issues.
"Air gap" isolation or "Parallel Network".
As a last resort, computers can be protected from malware, and infected computers can be prevented from disseminating trusted information, by imposing an "air gap" (i.e. completely disconnecting them from all other networks). However, malware can still cross the air gap in some situations. For example, removable media can carry malware across the gap. In December 2013 researchers in Germany showed one way that an apparent air gap can be defeated.
Later in 2015, "BitWhisper", a Covert Signaling Channel between Air-Gapped Computers using Thermal Manipulations was introduced. "BitWhisper" supports bidirectional communication and requires no additional dedicated peripheral hardware.
Grayware.
Grayware is a term applied to unwanted applications or files that are not classified as malware, but can worsen the performance of computers and may cause security risks.
It describes applications that behave in an annoying or undesirable manner, and yet are less serious or troublesome than malware. Grayware encompasses spyware, adware, fraudulent dialers, joke programs, remote access tools and other unwanted programs that harm the performance of computers or cause inconvenience. The term came into use around 2004.
Another term, PUP, which stands for "Potentially Unwanted Program" (or PUA "Potentially Unwanted Application"), refers to applications that would be considered unwanted despite often having been downloaded by the user, possibly after failing to read a download agreement. PUPs include spyware, adware, fraudulent dialers. Many security products classify unauthorised key generators as grayware, although they frequently carry true malware in addition to their ostensible purpose.
Software maker Malwarebytes lists several criteria for classifying a program as a PUP. Some adware (using stolen certificates) disables anti-malware and virus protection; technical remedies are available.
History of viruses and worms.
Before Internet access became widespread, viruses spread on personal computers by infecting the executable boot sectors of floppy disks. By inserting a copy of itself into the machine code instructions in these executables, a virus causes itself to be run whenever a program is run or the disk is booted. Early computer viruses were written for the Apple II and Macintosh, but they became more widespread with the dominance of the IBM PC and MS-DOS system. Executable-infecting viruses are dependent on users exchanging software or boot-able floppies and thumb drives so they spread rapidly in computer hobbyist circles.
The first worms, network-borne infectious programs, originated not on personal computers, but on multitasking Unix systems. The first well-known worm was the Internet Worm of 1988, which infected SunOS and VAX BSD systems. Unlike a virus, this worm did not insert itself into other programs. Instead, it exploited security holes (vulnerabilities) in network server programs and started itself running as a separate process. This same behavior is used by today's worms as well.
With the rise of the Microsoft Windows platform in the 1990s, and the flexible macros of its applications, it became possible to write infectious code in the macro language of Microsoft Word and similar programs. These "macro viruses" infect documents and templates rather than applications (executables), but rely on the fact that macros in a Word document are a form of executable code.
Today, worms are most commonly written for the Windows OS, although a few like Mare-D and the L10n worm are also written for Linux and Unix systems. Worms today work in the same basic way as 1988's Internet Worm: they scan the network and use vulnerable computers to replicate. Because they need no human intervention, worms can spread with incredible speed. The SQL Slammer infected thousands of computers in a few minutes in 2003.
Academic research.
The notion of a self-reproducing computer program can be traced back to initial theories about the operation of complex automata. John von Neumann showed that in theory a program could reproduce itself. This constituted a plausibility result in computability theory. Fred Cohen experimented with computer viruses and confirmed Neumann's postulate and investigated other properties of malware such as detectability and self-obfuscation using rudimentary encryption. His doctoral dissertation was on the subject of computer viruses. The combination of cryptographic technology as part of the payload of the virus, exploiting it for attack purposes was initialized and investigated from the mid 1990s, and includes initial ransomware and evasion ideas.

</doc>
<doc id="20905" url="https://en.wikipedia.org/wiki?curid=20905" title="Muttiah Muralitharan">
Muttiah Muralitharan

Deshabandu Muttiah Muralitharan (also spelt Muralidaran; born 1972) is a former Sri Lankan cricketer who was rated the greatest Test match bowler ever by "Wisden Cricketers' Almanack" in 2002. He retired from Test cricket in 2010, registering his 800th and final wicket on 22 July 2010 from his final ball in his last Test match. Muralitharan holds the world record for the most wickets in both test and one-day cricket.
Muralitharan took the wicket of Gautam Gambhir on 5 February 2009 in Colombo to surpass Wasim Akram's ODI record of 501 wickets. He became the highest wicket-taker in Test cricket when he overtook the previous record-holder Shane Warne on 2007. Muralitharan had previously held the record when he surpassed Courtney Walsh's 519 wickets in 2004, but he suffered a shoulder injury later that year and was then overtaken by Warne.
Averaging over six wickets per Test, Muralitharan is one of the most successful bowlers in the game. Muralitharan held the number one spot in the International Cricket Council’s player rankings for Test bowlers for a record period of 1,711 days spanning 214 Test matches.
Muralitharan's career was beset by controversy over his bowling action for much of his international career. Due to an unusual hyperextension of his congenitally bent arm during delivery, his bowling action was called into question on a number of occasions by umpires and sections of the cricket community. After biomechanical analysis under simulated playing conditions, Muralitharan's action was cleared by the International Cricket Council, first in 1996 and again in 1999. Former Australian Test player Bruce Yardley, who himself was an off spinner in his day, was assigned with the task of ensuring Muralitharan bowled all his deliveries with the same vigour as he would do so in match conditions when tested in 2004. Muralitharan had not commenced bowling the doosra at this time. The legality of his doosra was first called into question in 2004. This delivery was found to exceed the ICC elbow extension limit by nine degrees, five degrees being the limit for spinners at that time. Based on official studies into bowling actions, which revealed that 99% of bowlers whose actions were examined exceeded the elbow flexion limits, ICC revised the limits applying to all bowlers in 2005. The new limit of 15-degrees, one degree greater than Muralitharan was bowling his doosra, allowed him to continue without being called for throwing from then on.
In February 2009, after becoming cricket's highest wicket-taker in both forms of the game Muttiah Muralitharan hinted that he might retire at the conclusion of the 2011 World Cup. He stated "I think I am fit in my body and mind, I am enjoying my cricket and want to play more. But after the next World Cup, I will have nothing left to achieve in the game. The World Cup should mark the end of my career." Muralitharan announced his retirement from Test cricket after the first Test against India at Galle which commenced on 2010. During that match he captured 8 wickets and became the first to reach the milestone of taking 800 Test wickets by dismissing Pragyan Ojha.
He was the sixth international franchise player signed to the Caribbean Premier League and the first Sri Lankan player to be named to the new Twenty20 tournament.
Early years and personal life.
Muralitharan was born in Kandy, the eldest of the four sons to Sinnasamy Muttiah and Lakshmi. Muralitharan's father Sinnasamy Muttiah, runs a successful biscuit-making business.
When he was nine years old Muralitharan was sent to St. Anthony's College, Kandy, a private school run by Benedictine monks. He began his cricketing career as a medium pace bowler but on the advice of his school coach, Sunil Fernando, he took up off-spin when he was fourteen years old. He soon impressed and went on to play for four years in the school First XI. In those days he played as an all-rounder and batted in the middle order. In his final two seasons at St Anthony's College he took over one hundred wickets and in 1990/1 was named as the 'Bata Schoolboy Cricketer of the Year'.
After leaving school he joined Tamil Union Cricket and Athletic Club and was selected for the Sri Lanka A tour of England in 1991. He played in five games but failed to capture a single wicket. On his return to Sri Lanka he impressed against Allan Border's Australian team in a practice game and then went on to make his Test debut at R. Premadasa Stadium in the Second Test Match of the series.
When his grandfather died at the age of 104 in July 2004, Muralitharan returned home from a tour of India to attend his funeral. Periyasamy Sinasamy's first wish to see Muralitharan claiming the world record for the most Test wickets was realised (passing the record set by Courtney Walsh), but not his desire to live to see his grandson married. Muralitharan's grandmother had died one month earlier at the age of 97. Muralitharan's manager, Kushil Gunasekera stated that "Murali's family is closely knit and united. They respect traditional values. The late grandfather enjoyed a great relationship with Murali."
Muralitharan married Madhimalar Ramamurthy, a Chennai girl, on 2005. Madhimalar is the daughter of late Dr S. Ramamurthy of Malar Hospitals, and his wife Dr Nithya Ramamurthy. Their first child, Naren, was born in January 2006.
Muttiah Muralitharan holds Overseas Citizenship of India (OCI) and he does not need a visa for travelling to India. According to his manager, Kushil Gunasekera, Muralitharan qualifies for this status because his family originates from India.
Muralitharan's paternal grandfather Periyasamy Sinasamy came from South India to work in the tea plantations of central Sri Lanka in 1920. Sinasamy later returned to the country of his birth with his daughters and settled in Namakkal, Tamil Nadu, India. However, his sons, including Muralitharan's father Muttiah, remained in Sri Lanka.
Muttiah announced on 3 April 2011 that he was retiring from all sport.
Spelling and meaning of name.
Even though his name was widely romanised as Muralitharan from the start of his career, he prefers the spelling Muralidaran. The different spellings have arisen because the Tamil letter த can be pronounced as both 't' and 'd' depending on its place in a word. It is often transliterated as 'th' to distinguish it from another letter, ட, which is a retroflex 't' or 'd'. In 2007, when Cricket Australia decided to unveil the new Warne-Muralidaran Trophy, to be contested between Australia and Sri Lanka, Muralitharan was requested to clarify how his name should be spelt. Cricket Australia spokesman Peter Young confirmed that "the spelling he's given is Muralidaran".
The first-day cover involving Muralitharan bears an official seal captioned as "The highest wicket taker in Test cricket, MUTHIAH MURALIDARAN, First Day of Issue 03.12.2007, Camp Post Office, Asgiriya International Cricket Stadium, Kandy".
The name Muralitharan is derived from "murali dhar" (Devnagri: मुरली धर) meaning "the bearer of the flute", which is a synonym for Lord Krishna, a deity in Hinduism who is said to play upon his bamboo flute while looking after cattle. A variation of this Sanskrit name spelt as 'Muralidharan' and 'Muraleedharan' is a common name amongst Tamil and Malayali Hindus and is not related to the cricketer and the Sri Lankan Tamil community.
Domestic cricket.
In Sri Lanka.
In domestic cricket, Muralitharan played for two first-class Sri Lankan sides, Tamil Union Cricket and Athletic Club in the Premier Trophy and Central Province in the Provincial Championship. His record is exceptional – 234 wickets at 14.51 runs in 46 matches.
In England.
He also played county cricket in England, mainly for Lancashire (1999, 2001, 2005 and 2007) where he appeared in twenty-eight first-class games for the club. He played five first class games for Kent during the 2003 season. His bowling record in English domestic cricket is also exceptional – 236 wickets at 15.62 runs in 33 matches. Despite his efforts, he was never on a title winning first-class domestic team in either the Premier Trophy or the County Championship. He was unusual amongst his contemporaries in that he played in more Test matches than other first-class games (116 Tests and 99 other first class matches as of 2007). Muralitharan had been signed by Gloucestershire in 2011 to play in T20 matches, and he also renewed his T20 contract with Gloucestershire in 2012, but did not stay for the 2013 season.
In India.
In February 2008, Muralitharan was slated to play Twenty20 cricket for the Chennai Super Kings in the Indian Premier League (IPL). He was bought for $600,000 by India Cements, the Chennai franchisee of the IPL, through a bidding process. The Chennai Super Kings were the runners up in the inaugural edition of the IPL, losing to the Rajasthan Royals in the final. Muralitharan captured 11 wickets in 15 games, at an economy rate of 6.96 an over. In 2010, in the third season of IPL, Muralitharan was part of the Chennai Super Kings side that won the IPL championship. Muralitharan also remained the side's leading wicket-taker after all the three tournaments.
At the 2011 IPL Player Auction Muralitharan was bought by Kochi Tuskers Kerala for $1.1 million USD.
In the 2012 season Muralitharan moved to Royal Challengers Bangalore where he took 14 wickets in 9 games and had an average economy rate of 6.38. He played for Royal Challengers Bangalore from 2012-2014 and he later decided to retire from IPL in 2014
In 2015 Indian Premier League Muralitharan was appointed as Sunrisers Hyderabad Bowling coach and Mentor of the team
Muralitharan, was contracted to represent Bengal in the 2008–09 Ranji Trophy tournament. He was expected to play about four matches in the tournament's second division – the Plate League.
In Australia.
Muttiah Muralitharan signed for the Melbourne Renegades to play Twenty20 cricket in the Big Bash League, in 2012. He stated, "I wanted to play one season in Australia and the opportunity from the Melbourne Renegades was there so I took it with both hands."
International career.
Bowling style and career progress.
Muralitharan is the first wrist-spinning off-spinner in the history of the game.
He bowls marathon spells, yet he is usually on the attack. His unique bowling action begins with a short run-up, and culminates with an open-chested extremely wristy release from a partly supinated forearm which had him mistaken for a leg-spinner early in his career by Allan Border. Aside from his stock delivery, the off-break, of which he claim to have two variations, his main deliveries are a fast topspinner which lands on the seam and usually goes straight on, and the doosra, a surprise delivery which turns from leg to off (the opposite direction of his stock delivery) with no easily discernible change of action. His newest variation is a version of Shane Warne's slider, which is flicked out the side of his hand and rushes onto batsmen like a flipper. His super-flexible wrist makes him especially potent and guarantees him turn on any surface.
From his debut in 1992, Muralitharan took 800 Test wickets and over 500 One Day International wickets, becoming the first player to take 1,000 wickets combined in the two main forms of international cricket.
Test cricket.
Emerging years.
On 28 August 1992 at the age of 20, Muralitharan made his debut against Australia at the Khettarama Stadium and claimed 3 for 141. Craig McDermott was his first Test wicket. His freakish action and his angular run-up showed that this was no run-of-the-mill spinner. During his first Test, there was one dismissal which convinced many of Muralitharan's special powers. Tom Moody's leg-stump was dislodged when he shouldered arms to a delivery that pitched at least two feet outside the off-stump.
The youthful Muralitharan went from strength to strength, playing a major part in Sri Lanka's back-to-back Test victories against England and New Zealand in 1992–93. It was at this point in his career that he struck a close bond with his leader, mentor and one time business partner, the authoritative captain Arjuna Ranatunga. This relationship formed the bedrock of his success and meant that there were few doubts about his status as the team's sole wicket-taker. Ranatunga was thoroughly convinced that Muralitharan's precocious talent would signal a new era in Sri Lanka's short Test history.
In August 1993 at Moratuwa, Muralitharan captured 5 for 104 in South Africa's first innings, his first five-wicket haul in Tests. His wickets included Kepler Wessels, Hansie Cronje and Jonty Rhodes.
Muralitharan continued to baffle batsman outside the shores of Sri Lanka, irrespective of the team's performance. In Sri Lanka's humiliating drubbing at the hands of India in 1993–94, where all three Tests were innings defeats, Muralitharan was the sole success, with 12 wickets in the rubber. His perseverance in the face of some astronomical scores by the fearsome quartet of Mohammed Azharuddin, Sachin Tendulkar, Navjot Sidhu and Vinod Kambli was in sharp contrast to the submission with which his team-mates played the series.
It was in New Zealand in March 1995 that Muralitharan displayed his qualities as a match-winner on any surface. In Sri Lanka's first triumph on foreign soil, Muralitharan confused the crease-bound New Zealanders on a grassy pitch in Dunedin. The Sri Lankan manager Duleep Mendis' claim that Muralitharan can turn the ball on concrete was confirmed. On the eve of his tour of Pakistan later that year, doubts were cast on his ability to trouble subcontinental batsmen. By taking 19 wickets in the series and delivering a historic 2–1 victory, the off-spinner silenced the doubters. The Pakistanis, who had negotiated Warne's leg-breaks in the previous home series, were never at ease against him.
Prior to the eventful Boxing Day Test of 1995, Muralitharan had captured 80 wickets in 22 Tests at an unflattering average of 32.74. Even at that point in his career he was the leading wicket taker for Sri Lanka having gone past Rumesh Ratnayake's aggregate of 73 wickets.
Boxing Day Test 1995.
During the second Test between Sri Lanka and Australia at the Melbourne Cricket Ground on Boxing Day 1995, Australian umpire Darrell Hair called Sri Lankan spinner Muttiah Muralitharan for throwing in front of a crowd of 55,239. The off-spinner was no-balled seven times in three overs by Hair, who believed the then 23-year-old was bending his arm and straightening it in the process of delivery; an illegal action in cricket.
Muralitharan had bowled two overs before lunch from umpire Steve Dunne's or the Members' End of the ground with umpire Hair at square leg and these passed without incident. At he took up the attack from umpire Hair's or the southern end. Muralitharan's third over was a maiden with all deliveries again passed as legitimate but in his fourth Hair no-balled him twice for throwing on the fourth and sixth balls. The umpire continued to call him three times in his fifth over on the second, fourth and sixth balls. While the bowler stood with his hands on his hips perplexed, the five calls provoked an immediate response by the Sri Lankan captain Arjuna Ranatunga who left the field at in order to take advice from his team management. He returned at and continued with Muralitharan who was called two more times in his sixth over on the second and sixth balls. At Ranatunga removed the bowler from the attack, although he reintroduced him at at umpire Dunne's end. Although Hair reports in his book, "Decision Maker", that at the end of the tea break he stated that he would call Muralitharan no matter which end he bowled he did not do so. Muralitharan completed another twelve overs without further no-balls and, after bowling Mark Waugh, finished the day with figures of 18–3–58–1.
After being no-balled Muralitharan bowled a further 32 overs from umpire Steve Dunne's end without protest from either Dunne or Hair, at square leg. The Sri Lankan camp was outraged after the incident, but the ICC defended Hair, outlining a list of steps they had taken in the past to determine, without result, the legitimacy of Muralitharan's action. By calling Muralitharan from the bowlers' end Hair overrode what is normally regarded as the authority of the square leg umpire in adjudicating on throwing. Dunne would have had to break convention to support his partner.
At the end of the match the Sri Lankans requested from the ICC permission to confer with Hair in order to find out exactly how to remedy the problem with their bowler. Despite the game's controlling body agreeing to it, the Australian Cricket Board vetoed it on the grounds that it might lead to umpires being quizzed by teams after every game and meant that the throwing controversy would continue into the World Series Cup during the coming week. The Sri Lankans were disappointed they did not get an explanation and decided they would continue playing their bowler in matches not umpired by Hair and wanted to know whether other umpires would support or reject Hair's judgement.
Muralitharan's action was cleared by the ICC after biomechanical analysis at the University of Western Australia and at the Hong Kong University of Science & Technology in 1996. They concluded that his action created the 'optical illusion of throwing'.
Mid career.
On 16 March 1997, Muralitharan became the first Sri Lankan to reach 100 test wickets, when he dismissed Stephen Fleming in the second innings of the Hamilton Test.
In January 1998, Muralitharan took his first ten-wicket haul against Zimbabwe in the first test at Kandy. Sri Lanka won by eight wickets and Muralitharan had figures of 12 for 117.
In August that same year Muralitharan produces his career-best test match figures of 16 for 220, in the one-off test against England. In England's second innings Muralitharan bowled a marathon 54.2 overs to pick up 9 for 65 runs, the other wicket being a run out. Ben Hollioake becomes his 200th test wicket. Sri Lanka won by ten wickets, their first Test victory in England. After breaking the world record for the most test wickets in 2007, Muralitharan commented that his 1998 performance at the Oval against England, was his career highlight. He stated "Everyone thought I was a good bowler then and I didn't look back from there."
Playing his 58th test, Muralitharan claimed his 300th test wicket when he dismissed Shaun Pollock in the First Test in Durban, in December 2000. Only Dennis Lillee reached the milestone faster, in his 56th test.
On 4 January 2002 in Kandy Muralitharan might have finished with the best-ever figures for a single innings, but after he had claimed nine wickets against Zimbabwe Russel Arnold dropped a catch at short leg.
He missed out on the tenth when Chaminda Vaas dismissed Henry Olonga caught behind amid stifled appeals. Muralitharan follows up his 9 for 51 in the first innings with 4 for 64 in the second, equalling Richard Hadlee's record of 10 ten-wicket match hauls, but needing 15 fewer Tests to do so.
On 15 January 2002 playing in his 72nd test, Muralitharan became the fastest to reach the 400-wicket landmark when he bowled Olonga in the third Test in Galle.
On 16 March 2004 Muralitharan became the fastest and the youngest bowler to reach 500 wickets during the second test between Sri Lanka and Australia played in Kandy. In his 87th test, he bowled Kasprowicz to claim his 500th victim just four days after Warne reached the landmark on the fifth day of the First Test between the two teams at Galle. Warne took 108 tests to reach 500. Muralitharan took 4–48 on the first day of the second Test as Australia were skittled for 120 in the first innings.
Passing Walsh and Warne.
In May 2004, Muralitharan overtook West Indian Courtney Walsh's record of 519 Test match wickets to become the highest wicket-taker. Zimbabwe's Mluleki Nkala becomes Muralitharan's 520th scalp in Tests. Muralitharan held the record until Shane Warne claimed it in October 2004. Warne surpassed Sri Lankan Muttiah Muralitharan's mark of 532 wickets by dismissing India's Irfan Pathan. Warne said he enjoyed his duel with Muralitharan, who was sidelined following shoulder surgery at the time.
After an outstanding year Muralitharan was adjudged as the Wisden Leading Cricketer in the World in 2006. In six Tests, he took 60 wickets. He took ten in each of four successive matches, the second time he performed such a feat. The opponents for his 60-wicket haul were England away, South Africa at home and New Zealand away: serious opposition. In all, Muralitharan took 90 wickets in 11 Tests in the calendar year.
In July 2007, Muttiah Muralitharan became the second bowler after Australia's Shane Warne to capture 700 Test wickets. The off-spinner reached the landmark when he had Bangladesh's last man Syed Rasel caught in the deep by Farveez Maharoof on the fourth day of the third and final Test at the Asgiriya stadium in Kandy. The dismissal signalled Sri Lanka's victory by an innings and 193 runs to give the host a 3–0 sweep of the series. Muralitharan finished with six wickets in each innings to claim 10 wickets or more in a Test for the 20th time. However, he was unable to pass Warne's record of 708 wickets when Sri Lanka toured Australia in November 2007, capturing just four wickets in two Test matches.
Muralitharan reclaimed the record for most Test wickets during the first Test against England at Kandy on 2007. The spinner bowled England's Paul Collingwood to claim his 709th Test victim and overtaking Shane Warne in the process. Muralitharan reached the mark in his 116th Test – 29 fewer than Warne – and had conceded only 21.77 runs per wicket compared to the Australian's 25.41. This was Muralitharan's 61st 5-wicket haul. Warne believed that Muralitharan would take "1,000 wickets" before he retired. Former record holder Courtney Walsh also opined that this would be possible if Muralitharan retained his hunger for wickets. Muralitharan himself believed there was a possibility that he would reach this milestone.
Beyond the world record.
In July 2008, Muralitharan and Ajantha Mendis stopped India's strong batting as Sri Lanka won the first Test by a record innings and 239 runs in Colombo. Muralitharan finished the match with 11 wickets for 110, as India were shot out for 138 in their second innings after conceding a lead of 377 on the fourth day. He was well supported by debutant Ajantha Mendis, an unorthodox spinner with plenty of variation, who took eight wickets in his debut match.
Muralitharan believed the emergence of Mendis would help prolong his own career. Muralitharan, 36, and 23-year-old Mendis formed a formidable partnership in the first Test thrashing of India, taking 19 of the 20 wickets between them. "If he keeps performing this way, he will definitely take a lot of wickets in international cricket. Now that he has come, I think I can play Test cricket a few more years. Bowling 50 overs in a Test innings is very hard. Now if I bowl only 30–35 and he bowls more than me, the job will get easier for me."
Performance analysis.
In July 2007, Muralitharan achieved a career peak Test Bowling Rating of 920, based on the LG ICC Player Rankings. This is the highest ever rating achieved by a spin bowler in Test cricket. This also puts him in fourth place in the LG ICC Best-Ever Test bowling ratings.
Muralitharan has the unique distinction of getting 10 or more wickets in a match against all other nine Test playing nations as well as capturing over 50 wickets against each of them. He also obtained 7 or more wickets in an innings against five nations, namely England, India, South Africa, West Indies and Zimbabwe (refer to table above). Muttiah Muralitharan also took at least five five-fors against all the other nine Test sides.
He currently holds the highest wickets/match ratio (6.1) for any bowler with over 200 Test wickets and also represented Sri Lanka in 118 Tests of the 175 that they have played (67.4%).
Against teams excluding Bangladesh and Zimbabwe, Muralitharan took 624 wickets in 108 Tests. By comparison, excluding his matches against Bangladesh and Zimbabwe, Warne took 691 wickets in 142 tests. Murali's average of 24.05 is slightly superior to Warne's career average of 25.41. Muralitharan won 18 Man of the Match awards in Test cricket.
During Muralitharan's playing days, the ICC Future Tours Programme denied Sri Lanka and several other teams a level playing field. As a consequence Muralitharan never toured South Africa after December 2002 and never playing a Test at the spin-friendly Sydney Cricket Ground.
Another comparison of Muralitharan's bowling record against other successful international bowlers is their career record away from home. Muralitharan received criticism that he enjoyed great success on home soil, taking wickets on pitches that are more spin-friendly than other international pitches. A quick analysis of his Test record of matches played outside Sri Lanka shows that from 52 matches he took 278 wickets at an average of 26.24 runs per wicket, with a strike rate of 60.1 balls per wicket. Similarly, spin bowling rival Shane Warne retired with a slightly superior 'away' record of 362 wickets from 73 matches, at an average of 25.50 and a strike rate of 56.7. Due to the variabilities of Test cricket such as grounds played at and opposition played against it is difficult to compare the quality of the top level players and, as such, is very difficult and subjective. However, it is clear that Muralitharan did much better playing at home to test minnows Zimbabwe and Bangladesh, averaging less than 16 runs a wicket.
Cricinfo's statistics editor S Rajesh concluded that the decade 2000–2009 was the best 10-year period for Test batsmen since the 1940s. Muralitharan was clearly the leading Test wicket-taker during this period, capturing 565 wickets at 20.97 in spite of the dominance of the bat over ball. Shane Warne captured 357 wickets at an average of 25.17 during the decade. Of spinners with over Test 100 wickets only John Briggs (17.75), Jim Laker (21.24), Bill O Reilly (22.59) and Clarrie Grimmett (24.21) have sub 25.00 bowling averages.
Muralitharan was on the winning side on 54 of the 133 test matches he played. In those games he captured a total of 438 wickets (8.1 wickets per match), at an outstanding average of 16.18 per wicket and a strike rate of 42.7.
Muralitharan took 795 wickets for his country Sri Lanka in 132 tests. The next most wickets for Sri Lanka in these 132 Tests was Chaminda Vaas' 309 – less than 40% of the spinner's pile. No one else managed 100. Collectively Sri Lankan bowlers tallied 1968 wickets across that span, of which Muralitharan accounted for 40.4%. Among the 24 other Sri Lankans who took more than 10 of those wickets, only Lasith Malinga did so at a better strike rate (52.3) than Muralitharan's 54.9 – and the latter bowled rather more overs, 6657.1 of them to be precise.
Five wickets in an innings.
Muralitharan took five or more wickets in an innings on 67 occasions in Test cricket, which is a world record. In comparison, Shane Warne who is in 2nd place performed the feat 37 times.
One day internationals.
Career summary.
On 12 August 1993 Muralitharan made his One Day International (ODI) debut against India at the Khettarama Stadium and took 1 for 38 off ten overs. Praveen Amre was his first ODI wicket.
On 27 October 2000 in Sharjah, Muralitharan captured 7 for 30 against India, which were then the best bowling figures in One Day Internationals.
On 9 April 2002 Muralitharan achieved a career peak ODI Bowling Rating of 913, based on the LG ICC Player Rankings. This is the highest ever rating achieved by a spin bowler in One Day Internationals. This also puts him in fourth place in the LG ICC Best-Ever ODI bowling ratings.
In 2006, Muralitharan had the second (now third) highest number of runs (99) hit off him in a One Day International Innings. The Australians, especially Adam Gilchrist, attacked Muralitharan's bowling more than usual that day. It is also to be noted that Muralitharan does not have a great record against the Australians in ODIs and this was proved again as he was ineffective in the finals of the 2007 World Cup; his chief tormentor again being Gilchrist.
Muralitharan played in five Cricket World Cup tournaments, in 1996, 1999, 2003, 2007 and 2011. He captured 67 World Cup wickets and is second in the list behind Glenn McGrath who has 71, and represented Sri Lanka in three World Cup finals. In 1996 Muralitharan was part Sri Lanka's World Cup winning team that defeated Australia in Lahore, Pakistan. Muralitharan also played in the 2007 World Cup final, when Australia defeated Sri Lanka in Bridgetown, Barbados. He picked up 23 wickets in the 2007 World Cup, and finished as the second highest wicket taker in the tournament behind Glenn McGrath. He was part of the 2011 team who lost the world cup final against India in Mumbai. It was his farewell match as well.
Muttiah Muralitharan was left out of the Sri Lankan one-day squad to tour West Indies in April 2008. The chairman of selectors Ashantha De Mel clarifying the non-selection stated that "We know he (Muralitharan) can still play in the next World Cup if he is properly looked after, so we want to use him sparingly to preserve him for the big games and the World Cup coming up in the Asian sub-continent where Muralitharan will be a threat."
Muralitharan has the highest number of career wickets in One Day Internationals, having overtaken Wasim Akram on 2009. Akram took 502 wickets in 356 matches. On 2009, Muralitharan dismissed Yuvraj Singh in his 327th match, the third ODI against India in Colombo to equal Akram's record. He won 13 Man of the Match awards in this form of the game.
Batting.
An aggressive lower order batsman who usually batted at No. 11, Muralitharan was known for his tendency to back away to leg and slog. Sometimes, he could be troublesome for bowlers because of his unorthodox and adventurous ways. Once, in a Test match against England, while playing Alex Tudor, he moved back towards his leg stump trying to hook the ball and ended up lying on the ground sideways after the shot. He was infamously run out in a match against New Zealand when he left his crease to congratulate Kumar Sangakkara, who had just scored a single to reach his century; the New Zealand fielder had not yet returned the ball to the wicketkeeper, so the ball was still in play. His highest Test score of 67 came against India at Kandy in 2001, including three sixes and five fours. He made valuable scores on occasion, including 30 runs against England at the Oval in 1998, including 5 fours, 38 runs (4 fours, 1 six) against England at Galle in 2003, 43 runs (5 fours, 3 sixes) against Australia at Kandy in 2004 36 runs against the West Indies at Colombo in 2005, and his highest-ever ODI score, 33 not out (4 fours and 2 sixes off 16 balls) against Bangladesh in the final of the 2009 Tri-Series in Bangladesh. In the latter match, Muralitharan's effort, which included three fours and a six off one over, played a key role in Sri Lanka winning the match and series after the first eight overs saw them reduced to 6 for 5, the lowest score ever recorded in an ODI at the fall of the fifth wicket. Muralitharan has a strike rate close to 70 in Test cricket and scored over 55% of his Test runs in fours and sixes.
Muralitharan, together with Chaminda Vaas, holds the record for the highest 10th wicket partnership in Tests for Sri Lanka. The pair put on 79 runs for the last wicket at the Asgiriya Stadium against Australia in March 2004. Muralitharan also holds the record for scoring most runs in Test cricket while batting at the number 11 position.
Muralitharan currently holds the record for the most ducks (dismissals for zero) ever in international cricket (Tests, ODI's and Twenty20), with a total of 59 ducks.
Abuse in Australia.
Muralitharan voiced his frustration at routinely being heckled by Australian crowds who accuse him of throwing – one common jeer directed at him was "No Ball!". Following the then Australian Prime Minister John Howard's statement that Muralitharan was a "chucker", in 2004, Muralitharan indicated that he would skip future tours to Australia.
Tom Moody, the former Sri Lanka coach and former Australian Test cricketer, said he was embarrassed by the derogatory reaction and negative attention directed towards Muttiah Muralitharan by Australian crowds. Moody stated that "As an Australian when I have been with the Sri Lankan team in Australia, or playing against them in the World Cup, it's the only situation we find in the whole of the cricketing world where we have this disgraceful slant on a cricketer".
During the 2008 CB series in Australia, some members of the Sri Lankan contingent including Muralitharan, were the target of an egg throwing incident in Hobart. The Sri Lankan cricket selector Don Anurasiri was hit by an egg, while Muralitharan and two others were verbally abused by a car-load of people as they were walking from a restaurant back to the hotel.
Due to the incident taking place at night, it is unclear whether Muralitharan was indeed the target of the culprits. Even though the Australian coach of the Sri Lankan team, Trevor Bayliss, down-played the incident as "a non-event", Cricket Australia tightened security around the team. In response to this episode Muralitharan was quoted as saying "When you come to Australia, you expect such incidents".
At the conclusion of Muralitharan's test career cricket writer Rahul Bhattacharya summed up Muralitharan's trials thus:
"Murali is described often as a fox. This seems right. Unlike hedgehog bowlers who pursue one big idea, Murali, like a fox, had many ways of pursuit. Like a fox he did not hunt in a pack. Like a fox he was himself cruelly hunted for sport in some parts of the world. Fox hunting was banned a few years ago in England, but is still legal in Australia."
Retirement.
On 7 July 2010, Muttiah Muralitharan formally announced his retirement from Test cricket at a media briefing in Colombo. He confirmed that the first Test Match against India due to commence on , 2010 would be his last, but indicated that he was willing to play One-Day Internationals if it was considered necessary leading up to the 2011 World Cup, which Sri Lanka co-hosted. He identified Sri Lanka's World Cup win of 1996 as his greatest moment as a cricketer. He also stated that there were some regrets during his 19-year playing career. "Not winning Test Matches in South Africa, Australia and India are regrets. But I am sure we will win very soon." 
At the start of his last match, Muralitharan was eight short of 800 wickets. At the fall of the ninth wicket of the Indian's second innings Muralitharan still needed one wicket to reach the milestone. After 90 minutes of resistance Muralitharan was able to dismiss the last Indian batsman Pragyan Ojha on the last delivery of the over and his Test career. By doing so he became the only bowler to reach 800 wickets in Test cricket. Sri Lanka won the match by 10 wickets, the seventh time they have done so and the second time they have done it against India.
Muralitharan formally announced his retirement from international cricket after 2011 Cricket World Cup co-hosted by Bangladesh, India and Sri Lanka announcing "This World Cup will be my last outing. I am retiring totally from international cricket thereafter. My time is up. I've signed up to play for two years in IPL."
In July 2014, he played for the Rest of the World side in the Bicentenary Celebration match at Lord's.
World records and achievements.
Muttiah Muralitharan holds a number of world records, and several firsts:
Cricket awards.
Wisden Cricketers of the Year.
Was named Wisden Cricketers of the Year 1999.
Recognition.
In 2002, Wisden carried out a statistical analysis of all Test matches in an effort to rate the greatest cricketers in history, and Muralitharan was ranked as the best Test bowler of all time.
Muralitharan was selected as the Wisden Leading Cricketer in the World in 2000 and in 2006.
On 15 November 2007, the Warne-Muralidaran Trophy was unveiled named after the two leading wicket-takers in Test cricket, Shane Warne and Muralitharan. The trophy displays images of the two spin bowlers' hands each holding a cricket ball. This trophy will be contested between Australia and Sri Lanka in all future Test series.
On 3 December 2007, just hours after Muttiah Muralitharan became Test cricket's leading Test wicket-taker, Marylebone Cricket Club (MCC) announced it had unveiled a portrait of the Sri Lanka off-spinner at Lord's. On the same day the Philatelic Bureau of the Department of Posts in Sri Lanka issued a circular stamp with a denomination of Rs. 5 to mark the world record set by Muttiah Muralitharan. The circular design was meant to denote the cricket ball.
Australian musician Alston Koch provoked worldwide interest when he recorded the only official tribute song to Muralitharan. The song was even mentioned on the BBC's Test Match Special. The Muralitharan Song video was also released after he broke the world record.
On 10 January 2008, the Parliament of Sri Lanka felicitated Muttiah Muralitharan for his world record breaking feat of being the highest wicket taker in Test cricket.
This was the first time that a sportsman had been honoured in the country's Supreme Legislature.
The Central Provincial Council in Kandy has decided to rename the International Cricket Stadium in Pallekele after Muttiah Muralitharan.
Controversy of bowling action.
Throughout much of his international career, Muralitharan's action was suspected of contravening the laws of the game by the straightening of his bowling arm during delivery. Although he was cited three times, subsequent biomechanical testing led the ICC to clear him of the charge and permit him to continue bowling.
Biomechanical testing conducted on four occasions fueled debate as to whether his action was in fact illegal or actually an illusion created by his allegedly unique ability to generate extra movement both at the shoulder as well the wrist, which enables him to bowl the doosra without straightening the elbow.
First throwing citation and testing.
Initial concerns as to whether Muralitharan's action contravened the laws of the game by straightening his bowling arm during delivery broke into open controversy after Australian umpire Darrell Hair called a "no ball" for an illegal action seven times during the Boxing Day Test match in Melbourne, Australia, in 1995. Australian Sir Donald Bradman, universally regarded as the greatest batsman in history, was later quoted as saying it was the "worst example of umpiring that had witnessed, and against everything the game stands for. Clearly Murali does not throw the ball".
Ten days later, on 5 January 1996, Sri Lanka played the West Indies in the seventh ODI of the triangular World Series competition, in Brisbane. Umpire Ross Emerson officiating in his debut international match, no-balled Muralitharan three times in his first over, twice in his second and twice in his third. It was an identical tally to that called by Hair on Boxing Day and (like Hair) Emerson made his calls from the bowler's end while his partner stood silent. The main difference was that several no-balls were for leg-breaks instead of the bowler's normal off-breaks.
In February 1996, just before the world cup Muralitharan underwent biomechanical analysis at the Hong Kong University of Science and Technology under the supervision of Prof. Ravindra Goonetilleke, who declared his action legal in the conditions tested, citing a congenital defect in Muralitharan's arm which makes him incapable of fully straightening it, but giving the appearance of fully straightening the arm. Although under the original Laws a bowler's arm did not need to be fully straightened to be in breach of a legal delivery. They concluded that his action created the 'optical illusion of throwing'. Based on this evidence ICC gave clearance to Muralitharan to continue bowling.
Second citation and testing.
Doubts about Muralitharan's action persisted, however. On the 1998–99 tour to Australia he was once again called for throwing by Ross Emerson during a One Day International against England at the Adelaide Oval in Australia. The Sri Lankan team almost abandoned the match, but after instructions from the President of the Board of Control for Cricket in Sri Lanka, the game resumed. The Sri Lankan captain at the time Arjuna Ranatunga, was later fined and given a suspended ban from the game as a result. It later emerged that at the time of this match Emerson was on sick leave from his non-cricket job due to a stress-related illness and he stood down for the rest of the series. Muralitharan was sent for further tests in Perth and England and was cleared again. At no stage was Muralitharan requested to change or remodel his action, by the ICC. Up to this point in his career (1999) Muralitharan primarily bowled two types of deliveries, namely the off-break and the topspinner. He had not yet mastered the doosra.
Third citation and testing.
Muralitharan continued bowling, taking his 500th Test wicket in the second Test against Australia in Kandy on 2004. At the end of the series his doosra delivery was officially called into question by match referee Chris Broad. At the University of Western Australia (Department of Human Movement and Exercise Science), three-dimensional kinematic measurements of Muttiah Muralitharan's bowling arm were taken using an optical motion capture system while he bowled his doosra. Muralitharan's mean elbow extension angle for the doosra delivery was 14°, which was subsequently reduced to a mean of 10.2° after remedial training at the University. The findings reported to ICC by the University of Western Australia's study was that Muralitharan's doosra contravened the established ICC elbow extension limit of 5° for spinners.
Under the original throwing Laws of Cricket, the umpires officiating were under an obligation to call "no-ball" to a delivery that they were not entirely happy was absolutely fair. This Law gave the umpires absolutely no discretion. In 2000, the Laws were changed to put an allowable figure of straightening of 5° for spinners, 7.5° for medium pacers and 10° for fast bowlers in an attempt to more clearly define what was legal. But these figures proved difficult to enforce due to umpires being unable to discern actual amounts of straightening and the differentiation between the three different allowable figures. Testing in Test Match conditions is not currently possible "when the identification of elbow and shoulder joint centres in on-field data collection, where a shirt is worn, also involves large errors. In a match the ability to differentiate anatomical movements such as 'elbow extension' by digitising segment end-points, particularly if you have segment rotations, is extremely difficult and prone to error. This is certainly the case with spin bowlers. It is therefore not surprising that laboratory testing is preferred, particularly for spin bowlers, where an appropriate pitch length and run-up can be structured. This is clearly the only way to test players, where data would be able to withstand scientific and therefore legal scrutiny."
An extensive ICC study, the results of which were released in November 2004, was conducted to investigate the "chucking issue". A laboratory kinematic analysis of 42 non-Test playing bowlers done by Ferdinands and Kersting (2004) established that the 5° limit for slow and spin bowlers was particularly impractical.
Due to the overwhelming scientific findings, researchers recommended that a flat rate of 15° tolerable elbow extension be used to define a preliminary demarcation point between bowling and throwing. A panel of former Test players consisting of Aravinda de Silva, Angus Fraser, Michael Holding, Tony Lewis, Tim May and the ICC's Dave Richardson, with the assistance of several biomechanical experts, stated that 99% of all bowlers in the history of cricket straighten their arms when bowling. Only one player tested (part-time bowler Ramnaresh Sarwan) reportedly did not transgress the pre 2000 rules. Many of these reports have controversially not been published and as such, the 99% figure stated has yet to be proved. In fact, Muralitharan stirred up controversy when he said during an interview with a Melbourne radio station that Jason Gillespie, Glenn McGrath and Brett Lee flexed their arms by 12, 13 and 14–15 degrees respectively, although it is unclear as to where Muralitharan quoted these figures from. Muralitharan was censured by the Sri Lankan Cricket Board for these comments.
The ICC Executive was asked to ratify the panel's recommendations at the ICC's Annual General Meeting in February 2005. Based on the recommendations the ICC issued a new guideline (which was effective from 2005) allowing for extensions or hyperextensions of up to 15 degrees for all types of bowlers, thus deeming Muralitharan's doosra to be legal.
Explaining why the maximum level of 15 degrees was arrived at, panel member Angus Fraser stated "That is the number which biomechanics says that it (straightening) becomes visible. It is difficult for the naked eye to see less than 15 degrees in a bowler's action. We found when the biceps reached the shoulder the amount of bend was around 165 degrees. Very few bowlers can get to 180 degrees because the joint doesn't allow that. ... but once you go further than 15 degrees you get into an area which is starting to give you an unfair advantage and you are breaking the law".
University of South Australia study.
The original decision of disallowing the doosra bowling action was hailed widely as justifiable on account of being scientifically based. Hence, a team of Australian scientists representing the University of South Australia conducted an independent research, in line with modern Artificial Intelligence and biomechanics in order to solve the controversial issue arise from doosra. The University of South Australia's study, founded by Prof. Mahinda Pathegama, and contributed by Prof. Ozdemir Gol, Prof. J. Mazumdar, Prof. Tony Worsley and Prof. Lakmi Jain has analyzed the previous studies with close scrutiny since the techniques in their fields of expertise are employed in the course of assessment as the basis for decision-making. The findings based on this scientific study are overwhelming and Dave Richardson, General Manager ICC stated that "the ICC is currently reviewing the Law on throwing and the ICC regulations and the study done by Prof. Mahinda Pathegama with UniSA scientists is a valuable source of information in this regard". The team of Australian scientists including Sri Lankan-born Australian scientist, Prof. Mahinda Pathegama reporting their findings, in line with the Muralitharan test to ICC, has analyzed in-depth various issues, such as Pitfalls in image interpretation when using 2D images for 3D modeling associates compared to the modern techniques in Artificial Intelligence and biomechanics, and Biomechanics assessment for doosra bowling action, etc. Pathegama at al. (2004) further reports on the Disagreement of expression on measurement accuracy in the Murali Report, with the analysis of the Motion tracking system used for the Murali Report, and discussing Cognitive aspects, Evidence of errors in Anthropometric assessment and movement tracking, Lateral inhibition in response tracking, Psycho-physiological aspect on post-assessments, Angular measurement errors, Skin marker induced errors, Geometrics-and physics-based 3D modeling and the Approach to on-field assessment, etc.
The Muralitharan Report produced by the University of Western Australia's study has considered the Richards study done in 1999 to evaluate the error margin. University of South Australia's study done by Prof. Mahinda Pathegama argued that the Richards study which was presented by the University of Western Australia's study has used a rigid aluminium bar that only rotated in the horizontal plane to introduce such error margin. Pathegama's report stated that "in view of the system used in the test itself yielding considerable error even with a rigid aluminum bar (an "accuracy level of approximately 4 degrees" as stated in the Murali Report), it stands to reason that the error margin would be considerably larger when tracking skin markers on a spin bowler's moving upper limb by this same system".
Vincent Barnes in an interview argues that Bruce Elliott, the UWA professor who is also the ICC biomechanist, had made an interesting discovery in his dealings with finger spinners. "He said he had found that a lot of bowlers from the subcontinent could bowl the doosra legally, but not Caucasian bowlers."
Fourth round of testing.
On 2 February 2006, Muralitharan underwent a fourth round of biomechanical testing. There had been criticism that the previous round of tests in July 2004 did not replicate match conditions due to a slower bowling speed in the laboratory tests. The results showed that the average elbow flexation while bowling the 'doosra' delivery was 12.2 degrees, at an average of . The average for his off-break was 12.9 degrees at .
Bowling with an arm brace.
In July 2004 Muralitharan was filmed in England, bowling with an arm brace on. The film was shown on Britain's Channel 4 during the Test against England on 2004.
Initially, Muralitharan bowled three balls – the off-spinner, the top-spinner and the doosra – as he would in a match. Then he bowled the same three balls with a brace that is made from steel bars, which are set into strong resin. This brace has been moulded to his right arm, is approximately 46 centimetres long and weighs just under 1 kilogram.
TV presenter Mark Nicholas who tried the brace himself, confirmed that "There is no way an arm can be bent, or flexed, when it is in this brace." All three balls reacted in the same way as when bowled without the brace. They were not bowled quite so fast because the weight of the brace restricts the speed of Muralitharan's shoulder rotation, but the spin was still there.
With the brace on, there still appeared to be a jerk in his action. When studying the film at varying speeds, it still appeared as if he straightened his arm, even though the brace makes it impossible to do so. His unique shoulder rotation and amazing wrist action seem to create the illusion that he straightens his arm.
The off-spinner said the exercise was to convince a sceptical public rather than sway an ICC investigation into bowling actions launched after he was reported by match referee Chris Broad for his doosra delivery in March 2004, the third time action was taken on his bowling. In an interview for August 2004 edition of Wisden Asia Cricket, Muralitharan stated "I think it will prove a point to those who had said that it was physically impossible to bowl a ball that turned the other way. I proved that it was possible to bowl the doosra without bending the arm."
In 2004 at the R Premadasa Stadium in Colombo, Muralitharan voluntarily performed a series of tests with live video cameras. Michael Slater and Ravi Shastri witnessed it all unfold. Muralitharan once again showed he could bowl all his deliveries including the doosra with an arm brace that prevents any straightening of his elbow. Orthopediatrician Dr Mandeep Dillon stated that Muralitharan's unusual ability to generate extra movement both at the shoulder as well the wrist enables him to bowl the doosra without straightening the elbow.
Critics and converts.
Two vocal critics of Muralitharan's action have been former test cricketers, Australian Dean Jones and Bishan Bedi, the former Indian captain. Dean Jones later admitted to being wrong in his assessment of Murali when he witnessed first hand Murali bowling with an arm-brace on.
Michael Holding, the former West Indian fast bowler was also a critic of Muralitharan, but withdrew his criticisms under the light of the tests carried out. Holding had been quoted as being in "110% agreement" with Bedi, who likened Murali's action to a "javelin throw" and more recently, compared to a "shot putter". Following the ICC study, as a member of the panel that conducted the study, Holding stated, "The scientific evidence is overwhelming ... When bowlers who to the naked eye look to have pure actions are thoroughly analysed with the sophisticated technology now in place, they are likely to be shown as straightening their arm by 11 and in some cases 12 degrees. Under a strict interpretation of the Law, these players are breaking the rules. The game needs to deal with this reality and make its judgment as to how it accommodates this fact."
In May 2002, Adam Gilchrist, speaking at a Carlton (Australian) Football Club luncheon, claimed Muralitharan's action does not comply with the laws of cricket. The Melbourne-based Age newspaper quoted Gilchrist as saying."Yeah, I think he does (chuck), and I say that because, if you read the laws of the game, there's no doubt in my mind that he and many others, throughout cricket history have." These comments were made before the doosra controversy, in spite of Muralitharan's action having been cleared by ICC in both 1996 and 1999. For his comment Gilchrist was reprimanded by the Australian Cricket Board (ACB) and found guilty of being in breach of ACB rules concerned with "detrimental public comment".
During the 2006 tour of New Zealand another Muralitharan critic, former New Zealand captain and cricket commentator Martin Crowe, called for Muralitharan's doosra to be monitored more closely, asserting that his action seemed to deteriorate during a match. Earlier that year when delivering the Cowdrey lecture at Lords Martin Crowe had demanded zero tolerance instead of 15 degrees for throwing and specifically branded Muttiah Muralitharan a chucker. In response to Crowe's criticism ICC general manager Dave Richardson stated that the scientific evidence presented by biomechanists Professor Bruce Elliot, Dr Paul Hurrion and Mr Marc Portuswith was overwhelming and clarified that "Some bowlers, even those not suspected of having flawed actions, were found likely to be straightening their arms by 11 or 12 degrees. And at the same time, some bowlers that may appear to be throwing may be hyper-extending or bowl with permanently bent elbows. Under a strict interpretation of the law, they were breaking the rules – but if we ruled out every bowler that did that then there would be no bowlers left."
Scientific research on bowling actions.
Since 1999 there has been a number of scientific research publications discussing Muralitharan's bowling action as well the need for defining the legality of a bowling action using biomechanical concepts. This research directly contributed towards the official acceptance of Muralitharan's bowling action and convinced the ICC to redefine the bowling laws in cricket.
The key publications are listed below:
Philanthropy.
Muralitharan, along with his manager Kushil Gunasekara, established the "Foundation of Goodness", a charity organization, in the early 2000s. This organization is committed to the wellbeing of the Seenigama region (in southern Sri Lanka) and supports local communities through a range of projects across areas including children's needs, education and training, health care and psycho-social support, housing, livelihoods, sport and the environment. Murali’s Seenigama project raised funds from cricketers and administrators in England and Australia. Canadian pop-star Bryan Adams donated a swimming pool.
Muralitharan also plans to build a second sports complex for war-displaced civilians in Mankulam, a town located 300 kilometers from north of Colombo. The two-year one million dollar project aims to build a sports center, a school, English and IT training centers and an Elders' home. While the Sports Complex remains the main project, "Foundation of Goodness" also plans to help educate children, youth and adults. English cricketer Sir Ian Botham visited Mankulam with Muralitharan, and later addressing the media in Colombo on 27 March 2011 said that he will consider a walk from Point Pedro (the extreme northern tip of Sri Lanka) to Dondra Head (the extreme southern tip of Sri Lanka) to raise funds for the project.
In June 2004, Muralitharan also joined the United Nations World Food Program as an ambassador to fight hunger among school children.
When the tsunami devastated Sri Lanka on 2004, Muralitharan galvanised into action to ensure that aid reached people that needed it. He himself narrowly escaped death, arriving 20 minutes late at Seenigama, where he was to give away prizes at one of the charity projects he worked on. While international agencies were bringing food in by air, there was an urgent need for transport, and Murali organised three convoys of 10 trucks each, paying for these himself, to get the food to people who needed it. He persuaded those who could to donate clothes, and supervised the delivery himself.
During the hard work of rehabilitation in the tsunami's aftermath, cement was in short supply. Muralitharan promptly signed an endorsement deal with Lafarge, a global cement giant, that was a straight barter, where cement would be supplied to the Foundation for Goodness in exchange for work Muralitharan did. During the first three years since the tsunami, the foundation raised more than US$ to help survivors, and has built homes, schools, sports facilities and computer centres.
Beyond Cricket.
On 1 August 2015, Murali himself with another Sri Lankan crickter Tillakaratne Dilshan appointed as the Brand Ambassadors for the Presidential Task Force to combat kidney disease by the President Maithripala Sirisena.

</doc>
<doc id="20906" url="https://en.wikipedia.org/wiki?curid=20906" title="Mole Day">
Mole Day

Mole Day is an unofficial holiday celebrated among chemists, chemistry students and chemistry enthusiasts on October 23, between 6:02 AM and 6:02 PM, making the date 6:02 10/23 in the American style of writing dates. The time and date are derived from Avogadro's number, which is approximately 6.02×1023, defining the number of particles (atoms or molecules) in one mole of substance, one of the seven base SI units.
Mole Day originated in an article in "The Science Teacher" in the early 1980s. Inspired by this article, Maurice Oehler, now a retired high school chemistry teacher from Prairie du Chien, Wisconsin, founded the National Mole Day Foundation (NMDF) on May 15, 1991.
Many high schools around the United States, South Africa, Australia and in Canada celebrate Mole Day as a way to get their students interested in chemistry, with various activities often related to chemistry or moles.
The American Chemical Society sponsors National Chemistry Week, which occurs from the Sunday through Saturday during October in which the 23rd falls. This makes Mole Day an integral part of National Chemistry Week.

</doc>
<doc id="20907" url="https://en.wikipedia.org/wiki?curid=20907" title="Motörhead">
Motörhead

Motörhead () were an English rock band formed in June 1975 by bassist, singer, and songwriter Ian Fraser "Lemmy" Kilmister, who was the sole constant member; guitarist and songwriter Larry Wallis; and drummer Lucas Fox. The band is often considered a precursor to or one of the earliest members of the New Wave of British Heavy Metal, which re-energised heavy metal in the late 1970s and early 1980s.
Motörhead released 23 studio albums, 10 live recordings, 12 compilation albums, and five EPs over a career spanning 40 years. Usually a power trio, they had particular success in the early 1980s with several successful singles in the UK Top 40 chart. The albums "Overkill", "Bomber", "Ace of Spades", and particularly "No Sleep 'til Hammersmith" cemented Motörhead's reputation as a top-tier rock band. The band are ranked number 26 on VH1's 100 Greatest Artists of Hard Rock. As of 2012, they have sold more than 30 million albums worldwide.
Motörhead are typically classified as heavy metal, and their fusion of punk rock into the genre helped to pioneer speed metal and thrash metal. Their lyrics typically covered such topics as war, good versus evil, abuse of power, promiscuous sex, substance abuse, and, most famously, gambling.
Although Lemmy has been credited with being part of various musical scenes, thrash metal or speed metal in the main, from the mid 1970s onward, he has stated very clearly over the years, when asked the question, that he plays Rock n Roll. He has said had more of an affiliation with Punk Rockers than with the so-called Heavy Metal scene; Motörhead having evolved out of the London mid-1970s Punk era.
Lemmy died on 28 December 2015 after being initially diagnosed with an undisclosed aggressive form of cancer, which was later revealed as prostate cancer and heart failure, after which drummer Mikkey Dee and guitarist Phil Campbell both confirmed that Motörhead would not continue as a band.
History.
Formation and early years, 1975–77.
Lemmy was fired from Hawkwind in May 1975 after being arrested in Canada for drug possession; he said himself the band fired him for "doing the wrong drugs". Now on his own, Lemmy decided to form a new band called Motörhead, inspired by the final song he had written for Hawkwind.
Lemmy wanted the music to be "fast and vicious, just like the MC5". His stated aim was to "concentrate on very basic music: loud, fast, city, raucous, arrogant, paranoid, speedfreak rock n roll ... it will be so loud that if we move in next door to you, your lawn will die". On the recommendation of Mick Farren, he recruited Larry Wallis (ex-Pink Fairies) on electric guitar and Lucas Fox on drums. According to Lemmy, the band's first practice was at the now defunct Sound Management rehearsal studios, located on Kings Road, Chelsea in 1975 (Sound Management leased the basement area of furniture store "The Furniture Cave", located in adjacent Lots Road). Kilmister has said they used to steal equipment, as the band was short on gear. Their first engagement was supporting Greenslade at The Roundhouse, London on 20 July 1975. On 19 October, having played 10 gigs, they became the supporting act to Blue Öyster Cult at the Hammersmith Odeon.
The band were contracted to United Artists by Andrew Lauder, the A&R man for the band Lemmy was previously in, Hawkwind. They recorded sessions at Rockfield Studios in Monmouth with producer Dave Edmunds, during which Fox proved to be unreliable and was replaced by drummer Phil "Philthy Animal" Taylor, a casual acquaintance of Lemmy's. Their record label was dissatisfied with the material and refused to release it, although it was subsequently issued as "On Parole" in 1979 after the band had established some success.
In March 1976, deciding that two guitarists were required, the band auditioned "Fast" Eddie Clarke. Wallis, who was continuing to tour with a reformed Pink Fairies, quit immediately after the auditions and Clarke remained as the sole guitarist. This trio of Lemmy/Clarke/Taylor is today regarded as the "classic" Motörhead line-up. In December, the band recorded the "Leaving Here" single for Stiff Records, but United Artists intervened to prevent its general release as the band were still under contract to them, despite their refusal to issue their debut album. Initial reactions to the band had been unfavourable; they won a poll for "the best worst band in the world" in the music magazine "NME".
By April 1977, living in squats and with little recognition, Taylor and Clarke decided to quit the band, and after some debate, they agreed to do a farewell show at the Marquee Club in London. Lemmy had become acquainted with Ted Carroll from Chiswick Records and asked him to bring a mobile studio to the show to record it for posterity. Carroll was unable to get the mobile unit to the Marquee Club, but showed up backstage after the engagement and offered them two days at Escape Studios with producer Speedy Keen to record a single. The band took the chance, and instead of recording a single they laid down 11 unfinished tracks. Carroll gave them a few more days at Olympic Studios to finish the vocals and the band completed 13 tracks for release as an album. Chiswick issued the single "Motorhead" in June, followed by the album "Motörhead" in August, which spent one week in the UK Albums Chart at number 43. The band toured the UK supporting Hawkwind in June, then from late July they commenced the "Beyond the Threshold of Pain" tour with The Count Bishops.
In August, Tony Secunda took over the management of the band, and their cohesiveness became so unstable that by March 1978, Clarke and Taylor had formed and were performing as The Muggers with Speedy Keen and Billy Rath.
Rise to success: "Overkill" and "Bomber", 1978–79.
In July 1978, the band returned to the management of Douglas Smith, who secured a one-off singles deal with Bronze Records. The resulting "Louie Louie" single was issued in September peaking at number 68 on the UK Singles Chart, and the band toured the UK to promote it, recorded a BBC Radio 1 "John Peel in session" on 18 September (these tracks were later issued on the 2005 "BBC Live & In-Session" album), and appeared for the first time on BBC Television's "Top of the Pops" on 25 October. Chiswick capitalised on this new level of success by re-issuing the debut album "Motörhead" on white vinyl through EMI Records.
The single's success led to Bronze extending their contract, and put the band back into the studio to record an album, this time with producer Jimmy Miller at Roundhouse Studios. A hint of what the band had recorded for the album came on 9 March 1979 when the band played "Overkill" on "Top of the Pops" to support the release of the single ahead of the "Overkill" album, which was released on 24 March. It became Motörhead's first album to break into the top 40 of the UK Albums chart, reaching number 24, with the single reaching number 39 on the UK Singles Chart. These releases were followed by the "Overkill" UK tour which began on 23 March. A subsequent single was released in June, coupling the album track "No Class" as the A-side with the previously unreleased song "Like a Nightmare" on the B-side. It fared worse than both the album and previous single but reached number 61 on the UK singles chart.
During July and August, except for a break to appear at the Reading Festival, the band were working on their next album, "Bomber". Released on 27 October, it reached number 12 on the UK Albums Chart. On 1 December, it was followed by the "Bomber" single, which reached number 34 on the UK Singles Chart. The "Bomber" Europe and UK tour followed, with support from Saxon. The stage show featured a spectacular aircraft bomber-shaped lighting rig. During the "Bomber" tour, United Artists put together tapes recorded during the Rockfield Studios sessions in 1975–1976 and released them as the album "On Parole", which peaked at number 65 on the UK Albums Chart in December.
On 8 May 1980, while the band were on tour in Europe, Bronze released "The Golden Years", which sold better than any of their previous releases, reaching number eight on the UK Singles Chart. The band had, however, preferred the title "Flying Tonight", in reference to the "Bomber" lighting rig. On 20 August, the band (40 minutes) and Girlschool (20 minutes) were filmed performing live at the Nottingham Theatre Royal for the "Rockstage" programme, broadcast on UK television by the ATV station on 4 April 1981.
"Ace of Spades" and "Iron Fist", 1980–82.
During August and September 1980, the band were at Jackson's Studios in Rickmansworth, recording with producer Vic Maile. The "Ace of Spades" single was released on 27 October 1980 as a preview of the "Ace of Spades" album, which followed on 8 November. The single reached No. 15 and the album reached No. 4 on the UK charts. Bronze celebrated its gold record status by pressing a limited edition of the album in gold vinyl.
Motörhead made an appearance on "Top of the Pops" in November that year with "Ace of Spades", and between 22 October and 29 November the band were on their "Ace Up Your Sleeve" UK tour with support from Girlschool and Vardis, and also made an appearance as guests on the ITV children's show "Tiswas" on 8 November. The "Arizona desert-style" pictures used on the album sleeve and tour booklet cover were taken during a photo session at a sandpit in Barnet. "Ace of Spades", considered to be the definitive Motörhead anthem, "put a choke on the English music charts and proved to all that a band could succeed without sacrificing its blunt power and speed".
To coincide with the "Ace of Spades" release, Big Beat, who had inherited the Chiswick catalogue, put together four unused tracks from the Escape Studios sessions in 1977 and released them as "Beer Drinkers and Hell Raisers", which reached No. 43 on the UK Singles Chart in November.
The band had more chart hits in 1981 with the releases "St. Valentine's Day Massacre" EP, their collaboration with Girlschool which reached No. 5 on the UK Singles Chart in February; the live version of "Motorhead", which reached No. 6 on the UK Singles Chart in July; and the album it was taken from, "No Sleep 'til Hammersmith", which reached No. 1 on the UK Albums Chart in June. During March 1981, the band had been touring Europe, and in the final week of the month they conducted the "Short Sharp, Pain in the Neck" UK tour from which the recordings for "No Sleep 'til Hammersmith" were made.
From April through to July, the band toured North America for the first time ("Ace of Spades" was their debut release in the region) as guests of Blizzard of Ozz, an early incarnation of Ozzy Osbourne's band, but were still able to make an appearance on "Top of the Pops" on 9 July to promote the live "Motorhead" single. In October the band recorded tracks at BBC's Maida Vale 4 studio for the David Jensen show broadcast on 6 October. The band commenced a European tour on 20 November, supported by Tank, followed by Clarke producing Tank's debut album "Filth Hounds of Hades" at Ramport Studios in December and January.
Between 26 and 28 January 1982, the band started recording their self-produced new album at Ramport Studios, before moving onto Morgan Studios to continue the sessions throughout February. On 3 April the single "Iron Fist" was released, reaching No. 29 on the UK Singles Chart, followed by the parent album "Iron Fist", released on 17 April and peaking at No. 6 on the UK Albums Chart. They were the last releases to feature the Lemmy, Clarke, Taylor line-up, though the line-up continued to perform in the "Iron Fist" UK tour between 17 March and 12 April, and the band's first headlining North America tour from 12 May until Clarke's last engagement at the New York Palladium on 14 May.
Departures, "Another Perfect Day" and "No Remorse", 1982–84.
Clarke left as a consequence of the band recording "Stand By Your Man", a cover version of the Tammy Wynette classic, in collaboration with Wendy O. Williams and the Plasmatics. Clarke felt that the song compromised the band's principles, refused to play on the recording and resigned, later forming his own band, Fastway. Lemmy and Taylor made numerous telephone calls to find a guitarist, including one to Brian Robertson, formerly with Thin Lizzy, who was recording a solo album in Canada. He agreed to help out and complete the tour with them. Robertson signed a one-album deal resulting in 1983's "Another Perfect Day" and the two singles from it, "Shine" and "I Got Mine".
In June and July the band played five dates in Japan, and from mid-October until mid-November they toured Europe. From late May until early July, the band conducted the "Another Perfect Tour", followed by an American tour between July and August, and another European tour in October and November. Robertson began to cause friction in the band as a result of his on-stage attire, consisting of shorts and ballet shoes, and, furthermore, with his point blank refusal to play the old standards that every Motörhead audience expected to hear. This led to an amicable agreement that Robertson would leave, playing his last engagement with the band at the Berlin Metropol on 11 November.
After Robertson's departure in 1983, the band were sent tapes from all over the world from potential guitarists. The group returned to the concept of dual lead guitars by hiring unknowns Würzel and Phil Campbell (ex-Persian Risk). In February 1984, the Lemmy, Campbell, Würzel, and Taylor line-up recorded "Ace of Spades" for the "Bambi" episode in the British television series, "The Young Ones". Scenes of the band playing are interspersed with the characters' antics as they rush to the railway station, in a parody of The Beatles' comedy film "A Hard Day's Night". Taylor quit the band after that recording, causing Lemmy to quip: "Did I leave them or did they leave me?". Before joining Motörhead, Phil Campbell had met ex-Saxon drummer Pete Gill, and the trio decided to call him to see if he would like to visit London. The try-outs went well and Gill was hired.
Bronze Records thought the new line-up would not make the grade and decided to "nail down the lid" on the group with a compilation album. When Lemmy found out, he took over the project, selecting tracks, providing sleeve notes and insisted that Motörhead record four brand new tracks to go at the end of each side of the album. During the sessions between 19 and 25 May 1984 at Britannia Row Studios, London, the band recorded six tracks for the single's B-side and the album. The single "Killed by Death" was released on 1 September and reached No. 51 in the UK Singles Chart, the double album "No Remorse" was released on 15 September and reached silver disc status, attaining the position of No. 14 in the UK Album charts.
The band were involved in a court case with Bronze over the next two years, believing that their releases were not being promoted properly, and the record company banned them from the recording studio. The band looked to more touring for income; Australia and New Zealand in late July to late August, a brief tour of Hungary in September, and the "No Remorse" "Death on the Road" tour between 24 October and 7 November. On 26 October the band made a live appearance on the British Channel 4 music programme The Tube, performing "Killed By Death", "Steal Your Face" (over which the programme's end-credits were played) and the unbroadcast "Overkill", before going on to their next engagement that evening. From 19 November to 15 December the band toured America with Canadian speed metal band Exciter and Danish heavy metal band Mercyful Fate and from 26 to 30 December performed five shows in Germany.
On 5 April 1985, ITV broadcast four songs that were recorded after the band went off air on their earlier appearance on "The Tube" programme. A week later the band, dressed in tuxedos, played four songs on the live Channel 4 music show "ECT" (Extra-Celestial Transmission). To celebrate the band's tenth anniversary, two shows were arranged at Hammersmith Odeon on 28 and 29 June, a video of the second show was taken and later released as "The Birthday Party". From early June until early August the band were on their 'It Never Gets Dark' tour of Sweden and Norway, an American tour followed in mid-November until late December.
"Orgasmatron" and "Rock 'n' Roll", 1986–89.
From 26 March to 3 April 1986, the band toured Germany, the Netherlands and Denmark on their "Easter Metal Blast" and in June, played two dates in Bologna and Milan in Italy. The court case with Bronze was finally settled in the band's favour. The band's management instigated their own label, GWR. Recording took place in Master Rock Studios, London and the single "Deaf Forever" was released on 5 July as a taster for the "Orgasmatron" album, which was released on 9 August. On the same day as the release of the album, Lemmy and Würzel were interviewed by Andy Kershaw on the BBC Radio 1 "Saturday Live" show and "Orgasmatron" and "Deaf Forever" were played. The single reached No. 67 and the album reached No. 21 in the UK charts.
On 16 August, the band played at the Monsters of Rock at Castle Donington and was recorded by BBC Radio 1 for a future "Friday Rock Show" broadcast. The performance closed with a flyover by a couple of Second World War German aircraft. Also that day Lemmy was filmed giving his views on spoof metal act "Bad News" for inclusion in a Peter Richardson Comic Strip film entitled "More Bad News" since the band featuring Rik Mayall, Peter Richardson, Nigel Planer and Adrian Edmondson were also performing at Donington. In September the band conducted their "Orgasmatron" tour in Great Britain, supported by fledgling act Zodiac Mindwarp and the Love Reaction. In October they toured America and in December were in Germany.
In 1987, during the filming of "Eat the Rich" – in which Lemmy was taking a starring role alongside well-known comedy actors such as Robbie Coltrane, Kathy Burke, the regulars from The Comic Strip ensemble, and various other musician cameo appearances – Gill left the band and Taylor returned to appear in the band's cameo as "In House Club Band" alongside Würzel and Campbell. The band wrote "Eat the Rich" especially for the film, its soundtrack featured tracks from "Orgasmatron" and Würzel's solo single "Bess". The band's second album for GWR was "Rock 'n' Roll", released on 5 September, after a tight work schedule in the studio. While having some popular tracks and using "Eat the Rich" as its second track, the band commented that the album was virtually "nailed together".
On 2 July 1988 Motörhead were one of the performers at the Giants of Rock Festival in Hämeenlinna, Finland. The tracks were released as "No Sleep at All" on 15 October. A single from the album was planned with the band wanting "Traitor" as the A-side, but "Ace of Spades" was chosen instead. When the band noticed the change, they refused to allow the single to be distributed to the shops, and it was withdrawn and became available only on the "No Sleep at All" tour and through the "Motörheadbangers" fan club. While they continued to play live shows during 1989 and 1990, Motörhead once again felt unhappy with their career, and a court case with GWR followed, which was not resolved until mid-1990.
Epic/WTG years: "1916" and "March ör Die", 1990–92.
With the court case resolved, Motörhead signed to Epic/WTG and spent the last half of 1990 recording a new album and single in Los Angeles. Just prior to the album sessions the band's former manager, Doug Smith, released the recording of the band's tenth anniversary show, much against the bands wishes, having previously told him that they did not want it released, in 1986. In the studio they recorded four songs with producer Ed Stasium, before deciding he had to go.
When Lemmy listened to one of the mixes of "Going to Brazil", he asked for him to turn up four tracks, and on doing so heard claves and tambourines that Stasium had added without their knowledge. Stasium was fired and Peter Solley was hired as producer. The story according to Stasium was that Lemmy's drug and alcohol intake had far exceeded the limitations of Stasium's patience so he quit. The single "The One to Sing the Blues" issued on 24 December 1990 (7" and CD) and 5 January 1991 (12"), was followed by the album "1916" on 21 January. The single, which was issued in 7", cassette, shaped picture disc, 12" and CD single, reached No. 45 in the UK Singles Chart, the album reached No. 24 in the UK Album Charts.
The band conducted their "It Serves You Right" tour of Britain in February, the "Lights Out Over Europe" tour followed, lasting until early April, when the band returned to Britain to play another six venues. In June the band played five dates in Japan and five dates in Australia and New Zealand. Between July and August, they played across the United States with Judas Priest, Alice Cooper, Metal Church and opener Dangerous Toys on the "Operation Rock 'n' Roll" tour. The band finished the year with six dates in Germany during December.
On 28 March 1992, the band played what would turn out to be Taylor's last engagement at Irvine Meadows, Irvine, California. The band had been wanting Lemmy to get rid of their manager, Doug Banker, for some time and after an unsolicited visit from Todd Singerman, who insisted he should manage them despite never having managed a band before, the band met with Singerman and decided to take him on board, firing Banker. In the midst of this, the band were recording an album at Music Grinder Studios, in the city's east part of Hollywood during the 1992 Los Angeles riots. Three drummers participated in the making of the "March ör Die" album: Phil Taylor, who was fired because he did not learn the drum tracks on the song "I Ain't No Nice Guy"; Tommy Aldridge who recorded most of the material on the album; and Mikkey Dee, who recorded "Hellraiser", a song originally written by Lemmy for Ozzy Osbourne's "No More Tears" album. "March ör Die" features guest appearances by Ozzy Osbourne and Slash.
"Bastards", "Sacrifice" and "Overnight Sensation", 1993–97.
Lemmy had known Mikkey Dee from the time when King Diamond had toured with Motörhead. He had asked Dee to become Motörhead's drummer before, but Dee had declined due to his commitment to King Diamond. On this occasion, Dee was available and met the band to try out. Playing the song "Hellraiser" first, Lemmy thought "he was very good immediately. It was obvious that it was going to work." After recording "Hellraiser" and "Hell on Earth" in the studio, Dee's first engagement with Motörhead was on 30 August at the Saratoga Performing Arts Center. The new line-up then went on tour, playing dates with Ozzy Osbourne, Skew Siskin and Exodus. On 27 September, the band played at the Los Angeles Coliseum with Metallica and Guns N' Roses. The band toured Argentina and Brazil during October and conducted the "Bombers and Eagles in '92" tour of Europe with Saxon throughout December.
Motörhead played two dates at the Arena Obras Sanitarias in Buenos Aires in April 1993 and toured Europe from early June until early July, returning to the United States to play one show at the New York Ritz on 14 August. A new producer was sought for the band's next album and eventually Howard Benson, who was to produce the band's next four albums, was chosen. The band recorded at A&M Studios and Prime Time Studios in Hollywood and the resultant album, titled "Bastards", was released on 29 November 1993. The single "Don't Let Daddy Kiss Me" included the song "Born to Raise Hell", which also appeared on the album and would later be re-recorded with collaborative vocals from both Ice-T and Ugly Kid Joe frontman, Whitfield Crane for the soundtrack of the movie "Airheads" (in which Lemmy also made a cameo appearance) and released as a single in its own right. Although "Bastards" received airtime, the record company ZYX Music would not pay for promotional copies, so the band sent out copies themselves. A further tour of Europe was made throughout December that year.
In February and March 1994, Motörhead toured the United States with Black Sabbath and Morbid Angel. In April the band resumed their tour of the States until early May, playing an engagement with the Ramones on 14 May at the Estadio Velez in Buenos Aires, attracting a crowd of 50,000 people. The band toured Japan in late May and Europe in June, August and December.
The band's 1995 touring schedule began in Europe in late April. In June, they went on a second tour with Black Sabbath, this time supported by Tiamat, until the band succumbed to influenza and headed back to Los Angeles and Cherokee Studios in Hollywood where they were to record an album. During the sessions it became clear that Würzel was not extending himself and left the band after the recording. The title track from the album, "Sacrifice", was later used in the movie "Tromeo and Juliet", a film in which Lemmy appears as the narrator. The band decided to continue as a three-man line-up and a tour of Europe was performed throughout October and the first two days of November. A three-day tour of South America followed the week after. Lemmy celebrated his 50th Birthday later that year with the band at the Whisky a Go Go in Los Angeles; Metallica played at the event under the name "The Lemmy's".
In 1996, the band began touring the States in early January and played thirty venues up to 15 February; a seven-date tour of Europe in June and July was followed by two engagements in South America during August.
A tour of the United States with Belladonna and Speedball began with two shows (Los Angeles & Hollywood) in early October 1996 and concluded in Washington on 4 December. During this time the band had recorded "Overnight Sensation", at Ocean Studio and Track House Recording Studio. The album was released on 15 October, the first official album of the band as a three-piece since "Another Perfect Day" and the best distributed album the band had had for years. The band concluded the year's touring with thirteen dates in Germany.
During 1997, the band toured extensively, beginning with the first leg of the "Overnight Sensation" tour in Europe on 12 January at the London Astoria, where the guest musicians were Todd Campbell, Phil Campbell's son, on "Ace of Spades" and "Fast" Eddie Clarke for "Overkill". The European leg lasted until March and was followed by four dates in Japan, from late May to 1 June, and an American tour with W.A.S.P. throughout the rest of June. In August, three dates in Europe were followed by seven dates in Britain, which ended with a show at the Brixton Academy on 25 October, where the guest musician was Paul Inder, Lemmy's son, for "Ace of Spades". A further four dates in October in Russia concluded the year 1997.
"Snake Bite Love", "We Are Motörhead" and "Hammered", 1998–03.
Lemmy recalled that the touring was going particularly well, with some countries like Argentina and Japan putting the band in larger venues, and the English promoters discovered that "they could turn a nice profit with Motörhead shows". In his opinion, the three-piece line-up was performing excellently and it was high time they made another live record. The band did eventually, but made another studio album first, "Snake Bite Love", recorded in various studios and released on 3 March 1998.
The band joined with Judas Priest at the Los Angeles Universal Amphitheatre on 3 April, to begin their "Snake Bite Love" tour. On 21 May, Motörhead were recorded at The Docks in Hamburg. The tracks from this performance were later released as "Everything Louder Than Everyone Else". The band were invited to join the Ozzfest Tour and played dates across the States during early July until early August and were in Europe from early October until late November. The British leg of the tour was dubbed the "No Speak With Forked Tongue" tour and included support bands Groop Dogdrill, Radiator and Psycho Squad, which was fronted by Phil Campbell's son Todd.
In 1999 Motörhead made a tour of the states between 20 April and 2 June, before going to Karo Studios in Brackel, Germany to record their next album, "We Are Motörhead", which was released in May the following year. During the time the album sessions took place, the band played at venues around Europe, the first of which was at Fila Forum in Assago, near Milan, where Metallica's James Hetfield joined the band on-stage to play "Overkill". In October and early November, the band toured the states with Nashville Pussy. Throughout the rest of November, the band conducted their European "Monsters of the Millennium" tour with Manowar, Dio and Lion's Share, ending the Millennium with two shows at the London Astoria. The two shows were billed under the "Kerrang!" "X-Fest" banner and at the first show were supported by Backyard Babies and during the second show guest vocals were provided by Skin from Skunk Anansie and Nina C. Alice from Skew Siskin for "Born to Raise Hell", and Ace from Skunk Anansie played "Overkill" with the band.
In May 2000, the release of "We Are Motörhead" and the single from it, a cover of the Sex Pistol's "God Save the Queen", coincided with the start of the band's "We Are Motörhead" tour across South and North America during May and June, with a further nine shows across in Europe in July. Shows in the United States and France were followed by the release of a double-disc compilation album, "The Best Of", on 26 August.
Four dates in Japan preceded the band's 25th anniversary concert on 22 October at the Brixton Academy in London, where guest appearances were made by "Fast" Eddie Clarke, Brian May, Doro Pesch, Whitfield Crane, Ace, Paul Inder and Todd Campbell. The show also featured the return of the Bomber-lighting rig. The event was filmed and released the following year as the "25 & Alive Boneshaker" DVD, and the CD of the show, "Live at Brixton Academy", was released two years after that. Lemmy states the reason for the DVD as wanting "to record it for the posterity or whatever it is. I nodded off through the tenth anniversary, we never did anything on the twentieth, so the twenty-fifth made sense."
A tour of West and East Europe followed the anniversary concert, taking the band through October, November and December. The schedule for the Eastern European tour was quite brutal, involving two eighteen-hour drives back-to-back and little time off, at the Warsaw venue the band did not arrive until eleven o'clock and the crew were still loading into the venue at one in the morning, while the fans waited.
After taking a month off, the band began working on a new album at Chuck Reid's house in the Hollywood Hills. This album, "Hammered", was released the following year. On 1 April 2001, the band gave a one song performance for Triple H's entrance at WrestleMania X-Seven at the Reliant Astrodome in Houston. The second leg of the "We Are Motörhead" tour began in May in Ireland, moving across to the United Kingdom. In Manchester, the band were supported by Goldblade, and by Pure Rubbish at the two London shows. The second London show also included Backyard Babies and Paul Inder, who was guest musician for "Killed By Death". Between June and August, Motörhead played at a number of rock festivals in Europe; including as the Graspop Metal Meeting in Belgium, the Quart Festival in Norway, and the Wacken Open Air on 4 August, where four songs were recorded for the "25 & Alive Boneshaker" DVD. The band returned to the States for a seven show tour between late September and early October.
In April 2002, a DVD of some of Motörhead's performances from the 1970s and 1980s along with some stock footage of the band was released as "The Best of Motörhead". Two weeks earlier, the "Hammered" album was released and supported by the "Hammered" tour, which kicked off in the States at around the same time. The United States dates continued until late May, and a European leg followed between June and August. In October, the band played five dates in Great Britain with Anthrax, Skew Siskin and Psycho Squad. The final venue was the Wembley Arena in London, where instead of Psycho Squad, the band were supported by Hawkwind, with Lemmy performing "Silver Machine" on stage with them. Throughout the rest of October and better part of November, the band were on a European tour with Anthrax.
In April and May 2003, the band continued to promote the "Hammered" album in the States, and on the three dates Phil Campbell had to miss, his mother having died, Todd Youth stood in for him. Between late May and mid-July the band played seven dates at Summer Festivals in Europe and from late-July until the end of August, they were touring the United States with Iron Maiden and Dio. On 7 October a comprehensive five-disc collection of the band's recordings covering 1975–2002 was released as "Stone Deaf Forever!". On 1 September 2003, the band returned to Hollywood's Whisky A Go-Go club for the Hollywood Rock Walk of Fame Induction. During October, the band performed a tour of Great Britain with The Wildhearts and Young Heart Attack. The band performed seven shows across Belgium, the Netherlands and Spain between 21 and 28 October and from late-November until early-December they were in Germany and Switzerland, touring with Skew Siskin and Mustasch. On 9 December, the previously recorded "Live at Brixton Academy" album was released.
"Inferno", "Kiss of Death" and "Motörizer", 2004–09.
On 22 February 2004 Motörhead performed an invitation-only concert at the Royal Opera House in Covent Garden, London; at Summer Festivals in South America during May; and also Europe during June, July and August. The band had already spent time in the recording studio, working on their next album, "Inferno", which was released on 22 June and was followed by the "Inferno" tour of Ireland with Class of Zero for three dates, before being joined by Sepultura and taking it to Great Britain.
Some of the London show at the Hammersmith Apollo was filmed for TV as Gene Simmons introduced the extra opening act, The Class – a band made up of school children appearing in his Channel 4 series, "Rock School" – and Würzel joined as guest musician for "Overkill". The band continued the tour with Sepultura across Europe through the rest of November and December. At the show in Magdeburg, Germany on 4 December Motörhead joined Sepultura on stage during their support slot playing the song "Orgasmatron", in celebration of Sepultura's 20th Anniversary. The show on 7 December at the Philipshalle in Düsseldorf was recorded and later released as the "Stage Fright" DVD.
Motörhead picked up their first Grammy in the awards of 2005 in the Best Metal Performance category for their cover of Metallica's "Whiplash" on "". From March until early May, the band toured the United States, and in June and August were on the "30th Anniversary" tour in Europe. On 22 August, the band were the subject of an hour-long documentary, "Live Fast, Die Old", which was aired on Channel 4 as part of "The Other Side" series of documentaries, filmed by new and established directors.
On 20 September, a compilation album containing the band's appearances on BBC Radio 1 and a concert recording from Paris Theatre, London, was released as "BBC Live & In-Session". In October, the band toured Europe with Mondo Generator before returning to Great Britain to tour with In Flames and Girlschool in October and November. During the show at the Brixton Academy on 19 November, Lemmy joined Girlschool on stage to play "Please Don't Touch". Motörhead finished the year's tours in December, with two engagements in New Zealand and five in Australia with Mötley Crüe. Also in 2005, Motörhead played on the Vaya Con Tioz farewell festival Böhse Onkelz at Lausitzring.
In 2006, the band performed a four-date House of Blues tour in the States in March with Meldrum and from June until early August played at European open-air festivals with some indoor headlining shows. On 28 October, the band performed at The Rock Freakers Ball in Kansas City before heading off to tour Great Britain with Clutch and Crucified Barbara.
While that tour was still going, their next album, "Kiss of Death", was released on 29 August 2006 via Sanctuary Records, with a video for "Be My Baby". The tour ended with an engagement on 25 November at the Brixton Academy, where Phil Campbell was guest guitarist for "Killed By Death" played during Crucified Barbara's support set. A further twelve shows in Europe with Meldrum took them through the end of November to early December, the first two shows also featuring Skew Siskin.
In November, the band agreed to a sponsorship deal with the Greenbank B under-10s football team from North Hykeham, Lincoln, putting the band's name as well as War-Pig on the team's shirts; the under-10s run out to "Ace of Spades". Lemmy is old friends with Gary Weight, the team's manager; Weight "sent an email off to them and they came back and said it was a great idea" and hopes the deal will draw inspired performances from his team. On 25 April 2007, the band played at the Poliedro de Caracas in Caracas, Venezuela, and on 29 April at the Fundiçao Progresso, Rio de Janeiro. In June, Motörhead played an engagement at the Royal Festival Hall as part of Jarvis Cocker's Meltdown. On 26 February 2008, "No Sleep 'til Hammersmith" was reissued again as a two disc CD.
From March through to June 2008, the band convened in Los Angeles with producer Cameron Webb to begin work on their 19th album "Motörizer". Mikkey Dee's drum tracks were recorded at Dave Grohl's studio. Motörizer was released on 26 August. It does not feature artwork from Joe Petagno, the artist who designed many of their classic album covers.
In June 2008 the band performed at the main stage of the Download festival. Between 6 and 31 August, Motörhead joined with Judas Priest, Heaven & Hell and Testament on the Metal Masters Tour. On 20 August the band played one date at the Roseland Ballroom, New York, as part of "The Volcom Tour 2008", which continued with bands The Misfits, Airbourne, Valient Thorr and Year Long Disaster at House of Blues, Anaheim, California on 2 September, playing a further thirteen dates. The band concluded the tour without the supporting bands, playing one more show at the Roseland Ballroom on 20 September, and the final engagement, at The Stone Pony, Asbury Park, New Jersey on 21 September.
On 30 September, Reuters reported that Neverdie Studios had signed a deal with Lemmy and Motörhead to develop and market Lemmy's Castle and Motorhead Stadium inside the virtual world of Entropia Universe, an online virtual universe. The year's touring ended with a 34-date tour of Europe with a variety of support bands including Danko Jones, Saxon, Witchcraft, and Airbourne. On 6 March 2009, the band played in the Middle East for the first time, at the annual Dubai Desert Rock Festival in Dubai. On 1 April Motörhead were reported to have entered into a two-year sponsorship deal with UK Roller Derby team the Lincolnshire Bombers Roller Girls.
That September, noted drummer Matt Sorum filled in for Mikkey Dee for a U.S. tour.
In November 2009, the band are being supported by NWOBHM veterans Sweet Savage on the Irish leg of the tour (30 years after first sharing the stage together) and punk and goth rock legends The Damned on the UK leg of their world tour. On The Damned's official website, Captain Sensible is quoted as saying:
"The Wörld Is Yours", "Aftershock" and "Bad Magic", 2010–15.
In a November 2009 interview with ABORT Magazine's E.S. Day, Lemmy stated that Motörhead would enter the studio in February 2010 "to rehearse, write and record" their 20th studio album, to be released by the end of the year. The album was recorded with Cameron Webb and Welsh producer Romesh Dodangoda in Longwave Studio, Cardiff.
In an interview with Hungarian television in July 2010, drummer Mikkey Dee announced that the album was finished, with 11 tracks. The album's name was said to be "The Wörld Is Yours". On 3 November 2010, Future PLC, a UK media company, announced that Motörhead were to release "The Wörld is Yours" via an exclusive publishing deal with "Classic Rock" magazine on 14 December 2010. The standard CD release of "The Wörld is Yours" would go on sale on 17 January 2011, through Motörhead's own label, Motörhead Music.
To coincide with the release of their upcoming album, Motörhead embarked on a 35th Anniversary UK tour, from 8–28 November 2010, and a European tour from 30 November 2010 – 19 December 2010. They also took their tour to the Americas in 2011. In October, the band recorded a slow blues version of their longtime hit "Ace of Spades" for a TV spot for Kronenbourg beer. On 5 December the single "Get Back in Line" was released, followed by the release of a video for the single on 6 December. In December, Mikkey Dee stated to French journalists that Motörhead are planning to release a box-set with several DVDs in 2011. He did not give any details but said that it will come in a "beautiful package including many surprises".
On 17 January 2011, it was announced that Motörhead would be part of the Sonisphere Festival in Knebworth. In August 2011, they headlined the Brutal Assault open-air festival in the Czech Republic. On 2 March 2011 Motörhead performed on "Late Night with Jimmy Fallon".
On 9 July 2011, former guitarist Würzel died of a heart attack. In celebration of 35 years' touring, in late 2011 the band released the live DVD "The Wörld Is Ours – Vol 1 – Everywhere Further Than Everyplace Else", including performances at the O2 Apollo Manchester, Best Buy Theater, New York City and Teatro Caupolicán, Santiago de Chile.
On 19 December 2011, it was announced that Motörhead would play at the German festivals Rock am Ring and Rock im Park in Nürburgring and Nuremberg respectively in June 2012. On 12 January 2012, it was announced that Motörhead were touring the US and Canada in early 2012, along with three other metal bands Megadeth, Volbeat and Lacuna Coil. The Gigantour took place from 26 January to 28 February 2012, but Motörhead missed the final four shows because Lemmy had a combination of an upper respiratory viral infection and voice strain, resulting in severe laryngitis. Lemmy wrote on Facebook, "I'm giving my voice a good rest", hoping he would recover soon to play at the Mayhem Festival, which was held from 30 June to 5 August 2012. Motörhead also took part on 23 June in the Rock-A-Field Luxembourg Open Air Festival in Roeser.
In an April 2012 interview with Classic Rock Revisited, Lemmy was asked if Motörhead were planning to make a follow-up to "The Wörld Is Yours". He replied, "We have not started writing any songs yet but we will. We put out an album out every two years. I will continue to do that as long as I can afford an amp." On 28 June 2012, Lemmy told Auburn Reporter that Motörhead will release their next album in 2013 and they had written "about 6 songs so far." On 23 October 2012, Lemmy told Billboard.com that the band had planned to enter the studio in January to begin recording the album for a mid-2013 release. On 28 February 2013, it was announced that Motörhead had begun recording their new album. Motörhead released the live DVD "The Wörld Is Ours – Vol. 2 – Anyplace Crazy As Anywhere Else" in September 2012. On 18 June 2013, the new album's title was revealed to be "Aftershock".
In mid-November 2013, Motörhead were due to embark on a European tour alongside Saxon, followed by a tour in Germany and Scandinavia due to last until mid December 2013 but the dates were postponed and rescheduled for February and March 2014 due to Lemmy's health problems. However, in January 2014, Motörhead announced the cancellation of the new February and March dates of their European tour as Lemmy was still to reach full recovery from diabetes related health problems. But the same month, the band was confirmed for Coachella Festival to take place across two weekends in spring 2014 (12–14 and 19–21 April) in Indio, California, the exact dates to be revealed as 13 and 20 April 2014. In February 2014, Motörhead confirmed a Summer tour 2014 with eight European dates (from 24 June to 10 August) in France (2 dates), Switzerland, Italy, Germany (2 dates), Russia and Ukraine. In March 2014, the band announced a Los Angeles date on 11 April 2014 at Club Nokia. Later on, two new dates on 17 and 18 April 2014 respectively in Las Vegas (Pearl) and San Francisco (Warfield) were added. Still in March 2014, Motörhead announced that three heavy metal bands Megadeth, Anthrax and themselves would perform from 22 to 26 September 2014 at the first annual Motörhead's Motörboat cruise on board the Carnival Ecstasy (self-proclaimed "The Loudest Boat in the World"), due to sail from Miami and visit the ports of Key West and the Cozumel island just off Mexico's Yucatán Peninsula.
In a September 2014 interview on Full Metal Jackie, Lemmy stated that Motörhead would "probably" enter the studio in January 2015 to start work on their 22nd studio album for a tentative late 2015 release. On 25 February 2015, Motörhead officially confirmed that they were in the studio recording their new album in Los Angeles with longtime producer Cameron Webb. On 27 May 2015, the band released teasers on their Facebook page with the roman number "XXXX" on it. On 4 June the new album (which would be their last) "Bad Magic" was launched for pre-order on Amazon, revealing its title and cover art which also shows the "XXXX", coinciding with the 40th anniversary of the band. The album was released on 28 August 2015.
The band performed at the UK's Glastonbury Festival in June 2015, in what would turn out to be their final UK performance.
While touring the album as the "40th anniversary Tour", Motörhead had to cut short their Salt Lake City show on 27 August 2015 (in the Rocky Mountains) due to Lemmy's breathing problems (the result of an altitude sickness) and then they had to cancel completely day-off their Denver Riot Fest set on 28 August 2015. Their tour picked up again on 1 September 2015 at Emo's in Austin, Texas (moved from Cedar Park Center) but the group were again forced to abandon their set after three songs and to cancel subsequent shows (from the show on 2 September 2015 in San Antonio, Texas to the show on 5 September 2015 in Houston, Texas included).
Despite his ongoing health issues forcing Motörhead to cut short or cancel several US shows, Lemmy Kilmister was able to bounce back in time for the trio's annual Motörboat heavy metal cruise from Miami to the Bahamas which ran from 28 September through 2 October 2015 including performances by heavy metal legends Slayer and underground heroes like Anthrax, Exodus, Suicidal Tendencies and Corrosion of Conformity. For this occasion, Motörhead performed live two entire (identical) sets on 30 September and 1 October 2015.
Motörhead continued the "40th Anniversary Tour" in Europe in November and December. They played concerts in Germany, Sweden, Norway and Finland. Their final concert was in Berlin, Germany on December 11, 2015. After Lemmy's death, drummer Mikkey Dee spoke in an interview about him: "He was terribly gaunt. He spent all his energy on stage and afterwards he was very, very tired. It's incredible that he could even play, that he could finish the Europe tour. It was only 20 days ago. Unbelievable." The "40th Anniversary Tour" was planned to continue in January 2016 in the band's home country the U.K., the first concert would have been in Newcastle January 23, 2016.
Lemmy's death and breakup, 2015.
On 28 December 2015, Lemmy died, four days after celebrating his 70th birthday. He was the second Motörhead member to die in 2015, following Phil Taylor the previous month. The band posted the following message on Facebook:
The following day, drummer Mikkey Dee confirmed that Motörhead would not continue, stating, "Motörhead is over, of course. Lemmy was Motörhead. We won't be doing any more tours or anything. And there won't be any more records. But the brand survives, and Lemmy lives on in the hearts of everyone." Two days after Lemmy's death, guitarist Phil Campbell also stated that "Motörhead is no longer".
A few days later, the band's long-time manager Todd Singerman told the press that Lemmy had experienced chest pains two days after his 70th birthday party (held at Whisky a Go Go) and visited into the emergency room, but was released the next day. However, Singerman was concerned because Lemmy's speech was "getting bad" and took him to a brain scan. On December 26, the doctor came into Lemmy's apartment, "brought the results and told us all that he has two to six months to live". Lemmy reacted calmly. "He took it better than all of us," said Singerman. "His only comment was, 'Oh, only two months, huh?' The doctor goes, 'Yeah, Lem, I don't want to bullshit you. It's bad, and there's nothing anyone can do. I would be lying to you if I told you there was a chance.'"
Plans were made to treat Lemmy at home. A video game console at the Rainbow Bar and Grill that Lemmy loved to play was brought to his apartment. On 28 December 2015, he spent hours on the console, and Rainbow owner Mikael Maglieri paid a visit. Lemmy died in his sleep later that day.
UDR Music will release a Motörhead archive live album, "Clean Your Clock", on May 27, 2016, which will contain material recorded at the November 20–21, 2015 shows at the Zenith in Munich.
Style.
In a biography of the band, senior editor for AllMusic, Stephen Thomas Erlewine, wrote: "Motörhead's overwhelmingly loud and fast style of heavy metal was one of the most groundbreaking styles the genre had to offer in the late '70s" and though "Motörhead wasn't punk rock ... they were the first metal band to harness that energy and, in the process, they created speed metal and thrash metal." Whether they created these genres might be subject to debate, but Motörhead were unquestionably influential.
Although Motörhead is often considered a heavy metal band, Lemmy always described Motörhead's music as simply "rock and roll". In 2011, he said: "We were not heavy metal. We were a rock 'n' roll band. Still are. Everyone always describes us as heavy metal even when I tell them otherwise. Why won't people listen?" In 2014, he reiterated to "Der Spiegel" that he did not particularly like heavy metal.
Lemmy had stated that he generally felt more kinship with punk rockers than with heavy metal bands: Motörhead had engagements with fellow Brits The Damned, with whom he played bass on a handful of late 1970s engagements, as well as having penned the song "R.A.M.O.N.E.S." as a tribute to the Ramones. Motörhead, Lemmy stated, have more in common aesthetically with The Damned than Black Sabbath, and nothing whatsoever in common with Judas Priest. Lemmy said he felt little kinship with the speed metal bands Motörhead have inspired:
The "NME" stated that their brief solos were just long enough "... to open another bottle of beer", while a 1977 "Stereo Review" commented that "they know they're like animals, and they don't want to appear any other way. In view of the many ugly frogs in heavy metal who think they are God's gift to womankind these Quasimodos even seem charming in their own way". Motörhead's approach has not changed drastically over the band's career, though this is a deliberate choice: erstwhile Motörhead drummer Phil "Philthy Animal" Taylor said that rock icons like Chuck Berry and Little Richard never drastically altered their style, and, like them, Motörhead preferred to play what they enjoyed and did best. This fondness for the first decade of rock and roll (mid-1950s to mid-1960s) is also reflected in some of Motörhead's occasional cover songs from that era.
Lemmy often played powerchords in his basslines. When asked about whether he had begun as a rhythm guitarist, he stated:
Name and logo.
The name "Motörhead" is a reference to users of the drug amphetamine. The so-called "metal umlaut" over the second "o" has no effect on the pronunciation of the name, and was used in several heavy metal bands' names (along with blackletter fonts) to give them a Teutonic feel. The band's distinctive fanged-face logo, with its oversized boar's tusks, chains, and spikes, was created by artist Joe Petagno in 1977 for the cover of the "Motörhead" album and has appeared in many variations on covers of ensuing albums. The fanged face has been referred to variously as "War-Pig" and "Snaggletooth".
Cover art.
The band's name is usually printed in a lowercase form of blackletter. The umlaut character ö is possibly derived from the similar "heavy metal umlaut" in the name of their 1975 acquaintances Blue Öyster Cult. However, this umlaut does not alter the pronunciation of the band's name. When asked if Germans pronounced the band "Motuuuurhead", Lemmy answered "No, they don't. I only put it in there to look mean". 
Snaggletooth is the fanged face that serves as the symbol of Motörhead. Artist Joe Petagno drew it in 1977 for the cover of the band's debut album (with designer Phil Smee who turned it into a negative and did the lettering to complete the logo), having met Lemmy while doing some work with Hawkwind. Petagno stated:
Eddie Clarke was less sure about the imagery to begin with:
It has remained a symbol of Motörhead throughout the years, with Petagno creating many variations of Snaggletooth, or as some have called it and written it down as War-Pig, for the covers of ensuing albums. To date, only two of the original covers for Motörhead's 22 studio albums do not feature any variation of War-Pig on the cover: "On Parole" and "Overnight Sensation" (of which, "On Parole" was never sanctioned by the band), and was in any case reissued with a black Snaggletooth on a white background. Phil is wearing a Snaggletooth badge on the cover of "Ace of Spades". The cover of "Iron Fist" depicts a metal gauntlet wearing four skull-shaped rings, one of which is Snaggletooth, while the rear of the album-sleeve shows a fully detailed 3-D metal sculpture of the symbol. Originally the Snaggletooth design included a swastika on one of the helmet's spikes. This was painted out on later re-releases of the albums on CD.
On 21 September 2007, Petagno announced that "there will be no more "HEADS" from my hand", citing irreconcilable differences between himself and the band's current management, Singerman Entertainment. Petagno stated:
In reply, Lemmy stated:
Wrestling.
Motörhead are well known in the professional wrestling world for performing wrestler Triple H's entrance music, "The Game", which he has used as his entrance music since January 2001. In addition to the song playing whenever Triple H appears on WWE programming such as "Raw" or "SmackDown", and at other pay-per-view wrestling events, the band have performed the song live for him at WrestleMania X-Seven and WrestleMania 21. Their song "Rock Out" was also used as the theme song of the WWE pay-per-view Unforgiven in 2008. Motörhead also provided the entrance music for Triple H's faction Evolution, entitled "Line in the Sand". "The Game" was released on both the American version of the "Hammered" and "WWF The Music, Vol. 5" albums, and "Line in the Sand" was released on the "" album. Motörhead have since performed a new entrance track for Triple H, entitled "King of Kings", which made its debut at WrestleMania 22. Triple H has also introduced the band in concert. Lemmy inspired Triple H's facial hair, and Triple H spoke at Lemmy's funeral.

</doc>
<doc id="20908" url="https://en.wikipedia.org/wiki?curid=20908" title="MMU">
MMU

MMU may refer to:
2H6N2O), a chemical used in synthetic medications -->

</doc>
<doc id="20911" url="https://en.wikipedia.org/wiki?curid=20911" title="Multiverse">
Multiverse

The multiverse (or meta-universe) is the hypothetical set of finite and infinite possible universes, including the universe in which we live. Together, these universes comprise everything that exists: the entirety of space, time, matter, energy, and the physical laws and constants that describe them.
The various universes within the multiverse are called "parallel universes", "other universes" or "alternate universes."
The American philosopher and psychologist William James used the term "multiverse" in 1895, but in a different context.
Origin of the term.
In Dublin in 1952, Erwin Schrödinger gave a lecture in which he jocularly warned his audience that what he was about to say might "seem lunatic." He said that, when his Nobel equations seemed to describe several different histories, these were "not alternatives, but all really happen simultaneously." This is the earliest known reference to the multiverse.
Explanation.
The structure of the multiverse, the nature of each universe within it, and the relationships among these universes depend upon the specific multiverse hypothesis being considered.
Multiple universes have been hypothesized in cosmology, physics, astronomy, religion, philosophy, transpersonal psychology, and fiction, particularly in science fiction and fantasy. In these contexts, parallel universes are also called "alternate universes", "quantum universes", "interpenetrating dimensions", "parallel dimensions", "parallel worlds", "alternate realities", "alternate timelines", and "dimensional planes".
The physics community continues to debate the multiverse hypothesis. Prominent physicists disagree about whether the multiverse exists.
Some physicists say the multiverse is not a legitimate topic of scientific inquiry. Concerns have been raised about whether attempts to exempt the multiverse from experimental verification could erode public confidence in science and ultimately damage the study of fundamental physics. Some have argued that the multiverse is a philosophical rather than a scientific hypothesis because it cannot be falsified. The ability to disprove a theory by means of scientific experiment has always been part of the accepted scientific method. Paul Steinhardt has famously argued that no experiment can rule out a theory if the theory provides for all possible outcomes.
In 2007, Nobel laureate Steven Weinberg suggested that if the multiverse existed, "the hope of finding a rational explanation for the precise values of quark masses and other constants of the standard model that we observe in our Big Bang is doomed, for their values would be an accident of the particular part of the multiverse in which we live."
Search for evidence.
Around 2010, scientists such as Stephen M. Feeney analyzed Wilkinson Microwave Anisotropy Probe (WMAP) data and claimed to find evidence suggesting that our universe collided with other (parallel) universes in the distant past. However, a more thorough analysis of data from the WMAP and from the Planck satellite, which has a resolution 3 times higher than WMAP, did not reveal any statistically significant evidence of such a bubble universe collision.
In addition, there was no evidence of any gravitational pull of other universes on ours.
Proponents and skeptics.
Proponents of one of the multiverse hypotheses include Stephen Hawking, Brian Greene, Max Tegmark, Alan Guth, Andrei Linde, Michio Kaku, David Deutsch, Leonard Susskind, Alexander Vilenkin, Yasunori Nomura, Raj Pathria, Laura Mersini-Houghton, Neil deGrasse Tyson, and Sean Carroll.
Scientists who are generally skeptical of the multiverse hypothesis include: Nobel laureate Steven Weinberg, Nobel laureate David Gross, Paul Steinhardt, Neil Turok, Viatcheslav Mukhanov, Michael S. Turner, Roger Penrose, George Ellis, Joe Silk, Adam Frank, Marcelo Gleiser, Jim Baggott, and Paul Davies.
Arguments against multiverse theories.
In his 2003 "New York Times" opinion piece, "A Brief History of the Multiverse," author and cosmologist, Paul Davies, offered a variety of arguments that multiverse theories are non-scientific :
Taking cosmic inflation as a popular case in point, George Ellis, writing in August 2011, provided a balanced criticism of not only the science but, as he suggested, the scientific philosophy by which multiverse theories are generally substantiated.
He, like most cosmologists, accepts Tegmark's level-I "domains", even though they lie far beyond the cosmological horizon. Likewise, the multiverse of cosmic inflation is said to exist very far away. It would be so far away, however, that it's very unlikely any evidence of an early interaction will be found. He argues that, for many theorists, the lack of empirical testability or falsifiability is not a major concern.
Although he believes there's little hope that laboratory testing will ever be possible, he grants that the theories on which speculation is based have some scientific merit. He concluded that multiverse theory is a "productive research program":
Classification schemes.
Max Tegmark and Brian Greene have devised classification schemes for the various theoretical types of multiverse, or for the types of universe that a multiverse might comprise.
Max Tegmark's four levels.
Cosmologist Max Tegmark has provided a taxonomy of universes beyond the familiar observable universe. The four levels of Tegmark's classification are arranged such that subsequent levels can be understood to encompass and expand upon previous levels. They are briefly described below.
Level I: Beyond our cosmological horizon.
A prediction of chaotic inflation is the existence of an infinite ergodic universe, which, being infinite, must contain Hubble volumes realizing all initial conditions.
Accordingly, an infinite universe will contain an infinite number of Hubble volumes, all having the same physical laws and physical constants. In regard to configurations such as the distribution of matter, almost all will differ from our Hubble volume. However, because there are infinitely many, far beyond the cosmological horizon, there will eventually be Hubble volumes with similar, and even identical, configurations. Tegmark estimates that an identical volume to ours should be about 1010115 meters away from us.
Given infinite space, there would, in fact, be an infinite number of Hubble volumes identical to ours in the universe. This follows directly from the cosmological principle, wherein it is assumed that our Hubble volume is not special or unique.
Level II: Universes with different physical constants.
In the chaotic inflation theory, a variant of the cosmic inflation theory, the multiverse as a whole is stretching and will continue doing so forever, but some regions of space stop stretching and form distinct bubbles (like gas pockets in a loaf of rising bread). Such bubbles are embryonic level I multiverses. Linde and Vanchurin calculated the number of these universes to be on the scale of 101010,000,000.
Different bubbles may experience different spontaneous symmetry breaking, which results in different properties, such as different physical constants.
Level II also includes John Archibald Wheeler's oscillatory universe theory and Lee Smolin's fecund universes theory.
Level III: Many-worlds interpretation of quantum mechanics.
Hugh Everett's many-worlds interpretation (MWI) is one of several mainstream interpretations of quantum mechanics.
In brief, one aspect of quantum mechanics is that certain observations cannot be predicted absolutely. Instead, there is a range of possible observations, each with a different probability. According to the MWI, each of these possible observations corresponds to a different universe. Suppose a six-sided is thrown and that the result of the throw corresponds to a quantum mechanics observable. All six possible ways the die can fall correspond to six different universes.
Tegmark argues that a Level III multiverse does not contain more possibilities in the Hubble volume than a Level I or Level II multiverse. In effect, all the different "worlds" created by "splits" in a Level III multiverse with the same physical constants can be found in some Hubble volume in a Level I multiverse. Tegmark writes that, "The only difference between Level I and Level III is where your doppelgängers reside. In Level I they live elsewhere in good old three-dimensional space. In Level III they live on another quantum branch in infinite-dimensional Hilbert space."
Similarly, all Level II bubble universes with different physical constants can, in effect, be found as "worlds" created by "splits" at the moment of spontaneous symmetry breaking in a Level III multiverse. According to Yasunori Nomura, Raphael Bousso, and Leonard Susskind, this is because global spacetime appearing in the (eternally) inflating multiverse is a redundant concept. This implies that the multiverses of Levels I, II, and III are, in fact, the same thing. This hypothesis is referred to as "Multiverse = Quantum Many Worlds".
Related to the "many-worlds" idea are Richard Feynman's "multiple histories interpretation" and H. Dieter Zeh's "many-minds" interpretation.
Level IV: Ultimate ensemble.
The ultimate mathematical universe hypothesis is Tegmark's own hypothesis.
This level considers all universes to be equally real which can be described by different mathematical structures.
Tegmark writes that:
He argues that this "implies that any conceivable parallel universe theory can be described at Level IV" and "subsumes all other ensembles, therefore brings closure to the hierarchy of multiverses, and there cannot be, say, a Level V."
Jürgen Schmidhuber, however, says that the set of mathematical structures is not even well-defined and that it admits only universe representations describable by constructive mathematics — that is, computer programs.
Schmidhuber explicitly includes universe representations describable by non-halting programs whose output bits converge after finite time, although the convergence time itself may not be predictable by a halting program, due to the undecidability of the Halting problem. He also explicitly discusses the more restricted ensemble of quickly computable universes.
Brian Greene's nine types.
The American theoretical physicist and string theorist, Brian Greene, discussed nine types of parallel universes:
The quilted multiverse works only in an infinite universe. With an infinite amount of space, every possible event will occur an infinite number of times. However, the speed of light prevents us from being aware of these other identical areas.
Cyclic theories.
In several theories, there is a series of infinite, self-sustaining cycles (for example, an eternity of Big Bangs, Big Crunches, and/or Big Freezes).
M-theory.
A multiverse of a somewhat different kind has been envisaged within string theory and its higher-dimensional extension, M-theory.
These theories require the presence of 10 or 11 spacetime dimensions respectively. The extra 6 or 7 dimensions may either be compactified on a very small scale, or our universe may simply be localized on a dynamical (3+1)-dimensional object, a D3-brane. This opens up the possibility that there are other branes which could support other universes. This is unlike the universes in the quantum multiverse, but both concepts can operate at the same time.
Some scenarios postulate that our Big Bang was created, along with our universe, by the collision of two branes.
Black-hole cosmology.
A black-hole cosmology is a cosmological model in which the observable universe is the interior of a black hole existing as one of possibly many universes inside a larger universe. This includes the theory of white holes, which are on the opposite side of space-time.
While a black hole sucks everything in, including light, a white hole releases matter and light. Hence the name "white hole".
Anthropic principle.
The concept of other universes has been proposed to explain how our own universe appears to be fine-tuned for conscious life as we experience it.
If there were a large (possibly infinite) number of universes, each with possibly different physical laws (or different fundamental physical constants), then some of these universes (even if very few) would have the combination of laws and fundamental parameters that are suitable for the development of matter, astronomical structures, elemental diversity, stars, and planets that can exist long enough for life to emerge and evolve.
The weak anthropic principle could then be applied to conclude that we (as conscious beings) would only exist in one of those few universes that happened to be finely tuned, permitting the existence of life with developed consciousness. Thus, while the probability might be extremely small that any particular universe would have the requisite conditions for life (as we understand life), those conditions do not require intelligent design as an explanation for the conditions in the Universe that promote our existence in it.
Occam's Razor.
Proponents and critics disagree about how to apply Occam's Razor. Critics argue that to postulate an almost infinite number of unobservable universes, just to explain our own universe, seems contrary to Occam's Razor. But proponents argue that, in terms of Kolmogorov complexity, the proposed multiverse is simpler than a single idiosyncratic universe.
For example, multiverse proponent Max Tegmark argues:
Princeton cosmologist Paul Steinhardt used the 2014 Annual Edge Foundation Question to state his opposition to multiverse theories:
Steinhardt claims that multiverse theories have gained currency mostly because too much has been invested in theories that have failed (e.g., inflation theory and string theory). He sees in them an attempt to redefine the values of science, to which he objects even more strongly:
Modal realism.
Possible worlds are a way of explaining probability and hypothetical statements. Some philosophers, such as David Lewis, believe that all possible worlds exist and that they are just as real as the world we live in (a position known as modal realism).
Trans-world identity.
A metaphysical issue which crops up in multiverse theories that posit infinite identical copies of any given universe, is the notion that there can be identical objects in different possible worlds. According to the counterpart theory of David Lewis, the objects should be regarded as similar rather than identical.

</doc>
<doc id="20912" url="https://en.wikipedia.org/wiki?curid=20912" title="MBR">
MBR

MBR may refer to:

</doc>
<doc id="20914" url="https://en.wikipedia.org/wiki?curid=20914" title="Milton">
Milton

Milton may refer to:

</doc>
<doc id="20918" url="https://en.wikipedia.org/wiki?curid=20918" title="List of conflicts in the Near East">
List of conflicts in the Near East

The area known as the "Near East" is usually referred to as Middle East in modern contexts.
For periods predating Classical Antiquity, the common term is Ancient Near East.
The Near East is generally associated with Anatolia, the Levant, Mesopotamia, Persia, Egypt, the Arabian Peninsula, and the Caucasus.
Ancient Near East conflicts.
Early Iron Age.
"Note: This section is covering Iron Age I and II, Iron Age III is related as Classic Period"
Ottoman period conflicts 1453-1918.
Ottoman expansion.
Ottoman era period conflicts 1453-1516

</doc>
<doc id="20922" url="https://en.wikipedia.org/wiki?curid=20922" title="Molotov cocktail">
Molotov cocktail

A Molotov cocktail (, ), also known as a petrol bomb, poor man's grenade, fire bomb (not to be confused with an actual fire bomb) or just Molotov, is a generic name used for a variety of bottle-based improvised incendiary weapons. Due to the relative ease of production, they are frequently used by street criminals, protesters and non-professionally equipped fighters in riots, gang warfare, and urban guerrilla warfare. They are primarily intended to set targets ablaze rather than instantly obliterate them.
Name.
The name "Molotov cocktail" was coined by the Finns during the Winter War. The name is an insulting reference to Soviet foreign minister Vyacheslav Molotov, who was responsible for the setting of "spheres of interest" in Eastern Europe under the Molotov–Ribbentrop Pact in August 1939. The pact with the Nazis bearing Molotov's name was widely mocked by the Finns, as was much of the propaganda Molotov produced to accompany the pact, including his declaration on Soviet state radio that bombing missions over Finland were actually airborne humanitarian food deliveries for their starving neighbours. The Finns sarcastically dubbed the Soviet cluster bombs "Molotov bread baskets" in reference to Molotov's propaganda broadcasts. When the hand-held bottle firebomb was developed to attack Soviet tanks, the Finns called it the "Molotov cocktail", as "a drink to go with the food". Molotov himself despised the name, particularly as the term became ubiquitous.
Recipe.
A Molotov cocktail is a breakable glass bottle containing a flammable substance such as petrol or a napalm-like mixture, with some motor oil added, and usually a source of ignition such as a burning cloth wick held in place by the bottle's stopper. The wick is usually soaked in alcohol or kerosene, rather than petrol.
In action, the wick is lit and the bottle hurled at a target such as a vehicle or fortification. When the bottle smashes on impact, the ensuing cloud of petrol droplets and vapour ignites, causing an immediate fireball followed by spreading flames as the remainder of the fuel is consumed.
Other flammable liquids such as diesel fuel, methanol, turpentine, jet fuel, isopropyl alcohol and E85 have been used in place of, or combined with petrol. Thickening agents such as solvents, foam polystyrene, baking soda, petroleum jelly, tar, strips of tyre tubing, nitrocellulose, XPS foam, motor oil, rubber cement, detergent and dish soap have been added to help the burning liquid adhere to the target and create clouds of thick, choking smoke.
Development and use in war.
Spanish Civil War.
Improvised incendiary devices were used for the first time in the Spanish Civil War between July 1936 and April 1939, before they became known as "Molotov cocktails". In 1936, General Francisco Franco ordered Spanish Nationalist forces to use the weapon against Soviet T-26 tanks supporting the Spanish Republicans in a failed assault on the Nationalist stronghold of Seseña, near Toledo, south of Madrid. After that, both sides used simple petrol bombs or petrol-soaked blankets with some success. Tom Wintringham, a veteran of the International Brigades, later publicised his recommended method of using them:
Khalkhin Gol.
The Battle of Khalkhin Gol, a border conflict of 1939 ostensibly between Mongolia and Manchukuo, saw heavy fighting between Japanese and Soviet forces. Short of anti-tank equipment, Japanese infantry attacked Soviet tanks with gasoline-filled bottles. Japanese infantrymen claimed that several hundred Soviet tanks had been destroyed this way, though Soviet loss records do not support this assessment.
Finland.
On 30 November 1939, the Soviet Union invaded Finland, starting what came to be known as the Winter War. The Finnish Army faced large numbers of Red Army tanks. Being short on anti-tank guns, they improvised incendiary devices to use against them.
The Finns perfected the design and tactical use of the petrol bomb. The fuel for the Molotov cocktail was refined to a slightly sticky mixture of gasoline, kerosene, tar, and potassium chlorate. Further refinements included the attachment of wind-proof matches or a phial of chemicals that would ignite on breakage, thereby removing the need to pre-ignite the bottle, and leaving the bottle about one-third empty was found to make breaking more likely. As the cooling system was almost invariably placed where direct fire wouldn't hit it, the target of choice was the rear deck of a tank; the burning contents of the bottle would pour through the large cooling grills and ignite fuel, hydraulic fluids and ammunition.
A British War Office report dated June 1940 noted that:
Molotov cocktails were eventually mass-produced by the Alko corporation at its Rajamäki distillery, bundled with matches to light them. Production totalled 450,000 during the Winter War. The original recipe of the Molotov cocktail was a mixture of ethanol, tar and gasoline in a bottle. The bottle had two long pyrotechnic storm matches attached to either side. Before use, one or both of the matches was lit; when the bottle broke on impact, the mixture ignited. The storm matches were found to be safer to use than a burning rag on the mouth of the bottle.
Britain.
Early in 1940, with the prospect of immediate invasion, the possibilities of the petrol bomb gripped the imagination of the British public. For the layman, the petrol bomb had the benefit of using entirely familiar and available materials, and they were quickly improvised in large numbers, with the intention of using them against enemy tanks.
When used in the right way and in sufficient numbers, the Finns had found that they were effective. Although the experience of the Spanish Civil War received more publicity, the more sophisticated petroleum warfare tactics of the Finns were not lost on British commanders. In his 5 June address to LDV leaders, General Ironside said:
Wintringham advised that a tank that was isolated from supporting infantry was potentially vulnerable to men who had the required determination and cunning to get close. Rifles or even a shotgun would be sufficient to persuade the crew to close all the hatches, and then the view from the tank is very limited; a turret-mounted machine gun has a very slow traverse and cannot hope to fend off attackers coming from all directions. Once sufficiently close, it is possible to hide where the tank's gunner cannot see: "The most dangerous distance away from a tank is 200 yards; the safest distance is six inches." Petrol bombs will soon produce a pall of blinding smoke, and a well-placed explosive package or even a stout iron bar in the tracks can immobilise the vehicle, leaving it at the mercy of further petrol bombs – which will suffocate the engine and possibly the crew – or an explosive charge or anti-tank mine.
By August 1940, the War Office produced training instructions for the creation and use of Molotov cocktails. The instructions suggested scoring the bottles vertically with a diamond to ensure breakage and providing fuel-soaked rag, windproof matches or a length of cinema film (made of highly flammable nitrocellulose) as a source of ignition.
On 29 July 1940, manufacturers Albright & Wilson of Oldbury demonstrated to the RAF how their white phosphorus could be used to ignite incendiary bombs. The demonstration involved throwing glass bottles containing a mixture of petrol and phosphorus at pieces of wood and into a hut. On breaking, the phosphorus was exposed to the air and spontaneously ignited; the petrol also burned, resulting in a fierce fire. Because of safety concerns, the RAF was not interested in white phosphorus as a source of ignition, but the idea of a self-igniting petrol bomb took hold. Initially known as an A.W. bomb, it was officially named the No. 76 Grenade, but more commonly known as the SIP (Self-Igniting Phosphorus) grenade. The perfected list of ingredients was white phosphorus, benzene, water and a two-inch strip of raw rubber; all in a half-pint bottle sealed with a crown stopper. Over time, the rubber would slowly dissolve, making the contents slightly sticky, and the mixture would separate into two layers – this was intentional, and the grenade should not be shaken to mix the layers, as this would only delay ignition. When thrown against a hard surface, the glass would shatter and the contents would instantly ignite, liberating choking fumes of phosphorus pentoxide and sulphur dioxide as well as producing a great deal of heat. Strict instructions were issued to store the grenades safely, preferably underwater and certainly never in a house. Mainly issued to the Home Guard as an anti-tank weapon, it was produced in vast numbers; by August 1941 well over 6,000,000 had been manufactured.
However, there were voices that were more cautious. There were many who were sceptical about the efficacy of Molotov cocktails and SIPs grenades against the more modern German tanks. Weapon designer Stuart Macrae witnessed a trial of the SIPs grenade at Farnborough: "There was some concern that, if the tank drivers could not pull up quickly enough and hop out, they were likely to be frizzled to death, but after looking at the bottles they said they would be happy to take a chance." The drivers were proved right, trials on modern British tanks confirmed that Molotov and SIP grenades caused the occupants of the tanks "no inconvenience whatsoever".
Wintringham, though enthusiastic about improvised weapons cautioned against a reliance on petrol bombs and repeatedly emphasised the importance of using explosive charges.
Other fronts.
During the Irish War of Independence, the Irish Republican Army sometimes used sods of turf soaked in paraffin oil to attack British army barracks. Fencing wire was pushed through the sod to make a throwing handle.
The Polish Home Army developed a version which ignited on impact without the need of a wick. Ignition was caused by a reaction between concentrated sulfuric acid mixed with the fuel and a mixture of potassium chlorate and sugar which was crystallized from solution onto a rag attached to the bottle.
The United States Marine Corps developed a version during World War II that used a tube of nitric acid and a lump of metallic sodium to ignite a mixture of petrol and diesel fuel.
Modern use.
During the Second Battle of Fallujah in 2004, U.S. Marines employed Molotov cocktails made with "one part liquid laundry detergent, two parts gas" for 'burning out' their enemies from houses.
In Northern Ireland during the Troubles, Molotov cocktails were used by rioting paramilitary groups and protesters against the police, and they are also used to attack houses to burn the house or to intimidate the occupants.
In the Arab Spring, including in Cairo, Egypt, pro-government forces attacked protesters in Cairo with Molotovs. In the Bahraini uprising, protesters used Molotov cocktails against security forces.
Molotov cocktails were also used by protesters and civilian militia in Ukraine during violent outbreaks of the Euromaidan and the 2014 Ukrainian revolution. Protesters during the Ferguson riots used Molotov cocktails, while police used smoke bombs and tear gas.
In Bangladesh during anti government protests before the 2014 national election and in the year afterwards, many buses and cars were targeted with petrol bombs. A number of people burnt to death and many more were injured.
3 April 1981, Congress (I) activists threw a Molotov Cocktail on a public bus near Charu Market, Kolkata, West Bengal, India killing 7 passengers.
Legality.
As incendiary devices, Molotov cocktails are illegal to manufacture or possess in many regions. In the United States, Molotov cocktails are considered "destructive devices" under the National Firearms Act and regulated by the ATF.

</doc>
<doc id="20923" url="https://en.wikipedia.org/wiki?curid=20923" title="Matzo">
Matzo

Matzo, matza or matzah ( מצה ; plural matzot; matzos, matzus of Ashkenazi Hebrew dialect) is an unleavened flatbread that is part of Jewish cuisine and forms an integral element of the Passover festival, during which "chametz" (leaven and five grains that, per Jewish Law, can be leavened) is forbidden.
Matzo that is kosher for Passover is limited in Ashkenazi tradition to plain matzo made from flour and water. The flour may be whole grain or processed grain, but must be either wheat, spelt, barley, rye, or oat. Sephardic tradition also allow eggs to be used.
Passover and non-Passover matzo may be soft or crisp, but only the crisp "cracker" type is available commercially in most locations. Soft matzo, if it were commercially available, would essentially be a kosher flour tortilla. 
Non-Passover matzo may be made with onion, garlic, poppy seed, etc. It can even be made from rice, maize, buckwheat and other non-traditional flours that can never be used for Passover matzo. Gluten-free matzo-lookalike made from potato starch, tapioca starch, and other non-traditional flour is available and may be eaten on Passover, but does not fulfill the commandment of eating matzo, even for people with celiac disease who cannot eat Passover matzo, because matzo must be made from one of the 5 grains (wheat, barley, oat, spelt, and rye), all of which contain gluten, except for most (but not all) types of oat matzo. Oat matzo may only be used by those who can not have any other kind because it's not certain that oat is actually one of the 5 grains (it may be a mistranslation), so those who can have wheat matzo should do so.
Biblical sources.
"Matzo" is mentioned in the Torah several times in relation to The Exodus from Egypt:
Religious significance.
There are numerous explanations behind the symbolism of matzo. One is historical: Passover is a commemoration of the exodus from Egypt. The biblical narrative relates that the Israelites left Egypt in such haste they could not wait for their bread dough to rise; the bread, when baked, was matzo. (Exodus 12:39). The other reason for eating matzo is symbolic: On the one hand, matzo symbolizes redemption and freedom, but it is also "lechem oni", "poor man's bread". Thus it serves as a reminder to be humble, and to not forget what life was like in servitude. Also, leaven symbolizes corruption and pride as leaven "puffs up". Eating the "bread of affliction" is both a lesson in humility and an act that enhances the appreciation of freedom.
Another explanation is that matzo has been used to replace the pesach, or the traditional Passover offering that was made before the destruction of the Temple. During the Seder the third time the matzo is eaten it is preceded with the Sephardic rite, "zekher l’korban pesach hane’ekhal al hasova". This means "remembrance of the Passover offering, eaten while full". This last piece of the matzo eaten is called afikoman and many explain it as a symbol of salvation in the future.
The Passover Seder meal is full of symbols of salvation, including the opening of the door for Elijah and the closing line, “Next year in Jerusalem,” but the use of matzo is the oldest symbol of salvation in the Seder.
Ingredients.
At the Passover seder, simple matzo made of flour and water is mandatory. Sephardic tradition additionally permits the inclusion of eggs in the recipe. The flour must be ground from one of the five grains specified in Jewish law for Passover matzo: wheat, barley, spelt, rye or oat. Matzo made with wine, fruit juice, onion, garlic, etc., is not acceptable for use at any time during the Passover festival. 
Preparation.
Matzo dough is quickly mixed and rolled out without an autolyse step as used for leavened breads. Most forms are pricked with a fork or a similar tool to keep the finished product from puffing up, and the resulting flat piece of dough is cooked at high temperature until it develops dark spots, then set aside to cool and, if sufficiently thin, to harden to crispness. Dough is considered to begin the leavening process 18 minutes from the time it gets wet; sooner if eggs, fruit juice, or milk is added to the dough. The entire process of making matzo takes only a few minutes in efficient modern matzo bakeries.
After baking, matzo may be ground into fine crumbs, known as matzo meal. Matzo meal can be used like flour during the week of Passover when flour can otherwise be used only to make matzo.
Variations.
There are two major forms of matzo. In many western countries the most common form is the hard form of matzo which is cracker-like in appearance and taste and is used in all Ashkenazic and most Sephardic communities. Yemenites, and Iraqi Jews traditionally made a form of soft matzo which looks like Greek pita or like a tortilla. Soft matzo is made only by hand, and generally with "shmurah" flour.
Flavored varieties of matzo are produced commercially, such as poppy seed- or onion-flavored. Oat and spelt matzo with kosher certification are produced. Oat matzo is generally suitable for those who cannot eat gluten. Whole wheat, bran and organic matzo are also available. Chocolate-covered matzo is a favorite among children, although some consider it "enriched matzo" and will not eat it during the Passover holiday. A quite different flat confection of chocolate and nuts that resembles matzo is sometimes called "chocolate matzo".
Matzo contains typically 111 calories per 1-ounce/28g (USDA Nutrient Database), about the same as rye crispbread.
Shmurah matzo.
"Shmura" ("guarded") matzo (Hebrew מַצָּה שְׁמוּרָה "maṣṣā šəmūrā") is made from grain that has been under special supervision from the time it was harvested to ensure that no fermentation has occurred, and that it is suitable for eating on the first night of Passover. ("Shmura" wheat may be formed into either handmade or machine-made matzo, while non-"shmura" wheat is only used for machine-made matzo. It is possible to hand-bake matzo in "shmura" style from non-shmurah flour—this is a matter of style, it is not actually in any way "shmura"—but such matzo has rarely been produced since the introduction of machine-made matzo.)
Haredi Judaism is scrupulous about the supervision of matzo and have the custom of baking their own or at least participating in some stage of the baking process. Rabbi Chaim Halberstam of Sanz ruled that machine-made matzoth were "chametz". According to that opinion, hand-made non-"shmurah" matzot may be used on the eighth day of Passover outside of the Holy Land. However the non-Hasidic Haredi community of Jerusalem follows the custom that machine-made matzo may be used, with preference to the use of "shmurah" flour, in accordance with the ruling of Rabbi Yosef Chaim Sonnenfeld, who ruled that machine-made matzo may be preferable to hand made in some cases. The commentators to the Shulchan Aruch record that it is the custom of some of Diaspora Jewry to be scrupulous in giving Challah from the dough used for baking "Matzot Mitzvah" (the Shmurah Matzo eaten during Passover) to a Kohen child to eat.
Egg matzo.
"Egg (sometimes "enriched") matzo" are matzot usually made with fruit juice, often grape or apple juice instead of water, but not necessarily with eggs themselves. There is a custom among some Ashkenazi Jews not to eat them during Passover, except for the elderly, infirm, or children, who cannot digest plain matzo; these matzot are considered to be kosher for Passover if prepared otherwise properly. The issue of whether egg matzo is allowed for Passover comes down to whether there is a difference between the various liquids that can be used. Water facilitates fermentation of grain flour, but the question is whether fruit juice, eggs, honey, oil or milk are also deemed to do so.
The "Talmud", Pesachim 35a, states that liquid food extracts do not cause flour to leaven the way that water does. According to this view, flour mixed with other liquids would not need to be treated with the same care as flour mixed with water. The "Tosafot" (commentaries) explain that such liquids only produce a leavening reaction within flour "if" they themselves have had water added to them and otherwise the dough they produce is completely permissible for consumption during Passover, whether or not made according to the laws applying to matzot.
As a result, Joseph ben Ephraim Karo, author of the "Shulchan Aruch" or "Code of Jewish Law" (Orach Chayim 462:4) granted blanket permission for the use of any matzo made from non-water-based dough, including egg matzo, on Passover. Many egg matzo boxes no longer include the message, “Ashkenazi custom is that egg matzah is only allowed for children, elderly and the infirm during Passover.” Even amongst those who consider that enriched matzot may not be "eaten" during Passover, it is permissible to "retain" it in the home.
Cooking with matzo.
Matzo balls and matzo farfel are served in soup. Matzo brei is a dish of Ashkenazi origin made from matzo soaked in water and fried with eggs. These items are made from matzo meal, or finely ground matzo sometimes called cake meal, used as a binder in baked goods. Some Ashkenazim do not cook with matzo, believing that mixing it with water may allow leavening; the mixture is called "gebrochts" by Ashkenazi Jews. Kosher for Passover cakes and cookies are made with matzo meal or a finer variety called "cake meal", which gives them a denser texture than ordinary baked foods made with flour.
Sephardim use matzo soaked in water or stock to make pies or lasagne. known as "mina", "méguena", "mayena" or .
Matzo meal pancakes are made from a batter of matzo meal, egg, and milk.
Matzah pizza is a type of pizza made by covering a piece of matzo with sauce and melted cheese.
In Christianity.
Communion wafers used by the Catholic Church as well as in some Protestant traditions for the Eucharist are flat, unleavened bread. All Byzantine Rite churches use leavened bread for the Eucharist as this symbolizes the risen Christ. Some Oriental Orthodox and Eastern Catholic Christians use leavened bread, as in the east there is the tradition that leavened bread was on the table of the Last Supper. In the Armenian Apostolic Church, the Ethiopian Orthodox Tewahedo Church and Eritrean Orthodox Tewahedo Church, unleavened bread called "qǝddus qurban" in Ge'ez, the liturgical language of the Eritreans and Ethiopians, is used for communion.
Syrian Christians living on the Malabar coast of India (Kerala) have the customary celebration of Pesaha in their homes. On the evening before Good Friday, Pesaha bread is made at home. It is made with unleavened flour and they consume a sweet drink made up of coconut milk and jaggery along with this bread. On the Pesaha night, the bread is baked (steamed) immediately after rice flour is mixed with water and they pierce it many times with handle of the spoon to let out steam so that the bread will not rise (this custom is called "juthante kannu kuthal" in the Malayalam language meaning "piercing the bread according to the custom of Jews"). This bread is cut by the head of the family and shared among the family members.
Trivia.
At the end of World War II, the National Jewish Welfare Board had a matzo factory (according to the American Jewish Historical Society, it was probably the Manischewitz matzo factory in New Jersey) produce matzo in the form of a giant "V" for "Victory", for shipment to military bases overseas and in the U.S., for Passover seders for Jewish military personnel. Passover in 1945 began on 1 April, when the collapse of the Axis in Europe was clearly imminent; Germany surrendered a mere five weeks later.

</doc>
<doc id="20925" url="https://en.wikipedia.org/wiki?curid=20925" title="Michel Tremblay">
Michel Tremblay

Michel Tremblay, CQ (born 25 June 1942) is a Canadian novelist and playwright.
Tremblay was born in Montreal, Quebec, where he grew up in the French-speaking neighbourhood of Plateau Mont-Royal, at the time of his birth a neighbourhood with a working-class character and joual dialect, something that would heavily influence his work. Tremblay's first professionally produced play, "Les Belles-Sœurs", was written in 1965 and premiered at the Théâtre du Rideau Vert on August 28, 1968. It transformed the old guard of Canadian theatre and introduced joual to the mainstream. It stirred up controversy by portraying the lives of working class women and attacking the straight-laced, deeply religious society of mid-20th century Quebec.
His work and its impact.
The most profound and lasting effects of Tremblay's early plays, including "Hosanna" and "La Duchesse de Langeais", were the barriers they toppled in Quebec society. Until the Quiet Revolution of the early 1960s, Tremblay saw Quebec as a poor, working-class province dominated by an English-speaking elite and the Roman Catholic Church. Tremblay's work was part of a vanguard of liberal, nationalist thought that helped create an essentially modern society. His most famous plays are usually centered on homosexual characters. The women are usually strong but possessed with demons they must vanquish. It is said he sees Quebec as a matriarchal society. He is considered one of the best playwrights for women. In the late 1980s, "Les Belles-soeurs" ("The Sisters-in-Law") was produced in Scotland in Scots, as "The Guid-Sisters" ("guid-sister" being Scots for "sister-in-law"). His work has been translated into many languages, including Yiddish, and including such works as "Sainte-Carmen de la Main", "Ç'ta ton tour, Laura Cadieux", and "Forever Yours, Marilou" ("À toi pour toujours, ta Marie-Lou").
He has been openly gay throughout his public life, and he has written many novels ("The Duchess and the Commoner", "La nuit des princes charmants", "Le Coeur découvert", "Le Coeur éclaté") and plays ("Hosanna", "La duchesse de Langeais", "Fragments de mensonges inutiles") centred on gay characters. In a 1987 interview with Shelagh Rogers for CBC Radio's "The Arts Tonight", he remarked that he has always avoided behaviours he has considered masculine; for example, he does not smoke and he noted that he was 45 years old and did not know how to drive a car. "I think I am a rare breed," he said, "A homosexual who doesn't like men." He claims one of his biggest regrets in life was not telling his mother that he was gay, before she died.
His latest play to receive wide acclaim is "For the Pleasure of Seeing Her Again", a funny and nostalgic play, centered on the memories of his mother. He later published the Plateau Mont-Royal Chronicles, a cycle of six novels including "The Fat Woman Next Door is Pregnant" ("La grosse femme d'à côté est enceinte", 1978) and "The Duchess and the Commoner" ("La duchesse et le roturier", 1982). The second novel of this series, "Therese and Pierrette and the Little Hanging Angel" ("Thérèse et Pierrette à l'école des Saints-Anges", 1980), was one of the novels chosen for inclusion in the French version of "Canada Reads", "Le combat des livres", broadcast on Radio-Canada in 2005, where it was championed by union activist Monique Simard.
Tremblay worked also on a television series entitled "Le Cœur découvert" ("The Heart Laid Bare"), about the lives of a gay couple in Quebec, for the French-language TV network Radio-Canada. In 2005 he completed another novel cycle, the "Cahiers" ("Le Cahier noir" (translated as "The Black Notebook"), "Le Cahier rouge", "Le Cahier bleu"), dealing with the changes that occurred in 1960s Montreal during the Quiet Revolution. In 2009 "The Fat Woman Next Door" was a finalist in CBC's prestigious Canada Reads competition.
Political views.
For many years, Tremblay has believed that the only reasonable solution for Quebec is to separate from Canada. Once the Parti Québécois was elected in Quebec, he softened his views on allowing his plays to be produced in English there. He made it clear, however, that that did not mean that he agreed with bilingualism, calling it "stupid" and stating that he thought it ridiculous to expect a housewife in Vancouver to be fluent in both English and French.
Despite his often outspoken views in public, Tremblay's treatment of politics in his plays is subtle. Speaking of politics and the theatre in an CBC interview in 1978, Tremblay said:
"I know what I want in the theatre. I want a real political theatre, but I know that political theatre is dull. I write fables." 
In April 2006 he declared that he did not support the arguments put forward for the separation of Quebec. But he clarified his thoughts some time later by saying he was still a supporter of Quebec sovereignty, though critical of the actual state of the debate, which in his opinion was too much focused on economic issues. In response to this, the columnist Marc Cassivi of "La Presse" wrote that "there was only one closet a Quebec artist could never exit and that was the federalist one."
Awards and honours.
Tremblay has received numerous awards in recognition of his work. These include the "Prix Victor-Morin" (1974), the "Prix France-Québec" (1984), the Chalmers Award (1986) and the Molson Prize (1994).
He received the Lieutenant-Governor's award for Ontario in 1976 and 1977. Tremblay was named the "Montréalais le plus remarquable des deux dernières décennies dans le domaine du théâtre" (the most remarkable Montrealer of the past two decades in theatre) (1978). In 1991 he was appointed "Officier de l'Ordre de France," and in the same year, "Chevalier de l'Ordre National du Québec." He is also a recipient of the "Chevalier de l'Ordre des Arts et des Lettres de France" (1994).
In 1999, Tremblay received a Governor General's Performing Arts Award, Canada's highest honour in the performing arts. This produced controversy when several well-known Quebec nationalists suggested that he should refuse the award. While he did not do this, he did admit, for the first time, that he had refused the Order of Canada in 1990.
In 2000, "Encore une fois, si vous le permettez" ("For The Pleasure of Seeing Her Again") won a Chalmers Award and a Dora Mavor Moore Award.
Works.
Novels and short story collections.
Note: Most titles also available in English translations
Plays.
Note: Most titles also available in English translations

</doc>
<doc id="20926" url="https://en.wikipedia.org/wiki?curid=20926" title="Supervised learning">
Supervised learning

Supervised learning is the machine learning task of inferring a function from labeled training data. The training data consist of a set of "training examples". In supervised learning, each example is a "pair" consisting of an input object (typically a vector) and a desired output value (also called the "supervisory signal"). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see inductive bias). 
The parallel task in human and animal psychology is often referred to as concept learning.
Overview.
In order to solve a given problem of supervised learning, one has to perform the following steps:
A wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the No free lunch theorem). 
There are four major issues to consider in supervised learning:
Bias-variance tradeoff.
A first issue is the tradeoff between "bias" and "variance". Imagine that we have available several different, but equally good, training data sets. A learning algorithm is biased for a particular input formula_1 if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for formula_1. A learning algorithm has high variance for a particular input formula_1 if it predicts different output values when trained on different training sets. The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm. Generally, there is a tradeoff between bias and variance. A learning algorithm with low bias must be "flexible" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance. A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).
Function complexity and amount of training data.
The second issue is the amount of training data available relative to the complexity of the "true" function (classifier or regression function). If the true function is simple, then an "inflexible" learning algorithm with high bias and low variance will be able to learn it from a small amount of data. But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be learnable from a very large amount of training data and using a "flexible" learning algorithm with low bias and high variance. Good learning algorithms therefore automatically adjust the bias/variance tradeoff based on the amount of data available and the apparent complexity of the function to be learned.
Dimensionality of the input space.
A third issue is the dimensionality of the input space. If the input feature vectors have very high dimension, the learning problem can be difficult even if the true function only depends on a small number of those features. This is because the many "extra" dimensions can confuse the learning algorithm and cause it to have high variance. Hence, high input dimensionality typically requires tuning the classifier to have low variance and high bias. In practice, if the engineer can manually remove irrelevant features from the input data, this is likely to improve the accuracy of the learned function. In addition, there are many algorithms for feature selection that seek to identify the relevant features and discard the irrelevant ones. This is an instance of the more general strategy of dimensionality reduction, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.
Noise in the output values.
A fourth issue is the degree of noise in the desired output values (the supervisory target variables). If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples. Attempting to fit the data too carefully leads to overfitting. You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation that part of the target function that cannot be modeled "corrupts" your training data - this phenomenon has been called deterministic noise. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.
In practice, there are several approaches to alleviate noise in the output values such as early stopping to prevent overfitting as well as detecting and removing the noisy training examples prior to training the supervised learning algorithm. There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased generalization error with statistical significance.
Other factors to consider.
Other factors to consider when choosing and applying a learning algorithm include the following:
When considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see cross validation). Tuning the performance of a learning algorithm can be very time-consuming. Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.
The most widely used learning algorithms are Support Vector Machines, linear regression, logistic regression, naive Bayes, linear discriminant analysis, decision trees, k-nearest neighbor algorithm, and Neural Networks (Multilayer perceptron).
How supervised learning algorithms work.
Given a set of formula_4 training examples of the form formula_5 such that formula_6 is the feature vector of the i-th example and formula_7 is its label (i.e., class), a learning algorithm seeks a function formula_8, where formula_9 is the input space and
formula_10 is the output space. The function formula_11 is an element of some space of possible functions formula_12, usually called the "hypothesis space". It is sometimes convenient to
represent formula_11 using a scoring function formula_14 such that formula_11 is defined as returning the formula_16 value that gives the highest score: formula_17. Let formula_18 denote the space of scoring functions.
Although formula_12 and formula_18 can be any space of functions, many learning algorithms are probabilistic models where formula_11 takes the form of a conditional probability model formula_22, or formula_23 takes the form of a joint probability model formula_24. For example, naive Bayes and linear discriminant analysis are joint probability models, whereas logistic regression is a conditional probability model. 
There are two basic approaches to choosing formula_23 or formula_11: empirical risk minimization and structural risk minimization. Empirical risk minimization seeks the function that best fits the training data. Structural risk minimize includes a "penalty function" that controls the bias/variance tradeoff.
In both cases, it is assumed that the training set consists of a sample of independent and identically distributed pairs, formula_27. In order to measure how well a function fits the training data, a loss function formula_28 is defined. For training example formula_29, the loss of predicting the value formula_30 is formula_31. 
The "risk" formula_32 of function formula_11 is defined as the expected loss of formula_11. This can be estimated from the training data as
Empirical risk minimization.
In empirical risk minimization, the supervised learning algorithm seeks the function formula_11 that minimizes formula_32. Hence, a supervised learning algorithm can be constructed by applying an optimization algorithm to find formula_11. 
When formula_11 is a conditional probability distribution formula_40 and the loss function is the negative log likelihood: formula_41, then empirical risk minimization is equivalent to maximum likelihood estimation.
When formula_12 contains many candidate functions or the training set is not sufficiently large, empirical risk minimization leads to high variance and poor generalization. The learning algorithm is able
to memorize the training examples without generalizing well. This is called overfitting.
Structural risk minimization.
Structural risk minimization seeks to prevent overfitting by incorporating a regularization penalty into the optimization. The regularization penalty can be viewed as implementing a form of Occam's razor that prefers simpler functions over more complex ones.
A wide variety of penalties have been employed that correspond to different definitions of complexity. For example, consider the case where the function formula_11 is a linear function of the form
A popular regularization penalty is formula_45, which is the squared Euclidean norm of the weights, also known as the formula_46 norm. Other norms include the formula_47 norm, formula_48, and the formula_49 norm, which is the number of non-zero formula_50s. The penalty will be denoted by formula_51. 
The supervised learning optimization problem is to find the function formula_11 that minimizes
The parameter formula_54 controls the bias-variance tradeoff. When formula_55, this gives empirical risk minimization with low bias and high variance. When formula_54 is large, the learning algorithm will have high bias and low variance. The value of formula_54 can be chosen empirically via cross validation.
The complexity penalty has a Bayesian interpretation as the negative log prior probability of formula_11, formula_59, in which case formula_60 is the posterior probabability of formula_11.
Generative training.
The training methods described above are "discriminative training" methods, because they seek to find a function formula_11 that discriminates well between the different output values (see discriminative model). For the special case where formula_24 is a joint probability distribution and the loss function is the negative log likelihood formula_64 a risk minimization algorithm is said to perform "generative training", because formula_23 can be regarded as a generative model that explains how the data were generated. Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms. In some cases, the solution can be computed in closed form as in naive Bayes and linear discriminant analysis.
Generalizations of supervised learning.
There are several ways in which the standard supervised learning problem can be generalized:

</doc>
<doc id="20932" url="https://en.wikipedia.org/wiki?curid=20932" title="Martin Helwig">
Martin Helwig

Martin Helwig () (5 November 1516 – 26 January 1574) was a German cartographer of and from Silesia and
pedagogue. He was born in Neisse and died in Breslau, Holy Roman Empire.
Life.
A former pupil of an eminent German scholar and educationist Valentin Friedland, Martin Helwig went on to study at the University of Wittenberg, where as a student of Martin Luther and Philip Melanchthon he earned the academic degree of Magister. In 1552, he became Rector of St. Maria Magdalena School in Breslau (now Wrocław, in Poland). Equally proficient in mathematics and geography as well as classical languages, he produced the first woodcut map of Silesia made on the basis of surveys and data collected from local inhabitants, which he published in 1561 under the title "Silesiae Typus", and dedicated to Nicolaus II. Rehdiger, a wealthy Silesian merchant, banker, philanthropist, governor and patron of the principality of Breslau (Wrocław) who sponsored the map. Martin Helwig's map went on to receive acclaim in a public writing by Caspar Peucer, an eminent German scholar at the University of Wittenberg, and was later republished in several versions of Abraham Ortelius's pioneering world atlas, "Theatrum Orbis Terrarum".
The first map of Silesia by Martin Helwig constituted until the middle of the 18th century the main model and source of information for the cartographical presentation of this region of Europe on the maps of the most famous cartographers and publishers of those times.

</doc>
<doc id="20934" url="https://en.wikipedia.org/wiki?curid=20934" title="Macro virus">
Macro virus

In computing terminology, a macro virus is a virus that is written in a macro language: a programming language which is embedded inside a software application (e.g., word processors and spreadsheet applications). Some applications, such as Microsoft Office, allow macro programs to be embedded in documents such that the macros are run automatically when the document is opened, and this provides a distinct mechanism by which malicious computer instructions can spread. This is one reason it can be dangerous to open unexpected attachments in e-mails. Many antivirus programs can detect macro viruses, however they are still difficult to detect.
Fundamentals.
A macro is a series of commands and actions that help to automate some tasks - effectively a program but usually quite short and simple. However they are created, they need to be executed by some system which interprets the stored commands. Some macro systems are self-contained programs, but others are built into complex applications (for example word processors) to allow users to repeat sequences of commands easily, or to allow developers to tailor the application to local needs.
Operation.
A macro virus can be spread through e-mail attachments, removable media, networks, and the Internet, and is notoriously difficult to detect. A common way for a macro virus to infect a computer is by replacing normal macros with a virus. The macro virus replaces regular commands with the same name and runs when the command is selected. These malicious macros may start automatically when a document is opened or closed, without the user's knowledge.
Once a file containing a macro virus is opened, the virus can infect the system. When triggered, it will begin to embed itself in other documents and templates. It may corrupt other parts of the system, depending on what resources a macro in this application can access. When the infected documents are shared with other users and systems, the virus spreads. Macro viruses have been used as a method of installing software on a system without the user's consent, as they can be used to download and install software from the internet through the use of automated key-presses. However, this is uncommon as it is usually not fruitful for the virus coder since the installed software is usually noticed and uninstalled by the user. 
Since a macro virus depends on the application rather than the operating system, it can infect a computer running any operating system to which the targeted application has been ported. In particular, since Microsoft Word is available on Macintosh computers, word macro viruses can attack some Macs in addition to Windows platforms.
An example of a macro virus is the Melissa virus which appeared in March of 1999. When a user opens a Microsoft Word document containing the Melissa virus, their computer becomes infected. The virus then sends itself by email to the first 50 people in the person’s address book. This made the virus replicate at a fast rate.
Not all macro viruses are detected by antivirus software. Exercising caution when opening email attachments and other documents decreases the chance of becoming infected.

</doc>
<doc id="20935" url="https://en.wikipedia.org/wiki?curid=20935" title="Microsoft Access">
Microsoft Access

Microsoft Access is a DBMS (also known as Database Management System) from Microsoft that combines the relational Microsoft Jet Database Engine with a graphical user interface and software-development tools. It is a member of the Microsoft Office suite of applications, included in the Professional and higher editions or sold separately.
Microsoft Access stores data in its own format based on the Access Jet Database Engine. It can also import or link directly to data stored in other applications and databases.
Software developers and data architects can use Microsoft Access to develop application software, and "power users" can use it to build software applications. Like other Office applications, Access is supported by Visual Basic for Applications (VBA), an object-based programming language that can reference a variety of objects including DAO (Data Access Objects), ActiveX Data Objects, and many other ActiveX components. Visual objects used in forms and reports expose their methods and properties in the VBA programming environment, and VBA code modules may declare and call Windows operating-system functions.
History.
Project Omega.
Microsoft's first attempt to sell a relational database product was during the mid 1980s, when Microsoft obtained the license to sell . In the late 1980s Microsoft developed its own solution codenamed Omega. It was confirmed in 1988 that a database product for Windows and OS/2 was in development. It was going to include the "EB" Embedded Basic language, which was going to be the language for writing macros in all Microsoft applications, but the unification of macro languages did not happen until the introduction of Visual Basic for Applications (VBA). Omega was also expected to provide a front end to the Microsoft SQL Server. The application was very resource-hungry, and there were reports that it was working slowly on the 386 processors that were available at the time. It was scheduled to be released in the 1st quarter of 1990, but in 1989 the development of the product was reset and it was rescheduled to be delivered no sooner than in January 1991. Parts of the project were later used for other Microsoft projects: Cirrus (codename for Access) and Thunder (codename for Visual Basic, where the Embedded Basic engine was used). After Access's premiere, the Omega project was demonstrated in 1992 to several journalists and included features that were not available in Access.
Project Cirrus.
After the Omega project was scrapped, some of its developers were assigned to the Cirrus project (most were assigned to the team which created Visual Basic). Its goal was to create a competitor for applications like Paradox or dBase that would work on Windows. After Microsoft acquired FoxPro, there were rumors that the Microsoft project might get replaced with it, but the company decided to develop them in parallel. It was assumed that the project would make use of Extensible Storage Engine (Jet Blue) but, in the end, only support for Microsoft Jet Database Engine (Jet Red) was provided. The project used some of the code from both the Omega project and a pre-release version of Visual Basic. In July 1992, betas of Cirrus shipped to developers and the name Access became the official name of the product.
Timeline.
1992: Microsoft released Access version 1.0 on 13 November 1992, and an Access 1.1 release in May 1993 to improve compatibility with other Microsoft products and to include the Access Basic programming language.
1994: Microsoft specified the minimum hardware requirements for Access v2.0 as: Microsoft Windows v3.1 with 4 MB of RAM required, 6 MB RAM recommended; 8 MB of available hard disk space required, 14 MB hard disk space recommended. The product shipped on seven 1.44 MB diskettes. The manual shows a 1994 copyright date.
Originally, the software worked well with relatively small databases but testing showed that some circumstances caused data corruption. For example, file sizes over 10 MB proved problematic (note that most hard disks held less than 500 MB at the time this was in wide use), and the "Getting Started" manual warns about a number of circumstances where obsolete device drivers or incorrect configurations can cause data loss. With the phasing out of Windows 95, 98 and ME, improved network reliability, and Microsoft having released 8 service packs for the Jet Database Engine, the reliability of Access databases has improved and it supports both more data and a larger number of users.
With Office 95, Microsoft Access 7.0 (a.k.a. "Access 95") became part of the Microsoft Office Professional Suite, joining Microsoft Excel, Word, and PowerPoint and transitioning from Access Basic to VBA. Since then, Microsoft has released new versions of Microsoft Access with each release of Microsoft Office. This includes Access 97 (version 8.0), Access 2000 (version 9.0), Access 2002 (version 10.0), Access 2003 (version 11.5), Access 2007 (version 12.0), Access 2010 (version 14.0), and Access 2013 (version 15.0).
Versions 3.0 and 3.5 of Microsoft Jet database engine (used by Access 7.0 and the later-released Access 97 respectively) had a critical issue which made these versions of Access unusable on a computer with more than 1 GB of memory. While Microsoft fixed this problem for Jet 3.5/Access 97 post-release, it never fixed the issue with Jet 3.0/Access 95.
The native Access database format (the Jet MDB Database) has also evolved over the years. Formats include Access 1.0, 1.1, 2.0, 7.0, 97, 2000, 2002, 2007, and 2010. The most significant transition was from the Access 97 to the Access 2000 format; which is not backward compatible with earlier versions of Access. all newer versions of Access support the Access 2000 format. New features were added to the Access 2002 format which can be used by Access 2002, 2003, 2007, and 2010.
Microsoft Access 2000 increased the maximum database size to 2GB from 1GB in Access 97.
Microsoft Access 2007 introduced a new database format: ACCDB. It supports links to SharePoint lists and complex data types such as multivalue and attachment fields. These new field types are essentially recordsets in fields and allow the storage of multiple values or files in one field. Microsoft Access 2007 also introduced File Attachment field, which stored data more efficiently than the OLE (Object Linking and Embedding) field.
Microsoft Access 2010 introduced a new version of the ACCDB format supported hosting Access Web solutions on a SharePoint 2010 server. For the first time, this allowed Access solutions to be run without having to install Access on their PC and was the first support of Mac users. Any user on the SharePoint site with sufficient rights could use the Access Web solution. A copy of Access was still required for the developer to create the Access Web solution, and the desktop version of Access remained part of Access 2010. The Access Web solutions were not the same as the desktop solutions. Automation was only through the macro language (not VBA) which Access automatically converted to JavaScript. The data was no longer in an Access database but SharePoint lists. An Access desktop database could link to the SharePoint data, so hybrid applications were possible so that SharePoint users needing basic views and edits could be supported while the more sophisticated, traditional solutions could remain in the desktop Access database.
Microsoft Access 2013 offers traditional Access desktop solutions plus a significantly updated SharePoint 2013 web solution. The Access Web model in Access 2010 was replaced by a new architecture that stores its data in actual SQL Server databases. Unlike SharePoint lists, this offers true relational database design with referential integrity, scalability, extensibility and performance one would expect from SQL Server. The database solutions that can be created on SharePoint 2013 offer a modern user interface designed to display multiple levels of relationships that can be viewed and edited, along with resizing for different devices and support for touch. The Access 2013 desktop is similar to Access 2010 but several features were discontinued including support for Access Data Projects (ADPs), pivot tables, pivot charts, Access data collections, source code control, replication, and other legacy features. Access desktop database maximum size remained 2GB (as it has been since the 2000 version).
Prior to the introduction of Access, Borland (with Paradox and dBase) and Fox (with FoxPro) dominated the desktop database market. Microsoft Access was the first mass-market database program for Windows. With Microsoft's purchase of FoxPro in 1992 and the incorporation of Fox's Rushmore query optimization routines into Access, Microsoft Access quickly became the dominant database for Windows - effectively eliminating the competition which failed to transition from the MS-DOS world.
Access's initial codename was Cirrus; the forms engine was called Ruby. This was before Visual Basic. Bill Gates saw the prototypes and decided that the BASIC language component should be co-developed as a separate expandable application, a project called Thunder. The two projects were developed separately.
Access was also the name of a communications program from Microsoft, meant to compete with ProComm and other programs. This proved a failure and was dropped. Years later, Microsoft reused the name for its database software.
Uses.
In addition to using its own database storage file, Microsoft Access also may be used as the 'front-end' of a program while other products act as the 'back-end' tables, such as Microsoft SQL Server and non-Microsoft products such as Oracle and Sybase. Multiple backend sources can be used by a Microsoft Access Jet Database (ACCDB and MDB formats). Similarly, some applications such as Visual Basic, ASP.NET, or Visual Studio .NET will use the Microsoft Access database format for its tables and queries. Microsoft Access may also be part of a more complex solution, where it may be integrated with other technologies such as Microsoft Excel, Microsoft Outlook, Microsoft Word, Microsoft PowerPoint and ActiveX controls.
Access tables support a variety of standard field types, indices, and referential integrity including cascading updates and deletes. Access also includes a query interface, forms to display and enter data, and reports for printing. The underlying Jet database, which contains these objects, is multi-user and handles record-locking.
Repetitive tasks can be automated through macros with point-and-click options. It is also easy to place a database on a network and have multiple users share and update data without overwriting each other's work. Data is locked at the record level which is significantly different from Excel which locks the entire spreadsheet.
There are template databases within the program and for download from Microsoft's website. These options are available upon starting Access and allow users to enhance a database with predefined tables, queries, forms, reports, and macros. Database templates support VBA code but Microsoft's templates do not include VBA code.
Programmers can create solutions using VBA, which is similar to Visual Basic 6.0 (VB6) and used throughout the Microsoft Office programs such as Excel, Word, Outlook and PowerPoint. Most VB6 code, including the use of Windows API calls, can be used in VBA. Power users and developers can extend basic end-user solutions to a professional solution with advanced automation, data validation, error trapping, and multi-user support.
The number of simultaneous users that can be supported depends on the amount of data, the tasks being performed, level of use, and application design. Generally accepted limits are solutions with 1 GB or less of data (Access supports up to 2 GB) and performs quite well with 100 or fewer simultaneous connections (255 concurrent users are supported). This capability is often a good fit for department solutions. If using an Access database solution in a multi-user scenario, the application should be "split". This means that the tables are in one file called the back end (typically stored on a shared network folder) and the application components (forms, reports, queries, code, macros, linked tables) are in another file called the front end. The linked tables in the front end point to the back end file. Each user of the Access application would then receive his or her own copy of the front end file.
Applications that run complex queries or analysis across large datasets would naturally require greater bandwidth and memory. Microsoft Access is designed to scale to support more data and users by linking to multiple Access databases or using a back-end database like Microsoft SQL Server. With the latter design, the amount of data and users can scale to enterprise-level solutions.
Microsoft Access's role in web development prior to version 2010 is limited. User interface features of Access, such as forms and reports, only work in Windows. In versions 2000 through 2003 an Access object type called Data Access Pages created publishable web pages. Data Access Pages are no longer supported. The Microsoft Jet Database Engine, core to Access, can be accessed through technologies such as ODBC or OLE DB. The data (i.e., tables and queries) can be accessed by web-based applications developed in ASP.NET, PHP, or Java. With the use of Microsoft's Terminal Services and Remote Desktop Application in Windows Server 2008 R2, organizations can host Access applications so they can be run over the web. This technique does not scale the way a web application would but is appropriate for a limited number of users depending on the configuration of the host.
Access 2010 allows databases to be published to SharePoint 2010 web sites running Access Services. These web-based forms and reports run in any modern web browser. The resulting web forms and reports, when accessed via a web browser, don't require any add-ins or extensions (e.g. ActiveX, Silverlight).
Access 2013 can create web applications directly in SharePoint 2013 sites running Access Services. Access 2013 web solutions store its data in an underlying SQL Server database which is much more scalable and robust than the Access 2010 version which used SharePoint lists to store its data.
A compiled version of an Access database (File extensions: .MDE /ACCDE or .ADE; ACCDE only works with Access 2007 or later) can be created to prevent user from accessing the design surfaces to modify module code, forms, and reports. An MDE or ADE file is a Microsoft Access database file with all modules compiled and all editable source code removed. Both the .MDE and .ADE versions of an Access database are used when end-user modifications are not allowed or when the application’s source code should be kept confidential.
Microsoft also offers developer extensions for download to help distribute Access 2007 applications, create database templates, and integrate source code control with Microsoft Visual SourceSafe.
Features.
Users can create tables, queries, forms and reports, and connect them together with macros. Advanced users can use VBA to write rich solutions with advanced data manipulation and user control. Access also has report creation features that can work with any data source that Access can access.
The original concept of Access was for end users to be able to access data from any source. Other features include: the import and export of data to many formats including Excel, Outlook, ASCII, dBase, Paradox, FoxPro, SQL Server and Oracle. It also has the ability to link to data in its existing location and use it for viewing, querying, editing, and reporting. This allows the existing data to change while ensuring that Access uses the latest data. It can perform heterogeneous joins between data sets stored across different platforms. Access is often used by people downloading data from enterprise level databases for manipulation, analysis, and reporting locally.
There is also the Jet Database format (MDB or ACCDB in Access 2007) which can contain the application and data in one file. This makes it very convenient to distribute the entire application to another user, who can run it in disconnected environments.
One of the benefits of Access from a programmer's perspective is its relative compatibility with SQL (structured query language) — queries can be viewed graphically or edited as SQL statements, and SQL statements can be used directly in Macros and VBA Modules to manipulate Access tables. Users can mix and use both VBA and "Macros" for programming forms and logic and offers object-oriented possibilities. VBA can also be included in queries.
Microsoft Access offers parameterized queries. These queries and Access tables can be referenced from other programs like VB6 and .NET through DAO or ADO. From Microsoft Access, VBA can reference parameterized stored procedures via ADO.
The desktop editions of Microsoft SQL Server can be used with Access as an alternative to the Jet Database Engine. This support started with MSDE (Microsoft SQL Server Desktop Engine), a scaled down version of Microsoft SQL Server 2000, and continues with the SQL Server Express versions of SQL Server 2005 and 2008.
Microsoft Access is a file server-based database. Unlike client–server relational database management systems (RDBMS), Microsoft Access does not implement database triggers, stored procedures, or transaction logging. Access 2010 includes table-level triggers and stored procedures built into the ACE data engine. Thus a Client-server database system is not a requirement for using stored procedures or table triggers with Access 2010.
Tables, queries, forms, reports and macros can now be developed specifically for web base application in Access 2010. Integration with Microsoft SharePoint 2010 is also highly improved.
Access Services and Web database.
ASP.NET web forms can query a Microsoft Access database, retrieve records and display them on the browser.
SharePoint Server 2010 via Access Services allows for Access 2010 databases to be published to SharePoint, thus enabling multiple users to interact with the database application from any standards-compliant Web browser. Access Web databases published to SharePoint Server can use standard objects such as tables, queries, forms, macros, and reports. Access Services stores those objects in SharePoint.
Access 2013 offers the ability to publish Access web solutions on SharePoint 2013. Rather than using SharePoint lists as its data source, Access 2013 uses an actual SQL Server database hosted by SharePoint or SQL Azure. This offers a true relational database with referential integrity, scalability, maintainability, and extensibility compared to the SharePoint views Access 2010 used.. The macro language is enhanced to support more sophisticated programming logic and database level automation.
Import or Link sources.
Microsoft Access can also import or link directly to data stored in other applications and databases. Microsoft Office Access 2007 and newer can import from or link to:
Microsoft Access Runtime.
Microsoft offers free runtime versions of Microsoft Access: Access 2013 Runtime, Access 2010 Runtime, Access 2007 Runtime, which allow users to run an Access desktop application without needing to purchase or install a full version of Microsoft Access. This allows Access developers to create databases that can be freely distributed to an unlimited number of end-users. The runtime version allows users to view, edit and delete data, along with running queries, forms, reports, macros and VBA module code. But the runtime version does not allow users to change the design of Microsoft Access objects or code. The runtime versions are similar to their corresponding full version of Access and usually compatible with earlier versions; for example Access Runtime 2010 allows a user to run an Access application made with the 2010 version as well as 2007 through 2000. Due to deprecated features in Access 2013, its runtime version is also unable to support those older features.
Development.
Access stores all database tables, queries, forms, reports, macros, and modules in the Access Jet database as a single file.
For query development, Access offers a "Query Designer", a graphical user interface that allows users to build queries without knowledge of structured query language. In the Query Designer, users can "show" the datasources of the query (which can be tables or queries) and select the fields they want returned by clicking and dragging them into the grid. One can set up joins by clicking and dragging fields in tables to fields in other tables. Access allows users to view and manipulate the SQL code if desired. Any Access table, including linked tables from different data sources, can be used in a query.
Access also supports the creation of "pass-through queries". These snippets of SQL code can address external data sources through the use of ODBC connections on the local machine. This enables users to interact with data stored outside the Access program without using linked tables or Jet.
Users construct the pass-through queries using the SQL syntax supported by the external data source.
When developing reports (in "Design View") additions or changes to controls cause any linked queries to execute in the background and the designer is forced to wait for records to be returned before being able to make another change. This feature cannot be turned off.
Non-programmers can use the macro feature to automate simple tasks through a series of drop-down selections. Macros allow users to easily chain commands together such as running queries, importing or exporting data, opening and closing forms, previewing and printing reports, etc. Macros support basic logic (IF-conditions) and the ability to call other macros. Macros can also contain sub-macros which are similar to subroutines. In Access 2007, enhanced macros included error-handling and support for temporary variables. Access 2007 also introduced embedded macros that are essentially properties of an object's event. This eliminated the need to store macros as individual objects. However, macros were limited in their functionality by a lack of programming loops and advanced coding logic until Access 2013. With significant further enhancements introduced in Access 2013, the capabilities of macros became fully comparable to VBA. They made feature rich web-based application deployments practical, via a greatly enhanced Microsoft SharePoint interface and tools, as well as on traditional Windows desktops.
In common with other products in the Microsoft Office suite, the other programming language used in Access is Microsoft VBA. It is similar to Visual Basic 6.0 (VB6) and code can be stored in modules, classes, and code behind forms and reports. To create a richer, more efficient and maintainable finished product with good error handling, most professional Access applications are developed using the VBA programming language rather than macros, except where web deployment is a business requirement.
To manipulate data in tables and queries in VBA or macros, Microsoft provides two database access libraries of COM components:
As well as DAO and ADO, developers can also use OLE DB and ODBC for developing native C/C++ programs for Access. For ADPs and the direct manipulation of SQL Server data, ADO is required. DAO is most appropriate for managing data in Access/Jet databases, and the only way to manipulate the complex field types in ACCDB tables.
In the database container or navigation pane in Access 2007 and later versions, the system automatically categorizes each object by type (e.g., table, query, macro). Many Access developers use the Leszynski naming convention, though this is not universal; it is a programming convention, not a DBMS-enforced rule. It is particularly helpful in VBA where references to object names may not indicate its data type (e.g. tbl for tables, qry for queries).
Developers deploy Microsoft Access most often for individual and workgroup projects (the Access 97 speed characterization was done for 32 users). Since Access 97, and with Access 2003 and 2007, Microsoft Access and hardware have evolved significantly. Databases under 1 GB in size (which can now fit entirely in RAM) and 200 simultaneous users are well within the capabilities of Microsoft Access. Of course, performance depends on the database design and tasks. Disk-intensive work such as complex searching and querying take the most time.
As data from a Microsoft Access database can be cached in RAM, processing speed may substantially improve when there is only a single user or if the data is not changing. In the past, the effect of packet latency on the record-locking system caused Access databases to run slowly on a Virtual Private Network (VPN) or a Wide Area Network (WAN) against a Jet database. broadband connections have mitigated this issue. Performance can also be enhanced if a continuous connection is maintained to the back-end database throughout the session rather than opening and closing it for each table access. If Access database performance over VPN or WAN suffers, then a client using Remote Desktop Protocol (such as Microsoft Terminal Services) can provide an effective solution. Access databases linked to SQL Server or to Access Data Projects work well over VPNs and WANs.
In July 2011, Microsoft acknowledged an intermittent query performance problem with all versions of Access and Windows 7 and Windows Server 2008 R2 due to the nature of resource management being vastly different in newer operating systems. This issue severely affects query performance on both Access 2003 and earlier with the Jet Database Engine code, as well as Access 2007 and later with the Access Database Engine (ACE). Microsoft has issued hotfixes KB2553029 for Access 2007 and KB2553116 for Access 2010, but will not fix the issue with Jet 4.0 as it is out of mainstream support.
In earlier versions of Microsoft Access, the ability to distribute applications required the purchase of the Developer Toolkit; in Access 2007, 2010 and Access 2013 the "Runtime Only" version is offered as a free download, making the distribution of royalty-free applications possible on Windows XP, Vista, 7 and Windows 8.x.
Split database architecture.
Microsoft Access applications can adopt a split-database architecture. The single database can be divided into a separate "back-end" file that contains the data tables (shared on a file server) and a "front-end" (containing the application's objects such as queries, forms, reports, macros, and modules). The "front-end" Access application is distributed to each user's desktop and linked to the shared database. Using this approach, each user has a copy of Microsoft Access (or the runtime version) installed on their machine along with their application database. This reduces network traffic since the application is not retrieved for each use. The "front-end" database can still contain local tables for storing a user's settings or temporary data. This split-database design also allows development of the application independent of the data. One disadvantage is that users may make various changes to their own local copy of the application and this makes it hard to manage version control. When a new version is ready, the front-end database is replaced without impacting the data database. Microsoft Access has two built-in utilities, Database Splitter and Linked Table Manager, to facilitate this architecture.
Linked tables in Access use absolute paths rather than relative paths, so the development environment either has to have the same path as the production environment or a "dynamic-linker" routine can be written in VBA.
For very large Access databases, this may have performance issues and a SQL backend should be considered in these circumstances. This is less of an issue if the entire database can fit in the PC's RAM since Access caches data and indexes.
Migration to SQL Server.
To scale Access applications to enterprise or web solutions, one possible technique involves migrating to Microsoft SQL Server or equivalent server database. A client–server design significantly reduces maintenance and increases security, availability, stability, and transaction logging.
Access 2010 included a feature called the Upsizing Wizard that allowed users to upgrade their databases to Microsoft SQL Server, an ODBC client–server database. This feature was removed from Access 2013. An additional solution, the SQL Server Migration Assistant for Access (SSMA), continues to be available for free download from Microsoft.
A variety of upgrading options are available. After migrating the data and queries to SQL Server, the Access database can be linked to the SQL database. However, certain data types are problematic, most notably "Yes/No". In Microsoft Access there are three states for the Yes/No (True/False) data type: empty, no/false (zero) and yes/true (-1). The corresponding SQL Server data type is binary, with only two states, permissible values, zero and 1. Regardless, SQL Server is still the easiest migration, and most appropriate especially if the user does not have rights to create objects such as stored procedures on SQL Server. Retrieving data from linked tables is optimized to just the records needed, but this scenario may operate less efficiently than what would otherwise be optimal for SQL Server. For example, in instances where multi-table joins still require copying the whole table across the network.
In previous versions of Access, including Access 2010, databases can also be converted to Access Data Projects (ADP) which are tied directly to one SQL Server database. This feature was removed from Access 2013. ADP's support the ability to directly create and modify SQL Server objects such as tables, views, stored procedures, and SQL Server constraints. The views and stored procedures can significantly reduce the network traffic for multi-table joins. Fortunately, SQL Server supports temporary tables and links to other data sources beyond the single SQL Server database.
Finally, some Access databases are completely replaced by another technology such as ASP.NET or Java once the data is converted. However any migration may dictate major effort since the Access SQL language is a more powerful superset of standard SQL. Further, Access application procedures, whether VBA and macros, are written at a relatively higher level versus the currently available alternatives that are both robust and comprehensive. Note that the Access macro language, allowing an even higher level of abstraction than VBA, was significantly enhanced in Access 2010 and again in Access 2013.
In many cases, developers build direct web-to-data interfaces using ASP.NET, while keeping major business automation processes, administrative and reporting functions that don't need to be distributed to everyone in Access for information workers to maintain.
While all Access data can migrate to SQL Server directly, some queries cannot migrate successfully. In some situations, you may need to translate VBA functions and user defined functions into T–SQL or .NET functions / procedures. Crosstab queries can be migrated to SQL Server using the PIVOT command.
Protection.
Microsoft Access offers several ways to secure the application while allowing users to remain productive.
The most basic is a database password. Once entered, the user has full control of all the database objects. This is a relatively weak form of protection which can be easily cracked.
A higher level of protection is the use of workgroup security requiring a user name and password. Users and groups can be specified along with their rights at the object type or individual object level. This can be used to specify people with read-only or data entry rights but may be challenging to specify. A separate workgroup security file contains the settings which can be used to manage multiple databases. Workgroup security is not supported in the Access 2007 and Access 2010 ACCDB database format, although Access 2007 and Access 2010 still support it for MDB databases.
Databases can also be encrypted. The ACCDB format offers significantly advanced encryption from previous versions.
Additionally, if the database design needs to be secured to prevent changes, Access databases can be locked/protected (and the source code compiled) by converting the database to a .MDE file. All changes to the VBA project (modules, forms, or reports) need to be made to the original MDB and then reconverted to MDE. In Access 2007 and Access 2010, the ACCDB database is converted to an ACCDE file. Some tools are available for unlocking and "decompiling", although certain elements including original VBA comments and formatting are normally irretrievable.
File extensions.
Microsoft Access saves information under the following file formats:
Versions.
For a detailed list of updates within versions and download links: Microsoft Access Version Releases, Service Packs, Hotfixes, and Updates History

</doc>
<doc id="20941" url="https://en.wikipedia.org/wiki?curid=20941" title="Metabolic pathway">
Metabolic pathway

In biochemistry, a metabolic pathway is a series of chemical reactions occurring within a cell. The reactants, products, and intermediates of an enzymatic reaction are known as metabolites. In a pathway, the reactant is modified by a sequence of chemical reactions. These reactions are catalyzed by enzymes, where the product of one enzyme acts as the substrate for the next. These enzymes often require dietary minerals, vitamins, and other cofactors to function.
Different metabolic pathways function based on the position within a eukaryotic cell and the significance of the pathway in the given compartment of the cell. For instance, the citric acid cycle, electron transport chain, and oxidative phosphorylation all take place in the mitochondrial membrane. In contrast, glycolysis, pentose phosphate pathway, and fatty acid biosynthesis all occur in the cytosol of a cell.
Pathways are required for the maintenance of homeostasis within an organism and the flux of metabolites through a pathway is regulated depending on the needs of the cell and the availability of the substrate. The end product of a pathway may be used immediately, initiate another metabolic pathway or be stored for later use. The metabolism of a cell consists of an elaborate network of interconnected pathways that enable the synthesis and breakdown of molecules (anabolism and catabolism)
Overview.
Each metabolic pathway consists of a series of biochemical reactions that are connected by their intermediates: the products of one reaction are the substrates for subsequent reactions, and so on. Metabolic pathways are often considered to flow in one direction. Although all chemical reactions are technically reversible, conditions in the cell are often such that it is thermodynamically more favorable for flux to flow in one direction of a reaction. For example, one pathway may be responsible for the synthesis of a particular amino acid, but the breakdown of that amino acid may occur via a separate and distinct pathway. One example of an exception to this "rule" is the metabolism of glucose. Glycolysis results in the breakdown of glucose, but several reactions in the glycolysis pathway are reversible and participate in the re-synthesis of glucose (gluconeogenesis).
Major metabolic pathways.
Cellular respiration.
A core set of energy-producing catabolic pathways occur within all living organisms in some form. These pathways transfer the energy released by breakdown of nutrients into ATP and other small molecules used for energy (e.g. GTP, NADPH, FADH). All cells can perform anaerobic respiration by glycolysis. Additionally, most organisms can perform more efficient aerobic respiration through the citric acid cycle and oxidative phosphorylation. Additionally plants, algae and cyanobacteria are able to use sunlight to anabolically synthesise compounds from non-living matter by photosynthesis.

</doc>
<doc id="20942" url="https://en.wikipedia.org/wiki?curid=20942" title="Malthusian catastrophe">
Malthusian catastrophe

A Malthusian catastrophe (also known as Malthusian check) is a prediction of a forced return to subsistence-level conditions once population growth has outpaced agricultural production. 
Thomas Malthus.
In 1779, Thomas Malthus wrote:
Notwithstanding the apocalyptic image conveyed by this particular paragraph, Malthus himself did not subscribe to the notion that mankind was fated for a "catastrophe" due to population overshooting resources. Rather, he believed that population growth was generally restricted by available resources:
Neo-Malthusian theory.
After World War II, mechanized agriculture produced a dramatic increase in productivity of agriculture and the Green Revolution greatly increased crop yields, expanding the world's food supply while lowering food prices. In response, the growth rate of the world's population accelerated rapidly, resulting in predictions by Paul R. Ehrlich, Simon Hopkins, and many others of an imminent Malthusian catastrophe. However, populations of most developed countries grew slowly enough to be outpaced by gains in productivity.
By the early 21st century, many technologically developed countries had passed through the demographic transition, a complex social development encompassing a drop in total fertility rates in response to various fertility factors, including lower infant mortality, increased urbanization, and a wider availability of effective birth control. 
On the assumption that the demographic transition is now spreading from the developed countries to less developed countries, the United Nations Population Fund estimates that human population may peak in the late 21st century rather than continue to grow until it has exhausted available resources. 
Historians have estimated the total human population back to 10,000 BC. The figure on the right shows the trend of total population from 1800 to 2005, and from there in three projections out to 2100 (low, medium, and high). The graph of annual growth rates (at the top of the page) shows the annual growth rate over the same period. If population growth were exactly exponential, then the growth rate would be a flat line. The fact that it was increasing from 1920 to 1960 indicates faster-than-exponential growth over this period. However, the growth rate has been decreasing since then, and is projected to continue decreasing. The United Nations population projections out to 2100 (the red, orange, and green lines) show a possible peak in the world's population occurring by 2040 in the first scenario, and by 2100 in the second scenario, and never ending growth in the third. 
The graph of annual growth rates (at the top of the page) does not appear exactly as one would expect for long-term exponential growth. For exponential growth it should be a straight line at constant height, whereas in fact the graph from 1800 to 2005 is dominated by an enormous hump that began about 1920, peaked in the mid-1960s, and has been steadily eroding away for the last 40 years. The sharp fluctuation between 1959 and 1960 was due to the combined effects of the Great Leap Forward and a natural disaster in China. Also visible on this graph are the effects of the Great Depression, the two world wars, and possibly also the 1918 flu pandemic.
Though short-term trends, even on the scale of decades or centuries, cannot prove or disprove the existence of mechanisms promoting a Malthusian catastrophe over longer periods, the prosperity of a major fraction of the human population at the beginning of the 21st century, and the debatability of ecological collapse made by Paul R. Ehrlich in the 1960s and 1970s, has led some people, such as economist Julian L. Simon, to question its inevitability.
A 2004 study by a group of prominent economists and ecologists, including Kenneth Arrow and Paul Ehrlich suggests that the central concerns regarding sustainability have shifted from population growth to the consumption/savings ratio, due to shifts in population growth rates since the 1970s. Empirical estimates show that public policy (taxes or the establishment of more complete property rights) can promote more efficient consumption and investment that are sustainable in an ecological sense; that is, given the current (relatively low) population growth rate, the Malthusian catastrophe can be avoided by either a shift in consumer preferences or public policy that induces a similar shift. 
However, some contend that the Malthusian catastrophe is not imminent. A 2002 study by the UN Food and Agriculture Organization predicts that world food production will be in excess of the needs of the human population by the year 2030; however, that source also states that hundreds of millions will remain hungry (presumably due to economic realities and political issues).
Criticism.
Ester Boserup wrote in her book "The Conditions of Agricultural Growth: The Economics of Agrarian Change under Population Pressure", that population levels determine agricultural methods, rather than agricultural methods determining population (via food supply). A major point of her book is that "necessity is the mother of invention." Julian Simon was one of many economists who challenged the Malthusian catastrophe, citing (1) the existence of new knowledge, and educated people to take advantage of it, and (2) "economic freedom", that is, the ability of the world to increase production when there is a profitable opportunity to do so. 
The economist Henry George argued that Malthus didn't provide any evidence of a natural tendency for a population to overwhelm its ability to provide for itself. George wrote that even the main body of Malthus' work refuted this theory; that examples given show social causes for misery, such as "ignorance and greed... bad government, unjust laws, or war," rather than insufficient food production.
Friedrich Engels also criticizes the Malthusian catastrophe because Malthus failed to see that surplus population is connected to surplus wealth, surplus capital, and surplus landed property. Population is large where the overall productive power is large. Engels also states that the calculation that Malthus made with the difference in population and productive power is incorrect because Malthus does not take into consideration a third element, science. Scientific “progress is as unlimited and at least as rapid as that of population”. On the other hand, Joseph Tainter argues that science has diminishing marginal returns and scientific progress is becoming more difficult, harder to achieve and more costly.

</doc>
<doc id="20943" url="https://en.wikipedia.org/wiki?curid=20943" title="Millennialism">
Millennialism

Millennialism (from millennium, Latin for "thousand years"), or chiliasm in Greek, is a belief held by some Christian denominations that there will be a Golden Age or Paradise on Earth in which "Christ will reign" for 1000 years prior to the final judgment and future eternal state (the "World to Come" of the "New Heavens" and "New Earth"). This belief is derived primarily from . Millennialism is a specific form of millenarianism.
Similarities to millennialism are found in Zoroastrianism. It held that there were successive thousand-year periods, each of which will end in a cataclysm of heresy and destruction, until the final destruction of evil and of the spirit of evil by a triumphant king of peace at the end of the final millennial age (supposed by some to be the year 2000). "Then Saoshyant makes the creatures again pure, and the resurrection and future existence occur" ("Zand-i Vohuman Yasht 3:62").
Various other social and political movements, both religious and secular, have also been linked to millennialist metaphors by scholars.
Christianity.
Early church.
During the first centuries after Christ, various forms of chiliasm (millennialism) were to be found in the Church, both East and West. It was a decidedly majority view at that time, as admitted by Eusebius, himself an opponent of the doctrine History of the Church, Book 3:39. Nevertheless, strong opposition later developed from some quarters, most notably from Augustine of Hippo. The Church never took a formal position on the issue at any of the ecumenical councils, and thus both pro and con positions remained consistent with orthodoxy. It is sometimes mistakenly claimed that Millennialism was repudiated as a heresy in A.D. 381 at the First Council of Constantinople with its addition of the phrase "whose kingdom shall have no end" to the Nicene Creed, in order to rule out the idea of a Kingdom of God which would last for only 1000 literal years. However, a reading of the canons of the council reveals no mention of millennialism, much less any repudiation, and the doctrine is itself consistent with there being no end to Christ's kingdom since millennialism, while focusing on a particular 1000-year period, does not contemplate a terminus ad quem to the kingdom. Rather, the doctrine holds that after 1000 years of Christ's reign there will be an unsuccessful rebellion on the part of Satan and his allies, a rebellion which will be decisively defeated. Since an unsuccessful revolt does not put an end to any kingdom, the specious reasoning employed by the above noted opponents of millennialism is considered apparent. The addition to the Nicene Creed was, rather, intended to refute the perceived Sabellianism of Marcellus of Ancyra and others, a doctrine which does in fact include an end to Christ's reign and which is explicitly singled out for condemnation by the council #1. The Catholic Encyclopedia notes that the 2nd century proponents of various Gnostic beliefs (themselves considered heresies) also rejected millenarianism.
Millennialism was taught by various earlier writers such as Tertullian, Commodian, Lactantius, Methodius, and Apollinaris of Laodicea in a form now called premillennialism. According to religious scholar Rev. Dr. Francis Nigel Lee, "Justin's 'Occasional Chiliasm' sui generis which was strongly anti-pretribulationistic was followed possibly by Pothinus in A.D. 175 and more probably (around 185) by Irenaeus". Justin Martyr, discussing his own premillennial beliefs in his "Dialogue with Trypho the Jew", Chapter 110, observed that they were not necessary to Christians:
Melito of Sardis is frequently listed as a second century proponent of premillennialism. The support usually given for the supposition is that Jerome on Ezek. 36 and Gennadius Dogm. Eccl., Ch. 52 both affirm that he was a decided millenarian.”
In the early third century, Hippolytus of Rome wrote:
Around 220, there were some similar influences on Tertullian, although only with very important and extremely optimistic (if not perhaps even postmillennial) modifications and implications. On the other hand, 'Christian Chiliastic' ideas were indeed advocated in 240 by Commodian; in 250 by the Egyptian Bishop Nepos in his Refutation of Allegorists; in 260 by the almost unknown Coracion; and in 310 by Lactantius. Into the late fourth century, Bishop Ambrose of Milan had millennial leanings (Ambrose of Milan. Book II. On the Belief in the Resurrection, verse 108).
In a letter to Queen Gerberga of France around 950, Adso of Montier-en-Der established the idea of a "last World Emperor" who would conquer non-Christians before the arrival of the Antichrist.
Reformation and beyond.
Christian views on the future order of events diversified after the Protestant reformation (c.1517). In particular, new emphasis was placed on the passages in the Book of Revelation which seemed to say that as Christ would return to judge the living and the dead, Satan would be locked away for 1000 years, but then released on the world to instigate a final battle against God and his Saints (Rev. 20:1–6). Previous Catholic and Orthodox theologians had no clear or consensus view on what this actually meant (only the concept of the end of the world coming unexpectedly, "like a thief in a night", and the concept of "the antichrist" were almost universally held). Millennialist theories try to explain what this "1000 years of Satan bound in chains" would be like.
Various types of millennialism exist with regard to Christian eschatology, especially within Protestantism, such as Premillennialism, Postmillennialism, and Amillennialism. The first two refer to different views of the relationship between the "millennial Kingdom" and Christ's second coming. Premillennialism sees Christ's second advent as preceding the millennium, thereby separating the second coming from the final judgment. In this view, "Christ's reign" will be physically on the earth. Postmillennialism sees Christ's second coming as subsequent to the millennium and concurrent with the final judgment. In this view "Christ's reign" (during the millennium) will be spiritual in and through the church. Amillennialism basically denies a future literal 1000 year kingdom and sees the church age metaphorically described in Rev. 20:1–6 in which "Christ's reign" is current in and through the church.
The Catholic Church strongly condemns millennialism as the following shows:
A millennium is a period of one thousand years, and, in particular, Christ's thousand-year rule on this earth, either directly preceding or immediately following the Second Coming (and the Day of Judgment).
The millennium reverses the previous period of evil and suffering; it rewards the virtuous for their courage while punishing the evil-doers with a clear separation of saints and sinners. The vision of a thousand-year period of bliss for the faithful to be enjoyed here on earth ("heaven on earth"), exerted an irresistible power. Although the picture of life in the millennial era is almost willfully obscure and hardly more appealing than that of, say, the Golden Age, what has made the millennium much more powerful than the Golden Age or Paradise myths are the activities of the sects and movements that it has inspired. Throughout the ages, hundreds of sects were convinced that the millennium was imminent, about to begin in the very near future, with precise dates given on many occasions.
Premillennial sects look for signs of Christ's imminent return. Other chiliast sects, such as the prophetic Anabaptist followers of Thomas Müntzer, have believed that the millennium had already begun, with only their own members having realized this fact. Consequently, they have attempted to live out their own vision of millennial life, radically overturning the beliefs and practices of the surrounding society. In doing so, they offered a model of the good life and expressed their hope that soon the rest of the world would follow and live like they did.
See Christian eschatology for a discussion of "premillennialism" and "postmillennialism".
Utopianism.
The early Christian concept had ramifications far beyond strictly religious concern during the centuries to come, as it was blended and enhanced with ideas of utopia.
In the wake of early millennial thinking, the Three Ages philosophy developed. The Italian monk and theologian Joachim of Fiore (died 1202) claimed that all of human history was a succession of three ages:
It was believed that the Age of the Holy Spirit would begin at around 1260, and that from then on all believers would be living as monks, mystically transfigured and full of praise for God, for a thousand years until Judgment Day would put an end to the history of our planet.
In the Modern Era, some of the concepts of millennial thinking have found their way into various secular ideas, usually in the form of a belief that a certain historical event will fundamentally change human society (or has already done so). For example, the French Revolution seemed to many to be ushering in the millennial age of reason. Also, the philosophies of Georg Wilhelm Friedrich Hegel (1770–1831) and Karl Marx (1818–1883) carried strong millennial overtones. As late as 1970, Yale law teacher Charles A. Reich coined the term "Consciousness III" in his best seller "The Greening of America", in which he spoke of a new age ushered in by the hippie generation. However, these secular theories generally have little or nothing to do with the original millennial thinking, or with each other.
Jehovah's Witnesses.
Jehovah's Witnesses believe that Christ will rule from heaven for 1,000 years as king over the earth, assisted by 144,000 holy ones. The principal purpose of this millennial reign is to resolve the question of who legitimately deserves to be sovereign of the Earth and of the universe. It also serves to finally accomplish the Creator's original purpose of an Earth populated by a peaceful, satisfied and loving human society, descendants from the first human couple Adam and Eve. This will happen after the destruction of the wicked at Armageddon.
Armageddon will be a decisive battle between two opposing forces: on one side, Christ Jesus together with the holy angels; in opposition, human governments and institutions (manipulated by wicked spirits) insistent on maintaining control over humanity. Unlike natural or manmade catastrophes, Christ and his angels will selectively destroy those humans deemed incorrigible. Planet Earth will be rid of greed, corruption, and all individuals and institutions who impenitently ruin the earth and impose misery on others. (Rev 16:16; 1 John 5:19; Matthew 25:31–40)
Malevolent spiritual beings will be restrained and prevented from interfering in human affairs for the duration of Christ's reign. Free of untoward influences, the Witnesses see the 1,000 year reign as fulfillment of the Biblical promise of "New Heavens and a New Earth".
One aspect which differentiates Jehovah's Witnesses from other millennialists (such as Baptists, Church of God, Church of Christ, and other fundamentalist Christian groups) is the interpretation of 2 Peter 3:7, 13. Whereas the latter hold to a literal interpretation, namely that the planet Earth will be destroyed and replaced with another physical planet, Jehovah's Witnesses by contrast believe the language in 2 Peter 3:7 is figurative. Hence their understanding is that the literal planet Earth will not be destroyed but instead, the existing framework of human society, which includes greedy commerce, divisive religions and corrupt governments.
Christ's kingdom consists of those who govern (from heaven) and those who are governed (on earth). This government will accomplish in the comparatively short timespan of 1,000 years all the things human governments and institutions have promised (but failed to deliver) during thousands of years of rule, while experimenting every form of government imaginable. Jesus Christ, the Messiah, will be the 'head of state', or King officially designated by God. In turn, he will delegate authority to 144,000 select individuals, individually chosen by Jehovah from among humanity. Those chosen have already proven their complete allegiance to Jehovah God and to His legitimate right to govern. The first to be promised this privilege were the faithful apostles of Jesus Christ in the 1st century C.E. The rulers will be loving and fair, always intent on the common good of everyone.
On the earth, those who are kept safe through that 'great tribulation' (Matt 24:21; Rev 7:9) and the subsequent destruction of the world ruled by Satan the Devil will be ushered into a just, peaceful, and equitable earthwide society of humans. During the millennium, Christ will use his power to cure every sort of sickness (Rev 22:17), malady, and infirmity. Ultimately everyone who accepts living by Jehovah God's righteous standards (Exodus 20:1–17) will attain perfect health. Guided by the heavenly government, humans will work to progressively establish an earthwide paradise (Matt 19:27,28). Hunger and poverty will be completely eliminated (Rev 21:1–5).
Humans who died during all prior human history (but who were not deemed incorrigible) will be resurrected (or recreated) on the earth during the 1,000 years. These will have the opportunity to fully integrate into society (Isaiah 65:17).
At the culmination of the millennium, Christ will cede control of planet Earth to his Father Jehovah (1 Cor 15:28) and will himself acknowledge and accept Jehovah's right to rule (or sovereignty). The restraints on wicked spirit creatures will be removed and all humanity will face a test. With full understanding, each human must individually choose whether to accept or reject God's right to rule, his sovereignty. Those humans and (previously restrained) spirit creatures who reject rule by Jehovah God, showing themselves to be menaces to human society and the remainder of the universe, will be completely and permanently eliminated. For any of these who may have been resurrected, this will literally be a "second" death. Thereafter, obedient humankind will live forever on the earth and Jehovah God's original purpose for the earth will be accomplished. (Gen 1:28)
Nazism.
The most controversial interpretation of the Three Ages philosophy and of millennialism in general is Adolf Hitler's "Third Reich" (""Drittes Reich""), which in his vision would last for a thousand years to come (""Tausendjähriges Reich""), but which ultimately only lasted for 12 years (1933–1945).
The phrase "Third Reich" was originally coined by the German thinker Arthur Moeller van den Bruck, who in 1923 published a book titled "Das Dritte Reich". Looking back at German history, he distinguished two separate periods, and identified them with the ages of Joachim of Fiore:
After the interval of the Weimar Republic (1918–1933), during which constitutionalism, parliamentarism and even pacifism ruled, these were then to be followed by:
Although van den Bruck was unimpressed by Hitler when he met him in 1922 and did not join the Nazi Party, the phrase was nevertheless adopted by the Nazis to describe the totalitarian state they wanted to set up when they gained power, which they succeeded in doing in 1933. Later, however, the Nazi authorities banned the informal use of "Third Reich" throughout the German press in the summer of 1939, instructing it to use more official terms such as "German Reich", "Greater German Reich", and "National Socialist Germany" exclusively.
During the early part of the Third Reich many Germans also referred to Hitler as being the "German Messiah", especially when he conducted the Nuremberg Rallies, which came to be held at a date somewhat before the Autumn Equinox in Nuremberg, Germany.
In a speech held on 27 November 1937, Hitler commented on his plans to have major parts of Berlin torn down and rebuilt:
After Adolf Hitler's unsuccessful attempt to implement a thousand-year-reign, the Vatican issued an official statement that millennial claims could not be safely taught and that the related scriptures in Revelation (also called the Apocalypse) should be understood spiritually. Catholic author Bernard LeFrois wrote:
Theosophy.
The Theosophist Alice Bailey taught that Christ (in her books she refers to the powerful spiritual being best known by Theosophists as "Maitreya" as "The Christ" or "The World Teacher", not as "Maitreya") would return “sometime after AD 2025”, and that this would be the New Age equivalent of the Christian concept of the Second Coming of Christ.
Bailey stated that St. Germain (referred to by Bailey in her books as "The Master Rakoczi" or "The Master R.") is the manager of the executive council of the Christ. According to Bailey, when Christ returns he will stay the entire approximately 2,000 years period of the Age of Aquarius and thus the New Age equivalent of the Millennial Age, when Maitreya will reign as the spiritual leader of Earth as the Messiah who will bring world peace, will not be just a single millennium but will be the Aquarian bimillennium.
Social movements.
Millennial social movements are a specific form of millenarianism that are based on some concept of a one thousand-year cycle. Sometimes the two terms are used as synonyms, but this is not entirely accurate for a purist. Millennial social movements need not be religious, but they must have a vision of an apocalypse that can be utopian or dystopian.

</doc>
<doc id="20945" url="https://en.wikipedia.org/wiki?curid=20945" title="Might and Magic">
Might and Magic

Might and Magic is a series of role-playing video games from New World Computing, which in 1996 became a subsidiary of The 3DO Company. The producer of the series was Jon Van Caneghem.
"Might and Magic" is considered one of the defining examples of early PC role-playing games, along with the "The Bard's Tale", "Ultima" and "Wizardry" series.
The original "Might and Magic" series ended with the closure of the 3DO Company. The rights to the "Might and Magic" name were purchased for USD 1.3 million by Ubisoft, who "rebooted" the franchise with a new series with no apparent connection to the previous continuity, starting with the games "Heroes of Might and Magic V" and "Dark Messiah of Might and Magic".
History.
There are ten games in the series:
Anthologies.
There were several spin-offs from the main series, including "Heroes of Might and Magic", "Crusaders of Might and Magic", "Warriors of Might and Magic", "Legends of Might and Magic", and the fanmade "Swords of Xeen".
In August 2003, Ubisoft acquired the rights to the Might and Magic franchise for US$1.3 million after 3DO filed for Chapter 11 bankruptcy. Ubisoft has since released multiple new projects using the Might and Magic brand, including a fifth installment of the Heroes series, developed by Nival, an action-style game called "Dark Messiah of Might and Magic", developed by Arkane Studios and a puzzle RPG called "", developed by "Capybara Games".
In September 2009, the "Might and Magic Sixpack" was re-released via the digital distribution service, Good Old Games. In March 2011, The seventh and eighth installments of the series were also added to Good Old Games.
In March 2013, Ubisoft confirmed that Limbic Entertainment is developing "Might & Magic X Legacy" with a release date said to be in early 2014. The game is described as a solo, first-person RPG with turn-based gameplay. It takes place in the same world as "Might & Magic Heroes VI".
Gameplay.
The majority of the gameplay takes place in a medieval fantasy setting, while later sections of the games are often based on science fiction tropes, the transition often serving as a plot twist. The player controls a party of player characters, which can consist of members of various character classes. The game world is presented to the player in first person perspective. In the earlier games the interface is very similar to that of "Bard's Tale", but from "" onward, the interface features a three-dimensional environment. Combat is turn-based, though the later games allowed the player to choose to conduct combat in real time.
The game worlds in all of the Might and Magic games are quite large, and a player can expect each game to provide several dozen hours of gameplay. It is usually quite combat-intensive and often involves large groups of enemy creatures. Monsters and situations encountered throughout the series tend to be well-known fantasy staples such as giant rats, werewolf curses, dragon flights and zombie hordes, rather than original creations. "Isles of Terra" and the "Xeen" games featured a more distinct environment, blending fantasy and science fiction elements in a unique way.
Plot.
Although most of the gameplay reflects a distinctly fantasy genre, the overarching plot of the first nine games has something of a science fiction background. The series is set in a fictional galaxy as part of an alternative universe, where planets are overseen by a powerful race of space travelers known as Ancients. In each of the games, a party of characters fights monsters and completes quests on one of these planets, until they eventually become involved in the affairs of the Ancients.
Van Caneghem has stated in interview that the "Might and Magic" setting is inspired by his love for both science fiction and fantasy. He cites "The Twilight Zone" and the "Star Trek" episode "For the World is Hollow and I Have Touched the Sky" as having inspired "Might and Magic" lore.
The first five games in the series concern the renegade guardian of the planet Terra, named Sheltem, who becomes irrevocably corrupted, developing a penchant for throwing planets into their suns. Sheltem establishes himself on a series of flat worlds known as nacelles (which are implied to be giant spaceships) and Corak, a second guardian and creation of the Ancients, with the assistance of the player characters, pursues him across the Void. Eventually both Corak and Sheltem are destroyed in a climactic battle on the nacelle of Xeen.
The sixth, seventh and eighth games take place on Enroth, a single planet partially ruled by the Ironfist dynasty, and chronicle the events and aftermath of an invasion by the Kreegan (colloquially referred to as Devils), the demonlike arch-enemies of the Ancients. It is also revealed that the destruction wrought by the Ancients' wars with the Kreegan is the reason why the worlds of Might & Magic exist as medieval fantasy settings despite once being seeded with futuristic technology – the worlds have been 'cut off' from the Ancients and descended into barbarism. The first through third games in the "Heroes of Might and Magic" series traces the fortunes of the Ironfists in more detail. None of the science fiction elements appear in the "Heroes" series besides the appearance of Kreegan characters in "Heroes of Might and Magic III".
The Ubisoft release "Might & Magic X: Legacy" departs from this continuity and is set in the world of Ashan. Ashan is a high fantasy setting with no place for science fiction elements in its lore.

</doc>
<doc id="20947" url="https://en.wikipedia.org/wiki?curid=20947" title="Adobe Flash">
Adobe Flash

Adobe Flash (formerly called Macromedia Flash and Shockwave Flash) is a multimedia and software platform used for creating vector graphics, animation, browser games, rich Internet applications, desktop applications, mobile applications and mobile games. Flash displays text, vector and raster graphics to provide animations, video games and applications. It allows streaming of audio and video, and can capture mouse, keyboard, microphone and camera input.
Flash graphics and animation are designed using a variety of Flash editing software, such as Adobe Flash Builder, Adobe Animate, FlashDevelop, or any text editor when used with the Apache Flex SDK. Content may be viewed by end-users using Flash Player (for web browsers), AIR (for desktop or mobile apps) or third-party players such as Scaleform GFx (for video games). Adobe Flash Player enables end-users to view Flash content using web browsers, and is supported on Microsoft Windows, Mac OS X and Linux. Adobe Flash Lite enabled viewing Flash content on older smartphones, but has been discontinued and superseded by Adobe AIR.
The ActionScript programming language allows creation of interactive animations, video games, web applications, desktop applications and mobile applications. Flash software can be developed using an IDE such as Adobe Animate, Adobe Flash Builder, FlashDevelop and Powerflasher FDT. Adobe AIR enables full-featured desktop and mobile applications to be developed with Flash, and published for Microsoft Windows, Mac OS X, Google Android, and iOS.
Flash is frequently used to display streaming video, advertisement and interactive multimedia content on web pages and Flash-enabled software. However, after the 2000s, the usage of Flash on Web sites has declined; as of 2015, Flash is primarily used to build video games for mobile devices with Adobe AIR.
Applications.
Websites.
In the early 2000s,Flash was widely installed on desktop computers, and was commonly used to display interactive web pages, online games, and to playback video and audio content. In 2005, YouTube was founded by former PayPal employees, and it used Flash Player as a means to display compressed video content on the web.
Between 2000 and 2010,Swan, numerous businesses used Flash-based websites to launch new products, or to create interactive company portals. Notable users include Nike, Hewlett-Packard, Nokia, General Electric, World Wildlife Fund, HBO, Cartoon Network and Disney. After Adobe introduced hardware-accelerated 3D for Flash (Stage3D), Flash websites saw a growth of 3D content for product demonstrations and virtual tours.
In 2007, YouTube offered videos in HTML5 format to support the iPhone and iPad, which did not support Flash Player. After a controversy with Apple, Adobe stopped developing Flash Player for Mobile, focussing its efforts on Adobe AIR applications and HTML5 animation. In 2015, Google introduced Google Swiffy to convert Flash animation to HTML5, a tool Google would use to automatically convert Flash web ads for mobile devices. In 2015, YouTube switched to HTML5 technology on all devices, however it will preserve the Flash-based video player for older web browsers.
RIAs.
After Flash 5 introduced ActionScript in 2000, developers combined the visual and programming capabilities of Flash to produce interactive experiences and applications for the Web. Such Web-based applications eventually came to be known as "Rich Internet Applications" (RIAs).
In 2004, Macromedia Flex was released, and specifically targeted the application development market. Flex introduced new user interface components, advanced data visualization components, data remoting, and a modern IDE (Flash Builder). Flex competed with Asynchronous JavaScript and XML (AJAX) and Microsoft Silverlight during its tenure. Flex was upgraded to support integration with remote data sources, using AMF, BlazeDS, Adobe LiveCycle, Amazon Elastic Compute Cloud, and others. As of 2015, Flex applications can be published for desktop platforms using Adobe AIR.
As of 2015, Web applications and RIAs can be developed with Flash using the ActionScript 3.0 programming language and related tools such as Adobe Flash Builder. Third-party IDEs such as FlashDevelop and Powerflasher FDT also enable developers to create Flash games and applications, and are generally similar to Microsoft Visual Studio. Flex applications are typically built using Flex frameworks such as PureMVC.
Video games.
Flash video games are popular on the Internet, with portals like Newgrounds dedicated to hosting of Flash-based games. Popular games developed with Flash include "Angry Birds", "FarmVille", "AdventureQuest" and "Machinarium".
Adobe introduced various technologies to help build video games, including Adobe AIR (to release games for desktop or mobile platforms), Adobe Scout (to improve performance), CrossBridge (to convert C++-based games to run in Flash), and Stage3D (to support GPU-accelerated video games). 3D frameworks like Away3D and Flare3D simplified creation of 3D content for Flash.
Adobe AIR allows creation of Flash-based mobile games, which may be published to the Google Play and iTunes app stores.
Flash is also used to build interfaces and HUDs for 3D video games using Scaleform GFx, a technology that renders Flash content within non-Flash video games. Scaleform is supported by more than 10 major video game engines including Unreal Engine, UDK, CryEngine and PhyreEngine, and has been used to provide 3D interfaces for more than 150 major video game titles since its launch in 2003.
Film and animation.
Adobe Animate is one of the common animation programs for low-cost 2D television and commercial animation, in competition with Anime Studio and Toon Boom Animation.
Notable users of Flash include DHX Media Vancouver for productions including "Pound Puppies" and ', Fresh TV for Total Drama, Nelvana for "6teen" and "Clone High", Williams Street for "Metalocalypse" and "Squidbillies", Nickelodeon Animation Studios for "Wow! Wow! Wubbzy!" ', "Danny Phantom" and "Happy Tree Friends", and more.
Flash is less commonly used for feature-length animated films; however, 2009's "The Secret of Kells", an Irish film, was animated primarily in Adobe Flash, and was nominated for an Academy Award for Best Animated Feature at the 82nd Academy Awards.
Several popular online series are currently produced in Flash, such as the Emmy Award-winning "Off-Mikes", produced by ESPN and Animax Entertainment; "Gotham Girls", produced by Warner Brothers; "Crime Time", produced by Future Thought Productions and "Homestar Runner" produced by Mike and Matt Chapman.
Various third-party software packages designed for traditionally trained cartoonists and animators can publish animations in the SWF format.
History.
FutureWave.
Flash originated with the application SmartSketch, developed by Jonathan Gay. It was published by FutureWave Software, which was founded by Charlie Jackson and Michelle Welsh. SmartSketch was a drawing application for pen computers running the PenPoint OS. When PenPoint failed in the marketplace, SmartSketch was ported to Microsoft Windows and Mac OS.
As the Internet became more popular, FutureWave realized the potential for a vector-based web animation tool that might challenge Macromedia Shockwave technology. In 1995, FutureWave modified SmartSketch by adding frame-by-frame animation features and re-released it as FutureSplash Animator on Macintosh and PC.
FutureWave approached Adobe Systems with an offer to sell them FutureSplash in 1995, but Adobe turned down the offer at that time. Microsoft wanted to create an "online TV network" (MSN) and adopted FutureSplash animated content as a central part of it. Disney Online used FutureSplash animations for their subscription-based service Disney's Daily Blast. Fox Broadcasting Company launched The Simpsons using FutureSplash.
Macromedia.
In November 1996, FutureSplash was acquired by Macromedia, and Macromedia re-branded and released "FutureSplash Animator" as "Macromedia Flash 1.0". Flash was a two-part system, a graphics and animation editor known as Macromedia Flash, and a player known as Macromedia Flash Player.
"FutureSplash Animator" was an animation tool originally developed for pen-based computing devices, but due to the small size of the "FutureSplash Viewer", it was particularly suited for download over the Web. Macromedia distributed Flash Player as a free browser plugin in order to quickly gain market share. As of 2005, more computers worldwide had the Flash Player installed than any other Web media format, including Java, QuickTime, RealNetworks and Windows Media Player.
Macromedia upgraded the Flash system significantly from 1996 to 1999, adding MovieClips, Actions (the precursor to ActionScript), Alpha transparency, and other features. As Flash matured, Macromedia's focus shifted from marketing it as a graphics and media tool to promoting it as a Web application platform, adding scripting and data access capabilities to the player while attempting to retain its small footprint.
In 2000, the first major version of ActionScript was developed, and released with "Flash 5". Actionscript 2.0 was released with "Flash MX 2004" and supported object-oriented programming, improved UI components, and other advanced programming features. The last version of Flash released by Macromedia was "Flash 8", which focused on graphical upgrades such as filters (blur, drop shadow, etc.), blend modes (similar to Adobe Photoshop), and advanced features for FLV video.
Adobe.
Macromedia was acquired by Adobe Systems in 2005, and the entire Macromedia product line including Flash, Dreamweaver, Director/Shockwave and Authorware is now handled by Adobe.
In 2007, Adobe released "Adobe Flash CS3 Professional", the first version released under Adobe, and the ninth major version of Flash. It introduced the ActionScript 3.0 programming language, which supported modern programming practices and enabled business applications to be developed with Flash. Adobe Flex Builder (built on Eclipse) targeted the enterprise application development market, and was also released the same year. Flex Builder included the Flex SDK, a set of components that included charting, advanced UI, and data services ("Flex Data Services").
In 2008, Adobe released the historic tenth version of Flash, "Adobe Flash CS4". Flash 10 improved animation capabilities within the Flash editor, adding a motion editor panel (similar to Adobe After Effects), inverse kinematics (bones), basic 3D object animation, object-based animation, and other advanced text and graphics features. "Flash Player 10" included the first in-built 3D engine (without GPU acceleration), that allowed basic object transformations in 3D space (position, rotation, scaling).
Also in 2008, Adobe released the first version of Adobe Integrated Runtime (later re-branded as "Adobe AIR"), a runtime engine that replaced Flash Player, and provided additional capabilities to the ActionScript 3.0 language to build desktop and mobile applications. With AIR, developers could access the file system (files & folders), and connected devices (joystick, gamepad, sensors) for the first time.
In 2011, "Adobe Flash Player 11" was released, and with it the first version of Stage3D, allowing for GPU-accelerated 3D rendering for Flash applications and games, on desktop platforms such as Microsoft Windows and Mac OS X. Adobe further improved 3D capabilities from 2011 to 2013, adding support for 3D rendering on Android and iOS platforms, alpha-channels, compressed textures, texture atlases, and other features. Adobe AIR was upgraded to support 64-bit computers, and developers could now add additional functionality to the AIR runtime using "AIR Native Extensions" (ANE).
In 2014, Adobe AIR reached a milestone when over 100,000 unique applications were built on AIR, and over 1 billion installations of the same were logged from users across the world (May 2014). Adobe AIR was voted as the "Best Mobile Application Development" product at the Consumer Electronics Show for two consecutive years (CES 2014 and CES 2015).
Format.
FLA.
Flash source files are in the FLA format, and contain graphics, animation as well as embedded assets such as bitmap images, audio files and FLV video files. The Flash source file format is a proprietary format and Adobe Animate is the only available authoring tool capable of editing such files. Flash source files (.fla) may be compiled into Flash movie files (.swf) using Adobe Animate. Note that FLA files can be edited, but output (.swf) files cannot.
SWF.
Flash movie files are in the "SWF" format, traditionally called "ShockWave Flash" movies, "Flash movies", or "Flash applications", usually have a .swf file extension, and may be used in the form of a web page plug-in, strictly "played" in a standalone Flash Player, or incorporated into a self-executing Projector movie (with the .exe extension in Microsoft Windows). Flash Video filesF4V is based on ISO base media file format standard, available as a free download [http://standards.iso.org/ittf/PubliclyAvailableStandards/index.html]</ref> have a .flv file extension and are either used from within .swf files or played through a flv-aware player, such as VLC, or QuickTime and Windows Media Player with external codecs added.
The use of vector graphics combined with program code allows Flash files to be smaller—and thus allows streams to use less bandwidth—than the corresponding bitmaps or video clips. For content in a single format (such as just text, video, or audio), other alternatives may provide better performance and consume less CPU power than the corresponding Flash movie, for example when using transparency or making large screen updates such as photographic or text fades.
In addition to a vector-rendering engine, the Flash Player includes a virtual machine called the ActionScript Virtual Machine (AVM) for scripting interactivity at run-time, with video, MP3-based audio, and bitmap graphics. As of Flash Player 8, it offers two video codecs: On2 Technologies VP6 and Sorenson Spark, and run-time JPEG, Progressive JPEG, PNG, and GIF capability. In the next version, Flash is slated to use a just-in-time compiler for the ActionScript engine.
3D.
Flash Player 11 introduced a full 3D shader API, called Stage3D, which is fairly similar to WebGL. Stage3D enables GPU-accelerated rendering of 3D graphics within Flash games and applications, and has been used to build Angry Birds, and a couple of other notable games.
Various 3D frameworks have been built for Flash using Stage3D, such as Away3D 4, CopperCube, Flare3D, Starling. Professional game engines like Unreal Engine and Unity also export Flash versions which use Stage3D to render 3D graphics.
Flash Video.
Virtually all browser plugins for video are free of charge and cross-platform, including Adobe's offering of Flash Video, which was first introduced with Flash version 6. Flash Video has been a popular choice for websites due to the large installed user base and programmability of Flash. In 2010, Apple publicly criticized Adobe Flash, including its implementation of video playback for not taking advantage of hardware acceleration, one reason Flash is not to be found on Apple's mobile devices. Soon after Apple's criticism, Adobe demoed and released a beta version of Flash 10.1, which takes advantage of GPU hardware acceleration even on a Mac. Flash 10.2 beta, released December 2010, adds hardware acceleration for the whole video rendering pipeline.
Flash Player supports two distinct modes of video playback, and hardware accelerated video decoding may not be used for older video content. Such content causes excessive CPU usage compared to comparable content played with other players.
In tests done by Ars Technica in 2008 and 2009, Adobe Flash Player performed better on Windows than Mac OS X and Linux with the same hardware.
Performance has later improved for the latter two, on Mac OS X with Flash Player 10.1, and on Linux with Flash Player 11.
Flash Audio.
Flash Audio is most commonly encoded in MP3 or AAC (Advanced Audio Coding) however it can also use ADPCM, Nellymoser (Nellymoser Asao Codec) and Speex audio codecs. Flash allows sample rates of 11, 22 and 44.1 kHz. It cannot have 48 kHz audio sample rate, which is the standard TV and DVD sample rate.
On August 20, 2007, Adobe announced on its blog that with Update 3 of Flash Player 9, Flash Video will also implement some parts of the MPEG-4 international standards. Specifically, Flash Player will work with video compressed in H.264 (MPEG-4 Part 10), audio compressed using AAC (MPEG-4 Part 3), the F4V, MP4 (MPEG-4 Part 14), M4V, M4A, 3GP and MOV multimedia container formats, 3GPP Timed Text specification (MPEG-4 Part 17), which is a standardized subtitle format and partial parsing capability for the 'ilst' atom, which is the ID3 equivalent iTunes uses to store metadata. MPEG-4 Part 2 and H.263 will not work in F4V file format. Adobe also announced that it will be gradually moving away from the FLV format to the standard ISO base media file format (MPEG-4 Part 12) owing to functional limits with the FLV structure when streaming H.264. The final release of the Flash Player implementing some parts of MPEG-4 standards had become available in Fall 2007.
Adobe Flash Player 10.1 does not have acoustic echo cancellation, unlike the VoIP offerings of Skype and Google Voice, making this and earlier versions of Flash less suitable for group calling or meetings. Flash Player 10.3 Beta incorporates acoustic echo cancellation.
Scripting language.
"ActionScript" is the programming language used by Flash. It is an enhanced superset of the ECMAScript programming language, with a classical Java-style class model, rather than JavaScript's prototype model.
Specifications.
In October 1998, Macromedia disclosed the Flash Version 3 Specification on its website. It did this in response to many new and often semi-open formats competing with SWF, such as Xara's Flare and Sharp's Extended Vector Animation formats. Several developers quickly created a C library for producing SWF. In February 1999, MorphInk 99 was introduced, the first third-party program to create SWF files. Macromedia also hired Middlesoft to create a freely available developers' kit for the SWF file format versions 3 to 5.
Macromedia made the Flash Files specifications for versions 6 and later available only under a non-disclosure agreement, but they are widely available from various sites.
In April 2006, the Flash SWF file format specification was released with details on the then newest version format (Flash 8). Although still lacking specific information on the incorporated video compression formats (On2, Sorenson Spark, etc.), this new documentation covered all the new features offered in Flash v8 including new ActionScript commands, expressive filter controls, and so on. The file format specification document is offered only to developers who agree to a license agreement that permits them to use the specifications only to develop programs that can export to the Flash file format. The license does not allow the use of the specifications to create programs that can be used for playback of Flash files. The Flash 9 specification was made available under similar restrictions.
In June 2009, Adobe launched the Open Screen Project (Adobe link), which made the SWF specification available without restrictions. Previously, developers could not use the specification for making SWF-compatible players, but only for making SWF-exporting authoring software. The specification still omits information on codecs such as Sorenson Spark, however.
Animation tools.
Official tools.
The Adobe Animate authoring program is primarily used to design graphics and animation and publish the same for websites, web applications, and video games. The program also offers limited support for audio and video embedding, and ActionScript scripting.
Adobe released Adobe LiveMotion, designed to create interactive animation content and export it to a variety of formats, including SWF. LiveMotion failed to gain any notable user base.
In February 2003, Macromedia purchased Presedia, which had developed a Flash authoring tool that automatically converted PowerPoint files into Flash. Macromedia subsequently released the new product as Breeze, which included many new enhancements.
Third-party tools.
Various free and commercial software packages can output animations into the Flash SWF format, suitable for display on the web, including:
The Flash 4 Linux project was an initiative to develop an open source Linux application as an alternative to Adobe Animate. Development plans included authoring capacity for 2D animation, and tweening, as well as outputing SWF file formats. F4L evolved into an editor that was capable of authoring 2D animation and publishing of SWF files. Flash 4 Linux was renamed UIRA. UIRA intended to combine the resources and knowledge of the F4L project and the Qflash project, both of which were Open Source applications that aimed to provide an alternative to the proprietary Adobe Flash.
Programming tools.
Official tools.
Adobe provides a series of tools to develop software applications and video games for Flash:
Third-party tools.
Third-party development tools have been created to assist developers in creating software applications and video games with Flash.
Players.
Commercial.
Adobe Flash Player is the multimedia and application player originally developed by Macromedia and acquired by Adobe Systems. It plays SWF files, which can be created by Adobe Animate, Apache Flex, or a number of other Adobe Systems and 3rd party tools. It has support for a scripting language called ActionScript, which can be used to display Flash Video from an SWF file.
Scaleform GFx is a commercial alternative Flash player that features fully hardware-accelerated 2D graphics rendering using the GPU. Scaleform has high conformance with both Flash 10 ActionScript 3 and Flash 8 ActionScript 2. Scaleform GFx is a game development middleware solution that helps create graphical user interfaces or HUDs within 3D video games. It does not work with web browsers.
IrfanView, an image viewer, uses Flash Player to display SWF files.
Open source.
Lightspark is a free and open source SWF player that supports most of ActionScript 3.0 and has a Mozilla-compatible plug-in. It will fall back on Gnash, a free SWF player supporting ActionScript 1.0 and 2.0 (AVM1) code. Lightspark supports OpenGL-based rendering for 3D content. The player is also compatible with H.264 Flash videos on YouTube.
Gnash is an active project that aims to create a software player and browser plugin replacement for the Adobe Flash Player. Currently, Gnash can play SWF files up to version 7, and 80% of ActionScript 2.0. Gnash runs on Windows, Linux and other platforms for the 32-bit, 64-bit, and other operating systems.
Shumway is an open source Flash Player released by Mozilla in November 2012. It is built in JavaScript and is thus compatible with modern web-browsers. In early October 2013, Shumway was included by default in the Firefox nightly branch. Shumway renders Flash contents by translating contents inside Flash files to HTML5 elements, and running an ActionScript interpreter in JavaScript. It supports both AVM1 and AVM2, and ActionScript versions 1, 2, and 3.
Adobe Flash Player cannot ship as part of a pure open source, or completely free operating system, as its distribution is bound to the Macromedia Licensing Program and subject to proposition first from Adobe.
Availability.
Desktop computers.
Flash Player.
The latest version of Adobe Flash Player is available for many major desktop platforms, including Windows (XP and newer) and OS X (10.6 and later). The latest version is also available on Linux but only on Google Chrome as Adobe no longer releases updates for the non-PPAPI plugin on Linux.
Adobe Flash Player is available in three flavors: "ActiveX", "Plug-in" and "Projector". The "ActiveX" version is an ActiveX control for use in Internet Explorer and any other Windows applications that supports ActiveX technology. The "plug-in" version is available for Netscape-compatible browsers on Microsoft Windows, Macintosh and Linux. The "projector" version is a standalone player that can open SWF files directly.
The following table documents Flash Player and Adobe AIR support on desktop operating systems:
Adobe AIR.
The latest version of Adobe AIR, version 18, contains Adobe Flash Player 18, and is available for Windows XP and later, as well as OS X. Official support for desktop Linux distributions ceased in June 2011 with version 2.6.
Mobile devices.
Flash Player.
Adobe Flash Player was available for a variety of mobile operating systems, including Android (between versions 2.2 and 4.0.4), Pocket PC/Windows CE, QNX (e.g. on BlackBerry PlayBook), Symbian, Palm OS, and webOS (since version 2.0). Flash Player for smart phones was made available to handset manufacturers at the end of 2009.
However, in November 2011, Adobe announced the withdrawal of support for Flash Player on mobile devices. Adobe continues to support deploying Flash-based content as mobile applications via Adobe AIR.
Adobe is reaffirming its commitment to "aggressively contribute" to HTML5. Adobe announced the end of Flash for mobile platforms or TV, instead focusing on HTML5 for browser content and Adobe AIR for the various mobile application stores and described it as "the beginning of the end". BlackBerry LTD (formerly known as RIM) announced that it would continue to develop Flash Player for the PlayBook.
There is no Adobe Flash Player for iOS devices (iPhone, iPad and iPod Touch). However, Flash content can be made to run on iOS devices in a variety of ways:
The mobile version of Internet Explorer for Windows Phone cannot play Flash content, however Flash support is still present on the tablet version of Windows.
Adobe AIR.
Adobe AIR was released in 2008, and allows the creation of mobile applications and mobile games using Flash and ActionScript. Notable mobile games built with Flash include "Angry Birds", "Machinarium" and "Defend Your Castle".
Using AIR, developers can access the full Adobe Flash functionality, including text, vector graphics, raster graphics, video, audio, camera and microphone capability. Adobe AIR also includes additional features such as file system integration, native client extensions, desktop integration and access to connected devices and sensors.
AIR applications can be published as native phone applications on certain mobile operating systems, such as Android (ARM Cortex-A8 and above) and Apple iOS.
The following table explains to what extent Adobe AIR can run on various mobile operating systems:
Portable electronic devices.
Adobe Flash Lite is a lightweight version of Adobe Flash Player intended for mobile phones and other portable electronic devices like Chumby and iRiver.
On the emerging single-board enthusiast market, as substantially popularized by the Raspberry Pi, support from Adobe is lacking. However, the open-source player Gnash has been ported and found to be useful.
Open Screen Project.
On May 1, 2008, Adobe announced the "Open Screen Project", with the intent of providing a consistent application interface across devices such as personal computers, mobile devices, and consumer electronics. When the project was announced, seven goals were outlined: the abolition of licensing fees for Adobe Flash Player and Adobe Integrated Runtime, the removal of restrictions on the use of the Shockwave Flash (SWF) and Flash Video (FLV) file formats, the publishing of application programming interfaces for porting Flash to new devices, and the publishing of The Flash Cast protocol and Action Message Format (AMF), which let Flash applications receive information from remote databases.
, the specifications removing the restrictions on the use of SWF and FLV/F4V specs have been published. The Flash Cast protocol—now known as the Mobile Content Delivery Protocol—and AMF protocols have also been made available, with AMF available as an open source implementation, BlazeDS. 
The list of mobile device providers who have joined the project includes Palm, Motorola, and Nokia, who, together with Adobe, have announced a $10 million Open Screen Project fund. , the Open Screen Project is no longer accepting new applications according to partner BSQuare. However paid licensing is still an option for device makers who want to use Adobe software.
Mobile support.
Websites built with Adobe Flash will not function on most modern mobile devices running Google Android or iOS (iPhone, iPad). The only alternative is using HTML5 and responsive web design to build websites that support both desktop and mobile devices.
However, Flash is still actively used to build mobile games using Adobe AIR. Such games will not work in mobile web browsers, but must be installed via the appropriate app store.
Alternatives.
HTML5.
HTML5 is often cited as an alternative to Adobe Flash technology usage on web pages. Adobe released a tool that converts Flash to HTML5, and in June 2011, Google released an experimental tool that does the same. In January 2015, YouTube defaulted to HTML5 players to better support more devices.
Criticisms.
Vendor dependence.
The reliance on Adobe for decoding Flash makes its use on the World Wide Web a concern—the completeness of its public specifications are debated, and no complete implementation of Flash is publicly available in source code form with a license that permits reuse. Generally, public specifications are what makes a format re-implementable (see future proofing data storage), and reusable codebases can be ported to new platforms without the endorsement of the format creator.
Adobe's restrictions on the use of the SWF/FLV specifications were lifted in February 2009 (see Adobe's Open Screen Project). However, despite efforts of projects like Gnash, Swfdec and Lightspark, a complete free Flash player is yet to be seen, as of September 2011. For example, Gnash cannot use SWF v10 yet. Notably, Gnash has been a long-standing high priority project of the Free Software Foundation since at least 2007, and it was ranked number one in September 2011.
Notable advocates of free software, open standards, and the World Wide Web have warned against the use of Flash:
Founder of Mozilla Europe, Tristan Nitot stated in 2008:
Companies building websites should beware of proprietary rich-media technologies like Adobe's Flash and Microsoft's Silverlight. (...) You're producing content for your users and there's someone in the middle deciding whether users should see your content.
Representing open standards, inventor of CSS and co-author of HTML5, Håkon Wium Lie explained in a Google tech talk of 2007, entitled "the <video> element", the proposal of Theora as the format for HTML5 video:
I believe very strongly, that we need to agree on some kind of baseline video format if video element is going to succeed. Flash is today the baseline format on the web. The problem with Flash is that it's not an open standard.
Representing the free software movement, Richard Stallman stated in a speech in 2004 that: "The use of Flash in websites is a major problem for our community."
Accessibility.
Usability consultant Jakob Nielsen published an Alertbox in 2000 entitled, "Flash: 99% Bad", stating that "Flash tends to degrade websites for three reasons: it encourages design abuse, it breaks with the Web's fundamental interaction principles, and it distracts attention from the site's core value." Some problems have been at least partially fixed since Nielsen's complaints: Text size can be controlled using full page zoom and it has been possible for authors to include alternative text in Flash since Flash Player 6.
Flash blocking in web browsers.
Flash content is usually embedded using the codice_1 or codice_2 HTML element. A web browser that does not fully implement one of these elements displays the replacement text, if supplied by the web page. Often, a plugin is required for the browser to fully implement these elements, though some users cannot or will not install it.
Since Flash can be used to produce content (such as advertisements) that some users find obnoxious or take a large amount of bandwidth to download, some web browsers default to not play Flash content before the user clicks on it, e.g. Konqueror, K-Meleon.
Most current browsers have a feature to block plugins, playing one only when the user clicks it. Opera versions since 10.5 feature native Flash blocking. Opera Turbo requires the user to click to play Flash content, and the browser also allows the user to enable this option permanently. Both Chrome and Firefox have an option to enable "click to play plugins". Equivalent "Flash blocker" extensions are also available for many popular browsers: Firefox has Flashblock and NoScript, Internet Explorer has Foxie, which contains a number of features, one of them named Flashblock. WebKit-based browsers under Mac OS X, such as Apple's Safari, have ClickToFlash.
Security.
For many years Adobe Flash Player's security record has led many security experts to recommend against installing the player, or to block Flash content. The US-CERT has recommended blocking Flash, and security researcher Charlie Miller recommended "not to install Flash"; however, for people still using Flash, Intego recommended that users get trusted updates "only directly from the vendor that publishes them." As of February 12, 2015, Adobe Flash Player has over 400 CVE entries, of which over 300 lead to arbitrary code execution, and past vulnerabilities have enabled spying via web cameras. Security experts have long predicted the demise of Flash, saying that with the rise of HTML5 ""...the need for browser plugins such as Flash is diminishing"", yet a significant proportion of websites still use it.
Active moves by third-parties to limit the risk began with Steve Jobs in 2010 saying that Apple would not allow Flash on the iPhone, iPod touch and iPad - citing abysmal security as one reason. In July 2015, a series of newly discovered vulnerabilities resulted in Facebook's chief security officer, Alex Stamos, issuing a call to Adobe to discontinue the software entirely and the Mozilla Firefox web browser, Google Chrome and Apple Safari to blacklist all earlier versions of Flash Player.
Flash cookies.
Like the HTTP cookie, a flash cookie (also known as a “Local Shared Object”) can be used to save application data. Flash cookies are not shared across domains. An August 2009 study by the Ashkan Soltani and a team of researchers at UC Berkeley found that 50% of websites using Flash were also employing flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' cache and history suppress or delete functions did not affect Flash Player's writing Local Shared Objects to its own cache in version 10.2 and earlier, at which point the user community was much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users with those versions, having deleted HTTP cookies and purged browser history files and caches, may believe that they have purged all tracking data from their computers when in fact Flash browsing history remains. Adobe's own Flash Website Storage Settings panel, a submenu of Adobe's Flash Settings Manager web application, and other editors and toolkits can manage settings for and delete Flash Local Shared Objects.

</doc>
<doc id="20948" url="https://en.wikipedia.org/wiki?curid=20948" title="Mind control">
Mind control

Mind control (also known as brainwashing, reeducation, brainsweeping, coercive persuasion, thought control, or thought reform) is a controversial pseudo-scientific theory that human subjects can be indoctrinated in a way that causes "an impairment of autonomy, an inability to think independently, and a disruption of beliefs and affiliations. In this context, brainwashing refers to the involuntary reeducation of basic beliefs and values".
Theories of brainwashing and of mind control were originally developed to explain how totalitarian regimes appeared to systematically indoctrinate prisoners of war through propaganda and torture techniques. These theories were later expanded and modified by psychologists including Margaret Singer and Philip Zimbardo to explain a wider range of phenomena, especially conversions to some new religious movements (NRMs). The suggestion that NRMs use mind control techniques has resulted in scientific and legal debate; with Eileen Barker, James Richardson, and other scholars, as well as legal experts, rejecting at least the popular understanding of the concept.
Other theories have been proposed by scholars including: Robert Cialdini, Robert Jay Lifton, Michael J. Freeman, Daniel Romanovsky, Kathleen Taylor, and Benjamin Zablocki. The concept of mind control is sometimes involved in legal cases, especially regarding child custody; and is also a major theme in both science fiction and in criticism of modern political and corporate culture. However, in the view of scholars, the theory of mind control is not accepted as scientific fact.
The Korean War and brainwashing.
Origin of the concept.
The "Oxford English Dictionary" records the earliest known English-language usage of "brainwashing" in an article by newspaperman Edward Hunter, in "Miami News", published on 7 October 1950. Hunter, an outspoken anticommunist and said to be a CIA agent working undercover as a journalist, wrote a series of books and articles on the theme of Chinese brainwashing, and the word brainwashing quickly became a stock phrase in Cold War headlines.
The Chinese term "xǐ năo" (literally "wash brain") was originally used to describe methodologies of coercive persuasion used under the Maoist government in China, which aimed to transform individuals with a reactionary imperialist mindset into "right-thinking" members of the new Chinese social system. The term punned on the Taoist custom of "cleansing/washing the heart/mind" ("xǐ xīn") before conducting certain ceremonies or entering certain holy places.
Hunter and those who picked up the Chinese term used it to explain why, during the Korean War (1950-1953), some American prisoners of war cooperated with their Chinese captors, even in a few cases defecting to the enemy side. British radio operator Robert W. Ford and British army Colonel James Carne also claimed that the Chinese subjected them to brainwashing techniques during their war-era imprisonment.
The U.S. military and government laid charges of "brainwashing" in an effort to undermine detailed confessions made by military personnel to war crimes, including biological warfare. After Chinese radio broadcasts claimed to quote Frank Schwable, Chief of Staff of the First Marine Air Wing admitting to participating in germ warfare, United Nations commander Gen. Mark W. Clark asserted: "Whether these statements ever passed the lips of these unfortunate men is doubtful. If they did, however, too familiar are the mind-annihilating methods of these Communists in extorting whatever words they want ... The men themselves are not to blame, and they have my deepest sympathy for having been used in this abominable way."
Korean War brainwashing debunked.
In 1956, after reexamining the concept of brainwashing following the Korean War, the U.S. Army published a report entitled "Communist Interrogation, Indoctrination, and Exploitation of Prisoners of War" which called brainwashing a "popular misconception." The report states "exhaustive research of several government agencies failed to reveal even one conclusively documented case of 'brainwashing' of an American prisoner of war in Korea."
US POWs captured by North Korea were brutalized with starvation, beatings, forced death marches, exposure to extremes of temperature, binding in stress positions, and withholding of medical care, but the abuse had no relation to indoctrination "in which Korea was not particularly interested." In contrast American POWs in the custody of North Korea's Chinese Communist allies did face a concerted interrogation and indoctrination program. However, "systematic, physical torture was not employed in connection with interrogation or indoctrination," the report states.
The "most insidious" and effective Chinese technique according to the US Army Report was a convivial display of false friendship, which persuaded some GIs to make anti-American statements, and in a few isolated cases, refuse repatriation and remain in China:
"an American soldier was captured by the Chinese, he was given a vigorous handshake and a pat on the back. The enemy 'introduced' himself as a friend of the 'workers' of America ... in many instances the Chinese did not search the American captives, but frequently offered them American cigarettes. This display of friendship caught most Americans totally off-guard and they never recovered from the initial impression made by the Chinese. ... [After the initial contact with the enemy, some Americans seemed to believe that the enemy was sincere and harmless. They relaxed and permitted themselves to be lulled into a well-disguised trap cooperating with the cunning enemy." 
Two academic studies of the repatriation of American prisoners of war by Robert Jay Lifton and by Edgar Schein concluded that brainwashing (called "thought reform" by Lifton and "coercive persuasion" by Schein), if it occurred, had at worst a transient effect. In 1961, they both published books expanding on these findings. Schein published "Coercive Persuasion" and Lifton published "Thought Reform and the Psychology of Totalism".
CIA mind control program.
In 1999, forensic psychologist Dick Anthony concluded that the CIA had invented the concept of "brainwashing" as a propaganda strategy to undercut communist claims that American POWs in Korean communist camps had voluntarily expressed sympathy for communism. He argued that the books of Edward Hunter (whom he identified as a secret CIA "psychological warfare specialist" passing as a journalist) pushed the CIA brainwashing theory onto the general public. Succumbing to their own propaganda, for twenty years starting in the early 1950s, the CIA and the Defense Department conducted secret research (notably including Project MKULTRA) in an attempt to develop practical brainwashing techniques; the results are unknown. (See also Sidney Gottlieb.)
CIA experiments using various psychedelic drugs such as LSD and Mescaline drew from Nazi scientist research during World War II. 
American Psychological Association rejection of brainwashing theory.
Margaret Singer, who also spent time studying the political brainwashing of Korean prisoners of war, in her book "Cults in Our Midst", describes six conditions which would create an atmosphere in which thought reform is possible. In 1983, the American Psychological Association (APA) asked Singer to chair a taskforce called the APA Task Force on Deceptive and Indirect Techniques of Persuasion and Control (DIMPAC) to investigate whether brainwashing or "coercive persuasion" did indeed play a role in recruitment by such movements.
Before the taskforce had submitted its final report, the APA submitted on 10 February 1987 an "amicus curiæ" brief in an ongoing court case related to brainwashing. Although the amicus curiæ brief written by the APA denies the credibility of the brainwashing theory, the APA submitted the brief under "intense pressure by a consortium of pro-religion scholars (a.k.a. NRM scholars)". The brief repudiated Singer's theories on "coercive persuasion" and suggested that brainwashing theories were without empirical proof. Afterward the APA filed a motion to withdraw its signature from the brief, since Singer's final report had not been completed.
On 11 May 1987, the APA's Board of Social and Ethical Responsibility for Psychology (BSERP) rejected the DIMPAC report because the report "lacks the scientific rigor and evenhanded critical approach necessary for APA imprimatur", and concluded that "after much consideration, BSERP does not believe that we have sufficient information available to guide us in taking a position on this issue." Benjamin Zablocki and Alberto Amitrani interpreted the APA's response as meaning that there was no unanimous decision on the issue either way, suggesting also that Singer retained the respect of the psychological community after the incident.
Two critical letters from external reviewers Benjamin Beit-Hallahmi and Jeffery D. Fisher accompanied the rejection memo. The letters criticized "brainwashing" as an unrecognized theoretical concept and Singer's reasoning as so flawed that it was "almost ridiculous." After her findings were rejected, Singer sued the APA in 1992 for "defamation, frauds, aiding and abetting and conspiracy" and lost. After that time U.S. courts consistently rejected testimonies about mind control and manipulation, stating that such theories were not part of accepted mainline science according to the Frye Standard of 1923.
New religious movements.
In the 1970s, the anti-cult movement applied mind control theories to explain seemingly sudden and dramatic religious conversions to various new religious movements (NRMs). The media was quick to follow suit, and social scientists sympathetic to the anti-cult movement, who were usually psychologists, developed more sophisticated models of brainwashing. While some psychologists were receptive to these theories, sociologists were for the most part skeptical of their ability to explain conversion to NRMs.
Theories and religious conversion.
Over the years various theories of conversion and member retention have been proposed that link mind control to some new religious movements (NRMs), particularly those religious movements referred to as "cults" by their critics. Philip Zimbardo discusses mind control as "the process by which individual or collective freedom of choice and action is compromised by agents or agencies that modify or distort perception, motivation, affect, cognition and/or behavioral outcomes", and he suggests that any human being is susceptible to such manipulation. Another adherent to this view, Jean-Marie Abgrall was heavily criticized by forensic psychologist Dick Anthony for employing a pseudo-scientific approach and lacking any evidence that anyone's worldviews were substantially changed by these coercive methods. One the contrary, the theories and the fear surrounding them was used as a tool for the western anti-cult movement to rationalize the persecution of minority religious groups.
Debate over theories as applied to NRMs.
James Richardson observes that if the new religious movements (NRMs) had access to powerful brainwashing techniques, one would expect that NRMs would have high growth rates, yet in fact most have not had notable success in recruitment. Most adherents participate for only a short time, and the success in retaining members is limited. For this and other reasons, sociologists of religion including David Bromley and Anson Shupe consider the idea that "cults" are brainwashing American youth to be "implausible." In addition, Thomas Robbins, Massimo Introvigne, Lorne Dawson, Gordon Melton, Marc Galanter, and Saul Levine, amongst other scholars researching NRMs, have argued and established to the satisfaction of courts, relevant professional associations and scientific communities that there exists no generally accepted scientific theory, based upon methodologically sound research, that supports the brainwashing theories as advanced by the anti-cult movement.
Benjamin Zablocki responds that it is obvious that brainwashing occurs, at least to any objective observer; but that it isn't "a process that is directly observable." The "real sociological issue", he states, is whether "brainwashing occurs frequently enough to be considered an important social problem". Zablocki disagrees with scholars like Richardson, stating that Richardson's observation is flawed. According to Zablocki, Richardson misunderstands brainwashing, conceiving of it as a recruiting process, instead of a retaining process. Zablocki adds that the sheer number of former cult leaders and members who attest to brainwashing in interviews (performed in accordance with guidelines of the National Institute of Mental Health and National Science Foundation) is too large to be a result of anything other than a genuine phenomenon.
Zablocki also points out that in the two most prestigious journals dedicated to the sociology of religion, the number of articles "supporting the brainwashing perspective" have been zero, while over one hundred such articles have been published in other journals "marginal to the field". From this fact, Zablocki concludes that the concept brainwashing has been blacklisted unfairly from the field of sociology of religion.
Eileen Barker criticizes mind control theories because they function to justify costly interventions such as deprogramming or exit counseling. She has also criticized some mental health professionals, including Singer, for accepting expert witness jobs in court cases involving NRMs. Her 1984 book, "" describes the religious conversion process to the Unification Church (whose members are sometimes informally referred to as "Moonies") which had been one of the best known groups said to practice brainwashing. Barker spent close to seven years studying Unification Church members. She interviewed in depth and/or gave probing questionnaires to church members, ex-members, "non-joiners," and control groups of uninvolved people from similar backgrounds, as well as parents, spouses, and friends of members. She also attended numerous Unification Church workshops and communal facilities. Barker writes that she rejects the "brainwashing" theory as an explanation for conversion to the Unification Church, because, as she wrote, it explains neither the many people who attended a recruitment meeting and did not become members, nor the voluntary disaffiliation of members.
Other areas and studies.
Joost Meerloo, a Dutch psychiatrist, was an early leading proponent of the concept of brainwashing. His view was influenced by his experiences during the German occupation of his country in the Second World War and his work with the Dutch government and the American military in the interrogation of accused Nazi war criminals. He later emigrated to the United States and taught at Columbia University. His best-selling 1956 book, "The Rape of the Mind", concludes by saying: "The modern techniques of brainwashing and menticide-those perversions of psychology-can bring almost any man into submission and surrender. Many of the victims of thought control, brainwashing, and menticide that we have talked about were strong men whose minds and wills were broken and degraded. But although the totalitarians use their knowledge of the mind for vicious and unscrupulous purposes, our democratic society can and must use its knowledge to help man to grow, to guard his freedom, and to understand himself." ("Menticide" is a neologism coined by Meerloo meaning: "Killing of the mind.")
In Italy there has been controversy over the concept of "plagio", a crime consisting in an absolute psychological—and eventually physical—domination of a person. The effect of such domination is the annihilation of the subject's freedom and self-determination and the consequent negation of his or her personality. The crime of plagio has rarely been prosecuted in Italy, and only one person was ever convicted. In 1981, Italy the Court found the concept to be imprecise, lacking coherence, and liable to arbitrary application.
By the twenty-first century, the concept of brainwashing had spread to other fields and was being applied "with some success" in criminal defense, child custody, and child sexual abuse cases. In some cases "one parent is accused of brainwashing the child to reject the other parent, and in child sex abuse cases where one parent is accused of brainwashing the child to make sex abuse accusations against the other parent" (possibly resulting in or causing parental alienation).
In his 2000 book, "Destroying the World to Save It: Aum Shinrikyo, Apocalyptic Violence, and the New Global Terrorism", Robert Lifton applied his original ideas about thought reform to Aum Shinrikyo and the War on Terrorism, concluding that in this context thought reform was possible without violence or physical coercion. He also pointed out that in their efforts against terrorism Western governments were also using some mind control techniques, including thought-terminating clichés.
In 2003 forensic psychologist Dick Anthony said that "no reasonable person would question that there are situations where people can be influenced against their best interests, but those arguments are evaluated on the basis of fact, not bogus expert testimony." Dismissing the idea of mind control, he has defended NRMs, and argued that involvement in such movements may often have beneficial, rather than harmful effects: "There's a large research literature published in mainstream journals on the mental health effects of new religions. For the most part the effects seem to be positive in any way that's measurable."
In her 2004 book, "", neuroscientist and physiologist Kathleen Taylor put forth the theory that the neurological basis for reasoning and cognition in the brain and the self itself are changeable. She describes the physiology behind neurological pathways which include webs of neurons containing dendrites, axons, and synapses; and explains that certain brains with more rigid pathways will be less susceptible to new information or creative stimuli. She uses neurological science to demonstrate that brainwashed individuals have more rigid pathways, and that that rigidity can make it unlikely that the individual will rethink situations or be able to later reorganize these pathways. She explains that repetition is an integral part of brainwashing techniques because connections between neurons become stronger when exposed to incoming signals of frequency and intensity. She argues that people in their teenage years and early twenties are more susceptible to persuasion.Taylor explains that brain activity in the temporal lobe, the region responsible for artistic creativity, also causes spiritual experiences in a process known as lability.
In his 2007 book, "Influence: The Psychology of Persuasion", social psychologist Robert Cialdini argues that mind control is possible through the covert exploitation of the unconscious rules that underlie and facilitate healthy human social interactions. He states that common social rules can be used to prey upon the unwary. Using categories, he offers specific examples of both mild and extreme mind control—both one on one and in groups—notes the conditions under which each social rule is most easily exploited for false ends, and offers suggestions on how to resist such methods.
In 2009 historian Daniel Romanovsky wrote about what he called "Nazi brainwashing" of the people of Belarus by the occupying Germans during the Second World War, which took place through both mass propaganda and intense re-education, especially in schools. He notes that very soon most people had adopted the Nazi view of the Jews, that they were an inferior race and were closely tied to the Soviet government, views that had not been at all common before the occupation.
Popular culture.
In the 1950s many American movies were filmed that featured brainwashing of POWs, including "The Rack", "The Bamboo Prison", "Toward the Unknown", and "The Fearmakers". Fraser A. Sherman comments: "The possibility that advanced psychological techniques could reprogram people's minds became a permanent part of pop culture." "Forbidden Area" told the story of Soviet secret agents who had been brainwashed (through classical conditioning) by their own government so they wouldn't reveal their true identities. In 1962 "The Manchurian Candidate" "put brainwashing front and center" and featured a plot by the Soviet government to take over the United States by use of a brainwashed presidential candidate.
The concept of brainwashing became associated with the research of Russian psychologist Ivan Pavlov; which mostly involved dogs, not humans, as subjects. In "The Manchurian Candidate" the head brainwasher is Dr. Yen Lo, of the Pavlov Institute.
Mind control has often been an important theme in science fiction and fantasy stories. Terry O'Brien comments: "Mind control is such a powerful image that if hypnotism did not exist, then something similar would have to have been invented: the plot device is too useful for any writer to ignore. The fear of mind control is equally as powerful an image." A subgenre is "corporate mind control", in which a future society is run by one or more business corporations which dominate society using advertising and mass media to control the population's thoughts and feelings.
Social and political commentary.
Modern corporations are said to practice mind control to create a work force which shares the same common values and culture. Critics have linked "corporate brainwashing" with globalization, saying that corporations are attempting to create a world-wide monocultural network of producers, consumers, and managers. In his 1992 book, "Democracy in an Age of Corporate Colonization", Stanley A. Deetz says that modern "self awareness" and "self improvement" programs provide corporations with even more effective tools to control the minds of employees than traditional brainwashing. Modern educational systems have also been criticized, by both the left and the right, for contributing to corporate brainwashing.
The idea of mind control also appears in political rhetoric as an explanation why others hold contrary views. For example, the conservative blog Brietbart.com frequently uses the term "liberal brainwashing" to criticize a perceived lack of conservative scholars in American universities. The 2014 documentary "The Brainwashing of My Dad" by Jen Senko says that the programming of Fox News influenced her father to shift to strongly conservative views.
The popular notion of brainwashing has influenced attempts at legislation against various new religious movements. In 1983 the state legislature of Nevada saw several bills were introduced to attempt to limit the influence of a range of new religious groups. While none of the bills was passed, the votes were close. 

</doc>
