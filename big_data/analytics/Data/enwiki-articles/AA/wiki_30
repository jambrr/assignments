<doc id="2241" url="https://en.wikipedia.org/wiki?curid=2241" title="Antonio Salieri">
Antonio Salieri

Antonio Salieri (; 18 August 17507 May 1825) was an Italian classical composer, conductor, and teacher. He was born in Legnago, south of Verona, in the Republic of Venice, who spent his adult life and career as a subject of the Habsburg Monarchy.
Salieri was a pivotal figure in the development of late 18th-century opera. As a student of Florian Leopold Gassmann's, and a protégé of Gluck's, Salieri was a cosmopolitan composer who wrote operas in three languages. Salieri helped to develop and shape many of the features of operatic compositional vocabulary, and his music was a powerful influence on contemporary composers.
Appointed the director of the Italian opera by the Habsburg court, a post he held from 1774 until 1792, Salieri dominated Italian language opera in Vienna. During his career he also spent time writing works for opera houses in Paris, Rome, and Venice, and his dramatic works were widely performed throughout Europe during his lifetime. As the Austrian imperial Kapellmeister from 1788 to 1824, he was responsible for music at the court chapel and attached school. Even as his works dropped from performance, and he wrote no new operas after 1804, he still remained one of the most important and sought-after teachers of his generation, and his influence was felt in every aspect of Vienna's musical life. Franz Liszt, Franz Schubert, and Ludwig van Beethoven were among the most famous of his pupils.
Salieri's music slowly disappeared from the repertoire between 1800 and 1868 and was rarely heard after that period until the revival of his fame in the late 20th century. This revival was due to the dramatic and highly fictionalized depiction of Salieri in Peter Shaffer's play "Amadeus" (1979) and its 1984 film version. His music today has regained some modest popularity via recordings. He is popularly remembered as a supposedly bitter rival of Wolfgang Amadeus Mozart. This includes rumours that Salieri murdered Mozart out of jealousy, when in reality, they were at least respectful peers.
Life and career.
Salieri started his musical studies in his native town of Legnago; he was first taught at home by his older brother Francesco Salieri (a former student of the violinist and composer Giuseppe Tartini), and he received further lessons from the organist of the Legnago Cathedral, Giuseppe Simoni, a pupil of Padre Giovanni Battista Martini. Salieri would recall little from his childhood in later years except passions for sugar, reading, and music. He twice ran away from home without permission to hear his elder brother play violin concertos in neighboring churches on festival days (resulting in the loss of his beloved sugar), and he recounted being chastised by his father after failing to greet a local priest with proper respect. Salieri responded to the reprimand by saying the priest's organ playing displeased him because it was in an inappropriately theatrical style. Sometime between 1763 and 1764, Salieri suffered the deaths of both parents and was briefly taken in by an anonymous brother, a monk in Padua, and then for unknown reasons in 1765 or 1766, he became the ward of a Venetian nobleman named Giovanni Mocenigo (which Giovanni is at this time unknown), a member of the powerful and well connected Mocenigo family. It is possible that Antonio's father and Giovanni were friends or business associates, but this is obscure. While living in Venice Salieri continued his musical studies with the organist and opera composer Giovanni Battista Pescetti, then following Pescetti's sudden death he studied with the opera singer Ferdinando Pacini or Pasini. It was through Pacini that Salieri gained the attention of the composer Florian Leopold Gassmann, who, impressed with his protege's talents and concerned for the boy's future, took the young orphan to Vienna, where he personally directed and paid for the remainder of Salieri's musical education.
Salieri and Gassmann arrived in Vienna on 15 June 1766. Gassmann's first act was to take Salieri to the Italian Church to consecrate his teaching and service to God, an event that left a deep impression on Salieri for the rest of his life. Salieri's education included instruction in Latin and Italian poetry by Fr. Don Pietro Tommasi, instruction in the German language, and European literature. His music studies revolved around vocal composition, and thoroughbass. His musical theory training in harmony and counterpoint was rooted in Johann Fux's Gradus ad Parnassum, which Salieri translated during each Latin lesson. As a result, Salieri continued to live with Gassmann even after Gassmann's marriage, an arrangement that lasted until the year of Gassmann's death and Salieri's own marriage in 1774. Few of Salieri's compositions have survived from this early period. In his old age Salieri hinted that these works were either purposely destroyed, or had been lost with the exception of a few works for the church. Among these sacred works there survives a Mass in C major written without a "Gloria" and in the antique a cappella style (presumably for one of the church's penitential seasons) and dated 2 August 1767. A complete opera composed in 1769 (presumably as a culminating study) "La vestale" ("The Vestal Virgin") has also been lost.
Beginning in 1766 Gassmann introduced Salieri to the daily chamber music performances held during Emperor Joseph II's evening meal. Salieri quickly impressed the Emperor, and Gassmann was instructed to bring his pupil as often as he wished. This was the beginning of a relationship between monarch and musician that would last until Joseph's death in 1790. Salieri met Pietro Antonio Domenico Trapassi, better known as Metastasio and Christoph Willibald Gluck during this period at the famous Sunday morning salons held at the home of the Martinez family. Here Metastasio had an apartment and participated in the weekly gatherings. Over the next several years Metastasio gave Salieri informal instruction in prosody and the declamation of Italian poetry, and Gluck became an informal advisor, friend and confidante. It was toward the end of this extended period of study that Gassmann was called away on a new opera commission and a gap in the theater's program allowed for Salieri to make his debut as a composer of a completely original opera buffa. Salieri's first full opera was composed during the winter and carnival season of 1770; "Le donne letterate" and was based on Molière's "Les Femmes Savantes" ("The Learned Ladies") with a libretto by Giovanni Gastone Boccherini, a dancer in the court ballet and a brother of the famous composer Luigi Boccherini. The modest success of this opera would launch Salieri's 34-year operatic career as a composer of over 35 original dramas.
Early Viennese period and operas (1770–1778).
Following the modest success of "Le donne letterate" Salieri received new commissions writing two additional operas in 1770 both with libretti by Boccherini. The first a pastoral opera, "L'amore innocente" ("Innocent Love") was a light hearted comedy set in the Austrian mountains, and the second was based on an episode from Cervantes "Don Quixote" – "Don Chisciotte alle nozze di Gamace" ("Don Quixote at the Marriage of Camacho"). In these first works, drawn mostly from the traditions of mid-century opera buffa, Salieri showed a penchant for experimentation and for mixing the established characteristics of specific operatic genres. Don Chisciotte was a mix of ballet and opera buffa, and the lead female roles in "L'amore innocente" were designed to contrast and highlight the different traditions of operatic writing for soprano, even borrowing stylistic flourishes from opera-seria in the use of coloratura in what was a short pastoral comedy more in keeping with a Roman Intermezzo. The mixing and pushing against the boundaries of established operatic genres would be a continuing hallmark of Salieri's own personal style, and in his choice of material for the plot (as in his first opera), he manifested a lifelong interest in subjects drawn from classic drama and literature.
Salieri's first great success was in the realm of serious opera. Commissioned for an unknown occasion Salieri's "Armida" was based on Torquato Tasso's epic poem "La Gerusalemme liberata" ("Jerusalem Delivered") and premiered on 2 June 1771. "Armida" is a tale of love and duty in conflict and is saturated in magic. The opera is set during the First Crusade and it features a dramatic mix of ballet, aria, ensemble and choral writing combining theatricality, scenic splendor and high emotionalism. The work clearly followed in Gluck's footsteps and embraced his reform of serious opera begun with "Orfeo ed Euridice" and "Alceste". The libretto to "Armida" was by Marco Coltellini the house poet for the imperial theaters. While Salieri followed the precepts set forth by Gluck and his librettist Ranieri de' Calzabigi in the preface to "Alceste"; Salieri also drew on some musical ideas from the more traditional opera-seria and even opera buffa, creating a new synthesis in the process. "Armida" was translated into German and widely performed, especially in the northern German states, where it helped to establish Salieri's reputation as an important and innovative modern composer It would also be the first opera to receive a serious preparation in a piano and vocal reduction by Carl Friedrich Cramer in 1783.
"Armida" was soon followed by Salieri's first truly popular success; a commedia per musica in the style of Carlo Goldoni "La fiera di Venezia" ("The Fair of Venice"). "La fiera" was written for Carnival in 1772 and premiered on 29 January. Here Salieri returned to his collaboration with the young Boccherini who crafted an original plot. "La fiera" would feature characters singing in three languages, a bustling portrayal of the Ascension-tide Fair and Carnival in Venice, and large and lengthy ensembles and choruses. It also included an innovative scene that would combine a series of on stage dances with singing from both solo protagonists and the chorus. A pattern to be imitated by later composers, most famously and successfully by Wolfgang Amadeus Mozart in "Don Giovanni". Salieri would also write several bravura arias for a soprano playing the part of a middle class character that would combine coloratura and concertante woodwind solos, another innovation for a comic opera that was to be widely imitated.
Salieri's next two operas were not particular or lasting successes, of the two only "La secchia rapita" ("The Stolen Bucket"), deserves mention. A parody of Metastasian opera-seria it featured dazzling parodies of the high flown and emotive arias found in that genre, as well as bold and innovative orchestrations, including the first known use of three tympani. Again a classic of Renaissance literature was the basis of the libretto by Boccherini, in this case a comic mock-epic by Tassoni, in which a war between Modena and Bologna ensues over a stolen bucket. This uneven work was followed by another popular comedic success "La locandiera" ("Mine Hostess"), an adaptation of the classic and popular spoken stage comedy "La locandiera" by Carlo Goldoni, the libretto was prepared by Domenico Poggi.
The majority of Salieri's modest number of instrumental works also date from this time. Salieri's instrumental works have been judged by various critics and scholars to lack the inspiration and innovation found in his writing for the stage. These orchestral works are mainly in the galant style, and although they show some development toward the late classical, they reflect a general weakness in comparison to his operatic works of the same and later periods. These works were written for mostly unknown occasions and artists. They include two concertos for pianoforte, one in C major and one in B flat major (both 1773); a concerto for organ in C Major in two movements, (the middle movement is missing from the autograph score, or perhaps, it was an improvised organ solo) (also 1773); two concertante works: a concerto for oboe, violin and cello in D major (1770), and a flute and oboe concerto in C major (1774). These works are among the most frequently recorded of Salieri's compositions.
Upon Gassmann's death on 21 January, most likely due to complications from an accident with a carriage some years earlier, Salieri succeeded him as assistant director of the Italian opera in early 1774. In 1775 Salieri married Therese Helferstorfer on 10 October, she was the daughter of a recently deceased financier and official of the court treasury. Sacred music was not a high priority for the composer during this stage of his career, but he did compose an Alleluia for chorus and orchestra in 1774.
During the next three years Salieri was primarily concerned with rehearsing and conducting the Italian opera company in Vienna and teaching. His three complete operas written during this time show the development of his compositional skills, but included no great success, either commercially, or artistically. His most important compositions during this period were a symphony in D major, performed in the summer of 1776, and the oratorio "La passione di Gesù Cristo" with a text by Metastasio performed during Advent of 1776.
After the financial collapse of the Italian opera company in 1777 due to financial mis-management, Joseph II decided to end the performance of Italian opera, French spoken drama, and ballet. Instead, the two court-owned theaters would be reopened under new management, and partly subsidized by the Imperial Court, as a new National Theater. The re-launched theaters would promote German language plays and musical productions that reflected Austrian (or as Joseph II would have said) German values, traditions and outlook. The Italian opera buffa company was therefore replaced by a German language Singspiel troupe. For Joseph and his supports of Imperial reform, besides encouraging any first buddings of pan-national pride that would unite his multi-lingual and ethnic subjects under one common language; they also hoped to save a considerable amount of money in the process. Beginning in 1778 Emperor wished to have new works, in German, composed by his own subjects and brought on the stage with clear Imperial support. This in effect left Salieri's role as assistant court composer in a much reduced position. Salieri also had never truly mastered the German language, and he now felt no longer competent to continue as assistant opera director. A further blow to his career was landed when the spoken drama and musical Singspiel were placed on an equal footing. For the young composer there would be few, if any, new compositional commissions to receive from the court. Salieri was left with few financial options and he began casting about for new opportunities.
Italian tour (1778–1780).
However, in 1778 Gluck turned down an offer to compose the inaugural opera for La Scala in Milan; upon the suggestion of Joseph II and with the approval of Gluck, Salieri was offered the commission, which he gratefully accepted. Joseph II granted Salieri permission to take a year-long leave of absence (later extended) thus enabling him to write for La Scala and to undertake a tour of Italy. Salieri's Italian tour of 1778–80 began with the production of "Europa riconosciuta" ("Europa Recognized") for La Scala (which was revived in 2004 for the same opera house's re-opening following extensive renovations). From Milan Salieri included stops in Venice and Rome and finally a return to Milan. During this tour he wrote three new comic operas and he also collaborated with Giacomo Rust on one opera, "Il Talismano" ("The Talisman"). Of his Italian works one, "La scuola de' gelosi" ("The School for Jealousy"), a witty study of amorous intrigue and emotion, would prove a popular and lasting international success.
Middle Viennese period and Parisian operas (1780–1788).
Upon his return at imperial behest to Vienna in 1780, he wrote one German singspiel "Der Rauchfangkehrer" or ("The Chimney Sweep") which premiered in 1781. Salieri's "Chimney Sweep" and Mozart's work for the same company in 1782, "Die Entführung aus dem Serail" ("The Abduction from the Seraglio") would be the only two major successes to emerge from the German singspiel experiment, and only Mozart's opera would survive on the stage beyond the close of the 18th century. In 1783 the Italian opera company was revived with singers partly chosen and vetted by Salieri during his Italian tour, the new season would open with a slightly re-worked version of Salieri's recent success "La scuola de' gelosi". Salieri then returned to his rounds of rehearsing, composition and teaching. However, his time at home in Vienna would be quickly brought to a close when an opportunity to write an opera for Paris arose, again through the patronage of Gluck Salieri traveled abroad to fulfill an important commission.
The opera "Les Danaïdes" ("The Danaids") is a five-act tragédie lyrique; the plot was based on an ancient Greek legend that had been the basis for the first play in a trilogy by Aeschylus, entitled "The Suppliants". The original commission that reached Salieri in 1783–84 was to assist Gluck in finishing a work for Paris that had been all but completed; in reality, Gluck had failed to notate any of the score for the new opera and gave the entire project over to his young friend. Gluck feared that the Parisian critics would denounce the opera by a young composer known mostly for comic pieces and so the opera was originally billed in the press as being a new work by Gluck with some assistance from Salieri, then shortly before the premiere of the opera the Parisian press reported that the work was to be partly by Gluck and partly by Salieri, and finally after popular and critical success were won on stage the opera was acknowledged in a letter to the public by Gluck as being wholly by the young Salieri. "Les Danaïdes" was received with great acclaim and its popularity with audiences and critics alike produced several further requests for new works for Paris audiences by Salieri. "Les Danaïdes" followed in the tradition of reform that Gluck had begun in the 1760s and that Salieri had emulated in his earlier opera "Armida". Salieri's first French opera contained scenes of great solemnity and festivity; yet overshadowing it all was darkness and revenge. The opera depicted politically motivated murder, filial duty and love in conflict, tyrannicide and finally eternal damnation. The opera with its dark overture, lavish choral writing, many ballet scenes, and electrifying finale depicting a glimpse of hellish torture kept the opera on the stage in Paris for over forty years. A young Hector Berlioz recorded the deep impression this work made on him in his "Mémoires".
Upon returning to Vienna following his success in Paris, Salieri met and befriended Lorenzo Da Ponte and had his first professional encounters with Mozart. Da Ponte would write his first opera libretto for Salieri, "Il ricco d'un giorno" ("A Rich Man for a Day") in 1784, it was not a success. Salieri next turned to Giambattista Casti as a librettist, a more successful set of collaboration flowed from this pairing. In the mean time Da Ponte would begin work with Mozart on "Le nozze di Figaro" ("The Marriage of Figaro"). (For the famous relationship between Mozart and Salieri please see below.) Salieri soon produced one of his greatest works with the text by Casti "La grotta di Trofonio" ("The Cave of Trophonius") in 1785, the first opera buffa published in full score by Artaria. Shortly after this success Joseph II had Mozart and Salieri each contribute a one-act opera and/or singspiel for production at a banquet in 1786. Salieri collaborated with Casti to produce a parody of the relationship between poet and composer in "Prima la musica e poi le parole" ("First the Music and then the Words"). This short work also highlighted the typical backstage antics of two high flown sopranos. Salieri then returned to Paris for the premiere of his tragédie lyrique "Les Horaces" ("The Horatii") which proved a failure. However the failure of this work was more than made up for with his next Parisian opera "Tarare" with a libretto by Beaumarchais. This was intended to be the "" of reform opera, a completely new synthesis of poetry and music that was an 18th-century anticipation of the ideals of Richard Wagner. He also created a sacred cantata "Le Jugement dernier" ("The Last Judgement"). The success of his opera "Tarare" was such that it was soon translated into Italian at Joseph II's behest by Lorenzo Da Ponte as "Axur, Re d'Ormus" ("Axur, King of Hormuz") and staged at the royal wedding of Franz II in 1788.
Late Viennese operas (1788–1804).
In 1788 Salieri returned to Vienna, where he remained for the rest of his life. In that year he became Kapellmeister of the Imperial Chapel upon the death of Giuseppe Bonno; as Kapellmeister he conducted the music and musical school connected with the chapel until shortly before his death, being official retired from the post in 1824.
His Italian adaptation of "Tarare", "Axur" would prove to be his greatest international success. "Axur" was widely produced throughout Europe and it even reached South America with the exiled royal house of Portugal in 1824. "Axur" and his other new compositions completed by 1792 would mark the height of Salieri's popularity and his influence. Just as his apogee of fame was being reached abroad, his influence in Vienna would begin to diminish with the death of Joseph II in 1790. Joseph's death deprived Salieri of his greatest patron and protector. During this period of imperial change in Vienna and revolutionary ferment in France, Salieri composed two additional extremely innovative musical dramas to libretti by Giovanni Casti. Due, however, to their satiric and overtly liberal political inclinations, both operas were seen as unsuitable for public performance in the politically reactive cultures of Leopold II and later Francis II. This resulted in two of his most original operas being consigned to his desk drawer, namely "Cublai, gran kan de' Tartari" ("Kublai Grand Kahn of Tartary") a satire on the autocracy and court intrigues at the court of the Russian Czarina, Catherine the Great, and "Catilina" a semi-comic-semi-tragic account of the Catiline conspiracy that attempted to overthrow the Roman republic during the consulship of Cicero. These operas were composed in 1787 and 1792 respectively. Two other operas of little success and longterm importance were composed in 1789, and one great popular success "La cifra" ("The Cipher").
As Salieri's political position became very insecure he was retired as director of the Italian opera in 1792. He continued to write new operas per imperial contract until 1804, when he voluntarily withdrew from the stage. Of his late works for the stage only two works gained wide popular esteem during his life, "Palmira, regina di Persia" ("Palmira, Queen of Persia") 1795 and "Cesare in Farmacusa" ("Caesar on Pharmacusa"), both drawing on the heroic and exotic success established with "Axur". His late opera based on William Shakespeare's "The Merry Wives of Windsor", "Falstaff ossia Le tre burle" ("Falstaff, or the Three Tricks"), (1799) has found a wider audience in modern times than its original reception promised. His last opera was a German language singspiel "Die Neger", ("The Negroes"), a melodrama set in colonial Virginia with a text by Georg Friedrich Treitschke (the author of the libretto for Beethoven's "Fidelio") performed in 1804 and was a complete failure.
Life after opera (1804–1825).
When Salieri retired from the stage, he recognized that artistic styles had changed and he felt that he no longer had the creative capacity to adapt or the emotional desire to continue. Also as Salieri aged he moved slowly away from his more liberal political stances as he saw the enlightened reform of Joseph II's reign, and the hoped for reforms of the French revolution, replaced with more radical revolutionary ideas. As the political situation threatened and eventually overwhelmed Austria, which was repeatedly crushed by French political forces, Salieri's first and most important biographer Mosel described the emotional effect that this political, social, and cultural upheaval had on the composer. Mosel noted that these radical changes, especially the invasion and defeat of Austria, and the occupation of Vienna intertwined with the personal losses that struck Salieri in the same period led to his withdrawal from operatic work. Related to this Mosel quotes the aged composer concerning the radical changes in musical taste that were underway in the age of Beethoven, "From that period 1800 I realized that musical taste was gradually changing in a manner completely contrary to that of my own times. Eccentricity and confusion of genres replaced reasoned and masterful simplicity."
As his teaching and work with the imperial chapel continued, his duties required the composition of a large number of sacred works, and in his last years it was almost exclusively in religious works and teaching that Salieri occupied himself. Among his compositions written for the chapels needs were two complete sets of vespers, many graduals, offertories, and four orchestral masses. During this period he lost his only son in 1805 and his wife in 1807.
Salieri continued to conduct publicly (including the performance of Haydn's "The Creation", during which Haydn collapsed, and several premiers by Beethoven including the 1st and 2nd Piano Concertos and "Wellington's Victory"). He also continued to help administer several charities and organize their musical events.
His remaining secular works in this late period fall into three categories: first, large scale cantatas and one oratorio "Habsburg" written on patriotic themes or in response to the international political situation, pedagogical works written to aid his students in voice, and finally simple songs, rounds or canons written for home entertainment; many with original poetry by the composer. He also composed one large scale instrumental work in 1815 intended as a study in late classical orchestration: Twenty-Six Variations for the Orchestra on a Theme called La Folia di Spagna. The theme is likely folk derived and is known as "La Folía". This simple melodic and harmonic progression had served as an inspiration for many baroque composers, and would be used by later romantic and post-romantic composers. Salieri's setting is a brooding work in the minor key, which rarely moves far from the original melodic material, its main interest lies in the deft and varied handling of orchestral colors. "La Folia" was the most monumental set of orchestral variations before Brahms' "Variations on a Theme by Haydn".
His teaching of budding young musicians continued, and among his pupils in composition (usually vocal) were Ludwig van Beethoven, Antonio Casimir Cartellieri, Franz Liszt, Franz Schubert and many other luminaries of the early Romantic period. He also instructed many prominent singers throughout his long career, including Caterina Canzi. All but the wealthiest of his pupils received their lessons for free, a tribute to the kindness Gassmann had shown Salieri as a penniless orphan.
Salieri was committed to medical care and suffered dementia for the last year and a half of his life. He died in Vienna on 7 May 1825, and was buried in the Matzleinsdorfer Friedhof on 10 May. At his memorial service on 22 June 1825 his own Requiem in C minor – composed in 1804 – was performed for the first time. His remains were later transferred to the Zentralfriedhof. His monument is adorned by a poem written by Joseph Weigl, one of his pupils:
Works.
Opera.
During his time in Vienna, Salieri acquired great prestige as a composer and conductor, particularly of opera, but also of chamber and sacred music. Among the most successful of his 37 operas staged during his lifetime were "Armida" (1771), "La fiera di Venezia" (1772), "La scuola de' gelosi" (1778), "Der Rauchfangkehrer" (1781), "Les Danaïdes" (1784), which was first presented as a work of Gluck's, "La grotta di Trofonio" (1785), "Tarare" (1787) ("Tarare" was reworked and revised several times as was "Les Danaïdes" ), "Axur, re d'Ormus" (1788), "La cifra" (1789), "Palmira, regina di Persia" (1795), "Il mondo alla rovescia" (1795), "Falstaff" (1799), and "Cesare in Farmacusa" (1800).
Sacred works.
Salieri's earliest surviving work is a Mass in C major. He would write four major orchestral masses, a requiem, and many offertories, graduals, vesper settings, and sacred cantatas and oratorios. Much of his sacred music dates from after his appointment as Hofkapellmeister in 1788.
Instrumental works.
His small instrumental output includes two piano concerti, a concerto for organ written in 1773, a concerto for flute, oboe and orchestra (1774), a triple concerto for oboe, violin and cello, and a set of twenty-six variations on "La follia di Spagna" (1815).
Interaction with Mozart.
In the 1780s, while Mozart lived and worked in Vienna, he and his father Leopold wrote in their letters that several "cabals" of Italians led by Salieri were actively putting obstacles in the way of Mozart's obtaining certain posts or staging his operas. For example, Mozart wrote in December 1781 to his father that "the only one who counts in Emperor's eyes is Salieri". Their letters suggest that both Mozart and his father, being Germans who resented the special place that Italian composers had in the courts of the Austrian princes, blamed the Italians in general and Salieri in particular for all of Mozart's difficulties in establishing himself in Vienna. Mozart wrote to his father in May 1783 about Salieri and Lorenzo Da Ponte, the court poet: "You know those Italian gentlemen; they are very nice to your face! Enough, we all know about them. And if Ponte is in league with Salieri, I'll never get a text from him, and I would love to show here what I can really do with an Italian opera." In July 1783 Mozart wrote to his father of "a trick of Salieri's", one of several letters in which he accused Salieri of trickery. Decades after Mozart's death, a rumour began to circulate that Mozart had been poisoned by Salieri. This rumour has been attributed by some to a rivalry between the German and the Italian schools of music. Carl Maria von Weber, a relative of Mozart by marriage whom Wagner has characterized as the most German of German composers, is said to have refused to join Ludlams-Höhle, a social club of which Salieri was a member and avoided having anything to do with him. These rumours then made their way into popular culture. Albert Lortzing's "Singspiel" "Szenen aus Mozarts Leben" LoWV28 (1832) uses the cliché of the jealous Salieri trying to hinder Mozart's career.
Ironically, Salieri's music was much more in the tradition of Gluck and Gassmann than of the Italians like Paisiello or Cimarosa. In 1772, Empress Maria Theresa commented on her preference of Italian composers over Germans like Gassmann, Salieri or Gluck. While Italian by birth, Salieri had lived in imperial Vienna for almost 60 years and was regarded by such people as the music critic Friedrich Rochlitz as a German composer.
The biographer Alexander Wheelock Thayer believes that Mozart's rivalry with Salieri could have originated with an incident in 1781, when Mozart applied to be the music teacher of Princess Elisabeth of Württemberg, and Salieri was selected instead because of his reputation as a singing teacher. In the following year Mozart once again failed to be selected as the Princess' piano teacher. "Salieri and his tribe will move heaven and earth to put it down", Leopold Mozart wrote to his daughter Nannerl. But at the time of the premiere of "Figaro", Salieri was busy with his new French opera "Les Horaces". In addition, when Lorenzo Da Ponte was in Prague preparing the production of Mozart's setting of his "Don Giovanni", the poet was ordered back to Vienna for a royal wedding for which Salieri's "Axur, re d'Ormus" would be performed. Obviously, Mozart was not pleased by this.
However, even with Mozart and Salieri's rivalry for certain jobs, there is very little evidence that the relationship between the two composers was at all acrimonious beyond this, especially after 1785 or so, when Mozart had become established in Vienna. Rather, they appeared to usually see each other as friends and colleagues, and supported each other's work. For example, when Salieri was appointed Kapellmeister in 1788, he revived "Figaro" instead of bringing out a new opera of his own, and when he went to the coronation festivities for Leopold II in 1790, Salieri had no fewer than three Mozart masses in his luggage. Salieri and Mozart even composed a cantata for voice and piano together, called "Per la ricuperata salute di Ophelia," which celebrated the return to stage of the singer Nancy Storace. This work, although it had been printed by Artaria in 1785, was considered lost until the 10th of January 2016, when the "Schwäbische Zeitung" reported on the discovery, by musicologist and composer Timo Jouko Herrmann, of a copy of its text and music while doing research on Antonio Salieri in the collections of the Czech Museum of Music. Mozart's "Davide penitente" (1785), his Piano Concerto KV 482 (1785), the Clarinet Quintet (1789) and the 40th Symphony (1788) had been premiered on the suggestion of Salieri, who supposedly conducted a performance of it in 1791. In his last surviving letter from 14 October 1791, Mozart tells his wife that he collected Salieri and Caterina Cavalieri in his carriage and drove them both to the opera; about Salieri's attendance at his opera "The Magic Flute", speaking enthusiastically: "He heard and saw with all his attention, and from the overture to the last choir there was not a piece that didn't elicit a 'Bravo!' or 'Bello!' out of him [...]."
Salieri, along with Mozart's protégé J. N. Hummel, educated Mozart's younger son Franz Xaver Mozart, who was born in the year his father died.
Legacy.
Salierli and his music were largely forgotten from the 19th century until the late 20th century. This revival was due to the dramatic and highly fictionalized depiction of Salieri in Peter Shaffer's play "Amadeus" (1979), which was given its greatest exposure in its 1984 film version, directed by Miloš Forman. His music today has regained some modest popularity via recordings. It is also the subject of increasing academic study, and a small number of his operas have returned to the stage. In addition, there is now a Salieri Opera Festival sponsored by the Fondazione Culturale Antonio Salieri and dedicated to rediscovering his work and those of his contemporaries. It is developing as an annual autumn event in his native town of Legnago, where a theatre has been renamed in his honour.
Modern performances of Salieri's work.
In 2003, mezzo-soprano Cecilia Bartoli released "The Salieri Album", a CD with 13 arias from Salieri's operas, most of which had never been recorded before. Patrice Michaels sang a number of his arias on the CD "Divas of Mozart's Day". In 2008, another female opera star, Diana Damrau, released a CD with seven Salieri coloratura arias. Since 2000, there have also been complete recordings issued or re-issued of the operas "Axur Re d'Ormus", "Falstaff", "Les Danaïdes", "La Locandiera", "La grotta di Trofonio", "Prima la musica e poi le parole" and "Il mondo alla rovescia". Salieri has yet to fully re-enter the general repertory, but performances of his works are progressively becoming more regular.
His operas "Falstaff" (1995 production) and "Tarare" (1987 production) have been released on DVD. In 2004, the opera "Europa riconosciuta" was staged in Milan for the reopening of La Scala in Milan, with soprano Diana Damrau in the title role. This production was also broadcast on television.
In November 2009 at the Teatro Salieri in Legnago occurred the first staging in modern times of his opera "Il mondo alla rovescia", a co-production between the Fondazione Culturale Antonio Salieri and the Fondazione Arena di Verona for the Salieri Opera Festival.
Use of music by Salieri in films.
Salieri has even begun to attract some attention from Hollywood. In 2001, his triple concerto was used in the soundtrack of "The Last Castle", featuring Robert Redford and James Gandolfini. It is a story that builds on the rivalry between a meticulous but untested officer (Gandolfini) serving as the warden of a military prison and an imprisoned but much admired and highly decorated general (Redford). The Salieri piece is used as the warden's theme music, seemingly to invoke the image of jealousy of the inferior for his superior. In 2006, the movie "Copying Beethoven" referred to Salieri in a more positive light. In this movie a young female music student hired by Beethoven to copy out his Ninth Symphony is staying at a monastery. The abbess tries to discourage her from working with the irreverent Beethoven. She notes that she too once had dreams, having come to Vienna to study opera singing with Salieri. The 2008 film "Iron Man" used the Larghetto movement from Salieri's Piano Concerto in C major. The scene where Obadiah Stane, the archrival of Tony Stark, the wealthy industrialist turned Iron Man, tells Tony that he is being ousted from his company by the board, Obadiah plays the opening few bars of the Salieri concerto on a piano in Stark's suite.
Fictional treatments.
Salieri's life, and especially his relationship with Mozart, has been a subject of many stories, in a variety of media. 
References.
Notes
Cited sources
Further reading
External links.
Scores

</doc>
<doc id="2244" url="https://en.wikipedia.org/wiki?curid=2244" title="Cobble Hill Tunnel">
Cobble Hill Tunnel

The Cobble Hill Tunnel (popularly the Atlantic Avenue Tunnel) of the Long Island Rail Road (LIRR) is an abandoned railroad tunnel beneath Atlantic Avenue in downtown Brooklyn, New York City. When open, it ran for about between Columbia Street and Boerum Place. It is the oldest railway tunnel beneath a city street in North America that was fully devoted to rail.
Construction and operation.
Construction began in May 1844. The tunnel opened for use on December 3, 1844, but was not completely finished until late Spring 1845. It was built mainly to satisfy public demand for creation of a grade-separated right of way for the Brooklyn and Jamaica Railroad (later Long Island Rail Road) on its way to the South Ferry at the foot of Atlantic Street (later Atlantic Avenue), where passengers could catch ferries to Manhattan. The construction of the tunnel also lowered the LIRR's grade through Cobble Hill.
In exchange for building the tunnel, the City of Brooklyn granted the B&J permission to operate its steam locomotives on Atlantic Street west of Fifth Avenue (then Parmentier's Garden/Gowanus Lane), all the way to Brooklyn's South Ferry (the present location of Brooklyn's Pier 7). Prior to the tunnel being built, the LIRR's western terminus was Atlantic Street at Clinton Street. Train cars were hauled by teams of horses along Atlantic Street from Clinton Street to Parmentier's Garden, where steam locomotives were attached. While the tunnel was being built, the railroad operated to a temporary terminal at Pacific Street and Henry Street.
The Cobble Hill Tunnel was part of the first rail link between New York City and Boston, Massachusetts. The railroad connected Lower Manhattan via the South Ferry to Greenport on the North Fork of Long Island, where a ferry connected to Stonington, Connecticut, where a rail link continued to Boston. This avoided some difficult construction of bridges over the rivers of southern Connecticut. In 1848, the New York and New Haven Railroad Line was completed through Connecticut, providing a direct, faster rail connection from New York City to Boston. The Cobble Hill Tunnel and the Long Island Railroad remained the primary means of access to most of central Long Island from Manhattan and New York City. As built, the tunnel was wide, high and long.
Insofar as it carried railroad trains under a city street, some have claimed it be the world's first subway tunnel, although unlike in current rapid transit subway systems, it had no stations. The ends of the tunnel were sealed in the fall of 1861. The similar Murray Hill Tunnel on the New York and Harlem Railroad was built as an open cut around 1836, roofed over around the 1850s, and is in use for automobile traffic.
Closure controversy.
In 1861, the New York State Legislature voted to ban railroad locomotives from within the limits of the City of Brooklyn. A tax assessment was ordered on all property owners along Atlantic Street (today Atlantic Avenue), to defray the costs of the closure. It was undisclosed at the time that New York State Governor John A. King was a major shareholder in the Brooklyn and Jamaica Railroad (later the Long Island Rail Road) and therefore had a conflict of interest and stood to benefit by the compensation payments to the railroad from the tax assessment.
Dormancy.
Walt Whitman wrote of the tunnel:
In March 1916, the Bureau of Investigation suspected German terrorists were making bombs in the tunnel, and broke through the roof of the tunnel with jackhammers. They found nothing, installed an electric light, and resealed it. In the 1920s it was rumored used for both mushroom growing and bootleg whiskey stills even though there was no access into the main portion of the tunnel. It became an object of local folklore and legend. In 1936, the New York City Police Department unsuccessfully attempted to enter the tunnel, in order to look for the body of a hoodlum supposedly buried there. In 1941 it was rumored to have been inspected by the federal Works Progress Administration to determine its structural strength, but there is no evidence of this. A few years later, it was once again rumored to have been opened, this time by the FBI, in an unsuccessful search for spies; however, there is no evidence of this. During the late 1950s it was sought by two rail historians, George Horn and Martin Schachne, but they did not gain access to the tunnel itself.
Rediscovery.
Having fallen from public notice, the tunnel was rediscovered in 1981 by then 18-year-old Robert Diamond, who entered from a manhole he located at Atlantic Avenue and Court Street, crawled a distance of underground through a filled-in section of tunnel less than two feet high, and located the bulkhead wall that sealed off the main portion of the tunnel. With the assistance of a Brooklyn Union Gas Co. (now National Grid) engineering crew, he then broke through the massive concrete bulkhead wall, which is several feet thick. Diamond thereby opened access to the main portion of the tunnel, and began to popularize the tunnel as an antiquity. He led tours of its interior from 1982 until December 17, 2010, when the Department of Transportation terminated his contract, citing safety concerns. The tunnel has been listed on the National Register of Historic Places since 1989.
The History Channel series "Cities of the Underworld" ran a segment ("New York's Secret Societies") on the tunnel in Fall 2008. The TV show "Treasure Hunters" used it in an episode.
References.
Notes
Further reading

</doc>
<doc id="2245" url="https://en.wikipedia.org/wiki?curid=2245" title="Annapolis Valley">
Annapolis Valley

The Annapolis Valley is a valley and region in the Canadian province of Nova Scotia. It is located in the western part of the Nova Scotia peninsula, formed by a trough between two parallel mountain ranges along the shore of the Bay of Fundy. Statistics Canada defines the Annapolis Valley as an economic region, composed of Annapolis County, Kings County, and Hants County.
Geography.
The valley measures approximately in length from Digby and the Annapolis Basin in the west to Wolfville and the Minas Basin in the east, spanning the counties of Digby, Annapolis and Kings.
Some also include the western part of Hants County, including the towns of Hantsport and Windsor even further to the east, but geographically speaking they are part of the Avon River valley.
The steep face of basaltic North Mountain shelters the valley from the adjacent Bay of Fundy and rises over in elevation near Lawrencetown. The granitic South Mountain rises to a somewhat higher elevation and shelters the valley from the climate of the Atlantic Ocean approximately 100 kilometres further south on the province's South Shore.
The shelter provided by these two mountainous ridges has produced a "micro climate" which provides relatively mild temperatures for the region and, coupled with the fertile glacial sedimentary soils on the valley floor, the region is conducive to growing vegetable and fruit crops. Particularly famous for its apple crop, the valley hosts in excess of 1,000 farms of various types, the majority being relatively small family-owned operations.
Within the valley itself are two "major" rivers, the Annapolis River which flows west from the Caribou Bog in the central part of the valley into the Annapolis Basin, and the Cornwallis River which flows east from Caribou Bog into the Minas Basin. The North Mountain ridge forms the north side of the Annapolis Valley. Also flowing east, in two smaller valleys north of the Cornwallis River, are the Canard River and the Habitant River, both of which also flow into the Minas Basin.
History.
Long settled by the Mi'kmaq Nation, the valley experienced French settlement at the Habitation at Port-Royal, near modern-day Annapolis Royal in the western part of the valley, beginning in 1605. From there, the Acadians spread throughout the Valley, in various communities, building dykes to claim the tidal lands along the Annapolis and Cornwallis Rivers. They continued throughout the Annapolis Valley until the British-ordered expulsion of Acadians in 1755 which is memorialized at Grand Pré in the eastern part of the valley. New England Planters moved in to occupy the abandoned Acadian farming areas and the region also saw subsequent settlement by Loyalist refugees of the American Revolutionary War, as well as foreign Protestants. These were followed by significant numbers of freed Africans in the War of 1812, Irish immigrants in the mid-19th century and Dutch immigrants after World War II. Agriculture in the Annapolis valley boomed in the late 19th century with the arrival of the Windsor and Annapolis Railway, later the Dominion Atlantic Railway, which developed large export markets for Annapolis Valley apples.
Economy.
The Valley has been traditionally been built on a diversified agricultural industry, with a wide range of output ranging from livestock to fruit trees and berries. The last quarter century has also seen the development of a wine industry, with such notable wineries as Gaspereau Vineyards winning national and international awards for their produce.
Today, the Valley is still largely dominated by agriculture but also has a growing diversity in its economies, partly aided by the importance of post-secondary education centres provided by Acadia University in Wolfville, and the Nova Scotia Community College campuses located in Kentville, Middleton, Lawrencetown, and Digby.
Michelin has an important truck tire manufacturing plant in Waterville and the Department of National Defence has its largest air force base in Atlantic Canada located at CFB Greenwood along with an important training facility at Camp Aldershot, near Kentville.
Tourism is also an important industry and the Annapolis Valley is known for its scenic farmland, although today some is threatened with suburban development in the eastern end, and a great deal has been abandoned. The valley also struggles with pollution from farm runoffs and residential sewers in its two major rivers, the Annapolis River and the Cornwallis River. The Annapolis Valley additionally has become home to the majority of Nova Scotia wineries, located in either the Gaspereau Valley or in the Canning, Grand Pré, or Bear River areas.
The Valley is home to the annual Apple Blossom Festival, held in late spring. In July is the annual Steer Bar-B-Que in Kingston, and Heart of the Valley Festival in Middleton. August sees Mud Creek Days in Wolfville and the Annapolis Valley Exhibition in Lawrencetown. Bridgetown's Cider Festival comes in mid-September. The Canadian Deep Roots Music Festival is held each year at the end of September in Wolfville, a community-based festival, supported by both The Town of Wolfville and Acadia University and built on countless hours of volunteerism by a stable base of over 100 volunteers, and on in-kind and financial support from virtually all sectors of the Valley community. Farmers markets in Annapolis Royal, Bridgetown, Middleton, Kentville, Kingsport, Berwick and Wolfville bring a wealth of fresh produce and other fine goods to the public every week. In the fall the Pumpkin People in Kentville entice the imagination.
Communities.
Communities in the Valley from west to east include:
Bolded communities are major communities

</doc>
<doc id="2246" url="https://en.wikipedia.org/wiki?curid=2246" title="Analgesic">
Analgesic

An analgesic or painkiller is any member of the group of drugs used to achieve analgesia, relief from pain. 
Analgesic drugs act in various ways on the peripheral and central nervous systems. They are distinct from anesthetics, which reversibly eliminate sensation. Analgesics include paracetamol (known in North America as acetaminophen or simply APAP), the non-steroidal anti-inflammatory drugs (NSAIDs) such as the salicylates, and opioid drugs such as morphine and oxycodone.
In choosing analgesics, the severity and response to other medication determines the choice of agent; the World Health Organization (WHO) pain ladder specifies mild analgesics as its first step.
Analgesic choice is also determined by the type of pain: For neuropathic pain, traditional analgesics are less effective, and there is often benefit from classes of drugs that are not normally considered analgesics, such as tricyclic antidepressants and anticonvulsants.
Name.
The word "analgesic" derives from Greek "an-" (, "without"), "álgos" (, "pain"), and "-ikos" (, forming adjectives). Such drugs were usually known as anodynes before the 20th century.
Major classes.
Paracetamol and NSAIDs.
The exact mechanism of action of paracetamol/acetaminophen is uncertain but appears to act centrally in the brain rather than peripherally in nerve endings. Aspirin and the other non-steroidal anti-inflammatory drugs (NSAIDs) inhibit cyclooxygenases, leading to a decrease in prostaglandin production. In contrast to paracetamol and the opioids, this reduces not only pain but inflammation as well.
Paracetamol has few side-effects and is regarded as generally safe in low and infrequent doses as prescribed, or per manufacturer's instructions, otherwise use can lead to potentially life-threatening liver damage and occasionally kidney damage. Side effects include bloody or black, tarry stools, bloody or cloudy urine, fever with or without chills (not present before treatment and not caused by the condition being treated), pain in the lower back and/or side (severe and/or sharp), pinpoint red spots on the skin, skin rash, hives, or itching, sore throat (not present before treatment and not caused by the condition being treated), sores, ulcers, or white spots on the lips or in the mouth, sudden decrease in the amount of urine, unusual bleeding or bruising, unusual tiredness or weakness, yellow eyes or skin.
While paracetamol is usually taken orally or rectally, an intravenous preparation introduced in 2002 has been shown to improve pain relief and reduce opioid consumption in the perioperative setting.
NSAIDs can predispose to in some patients peptic ulcers, renal failure, allergic reactions, and occasionally tinnitus with excess dosage, and they can increase the risk of hemorrhage by affecting platelet function. The use of aspirin in children under 16 suffering from viral illness has been linked to Reye's syndrome, a rare but severe liver disorder.
COX-2 inhibitors.
These drugs have been derived from NSAIDs. The cyclooxygenase enzyme inhibited by NSAIDs was discovered to have at least 2 different versions: COX1 and COX2. Research suggested most of the adverse effects of NSAIDs to be mediated by blocking the COX1 (constitutive) enzyme, with the analgesic effects being mediated by the COX2 (inducible) enzyme. Thus, the COX2 inhibitors were developed to inhibit only the COX2 enzyme (traditional NSAIDs block both versions in general). These drugs (such as rofecoxib, celecoxib, and etoricoxib) are equally effective analgesics when compared with NSAIDs, but cause less gastrointestinal hemorrhage in particular.
After widespread adoption of the COX-2 inhibitors, it was discovered that most of the drugs in this class increase the risk of cardiovascular events by 40% on average. This led to the withdrawal of rofecoxib and valdecoxib, and warnings on others. Etoricoxib seems relatively safe, with the risk of thrombotic events similar to that of non-coxib NSAID diclofenac.
Opioids.
Morphine, the archetypal opioid, and other opioids (e.g., codeine, oxycodone, hydrocodone, dihydromorphine, pethidine) all exert a similar influence on the cerebral opioid receptor system. Buprenorphine is a partial agonist of the μ-opioid receptor, and tramadol is a serotonin norepinephrine reuptake inhibitor (SNRI) with weak μ-opioid receptor agonist properties. Tramadol is structurally closer to venlafaxine than to codeine and delivers analgesia by not only delivering "opioid-like" effects (through mild agonism of the mu receptor) but also by acting as a weak but fast-acting serotonin releasing agent and norepinephrine reuptake inhibitor. Tapentadol, with some structural similarities to tramadol, presents what is believed to be a novel drug working through two (and possibly three) different modes of action in the fashion of both a traditional opioid and as a SNRI. The effects of serotonin and norepinephrine on pain, while not completely understood, have had causal links established and drugs in the SNRI class are commonly used in conjunction with opioids (especially tapentadol and tramadol) with greater success in pain relief. Dosing of all opioids may be limited by opioid toxicity (confusion, respiratory depression, myoclonic jerks and pinpoint pupils), seizures (tramadol), but opioid-tolerant individuals usually have higher dose ceilings than patients without tolerance. 
Opioids, while very effective analgesics, may have some unpleasant side-effects. Patients starting morphine may experience nausea and vomiting (generally relieved by a short course of antiemetics such as phenergan). Pruritus (itching) may require switching to a different opioid. Constipation occurs in almost all patients on opioids, and laxatives (lactulose, macrogol-containing or co-danthramer) are typically co-prescribed.
When used appropriately, opioids and other central analgesics are otherwise safe and effective, however risks such as addiction and the body's becoming used to the drug (tolerance) can occur. The effect of tolerance means that frequent use of the drug may result in its diminished effect so, when safe to do so, the dosage may need to be increased to maintain effectiveness. This may be of particular concern regarding patients suffering with chronic pain. Opioid tolerance is often addressed with "opioid rotation therapy" in which a patient is routinely switched between two or more non-cross-tolerant opioid medications in order to prevent exceeding safe dosages in the attempt to achieve an adequate analgesic effect.
Flupirtine.
Flupirtine is a centrally acting K+ channel opener with weak NMDA antagonist properties. It is used in Europe for moderate to strong pain and migraine and its muscle-relaxant properties. It has no anticholinergic properties and is believed to be devoid of any activity on dopamine, serotonin, or histamine receptors. It is not addictive, and tolerance usually does not develop. However, tolerance may develop in single cases.
Specific agents.
In patients with chronic or neuropathic pain, various other substances may have analgesic properties. Tricyclic antidepressants, especially clomipramine and amitriptyline, have been shown to improve pain in what appears to be a central manner. Nefopam is used in Europe for pain relief with concurrent opioids. The exact mechanism of carbamazepine, gabapentin, and pregabalin is similarly unclear, but these anticonvulsants are used to treat neuropathic pain with differing degrees of success. Anticonvulsants are most commonly used for neuropathic pain as their mechanism of action tends to inhibit pain sensation.
Specific forms and uses.
Combinations.
Analgesics are frequently used in combination, such as the paracetamol and codeine preparations found in many non-prescription pain relievers. They can also be found in combination with vasoconstrictor drugs such as pseudoephedrine for sinus-related preparations, or with antihistamine drugs for allergy sufferers.
While the use of paracetamol, aspirin, ibuprofen, naproxen, and other NSAIDS concurrently with weak to mid-range opiates (up to about the hydrocodone level) has been said to show beneficial synergistic effects by combatting pain at multiple sites of action, several combination analgesic products have been shown to have few efficacy benefits when compared to similar doses of their individual components. Moreover, these combination analgesics can often result in significant adverse events, including accidental overdoses, most often due to confusion that arises from the multiple (and often non-acting) components of these combinations.
Topical or systemic.
Topical analgesia is generally recommended to avoid systemic side-effects. Painful joints, for example, may be treated with an ibuprofen- or diclofenac-containing gel (The labeling for topical diclofenac has been updated to warn about drug-induced hepatotoxicity.); capsaicin also is used topically. Lidocaine, an anesthetic, and steroids may be injected into painful joints for longer-term pain relief. Lidocaine is also used for painful mouth sores and to numb areas for dental work and minor medical procedures. In February 2007 the FDA notified consumers and healthcare professionals of the potential hazards of topical anesthetics entering the blood stream when applied in large doses to the skin without medical supervision. These topical anesthetics contain anesthetic drugs such as lidocaine, tetracaine, benzocaine, and prilocaine in a cream, ointment, or gel.
Psychotropic agents.
Tetrahydrocannabinol (THC) and some other cannabinoids, either from the "Cannabis sativa" plant or synthetic, have analgesic properties, although the use of cannabis derivatives is currently illegal in many countries. A recent study finds that inhaled cannabis is effective in alleviating neuropathy and pain resulting from, e.g., spinal injury and multiple sclerosis.
Other psychotropic analgesic agents include ketamine (an NMDA receptor antagonist), clonidine and other α2-adrenoreceptor agonists, and mexiletine and other local anaesthetic analogues.
Atypical, adjuvant analgesics & potentiators.
Drugs that have been introduced for uses other than analgesics are also used in pain management. Both first-generation (such as amitriptyline) and newer anti-depressants (such as duloxetine) are used alongside NSAIDs and opioids for pain involving nerve damage and similar problems. Other agents directly potentiate the effects of analgesics, such as using hydroxyzine, promethazine, carisoprodol, or tripelennamine to increase the pain-killing ability of a given dose of opioid analgesic.
Adjuvant analgesics, also called atypical analgesics, include nefopam, orphenadrine, pregabalin, gabapentin, cyclobenzaprine, scopolamine, and other drugs possessing anticonvulsant, anticholinergic, and/or antispasmodic properties, as well as many other drugs with CNS actions. These drugs are used along with analgesics to modulate and/or modify the action of opioids when used against pain, especially of neuropathic origin.
Dextromethorphan has been noted to slow the development of tolerance to opioids and exert additional analgesia by acting upon the NMDA receptors; some analgesics such as methadone and ketobemidone and perhaps piritramide have intrinsic NMDA action.
High-alcohol liquor, two forms of which found in the US Pharmacopoeia up until 1916 and in common use by physicians well into the 1930s, has been used in the past as an agent for dulling pain, due to the CNS depressant effects of ethyl alcohol, a notable example being the American Civil War. However, the ability of alcohol to relieve severe pain is likely inferior to many analgesics used today (e.g., morphine, codeine). As such, in general, the idea of alcohol for analgesia is considered a primitive practice in virtually all industrialized countries today.
The use of adjuvant analgesics is an important and growing part of the pain-control field and new discoveries are made practically every year. Many of these drugs combat the side-effects of opioid analgesics, an added bonus. For example, antihistamines including orphenadrine combat the release of histamine caused by many opioids. Stimulants such as methylphenidate, caffeine, ephedrine, dextroamphetamine, methamphetamine, and cocaine work against heavy sedation and may elevate mood in distressed patients as do the antidepressants. The use of medicinal cannabis remains a debated issue.
Novel analgesics.
Some novel and investigational analgesics include subtype-selective voltage-gated sodium channel blockers such as funapide and raxatrigine, as well as multimodal agents such as ralfinamide.

</doc>
<doc id="2250" url="https://en.wikipedia.org/wiki?curid=2250" title="Abiotic stress">
Abiotic stress

Abiotic stress is defined as the negative impact of non-living factors on the living organisms in a specific environment. The non-living variable must influence the environment beyond its normal range of variation to adversely affect the population performance or individual physiology of the organism in a significant way.
Whereas a biotic stress would include such living disturbances as fungi or harmful insects, abiotic stress factors, or stressors, are naturally occurring, often intangible, factors such as intense sunlight or wind that may cause harm to the plants and animals in the area affected. Abiotic stress is essentially unavoidable.
Abiotic stress affects animals, but plants are especially dependent on environmental factors, so it is particularly constraining. Abiotic stress is the most harmful factor concerning the growth and productivity of crops worldwide. Research has also shown that abiotic stressors are at their most harmful when they occur together, in combinations of abiotic stress factors.
Examples.
Abiotic stress comes in many forms. The most common of the stressors are the easiest for people to identify, but there are many other, less recognizable abiotic stress factors which affect environments constantly.
The most basic stressors include: 
Lesser-known stressors generally occur on a smaller scale. They include: poor edaphic conditions like rock content and pH levels, high radiation, compaction, contamination, and other, highly specific conditions like rapid rehydration during seed germination.
Effects.
Abiotic stress, as a natural part of every ecosystem, will affect organisms in a variety of ways. Although these effects may be either beneficial or detrimental, the location of the area is crucial in determining the extent of the impact that abiotic stress will have. The higher the latitude of the area affected, the greater the impact of abiotic stress will be on that area. So, a taiga or boreal forest is at the mercy of whatever abiotic stress factors may come along, while tropical zones are much less susceptible to such stressors.
Benefits.
One example of a situation where abiotic stress plays a constructive role in an ecosystem is in natural wildfires. While they can be a human safety hazard, it is productive for these ecosystems to burn out every once in a while so that new organisms can begin to grow and thrive.
Even though it is healthy for an ecosystem, a wildfire can still be considered an abiotic stressor, because it puts an obvious stress on individual organisms within the area. Every tree that is scorched and each bird nest that is devoured is a sign of the abiotic stress. On the larger scale, though, natural wildfires are positive manifestations of abiotic stress.
What also needs to be taken into account when looking for benefits of abiotic stress, is that one phenomenon may not affect an entire ecosystem in the same way. While a flood will kill most plants living low on the ground in a certain area, if there is rice there, it will thrive in the wet conditions.
Another example of this is in phytoplankton and zooplankton. The same types of conditions are usually considered stressful for these two types of organisms. They act very similarly when exposed to ultraviolet light and most toxins, but at elevated temperatures the phytoplankton reacts negatively, while the thermophilic zooplankton reacts positively to the increase in temperature. The two may be living in the same environment, but an increase in temperature of the area would prove stressful only for one of the organisms.
Lastly, abiotic stress has enabled species to grow, develop, and evolve, furthering natural selection as it picks out the weakest of a group of organisms. Both plants and animals have evolved mechanisms allowing them to survive extremes.
Detriments.
The most obvious detriment concerning abiotic stress involves farming. It has been claimed by one study that abiotic stress causes the most crop loss of any other factor and that most major crops are reduced in their yield by more than 50% from their potential yield.
Because abiotic stress is widely considered a detrimental effect, the research on this branch of the issue is extensive. For more information on the harmful effects of abiotic stress, see the sections below on plants and animals.
In plants.
A plant’s first line of defense against abiotic stress is in its roots. If the soil holding the plant is healthy and biologically diverse, the plant will have a higher chance of surviving stressful conditions.
Facilitation, or the positive interactions between different species of plants, is an intricate web of association in a natural environment. It is how plants work together. In areas of high stress, the level of facilitation is especially high as well. This could possibly be because the plants need a stronger network to survive in a harsher environment, so their interactions between species, such as cross-pollination or mutualistic actions, become more common to cope with the severity of their habitat.
Plants also adapt very differently from one another, even from a plant living in the same area. When a group of different plant species was prompted by a variety of different stress signals, such as drought or cold, each plant responded uniquely. Hardly any of the responses were similar, even though the plants had become accustomed to exactly the same home environment.
Rice ("Oryza sativa") is a classic example. Rice is a staple food throughout the world, especially in China and India. Rice plants experience different types of abiotic stresses, like drought and high salinity. These stress conditions have a negative impact on rice production. Genetic diversity has been studied among several rice varieties with different genotypes using molecular markers.
Serpentine soils (media with low concentrations of nutrients and high concentrations of heavy metals) can be a source of abiotic stress. Initially, the absorption of toxic metal ions is limited by cell membrane exclusion. Ions that are absorbed into tissues are sequestered in cell vacuoles. This sequestration mechanism is facilitated by proteins on the vacuole membrane.
Chemical priming has been proposed to increase tolerance to abiotic stresses in crop plants. In this method, which is analogous to vaccination, stress-inducing chemical agents are introduced to the plant in brief doses so that the plant begins preparing defense mechanisms. Thus, when the abiotic stress occurs, the plant has already prepared defense mechanisms that can be activated faster and increase tolerance. 
In animals.
For animals, the most stressful of all the abiotic stressors is heat. This is because many species are unable to regulate their internal body temperature. Even in the species that are able to regulate their own temperature, it is not always a completely accurate system. Temperature determines metabolic rates, heart rates, and other very important factors within the bodies of animals, so an extreme temperature change can easily distress the animal’s body. Animals can respond to extreme heat, for example, through natural heat acclimation or by burrowing into the ground to find a cooler space.
It is also possible to see in animals that a high genetic diversity is beneficial in providing resiliency against harsh abiotic stressors. This acts as a sort of stock room when a species is plagued by the perils of natural selection. A variety of galling insects are among the most specialized and diverse herbivores on the planet, and their extensive protections against abiotic stress factors have helped the insect in gaining that position of honor.
In endangered species.
Biodiversity is determined by many things, and one of them is abiotic stress. If an environment is highly stressful, biodiversity tends to be low. If abiotic stress does not have a strong presence in an area, the biodiversity will be much higher.
This idea leads into the understanding of how abiotic stress and endangered species are related. It has been observed through a variety of environments that as the level of abiotic stress increases, the number of species decreases. This means that species are more likely to become population threatened, endangered, and even extinct, when and where abiotic stress is especially harsh.

</doc>
<doc id="2251" url="https://en.wikipedia.org/wiki?curid=2251" title="Accusative case">
Accusative case

The accusative case (abbreviated ) of a noun is the grammatical case used to mark the direct object of a transitive verb. The same case is used in many languages for the objects of (some or all) prepositions. It is a noun that is having something done to it, usually used together (such as in Latin) with the nominative case. For example, "they" in English is nominative; "them" is accusative. The sentence "They like them" clearly shows the nominative case and accusative case working in conjunction using the same base word. The syntactic functions of the accusative consist of designating the immediate object of an action, the intended result, the goal of a motion, and the extent of an action.
The accusative case existed in Proto-Indo-European and is present in some Indo-European languages (including Latin, Sanskrit, Greek, German, Polish, Romanian, Russian, Ukrainian), in the Uralic languages, in Altaic languages, and in Semitic languages (such as Hebrew and Classical Arabic). Finnic languages, such as Finnish and Estonian, have two cases to mark objects, the accusative and the partitive case. In morphosyntactic alignment terms, both perform the accusative function, but the accusative object is telic, while the partitive is not.
Modern English, which almost entirely lacks declension in its nouns, does not have an explicitly marked accusative case even in the pronouns. Such forms as "whom", "them", and "her" derive rather from the old Germanic dative forms, of which the -m and -r endings are characteristic. This conflation of the old accusative, dative, instrumental, and (after prepositions) genitive cases is the "oblique case". Most modern English grammarians no longer use the Latin accusative/dative model, though they tend to use the terms "objective" for oblique, "subjective" for nominative, and "possessive" for genitive "(see Declension in English)." "Hine", a true accusative masculine third person singular pronoun, is attested in some northern English dialects as late as the 19th century.
Etymology.
The English name "accusative (case)" is an Anglicisation of the Latin "accūsātīvus" ("cāsus"), which was translated from Ancient Greek αἰτιατικὴ (πτῶσις), "aitiatikē (ptôsis)". The Greek term can mean either "(inflection) for something caused" or "for an accusation". The intended meaning was likely the first, which would be translated as Latin "causātīvus" or "effectīvus", but the Latin term was a translation of the second. Compare Russian вини́тельный "vinítel’nyj", from винить "vinít’" "to blame".
Description.
In the sentence "He sees the woman", "he" is the subject of the sentence, while in "The woman sees him, "him" is the object. In English the two uses are distinguished by different forms of the pronoun: he/him. If, however, instead of a pronoun, we use a noun, we make no such distinction in the form of the word. Thus, we use the same word "man" in both The man sees the woman" and "The woman sees the man". In many languages, however, different forms of the word are used not only for pronouns, but for nouns too. For example, in Latin "The man sees the woman" = "Vir feminam videt", while "The woman sees the man" = "Femina virum videt". For "man", Latin uses "vir" for the subject, and "virum" for the object. Likewise, in the same pair of sentences, we have "femina" for a subject and "feminam" for object. The form used for the direct object ("him", "virum", "feminam") is known as the "accusative case", while the form used for the subject ("he", "vir", "femina") is known as the nominative case.
Just as with pronouns and nouns, many inflected languages also make distinctions between cases in their adjectives and (for languages that have them) articles. Thus in German, "the giant" as the subject of a sentence may be expressed as "der Riese": nominative case. As the object of a verb, this becomes "den Riesen", the accusative.
Examples.
Indo-European languages.
Latin.
In Latin, nouns, adjectives, or pronouns in the accusative case ("accusativus") can be used
For the accusative endings, see Latin declension.
Latin prepositions.
Some Latin prepositions take a noun in the accusative. A few prepositions may take either an accusative or an ablative, in which case the accusative indicates motion, and the ablative indicates no motion. E.g. (ablative) "in casā", "in the cottage"; (accusative) "in casam", "into the cottage".
This "aide-memoire" was taught in schools when Latin was on the curriculum:
"Ante, apud, ad, adversus,"
"Circum, circa, citra, cis,"
"Contra, inter, erga, extra,"
"Infra, intra, iuxta, ob,"
"Penes, pone, post," and "praeter,"
"Prope, propter, per, secundum,"
"Supra, versus, ultra, trans:"
When 'motion' 'tis, not 'state' they mean.**
Or try: ** "And unto these if motion be intended,"
"Let In, Sub, Super, Subter be appended ' '
German.
German uses the accusative to mark direct objects and objects of certain prepositions, or adverbs relating to time. The accusative is only marked for masculine articles, pronouns, adjectives, and weak nouns.
German articles.
The masculine forms for German articles, e.g., "der" ('the'), "ein" ('a/an'), "mein" ('my'), etc., change in the accusative case: they always end in "-en". The article of feminine, neutral and plural forms do not change.
For example, ""Hund"" (dog) is a masculine ("ein/der") word, so the article changes when used in the accusative case:
German pronouns.
Some German pronouns also change in the accusative case.
German prepositions.
The accusative case is also used after particular German prepositions. These include "bis, durch, entlang, für, gegen, ohne, um", after which the accusative case is always used, and "an, auf, hinter, in, neben, über, unter, vor, zwischen" which can govern either the accusative or the dative. The latter prepositions take the accusative when motion or action is specified (being done into/onto the space), but take the dative when location is specified (being done in/on that space). These prepositions are also used in conjunction with certain verbs, in which case it is the verb in question which governs whether the accusative or dative should be used.
German adjectives.
Adjective endings also change in the accusative case. Another factor that determines the endings of adjectives is whether the adjective is being used after a definite article (the), after an indefinite article (a/an) or without any article before the adjective ("many" green apples).
German adverbial use.
In German, the accusative case is also used for some adverbial expressions, mostly temporal ones, as in ""Diesen Abend bleibe ich daheim"" (This evening I'm staying at home), where ""diesen Abend"" is marked as accusative, although not a direct object.
Russian.
In Russian, the accusative is used not only to indicate the direct object of an action, but also to indicate the destination or goal of motion. It is also used with some prepositions. The prepositions "в" and "на" can both take the accusative in situations where they indicate the goal of a motion.
In the masculine, Russian also distinguishes between animate and inanimate nouns with regard to the accusative; only the animates carry a marker in this case.
In fact Russian almost lost the real PIE accusative case, since only singular feminine nouns ending in 'a' have a distinct form. Other words use the genitive case or the nominative case in place of the accusative, depending on their animacy.
Armenian.
While the Armenian dialects both have a de facto accusative case, Eastern Armenian uses an accusative marker for transitive verbs
Example:
գիրք - girkh - book (Nominative)
ուսուցիչ - usuchičh - teacher (Nominative)
Aramë verchrech girkhë
Aram took the book.
Aramë sirum ē ir usuchčhin
Aram loves his teacher.
Greek.
In both Ancient and Modern Greek, nouns, adjectives, verb participles, articles and pronouns are used in the accusative case, when they indicate a direct object or if they are preceded by a preposition. There is a wide variety of accusative markers depending on gender, number and declension. Like in Latin, all neuter names yield the same form in both the nominative and the accusative case in Ancient Greek. In its modern successor, this rule also extends to most feminine nouns, except these ending to -ος.
Example: ""He was also calumniating Socrates.""
Constructed languages.
Esperanto.
Esperanto grammar involves only two cases, a nominative and an accusative. The accusative is formed by the addition of "-n" to the nominative form, and is the case used for direct objects. (Example: "knabo" ("boy") → "knabon" ("boy.ACC")) Other case functions, including dative functions, are achieved with prepositions, all of which normally take the nominative case. Direction of motion can be expressed either by the accusative case, or by the preposition "al" (to) with the nominative.
Ido.
In Ido the "-n" suffix is optional, as subject–verb–object order is assumed when it is not present. Note that this is sometimes done in Esperanto, especially by beginners, but it is considered incorrect while in Ido it is the norm.
Uralic languages.
Finnish.
According to traditional Finnish grammars, the accusative is the case of a total object, while the case of a partial object is the partitive. The negative forms of verbs always take the partial object, whereas in positive sentences it depends on the nature of the action, the main rule being that incomplete or indefinite action requires a partial object.
The accusative singular is identical either to the nominative (often called nominative-accusative) or the genitive (genitive-accusative). In plural, only nominative-accusative exists. The active verb forms usually require the total object in the genitive-accusative and passive forms take the nominative-accusative. The only exceptions to this rule are imperative first and second persons, and the rarely used third infinitive in instructive, which take the total object in nominative-accusative.
The personal pronouns and the personal interrogative pronoun "kuka/ken" have a special accusative form ending in "-t" which is used in place of both nominative-accusative and genitive-accusative. For example, the accusative form of "hän" (he/she) is "hänet", and the accusative form of "kuka" (or "ken") is "kenet".
The major new Finnish grammar, "Iso suomen kielioppi", breaks with the traditional classification by limiting the accusative case to the special case of the personal pronouns and "kuka/ken". The new grammar considers other total objects as being in the nominative or genitive case.
Hungarian.
The accusative case in Hungarian applies to nouns, pronouns; even to adjectives and numerals when either of them stands alone in the sense of direct object.
Accusative is formed by the suffix -t. In many cases, "-t" is preceded by a suffix-initial vowel, primarily based on specific vowel harmony, resulting in "-et", "-ot", or "-öt". The rules are complex, also involve consonants, and have exceptions. Thus: k"e"rt"et" "garden", k"é"k"et" "blue"; h"a"t"o"t "six"; p"o"lc"ot" "shelf"; k"ö"d"öt" "fog".
In some words, a low vowel "a" or "e" appears instead of the expected harmonic vowel: e.g. fal"at" (ˣfal"ot") "wall"; nyolc"at" (ˣnyolc"ot") "eight"; könyv"et" (ˣkönyv"öt") "book".
In fewer cases, the root of the word is also affected. Word endings "-a" or "-e" will (even if they are the endings of a preceding suffix) change to "-á" and "-é", respectively, before "-t". E.g.: f"a" (tree) -> fát. The long vowel of a one-syllable word may get shortened. E.g.: úr (lord) -> "u"rat. But: b"ú"r (Boer) -> b"ú"rt. If a word has more than one syllable and the last syllable ends in a consonant, the vowel of the last syllable may drop. E.g.: köröm (fingernail) -> "körmöt". But: kör"öm" ("my" circle) -> körömet. Notably, the first-person and second-person personal pronouns have quite unique accusative forms (indeed, as indicated in the table, in the singular case the ending "-et" is rather optional, even considered archaic).
Semitic languages.
An ending for accusative case existed in Proto-Semitic, Akkadian, and Ugaritic, but today it is preserved only in literary Arabic and Ge'ez.
Classical Arabic.
In Arabic, the accusative case (also the subjunctive mood) is called النصب "an-naṣb", and a word in the accusative case (also a verb in the subjunctive) is called المنصوب "al-manṣūb", both from the verb نصب "naṣaba" "set up". The accusative is used in 51 places, but mainly to mark the object of a verb and to form adverbs.

</doc>
<doc id="2257" url="https://en.wikipedia.org/wiki?curid=2257" title="Apostolic succession">
Apostolic succession

Apostolic succession is the method whereby the ministry of the Christian Church is held to be derived from the apostles by a continuous succession, which has usually been associated with a claim that the succession is through a series of bishops. This series was seen originally as that of the bishops of a particular see founded by one or more of the apostles. According to historian Justo L. González, apostolic succession is generally understood today as meaning a series of bishops, regardless of see, each consecrated by other bishops, themselves consecrated similarly in a succession going back to the apostles. But, according to documentation produced by the Joint International Commission for Theological Dialogue Between the Catholic Church and the Orthodox Church, the "sees ("cathedra") plays an important role in inserting the bishop into the heart of ecclesial apostolicity".
Those who hold for the importance of apostolic succession via episcopal laying on of hands appeal to the New Testament, which, they say, implies a personal apostolic succession (from Paul to Timothy and Titus, for example). They appeal as well to other documents of the early Church, especially the Epistle of Clement. In this context, Clement explicitly states that the apostles appointed bishops as successors and directed that these bishops should in turn appoint their own successors; given this, such leaders of the Church were not to be removed without cause and not in this way. Further, proponents of the necessity of the personal apostolic succession of bishops within the Church point to the universal practice of the undivided early Church (up to AD 431), before being divided into the Church of the East, Oriental Orthodoxy, the Eastern Orthodox Church and the Catholic Church. Christians of the Roman Catholic, Eastern Orthodox, Old Catholic, Anglican, Moravian, and Scandinavian Lutheran traditions maintain that "a bishop cannot have regular or valid orders unless he has been consecrated in this apostolic succession." Each of these groups does not necessarily consider consecration of the other groups as valid.
However, some Protestants deny the need for this type of continuity, and the historical claims involved have been severely questioned by them; Eric G. Jay comments that the account given of the emergence of the episcopate in chapter III of the encyclical "Lumen Gentium" (1964) "is very sketchy, and many ambiguities in the early history of the Christian ministry are passed over". These denominations, instead, hold that apostolic succession is "understood as a continuity in doctrinal teaching from the time of the apostles to the present."
Various meanings.
Michael Ramsey, an English Anglican bishop and the Archbishop of Canterbury (1961–1974), described three meanings of "apostolic succession":
He adds that this last has been controversial in that it has been claimed that this aspect of the doctrine is not found before the time of Augustine of Hippo, while others allege that it is implicit in the Church of the second and third centuries.
In its 1982 statement on Baptism, Eucharist and Ministry, the Faith and Order Commission of the World Council of Churches stated that "the primary manifestation of apostolic succession is to be found in the apostolic tradition of the Church as a whole... Under the particular historical circumstances of the growing Church in the early centuries, the succession of bishops became one of the ways, together with the transmission of the Gospel and the life of the community, in which the apostolic tradition of the Church was expressed." It spoke of episcopal succession as something that churches that do not have bishops can see "as a sign, though not a guarantee, of the continuity and unity of the Church" and that all churches can see "as a sign of the apostolicity of the life of the whole church".
The Porvoo Common Statement (1996), agreed to by the Anglican churches of the British Isles and most of the Lutheran churches of Scandinavia and the Baltic, also stated that "the continuity signified in the consecration of a bishop to episcopal ministry cannot be divorced from the continuity of life and witness of the diocese to which he is called."
Some Anglicans, in addition to other Protestants, held that apostolic succession "may also be understood as a continuity in doctrinal teaching from the time of the apostles to the present." For example, the British Methodist Conference locates the "true continuity" with the Church of past ages in "the continuity of Christian experience, the fellowship in the gift of the one Spirit; in the continuity in the allegiance to one Lord, the continued proclamation of the message; the continued acceptance of the mission;..."
The teaching of the Second Vatican Council on apostolic succession has been summed up as follows:
In the early Fathers.
According to International Theological Commission (ITC), conflicts could not always be avoided between individuals among the New Testament communities; Paul appealed to his apostolic authority when it conflict? was a disagreement about the Gospel or principles of Christian life. How the development of apostolic government [evolved?] is difficult to say accurately because of the absence of certain documents. ITC says that the apostles or their closest assistants or their successors directed the local colleges of "episkopoi" and "presbyteroi" by the end of the first century; while by the beginning of the second century the figure of a single bishop, as the head of the communities, appears explicitly in the letters of Ignatius of Antioch ( 35-107). In the "Epistle to the Smyrnaeans", Ignatius wrote about three degrees ministry:
"See that you all follow the "bishop", even as Jesus Christ does the Father, and the "presbytery" as you would the apostles; and reverence the "deacons", as being the institution of God. Let no man do anything connected with the Church without the bishop."
Ramsey says that the doctrine was formulated in the second century in the first of the three senses given by him, originally as a response to Gnostic claims of having received secret teaching from Christ or the apostles; it emphasised the public manner in which the apostles had passed on authentic teaching to those whom they entrusted with the care of the churches they founded and that these in turn had passed it on to their successors. Ramsey argues that only later was it given a different meaning, a process in which Augustine (Bp of Hippo Regis, 395–430) played a part by emphasising the idea of "the link from consecrator to consecrated whereby the grace of order was handed on."
Writing about AD 94, Clement of Rome states that the apostles appointed successors to continue their work where they had planted churches and for these in their turn to do the same because they foresaw the risk of discord. He uses both 'bishop' and 'presbyter' to refer to these men. According to Eric G. Jay, the interpretation of his writing is disputed, but it is clear that he supports some sort of approved continuation of the ministry exercised by the apostles which in its turn was derived from Christ.
Hegesippus (180?) and Irenaeus (180) introduce explicitly the idea of the bishop's succession in office as a guarantee of the truth of what he preached in that it could be traced back to the apostles. and they produced succession lists to back this up. That this succession depended on the fact of ordination to a vacant see and the status of those who administered the ordination is seldom commented on. Woollcombe also states that no one questioned the apostolicity of the See of Alexandria despite the fact that its Popes were consecrated by the college of presbyters up till the time of the Council of Nicaea in 325. On the contrary, other sources clearly state that Mark the Evangelist is the first bishop of Alexandria (Pope of Alexandria), then he ordained Annianus as his successor bishop (2nd Pope) as told by Eusebius ("Historia Ecclesiastica" 2.24.1).
James F. Puglisi, director of Centro Pro Unione, made a conclusion about Irenaeus' writings: "the terms "episkopos" and "presbyteros" are interchangeable, but the term "episkopos" is applied to the person who is established in every Church by the apostles and their successors". According to Eric G. Jay, Irenaeus also refers to a succession of presbyters who preserve the tradition "which originates from the apostles". and later goes on to speak of their having "an infallible gift of truth" ["charisma veritatis certum". Jay comments that this is sometimes seen as an early reference to the idea of the transmission of grace through the apostolic succession which in later centuries was understood as being specifically transmitted through the laying on of hands by a bishop within the apostolic succession (the "pipeline theory"). He warns that this is open to the grave objection that it makes grace a (quasi)material commodity and represents an almost mechanical method of imparting what is by definition a free gift. He adds that the idea cannot be squeezed out of Irenaeus' words.
Writing a little later, Tertullian makes the same main point but adds expressly that recently founded churches (such as his own in Carthage) could be considered apostolic if they had "derived the tradition of faith and the seeds of doctrine" from an apostolic church. His disciple, Cyprian (Bishop of Carthage 248–58) appeals to the same fundamental principle of election to a vacant see in the aftermath of the Decian Persecution when denying the legitimacy of his rigorist rival in Carthage and that of the anti-pope Novatian in Rome; Cyprian also laid great emphasis on the fact that any minister who broke with the Church lost "ipso facto" the gift of the Spirit which had validated his orders. This meant that the minister would had no power or authority to celebrate an efficacious sacrament.
As transmission of grace.
For the adherents of this understanding of apostolic succession, grace is transmitted during episcopal consecrations (the ordination of bishops) by the laying on of hands of bishops previously consecrated within the apostolic succession). They hold that this lineage of ordination derives from the Twelve Apostles, thus making the Church the continuation of the early Apostolic Christian community. They see it as one of four elements that define the true Church of Jesus Christ and legitimize the ministry of its clergy, since only a bishop within the succession can perform valid ordinations, and only bishops and presbyters (priests) ordained by bishops in the apostolic succession can validly celebrate (or "confect") several of the other sacraments, including the Eucharist, reconciliation of penitents, confirmation and anointing of the sick. Everett Ferguson argued that Hippolytus, in "Apostolic Tradition 9", is the first known source to state that only bishops have the authority to ordain; and normally at least three bishops were required to ordain another bishop (First Council of Nicaea, "can". 4). Cyprian also asserts that "if any one is not with the bishop, he is not in the church" ("Ep." 66.9). 
This position was stated by John Henry Newman, before his conversion from Anglicanism to Roman Catholicism, in "Tracts for the Times":
We of the Church of England have been born, not of blood, nor of the will of the flesh, nor of the will of man, but of God. The Lord Jesus Christ gave His Spirit to His Apostles; they in turn laid their hands on those who should succeed them; and these again on others; and so the sacred gift has been handed down to our present bishops, who have appointed us as their assistants, and in some sense representatives. ... we must necessarily consider none to be "really" ordained who have not "thus" been ordained.
Ferguson, in "Encyclopedia of Early Christianity", says that example of James and the elders of the Jerusalem Church (Acts 21:18) may have provided a model for the development of 'monepiscopacy', in which James' position has figured conspicuously in modern theories about the rise of the monepiscopacy. Raymond E. Brown says that in the earlier stage (before the third century and perhaps earlier) there were plural bishops or overseers ("presbyter-bishops") in an individual community; in the later stage changed to only one bishop per community. Little known about how the early bishops were formally chosen or appointed; afterwards the Church developed a regularized pattern of selection and ordination of bishops, and from the third century on that was universally applied. Brown asserts that the ministry was not ordained by the Church to act on its own authority, but as an important part to continue the ministry of Jesus Christ and helps to make the Church what it is.
Raymond E. Brown also states that by the early second century, as written in the letters of Ignatius of Antioch, in the threefold structure of the single bishop, plural presbyters, and plural deacons, the celebration of the Eucharist is assigned to the bishop alone; the bishop may delegate others when he goes away. At the Last Supper, Jesus says to those present, who were or included the Twelve Apostles, "Do this in commemoration of me," Brown presumes that the Twelve were remembered as presiding at the Eucharist. But they could scarcely have been present at all the Eucharists of the first century, and no information in New Testament whether a person was regularly assigned to do this task and, if so, who that person was. After all the Church regulated and regularized the celebration of the Eucharist, as that was an inevitable establishment if communities were to be provided regularly with the 'bread of life', since it could not rely on gratuitous provision.
Objections to the transmission of grace theory.
According to William Griffith Thomas, some Protestants have objected that this theory is not explicitly found in Scripture, and the New Testament uses 'bishop' and 'presbyter' as alternative names for the same office. Michael Ramsey argued it is not clearly found in the writings of the Fathers before Augustine in the fourth century and there were attempts to read it back as implicit in earlier writers.
For example, C. K. Barrett points out that the Pastoral Epistles are concerned that ministers of the generation of Timothy and Titus should pass on the doctrine they had received to the third generation. According to Barrett, teaching and preaching are "the main, almost the only, activities of ministry." He argues that in Clement of Rome ministerial activity is liturgical: the undifferentiated 'presbyter-bishops' are to "make offerings to the Lord at the right time and in the right places" something which is simply not defined by the evangelists. He also mentions the change in the use of sacrificial language as a more significant still: for Paul the Eucharist is a receiving of gifts from God, the Christian sacrifice is the offering of one's body (Romans 12:1). Moving on to Ignatius of Antioch, Barrett states that a sharp distinction found between 'presbyter' and 'bishop': the latter now stands out as "an isolated figure" who is to be obeyed and without whom it is not lawful to baptise or hold a love-feast. He also points out that when Ignatius writes to the Romans, there is no mention of a bishop of the Roman Church, "which we may suppose had not yet adopted the monarchical episcopate." Jalland comes to a similar conclusion and locates the change from the "polyepiscopacy" of the house church model in Rome, to monepiscopacy as occurring before the middle of the second century.
Similar objections are voiced by Harvey who comments that there is a "strong and ancient tradition" that the presence of an ordained man is necessary for the celebration of the Eucharist. But, according to him, there is "certainly no evidence for this view in the New Testament" and in the case of Clement of Rome and Ignatius of Antioch the implication is not that it "cannot" be celebrated by anyone else, but that it "ought" not. Harvey says in the third century this "concern for propriety" begins to be displaced by the concept of 'power' to do so which means that in the absence of such a man it is "literally impossible" for a Eucharist to be celebrated.
Apostolicity as doctrinal and related continuity.
Some Protestant denominations, not including Scandinavian Lutherans, High Church Anglicans and Moravians, deny the need of maintaining episcopal continuity with the early Church, holding that the role of the apostles was that, having been chosen directly by Jesus as witnesses of his resurrection, they were to be the "special instruments of the Holy Spirit in founding and building up the Church". E.A. Litton argues that the Church is "built upon 'the foundation of the Prophets and Apostles' (Ephes. ii. 20), but a foundation does not repeat itself"; therefore he says that when the apostles died, they were replaced by their writings. To share with the apostles the same faith, to believe their word as found in the Scriptures, to receive the same Holy Spirit, is to many Protestants the only meaningful "continuity". The most meaningful "apostolic succession" for them, then, is a "faithful succession" of apostolic teaching.
Max Thurian, before his conversion to Roman Catholicism on 1988, described the classic Reformed/Presbyterian concept of apostolic succession in the following terms. "The Christian ministry is not derived from the people but from the pastors; a scriptural ordinance provides for this ministry being renewed by the ordination of a presbyter by presbyters; this ordinance originates with the apostles, who were themselves presbyters, and through them it goes back to Christ as its source.". Then he continued:
At the same time Thurian argued that the realities form a "composite faithfulness" and are (i) "perseverance in the apostolic doctrine"; (ii) "the will to proclaim God's word"; (iii) "communion in the fundamental continuity of the Church, the Body of Christ, the faithful celebration of Baptism and the Eucharist"; (iv) "succession in the laying on of hands, the sign of ministerial continuity".
According to Walter Kasper, the Reformed-Catholic dialogue came to belief that there is an apostolic succession which is important to the life of the Church, though both sides distinguish the meaning of that succession. Besides, the dialogue states that apostolic succession "consists at least in continuity of apostolic doctrine, but this is not in opposition to succession through continuity of ordained ministry" ("Ref I", 100). While the Lutheran-Catholic dialogue distinguishes between apostolic succession in faith (in substantive meaning) and apostolic succession as ministerial succession of bishops; agreed that "succession in the sense of the succession of ministers must be seen within the succession of the whole church in the apostolic faith" ("Ministry", 61; cf. "Malta", 48).
Joint International Commission for Theological Dialogue Between the Catholic Church and the Orthodox Church asserts that apostolic succession means something more than just a transmission of authorities; it witnesses to the apostolic faith from the same apostolic faith, and in communion with other Churches (attached to the apostolic communion). Apostolic tradition deals with the community, not only an ordained bishop as an isolated person. Since the bishop, once ordained, becomes the guarantor of apostolicity and successor of the apostles; he joins together all the bishops, thus maintaining "episkope" of the local Churches derived from the college of the apostles.
Churches claiming apostolic succession.
Churches that claim some form of episcopal apostolic succession, dating back to the apostles or to leaders from the apostolic era, include the Catholic Church, the Eastern Orthodox and Oriental Orthodox Churches, the Church of the East, the Anglican Communion, some Lutheran Churches (see below), the Church of Jesus Christ of Latter Day Saints and other smaller bodies incorporating the term "Catholic". The Anglican Communion (see below) and those Lutheran Churches which claim apostolic succession do not specifically teach this but exclusively practice episcopal ordination. While some Anglicans claim it for their communion, their views are often nuanced and there is widespread reluctance to 'unchurch' Christian bodies which lack it.
Roman Catholics recognise the validity of the apostolic successions of the bishops, and therefore the rest of the clergy, of the Eastern Orthodox, Oriental Orthodox, Church of the East, Old Catholic Church (Union of Utrecht only), and Polish National Catholic Church. The Eastern Orthodox generally recognise Roman Catholic orders, but have a different concept of the apostolic succession as it exists outside of Eastern Orthodoxy. The lack of apostolic succession through bishops is the primary basis on which Protestant communities are not called "Churches", in the proper sense, by the Orthodox churches and the Roman Catholic Church. The Church of Jesus Christ of Latter-Day Saints also claims Apostolic succession. Per church teachings, Joseph Smith received the priesthood from Peter James and John. After that, each subsequent prophet and leader of the church have received the authority passed down by the laying on of hands, or through apostolic succession.
Apostolic founders.
An early understanding of apostolic succession is represented by the traditional claims of various churches, as organised around important episcopal sees, to have been founded by specific apostles. On the basis of these traditions, the churches claim to have inherited specific authority, doctrines and/or practices on the authority of their founding apostle(s), which is understood to be continued by the bishops of the apostolic throne of the church that each founded and whose original leader he was. Thus:
Teachings.
Catholic Church.
In Roman Catholic theology, the doctrine of apostolic succession states that Christ gave the full sacramental authority of the Church to the Twelve Apostles through the sacrament of Holy Orders. By conferring the fullness of the sacrament of Holy Orders on the apostles, they were given the authority to confer the sacrament on others, thus consecrating bishops in a direct lineage that can trace its origin back to the Twelve Apostles and Christ. This direct succession of bishops from the apostles to the present day bishops is referred to as apostolic succession.
Papal primacy is different though related to apostolic succession as described here. The Catholic Church has traditionally claimed a unique leadership role for the Apostle Peter, believed to have been named by Jesus as head of the Apostles and as a focus of their unity, who became the first Bishop of Rome, and whose successors inherited the role and accordingly became the leaders of the worldwide Church as well. Even so, Catholicism acknowledges the papacy is built on apostolic succession, not the other way around. As such, apostolic succession is a foundational doctrine of authority in the Catholic Church.
Catholicism holds that Christ entrusted the Apostles with the leadership of the community of believers, and the obligation to transmit and preserve the "deposit of faith" (the experience of Christ and his teachings contained in the doctrinal "tradition" handed down from the time of the apostles and the written portion, which is Scripture). The apostles then passed on this office and authority by ordaining bishops to follow after them.
Roman Catholic theology holds that the apostolic succession effects the power and authority to administer the sacraments except for baptism and matrimony. (Baptism may be administered by anyone and matrimony by the couple to each other.) Authority to so administer such sacraments is passed on only through the sacrament of Holy Orders, a rite by which a priest is ordained (ordination can be conferred only by bishop). The bishop, of course, must be from an unbroken line of bishops stemming from the original apostles selected by Jesus Christ. Thus, apostolic succession is necessary for the valid celebration of the sacraments.
On 29 June 2007, the Congregation for the Doctrine of the Faith explained why apostolic succession is integral to, and indeed, "a constitutive element" of the Church. In response to the question why the Second Vatican Council and other official statements of the Catholic Church do not call Protestant Christian Communities "Churches", it stated that "according to Catholic doctrine, these Communities do not enjoy "apostolic succession" in the sacrament of Orders, and are, therefore, deprived of a constitutive element of the Church. These ecclesial Communities which, specifically because of the absence of the sacramental priesthood, have not preserved the genuine and integral substance of the Eucharistic Mystery cannot, according to Catholic doctrine, be called 'Churches' in the proper sense".
Orthodox churches.
While Eastern Orthodox sources often refer to the bishops as "successors of the apostles" under the influence of Scholastic theology, strict Orthodox ecclesiology and theology hold that all legitimate bishops are properly successors of Peter. This also means that presbyters (or "priests") are successors of the apostles. As a result, Orthodox theology makes a distinction between a geographical or historical succession and proper ontological or ecclesiological succession. Hence, the bishops of Rome and Antioch can be considered successors of Peter in a historical sense on account of Peter's presence in the early community. This does not imply that these bishops are more successors of Peter than all others in an ontological sense.
According to ancient canons still observed with the Orthodox communion, a bishop must be consecrated by at least three other bishops; so-called "single handed ordinations" do not exist. Moreover, bishops are never ordained "at large" but only for a specific Eucharist community, in due historical and sacramental succession.
Views concerning other churches.
The Eastern Orthodox have often permitted non-Orthodox clergy to be rapidly ordained within Orthodoxy as a matter of pastoral necessity and economia. Priests entering Eastern Orthodoxy from Oriental Orthodoxy and Roman Catholicism have usually been received by "vesting" and have been allowed to function immediately within Eastern Orthodoxy as priests. Recognition of Roman Catholic orders by the Russian Orthodox Church was stipulated in 1667 by the Synod of Moscow, but this position is not universal within the Eastern Orthodox communion. For example, Fr. John Morris of the Antiochian Orthodox Christian Archdiocese of North America, states that "Apostolic Succession is not merely an historical pedigree, but also requires Apostolic Faith. This is because Apostolic Succession is not the private possession of a bishop, but is the attribute of a local Church. A bishop who goes in schism or is cast out of office due to heresy does not take his Apostolic Succession with him as a private possession." The validity of a priest's ordination is decided by each autocephalic Orthodox church.
The Armenian Apostolic Church, which is one of the Oriental Orthodox churches, recognises Roman Catholic episcopal consecrations without qualification.
In 1922 the Eastern Orthodox Ecumenical Patriarch of Constantinople recognised Anglican orders as valid, holding that they carry "the same validity as the Roman, Old Catholic and Armenian Churches possess". In the encyclical "From the Oecumenical Patriarch to the Presidents of the Particular Eastern Orthodox Churches", Meletius IV of Constantinople, the Oecumenical Patriarch, wrote: "That the Orthodox theologians who have scientifically examined the question have almost unanimously come to the same conclusions and have declared themselves as accepting the validity of Anglican Orders." Following this declaration, in 1923, the Eastern Orthodox Church of Jerusalem, as well as the Eastern Orthodox Church of Cyprus agreed by "provisionally acceding that Anglican priests should not be re-ordained if they became Orthodox"; in 1936, the Romanian Orthodox Church "endorsed Anglican Orders". Historically, some Eastern Orthodox bishops have assisted in the consecration of Anglican bishops; for example, in 1870, the Most Reverend Alexander Lycurgus, the Greek Orthodox Archbishop of Syra and Tinos, was one of the bishops who consecrated Henry MacKenzie as the Suffragan Bishop of Nottingham.
Succeeding judgements, however, have been more conflicting. The Eastern Orthodox churches require a totality of common teaching to recognise orders and in this broader view find ambiguities in Anglican teaching and practice problematic. Accordingly, in some parts of the Eastern Orthodox Church, Anglican clergy who convert to Orthodoxy are reordained, rather than vested.
Anglican Communion.
The Anglican Communion "has never officially endorsed any one particular theory of the origin of the historic episcopate, its exact relation to the apostolate, and the sense in which it should be thought of as God given, and in fact tolerates a wide variety of views on these points". Its claim to apostolic succession is rooted in the Church of England's evolution as part of the Western Church. Apostolic succession is viewed not so much as conveyed mechanically through an unbroken chain of the laying-on of hands, but as expressing continuity with the unbroken chain of commitment, beliefs and mission starting with the first apostles; and as hence emphasising the enduring yet evolving nature of the Church.
When Henry VIII broke away from the jurisdiction of Rome in 1533/4, the English Church claimed the episcopal polity and apostolic succession inherent in its Catholic past; however, Protestant theology gained a certain foothold and under his successor, Edward VI what had been an administrative schism became a Protestant reformation under the guiding hand of Thomas Cranmer. Although care was taken to maintain the unbroken sequence of episcopal consecrations, particularly in the case of Matthew Parker, who was consecrated Archbishop of Canterbury in 1559 by two bishops who had been ordained in the 1530s with the Roman Pontifical and two ordained with the Edwardine Ordinal of 1550, apostolic succession was not seen as a major concern that a true ministry could not exist without episcopal consecrations: English Reformers such as Richard Hooker rejected the Catholic position that Apostolic Succession is divinely commanded or necessary for true Christian ministry. Richard A. Norris says that the ""foreign" Reformed Churches" were genuine ones despite the lack of apostolic succession because they had been abandoned by their bishops at the Reformation.
In very different ways both James II and William III of England made it plain that the Church of England could no longer count on the 'godly prince' to maintain its identity and traditions and the 'High Church' clergy of the time began to look to the idea of apostolic succession as a basis for the church's life. For William Beveridge (Bp of St Asaph 1704–8) the importance of this lay in the fact that Christ himself is "continually present at such imposition of hands; thereby transferring the same Spirit, which He had first breathed into His Apostles, upon others successively after them"., but the doctrine did not really come to the fore until the time of the Tractarians.
In 1833, before his conversion to Roman Catholicism, Newman wrote about the apostolic succession: "We must necessarily consider none to be "really" ordained who has not been "thus" ordained". After quoting this, Michael Ramsey continues: "With romantic enthusiasm, the Tractarians propagated this doctrine. In doing so they involved themselves in some misunderstandings of history and in some confusion of theology". He goes on to explain that they ascribed to early Anglican authors a far more exclusive version of the doctrine than was the case, they blurred the distinction between succession in office (Irenaeus) and succession in consecration (Augustine); they spoke of apostolic succession as the channel of grace in a way that failed to do justice to His gracious activity within all the dispensations of the New Covenant.(p. 111) Newman, and after him, Charles Gore held that the episcopate was passed down from the apostles through men like Timothy and Titus to single bishops in particular localities (monarchial episcopacy). However Bp. Lightfoot argued that monarchial episcopacy evolved upwards from a college of presbyters by the elevation of one of their number to be the episcopal president(p. 116) and A.C. Headlam laid great stress on Irenaeus' understanding of succession which had been lost from sight behind the Augustinian 'pipe-line theory'.(pp. 117,18)
Roman Catholic views on Anglican orders.
In the Catholic Church, Pope Leo XIII stated in his 1896 bull "Apostolicae curae" that the Catholic Church believes specifically that the Anglican consecrations are "absolutely null and utterly void" because of changes made to the rite of consecration during the 16th century under Edward VI, thus denying that Anglicans participate in the apostolic succession. Anglican clergy, then, are ordained as Catholic priests upon entry into the Catholic Church.
A reply from the Archbishops of Canterbury and York (1896) was issued to counter Pope Leo's arguments: "Saepius officio: Answer of the Archbishops of Canterbury and York to the Bull Apostolicae Curae of H. H. Leo XIII". They argued that if the Anglican orders were invalid, then the Roman orders were as well since the Pope based his case on the fact that the Anglican ordinals used did not contain certain essential elements but these were not found in the early Roman rites either. However, Catholics argue, this argument does not consider the sacramental intention involved in validating Holy Orders. In other words, Catholics believe that the ordination rites were reworded so as to invalidate the ordinations because the intention behind the alterations in the rite was a fundamental change in Anglican understanding of the priesthood.
It is Roman Catholic doctrine that the teaching of "Apostolicae curae" is a truth to be "held definitively", as stated in a commentary by the Congregation for the Doctrine of the Faith. Cardinal Basil Hume explained the conditional character of his ordination of Graham Leonard, former Anglican bishop of the Diocese of London, to the priesthood in the following way: "While firmly restating the judgement of "Apostolicae Curae" that Anglican ordination is invalid, the Catholic Church takes account of the involvement, in some Anglican episcopal ordinations, of bishops of the Old Catholic Church of the Union of Utrecht who are validly ordained. In particular and probably rare cases the authorities in Rome may judge that there is a 'prudent doubt' concerning the invalidity of priestly ordination received by an individual Anglican minister ordained in this line of succession." At the same time, he stated: "Since the church must be in no doubt of the validity of the sacraments celebrated for the Catholic community, it must ask all who are chosen to exercise the priesthood in the Catholic Church to accept sacramental ordination in order to fulfill their ministry and be integrated into the apostolic succession." Since "Apostolicae curae" was issued many Anglican jurisdictions have revised their ordinals, bringing them more in line with ordinals of the early Church.
Timothy Dufort, writing in "The Tablet" in 1982, argued that by 1969 all Anglican bishops had acquired apostolic succession fully recognized by Rome, since from the 1930s Old Catholic bishops (whose orders Rome recognises as valid) have acted as co-consecrators in the ordination of Anglican bishops. This view is not accepted by the Holy See, and the matter has been further complicated by the Anglican ordination of women. In a document it published in July 1998, the Congregation for the Doctrine of the Faith stated that the Catholic Church's declaration on the invalidity of Anglican ordinations is a teaching that the church has definitively propounded and that therefore every Catholics is required to give "firm and definitive assent" to this matter.
Porvoo Communion of Churches.
Negotiated at Järvenpää, Finland, and inaugurated with a celebration of the eucharist at Porvoo Cathedral in 1992, this agreement of unity includes the mutual recognition of the traditional apostolic succession among the following Churches:
Of note is the fact that at least one of the Scandinavian Lutheran Churches in the Porvoo Communion of Churches, the Church of Denmark has bishops, but strictly speaking they were not in the historic apostolic succession prior to their entry into the Porvoo Communion, since their Episcopate and Holy Orders derived from Dr. Johannes Bugenhagen, who was a pastor, not a bishop. In 2010, the Church of Denmark joined the Porvoo Communion of Churches, after a process of mutual consecrations of bishops had led to the introduction of historic apostolic succession. The Lutheran Church in Great Britain also joined the Porvoo Agreement, in 2014.
Lutheran churches.
Wide variations exist within Lutheranism on this issue. Most Lutheran churches in Scandinavian countries are favorable to the traditional doctrine of apostolic succession. Others de-emphasize it, e.g., many German Lutheran churches in former Prussian lands, resulting from their state-ordered union with Reformed (Calvinist) churches in 1817.
Lutheran claims to apostolic succession.
In Scandinavia and the Baltic region, Lutheran churches participating in the Porvoo Communion (those of Iceland, Norway, Sweden, Finland, Estonia, and Lithuania), as well as non Porvoo membership Lutheran churches in the region (including those of Latvia, and Russia), believe that they ordain their bishops in the apostolic succession in lines stemming from the original apostles. "The New Westminster Dictionary of Church History" states that "In Sweden the apostolic succession was preserved because the Catholic bishops were allowed to stay in office, but they had to approve changes in the ceremonies."
The Lutheran Church of Finland was then one with the Church of Sweden and so holds the same view regarding the see of Åbo/Turku.
Similarly, in the High Church Lutheranism of Germany, some religious brotherhoods like Hochkirchliche St. Johannes-Bruderschaft and Hochkirchlicher Apostolat St. Ansgar have managed to arrange for their own bishop to be re-ordained in apostolic succession. The members of these brotherhoods do not form into separate ecclesia.
The Evangelical Lutheran Church in America, North America's largest Lutheran body, became united in the historic episcopate of the Episcopal Church in 2000, upon the signing of "Called to Common Mission". By this document the full communion between the Evangelical Lutheran Church in America and the Episcopal Church was established. As such, "all episcopal installations in the Evangelical Lutheran Church in America take place with the participation of bishops in the apostolic succession." The Evangelical Lutheran Church in America is headed by a presiding bishop who is elected by the churchwide assembly for a six-year term.
In recent years a number of Lutheran churches at the most Catholic edge of the Evangelical Catholic High Church Lutheran spectrum in the United States of America have accepted the doctrine of apostolic succession and have successfully recovered it, generally from Independent Catholic Churches. At present, most of these church bodies have memberships numbering in the hundreds.
The Catholic Church "has never officially expressed its judgement on the validity of orders as they have been handed down by episcopal succession in these two national Lutheran churches."
Indifference to the issue.
Many German Lutherans appear to demur on this issue, which may be sourced in the church governance views of Martin Luther. Luther's reform movement, however, usually did not as a rule abrogate the ecclesiastic office of Bishop.
An important historical context to explicate the wide differences among German Lutheran Churches is the Prussian Union of 1817, whereby the secular government directed the Lutheran Churches in Prussia to merge with non-Lutheran Reformed Churches in Prussia. The Reformed Churches generally oppose on principle the traditional doctrine of ecclesiastic Apostolic Succession, e.g., not usually even recognising the church office of Bishop. Later in the 19th century, other Lutheran and Reformed congregations merged to form united church bodies in some of the other 39 states of the German Confederation, e.g., in Anhalt, Baden, Bremen, Hesse and Nassau, Hesse-Kassel and Waldeck, and the Palatinate. Yet the partial nature of this list also serves to show that in Germany there remained many Lutherans who never did unite with the Reformed.
Other Lutheran Churches seem indifferent as a matter of understood doctrine regarding this particular issue of ecclesiastical governance. In America, the conservative Missouri Synod places its church authority in the congregation rather than in the bishop, though its founder, C.F.W. Walther, while establishing congregational polity for the Missouri Synod, did consider Polity (a Church's form of government) to be a matter of adiaphora (something indifferent.) Still, other conservative Lutherans, however, may favour High Church Lutheranism which remains generally favourable to the traditional doctrine of Apostolic Succession (see above).
Methodist churches.
In the beginnings of the Methodist movement, adherents were instructed to receive the sacraments within the Anglican Church; however, the American Methodists soon petitioned to receive the sacraments from the local preachers who conducted worship services and revivals. The Bishop of London refused to ordain ministers in the British American colonies. John Wesley, the founder of the movement, was reluctant to allow unordained preachers to administer the sacraments:
Some scholars argue that in 1763, Greek Orthodox bishop Erasmus of the Diocese of Arcadia, who was visiting London at the time, consecrated John Wesley a bishop, and ordained several Methodist lay preachers as priests, including John Jones. However, Wesley could not openly announce his episcopal consecration without incurring the penalty of the Præmunire Act. In light of Wesley's episcopal consecration, the Methodist Church can lay a claim on apostolic succession, as understood in the traditional sense. Since John Wesley ordained and sent forth every Methodist preacher in his day, who preached and baptized and ordained, and since every Methodist preacher who has ever been ordained as a Methodist was ordained in this direct "succession" from Wesley, then the Methodist Church teaches that it has all the direct merits coming from apostolic succession, if any such there be. This apostolic succession is recognized by Unity Catholic Church, an independent Catholic church.
However, most Methodists view apostolic succession outside its high church sense. This is because Wesley believed that the offices of bishop and presbyter constituted one order, citing an ancient opinion from the Church of Alexandria. Wesley argued that for two centuries the succession of bishops in the Church of Alexandria, which was founded by Mark the Evangelist, was preserved through ordination by presbyters alone and was considered valid by that ancient Church.
Since the Bishop of London refused to ordain ministers in the British American colonies, this constituted an emergency and as a result, on 2 September 1784, Wesley, along with a priest from the Anglican Church and two other elders, operating under the ancient Alexandrian habitude, ordained Thomas Coke a superintendent, although Coke embraced the title bishop.
Today, the United Methodist Church follows this ancient Alexandrian practice as bishops are elected from the presbyterate: the "Discipline of the Methodist Church", in ¶303, affirms that "ordination to this ministry is a gift from God to the Church. In ordination, the Church affirms and continues the apostolic ministry through persons empowered by the Holy Spirit." It also uses sacred scripture in support of this practice, namely, 1 Timothy 4:14, which states: 
The Methodist Church also buttresses this argument with the leg of sacred tradition of the Wesleyan Quadrilateral by citing the Church Fathers, many of whom concur with this view.
In addition to the aforementioned arguments—or perhaps instead of them—in 1937 the annual Conference of the British Methodist Church located the "true continuity" with the Church of past ages in "the continuity of Christian experience, the fellowship in the gift of the one Spirit; in the continuity in the allegiance to one Lord, the continued proclamation of the message; the continued acceptance of the mission;..." a long chain which goes back to the "the first disciples in the company of the Lord Himself ... This is our doctrine of apostolic succession" neither depends on, nor is secured by, "an official succession of ministers, whether bishops or presbyters, from apostolic times, but rather by fidelity to apostolic truth".
In June 2014, the Church of Ireland, a province of the Anglican Communion, extended its lines of apostolic succession into the Methodist Church in Ireland, as "the Archbishop of Dublin and Bishop of Down and Dromore took part in the installation of the new President of the Methodist Church of Ireland, the Rev. Peter Murray." In May 2014, the "Church of Ireland’s General Synod approved an agreement signed with the Methodist Church that provided for the interchangeability of clergy, allowing an ordained minister of either church to come under the discipline and oversight of the other."
Moravian Church.
The Moravian Church teaches that it has preserved apostolic succession. The Church claims apostolic succession as a legacy of the old Unity of the Brethren. In order to preserve the succession, three Bohemian Brethren were consecrated bishops by Bishop Stephen of Austria, a Waldensian bishop who had been ordained by a Roman Catholic bishop in 1434. These three consecrated bishops returned to Litice in Bohemia and then ordained other brothers, thereby preserving the historic episcopate.
Denominations that reject apostolic succession.
Some Nonconformist Protestants, particularly those in the Calvinist tradition, deny the doctrine of apostolic succession, believing that it is neither taught in Scripture nor necessary for Christian teaching, life, and practice. Accordingly, these Protestants strip the notion of apostolic succession from the definition of "apostolic" or "apostolicity." For them, to be apostolic is simply to be in submission to the teachings of the original twelve apostles as recorded in Scripture. This doctrinal stance reflects the Protestant view of authority, embodied in the doctrine known as Sola Scriptura.
Among the original champions of Protestantism who rejected the doctrine of apostolic succession were John Calvin, and Martin Luther. They both said that the episcopacy was inadequate to address corruption, doctrinal or otherwise, and that this inadequacy justified the intervention of the church of common people. In part this position was also necessary, as otherwise there would have been no means to elicit or initiate reform of the church.
In the 20th century, there has been more contact between Protestants and Christians from Eastern traditions which claim apostolic succession for their ministry. Like the Roman Catholic Church, these ancient Eastern churches may use the doctrine of apostolic succession in ministry in their apologetics against some forms of Protestantism. Some Protestants feel that such claims of apostolic succession are proven false by the differences in traditions and doctrines between these churches: Roman Catholics and Eastern Orthodox consider both the Church of the East and the Oriental Orthodox churches to be heretical, having been anathematized in the early ecumenical councils of Ephesus (431) and Chalcedon (451) respectively. However, churches that claim apostolic succession in ministry distinguish this from doctrinal orthodoxy, holding that "it is possible to have valid orders coming down from the apostles, and yet not to have a continuous spiritual history coming down from the apostles".
All Christians who have a genuine relationship with God through and in Christ are part of the "true Church", according to exemplary statements of evangelical Protestant theology, notwithstanding condemnation of the Catholic Church by some Protestants. According to these statements, claims that one or more denominations might be the "true Church" are nothing more than propaganda which has evolved over centuries to support authoritarian claims—based on tradition or based on scripture—of merely human institutions. Such claims can be found among the worldwide community of Christians. Yet all appear to treasure the truth that liberates, and Jesus taught his followers to love one another.
Confessional Lutheranism.
Confessional Lutheranism rejects Apostolic Succession as a biblical doctrine, stating that there is no evidence the Popes have historic succession from Peter other than their own claim that it is so. Furthermore, they claim that the Bible contains no evidence showing that the office must be conveyed by laying-on of hands and no Biblical command that it must be by a special class of bishops. Laying-on of hands is repeatedly mentioned, especially in the case of Paul and Timothy; however, it is a descriptive, non-prescriptive teaching in the Bible:
Confessional Lutheran churches teach:
Lutheran apologists state that there are a number of major problems with the Roman Catholic view on apostolic succession:
For example, the Wisconsin Evangelical Lutheran Synod, a Confessional Lutheran church body, holds that it's their custom that ordination of pastors is by other pastors, and that neither the Bible nor the Lutheran confessions make this the only divinely mandated way of entering the pastoral ministry. The Wisconsin Synod teaches that "it is the call of the church that is the essential element, more specifically, the call of Christ through the church."
Other teachings on apostolic succession.
Latter Day Saint Movement.
Denominations within the Latter Day Saint movement claim apostolic succession through the process of restoration. According to their teaching, a period of universal apostasy followed the death of the Twelve Apostles. Without apostles or prophets left on the earth with the legitimate Priesthood Authority, many of the true teachings and practices of Christianity were lost. Eventually these were restored to the prophet Joseph Smith and various others in a series of divine conferrals and ordinations by angelic men who had held this authority during their lifetimes (see this partial list of restoration events). As it relates to apostolic succession, Joseph Smith and Oliver Cowdery said that the apostles Peter, James, and John appeared to them in 1829 and conferred upon them the Melchizedek Priesthood and with it "the keys of the kingdom, and of the dispensation of the fulness of times".
For The Church of Jesus Christ of Latter-day Saints (LDS Church), the largest denomination in the Latter-day Saint movement, Apostolic Succession is the leadership of the Church being established through the Quorum of the Twelve Apostles. Each time the President of the Church dies, the most senior Apostle, who is designated as the President of the Quorum of the Twelve Apostles, is set apart as the new church president.

</doc>
<doc id="2264" url="https://en.wikipedia.org/wiki?curid=2264" title="List of Anglo-Saxon monarchs and kingdoms">
List of Anglo-Saxon monarchs and kingdoms

A succession of monarchs ruled the various independent kingdoms which arose in England following the end of Roman rule in Britain in the 5th century. The most prominent of these kingdoms were Kent, East Anglia, Sussex, Wessex, Mercia and Northumbria, with each kingdom often recognising their own monarch.
The early genealogies are based on the (semi-historical) Anglo-Saxon royal genealogies as compiled in the 9th century.

</doc>
<doc id="2268" url="https://en.wikipedia.org/wiki?curid=2268" title="Ascorbic acid">
Ascorbic acid

Ascorbic acid is a naturally occurring organic compound with antioxidant properties. It is a white solid, but impure samples can appear yellowish. It dissolves well in water to give mildly acidic solutions. Ascorbic acid is one form ("vitamer") of vitamin C. It was originally called L-hexuronic acid, but, when it was found to have vitamin C activity in animals ("vitamin C" being defined as a vitamin activity, not then a specific substance), the suggestion was made to rename it. The new name, ascorbic acid, is derived from "a-" (meaning "no") and "scorbutus" (scurvy), the disease caused by a deficiency of vitamin C. Because it is derived from glucose, many non-human animals are able to produce it, but humans require it as part of their nutrition. Other vertebrates which lack the ability to produce ascorbic acid include some primates, guinea pigs, teleost fishes, bats, and some birds, all of which require it as a dietary micronutrient (that is, in vitamin form).
History.
From the middle of the 18th century, it was noted that lemon and lime juice could help prevent sailors from getting scurvy. At first, it was supposed that the acid properties were responsible for this benefit; however, it soon became clear that other dietary acids, such as vinegar, had no such benefits. In 1907, two Norwegian physicians reported an essential disease-preventing compound in foods that was distinct from the one that prevented beriberi. These physicians were investigating dietary-deficiency diseases using the new animal model of guinea pigs, which are susceptible to scurvy. The newly discovered food-factor was eventually called vitamin C.
From 1928 to 1932, the Hungarian research team led by Albert Szent-Györgyi, as well as that of the American researcher Charles Glen King, identified the antiscorbutic factor as a particular single chemical substance. At the Mayo clinic, Szent-Györgyi had isolated the chemical hexuronic acid from animal adrenal glands. He suspected it to be the antiscorbutic factor but could not prove it without a biological assay. This assay was finally conducted at the University of Pittsburgh in the laboratory of King, which had been working on the problem for years, using guinea pigs. In late 1931, King's lab obtained adrenal hexuronic acid indirectly from Szent-Györgyi and, using their animal model, proved that it is vitamin C, by early 1932.
This was the last of the compound from animal sources, but, later that year, Szent-Györgyi's group discovered that paprika pepper, a common spice in the Hungarian diet, is a rich source of hexuronic acid. He sent some of the now more available chemical to Walter Norman Haworth, a British sugar chemist. In 1933, working with the then-Assistant Director of Research (later Sir) Edmund Hirst and their research teams, Haworth deduced the correct structure and optical-isomeric nature of vitamin C, and in 1934 reported the first synthesis of the vitamin. In honor of the compound's antiscorbutic properties, Haworth and Szent-Györgyi now proposed the new name of "a-scorbic acid" for the compound. It was named L-ascorbic acid by Haworth and Szent-Györgyi when its structure was finally proven by synthesis.
In 1937, the Nobel Prize for chemistry was awarded to Haworth for his work in determining the structure of ascorbic acid — shared with Paul Karrer, who received his award for work on vitamins — and the prize for Physiology or Medicine that year went to Albert Szent-Györgyi for his studies of the biological functions of L-ascorbic acid.
The American physician Fred R. Klenner, M.D. promoted vitamin C as a cure for many diseases in the 1950s by elevating the dosages greatly to as much as tens of grams vitamin C daily orally and by injection. From 1967 on, Nobel prize winner Linus Pauling recommended high doses of ascorbic acid as a prevention against cold and cancer. However, modern evidence does not support a role for high-dose vitamin C in the treatment of cancer or the prevention of the common cold in the general population.
Acidity.
Ascorbic acid is classed as a reductone. The ascorbate anion is stabilized by electron delocalization, as shown above in terms of resonance between two canonical forms. For this reason, ascorbic acid is much more acidic than would be expected if the compound contained only isolated hydroxyl groups.
Antioxidant mechanism.
The ascorbate ion is the predominant species at typical biological pH values. It is a mild reducing agent and antioxidant. It is oxidized with loss of one electron to form a radical cation and then with loss of a second electron to form dehydroascorbic acid. It typically reacts with oxidants of the reactive oxygen species, such as the hydroxyl radical. Such radicals are damaging to animals and plants at the molecular level due to their possible interaction with nucleic acids, proteins, and lipids. Sometimes these radicals initiate chain reactions. Ascorbate can terminate these chain radical reactions by electron transfer. Ascorbic acid is special because it can transfer a single electron, owing to the resonance-stabilized nature of its own radical ion, called semidehydroascorbate. The net reaction is:
The oxidized forms of ascorbate are relatively unreactive and do not cause cellular damage.
However, being a good electron donor, excess ascorbate in the presence of free metal ions can not only promote but also initiate free radical reactions, thus making it a potentially dangerous pro-oxidative compound in certain metabolic contexts.
On exposure to oxygen, ascorbic acid will undergo further oxidative decomposition to various products including diketogulonic acid, xylonic acid, threonic acid and oxalic acid.
Food chemistry.
Ascorbic acid and its sodium, potassium, and calcium salts are commonly used as antioxidant food additives. These compounds are water-soluble and, thus, cannot protect fats from oxidation: For this purpose, the fat-soluble esters of ascorbic acid with long-chain fatty acids (ascorbyl palmitate or ascorbyl stearate) can be used as food antioxidants. Eighty percent of the world's supply of ascorbic acid is produced in China.
The relevant European food additive E numbers are:
It creates volatile compounds when mixed with glucose and amino acids in 90 °C.
It is a cofactor in tyrosine oxidation.
Biosynthesis.
Ascorbic acid is found in plants and animals where it is produced from glucose. Animals must either produce it or digest it, otherwise a lack of vitamin C may cause scurvy, which may eventually lead to death. Reptiles and older orders of birds make ascorbic acid in their kidneys. Recent orders of birds and most mammals make ascorbic acid in their liver where the enzyme L-gulonolactone oxidase is required to convert glucose to ascorbic acid. Humans, other higher primates, guinea pigs and most bats require dietary L-gulonolactone oxidase because the enzyme catalysing the last step in the biosynthesis is highly mutated and non-functional, therefore, unable to make ascorbic acid. Synthesis and signalling properties are still under investigation.
Animal ascorbic acid biosynthesis pathway.
The biosynthesis of ascorbic acid starts with the formation of UDP-glucuronic acid. UDP-glucuronic acid is formed when UDP-glucose undergoes two oxidations catalyzed by the enzyme UDP-glucose 6-dehydrogenase. UDP-glucose 6-dehydrogenase uses the co-factor NAD+ as the electron acceptor. The transferase UDP-glucuronate pyrophosphorylase removes a UMP and glucuronokinase, with the cofactor ADP, removes the final phosphate leading to D-glucuronic acid. The aldehyde group of this is reduced to a primary alcohol using the enzyme glucuronate reductase and the cofactor NADPH, yielding L-gulonic acid. This is followed by lactone formation with the hydrolase gluconolactonase between the carbonyl on C1 and hydroxyl group on C4. L-Gulonolactone then reacts with oxygen, catalyzed by the enzyme L-gulonolactone oxidase (which is nonfunctional in humans and other Haplorrhini primates) and the cofactor FAD+. This reaction produces 2-oxogulonolactone, which spontaneously undergoes enolization to form ascorbic acid.
Plant ascorbic acid biosynthesis pathway.
There are many different biosynthesis pathways for ascorbic acid in plants. Most of these pathways are derived from products found in glycolysis and other pathways. For example, one pathway goes through the plant cell wall polymers. The plant ascorbic acid biosynthesis pathway most principal seems to be L-galactose. L-Galactose reacts with the enzyme L-galactose dehydrogenase, whereby the lactone ring opens and forms again but with between the carbonyl on C1 and hydroxyl group on the C4, resulting in L-galactonolactone. L-Galactonolactone then reacts with the mitochondrial ﬂavoenzyme L-galactonolactone dehydrogenase. to produce ascorbic acid. L-Ascorbic acid has a negative feedback on L-galactose dehydrogenase in spinach.
Ascorbic acid efflux by embryo of dicots plants is a well-established mechanism of iron reduction, and a step obligatory for iron uptake.
Yeasts do not make L-ascorbic acid but rather a similar antioxidant known as D-erythroascorbic acid.
Industrial preparation.
Ascorbic acid is prepared in industry from glucose in a method based on the historical Reichstein process. In the first of a five-step process, glucose is catalytically hydrogenated to sorbitol, which is then oxidized by the microorganism "Acetobacter suboxydans" to sorbose. Only one of the six hydroxy groups is oxidized by this enzymatic reaction. From this point, two routes are available. Treatment of the product with acetone in the presence of an acid catalyst converts four of the remaining hydroxyl groups to acetals. The unprotected hydroxyl group is oxidized to the carboxylic acid by reaction with the catalytic oxidant TEMPO (regenerated by sodium hypochlorite — bleaching solution). Historically, industrial preparation via the Reichstein process used potassium permanganate as the bleaching solution. Acid-catalyzed hydrolysis of this product performs the dual function of removing the two acetal groups and ring-closing lactonization. This step yields ascorbic acid. Each of the five steps has a yield larger than 90%.
A more biotechnological process, first developed in China in the 1960s, but further developed in the 1990s, bypasses the use of acetone-protecting groups. A second genetically modified microbe species, such as mutant "Erwinia", among others, oxidises sorbose into 2-ketogluconic acid (2-KGA), which can then undergo ring-closing lactonization via dehydration. This method is used in the predominant process used by the ascorbic acid industry in China, which supplies 80% of world's ascorbic acid. American and Chinese researchers are competing to engineer a mutant that can carry out a one-pot fermentation directly from glucose to 2-KGA, bypassing both the need for a second fermentation and the need to reduce glucose to sorbitol.
There exists a D-ascorbic acid, which does not occur in nature but can be synthesized artificially. It has identical antioxidant properties to L-ascorbic acid yet has far less vitamin C activity (although not quite zero). This fact is taken as evidence that the antioxidant properties of ascorbic acid are only a small part of its effective vitamin activity. To be specific, L-ascorbate is known to participate in many specific enzyme reactions that require the correct enantiomer (L-ascorbate and not D-ascorbate). L-Ascorbic acid has a specific rotation of [α] = +23°.
Determination.
The traditional way to analyze the ascorbic acid content is the process of titration with an oxidizing agent, and several procedures have been developed, mainly relying on iodometry. Iodine is used in the presence of a starch indicator. Iodine is reduced by ascorbic acid, and, when all the ascorbic acid has reacted, the iodine is then in excess, forming a blue-black complex with the starch indicator. This indicates the end-point of the titration. As an alternative, ascorbic acid can be treated with iodine in excess, followed by back titration with sodium thiosulfate using starch as an indicator. The preceding iodometric method has been revised to exploit reaction of ascorbic acid with iodate and iodide in acid solution. Electrolyzing the solution of potassium iodide produces iodine, which reacts with ascorbic acid. The end of process is determined by potentiometric titration in a manner similar to Karl Fischer titration. The amount of ascorbic acid can be calculated by Faraday's law.
An uncommon oxidising agent is "N"-bromosuccinimide (NBS). In this titration, the NBS oxidizes the ascorbic acid in the presence of potassium iodide and starch. When the NBS is in excess (i.e., the reaction is complete), the NBS liberates the iodine from the potassium iodide, which then forms the blue-black complex with starch, indicating the end-point of the titration.

</doc>
<doc id="2273" url="https://en.wikipedia.org/wiki?curid=2273" title="AFC Ajax">
AFC Ajax

Amsterdamsche Football Club Ajax (), also AFC Ajax or Ajax Amsterdam, is a Dutch professional football club based in Amsterdam. Historically, Ajax (named after the legendary Greek hero) is the most successful club in the Netherlands, with 33 Eredivisie titles and 18 KNVB Cups. It has continuously played in the Eredivisie, the Dutch football top division, since its inception in 1956 and, along with Feyenoord and PSV Eindhoven, it is one of the country's "big three" clubs that have dominated that competition.
Ajax is historically one of the most successful clubs in the world; according to the IFFHS, Ajax were the seventh-most successful European club of the 20th century. The club is one of the five teams that has earned the right to keep the European Cup and to wear a multiple-winner badge; they won consecutively in 1971–1973. In 1972, they completed the continental treble by winning the Eredivisie, KNVB Cup, and the European Cup. Ajax's last international trophies were the 1995 Intercontinental Cup and the 1995 Champions League, where they defeated Milan in the final; they lost the 1996 Champions League final on penalties to Juventus.
Ajax is also one of three teams to win the continental treble and the Intercontinental Cup in the same season/calendar year; This was achieved in the 1971–72 season. Ajax, Juventus, Bayern Munich, and Chelsea are the four clubs to have won all three major UEFA club competitions. They have also won the Intercontinental Cup twice, the 1991–92 UEFA Cup, as well as the Karl Rappan Cup, a predecessor of the UEFA Intertoto Cup in 1962. Ajax plays at the Amsterdam Arena, which opened in 1996. They previously played at De Meer Stadion and the Amsterdam Olympic Stadium (for international matches).
History.
Ajax was founded in Amsterdam on 18 March 1900. The club achieved promotion to the highest level of Dutch football in 1911 and had its first major success in 1917, winning the KNVB Beker, the Netherlands' national cup. The following season, Ajax became national champion for the first time. The club defended its title in 1918–19, becoming the only team to achieve an unbeaten season in the Netherlands Football League Championship.
Throughout the 1920s, Ajax was a strong regional power, winning the Eerste Klasse West division in 1921, 1927 and 1928, but could not maintain its success at national level. This changed in the 1930s, with the club winning five national championships (1931, 1932, 1934, 1937, 1939), making it the most successful Dutch team of the decade. Ajax won its second KNVB Cup in 1942–43, and an eighth Dutch title in 1946–47, the last season the club was managed by Englishman Jack Reynolds, who, up to this point, had overseen all of its national championship successes as well as its 1917 KNVB Cup win.
In 1956, the first season of the Netherlands' new professional league, the Eredivisie, was played with Ajax participating as a founding member. The Amsterdam club became the first national champions under the new format and made its debut in the European Champion Clubs' Cup the following year, losing to Hungarian champions Vasas SC 6–2 on aggregate at the quarter-final stage. The team were again Eredivisie champions in 1960 and won a third KNVB Cup in 1961.
In 1965, Rinus Michels, who had played for the club between 1946 and 1958, was appointed manager of Ajax, implementing his philosophy of Total Football which was to become synonymous with both Ajax and the Netherlands national football team. A year earlier, Johan Cruijff, who would go on to become the greatest Dutch footballer of all time, made his debut. Between them, Michels and Cruijff led Ajax through the most successful period in its history, winning seven Eredivisie titles, four KNVB Cups and three European Cups.
Ajax won the Dutch championship in 1966, 1967, and 1968, and reached the 1969 European Cup Final, losing to A.C. Milan. During the 1966–67 season, Ajax scored a record 122 goals in an Eredivisie season and also won the KNVB Cup to achieve its first league and cup double. In 1969–70, Ajax won a fourth Dutch league championship and second league and cup double in five seasons, winning 27 out of 34 league games and scoring 100 goals.
The 1970–71 season saw Ajax retain the KNVB Cup and reach the 1971 European Cup Final, where they beat Panathinaikos 2–0 with goals from Dick van Dijk and Arie Haan to become continental champions for the first time, with Cruijff being named European Footballer of the Year. After this success, Michels departed to become manager of FC Barcelona and was replaced by the Romanian Ștefan Kovács. In Kovács' first season, Ajax completed a treble of the European Cup, the Eredivisie and a third consecutive KNVB Cup. The following season, the team beat Argentine club Independiente to win the 1972 Intercontinental Cup and retained their Eredivisie and European Cup titles, becoming the first club to win three consecutive European Cups since Real Madrid in the 1950s.
In 1973, Michels' Barcelona broke the world transfer record to bring Cruijff to Catalonia. Kovács also departed to become manager of the France national football team signalling the end of this period of international success.
In 1976–77, Ajax won its first domestic championship in four seasons and recorded a double of the Eredivisie and KNVB Cup two years later.
The early 1980s saw the return of Johan Cruijff to the club, as well as the emergence of young players Marco van Basten and Frank Rijkaard. The team won back-to-back Eredivisie titles in 1982 and 1983, with all three playing a significant role in the latter. After Cruijff's sale to rivals Feyenoord in 1983, Van Basten became Ajax's key player, top scoring in the Eredivisie for four seasons between 1983–84 and 1986–87.
In 1985, Cruijff returned to Ajax as manager and the team ended his first season in charge with 120 goals from 34 matches. However, Ajax still finished as runner up to PSV by eight points. The following season, Ajax again lost out on the Eredivisie title to PSV, but won the European Cup Winners' Cup, its first continental trophy in fourteen years. After this, Cruijff left the club to become manager of Barcelona and Rijkaard and Van Basten were sold to Sporting CP and A.C. Milan respectively. Despite these losses, Ajax reached a second consecutive Cup Winners' Cup final in 1988, where they lost to Belgian club KV Mechelen.
The 1988–89 season saw Dennis Bergkamp, a young forward who had first appeared under Cruijff in 1986, establish himself as a regular goalscorer for Ajax. Bergkamp helped Ajax to the 1989–90 Eredivisie title and was the top scorer in the division in 1990–91, 1991–92 and 1992–93. Under the management of Louis van Gaal, Ajax won the UEFA Cup in 1992 to become the second club, after Juventus, to have won all three major European club competitions.
After the sale of Bergkamp to Internazionale in 1993, Van Gaal re-signed the experienced Frank Rijkaard to complement his young Ajax team featuring academy graduates Frank and Ronald de Boer, Edwin van der Sar, Clarence Seedorf, Edgar Davids, Michael Reiziger, and Winston Bogarde, as well as mercurial foreign talents Finidi George, Nwankwo Kanu and Jari Litmanen, and veteran captain Danny Blind. The team regained the Dutch championship in 1993–94, and won it again in 1994–95 and 1995–96 to become the first Ajax side to win three back-to-back championships since 1968. The height of Van Gaal's success came in 1994–95, where Ajax became the first, and to date only, team to complete an entire Eredivisie season unbeaten. The team also won its first European Cup since its glorious 1970s era, beating Milan in the 1995 UEFA Champions League Final 1–0, with the winning goal scored by 18-year-old Patrick Kluivert. Ajax again reached the final a year later but were defeated on penalties by Juventus.
Ajax's return as a European force was short lived as Van Gaal and several members of the squad soon departed to some of the continent's biggest clubs. The 2000s was a lean decade for the club with only two Eredivisie championships won. However, Ajax's academy continued to produce star players such as Wesley Sneijder and Rafael van der Vaart.
In 2010, Frank de Boer was appointed manager of Ajax and led the club to its first league title in seven years, and record 30th title overall, in the 2010–11 season. This was followed by back-to-back wins in 2011–12 and 2012–13 to match his three consecutive titles as a player in the 1990s. In 2013–14, Ajax were again Eredivisie champions, winning four consecutive league titles for the first time in the club's history.
Youth program.
The club is also particularly famous for its renowned youth program that has produced many Dutch talents over the years – Johan Cruijff, Edwin van der Sar, Dennis Bergkamp, former national team top scorer Patrick Kluivert, and former national team coach Marco van Basten. Dutch national first-team players Rafael van der Vaart, Ryan Babel, Wesley Sneijder, Maarten Stekelenburg, Eljero Elia, André Ooijer, John Heitinga and Nigel de Jong had also came through the ranks at Ajax and all are now playing for top-flight clubs. Ajax also regularly supplies the Dutch national youth teams with local talent. First team regulars Siem de Jong, Urby Emanuelson and Gregory van der Wiel are former youth internationals who made the successful step up to the senior side.
Due to mutual agreements with foreign clubs, the youth academy has also signed foreign players as teenagers before making first team debuts, such as Belgian defensive trio Jan Vertonghen, Toby Alderweireld and Thomas Vermaelen along with winger Tom de Mul, all of whom are full internationals as well as Dutch international Vurnon Anita as well as Javier Martina from Curaçao.
Ajax has also expanded its talent searching program to South Africa with Ajax Cape Town. Ajax Cape Town was set up with the help of Rob Moore. Ajax has also had a satellite club in the United States under the name Ajax America, until it filed for bankruptcy. There are some youth players from Ajax Cape Town that have been drafted into the Eredivisie squad, such as South African internationals Steven Pienaar, Thulani Serero and Cameroonian international Eyong Enoh.
In 1995, the year Ajax won the Champions League, the Dutch national team was almost entirely composed of Ajax players, with Edwin van der Sar in goal; players such as Michael Reiziger, Frank de Boer, and Danny Blind in defense; Ronald de Boer, Edgar Davids, and Clarence Seedorf in midfield; and Patrick Kluivert and Marc Overmars in attack.
In 2011 AFC Ajax opened its first youth academies outside the Netherlands, when the club partnered up with George Kazianis and All Star Consultancy in Greece to open the Ajax Hellas Youth Academy. The offices are based in Nea Smyrni, Attica, with the main training facility located on the island of Corfu, hosting a total of 15 football youth academies throughout Greece and Cyprus. Eddie van Schaik heads the organization as coach and consultant, introducing the Ajax football philosophy at the various Greek football training camps.
Stadiums.
Ajax' first stadium was built in 1911 out of wood and was called "Het Houten Stadion" (The Wooden Stadium). Ajax later played in the stadium built for the 1928 Summer Olympics hosted in Amsterdam. This stadium, designed by Jan Wils, is known as the Olympic Stadium. In 1934, Ajax moved to De Meer Stadion in east Amsterdam, designed by architect and Ajax-member Daan Roodenburgh, who had also designed the club's first stadium. It could accommodate 29,500 spectators and Ajax continued to play there until 1996. For big European and national fixtures the club would often play at the Olympic Stadium, which could accommodate about twice the number of spectators.
In 1996, Ajax moved to a new home ground in the southeast of the city known as the Amsterdam ArenA This was built by the Amsterdam city authority at a cost of $134 million. The stadium is capable of holding approximately 52,000 people. The average attendance in 2006/07 was 48,610, rising in the next season to 49,128. The ArenA has a retractable roof and set a trend for other modern stadiums built in Europe in the following years. In the Netherlands, the ArenA has earned a reputation for a terrible grass pitch caused by the removable roof that, even when open, takes away too much sunlight and fresh air. During the 2008–2009 season ground staff introduced an artificial lighting system that has finally reduced this problem considerably.
The much-loved De Meer stadium was torn down and the land was sold to the city council. A residential neighbourhood now occupies the area. The only thing left of the old stadium are the letters AJAX, nowadays in place on the façade of the youth training grounds De Toekomst, near the Amsterdam Arena.
Crest and colours.
Crest.
In 1900, when the club was founded, the emblem of Ajax was just a picture of an Ajax player. The crest was slightly altered following the club's promotion to the top division in 1911 to match the club's new outfits. In 1928, the club logo was introduced with the head of the Greek hero Ajax. The logo was once again changed in 1990 into an abstract version of the previous one. The new logo still sports the portrait of Ajax, but drawn with just 11 lines, symbolizing the 11 players of a football team.
Colors.
Ajax originally played in an all-black uniform with a red sash tied around the players' waists, but that uniform was soon replaced by a red/white striped shirt and black shorts. Red, black and white are the three colours of the flag of Amsterdam. However, when, under manager Jack Kirwan, the club got promoted to the top flight of Dutch football for the first time in 1911 (then the "Eerste Klasse" or 'First Class', later named the Eredivisie), Ajax were forced to change their colours because Sparta Rotterdam already had exactly the same outfit. Special kits for away fixtures did not exist at the time and according to football association regulations the newcomers had to change their colours if two teams in the same league had identical uniforms. Ajax opted for white shorts and white shirt with a broad, vertical red stripe over chest and back, which still is Ajax's outfit.
Financial.
AFC Ajax N.V..
AFC Ajax are the only Dutch club with an Initial public offering (IPO). The club is registered as a Naamloze vennootschap (N.V.) listed on the stock exchange Euronext Amsterdam, since 17 May 1998. With a launch price of ƒ25,- (Guilders) the club managed to a bring their total revenue up to €54 million euros (converted) in their first year on the market. After short lived success however the rate dropped, at one point as low as €3,50. Criticism was brought forth that the legal grid for a naamloze vennootschap would not be suitable for a Football club, and that the sports related ambitions would suffer from the new commercial interests of the now listed Ajax. Shares of the company in the year 2008 were valued at approximately €5,90 per share.
In 2008 a Commission under guidance of honorary member Uri Coronel concluded, that the IPO was of no value to the club, and that measures should be taken to exit the stock exchange by purchasing back all public shares. Ajax remain on the stock exchange.
Sponsorship.
Ajax's shirts have been sponsored by TDK from 1982 to 1991, and by ABN AMRO from 1991 to 2008. AEGON then replaced ABN AMRO as the new head sponsor for a period of seven years. On 1 April 2007, Ajax wore a different sponsor for the match against Heracles Almelo: "Florius". Florius is a banking program launched by ABN AMRO who wanted it to be the shirt sponsor for one match.
The shirts have been manufactured by Le Coq Sportif (1973–1977), Puma (1977–1980), Le Coq Sportif (1980–1984), Kappa (1985-1989) and Umbro (1989–2000) in the past, and by Adidas since 2000 (until at least 2019).
In conclusion of the 2013–14 season, Ajax won the Football shirt of the Year award for their black and rose colored away shirt by adidas. An annual award presented by Subside Sports which had previously been won by Internazionale, Juventus and the Belgium national team. It was Ajax first time winning the award.
On 7 November 2014 it was announced that Ajax had agreed to 4,5 year contract worth €8 million annually with Dutch cable operating company Ziggo as the new shirt sponsor for the club. Having extended their contract with AEGON for half a season until December, the club featured "Fonds Gehandicaptensport", a charitable fund for handicapped sports on its away shirts for a six-month period before transitioning to Ziggo in 2015.
Other teams.
Reserves team.
Jong Ajax ("formerly more commonly known as Ajax 2") is the reserve team of AFC Ajax. The team is composed mostly of professional footballers, who are often recent graduates from the highest youth level (Ajax A1) serving their first professional contract as a reserve, or players who are otherwise unable to play in the first team.
Since 1992 Jong Ajax have competed in the Beloften Eredivisie, competing against other reserve teams such as Jong PSV, Jong FC Groningen or Jong AZ. They have won the Beloften Eredivisie title a record eight times, as well as the KNVB Reserve Cup three times, making them the most successful reserve squad in the Netherlands. By winning the Beloften Eredivisie title, Jong Ajax were able to qualify for the actual KNVB Cup, even advancing to the semi-finals on three occasions. Their best result in the Dutch Cup was under manager Jan Olde Riekerink in 2001-02, when a semi-final loss to FC Utrecht in a Penalty shoot-out after extra time, which saw Utrecht advance, and thus preventing an Ajax vs. Jong Ajax Dutch Cup final.
The 2013–14 season marked the Jupiler League debut of the AFC Ajax reserves' squad Jong Ajax. Previously playing in the Beloften Eredivisie (a separate league for reserve teams, not included in the Dutch professional or amateur league structure) players were allowed to move around freely between the reserve team and the first team during the season. This is no longer the case as Jong Ajax now registers and fields a separate squad from that of Ajax first team for the Eerste Divisie, the second tier of professional football in the Netherlands. Their home matches are played at Sportpark De Toekomst, except for the occasional match in the Amsterdam Arena. Now regarded a semi-professional team in their own respect, the only period in which players are able to move between squads are during the transfer windows, unless the player has made less than 15 appearances for the first team, then he is still eligible to appear in both first team and second team matches during the season. Furthermore, the team is not eligible for promotion to the Eredivisie or to participate in the KNVB Cup. Jong Ajax were joined in the Eerste Divisie by Jong Twente and Jong PSV, reserve teams who have also moved from the Beloften Eredivisie to the Eerste Divisie, in place of VV Katwijk, SC Veendam and AGOVV Apeldoorn, increasing the total amount of teams in the Jupiler League from 18 to 20.
Ajax reserve squad Jong Ajax left the Beloften Eredivisie in 2013, having held a 21-year tenure in the reserves league, having also won the league title a record eight times. (1994, 1996, 1998, 2001, 2002, 2004, 2005, 2009)
Amateur team.
AFC Ajax Amateurs, better known as Ajax Zaterdag is a Dutch amateur football club founded 18 March 1900. It is the amateur team of the professional club AFC Ajax, who play their home matches at the Sportpark De Toekomst training grounds to a capacity of 5,000. The team was promoted from the Eerste Klasse to the Hoofdklasse ahead of the 2011–12 season, the league in which they are currently competing. The team has won the Eerste Klasse title twice, as well as the *KNVB District Cup West I on two occasions as well.
Furthermore, Ajax Zaterdag have also managed to qualify for the KNVB Cup on their own accord on three occasions, namely in 2004, 2005 and in 2008, even advancing to the second round before bowing out to Vitesse on 24 September 2008 during their last appearance in the cup tournament.
Women's team.
AFC Ajax Vrouwen ("English: AFC Ajax Women") are the women's team of AFC Ajax, competing in the BeNe League, the highest level of professional football in Belgium and the Netherlands. Founded on 18 May 2012, the women's team saw Ajax attracting many of the Netherlands top talents, with International players such as Anouk Hoogendijk, Daphne Koster and Petra Hogewoning joining the Amstedam club on its maiden season in women's professional football. The team won their first piece of silverware when the defeated PSV/FC Eindhoven 2–1 in the final of the KNVB Women's Cup.
Other sports.
Baseball team.
Ajax HVA (1922–1972) was the baseball team of AFC Ajax founded in 1922, and competing as founding members of the Honkbal Hoofdklasse, the top flight of professional baseball in the Netherlands. Ajax won the national baseball title a total of four times (1924, 1928, 1942, 1948) before the club opted to no longer field a baseball team, and to focus solely on football in 1972. Ajax spent a total of 50 years at the top flight of Baseball in the Netherlands from 1922 to 1972. The dissolution of Ajax baseball club resulted in the players finding a new sponsor in a mustard manufacturing company called Luycks, while merging with the Diemen Giants to become the Luycks Giants, thus replacing both former clubs.
Affiliated clubs.
The following clubs are currently affiliated with AFC Ajax:
The following clubs were affiliated with AFC Ajax in the past:
Rivalries.
"As one of the traditional big three clubs in the Netherlands, Ajax have amassed a number of intense rivalries over the years. Listed below are the most significant of the rivalries involving Ajax Amsterdam."
Rivalry with Feyenoord.
Feyenoord from Rotterdam are Ajax's arch rivals. Every year both clubs play the "De Klassieker" ("The Classic"), a match between the teams from the two largest cities of the Netherlands. During the seventies, Ajax and Feyenoord were the only two clubs in the Netherlands who were able to clinch national titles, as well as achieve continental and even global success. A meeting between the two clubs became the measure for who was truly the best club in the Netherlands. The Klassieker is the most famous of all the rivalries in the Netherlands and the matches are always sold out. The fixture is seen in the public eye as ""The graceful and elegant football of Ajax, against the indomitable fighting spirit of Feyenoord"". The confidence of the Capital versus the Blue collar mentality of Rotterdam. Matches are known for their tension and violence, both on and off the pitch. Over the years several violent incidents have taken place involving rival supporters, leading to the current prohibition of away-supporters in both stadiums. The lowest point was reached on 23 March 1997, when supporters of both clubs meet on a field near Beverwijk, where Ajax-supporter Carlo Picornie was fatally injured, the incident is commonly referred to as the "Battle of Beverwijk".
Rivalry with PSV.
PSV are also a rival of Ajax, but in terms of tension and rivalry, these matches are not as loaded as the duels with Feyenoord. The rivalry has existed for some time with PSV and stems from various causes, such as the different interpretations of whether current national and international successes of both clubs correlates and the supposed opposition between the Randstad and the province. The matches between these two teams is commonly referred to as "De Topper" ("The Topper"), and involves the two most trophy-laden sides in Dutch football and is essentially a clash of two competing schools of thought in Dutch football. Historically PSV compete with a workmanlike ethic, preferring a more robust 4-3-1-2 or 4-2-3-1, typically shunning the seductive 4-3-3 approach favoured in Amsterdam. While Rinus Michels and Johan Cruijff helped to innovate Total Football in the sixties and seventies, a different philosophy was honed in Eindhoven by Kees Rijvers and Guus Hiddink in the late seventies and eighties. This in turn has created one of the more philosophical rivalries in football, an ideological battleground, which is gradually becoming as heated and intense as the matches Ajax and Feyenoord partake in.
Rivalries with other clubs.
Aside from Feyenoord and PSV, Ajax have several other rivalries, although in most cases the sentiment is mostly felt by the opposition and is more directed towards Ajax, with one of them being FC Utrecht. Although the rivalry is more felt on the Utrecht side then with Ajax, matchups between the two sides are often quite intense. Both teams have fanatic supporters, and clashes off the pitch are more often the rule than the exception. The same goes for ADO Den Haag, with both supporter-groups often getting in conflicts, when ADO-Hooligans set fire to the Supporters home of Ajax, and Ajax-Hooligans subsequently broke into the Supporters home of ADO tensions between the two clubs rose. In 2006 Supporters from both clubs were banned from attending away matches for five years, due to frequent violent outbreaks and clashes.
Further teams who share a rivalry with Ajax include FC Twente, FC Groningen and AZ. Although the latter are often regarded by Ajax-supporters as the club's little brother. Being from nearby Alkmaar, and with both clubs sharing the same Province, match-ups between the two sides are commonly known as the "De Noord-Hollandse Derby" ("North Holland Derby") and are often very competitive, intense and loaded fixtures.
Past rivalries include local Amsterdam derbies between Ajax and clubs such as Blauw-Wit, DWS and De Volewijckers (who later merged to become FC Amsterdam in 1972). The tension between the local sides lessened however, as the division of the clubs through playing in different leagues over time became greater. Years of not competing in the same league resulted in less frequent match-ups, until tensions finally settled between the Amsterdam clubs. The last Amsterdam derby to take place in an official league match was when Ajax defeated FC Amsterdam 5-1, on 19 March 1978.
Supporters.
Ajax are known for having fanatic core supporter-groups, of which F-Side and VAK410 are the most famous. F-Side were founded on 3 October 1976, and are situated right behind the goal In the Amsterdam ArenA, on the southern end of the stadium in rows 125–129. Their name is derived from the group's former location on the F-side of the old De Meer Stadion. The F-side supporters are responsible for a big part of the atmosphere in the stadium, but are also known for rioting during and after matches. If in any match Ajax should win the coin toss, the second half of the match Ajax always play towards the south-end of the stadium. VAK410 (English: Row 410) were founded in 2001 and are situated in the Zuidhoek ("South corner") of the stadium on the upper ring in rows 424–425. The group was originally situated on the North-West side of the stadium in row 410, from where it derives its name, until relocating to their current place in the stands in 2008. Members of VAK410 are known to perform various stunts, which include massive banners, to enhance the atmosphere in the stadium. Neither F-Side or VAK410 have seats in their sections of the stadium, and both groups stand for the duration of the match.
Through the official "Football Top 20" of Dutch sports research group "SPORT+MARKT" it was revealed in 2010 that Ajax had approximately 7,1 million supporters throughout Europe. Slightly more than rivals Feyenoord and PSV (each 1,6 and 1,3 million, respectively), which put Ajax in 15th place for most supporters in all of Europe. The study also revealed that approximately 39% of the Netherlands were Ajax supporters. Not only does Ajax have a lot of supporters, but several fans attend their matches in European competition, with an average attendance of 48.677 spectators for every International match Ajax played, putting the team at 12th place in Europe for highest attendance, ahead of big name clubs such as Milan, Manchester City or Chelsea. It is noteworthy that not all stadiums share the capacity of the Amsterdam Arena.
Supporters clubs.
The Supporters Club Ajax () is officially the largest Supporters club in the Netherlands with 94,000 members. Founded on 7 May 1992, the supporters club organize big monthly events throughout the Netherlands, and particularly around the official Ajax Open Training Day, which attracts thousands of supporters each year. Furthermore, the Supporters group is responsible for the Ajax Life website, as well as the fanzine which is issued 20 times a year. In 2006, the AFCA Supportersclub was introduced as the club's second official supporters' association, through the merger of the Onafhankelijke Fanclub Ajax (OFA) and the Ajax Supporters Delegatie (ASD). The AFCA Supportersclub has a reported 42,000 members, as well as a former member on the Board of Administration of Ajax, in Ronald Pieloor.
Average attendance.
This graph displays the average attendance for home matches of Ajax from 1988–2012, whereby the difference in capacity of the De Meer Stadion and the Amsterdam ArenA (est. 1996) is clearly visible.
Jewish connection.
Historically, Ajax was popularly seen as having "Jewish roots". Although not an official Jewish club like the city's WV-HEDW, Ajax has had a Jewish image since the 1930s when the home stadium was located next to a Jewish neighbourhood of Amsterdam-Oost and opponents saw many supporters walking through the Nieuwmarkt/Waterloopleinbuurt (de Jodenhoek—the "Jews' corner") to get to the stadium. The city of Amsterdam was historically referred to as a Mokum city, Mokum (מקום) being the Yiddish word for "place" or "safe haven", and as anti-Semitic chants and name calling developed and intensified at the old De Meer Stadion from frustrated supporters of opposing clubs, Ajax fans (few of whom are actually Jewish) responded by embracing Ajax's "Jewish" identity: calling themselves "super Jews", chanting "Jews, Jews" ("Joden, Joden") at games, and adopting Jewish symbols such as the Star of David and the Israeli flag.
This Jewish imagery eventually became a central part of Ajax fans' culture. At one point ringtones of "Hava Nagila", a Hebrew folk song, could be downloaded from the club's official website. Beginning in the 1980s, fans of Ajax's rivals escalated their antisemitic rhetoric, chanting slogans like "Hamas, Hamas/Jews to the gas" ("Hamas, hamas, joden aan het gas"), hissing to imitate the flow of gas, giving Nazi salutes, etc. The eventual result was that many (genuinely) Jewish Ajax fans stopped going to games.
In the 2000s the club began trying to persuade fans to drop their Jewish image. In 2013 a documentary titled "Superjews" was released by NTR and Viewpoint Productions which premiered at the International Documentary Film Festival Amsterdam (IDFA). The film was directed by Nirit Peled, an Israeli living in Amsterdam, and an independent film maker who offers a very personal view into the game, the lore of Ajax and its relation to Judaism from both the supporters as well as from a Jewish perspective.
Notable former players.
The players below are part of the AFC Ajax Hall of Fame.
1910–1920
1920–1930
1930–1940
1940–1950
1950–1960
1960–1970
1960–1970 (continued)
1970–1980
1980–1990
1990–2000
2000–2010
Honours.
Official trophies (recognized by UEFA and FIFA).
Other trophies.
Ajax have won numerous friendly tournaments, unsanctioned by UEFA or FIFA, including the Amsterdam Tournament, Bruges Matins Trophy, Trofeo Santiago Bernabéu, Eusébio Cup, Ted Bates Trophy, Jalkapalloturnaus and Chippie Polar Cup. ("For a complete list, see main article")
Honorary club members.
Ajax have a total of 45 honorary club members, from people who have been invested within the club's administrative engagements, to committed players who have excelled in the athletic department. Of those 45 members 39 have since deceased. Six members still remain, having been reduced from eight members after Piet Keizer denounced his membership, and seven after the passing of Johan Cruijff.
The remaining 39 honorary members who have since died:
Results.
Domestic results.
Below is a table with Ajax's domestic results since the introduction of the Eredivisie in 1956.
Club van 100.
The Club van 100 is the official list of Football players who have appeared in one hundred or more official matches for AFC Ajax. The club currently has a total of 150 members with Daley Blind being the latest addition. The record for league appearances is held by Mr. Ajax himself Sjaak Swart, who appeared in 463 league matches for Ajax 1. There is a beneficiary team called Lucky Ajax, which was initiated by Sjaak Swart. Lucky Ajax participate in at least one match a year, usually in the name of charity, and commonly at football ceremonies to bid farewell to retiring players. One of the prerequisites for playing on Lucky Ajax, which is invitational only, is that you are a member of the Club van 100, having made at least 100 official match appearances for Ajax Amsterdam in the first team of the club.
Lucky Ajax.
Lucky Ajax are a beneficiary team that was initiated by Sjaak Swart in the seventies, competing in at least one match a year, usually in the name of charity and/or to bid farewell to retiring former Ajax players. The team is made up of various members of the Club van 100 of Ajax who will come out of retirement for this match to face the Ajax squad that is current of that year. Past participants have included Barry Hulshoff, Sonny Silooy, Simon Tahamata, Ronald Koeman, Tscheu La Ling, Gerrie Mühren, John van 't Schip, Brian Roy, Stanley Menzo, Peter van Vossen and Fred Grim. The name Lucky Ajax is derived from the famous ""Lucky Ajax"" nickname from how people used to refer to the club when Ajax would either win a match by chance, by a decision of a referee, or by coincidence such as was said to be the case during the infamous Mistwedstrijd (Fog Match).
Number 14 shirt.
As of the 2007–08 season, no player could wear the number 14 shirt at Ajax, after the club decided to retire the shirt out of respect for Johan Cruyff, "the legendary number fourteen". Cruyff himself laughed off the tribute saying the club had to let its best player play with number 14. Spanish midfielder Roger was the last player to wear the number. Marvin Zeegelaar wore the shirt number In preparation for the 2011–12 season in one preseason match, while Aras Özbiliz wore the number 14 shirt in one preseason match ahead of the 2011–12 season as well. The club stated that this was in fact not done in error.
List of players to wear the number 14 shirt since Johan Cruyff's departure.
Team tournaments.
Amsterdam Tournament.
Established in 1975 as the Amsterdam 700 Tournament to celebrate 700 years of history in the city. The tournament was hosted annually each summer by Ajax until 1992, when the last edition of the original tournament was played. It returned in 1999 with the backing of the International Event Partnership (IEP). Four teams participate in the competition, played in a league format since 1986. Since its return, the tournament has used an unusual point scoring system. As with most league competitions, three points are awarded for a win, one for a draw, and none for a loss. However, an additional point is awarded for each goal scored. The system is designed to reward teams that adopt a more attacking style of play. Each entrant plays two matches, with the winner being the club that finishes at the top of the table. The original competition was held at De Meer, Ajax's home between 1934 and 1996. The Amsterdam Arena has played host to the event since its return until the last edition was played in 2009. Ajax is the most successful team of the tournament, having won it a record 10 times, while S.L. Benfica from Portugal were the last team to win the tournament in 2009.
Copa Amsterdam.
Established in 2005, the Copa Amsterdam is an international friendly football tournament for Under-19 youth teams, that is organized by Ajax and the Amsterdam city council, which takes place at the Olympic Stadium as part of the annual Amsterdam Sports Weekend, a citywide sponsored initiative to promote 'sports and recreation' within the city of Amsterdam. Each Summer the city of Amsterdam and Ajax invite U-19 teams from various top clubs from around the World to participate in the tournament. Seven teams are invited and play in the competition every year with the ninth edition of the tournament having occurred in 2013. Over the years, clubs such as Barcelona, Juventus, Chelsea and Real Madrid have had their senior youth teams participate in the tournament. Cruzeiro from Brazil are the most successful club in the history of the tournament, having won it three times in total, while Ajax Cape Town from South Africa are the current cup holders.
Future Cup.
Established in 2010, the AEGON Future Cup is an international friendly tournament for Under-17 youth teams, which is organized by AFC Ajax and their main sponsor, the insurance company AEGON. The tournament is held each year at the Amsterdam Arena and at the Sportpark De Toekomst, the teams training ground, which also inspired the name of the competition, since "De Toekomst" in Dutch means The Future. Every year during the Easter weekend, six U-17 teams are invited to participate in the competition, while the seventh place for the contesters is reserved for the winners of the "Craques Mongeral AEGON Future Cup" in Brazil, the sister competition of the tournament in South America. Youth teams from top clubs such as Manchester United, Bayern München, Milan and many more have participated in the competition over the years. Ajax are the most successful club of the tournament, having won the trophy a total of three times, and current cup holders having defeated Liverpool in the final of the latest edition.

</doc>
<doc id="2274" url="https://en.wikipedia.org/wiki?curid=2274" title="Arthur Eddington">
Arthur Eddington

Sir Arthur Stanley Eddington (28 December 1882 – 22 November 1944) was an English astronomer, physicist, and mathematician of the early 20th century who did his greatest work in astrophysics. He was also a philosopher of science and a popularizer of science. The Eddington limit, the natural limit to the luminosity of stars, or the radiation generated by accretion onto a compact object, is named in his honor.
He is famous for his work concerning the theory of relativity. Eddington wrote a number of articles that announced and explained Einstein's theory of general relativity to the English-speaking world. World War I severed many lines of scientific communication and new developments in German science were not well known in England. He also conducted an expedition to observe the Solar eclipse of 29 May 1919 that provided one of the earliest confirmations of General Relativity, and he became known for his popular expositions and interpretations of the theory.
Early years.
Eddington was born 28 December 1882 in Kendal, Westmorland (now Cumbria), England, the son of Quaker parents, Arthur Henry Eddington, headmaster of the Quaker School, and Sarah Ann Shout.
His father taught at a Quaker training college in Lancashire before moving to Kendal to become headmaster of Stramongate School. He died in the typhoid epidemic which swept England in 1884. His mother was left to bring up her two children with relatively little income. The family moved to Weston-super-Mare where at first Stanley (as his mother and sister always called Eddington) was educated at home before spending three years at a preparatory school. The family lived at a house called Varzin, 42 Walliscote Road, Weston-super-Mare. There is a commemorative plaque on the building explaining Sir Arthur's contribution to science.
In 1893 Eddington entered Brynmelyn School. He proved to be a most capable scholar, particularly in mathematics and English literature. His performance earned him a scholarship to Owens College, Manchester (what was later to become the University of Manchester) in 1898, which he was able to attend, having turned 16 that year. He spent the first year in a general course, but turned to physics for the next three years. Eddington was greatly influenced by his physics and mathematics teachers, Arthur Schuster and Horace Lamb. At Manchester, Eddington lived at Dalton Hall, where he came under the lasting influence of the Quaker mathematician J. W. Graham. His progress was rapid, winning him several scholarships and he graduated with a B.Sc. in physics with First Class Honors in 1902.
Based on his performance at Owens College, he was awarded a scholarship to Trinity College at the University of Cambridge in 1902. His tutor at Cambridge was Robert Alfred Herman and in 1904 Eddington became the first ever second-year student to be placed as Senior Wrangler. After receiving his M.A. in 1905, he began research on thermionic emission in the Cavendish Laboratory. This did not go well, and meanwhile he spent time teaching mathematics to first year engineering students. This hiatus was brief. Through a recommendation by E. T. Whittaker, his senior colleague at Trinity College, he secured a position at the Royal Observatory in Greenwich where he was to embark on the career in astronomy, a career whose seeds had been sown even as a young child when he would often "try to count the stars".
Death.
Eddington died of cancer in the Evelyn Nursing Home, Cambridge, on 22 November 1944. His body was cremated at Cambridge Crematorium (Cambridgeshire) on 27 November 1944; the cremated remains were buried in the grave of his mother in the Ascension Parish Burial Ground in Cambridge.
The new NW Cambridge development is going to be called "Eddington" after him.
Astronomy.
In January 1906, Eddington was nominated to the post of chief assistant to the Astronomer Royal at the Royal Greenwich Observatory. He left Cambridge for Greenwich the following month. He was put to work on a detailed analysis of the parallax of 433 Eros on photographic plates that had started in 1900. He developed a new statistical method based on the apparent drift of two background stars, winning him the Smith's Prize in 1907. The prize won him a Fellowship of Trinity College, Cambridge. In December 1912 George Darwin, son of Charles Darwin, died suddenly and Eddington was promoted to his chair as the Plumian Professor of Astronomy and Experimental Philosophy in early 1913. Later that year, Robert Ball, holder of the theoretical Lowndean chair also died, and Eddington was named the director of the entire Cambridge Observatory the next year. In May 1914 he was elected a Fellow of the Royal Society and won their Royal Medal in 1918 and delivered their Bakerian Lecture in 1926.
Eddington also investigated the interior of stars through theory, and developed the first true understanding of stellar processes. He began this in 1916 with investigations of possible physical explanations for Cepheid variable stars. He began by extending Karl Schwarzschild's earlier work on radiation pressure in Emden polytropic models. These models treated a star as a sphere of gas held up against gravity by internal thermal pressure, and one of Eddington's chief additions was to show that radiation pressure was necessary to prevent collapse of the sphere. He developed his model despite knowingly lacking firm foundations for understanding opacity and energy generation in the stellar interior. However, his results allowed for calculation of temperature, density and pressure at all points inside a star, and Eddington argued that his theory was so useful for further astrophysical investigation that it should be retained despite not being based on completely accepted physics. James Jeans contributed the important suggestion that stellar matter would certainly be ionized, but that was the end of any collaboration between the pair, who became famous for their lively debates.
Eddington defended his method by pointing to the utility of his results, particularly his important mass-luminosity relation. This had the unexpected result of showing that virtually all stars, including giants and dwarfs, behaved as ideal gases. In the process of developing his stellar models, he sought to overturn current thinking about the sources of stellar energy. Jeans and others defended the Kelvin–Helmholtz mechanism, which was based on classical mechanics, while Eddington speculated broadly about the qualitative and quantitative consequences of possible proton-electron annihilation and nuclear fusion processes.
With these assumptions, he demonstrated that the interior temperature of stars must be millions of degrees. In 1924, he discovered the mass-luminosity relation for stars (see Lecchini in #External links and references ). Despite some disagreement, Eddington's models were eventually accepted as a powerful tool for further investigation, particularly in issues of stellar evolution. The confirmation of his estimated stellar diameters by Michelson in 1920 proved crucial in convincing astronomers unused to Eddington's intuitive, exploratory style. Eddington's theory appeared in mature form in 1926 as "The Internal Constitution of the Stars", which became an important text for training an entire generation of astrophysicists.
Eddington's work in astrophysics in the late 1920s and the 1930s continued his work in stellar structure, and precipitated further clashes with Jeans and Edward Arthur Milne. An important topic was the extension of his models to take advantage of developments in quantum physics, including the use of degeneracy physics in describing dwarf stars.
Dispute with Chandrasekhar on existence of black holes.
The topic of extension of his models precipitated his famous dispute with Subrahmanyan Chandrasekhar, who was then a student at Cambridge. Chandrasekhar's work presaged the discovery of black holes, which at the time seemed so absurdly non-physical that Eddington refused to believe that Chandrasekhar's purely mathematical derivation had consequences for the real world. History clearly proved Eddington wrong, but his motivation remains a matter of some controversy. Chandrasekhar's narrative of this incident, in which his work is harshly rejected, portrays Eddington as rather cruel, dogmatic, and racist. This is at variance with Eddington's character as described by other contemporaries. Eddington's criticism seems to have been based on a suspicion that a purely mathematical derivation from relativity theory was not enough to explain away the seemingly daunting physical paradoxes that were inherent to degenerate stars.
Relativity.
During World War I, Eddington was Secretary of the Royal Astronomical Society, which meant he was the first to receive a series of letters and papers from Willem de Sitter regarding Einstein’s theory of general relativity. Eddington was fortunate in being not only one of the few astronomers with the mathematical skills to understand general relativity, but owing to his internationalist and pacifist views inspired by his Quaker religious beliefs, one of the few at the time who was still interested in pursuing a theory developed by a German physicist. He quickly became the chief supporter and expositor of relativity in Britain. He and Astronomer Royal Frank Watson Dyson organized two expeditions to observe a solar eclipse in 1919 to make the first empirical test of Einstein’s theory: the measurement of the deflection of light by the sun's gravitational field. In fact, Dyson’s argument for the indispensability of Eddington’s expertise in this test was what prevented Eddington from eventually having to enter military service.
When conscription was introduced in Britain on 2 March 1916, Eddington intended to apply for an exemption as a conscientious objector. Cambridge University authorities instead requested and were granted an exemption on the ground of Eddington's work being of national interest. In 1918, this was appealed against by the Ministry of National Service. Before the appeal tribunal in June, Eddington claimed conscientious objector status, which was not recognized and would have ended his exemption in August 1918. A further two hearings took place in June and July, respectively. Eddington's personal statement at the June hearing about his objection to war based on religious grounds is on record. Astronomer Royal, Sir Frank Dyson, supported Eddington at the July hearing with a written statement, emphasizing Eddington's essential role in the solar eclipse expedition to Principe in May 1919. Eddington made clear his willingness to serve in the Friends' Ambulance Unit, the Red Cross, or as a harvest laborer. However, the tribunal's decision to grant a further twelve months exemption from military service was on condition of Eddington continuing his astronomy work, in particular in preparation for the Principe expedition. The war ended before the end of his exemption.
After the war, Eddington traveled to the island of Príncipe near Africa to watch the solar eclipse of 29 May 1919. During the eclipse, he took pictures of the stars (several stars in the Hyades cluster include Kappa Tauri of the constellation Taurus) in the region around the Sun. According to the theory of general relativity, stars with light rays that passed near the Sun would appear to have been slightly shifted because their light had been curved by its gravitational field. This effect is noticeable only during eclipses, since otherwise the Sun's brightness obscures the affected stars. Eddington showed that Newtonian gravitation could be interpreted to predict half the shift predicted by Einstein.
Eddington's observations published the next year confirmed Einstein's theory, and were hailed at the time as a conclusive proof of general relativity over the Newtonian model. The news was reported in newspapers all over the world as a major story. Afterward, Eddington embarked on a campaign to popularize relativity and the expedition as landmarks both in scientific development and international scientific relations.
It has been claimed that Eddington's observations were of poor quality, and he had unjustly discounted simultaneous observations at Sobral, Brazil, which appeared closer to the Newtonian model, but a 1979 re-analysis with modern measuring equipment and contemporary software validated Eddington's results and conclusions. The quality of the 1919 results was indeed poor compared to later observations, but was sufficient to persuade contemporary astronomers. The rejection of the results from the Brazil expedition was due to a defect in the telescopes used which, again, was completely accepted and well-understood by contemporary astronomers.
Throughout this period, Eddington lectured on relativity, and was particularly well known for his ability to explain the concepts in lay terms as well as scientific. He collected many of these into the "Mathematical Theory of Relativity" in 1923, which Albert Einstein suggested was "the finest presentation of the subject in any language." He was an early advocate of Einstein's General Relativity, and an interesting anecdote well illustrates his humour and personal intellectual investment: Ludwik Silberstein, a physicist who thought of himself as an expert on relativity, approached Eddington at the Royal Society's (6 November) 1919 meeting where he had defended Einstein's Relativity with his Brazil-Principe Solar Eclipse calculations with some degree of skepticism, and ruefully charged Arthur as one who claimed to be one of three men who actually understood the theory (Silberstein, of course, was including himself and Einstein as the other). When Eddington refrained from replying, he insisted Arthur not be "so shy", whereupon Eddington replied, "Oh, no! I was wondering who the third one might be!"
Cosmology.
Eddington was also heavily involved with the development of the first generation of general relativistic cosmological models. He had been investigating the instability of the Einstein universe when he learned of both Lemaître's 1927 paper postulating an expanding or contracting universe and Hubble's work on the recession on the spiral nebulae. He felt the cosmological constant must have played the crucial role in the universe's evolution from an Einsteinian steady state to its current expanding state, and most of his cosmological investigations focused on the constant's significance and characteristics. In "The Mathematical Theory of Relativity," Eddington interpreted the cosmological constant to mean that the universe is "self-gauging".
Fundamental theory and the Eddington number.
During the 1920s until his death, he increasingly concentrated on what he called "fundamental theory" which was intended to be a unification of quantum theory, relativity, cosmology, and gravitation. At first he progressed along "traditional" lines, but turned increasingly to an almost numerological analysis of the dimensionless ratios of fundamental constants.
His basic approach was to combine several fundamental constants in order to produce a dimensionless number. In many cases these would result in numbers close to 1040, its square, or its square root. He was convinced that the mass of the proton and the charge of the electron were a "natural and complete specification for constructing a Universe" and that their values were not accidental. One of the discoverers of quantum mechanics, Paul Dirac, also pursued this line of investigation, which has become known as the Dirac large numbers hypothesis, and some scientists even today believe it has something to it.
A somewhat damaging statement in his defence of these concepts involved the fine structure constant, α. At the time it was measured to be very close to 1/136, and he argued that the value should in fact be exactly 1/136 for epistemological reasons. Later measurements placed the value much closer to 1/137, at which point he switched his line of reasoning to argue that one more should be added to the degrees of freedom, so that the value should in fact be exactly 1/137, the Eddington number. Wags at the time started calling him "Arthur Adding-one". This change of stance detracted from Eddington's credibility in the physics community. The current measured value is estimated at 1/137.035 999 074(44).
Eddington believed he had identified an algebraic basis for fundamental physics, which he termed "E-numbers" (representing a certain group – a Clifford algebra). These in effect incorporated spacetime into a higher-dimensional structure. While his theory has long been neglected by the general physics community, similar algebraic notions underlie many modern attempts at a grand unified theory. Moreover, Eddington's emphasis on the values of the fundamental constants, and specifically upon dimensionless numbers derived from them, is nowadays a central concern of physics. In particular, he predicted a number of hydrogen atoms in the Universe 136 × 2256, or equivalently the half of the total number of particles protons + electrons. When equalized with the non-dark energy equivalent number of hydrogen atoms (3/10) × Rc2/GmH, this corresponds to a Universe radius R = 13.8 Giga light year, a value predicted for years from universal constants using an atomic-cosmic symmetry, and compatible with c-times the so-called Universe age 13.80(4) Gyr, as determined by the recent mission Planck (March 2003).
He did not complete this line of research before his death in 1944; his book "Fundamental Theory" was published posthumously in 1948.
Eddington number for cycling.
Eddington is credited with devising a measure of a cyclist's long-distance riding achievements. The Eddington number in the context of cycling is defined as the maximum number E such that the cyclist has cycled E miles on E days. For example, an Eddington number of 70 would imply that the cyclist has cycled at least 70 miles in a day on 70 occasions. Achieving a high Eddington number is difficult since moving from, say, 70 to 75 will probably require more than five new long distance rides since any rides shorter than 75 miles will no longer be included in the reckoning. Eddington's own E-number was 84.
The Eddington number for cycling is analogous to the "h"-index that quantifies both the actual scientific productivity and the apparent scientific impact of a scientist.
It should be noted that the Eddington Number for cycling has units (indeed applying it to any physical property will result in E having units). For example, an E of 62 miles means a cyclist has covered 62 or more miles on 62 or more days. However, in units of kilometers the 62 miles becomes 100 km. It is possible that the cyclist, while having covered 100 km on 62 days or more, may not have covered 100 km on 100 days or more.
Philosophy.
Idealism.
Sir Arthur Eddington wrote in his book "The Nature of the Physical World" that "The stuff of the world is mind-stuff."
The idealist conclusion was not integral to his epistemology but was based on two main arguments.
The first derives directly from current physical theory. Briefly, mechanical theories of the ether and of the behavior of fundamental particles have been discarded in both relativity and quantum physics. From this, Eddington inferred that a materialistic metaphysics was outmoded and that, in consequence, since the disjunction of materialism or idealism are assumed to be exhaustive, an idealistic metaphysics is required. The second, and more interesting argument, was based on Eddington's epistemology, and may be regarded as consisting of two parts. First, all we know of the objective world is its structure, and the structure of the objective world is precisely mirrored in our own consciousness. We therefore have no reason to doubt that the objective world too is "mind-stuff." Dualistic metaphysics, then, cannot be evidentially supported.
But, second, not only can we not know that the objective world is nonmentalistic, we also cannot intelligibly suppose that it could be material. To conceive of a dualism entails attributing material properties to the objective world. However, this presupposes that we could observe that the objective world has material properties. But this is absurd, for whatever is observed must ultimately be the content of our own consciousness, and consequently, nonmaterial.
Ian Barbour, in his book Issues in Science and Religion (1966), p. 133, cites Arthur Eddington's The Nature of the Physical World (1928) for a text that argues The Heisenberg Uncertainty Principles provides a scientific basis for "the defense of the idea of human freedom" and his Science and the Unseen World (1929) for support of philosophical idealism "the thesis that reality is basically mental".
Charles De Koninck points out that Eddington believed in objective reality existing apart from our minds, but was using the phrase "mind-stuff" to highlight the inherent intelligibility of the world: that our minds and the physical world are made of the same "stuff" and that our minds are the inescapable connection to the world. As De Koninck quotes Eddington,
Indeterminism.
Against Albert Einstein and others who advocated determinism, indeterminism—championed by Eddington—says that a physical object has an ontologically undetermined component that is not due to the epistemological limitations of physicists' understanding. The uncertainty principle in quantum mechanics, then, would not necessarily be due to hidden variables but to an indeterminism in nature itself.
Popular and philosophical writings.
Eddington wrote a clever parody of "The Rubaiyat of Omar Khayyam", recounting his 1919 solar eclipse experiment. It contained the following quatrain:
During the 1920s and 30s, Eddington gave innumerable lectures, interviews, and radio broadcasts on relativity, in addition to his textbook "The Mathematical Theory of Relativity", and later, quantum mechanics. Many of these were gathered into books, including "The Nature of the Physical World" and "New Pathways in Science". His skillful use of literary allusions and humor helped make these famously difficult subjects quite accessible.
Eddington's books and lectures were immensely popular with the public, not only because of Eddington’s clear and entertaining exposition, but also for his willingness to discuss the philosophical and religious implications of the new physics. He argued for a deeply rooted philosophical harmony between scientific investigation and religious mysticism, and also that the positivist nature of modern physics (i.e., relativity and quantum physics) provided new room for personal religious experience and free will. Unlike many other spiritual scientists, he rejected the idea that science could provide proof of religious propositions.
He is sometimes misunderstood as having promoted the infinite monkey theorem in his 1928 book "The Nature of the Physical World", with the phrase "If an army of monkeys were strumming on typewriters, they might write all the books in the British Museum". It is clear from the context that Eddington is not suggesting that the probability of this happening is worthy of serious consideration. On the contrary, it was a rhetorical illustration of the fact that below certain levels of probability, the term "improbable" is functionally equivalent to "impossible".
His popular writings made him, quite literally, a household name in Great Britain between the world wars.
Honors.
Awards
Named after him
Service

</doc>
<doc id="2275" url="https://en.wikipedia.org/wiki?curid=2275" title="Apple II">
Apple II

The Apple II (stylized as apple ][) is an 8-bit home computer, one of the first highly successful mass-produced microcomputer products, designed primarily by Steve Wozniak (Steve Jobs oversaw the development of the Apple II's unusual case and Rod Holt developed the unique power supply). It was introduced in 1977 at the West Coast Computer Faire by Jobs and was the first consumer product sold by Apple Computer. It is the first model in a series of computers which were produced until Apple IIe production ceased in November 1993.
History.
The earliest Apple IIs were assembled in Silicon Valley, and later in Texas; printed circuit boards were manufactured in Ireland and Singapore. The first computers went on sale on June 10, 1977 with a MOS Technology 6502 microprocessor running at , two game paddles, of RAM, an audio cassette interface for loading programs and storing data, and the Integer BASIC programming language built into the ROMs. The video controller displays 24 lines by 40 columns of monochrome, upper-case-only (the original character set matches ASCII characters 20h to 5Fh) text on the screen, with NTSC composite video output suitable for display on a TV monitor, or on a regular TV set by way of a separate RF modulator. The original retail price of the computer was (with of RAM) and (with the maximum of RAM). To reflect the computer's color graphics capability, the Apple logo on the casing has rainbow stripes, which remained a part of Apple's corporate logo until early 1998.
Overview.
In the May 1977 issue of "BYTE", Steve Wozniak published a detailed description of his design; the article began, "To me, a personal computer should be small, reliable, convenient to use and inexpensive".
The Apple II used a multiplicity of idiosyncratic engineering shortcuts to save hardware and reduce costs. For example: 
The text and graphics screens have a complex arrangement (the scanlines were not stored in sequential areas of memory) which is reputedly due to Wozniak's realization that doing it that way would allow for the refresh of the dynamic RAM as a side effect, as described above; it had no cost overhead to have software calculate or look up the address of the required scanline and avoided the need for significant extra hardware. Similarly, in the high-resolution graphics mode, color is determined by pixel position and can thus be implemented in software, saving Wozniak the chips needed to convert bit patterns to colors. This also allows for subpixel font rendering since orange and blue pixels appear half a pixel-width farther to the right on the screen than green and purple pixels.
The Apple II at first used data cassette storage like most other microcomputers of the time. In 1978 the company introduced an external 5¼-inch floppy disk drive, the Disk II, attached via a controller card that plugs into one of the computer's expansion slots (usually slot 6). The Disk II interface, created by Wozniak, is regarded as an engineering masterpiece for its economy of electronic components.
The approach taken in the Disk II controller is typical of Wozniak's designs. With a few small-scale logic chips and a cheap PROM (programmable read-only memory), he created a functional floppy-disk interface at a fraction of the component cost of standard circuit configurations.
Innovation of integrated user interface.
With the Apple I and the Apple II, Wozniak introduced an entirely novel configuration of the microcomputer concept which was immediately adopted as the industry standard, and remains taken for granted to this day - namely the integration of the standard input and output devices (the typewriter style keyboard and the video display screen) into the computer itself. Until that time, microcomputer devices either had an extremely limited I/O capability - such as perhaps a hex keypad and a 16 or 32 character display, or no built-in user interface at all following the convention of mainframe and minicomputers in requiring the connection of an external teleprinter unit or visual display terminal to complete a usable system. The cost of such terminals could easily exceed the price of the computer itself. Wozniak's inclusion of an RF output which could connect to the aerial socket of a standard domestic television set enabled users to acquire a complete system without incurring the cost of a video monitor.
Display and graphics.
Color on the Apple II series uses a quirk of the NTSC television signal standard, which made color display relatively easy and inexpensive to implement. The original NTSC television signal specification was black-and-white. Color was added on later by adding a 3.58-MHz subcarrier signal that was partially ignored by B&W TV sets. Color is encoded based on the "phase" of this signal in relation to a reference "color burst" signal. The result is that the position, size, and intensity of a series of pulses define color information. These pulses can translate into "pixels" on the computer screen, with the possibility of exploiting composite artifact colors.
The Apple II display provides two pixels per subcarrier cycle. When the color burst reference signal is turned on and the computer attached to a color display, it can display green by showing one alternating pattern of pixels, magenta with an opposite pattern of alternating pixels, and white by placing two pixels next to each other. Blue and orange are available by tweaking the offset of the pixels by half a pixel-width in relation to the color-burst signal. The high-resolution display offers more colors by compressing more, narrower pixels into each subcarrier cycle.
The coarse, low-resolution graphics display mode works differently, as it can output a pattern of dots per pixel to offer more color options. These patterns are stored in the character generator ROM and replace the text character bit patterns when the computer is switched to low-res graphics mode. The text mode and low-res graphics mode use the same memory region and the same circuitry is used for both.
Sound.
Rather than having a dedicated sound-synthesis chip, the Apple II has a toggle circuit that can only emit a click through a built-in speaker or a line out jack; all other sounds (including two, three and, eventually, four-voice music and playback of audio samples and speech synthesis) are generated entirely by software that clicked the speaker at just the right times. Similar techniques are used for cassette storage: the cassette output works the same as the speaker, and the input is a simple zero-crossing detector that serves as a relatively crude (1-bit) audio digitizer. Routines in the ROM encode and decode data in frequency-shift keying for the cassette.
Languages.
Initially the Apple II was shipped with a built-in BASIC language interpreter encoded in the mother-board ROM chips. Written by Wozniak, the interpreter enabled users to write software applications without needing to purchase additional development utilities. Written with games programmers and hobbyists in mind, the language only supported the encoding of numbers in 16-bit integer format. The limitation of restricting numerical values to whole numbers in the range between -32768 to +32767 compromised the machine's attraction to business users. Jobs responded by licensing a floating-point version of Basic from Microsoft which was initially available as a plug-in expansion card. This more versatile (but slower) variant was more popular with customers, so later models were shipped with it as standard and anyone wanting Integer Basic had to get that on a language card.
As shipped, the machine incorporated a "monitor" program which supported functions such as displaying and altering the contents of the computer's RAM memory in hexadecimal format, either one byte at a time or in blocks of 256 bytes at once. This feature enabled hackers to write and debug machine code programs without needing further development software.
A 6502 assembler was soon offered on disk, and later the UCSD complier and operating system for the Pascal language was made available. The Pascal system required a 16k RAM card to be installed in the language card position (expansion slot 0) in addition to the full 48k of mother-board memory.
Third-party devices and applications.
Wozniak's open architecture design and the Apple II's multiple expansion slots permit a wide variety of third-party devices, including peripheral cards such as serial controllers, display controllers, memory boards, hard disks, networking components, and realtime clocks. There are plug-in expansion cards – such as the Z-80 SoftCard – that permit the Apple to use the Z80 processor and run programs for the CP/M operating system, including the dBase II database and the WordStar word processor. There is also a third-party 6809 card that allows OS-9 Level One to be run. Third-party sound cards greatly improve audio capabilities, allowing simple music synthesis and text-to-speech functions. Apple II accelerator cards double or quadruple the computer's speed.
Reception.
After seeing a crude, wire-wrapped prototype demonstrated by Wozniak and Steve Jobs in November 1976, "BYTE" predicted in April 1977 that the Apple II "may be the first product to fully qualify as the 'appliance computer' ... a completed system which is purchased off the retail shelf, taken home, plugged in and used". As Jesse Adams Stein points out, "As the first company to release a 'consumer appliance' micro-computer, Apple Computer offers us a clear view of this shift from a 'machine' to an 'appliance'." But the company also had "to negotiate the attitudes of its potential buyers, bearing in mind social anxieties about the uptake of new technologies in multiple contexts. The office, the home and the 'office-in-the-home' were implicated in these changing spheres of gender stereotypes and technological development."
The computer's color graphics capability especially impressed the magazine. The magazine published a favorable review of the computer in March 1978, concluding that "For the user that wants color graphics, the Apple II is the only practical choice available in the 'appliance' computer class".
"Personal Computer World" in August 1978 also cited the color capability as a strength, stating that "the prime reason that anyone buys an Apple II must surely be for the colour graphics". While mentioning the "oddity" of the artifact colors that produced output "that is not always what one wishes to do", it noted that "no-one has colour graphics like this at this sort of price". The magazine praised the sophisticated monitor software, user expandability, and comprehensive documentation, and concluded that "the Apple II is a very promising machine" which "would be even more of a temptation were its price slightly lower ... for the moment, colour is an Apple II".
Although it sold briskly from the launch, the initial market was to hobbyists, games players and computer enthusiasts. Sales expanded exponentially into the business and professional market when the spreadsheet program VisiCalc was launched in mid 1979. VisiCalc is credited with being the defining "killer app" in the microcomputer industry.
During the first five years of operations revenues grew exponentially, doubling about every four months. Between September 1977 and September 1980 yearly sales grew from $775,000 to $118m, an average annual growth rate of 533%. During this period the sole products of the company were the Apple II and its peripherals, accessories and software.

</doc>
<doc id="2279" url="https://en.wikipedia.org/wiki?curid=2279" title="April 3">
April 3


</doc>
<doc id="2282" url="https://en.wikipedia.org/wiki?curid=2282" title="Alexis Korner">
Alexis Korner

Alexis Korner (19 April 1928 – 1 January 1984) was a British blues musician and radio broadcaster, who has sometimes been referred to as "a founding father of British blues". A major influence on the sound of the British music scene in the 1960s, Korner was instrumental in bringing together various English blues musicians.
Early career.
Alexis Andrew Nicholas Koerner was born in Paris to an Austrian Jewish father and a -Greek mother. He spent his childhood in France, Switzerland and North Africa and arrived in London in 1940 at the start of World War II. One memory of his youth was listening to a record by black pianist Jimmy Yancey during a German air raid. Korner said, "From then on all I wanted to do was play the blues."
After the war, Korner played piano and guitar (his first guitar was built by friend and author Sydney Hopkins, who wrote "Mister God, This Is Anna") and in 1949 joined Chris Barber's Jazz Band where he met blues harmonica player Cyril Davies. They started playing together as a duo, started the influential London Blues and Barrelhouse Club in 1955 and made their first record together in 1957. Korner made his first official record on Decca Records DFE 6286 in the company of Ken Colyer's Skiffle Group. His talent extended to playing mandolin on one of the tracks of this rare British EP, recorded in London on 28 July 1955. Korner brought many American blues artists, previously virtually unknown in Britain, to perform.
The 1960s.
In 1961, Korner and Davies formed Blues Incorporated, initially a loose-knit group of musicians with a shared love of electric blues and R&B music. The group included, at various times, Charlie Watts, Jack Bruce, Ginger Baker, Long John Baldry, Graham Bond, Danny Thompson and Dick Heckstall-Smith. It also attracted a wider crowd of mostly younger fans, some of whom occasionally performed with the group, including Mick Jagger, Keith Richards, Brian Jones, Geoff Bradford, Rod Stewart, John Mayall and Jimmy Page.
One story is that the Rolling Stones went to stay at Korner's house late one night, in the early 1960s, after a performance. They entered in the accepted way, by climbing in through the kitchen window, to find Muddy Waters' band sleeping on the kitchen floor.
Although Cyril Davies left the group in late-1962, Blues Incorporated continued to record, with Korner at the helm, until 1966. However, by that time its originally stellar line-up (and crowd of followers) had mostly left to start their own bands. "While his one-time acolytes the Rolling Stones and Cream made the front pages of music magazines all over the world, Korner was relegated to the role of 'elder statesman'."
Although he himself was a blues purist, Korner criticised better-known British blues musicians during the blues boom of the late 1960s for their blind adherence to Chicago blues, as if the music came in no other form. He liked to surround himself with jazz musicians and often performed with a horn section drawn from a pool that included, among others, saxophone players Art Themen, Mel Collins, Dick Heckstall-Smith, Lol Coxhill, Dick Morrissey, John Surman and trombonist Mike Zwerin.
Broadcasting.
In the 1960s Korner began a media career, working initially as a show business interviewer and then on ITV's "Five O'Clock Club", a children's TV show. Korner also wrote about blues for the music papers, and continued to maintain his own career as a blues artist, especially in Europe.
On 17 October 1967, Korner interviewed the Jimi Hendrix Experience for the BBC radio show "Top Gear". Some of these tracks, including audio of Korner himself, appear on the Hendrix double-CD "BBC Sessions", including Korner playing slide guitar on "(I'm Your) Hoochie Coochie Man".
While touring Scandinavia he formed the band New Church with guitarist and singer Peter Thorup. They subsequently were one of the support bands at the Rolling Stones Free Concert in Hyde Park, London, on 5 July 1969. Jimmy Page reportedly found out about a new singer, Robert Plant, who had been jamming with Korner, who wondered why Plant had not yet been discovered. Plant and Korner were recording an album with Plant on vocals until Page had asked him to join "the New Yardbirds", a.k.a. Led Zeppelin. Only two songs are in circulation from these recordings: "Steal Away" and "Operator". Alexis Korner gave one of his last radio interviews to BBC Midlands on the "Record Collectors Show" with Mike Adams and the Late Chris Savory.
1970s.
In 1970 Korner and Thorup formed a big-band ensemble, C.C.S. – short for "The Collective Consciousness Society" – which had several hit singles produced by Mickie Most, including a version of Led Zeppelin's "Whole Lotta Love", which was used as the theme for BBC's "Top of the Pops" between 1971 and 1981. Another instrumental called "Brother" was used as the theme to the BBC Radio 1 Top 20/40 when Tom Browne/Simon Bates presented the programme in the 1970s. It was also used in the 1990s on Radio Luxembourg for the Top 20 Singles chart. This was the period of Korner's greatest commercial success in the UK.
1970s to 1984.
In 1973, he and Peter Thorup formed another group, Snape, with Boz Burrell, Mel Collins, and Ian Wallace, who were previously together in King Crimson. Korner also played on B.B. King's "In London" album, and cut his own, similar "supersession" album; "Get Off My Cloud", with Keith Richards, Steve Marriott, Peter Frampton, Nicky Hopkins and members of Joe Cocker's Grease Band. In the mid-1970s, while touring Germany, Korner established an intensive working relationship with bassist Colin Hodgkinson who played for the support act Back Door. They would continue to collaborate right up until Korner's death.
In the 1970s Korner's main career was in broadcasting. In 1973 he presented a unique 6-part documentary on BBC Radio 1, "The Rolling Stones Story", and in 1977 he established a Sunday-night blues and soul show on Radio 1, "Alexis Korner's Blues and Soul Show", which ran until 1981. He also used his gravelly voice to great effect as an advertising voice-over artist. In 1978, for Korner's 50th birthday, an all-star concert was held featuring many of his above-mentioned friends, as well as Eric Clapton, Paul Jones, Chris Farlowe, Zoot Money and others, which was later released as "The Party Album", and as a video.
In 1981, Korner joined another "supergroup", Rocket 88, a project led by Ian Stewart based on boogie-woogie keyboard players, which featured a rhythm section comprising Jack Bruce and Charlie Watts, among others, as well as a horn section. They toured Europe and released an album on Atlantic Records. He played in Italy with Paul Jones and the Blues Society of Italian bluesman Guido Toffoletti.
Family life and death.
In 1950, Korner married Roberta Melville, daughter of art critic Robert Melville. Korner died aged 55 years, on 1 January 1984. 

</doc>
<doc id="2284" url="https://en.wikipedia.org/wiki?curid=2284" title="Assault gun">
Assault gun

An assault gun is a gun or howitzer mounted on a motor vehicle or armoured chassis, designed for use in the direct fire role in support of infantry when attacking other infantry or fortified positions. The term is a literal translation of the German word "Sturmgeschütz". Nazi Germany introduced the first purpose-built assault gun, the StuG III, in the late 1930s, thus establishing this category of armoured vehicles.
Historically, the custom-built fully armoured assault guns usually mounted the gun or howitzer in a fully enclosed casemate on a tank chassis. The use of a casemate instead of a turret limited these weapons' field of fire, but allowed a larger gun to be fitted relative to the chassis, more armour to be fitted for the same weight, and provided a cheaper construction. In most cases, these turretless vehicles also presented a lower profile as a target for the enemy.
The assault gun looks and works in the same way as the similar tank destroyer, the only difference in most cases being the gun. Assault guns generally used larger calibre, lower velocity guns, with their primary ammunition being that of high-explosive shells; these were meant for taking out soft targets as outlined in its infantry support role. This was contrasted with the tank destroyer, which utilized higher velocity, and therefore smaller calibre guns, firing armour-piercing shells as their primary ammunition. Therefore, these vehicles often sacrificed being able to fire a good high-explosive shell in exchange for maximal armour penetration characteristics. Towards the beginning of the war, a single vehicle could generally be used in both roles, but that changed as the classes became increasingly specialized as the war progressed.
History.
World War II.
Assault guns were primarily used during World War II by the forces of Nazi Germany and the Soviet Union. Early in the war, the Germans began to create makeshift assault guns by mounting their infantry support weapons on the bed of a truck or on obsolete tanks with the turret removed. Later in the war, both the Germans and the Soviets introduced fully armoured purpose-built assault guns into their arsenals.
Early on, the Soviets built the KV-2, a variant of the KV-1 heavy tank with a short-barrelled 152 mm howitzer mounted in an oversized turret. This was not a success in battle, and was replaced with a very successful series of increasingly powerful turretless assault guns: the SU-76, SU-122, and the heavy SU-152, which were followed by the ISU-122 and ISU-152 on the new IS heavy tank chassis.
The primary German assault gun was the "Sturmgeschütz III" (StuG III). Late production StuG III variants, armed with a high-velocity dual-purpose 75mm gun blurred the line between assault guns and tank destroyers and were the Wehrmacht's most-produced armoured fighting vehicle, at some 9,400 examples. The Germans also built a number of other fully armoured turretless assault guns, including the StuG IV, "Brummbär" and "Sturmtiger". The latter two were very heavy vehicles, and were built only in small quantities.
Battalions of assault guns, usually StuG IIIs, commonly replaced the intended panzer battalion in the German panzergrenadier divisions due to the chronic shortage of tanks, and were sometimes used as makeshifts even in the panzer divisions. Independent battalions were also deployed as "stiffeners" for infantry divisions, and the StuG III's anti-tank capabilities bolstered dwindling tank numbers on the Eastern and Western fronts.
US and UK forces also deployed vehicles designed for a close support role, but these were conventional tanks whose only significant modification was the replacement of the main gun with a howitzer. Two versions of the American Sherman tank were armed with the M4 105 mm howitzer, the M4(105) and the M4A3(105). The Churchill, Centaur and Cromwell tanks were all produced in versions armed with 95 mm howitzers: the Churchill Mark V and Mark VIII, the Centaur Mark IV and the Cromwell Mark VI. Earlier British tanks, such as the Crusader cruiser tank and the Matilda II Infantry tank were produced in versions armed with the 3-inch howitzer; the first versions of the Churchill tank also had this gun in a hull mounting. As the amount of German armour encountered by the Allies decreased, especially in Italy, a number of American tank destroyer units were used in the assault gun role for infantry support.
The AVRE version of the Churchill Tank was armed with a Spigot mortar that fired a HE-filled projectile (nicknamed the "Flying Dustbin") . Its task was to attack fortified positions such as bunkers at close range (see Hobart's Funnies).
Post-war use.
In the post-WWII era, vehicles fitting into an "assault gun" category were developed as a light-weight, air-deployable, direct fire weapon for use with airborne troops. Current weapons were either based on jeeps or small tracked vehicles and the airborne troops thus always fought at a distinct disadvantage in terms of heavy weapons. The Soviet Union and the United States were the most attracted to the idea of providing this capability to traditionally light airborne forces. Their answers to the problem were similar, with the United States developing the M56 Scorpion and the Soviet Union developing the ASU-57, both essentially air-droppable light anti-tank guns.
The Soviets went on to develop an improved air-droppable assault gun, the ASU-85, which served through the 1980s, while their SU-100 remained in service with Communist countries, including Vietnam and Cuba, years after WW2. The US M56 and another armoured vehicle, the M50 Ontos, were to be the last of the more traditional assault guns in US service. Improvised arrangements such as M113 personnel carriers with recoilless rifles were quickly replaced by missile carrier vehicles in the anti-tank role.
The only vehicle with the qualities of an assault gun to be fielded after the removal of the M50 and M56 from service within the US military was the M551 Sheridan. The Sheridan's gun was a low-velocity weapon suitable in the assault role, but with the addition of the Shillelagh missile could double in the anti-tank role as well. The Sheridan, however, was not developed as an assault gun but as a light reconnaissance vehicle.
Currently there appears to be a move toward wheeled vehicles fitting a "tank destroyer" or "assault gun" role, such as the M1128 Mobile Gun System of the US Army, the Centauro Wheeled Tank Destroyer of the Italian and Spanish Armies, the Chinese anti-tank gun PTL-02 and ZBL08 assault gun, and the French AMX 10 RC heavy armoured car. While these vehicles might be useful in a direct fire role, none were developed with this specifically in mind, reminiscent of the use of tank destroyers by the US military in the assault gun role during WWII.

</doc>
<doc id="2286" url="https://en.wikipedia.org/wiki?curid=2286" title="Tank destroyer">
Tank destroyer

A tank destroyer or tank hunter is a type of armoured fighting vehicle, armed with a direct-fire artillery gun or missile launcher, with limited operational capacities and designed specifically to engage enemy armoured vehicles.
Tanks are generally armoured fighting vehicles designed for front-line combat which combine operational mobility and tactical offensive and defensive capabilities and perform all primary tasks of the armoured troops on the battlefield; the tank destroyer on the other hand is specifically designed mainly for taking on enemy armour. Many have been based on a tracked tank chassis, while others are wheeled.
Since World War II, gun-armed tank destroyers have fallen out of favor as armies have favored multirole main battle tanks. However, lightly armored anti-tank guided missile (ATGM) carriers are commonly used for supplementary long-range anti-tank work. The resurgence of expeditionary warfare in the past twenty years has seen the emergence of gun-armed wheeled vehicles, sometimes called "protected gun systems", which may bear a superficial resemblance to tank destroyers, but are employed as direct fire support units typically providing support in low-intensity operations such as the wars in Iraq and Afghanistan.
World War II.
Dedicated anti-tank vehicles made their first major appearance in the Second World War as combatants developed effective armored vehicles and tactics. Some were little more than stopgap solutions, mounting an anti-tank gun on a tracked vehicle to give mobility, while others were more sophisticated designs. An example of the development of tank destroyer technology throughout the war are the Marder III and Hetzer vehicle, that were very different in spite of being based on the same chassis: Marder was straightforwardly an anti-tank gun on tracks whereas Hetzer traded some firepower (its Pak 39, designed to operate within the confines of a fully armored fighting compartment, fires the same projectiles from a reduced propellant charge compared to Marder's Pak 40) for better armor protection and ease of concealment on the battlefield.
Except for most American designs, tank destroyers were all turretless and had fixed or casemate superstructures. When a tank destroyer was used against enemy tanks from a defensive position such as by ambush, the common lack of a rotating turret was not particularly critical, while the lower silhouette was highly desirable. The turretless design allowed accommodation of a more powerful gun, typically a dedicated anti-tank gun (in lieu of a regular tank's general-purpose main gun that fired both anti-tank and high explosive ammunition) that had a longer barrel than could be mounted in a turreted tank on the same chassis. The lack of a turret increased the vehicle's internal volume, allowing for increased ammunition stowage and crew comfort. Eliminating the turret allowed the vehicle to carry thicker armor than would otherwise be the case, and also allowed this armour to be concentrated in the hull. Sometimes there was no armored roof (only a weather cover) to keep the overall weight down to the limit that the chassis could bear. The absence of a turret meant that tank destroyers could be manufactured significantly cheaper, faster and more easily than the tanks on which they were based and found particular favor when production resources were lacking. After hard lessons early in the war, machine guns were mounted for use against infantry, but the limited traverse of the mounting meant that they were still less effective than those used on turreted tanks.
Polish.
Variants of the Polish TKS and TK-3 tankettes up-armed with 20 mm gun (23–26 vehicles) were operationally deployed in the invasion of Poland. They were used as an anti-tank component of the reconnaissance units.
French.
Due to the quick defeat of France, few French vehicles were built. The Laffly W15 TCC ("Chasseur de char") was an attempt to quickly build a light tank destroyer by mounting a 47mm SA37 anti-tank gun onto a lightly armored Laffly W15T artillery tractor. Other French tank destroyers were being developed, including the SOMUA SAu-40, ARL V39 and various ad hoc conversions of the Lorraine 37L.
German.
The first German tank destroyers were the "Panzerjäger" ("tank hunters") which took an existing anti-tank gun and mounted it on a convenient chassis to give mobility, usually with just a three-sided gun shield for crew protection. For instance, 202 obsolete Panzer I light tanks were modified by removing the turret and were rebuilt as the Panzerjäger I self-propelled Skoda anti-tank gun. Similarly, Panzer II tanks were used on the eastern front. Captured Soviet anti-tank guns were mounted on modified Panzer II chassis, producing the Marder II self-propelled anti-tank gun. The most common mounting was a German anti-tank gun on the Czech Panzer 38(t) chassis to produce the Marder III. The Panzer 38(t) chassis was also used to make the Jagdpanzer 38 'Hetzer' casemate style tank destroyer. The Panzerjäger series continued up to the equipped Nashorn.
German tank destroyers based on the Panzer III and later German tanks were unique in that they had more armor than their tank counterparts. One of the more successful German tank destroyers was actually designed as a self-propelled artillery gun, the Sturmgeschütz III. Based on the Panzer III tank chassis, the Sturmgeschütz III was originally fitted with a low-velocity gun, and was assigned to the artillery arm for infantry fire support. Later, after encountering Soviet tanks, it was refitted with a comparatively short-barreled high-velocity anti-tank gun, usually with a muzzle brake, enabling it to function as a tank destroyer. The "Sturmgeschütz III" from its 1938 origin used a new casemate-style superstructure with an integrated design similar to the later "Jagdpanzer" to completely enclose the crew. It was employed in infantry support and offensive armored operations as well as in the defensive anti-tank role. The StuG III was the most-produced German armored fighting vehicle of any type built during the war years, with some 10,000 examples built from January 1940 through March 1945.
Although the early German "Panzerjäger" carried more effective weapons than the tanks on which they were based, they were generally lacking in protection for the crew, having thinly armored open-topped superstructures. The "open-topped" design format of the "Panzerjäger" vehicles was succeeded by the "Jagdpanzer" '("hunting tanks") which mounted the gun in true casemate-style superstructures, completely enclosing the crew compartment in armor that would usually be integral to the hull. The first of these "Jagdpanzer"s was the 70-ton "Ferdinand" (later renamed "Elefant"), based on the chassis, hulls, and drive systems of ninety-one Porsche VK4501 (P) heavy tanks, mounting a long-barreled 88 mm cannon in an added casemate, more like the earlier "Panzerjägers" had with their added-on armor shielding for the gun crew, but in the "Elefant" completely enclosing the gun and firing crew in the added casemate, as the later purpose-built "Jagdpanzers" would. However, the "Elefant" proved to be mechanically unreliable and difficult to maneuver, and once all ninety-one unturreted "Porsche Tiger" hulls/drive systems were converted, no more were built. The German Army had more success with the Jagdpanther. Introduced in mid-1944, the Jagdpanther was considered the best of the casemate-design Jagdpanzer designs. It featured the same powerful PaK 43 88mm cannon used on the unwieldy "Elefant", now fitted to the chassis of the medium Panther tank, providing greatly improved armor-penetrating capability in a medium-weight vehicle.
Facing an increasingly defensive war, the German Army turned to larger and more powerfully armed Jagdpanzer designs, and in July 1944 the first "Jagdtiger" rolled off the production line; it was the heaviest German armored fighting vehicle to go into active service. The "Jagdtiger" featured a huge 128 mm PaK 44 cannon and heavy armor protection. Only 88 "Jagdtiger" vehicles were produced, barely matching the total number of the earlier Ferdinand/Elefant vehicles. They were first deployed to combat units in September 1944.
The decision of German armored vehicle designers to use a casemate-style superstructure for all tank destroyers had the advantage of a reduced silhouette, allowing the crew to more frequently fire from defilade ambush positions. Such designs were also easier and faster to manufacture and offered good crew protection from artillery fire and shell splinters. However, the lack of a rotating turret limited the gun's traverse to a few degrees. This meant that the entire tank normally had to be turned onto its target by the driver, a much slower process than simply rotating a powered turret. If the vehicle became immobilized due to engine failure or track damage, it could not rotate its gun to counter opposing tanks, making it highly vulnerable to counterfire. This vulnerability was later exploited by opposing tank forces. Even the largest and most powerful of German tank destroyers were found abandoned on the field after a battle, having been immobilized by one or more hits by high explosive (HE) or armor-piercing (AP) shells to the track or front drive sprocket.
Soviet.
As with the Germans of 1943, most of the Soviet designs mounted anti-tank guns, with limited traverse in casemate-style turretless hulls, in a general design format looking much like the Germans' own "Jagdpanzer" vehicles. The results were smaller, lighter, and simpler to build weapons that could carry larger guns than any contemporary tank, including the King Tiger II. The Soviets produced high numbers of the SU-85 and SU-100 self-propelled guns based on the same chassis as the T-34 medium tank; the heavier-duty powertrain and hull of the IS-2 heavy tank were instead used to produce the heavier-hitting -armed ISU-122 and -armed ISU-152, both of which had impressive anti-tank capabilities earning each of them the Russian nickname "Zveroboy" ("beast killer") for their ability to destroy German Tigers, Panthers and Elefants. The predecessor of the ISU 152 was the SU 152, built on the KV1S chassis and shared many similarities (including its gun) with the ISU 152. The ISU-152 built as a heavy assault gun, relied on the weight of the shell fired from its M-1937/43 howitzer to defeat tanks. In 1943, the Soviets also shifted all production of light tanks like the T-70 to much simpler and better-armed SU-76 self-propelled guns, which used the same drive train. The SU-76 was originally designed as an anti-tank vehicle, but was soon relegated to the infantry-support role.
American.
U.S. Army and counterpart British designs were very different in conception. U.S. doctrine was based, in light of the fall of France, on the perceived need to defeat German blitzkrieg tactics, and U.S. units expected to be faced with large numbers of German tanks attacking on relatively narrow fronts. These were "expected" to break through a thin screen of anti-tank guns, hence the decision that the main anti-tank units – the Tank Destroyer (TD) battalions – should be concentrated and very mobile. In actual practice, such German attacks rarely happened; throughout the war only one battalion ever fought in an engagement quite like that which had originally been envisaged (the 601st, at the Battle of El Guettar). The Tank Destroyer Command eventually numbered over 100,000 men and 80 battalions each equipped with 36 self-propelled tank destroyers or towed guns.
Only a few shots were expected to be fired from any firing position. Strong reconnaissance elements were provided so that TDs would be able to use pre-arranged firing positions to best advantage. Flanking fire by TDs was emphasized, both to penetrate thinner enemy side armor, and to reduce the likelihood of accurate enemy return fire.
All American tank destroyers were officially known by exactly the same collective term used for American self-propelled artillery ordnance, "Gun Motor Carriage". The designs were intended to be very mobile and heavily armed. Most of the tank-hull based designs used special open-topped turrets, of a differing design to the original tank it was to be based on, which was meant to both save weight and to accommodate a larger gun. The earliest expedient design was an M3 Half-track mounting an M1897 gun in a limited-traverse mount, and called the 75 mm Gun Motor Carriage M3. Another, considerably less successful, early design mounted a 37-mm anti-tank gun in the bed of a Dodge 3/4-ton truck - the 37-mm GMC M6. By far the most common US design, and the first to be fully tracked and turreted (which became the American hallmark of World War II "tank destroyer" design) was the 3in Gun Motor Carriage M10 (Wolverine), later supplemented by the 90 mm Gun Motor Carriage M36 - both based on the M4 Sherman hull and powertrain - and the 76 mm Gun Motor Carriage M18 (Hellcat), based on a unique hull and powertrain design, with a slight visual resemblance to what was used for the later M24 Chaffee light tank. The M18 came closest to the US ideal; the vehicle was very fast, small, and mounted a gun in a roofless open turret. The M36 Jackson GMC possessed the only American-origin operational gun that could rival the vaunted 88 mm German anti-tank ordnance, the 90 mm M3 gun, and the M36 remained in service well after World War II. The only dedicated American-origin, casemate hull design fighting vehicle of any type to be built during the war, that resembled the German and Soviet tank destroyers in hull and general gun mounting design, was the experimental T28 Super Heavy Tank, which mounted a 105 mm T5E1 long-barrel cannon, which had a maximum firing range of 12 miles (20 km), and was originally designed as a self-propelled assault gun to breach Germany's Siegfried Line defenses.
Of these tank destroyers, only the gun of the M36 proved to be effective against the frontal armor of Germans' larger armored vehicles at long range. The open top and light armor made these tank destroyers vulnerable to anything greater than small-arms fire. As the number of German tanks encountered by American forces steadily decreased throughout the war, most battalions were split up and assigned to infantry units as supporting arms, fighting as assault guns or being used essentially as tanks.
Doctrinists' expectation that German tanks would be engaged in mass formation was a failed assumption. In reality, German attacks effectively utilized combined arms on the ground fighting cohesively. American tank destroyer battalions comprised three tank destroyer companies supported by nine security sections. The single-purpose tactics of the tank destroyer battalion failed to account for non-tank threats.
British.
British tanks in the early years of the war, both infantry and cruiser, were (with the exception of the pre-war Matilda I design) equipped with a gun capable of use against contemporary enemy tanks - the 40 mm Ordnance QF 2 pounder. This was replaced with the 57 mm Ordnance QF 6 pounder when that became available. There was extra impetus given to the development of anti-tank weaponry, which culminated in the 76mm Ordnance QF 17 pounder, widely considered one of the best anti-tank guns of the war.
Towed anti-tank guns were the domain of the Royal Artillery rather than the Royal Armoured Corps and vehicles adapted to mount artillery, including anti-tank self-propelled guns such as the Deacon (6pdr on an armoured wheeled truck chassis) and Archer (17pdr on tracked chassis), were their preserve, as were US-supplied vehicles.
The self-propelled guns that were built in the "tank destroyer" mould came about through the desire to field the QF 17 pounder anti-tank gun and simultaneous lack of suitable standard tanks to carry it. As a result, they were of a somewhat extemporized nature. Mounting the gun on the Valentine tank chassis in a fixed superstructure gave the Archer, looking somewhat like the light-chassis German Marder III in appearance. The 17 pounder was also used to re-equip the US-supplied M10 Tank Destroyer, replacing the American 3-inch gun to produce the 17pdr SP Achilles.
While there was a general move to a general purpose gun that was usable against both tanks and in supporting infantry, there was a need to put the 17 pdr into a tank for use against the enemy's heavy tanks. The Cruiser Mk VIII Challenger was a project to bring a 17 pdr tank into use to support the Cromwell cruiser tank. Delays led to it being outnumbered in use by the Sherman Firefly, but a derivative of Challenger was the more-or-less open-topped variant "Avenger" which was delayed until post war before entering service. A cut-down 17 pdr - the 77mmHV was used to equip the Comet tank in the last year of the war.
The closest the British came to developing an armored tank destroyer in the vein of the German Jagdpanzers or Soviet ISU series was the Churchill 3-inch Gun Carrier - a Churchill tank chassis with a boxy superstructure in place of the turret and mounting a 3-inch anti-aircraft gun. Although a number were ordered, they were not put into service as the immediate threat passed. The design was rejected in favor of developing a 17 pounder armed Cromwell tank variant, ultimately leading to the Comet tank. The Tortoise "heavy assault tank" , intended for use in breaking through fixed defensive lines, was well armoured and had a very powerful 32-pounder (94 mm) gun, but did not reach service use.
By 1944, a number of the Shermans in British use were being converted to Sherman Fireflies by adding the QF 17 pounder gun. Initially this gave each troop (platoon) of Shermans one powerfully armed tank. By war's end - through the production of more Fireflies and the replacement of Shermans by British tanks - about 50% of Shermans in British service were Fireflies.
Romanian.
During World War 2, the Romanians made some tank destroyers by removing the turrets of some of their tanks and adding them a compartment and a stronger gun that could face the new Soviet tanks that were much stronger than the Romanian ones. One or these tank destroyers was the TACAM T-60 created on the hull of the Soviet T-60 light tank by removing its turret and adding a compartment together with a 76,2 FL-22 L/51 model 1936 gun. Another tank destroyer was the TACAM R-2 created by removing the turret of the R-2 light tank (name of the Czechoslovakian LT vz. 35 in the Romanian army) and adding it a compartment together with a Soviet 76,2mm ZiS-3 gun. There were 21 pieces made of which 1 survived and can be found in the National Military Museum, Bucharest. The only turreted tank destroyer made by Romania was the Vânătorul de care R-35, created by extending the turret of the French Renault R-35 tank and adding it a 45 mm gun instead of its 37 mm gun. The Romanians first planned to make it a non-turreted tank destroyer too, after this, they wanted to add it the turret of the Soviet T-26 tank, but then they came with the idea of extending the R-35's turret. Another tank destroyer was the Mareşal, the tank destroyer that inspired the German Hetzer. The first prototypes were made on a modified T-60 hull and were equipped with a 122 mm Soviet howitzer. Other used guns were a Soviet 76 mm gun and the Romanian 75 mm DT-UDR 26 Reşiţa. The prototypes and plans were captured by the Soviets after they invaded Romania. Two planned tank destroyers were the TACAM R-1 and the TACAM T-38.
Post-World War II.
In the face of the Warsaw Pact, a general need for extra firepower was identified. In the 1950s, the UK produced the FV 4101 Charioteer to beef up the tank regiments, mounting a 20 pounder gun in an oversize turret on the Cromwell tank hull—it lacked the all round capability of the Centurion tank. In the late 1960s, Germany developed the Kanonenjagdpanzer, essentially a modernized World War II Jagdpanzer mounting a gun. As Soviet designs became more heavily armored, the gun became ineffective and the Kanonenjagdpanzers were retrofitted for different roles or retired. Some provisions were made for the fitting of a 105 mm cannon, and many of the vehicles were modified to fire HOT or TOW missiles in place of a main gun. These upgraded variants remained in service into the 1990s.
With the development of flexible anti-tank missiles, which were capable of installation on almost any vehicle in the 1960s, the concept of the tank destroyer has morphed into light vehicles with missiles. With the weight of main battle tanks growing to the forty to seventy-tonne range, airborne forces were unable to deploy reasonable anti-tank forces. The result was a number of attempts to make a light vehicle, including the conventional ASU-85, the recoilless rifle-armed Ontos, and missile-armed Hornet Malkara armored car and Sheridan light assault vehicle. The latest entry into that category is the 2S25 Sprut-SD, armed with a current-issue 125 mm tank gun that is also capable of launching missiles like the 9M119 Svir.
Modern.
Many forces' infantry fighting vehicles (IFV) carry anti-tank missiles in every infantry platoon, and attack helicopters have also added anti-tank capability to the modern battlefield. But there are still dedicated anti-tank vehicles with very heavy long-range missiles, and ones intended for airborne use.
There have also been dedicated anti-tank vehicles built on ordinary armored personnel carrier or armored car chassis. Examples include the U.S. M901 ITV (Improved TOW Vehicle) and the Norwegian NM142, both on an M113 chassis, several Soviet ATGM launchers based on the BRDM reconnaissance car, the British FV438 Swingfire and FV102 Striker and the German Raketenjagdpanzer series built on the chassis of the HS 30 and Marder IFV.
A US Army combined arms battalion has two infantry companies with TOW missile-armed Bradley IFVs and can bring a large concentration of accurate and lethal fire to bear on an attacking enemy unit that uses AFVs. They can be complemented by mobile units of AH-64 Apache Helicopters armed with Hellfire antitank missiles.
Missile carrying vehicles however are referred to as anti-tank missile carriers instead of tank destroyers.
Some gun-armed tank destroyers continue to be used. China has developed the tracked PTZ89 and the wheeled PTL02 tank destroyers. PTZ89 is armed with a smoothbore cannon while PTL02, developed by NORINCO for the PLA's new light (rapid reaction) mechanized infantry divisions, carries a one (a version armed with a 105 mm rifled gun is available for export). PTL02 is built on the 6×6 wheeled chassis of the WZ551 APC.
Italy and Spain use the Italian-built Centauro, a wheeled tank destroyer with a cannon. The gun-armed tank destroyer may possibly see revival in the US Army through the introduction of the Stryker, more specifically, the M1128 Mobile Gun System, a Stryker variant armed with a cannon which has remote control and autoloading capabilities. Originally, the Canadian Forces had considered replacing their aging Leopard 1 tanks with the Stryker Mobile Gun System. But with the increased use of IEDs capable of destroying Strykers by insurgent forces, they opted instead to purchase the Leopard 2 tank.

</doc>
<doc id="2287" url="https://en.wikipedia.org/wiki?curid=2287" title="Armored car (military)">
Armored car (military)

A military armored (or armoured) car is a lightweight wheeled armored fighting vehicle, historically employed for reconnaissance, internal security, armed escort, and other subordinate battlefield tasks. With the gradual decline of mounted cavalry, armored cars were developed for carrying out duties formerly assigned to horsemen. Following the invention of the tank, the armored car remained popular due to its comparatively simplified maintenance and low production cost. It also found favor with several colonial armies as a cheaper weapon for use in underdeveloped regions. During World War II, most armored cars were engineered for reconnaissance and passive observation, while others were devoted to communications tasks. Some equipped with heavier armament could even substitute for tracked combat vehicles in favorable conditions—such as pursuit or flanking maneuvers during the North African Campaign.
Since World War II the traditional functions of the armored car have been occasionally combined with that of the armored personnel carrier, resulting in such multipurpose designs as the Cadillac Gage Commando. Postwar advances in recoil control technology have also made it possible for a few armored cars, including the AMX-10RC and EE-9 Cascavel, to carry large cannon capable of threatening many tanks. 
History.
Armed car.
The Motor Scout was designed and built by British inventor F.R. Simms in 1898. It was the first armed petrol engine-powered vehicle ever built. The vehicle was a De Dion-Bouton quadricycle with a mounted Maxim machine gun on the front bar. An iron shield in front of the car protected the driver.
Another early armed car was invented by Royal Page Davidson at Northwestern Military and Naval Academy in 1898 with the Davidson-Duryea gun carriage and the later Davidson Automobile Battery armored car.
However, these were not 'armored cars' as the term is understood today, as they provided no real protection for their crews against any kind of opposing fire. They were also, by virtue of their small capacity engines, far less efficient than the cavalry and horse-drawn guns that they were intended to complement.
First armored cars.
At the beginning of the 20th century, the first military armored vehicles were manufactured, by adding armor and weapons to existing vehicles.
The first armoured car was the Simms' Motor War Car, designed by F.R. Simms and built by Vickers, Sons & Maxim of Barrow on a special Coventry-built Daimler chassis with a German-built Daimler motor in 1899. and a single prototype was ordered in April 1899 The prototype was finished in 1902, too late to be used during the Boer War.
The vehicle had Vickers armour 6 mm thick and was powered by a four-cylinder 3.3-litre 16-hp Cannstatt Daimler engine, giving it a maximum speed around 9 miles per hour (14.5 km/h). The armament, consisting of two Maxim guns, was carried in two turrets with 360° traverse. It had a crew of four. Simms' Motor War Car was presented at the Crystal Palace, London, in April 1902.
Another early armoured car of the period was the French Charron, Girardot et Voigt 1902, presented at the "Salon de l'Automobile et du cycle" in Brussels, on 8 March 1902. The vehicle was equipped with a Hotchkiss machine gun, and with 7 mm armour for the gunner.
The Italians used armored cars during the Italo-Turkish War. A great variety of armored cars appeared on both sides during World War I and these were used in various ways.
World War I.
Generally, the armored cars were used by more or less independent car commanders. However, sometimes they were used in larger units up to squadron size. The cars were primarily armed with light machine guns, but larger units usually employed a few cars with heavier guns. As air power became a factor, armored cars offered a mobile platform for antiaircraft guns.
The first effective use of an armored vehicle in combat was achieved by the Belgian Army in August–September 1914. They had placed Cockerill armour plating and a Hotchkiss machine gun on Minerva Armored Cars. Their successes in the early days of the war convinced the Belgian GHQ to create a Corps of Armoured Cars, who would be sent to fight on the Eastern front once the western front immobilized after the Battle of the Yser.
The British Royal Naval Air Service dispatched aircraft to Dunkirk to defend the UK from Zeppelins. The officers' cars followed them and these began to be used to rescue downed reconnaissance pilots in the battle areas. They mounted machine guns on them and as these excursions became increasingly dangerous, they improvised boiler plate armoring on the vehicles provided by a local shipbuilder. In London Murray Sueter ordered "fighting cars" based on Rolls-Royce, Talbot and Wolseley chassis. By the time Rolls-Royce Armoured Cars arrived in December 1914, the mobile period on the Western Front was already over. As described below, they had a fascinating birth and long and interesting service.
More tactically important was the development of formed units of armoured cars, such as the Canadian Automobile Machine Gun Brigade, which was the first fully mechanized unit in the history of the British Army. The brigade was established on September 2, 1914 in Ottawa, as Automobile Machine Gun Brigade No. 1 by Brigadier-General Raymond Brutinel. The Brigade was originally equipped with 8 Armoured Autocars mounting 2 machine guns. By 1918 Brutinel's force consisted of two Motor Machine Gun Brigades (each of five gun batteries containing eight weapons apiece). The brigade, and its armoured cars, provided yeoman service in many battles, notably at Amiens.
The Rolls-Royce Armoured Car was famously proposed, developed, and utilised by the 2nd Duke of Westminster. He took a squadron of these cars to France in time to make a noted contribution to the Second Battle of Ypres, and thereafter the cars with their master were sent to the Middle East to play a part in the British campaign in Palestine and elsewhere. These cars appear in the memoirs of numerous officers of the BEF during the earlier stages of the Great War - their ducal master often being described in an almost piratical style.
World War II.
The British Royal Air Force (RAF) in the Middle East was equipped with Rolls-Royce Armoured Cars and Morris tenders. Some of these vehicles were among the last of a consignment of ex-Royal Navy armored cars that had been serving in the Middle East since 1915. In September 1940 a section of the No. 2 Squadron RAF Regiment Company was detached to General Wavell’s ground forces during the first offensive against the Italians in Egypt. It is said that these armored cars became ‘the eyes and ears of Wavell’. During the actions in the October of that year the Company was employed on convoy escort tasks, airfield defense, fighting reconnaissance patrols and screening operations.
During the Anglo-Iraqi War, some of the units located in the British Mandate of Palestine were sent to Iraq and drove Fordson armored cars. "Fordson" armored cars were Rolls-Royce armored cars which received new chassis from a Fordson truck in Egypt.
Since the Treaty of Versailles did not mention armored cars, Germany began developing them early. By the start of the new war, the German army possessed some highly effective reconnaissance vehicles, such as the "Schwerer Panzerspähwagen".
The Soviet BA-64 was influenced by a captured "Leichter Panzerspähwagen" before it was first tested in January 1942.
In the second half of the war, the American M8 Greyhound and the British Daimler Armoured Cars featured turrets with light guns (40 mm or less) mounted in turrets. As with other wartime armored cars, their reconnaissance roles emphasized greater speed and stealth than a tracked vehicle could provide, so their limited armor, armament and off-road capabilities were seen as acceptable compromises.
Military use.
A military armored car is a type of armored fighting vehicle having wheels (from four to ten large, off-road wheels) instead of tracks, and usually light armor. Armored cars are typically less expensive and on roads have better speed and range than tracked military vehicles. They do however have less mobility as they have less off-road capabilities because of the higher ground pressure. They also have less obstacle climbing capabilities than tracked vehicles. Wheels are more vulnerable to enemy fire than tracks, they have a higher signature and in most cases less armor than comparable tracked vehicles. As a result, they are not intended for heavy fighting; their normal use is for reconnaissance, command, control, and communications, or for use against lightly armed insurgents or rioters. Only some are intended to enter close combat, often accompanying convoys to protect soft-skinned vehicles.
Light armored cars, such as the British Ferret are armed with just a machine gun. Heavier vehicles are armed with autocannon or a small tank gun. The heaviest armored cars, such as the German, World War II era SdKfz 234 or the modern, US M1128 Mobile Gun System, mount the same guns that arm medium tanks.
Armored cars are popular for peacekeeping or internal security duties. Their appearance is less confrontational and threatening than tanks, and their size and maneuverability is said to be more compatible with tight urban spaces designed for wheeled vehicles. However they do have a larger turning radius compared to tracked vehicles which can turn on the spot and their tires are vulnerable and are less capable in climbing and crushing obstacles. However, when there is true combat they are easily outgunned and lightly armored. The threatening appearance of a tank is often enough to keep an opponent from attacking, whereas a less threatening vehicle such as an armored car is more likely to be attacked.
Many modern forces now have their dedicated armored car designs, to exploit the advantages noted above. Examples would be the M1117 Armored Security Vehicle of the USA or Alvis Saladin of the post-World War II era in the United Kingdom.
Alternatively, civilian vehicles may be modified into improvised armored cars in "ad hoc" fashion. Many militias and irregular forces adapt civilian vehicles into AFVs (armored fighting vehicles) and troop carriers, and in some regional conflicts these "technicals" are the only combat vehicles present. On occasion, even the soldiers of national militaries are forced to adapt their civilian-type vehicles for combat use, often using improvised armor and scrounged weapons.

</doc>
<doc id="2288" url="https://en.wikipedia.org/wiki?curid=2288" title="Self-propelled anti-aircraft weapon">
Self-propelled anti-aircraft weapon

An anti-aircraft vehicle, also known as a self-propelled anti-aircraft gun (SPAAG) or self-propelled air defense system (SPAD), is a mobile vehicle with a dedicated anti-aircraft capability. The Russian equivalent of "SPAAG" is "ZSU", for "zenitnaya samokhodnaya ustanovka", ("anti-aircraft self-propelled mount").
Specific weapon systems used include machine guns, autocannons, larger guns, or missiles, and some mount both guns and longer-ranged missiles (e.g. the Pantsir-S1). Platforms used include both trucks and heavier combat vehicles such as APCs and tanks, which add protection from aircraft, artillery, and small arms fire for front line deployment.
Anti-aircraft guns are usually mounted in a quickly-traversing turret with a high rate of elevation, for tracking fast-moving aircraft. They are often in dual or quadruple mounts, allowing a high rate of fire. Today, missiles (generally mounted on similar turrets) have largely supplanted anti-aircraft guns.
History.
World War I.
Anti-aircraft machine guns have long been mounted on trucks, and these were quite common during World War I. A predecessor of the WW2 German "88" anti-aircraft gun, the WWI German 77 mm anti-aircraft gun, was truck-mounted and used to great effect against British tanks.
The British QF 3 inch 20 cwt was mounted on trucks for use on the Western Front.
Inter-war period.
Between the two World Wars the United Kingdom developed the Birch gun, a general purpose artillery piece on an armoured tracked chassis capable of maintaining formation with their current tanks. The gun could be elevated for anti-aircraft use.
Vickers Armstrong also developed a SPAAG based on the chassis of the Mk.E 6-ton light tank/Dragon Medium Mark IV tractor, mounting a Vickers QF-1 "Pom-Pom" gun of 40 mm. About 26 were sold to Siam and saw action as Infantry support guns and AA guns during the Franco-Thai war (1940-1941) along with 30 Vickers Mk.E Type B 6-ton tanks. This was probably the first tracked SPAAG manufactured in series. Later the British also developed a version of the Mk.VI light tank armed with 4 machine guns that was known as Light Tank AA Mk.I. And also a twin 15 mm version based on the Light Tank Mk.V was built.
Among early pre-war pioneers of self-propelled AA guns were the Germans. By the time of the war, they fielded the SdKfz 10/4 and 6/2, cargo halftracks mounting single 20 mm or 37 mm AA guns (respectively). Later in the war similar German halftracks mounted quadruple 20 mm weapons.
World War II.
Larger guns followed on larger trucks, but these mountings generally required off-truck setup in order to unlimber the stabilizing legs these guns needed. One exception to this rule was the Italian Cannone da 90/53 which was highly effective when mounted on trucks, a fit known as the ""autocannoni da 90/53"". The 90/53 was a feared weapon, notably in the anti-tank role, but only a few hundred had been produced by the time of the armistice in 1943.
Other nations tended to work on truck chassis. Starting in 1941, the British developed the "en portee" method of mounting an anti-tank gun (initially a 2 pounder) on a truck. This was to prevent the weapon from being damaged by long-distance towing across rough, stony deserts, and it was intended only to be a carrying method, with the gun unloaded for firing. However, crews tended to fire their weapons from their vehicles for the mobility this method provided, with consequent casualties. 
This undoubtedly inspired their Morris C9/B (officially the "Carrier, SP, 4x4, 40 mm AA"), a Bofors 40 mm AA gun mounted on a chassis derived from the Morris "Quad" Field Artillery Tractor truck. Similar types, based on 3-ton lorries, were produced in Britain, Canada and Australia, and together formed the most numerous self-propelled AA guns in British service.
The U.S. Army brought truck-towed Bofors 40 mm AA guns along with truck-mounted units fitted with mechanized turrets when they sailed, first for Great Britain and then onto France. The turrets carried four .50 inch (12.7 mm) machine guns, which were designed to be adjusted to converge at the single point where enemy aircraft were expected to appear at low altitude in conduction of strafing runs directed at large infantry and field artillery units.
Interest in mobile AA turned to heavier vehicles with the mass and stability needed to easily train weapons of all sizes. Probably the desire, particularly in German service, for anti-aircraft vehicles to be armoured for their own protection also assisted this trend.
The concept of an armored SPAAG was pioneered by Hungary during World War II Hungary by producing the 40M Nimrod based on the Luftvärnskanonvagn L-62 Anti II license acquired from Sweden. Germany followed later with their ""Flakpanzer"" series. German World War II SPAAGs include the Möbelwagen, Wirbelwind, Ostwind and Kugelblitz. Other forces followed with designs of their own, notably the American M16 created by mounting quadruple M2HB Browning machine guns on a M3 Half-track.
The British developed their own SPAAGs throughout the war mounting multiple machine guns and light cannon on various tank and armoured car chassis and by 1943, the Crusader AA tanks, which mounted the Bofors 40 mm gun or two-three Oerlikon 20 mm cannon. Although used during the Normandy landings, by that point German aircraft were contained by the Allies own air forces and they were largely unneeded.
Cold War and later.
The introduction of jet engines and the subsequent rough doubling of aircraft speeds greatly reduced the effectiveness of the SPAAG against attack aircraft. A typical SPAAG round might have a muzzle velocity on the order of and might take as long as two to three seconds to reach a target at its maximum range. An aircraft flying at is moving at a rate of about . This means the aircraft will have moved hundreds of meters during the flight time of the shells, greatly complicating the aiming problem to the point where close passes were essentially impossible to aim using manual gunsights. This speed also allowed the aircraft to rapidly fly out of range of the guns; even if the aircraft passes directly over the SPAAG, it would be within its firing radius for under 30 seconds.
SPAAG development continued through the early 1950s with ever-larger guns, improving the range and allowing the engagement to take place at longer distances where the crossing angle was smaller and aiming was easier. Examples including the 40 mm U.S. M42 Duster and the 57 mm Soviet ZSU-57-2. However, both were essentially obsolete before they entered service, and found employment solely in the ground-support role. The M42 was introduced to the Vietnam War to counter an expected North Vietnamese air offensive, but when this failed to materialize it was used as an effective direct-fire weapon. The ZSU-57 found similar use in the Yugoslav Wars, where its high-angle fire was useful in the mountainous terrain.
By the late 1950s the US Army had given up on the SPAAG concept, considering all gun-based weapons to be useless against modern aircraft. This belief was generally held by many forces, and the anti-aircraft role turned almost exclusively to missile systems. The Soviet Union remained an outlier, beginning development of a new SPAAG in 1957, which emerged as the ZSU-23-4 in 1965. This system included search-and-track radars, fire control, and automatic gun-laying, greatly increasing its effectiveness against modern targets. The ZSU-23 proved very effective when used in concert with SAMs; the presence of SAMs forced aircraft to fly low to avoid their radars, placing them within range of the ZSUs.
The success of the ZSU-23 led to a resurgence of SPAAG development. This was also prompted by the introduction of attack helicopters in the 1970s, which could hide behind terrain and then "pop up" for an attack lasting only a few tens of seconds; missiles were ineffective at low altitudes, while the helicopters would often be within range of the guns for a rapid counterattack. Notable among these later systems is the German Gepard, the first western SPAAG to offer performance equal to or better than the ZSU. This system was widely copied in various NATO forces. US attempts to introduce a new SPAAG were doomed to become a series of half-measures and dismal failures; the failure of the missile-based MIM-46 Mauler led to the introduction of the optically-aimed M163 VADS of very short range, and the long-delayed and finally cancelled M247 Sergeant York which offered almost laughable performance in testing, unable to hit even stationary targets. 
SPAAG development continues, with many modern examples often combining both guns and short-range missiles. Examples include the Soviet/Russian Tunguska-M1, which supplanted the ZSU-23 in service, newer versions of the Gepard, and the British Marksman turret, which can be used on a wide variety of platforms.

</doc>
<doc id="2289" url="https://en.wikipedia.org/wiki?curid=2289" title="AZ Alkmaar">
AZ Alkmaar

Alkmaar Zaanstreek (), better known as AZ Alkmaar or simply AZ (), is a Dutch professional football club from Alkmaar and the Zaanstreek. The club plays in the Eredivisie, the highest professional football league in the Netherlands, and hosts home games at the AFAS Stadion.
AZ has won the Eredivisie twice, in 1980–81 and 2008–09. In the same season as their first league title, they also reached the UEFA Cup Final, which they lost to Ipswich Town. In addition, the team has won the KNVB Cup on four occasions.
History.
1954–1972: Foundation and first years.
AZ was founded on 10 May 1967 as AZ '67, the result of a merger of Alkmaar '54 and FC Zaanstreek. FC Zaanstreek was formed in 1964, continuing the professional adventure of the Kooger Football Club (KFC). KFC had been founded in 1910, had nearly become National Champion in 1934 through a narrow loss to Ajax in the finals, and had been professional since 1955.
In 1964, the brothers Cees and Klaas Molenaar, former players for KFC and owners of a growing appliance store chain, sought to create a powerful football team in Zaanstreek by merging the two local professional teams: KFC and Zaanlandsche Football Club.
After this merger failed, they successfully merged KFC (now "FC Zaanstreek") with Alkmaar '54; the team would be based in Alkmaar.
Partially through the hiring of expensive foreign players, the new club soon acquired large debts.
1972–1985: The Molenaar years.
Fortunately in 1972 the Molenaar brothers bailed it out and invested heavily in the club, to the point that AZ '67 were successful in the late seventies and early eighties, regularly playing European football from 1977 to 1982 whilst also winning the Dutch Cup three times over that period.
After four close league campaigns AZ finally became Dutch champions in 1981, they were the only team other than the "big three" (Ajax, Feyenoord, and PSV) to do so in a 44-year period spanning from 1965 to 2009, when AZ once again won the league title. They won the 1980–81 season with overwhelming power, winning 27 of 34 matches and only losing once whilst scoring a club record 101 goals and conceding just 30 goals.
The same season AZ reached the final of the UEFA Cup, losing 5–4 on aggregate to Ipswich Town. The next year in the UEFA Champions League they lost in the second round 3–2 on aggregate to Liverpool.
Georg Keßler was AZ's manager over most of these years (1978–82), while star players included: Kees Kist the club's highest ever goalscorer with 212 goals and the first ever Dutchman to win the European Golden Boot in 1979 when he scored 34 goals in a season; Jan Peters who played 120 games for AZ during this period scoring 30 goals from midfield; Hugo Hovenkamp played 239 games in defence for AZ from 1975–83 as well as receiving 31 caps for the Netherlands from 1977–83 and playing each game in Euro '80 while an AZ player.
John Metgod spent six years at AZ playing 195 games as a defender, scoring 26 goals including a goal against Ipswich Town in the final of the UEFA Cup. Like Hovenkamp, Metgod was included in the Netherlands squad for Euro '80; The Danish forward Kristen Nygaard who spent 10 years at AZ scoring 104 goals in 363 games between 1972 and 1982.
1985–1993: The interim years.
The club deteriorated after Klaas Molenaar left the club in 1985 (Cees died in 1979). AZ were relegated in 1988 from the Eredivisie.
1993–2009: The Scheringa years.
The involvement of businessman Dirk Scheringa in the mid 1990s marked the revival of the club as AZ returned to the Eredivisie in 1998.
After a 22-year hiatus from European football AZ appeared in the 2004–05 UEFA Cup advancing to the semi-finals. The second leg of the semi-final against Sporting CP had a heart-breaking conclusion, when Sporting scored in the 122nd minute (2 minutes into stoppage time) to reach an aggregate score of 4–4, Sporting advanced to the Final thanks to the away goals rule. In the same season AZ finished third in the Eredivisie, qualifying for the UEFA Cup again. These were great achievements for the club which does not have a similar sized fanbase relative to Eredivisie and European rivals; AZ's home ground until the 2006–07 season, the Alkmaarderhout, had a capacity of only 8,390.
In the summer of 2006, the club moved to a new 17,000 capacity stadium AZ Stadion.
AZ had a very good 2006–07 season, despite ending in disaster. Going into the last game of the 2006–07 season, AZ led PSV and Ajax by goal difference in the Eredivisie, but ended up third after losing their last match against the now relegated and bottom of the table Excelsior, playing with 10 men for 80 minutes.
Furthermore, AZ lost the KNVB Cup final to Ajax 8–7 after a penalty shoot-out and also lost to Ajax over two play-off games for the Champions League. After the season, key players like Tim de Cler, Danny Koevermans, and Shota Arveladze left the team.
A remarkable run ended in the 2007–08 season; AZ lost a group game against Everton 3–2 in the UEFA Cup which ended an unbeaten run of 32 home matches in European competitions, a record which ran from 1977 to 2007.
Also on this season AZ performed so badly (first round loss in the KNVB Cup, elimination from the UEFA Cup group stage and 11th place league finish), that team manager Louis van Gaal felt obliged to hand in his resignation in March 2008. However, after protests from the players and directors, van Gaal withdrew his resignation.
The 2008–09 season had an unpromising start with two defeats against NAC Breda and ADO Den Haag. However, starting with a 1–0 victory over defending league champions PSV, AZ didn't lose a game in the next 28 matches, including a run of 11 matches where AZ did not concede an opposition goal. Three weeks before the end of the season AZ became Eredivisie champions beating nearest rivals Twente and Ajax comfortably. Being league champions, AZ qualified for the UEFA Champions League for the second time, but only took four points from six matches and finished bottom of their group.
2009–Present: Recent years.
Ronald Koeman succeeded Louis van Gaal after the 2008–09 season. Van Gaal had already left for Bayern Munich after becoming league champions with AZ. Koeman became the manager for AZ on 17 May 2009. On 5 December 2009 AZ announced that Koeman no longer was in charge of AZ, after losing 7 of the first 16 games in his reign. Former Rangers and Zenit St. Petersburg manager Dick Advocaat took over for the rest of the season. Under Advocaat, AZ achieved some good results and secured European football for the next season.
For the 2010–11 season AZ appointed Gertjan Verbeek as their new manager. AZ finished the 2010–11 season in 4th place, securing Europa League football for the next season. In the KNVB Cup AZ reached the last eight, where they were beaten by rivals Ajax with 1–0. AZ finished third in their Europa League group, thus not qualifying for the knock out round.
The 2011–12 season AZ finished the Eredivisie in 4th place and performed significantly better in cup competitions, reaching the semi-finals in the KNVB cup (losing to Heracles Almelo after extra time) and the quarter-finals in the Europa League, ultimately losing to Valencia after beating Udinese, Anderlecht, Malmö FF, Austria Wien, Metalist Kharkiv, Aalesund and FK Baumit Jablonec.
On 21 December 2011, during the quarter-finals of the KNVB Cup, a 19-year-old Ajax fan entered the Amsterdam ArenA pitch in the 36th minute, with Ajax winning 1–0, attacking AZ goalkeeper Esteban Alvarado. The fan slipped and Alvarado kicked the fan twice, which led to the goalkeeper being sent off. Following this, Gertjan Verbeek ordered his players to leave the pitch for the dressing room in protest. Later, the match was played again on 19 January 2012, with Alvarado's red card rescinded. AZ won the match 3–2.
The 2012–13 season started in the Europa League with a qualifying play-off round against Guus Hiddinks Anzhi Makhachkala, AZ were hammered 6–0 on aggregate. Disappointingly AZ finished the Eredivisie in 10th place, however AZ won silverware by winning the domestic cup after beating PSV 2–1. Winning the KNVB Beker AZ automatically qualified for Europa League football despite finishing the league in tenth position and out of the league's Europa League play-off system.
In September 2013, just a day after emphatically beating PSV, then league leaders, Verbeek was dismissed as first team manager by the club due to 'a lack of chemistry' between the management and players. He was replaced by Dick Advocaat for the rest of the season until a permanent replacement was found. Advocaat took AZ to the semi-finals of the KNVB Beker, the quarter-finals of the Europa League and 8th in the league, ultimately losing to FC Groningen in Europa League play-off final round (their 58th game of the season, a club record).
The 2014–15 season started with a new manager at the helm, former SC Heerenveen manager and Ajax player Marco van Basten.
Current squad.
"For recent transfers, see List of Dutch football transfers summer 2015"
Stadium and sponsor.
AZ play their home games at the AFAS Stadion, located in the southern part of the city of Alkmaar. The stadium, which is owned directly by the club, was opened in 2006 and replaced the old Alkmaarderhout venue as the DSB Stadion. The stadium currently has a capacity of "17,023". During its design stages the name Victorie Stadion was frequently used, referring to the Dutch War of Independence, the phrase ""n Alkmaar begint de victorie" (Victory begins in Alkmaar)" in particular. Until now, this name hasn't been officially in use, the board instead opting for sponsorship deals because of financial motives. However, to this day the name maintains a good share of support among the fans.
In order to further increase revenue, the "AZ board" of directors decided to extend the capacity of the new stadium to a minimum of "30,000" seated spectators somewhere in the future. The extension will be realised by constructing a second tier to three of the four stands. The main stand with all technical areas, "VIP" and sponsor and media facilities will remain in place. However, these plans were put on hold after the DSB bankruptcy and there are no current plans to increase the capacity.
In October 2009 sponsor DSB Bank was declared bankrupt.
The stadium name temporarily changed from DSB Stadion to AZ Stadion, as it was considered undesirable that the stadium was linked with a non-existent bank. In February 2010 a new main sponsor was found: construction works service provider BUKO from Beverwijk.
A year later, in the season 2010–11, "AFAS Erp Software" took over as official shirt sponsor, also taking over duties as stadium sponsor. The current external name of the ground is AFAS Stadion.
AZ in Europe.
Below is a table with AZ's international results in the past seasons.
Domestic results.
Below is a table with AZ's domestic results since the introduction of professional football in 1956.

</doc>
<doc id="2296" url="https://en.wikipedia.org/wiki?curid=2296" title="Adrenal gland">
Adrenal gland

The adrenal glands (also known as suprarenal glands) are endocrine glands that produce a variety of hormones including adrenaline and the steroids aldosterone and cortisol. They are found above the kidneys. Each gland has an outer cortex which produces steroid hormones and an inner medulla. The adrenal cortex itself is divided into three zones: zona glomerulosa, the zona fasciculata and the zona reticularis.
The adrenal cortex produces three main types of steroid hormones: mineralocorticoids, glucocorticoids, and androgens. Mineralocorticoids (such as aldosterone) produced in the zona glomerulosa help in the regulation of blood pressure and electrolyte balance. The glucocorticoids cortisol and corticosterone are synthesized in the zona fasciculata; their functions include the regulation of metabolism and immune system suppression. The innermost layer of the cortex, the zona reticularis, produces androgens that are converted to fully functional sex hormones in the gonads and other target organs. The production of steroid hormones is called steroidogenesis, and involves a number of reactions and processes that take place in cortical cells. The medulla produces the catecholamines adrenaline and noradrenaline, which function to produce a rapid response throughout the body in stress situations.
A number of endocrine diseases involve dysfunctions of the adrenal gland. Overproduction of cortisol leads to Cushing's syndrome, whereas insufficient production is associated with Addison's disease. Congenital adrenal hyperplasia is a genetic disease produced by dysregulation of endocrine control mechanisms. A variety of tumors can arise from adrenal tissue and are commonly found in medical imaging when searching for other diseases.
Structure.
The adrenal glands are located on both sides of the body in the retroperitoneum, above and slightly medial to the kidneys. In humans, the right adrenal gland is pyramidal in shape, whereas the left is semilunar and somewhat larger. The glands are usually about 5x3 cm in size, and their combined weight in an adult human ranges from 7 to 10 grams. The glands are yellowish in colour. 
The adrenal glands are surrounded by a fatty capsule and lie within the renal fascia, which also surrounds the kidneys. A weak wall of connective tissue separates the glands from the kidneys. The adrenal glands are directly below the diaphragm, and are attached to the crura of the diaphragm by the renal fascia.
Each adrenal gland has two distinct parts, each with a unique function, the outer adrenal cortex and the inner medulla, both of which produce hormones.
Cortex.
The adrenal cortex is the outermost layer of the adrenal gland. Within the cortex are three layers, called "zones". When viewed under a microscope each layer has a distinct appearance, and each has a different function. The adrenal cortex is devoted to production of hormones, namely aldosterone, cortisol, and androgens.
Zona glomerulosa.
The outermost layer of the adrenal cortex is the zona glomerulosa. It lies immediately under the fibrous capsule of the gland. Cells in this layer form oval groups, separated by thin strands of connective tissue from the fibrous capsule of the gland and carry wide capillaries.
This layer is the main site for production of aldosterone, a mineralocorticoid, by the action of the enzyme aldosterone synthase. Aldosterone plays an important role in the long-term regulation of blood pressure.
Zona fasciculata.
The zona fasciculata is situated between the zona glomerulosa and zona reticularis. Cells in this layer are responsible for producing glucocorticoids such as cortisol. It is the largest of the three layers, accounting for nearly 80% of the volume of the cortex. In the zona fasciculata, cells are arranged in columns radially oriented towards the medulla. Cells contain numerous lipid droplets, abundant mitochondria and a complex smooth endoplasmic reticulum.
Zona reticularis.
The innermost cortical layer, the zona reticularis, lies directly adjacent to the medulla. It produces androgens, mainly dehydroepiandrosterone (DHEA), DHEA sulfate (DHEA-S), and androstenedione (the precursor to testosterone) in humans. Its small cells form irregular cords and clusters, separated by capillaries and connective tissue. The cells contain relatively small quantities of cytoplasm and lipid droplets, and sometimes display brown lipofuscin pigment.
Medulla.
The adrenal medulla is at the centre of each adrenal gland, and is surrounded by the adrenal cortex. The chromaffin cells of the medulla are the body's main source of the catecholamines adrenaline and noradrenaline, released by the medulla. Approximately 20% noradrenaline (norepinephrine) and 80% adrenaline (epinephrine) are secreted here.
The adrenal medulla is driven by the sympathetic nervous system via preganglionic fibers originating in the thoracic spinal cord, from vertebrae T5–T11. Because it is innervated by preganglionic nerve fibers, the adrenal medulla can be considered as a specialized sympathetic ganglion. Unlike other sympathetic ganglia, however, the adrenal medulla lacks distinct synapses and releases its secretions directly into the blood.
Blood supply.
The adrenal glands have one of the greatest blood supply rates per gram of tissue of any organ: up to 60 small arteries may enter each gland. Three arteries usually supply each adrenal gland:
These blood vessels supply a network of small arteries within the capsule of the adrenal glands. Thin strands of the capsule enter the glands, carrying blood to them.
Venous blood is drained from the glands by the suprarenal veins, usually one for each gland:
The central adrenomedullary vein, in the adrenal medulla, is an unusual type of blood vessel. Its structure is different from the other veins in that the smooth muscle in its tunica media (the middle layer of the vessel) is arranged in conspicuous, longitudinally oriented bundles.
Variability.
The adrenal glands may not develop at all, or may be fused in the midline behind the aorta. These are associated with other congenital abnormalities, such as failure of the kidneys to develop, or fused kidneys. The gland may develop with a partial or complete absence of the cortex, or may develop in an unusual location.
Function.
The adrenal gland secretes a number of different hormones which are metabolised by enzymes either within the gland or in other parts of the body. These hormones are involved in a number of essential biological functions.
Corticosteroids.
Corticosteroids are a group of steroid hormones produced from the cortex of the adrenal gland, from which they are named. Corticosteroids are named according to their actions:
The adrenal gland produces aldosterone, a mineralocorticoid, which is important in the regulation of salt ("mineral") balance and blood volume. In the kidneys, aldosterone acts on the distal convoluted tubules and the collecting ducts by increasing the reabsorption of sodium and the excretion of both potassium and hydrogen ions. Aldosterone is responsible for the reabsorption of about 2% of filtered sodium in the kidneys, which is nearly equal to the entire sodium content in human blood under normal glomerular filtration rates. Sodium retention is also a response of the distal colon and sweat glands to aldosterone receptor stimulation. Angiotensin II and extracellular potassium are the two main regulators of aldosterone production. The amount of sodium present in the body affects the extracellular volume, which in turn influences blood pressure. Therefore, the effects of aldosterone in sodium retention are important for the regulation of blood pressure.
Cortisol is the main glucocorticoid in humans. In species that do not create cortisol, this role is played by corticosterone instead. Glucocorticoids have many effects on metabolism. As their name suggests, they increase the circulating level of glucose. This is the result of an increase in the mobilization of amino acids from protein and the stimulation of synthesis of glucose from these amino acids in the liver. In addition, they increase the levels of free fatty acids, which cells can use as an alternative to glucose to obtain energy. Glucocorticoids also have effects not related to the regulation of blood sugar levels, including the suppression of the immune system and a potent anti-inflammatory effect. Cortisol reduces the capacity of osteoblasts to produce new bone tissue and decreases the absorption of calcium in the gastrointestinal tract.
The adrenal gland secretes a basal level of cortisol but can also produce bursts of the hormone in response to adrenocorticotropic hormone (ACTH) from the anterior pituitary. Cortisol is not evenly released during the day – its concentrations in the blood are highest in the early morning and lowest in the evening as a result of the circadian rhythm of ACTH secretion. Cortisone is an inactive product of the action of the enzyme 11β-HSD on cortisol. The reaction catalyzed by 11β-HSD is reversible, which means that it can turn administered cortisone into cortisol, the biologically active hormone.
All corticosteroid hormones share cholesterol as a common precursor. Therefore, the first step in steroidogenesis is cholesterol uptake or synthesis. Cells that produce steroid hormones can acquire cholesterol through two paths. The main source is through dietary cholesterol transported via the blood as cholesterol esters within low density lipoproteins (LDL). LDL enters the cells through receptor-mediated endocytosis. The other source of cholesterol is synthesis in the cell's endoplasmic reticulum. Synthesis can compensate when LDL levels are abnormally low. In the lysosome, cholesterol esters are converted to free cholesterol, which is then used for steroidogenesis or stored in the cell.
The initial part of conversion of cholesterol into steroid hormones involves a number of enzymes of the cytochrome P450 family that are located in the inner membrane of mitochondria. Transport of cholesterol from the outer to the inner membrane is facilitated by steroidogenic acute regulatory protein and is the rate-limiting step of steroid synthesis. 
The layers of the adrenal gland differ by function, with each layer having distinct enzymes that produce different hormones from a common precursor. The first enzymatic step in the production of all steroid hormones is cleavage of the cholesterol side chain, a reaction that forms pregnenolone as a product and is catalyzed by the enzyme P450scc, also known as "cholesterol desmolase". After the production of pregnenolone, specific enzymes of each cortical layer further modify it. Enzymes involved in this process include both mitochondrial and microsomal P450s and hydroxysteroid dehydrogenases. Usually a number of intermediate steps in which pregnenolone is modified several times are required to form the functional hormones. Enzymes that catalyze reactions in these metabolic pathways are involved in a number of endocrine diseases. For example, the most common form of congenital adrenal hyperplasia develops as a result of deficiency of 21-hydroxylase, an enzyme involved in an intermediate step of cortisol production.
Glucocorticoids are under the regulatory influence of the hypothalamus-pituitary-adrenal (HPA) axis. Glucocorticoid synthesis is stimulated by adrenocorticotropic hormone (ACTH), a hormone released into the bloodstream by the anterior pituitary. In turn, production of ACTH is stimulated by the presence of corticotropin-releasing hormone (CRH), which is released by neurons of the hypothalamus. ACTH acts on the adrenal cells first by increasing the levels of StAR within the cells, and then of all steroidogenic P450 enzymes. The HPA axis is an example of a negative feedback system, in which cortisol itself acts as a direct inhibitor of both CRH and ACTH synthesis. The HPA axis also interacts with the immune system through increased secretion of ACTH at the presence of certain molecules of the inflammatory response.
Mineralocorticoid secretion is regulated mainly by the renin–angiotensin–aldosterone system (RAAS), the concentration of potassium, and to a lesser extent the concentration of ACTH. Sensors of blood pressure in the juxtaglomerular apparatus of the kidneys release the enzyme renin into the blood, which starts a cascade of reactions that lead to formation of angiotensin II. Angiotensin receptors in cells of the zona glomerulosa recognize the substance, and upon binding they stimulate the release of aldosterone.
Adrenaline and noradrenaline.
Nowadays referred to as Epinephrine and norepinephrine,
Adrenaline and noradrenaline are catecholamines, water-soluble compounds that have a structure made of a catechol group and an amine group. The adrenal glands are responsible for most of the adrenaline that circulates in the body, but only for a small amount of circulating noradrenaline. These hormones are released by the adrenal medulla, which contains a dense network of blood vessels. Adrenaline and noradrenaline act at adrenoreceptors throughout the body, with effects that include an increase in blood pressure and heart rate. The actions of adrenaline and noradrenaline are responsible for the fight or flight response, characterised by a quickening of breathing and heart rate, an increase in blood pressure, and constriction of blood vessels in many parts of the body. 
Catecholamines are produced in chromaffin cells in the medulla of the adrenal gland, from tyrosine, a non-essential amino acid derived from food or produced from phenylalanine in the liver. The enzyme tyrosine hydroxylase converts tyrosine to L-DOPA in the first step of catecholamine synthesis. L-DOPA is then converted to dopamine before it can be turned into noradrenaline. In the cytosol, noradrenaline is converted to epinephrine by the enzyme phenylethanolamine N-methyltransferase (PNMT) and stored in granules. Glucocorticoids produced in the adrenal cortex stimulate the synthesis of catecholamines by increasing the levels of tyrosine hydroxylase and PNMT.
Catecholamine release is stimulated by the activation of the sympathetic nervous system. Splanchnic nerves of the sympathetic nervous system innervate the medulla of the adrenal gland. When activated, it evokes the release of catecholamines from the storage granules by stimulating the opening of calcium channels in the cell membrane.
Androgens.
Cells in zona reticularis of the adrenal glands produce male sex hormones, or androgens, the most important of which is DHEA. In general, these hormones do not have an overall effect in the male body, and are converted to more potent androgens such as testosterone and DHT or to estrogens (female sex hormones) in the gonads, acting in this way as a metabolic intermediate.
Development.
The adrenal glands are composed of two heterogenous types of tissue. In the center is the adrenal medulla, which produces adrenaline and noradrenaline and releases them into the bloodstream, as part of the sympathetic nervous system. Surrounding the medulla is the cortex, which produces a variety of steroid hormones. These tissues come from different embryological precursors and have distinct prenatal development paths. The cortex of the adrenal gland is derived from mesoderm, whereas the medulla is derived from the neural crest, which is of ectodermal origin.
The adrenal glands in a newborn baby are much larger as a proportion of the body size than in an adult. For example, at age three months the glands are four times the size of the kidneys. The size of the glands decreases relatively after birth, mainly because of shrinkage of the cortex. The cortex, which almost completely disappears by age 1, develops again from age 4–5. The glands weigh about 1 g at birth and develop to an adult weight of about 4 grams each. In a fetus the glands are first detectable after the sixth week of development.
Cortex.
Adrenal cortex tissue is derived from the intermediate mesoderm. It first appears 33 days after fertilisation, shows steroid hormone production capabilities by the eighth week and undergoes rapid growth during the first trimester of pregnancy. The fetal adrenal cortex is different from its adult counterpart, as it is composed of two distinct zones: the inner "fetal" zone, which carries most of the hormone-producing activity, and the outer "definitive" zone, which is in a proliferative phase. The fetal zone produces large amounts of adrenal androgens (male sex hormones) that are used by the placenta for estrogen biosynthesis. Cortical development of the adrenal gland is regulated mostly by ACTH, a hormone produced by the pituitary gland that stimulates cortisol synthesis. During midgestation, the fetal zone occupies most of the cortical volume and produces 100–200 mg/day of DHEA-S, an androgen and precursor of both androgens and estrogens (female sex hormones). Adrenal hormones, especially glucocorticoids such as cortisol, are essential for prenatal development of organs, particularly for the maturation of the lungs. The adrenal gland decreases in size after birth because of the rapid disappearance of the fetal zone, with a corresponding decrease in androgen secretion.
Adrenarche.
During early childhood androgen synthesis and secretion remain low, but several years before puberty (from 6–8 years of age) changes occur in both anatomical and functional aspects of cortical androgen production that lead to increased secretion of the steroids DHEA and DHEA-S. These changes are part of a process called adrenarche, which has only been described in humans and some other primates. Adrenarche is independent of ACTH or gonadotropins and correlates with a progressive thickening of the zona reticularis layer of the cortex. Functionally, adrenarche provides a source of androgens for the development of axillary and pubic hair before the beginning of puberty.
Medulla.
The adrenal medulla is derived from neural crest cells, which come from the ectoderm layer of the embryo. These cells migrate from their initial position and aggregate in the vicinity of the dorsal aorta, a primitive blood vessel, which activates the differentiation of these cells through the release of proteins known as BMPs. These cells then undergo a second migration from the dorsal aorta to form the adrenal medulla and other organs of the sympathetic nervous system. Cells of the adrenal medulla are called chromaffin cells because they contain granules that stain with chromium salts, a characteristic not present in all sympathetic organs. Glucocorticoids produced in the adrenal cortex were once thought to be responsible for the differentiation of chromaffin cells. More recent research suggests that BMP-4 secreted in adrenal tissue is the main responsible for this, and that glucocorticoids only play a role in the subsequent development of the cells.
Clinical significance.
The normal function of the adrenal gland may be impaired by conditions such as infections, tumors, genetic disorders and autoimmune diseases, or as a side effect of medical therapy. These disorders affect the gland either directly (as with infections or autoimmune diseases) or as a result of the dysregulation of hormone production (as in some types of Cushing's syndrome) leading to an excess or insufficiency of adrenal hormones and the related symptoms.
Corticosteroid overproduction.
Cushing's syndrome.
Cushing's syndrome is the manifestation of glucocorticoid excess. It can be the result of a prolonged treatment with glucocorticoids or be caused by an underlying disease which produces alterations in the HPA axis or the production of cortisol. Causes can be further classified into ACTH-dependent or ACTH-independent. The most common cause of endogenous Cushing's syndrome is a pituitary adenoma which causes an excessive production of ACTH. The disease produces a wide variety of signs and symptoms which include obesity, diabetes, increased blood pressure, excessive body hair (hirsutism), osteoporosis, depression and, most distinctively, stretch marks in the skin, caused by its progressive thinning.
Primary aldosteronism.
When the zona glomerulosa produces excess aldosterone, the result is primary aldosteronism. Causes for this condition are bilateral hyperplasia (excessive tissue growth) of the glands, or aldosterone-producing adenomas (a condition called Conn's syndrome). Primary aldosteronism produces hypertension and electrolyte imbalance, increasing potassium depletion and sodium retention.
Adrenal insufficiency.
Adrenal insufficiency (the deficiency of glucocorticoids) occurs in about 5 in 10,000 in the general population. Diseases classified as "primary adrenal insufficiency" (including Addison's disease and genetic causes) directly affect the adrenal cortex. If a problem that affects the hypothalamic-pituitary-adrenal axis arises outside the gland, it is a "secondary adrenal insufficiency".
Addison's disease.
Addison's disease refers to primary hypoadrenalism, which is a deficiency in glucocorticoid and mineralocorticoid production by the adrenal gland. In the Western world, Addison's disease is most commonly an autoimmune condition, in which the body produces antibodies against cells of the adrenal cortex. Worldwide, the disease is more frequently caused by infection, especially from tuberculosis. A distinctive feature of Addison's disease is hyperpigmentation of the skin, which presents with other nonspecific symptoms such as fatigue.
A complication seen in untreated Addison's disease and other types of primary adrenal insufficiency is the adrenal crisis, a medical emergency in which low glucocorticoid and mineralocorticoid levels result in hypovolemic shock and symptoms such as vomiting and fever. An adrenal crisis can progressively lead to stupor and coma. The management of adrenal crises includes the application of hydrocortisone injections.
Secondary adrenal insufficiency.
In secondary adrenal insufficiency, a dysfunction of the hypothalamic-pituitary-adrenal axis leads to decreased stimulation of the adrenal cortex. Apart from suppression of the axis by glucocorticoid therapy, the most common cause of secondary adrenal insufficiency are tumors that affect the production of adrenocorticotropic hormone (ACTH) by the pituitary gland. This type of adrenal insufficiency usually does not affect the production of mineralocorticoids, which are under regulation of the renin-angiotensin system instead.
Congenital adrenal hyperplasia.
Congenital adrenal hyperplasia is a congenital disease in which mutations of enzymes that produce steroid hormones result in a glucocorticoid deficiency and malfunction of the negative feedback loop of the HPA axis. In the HPA axis, cortisol (a glucocorticoid) inhibits the release of CRH and ACTH, hormones that in turn stimulate corticosteroid synthesis. As cortisol cannot be synthesized, these hormones are released in high quantities and stimulate production of other adrenal steroids instead. The most common form of congenital adrenal hyperplasia is due to 21-hydroxylase deficiency. 21-hydroxylase is necessary for production of both mineralocorticoids and glucocorticoids, but not androgens. Therefore, ACTH stimulation of the adrenal cortex induces the release of excessive amounts of adrenal androgens, which can lead to the development of ambiguous genitalia and secondary sex characteristics.
Adrenal tumors.
Adrenal tumors are commonly found as incidentalomas, unexpected asymptomatic tumors found during medical imaging. They are seen in around 3.4% of CT scans, and in most cases they are benign adenomas. Adrenal carcinomas are very rare, with an incidence of 1 case per million per year.
Pheochromocytomas are tumors of the adrenal medulla that arise from chromaffin cells. They can produce a variety of nonspecific symptoms, which include headaches, sweating, anxiety and palpitations. Common signs include hypertension and tachycardia. Surgery, especially adrenal laparoscopy, is the most common treatment for small pheochromocytomas.
History.
Bartolomeo Eustachi, an Italian anatomist, is credited with the first description of the adrenal glands in 1563-4. However, these publications were part of the papal library and did not receive public attention, which was first received with Caspar Bartholin the Elder's illustrations in 1611.
The adrenal glands are named for their location relative to the kidneys. The term "adrenal" comes from "ad-" (Latin, "near") and "renes" (Latin, "kidney"). Similarly, "suprarenal", as termed by Jean Riolan the Younger in 1629, is derived from the Latin "supra" () and "renes" (). The suprarenal nature of the glands was not truly accepted until the 19th century, as anatomists clarified the ductless nature of the glands and their likely secretory role – prior to this, there was some debate as to whether the glands were indeed suprarenal or part of the kidney.
One of the most recognized works on the adrenal glands came in 1855 with the publication of "On the Constitutional and Local Effects of Disease of the Suprarenal Capsule", by the English physician Thomas Addison. In his monography, Addison described what the French physician George Trousseau would later name Addison's disease, an eponym still used today for a condition of adrenal insufficiency and its related clinical manifestations. In 1894, English physiologists George Oliver and Edward Schafer studied the action of adrenal extracts and observed their pressor effects. In the following decades several physicians experimented with extracts from the adrenal cortex to treat Addison's disease. Edward Calvin Kendall, Philip Hench and Tadeusz Reichstein were then awarded the 1950 Nobel Prize in Physiology or Medicine for their discoveries on the structure and effects of the adrenal hormones.

</doc>
<doc id="2299" url="https://en.wikipedia.org/wiki?curid=2299" title="American Media (publisher)">
American Media (publisher)

American Media, Inc., is an American publisher of magazines, supermarket tabloids, and books.
History.
The modern American Media came into being after Generoso Pope, Jr., longtime owner of the "National Enquirer", died in 1988, and his tabloids came under new ownership. American tabloids began consolidating in 1990, when American Media bought "Star" from Rupert Murdoch. The purchase of Globe Communications (owner of the "Globe" and the "National Examiner") followed nine years later.
American Media is not to be confused with American Media Distribution the international news coverage firm. American Media's corporate headquarters in Boca Raton, Florida, figured prominently in news headlines in late 2001, after an anthrax attack was perpetrated on the company. Since then the corporate headquarters have moved to New York City at 1 Park Avenue in Manhattan, before moving to the Financial District to the former JP Morgan Chase headquarters at 4 New York Plaza. That building was severely damaged by Hurricane Sandy but reopened in February 2013. The CEO, David J. Pecker, travels between the Boca Raton and New York offices while managing the company.
AMI continued to expand after it bought Joe Weider's Weider Publications in 2002. Joe Weider continues to manage control of his magazines under AMI's Weider Publications subsidiary.
American Media also owns Distribution Services, an in-store magazine merchandising company. In fall 2002, it launched the book-publishing imprint, AMI Books.
Roger Altman, through Evercore Partners, bought a controlling stake in American Media in 1999. In 2009, American Media was taken over by its bondholders to keep it out of bankruptcy.
In November 2010, American Media filed for Chapter 11 bankruptcy protection due to nearly $1 billion in debt, and assets of less than $50,000. Its subsidiary, American Media Operations Inc., listed assets of $100 to $500 million and debt of over $1 billion. It exited in December.
In May 2014, American Media announced a decision to shift the headquarters of the "National Enquirer" from Florida, where it had been located since 1971, back to New York City, where it originally began as "The New York Enquirer" in 1926.
In 2015, American Media sold "Shape", "Natural Health", and "Fit Pregnancy" to Meredith.

</doc>
<doc id="2303" url="https://en.wikipedia.org/wiki?curid=2303" title="Aramaic language">
Aramaic language

Aramaic ("Arāmāyā", ) is a family of languages or dialects belonging to the Semitic family. More specifically, it is part of the Northwest Semitic subfamily, which also includes Canaanite languages such as Hebrew and Phoenician. The Aramaic alphabet was widely adopted for other languages and is ancestral to the Hebrew, Syriac and Arabic alphabets. Jesus, the central figure of Christianity, spoke an Aramaic dialect during his public ministry.
During its approximately 3000 years of written history, Aramaic has served variously as a language of administration of empires and as a language of divine worship. It became the lingua franca of the Neo-Assyrian Empire (911–605 BC), Neo-Babylonian Empire (605–539 BC), the Achaemenid Empire (539–323 BC), the Parthian Empire (247 BC–224 AD), and the Sasanian Empire (224–651), of the Neo-Assyrian states of Assur, Adiabene, Osroene and Hatra; the state of Palmyra, and the day-to-day language of Yehud Medinata and of Roman Judaea (539 BC – 70 AD). It was the language that Jesus supposedly used the most, the language of large sections of the biblical books of Daniel and Ezra, as well as the main language of the Talmud. Aramaic was also the original language of the Bahrani people of Eastern Arabia, and of the Mandaeans and their gnostic religion, Mandaeism, as well as the language of the once widespread but now extinct religion of Manichaeism.
The major Aramaic dialect Syriac is the liturgical language of Syriac Christianity, in particular the Church of the East, the Chaldean Catholic Church, the Saint Thomas Christian churches in India, the Syriac Orthodox Church, the Assyrian Pentecostal Church, and the Maronite Church.
Aramaic's long history and diverse and widespread use has led to the development of many divergent varieties, which are sometimes considered dialects, though they are distinct enough that they are sometimes considered languages. Therefore, there is not one singular, static Aramaic language; each time and place rather has had its own variation. Aramaic is retained as a liturgical language by certain Eastern Christian churches, in the form of Syriac, the Aramaic variety by which Eastern Christianity was diffused, whether or not those communities once spoke it or another form of Aramaic as their vernacular, but have since shifted to another language as their primary community language.
Neo-Aramaic languages are spoken today as a first language by many scattered, predominantly small, and largely isolated communities of differing Christian, Jewish, and Mandaean ethnic groups of Western Asia —most numerously by the Assyrian people in the form of Turoyo, Assyrian Neo-Aramaic and Chaldean Neo-Aramaic—that have all retained use of the once dominant lingua franca despite subsequent language shifts experienced throughout the Middle East. The Aramaic languages are now considered endangered.
Etymology.
The term "Aramaic", meaning the language of Arameans settling in the region of ancient Aram, ארם or ܐܪܡ (ʾArām), derives from the Hebrew/Aramaic root verb רום (rum) meaning "to rise, be high, piled up, or tall".
"Aram" is used as a proper name of several people in the Torah (Hebrew Bible) including descendants of Shem (Genesis 10:22), Abraham (Genesis 22:21) and Jacob (1 Chronicles 7:34).
Ancient Aram, bordering Northern Israel and now called Syria, is considered the linguistic epicenter of Aramaic, the language of the Arameans who settled the area during the Bronze Age circa 3500 BC. There is some confusion about the origin of the language, often mistaken to have originated within Assyria (Iraq). In fact, Arameans carried their language and writing into Mesopotamia by voluntary migration, by forced exile of conquering armies, and by nomadic Chaldean invasions of Babylonia in 1200 BC to 1000 BC. Interestingly, the Christian primary text written in Koine Greek, New Testament, translates the word "Hebrew" as "Aramaic". Part of this confusion is attributed to the Greek naming "Aram" "Syria" (Συρια; Acts 15:41, Galatians 1:21), and at the same time calling "Assyria" (Iraq) "Syria".
Geographic distribution.
During the Neo-Assyrian and the Neo-Babylonian period, Aramaeans, the native speakers of Aramaic, began to settle in greater numbers, at first in Babylonia, and later in Assyria (Upper Mesopotamia, modern-day northern Iraq, northeast Syria, northwest Iran, and south eastern Turkey). The influx eventually resulted in the Neo-Assyrian Empire (911-605 BC) adopting an Akkadian-influenced Imperial Aramaic as the "lingua franca" of its empire. This policy was continued by the short-lived Neo-Babylonian Empire and Median Empire, and all three empires became operationally bilingual in written sources, with Aramaic used alongside Akkadian. The Persian Empire (539-323 BC) continued this tradition, and the extensive influence of these empires led to Aramaic gradually becoming the "lingua franca" of most of western Asia, the Arabian Peninsula, Asia Minor, the Caucasus, and Egypt. Aramaic was also the lingua franca of the Parthian Empire. Aramaic writing has been found as far north as Hadrian's Wall in Ancient Britain, in the form of inscriptions in Aramaic, made by Assyrian and Aramean soldiers serving in the Roman Legions in northern England during the 2nd century AD. The successor state of the Parthians and thus the new neighboring arch rival of the Roman-Byzantine Empire, the Sasanian Empire, continued with the usage of Aramaic as the lingua franca. From the late 7th century AD to the 14th century AD, Aramaic was gradually replaced as the "lingua franca" of the Middle East by Arabic. However, Aramaic remains a spoken, literary, and liturgical language among indigenous Assyrians, and also some Jews. It is spoken by the Assyrians of Iraq, northeastern Syria, southeastern Turkey, and northwest Iran, with diaspora communities in Armenia, Georgia, Azerbaijan and southern Russia. Mandaeans also continue to use Aramaic as a liturgical language, as most are now Arabic-speakers. There are still also a small number of native speakers of Western Aramaic in isolated villages in western Syria. The turbulence of the last two centuries (particularly the Assyrian Genocide) has seen speakers of first-language and literary Aramaic dispersed throughout the world. However, there are a number of sizable Assyrian towns in northern Iraq such as Alqosh, Bakhdida, Bartella, Tel Esqof, and Tel Keppe, and numerous small villages, where Aramaic is still the main spoken language, and many large cities in this region also have Assyrian Aramaic-speaking communities, particularly Mosul, Irbil, Kirkuk, Dohuk, and Hasakah. Aramaic is also experiencing a revival among Israeli Maronites in Jish.
Aramaic languages and dialects.
Aramaic is often spoken of as a single language. However, it is in reality a group of related languages, rather than a single monolithic language—something which it has never been. Some Aramaic languages differ more from each other than the Romance languages do among themselves. Its long history, extensive literature, and use by different religious communities are all factors in the diversification of the language. Some Aramaic dialects are mutually intelligible, whereas others are not, not unlike the situation with modern Varieties of Arabic. Some Aramaic languages are known under different names; for example, Syriac is particularly used to describe the Eastern Aramaic of indigenous Christian ethnic communities of Assyrians (a.k.a. Chaldo-Assyrians) in Iraq, southeastern Turkey, northeastern Syria, and northwestern Iran, and Saint Thomas Christians in India. Most dialects can be described as either "Eastern" or "Western", the dividing line being roughly the Euphrates, or slightly west of it. It is also helpful to draw a distinction between those Aramaic languages that are modern living languages (often called "Neo-Aramaic"), those that are still in use as literary languages, and those that are extinct and are only of interest to scholars. Although there are some exceptions to this rule, this classification gives "Modern", "Middle", and "Old" periods, alongside "Eastern" and "Western" areas, to distinguish between the various languages and dialects that are Aramaic.
Writing system.
The earliest Aramaic alphabet was based on the Phoenician alphabet. In time, Aramaic developed its distinctive "square" style. The ancient Israelites and other peoples of Canaan adopted this alphabet for writing their own languages. Thus, it is better known as the Hebrew alphabet today. This is the writing system used in Biblical Aramaic and other Jewish writing in Aramaic. The other main writing system used for Aramaic was developed by Christian communities: a cursive form known as the Syriac alphabet. A highly modified form of the Aramaic alphabet, the Mandaic alphabet, is used by the Mandaeans.
In addition to these writing systems, certain derivatives of the Aramaic alphabet were used in ancient times by particular groups: Nabataean in Petra, for instance and Palmyrenean in Palmyra. In modern times, Turoyo (see below) has sometimes been written in a Latin alphabet.
History.
The history of Aramaic is broken down into three broad periods:
This classification is based on that used by Klaus Beyer*.
Old Aramaic.
The term "Old Aramaic" is used to describe the varieties of the language from its first known use until the point roughly marked by the rise of the Sasanian Empire (224 CE), dominating the influential, eastern dialect region. As such, the term covers over thirteen centuries of the development of Aramaic. This vast time span includes all Aramaic that is now effectively extinct.
The central phase in the development of Old Aramaic was its official use by the Achaemenid Empire (500–330 BCE). The period before this, dubbed "Ancient Aramaic", saw the development of the language from being spoken in Aramaean city-states to become a major means of communication in diplomacy and trade throughout Mesopotamia, the Levant and Egypt. After the fall of the Achaemenid Empire, local vernaculars became increasingly prominent, fanning the divergence of an Aramaic dialect continuum and the development of differing written standards.
Ancient Aramaic.
"Ancient Aramaic" refers to the earliest known period of the language, from its origin until it becomes the "lingua franca" of the Fertile Crescent. It was the language of the Aramaean city-states of Damascus, Hamath and Arpad.
There are inscriptions that evidence the earliest use of the language, dating from the 10th century BC. These inscriptions are mostly diplomatic documents between Aramaean city-states. The alphabet of Aramaic at this early period seems to be based on Phoenician, and there is a unity in the written language. It seems that, in time, a more refined alphabet, suited to the needs of the language, began to develop from this in the eastern regions of Aram. Oddly, the dominance of the Neo-Assyrian Empire under Tiglath-Pileser III over Aram in the middle of the 8th century led to the establishment of Aramaic as a lingua franca of the empire, rather than it being eclipsed by Akkadian.
From 700 BC, the language began to spread in all directions, but lost much of its homogeneity. Different dialects emerged in Assyria, Babylonia, the Levant and Egypt. However, the Akkadian-influenced Aramaic of Assyria, and then Babylon, started to come to the fore. As described in 2 Kings 18:26, diplomats of Hezekiah, king of Judah, desired to negotiate with Assyrian ambassadors in Aramaic, the author claiming this was so that the common people would not understand. Around 600 BC, Adon, a Canaanite king, used Aramaic to write to an Egyptian Pharaoh.
"Chaldee" or "Chaldean Aramaic" used to be common terms for the Aramaic of the Chaldean dynasty of Babylonia. It was used to describe Biblical Aramaic, which was, however, written in a later style. It is not to be confused with the modern language Chaldean Neo-Aramaic.
Imperial Aramaic.
Around 500 BC, following the Achaemenid conquest of Mesopotamia under Darius I, Aramaic (as had been used in that region) was adopted by the conquerors as the "vehicle for written communication between the different regions of the vast empire with its different peoples and languages. The use of a single official language, which modern scholarship has dubbed Official Aramaic or Imperial Aramaic, can be assumed to have greatly contributed to the astonishing success of the Achaemenids in holding their far-flung empire together for as long as they did". In 1955, Richard Frye questioned the classification of Imperial Aramaic as an "official language", noting that no surviving edict expressly and unambiguously accorded that status to any particular language. Frye reclassifies Imperial Aramaic as the "lingua franca" of the Achaemenid territories, suggesting then that the Achaemenid-era use of Aramaic was more pervasive than generally thought.
Imperial Aramaic was highly standardised; its orthography was based more on historical roots than any spoken dialect, and the inevitable influence of Persian gave the language a new clarity and robust flexibility. For centuries after the fall of the Achaemenid Empire (in 331 BC), Imperial Aramaic – or near enough for it to be recognisable – would remain an influence on the various native Iranian languages. Aramaic script and – as ideograms – Aramaic vocabulary would survive as the essential characteristics of the Pahlavi writing system.
One of the largest collections of Imperial Aramaic texts is that of the Persepolis fortification tablets, which number about five hundred. Many of the extant documents witnessing to this form of Aramaic come from Egypt, and Elephantine in particular (see Elephantine papyri). Of them, the best known is the "Wisdom of Ahiqar", a book of instructive aphorisms quite similar in style to the biblical book of Proverbs. Achaemenid Aramaic is sufficiently uniform that it is often difficult to know where any particular example of the language was written. Only careful examination reveals the occasional loan word from a local language.
A group of thirty Aramaic documents from Bactria have been discovered, and an analysis was published in November 2006. The texts, which were rendered on leather, reflect the use of Aramaic in the 4th century BC Achaemenid administration of Bactria and Sogdiana.
Post-Achaemenid Aramaic.
The conquest by Alexander the Great did not destroy the unity of Aramaic language and literature immediately. Aramaic that bears a relatively close resemblance to that of the 5th century BC can be found right up to the early 2nd century BCE. The Seleucids imposed Greek in the administration of Syria and Mesopotamia from the start of their rule. In the 3rd century BCE, Greek overtook Aramaic as the common language in Egypt and Syria. However, a post-Achaemenid Aramaic continued to flourish from Judaea, Assyria, Mesopotamia, through the Syrian Desert and into northern Arabia and Parthia.
Biblical Aramaic is the Aramaic found in four discrete sections of the Hebrew Bible:
Biblical Aramaic is a somewhat hybrid dialect. It is theorized that some Biblical Aramaic material originated in both Babylonia and Judaea before the fall of the Achaemenid dynasty. According to historical criticism, defiant Jewish propaganda shaped Aramaic Daniel during Seleucid rule. These stories might have existed as oral traditions at their earliest stage. This might be one factor that led to differing collections of Daniel in the Greek Septuagint and the Masoretic Text, which presents a lightly Hebrew-influenced Aramaic.
Under the category of post-Achaemenid is Hasmonaean Aramaic, the official language of Hasmonaean Judaea (142–37 BC). It influenced the Biblical Aramaic of the Qumran texts, and was the main language of non-biblical theological texts of that community. The major Targums, translations of the Hebrew Bible into Aramaic, were originally composed in Hasmonaean. Hasmonaean also appears in quotations in the Mishnah and Tosefta, although smoothed into its later context. It is written quite differently from Achaemenid Aramaic; there is an emphasis on writing as words are pronounced rather than using etymological forms.
Babylonian Targumic is the later post-Achaemenid dialect found in the Targum Onqelos and Targum Jonathan, the "official" targums. The original, Hasmonaean targums had reached Babylon sometime in the 2nd or 3rd century AD. They were then reworked according to the contemporary dialect of Babylon to create the language of the standard targums. This combination formed the basis of Babylonian Jewish literature for centuries to follow.
Galilean Targumic is similar to Babylonian Targumic. It is the mixing of literary Hasmonaean with the dialect of Galilee. The Hasmonaean targums reached Galilee in the 2nd century AD, and were reworked into this Galilean dialect for local use. The Galilean Targum was not considered an authoritative work by other communities, and documentary evidence shows that its text was amended. From the 11th century CE onwards, once the Babylonian Targum had become normative, the Galilean version became heavily influenced by it.
Babylonian Documentary Aramaic is a dialect in use from the 3rd century CE onwards. It is the dialect of Babylonian private documents, and, from the 12th century, all Jewish private documents are in Aramaic. It is based on Hasmonaean with very few changes. This was perhaps because many of the documents in BDA are legal documents, the language in them had to be sensible throughout the Jewish community from the start, and Hasmonaean was the old standard.
Nabataean Aramaic is the language of the Arameo-Arab kingdom of Petra. The kingdom ("c." 200 BC–106 AD) covered the east bank of the Jordan River, the Sinai Peninsula and northern Arabia. Perhaps because of the importance of the caravan trade, the Nabataeans began to use Aramaic in preference to Old North Arabic. The dialect is based on Achaemenid with a little influence from Arabic: "l" is often turned into "n", and there are a few Arabic loanwords. Some Nabataean Aramaic inscriptions exist from the early days of the kingdom, but most are from the first four centuries AD The language is written in a cursive script that is the precursor to the modern Arabic alphabet. The number of Arabic loanwords increases through the centuries, until, in the 4th century, Nabataean merges seamlessly with Arabic.
Palmyrene Aramaic is the dialect that was in use in the Syriac city state of Palmyra in the Syrian Desert from 44 BC to 274 AD. It was written in a rounded script, which later gave way to cursive Estrangela. Like Nabataean, Palmyrene was influenced by Arabic, but to a much lesser degree.
Arsacid Aramaic, that in use during the Arsacid empire (247 BC – 224 AD), represents a continuation of Achaemenid Aramaic, widely spoken throughout the west of the empire. Aramaic continued as the scribal basis for Pahlavi as it developed for the needs of Parthian: using an Aramaic-derived script and incorporating many heterograms, or Aramaic words meant to be read as Parthian ones. The Arsacids saw themselves as a continuation of Achaemenid rule, and so Arsacid Aramaic, more than any other post-Achaemenid dialect, continued the tradition of the chancery of Darius I. Over time, however, it came under the influence of contemporary, spoken Aramaic, Georgian and Persian. After the conquest of the Parthians by the Persian-speaking Sassanids, Arsacid Pahlavi and Aramaic were influential on Sasanian language use.
Late Old Eastern Aramaic.
The dialects mentioned in the last section were all descended from Achaemenid Imperial Aramaic. However, the diverse regional dialects of Late Ancient Aramaic continued alongside these, often as simple, spoken languages. Early evidence for these spoken dialects is known only through their influence on words and names in a more standard dialect. However, these regional dialects became written languages in the 2nd century BC. These dialects reflect a stream of Aramaic that is not dependent on Imperial Aramaic, and shows a clear division between the regions of Mesopotamia, Babylon and the east, and Judah, Syria, and the west.
In the East, the dialects of Palmyrene and Arsacid Aramaic merged with the regional languages to create languages with a foot in Imperial and a foot in regional Aramaic. The written form of Mandaic, the language of the Mandaean religion, was descended from the Arsacid chancery script.
In the kingdom of Osroene, centred on Edessa and founded in 132 BCE, the regional dialect became the official language: Old Syriac. On the upper reaches of the Tigris, East Mesopotamian Aramaic flourished, with evidence from Hatra, Assur and the Tur Abdin. Tatian, the author of the gospel harmony the Diatessaron came from Assyria, and perhaps wrote his work (172 CE) in East Mesopotamian rather than Syriac or Greek. In Babylonia, the regional dialect was used by the Jewish community, Jewish Old Babylonian (from "c." 70 CE). This everyday language increasingly came under the influence of Biblical Aramaic and Babylonian Targumic.
Late Old Western Aramaic.
The western regional dialects of Aramaic followed a similar course to those of the east. They are quite distinct from the eastern dialects and Imperial Aramaic. Aramaic came to coexist with Canaanite dialects, eventually completely displacing Phoenician in the 1st century BCE and Hebrew around the turn of the 4th century CE.
The form of Late Old Western Aramaic used by the Jewish community is best attested, and is usually referred to as Jewish Old Palestinian. Its oldest form is Old East Jordanian, which probably comes from the region of Caesarea Philippi. This is the dialect of the oldest manuscript of Enoch ("c." 170 BCE). The next distinct phase of the language is called Old Judaean into the 2nd century CE. Old Judaean literature can be found in various inscriptions and personal letters, preserved quotations in the Talmud and receipts from Qumran. Josephus' first, non-extant edition of his "Jewish War" was written in Old Judaean.
The Old East Jordanian dialect continued to be used into the 1st century AD by pagan communities living to the east of the Jordan. Their dialect is often then called Pagan Old Palestinian, and it was written in a cursive script somewhat similar to that used for Old Syriac. A Christian Old Palestinian dialect may have arisen from the pagan one, and this dialect may be behind some of the Western Aramaic tendencies found in the otherwise eastern Old Syriac gospels (see Peshitta).
Languages during Jesus' lifetime.
It is generally believed by Christian scholars that in the 1st century CE, Jews in Judaea primarily spoke Aramaic with a decreasing number using Hebrew as a native language. Many learned Hebrew as a liturgical language. Additionally, Koine Greek was the lingua franca or international language of the Middle East in trade, among the Hellenized classes (much like French in the 18th,19th and 20th centuries in Europe), and in the Roman administration. Latin, the language of the Roman army and higher levels of administration, had almost no impact on the linguistic landscape.
In addition to the formal, literary dialects of Aramaic based on Hasmonaean and Babylonian there were a number of colloquial Aramaic dialects. Seven dialects of Western Aramaic were spoken in the vicinity of Judaea in Jesus' time. They were probably distinctive yet mutually intelligible. Old Judaean was the prominent dialect of Jerusalem and Judaea. The region of Engedi had the South-east Judaean dialect. Samaria had its distinctive Samaritan Aramaic, where the consonants "he", "" and "‘ayin" all became pronounced as "aleph". Galilean Aramaic, the dialect of Jesus' home region, is only known from a few place names, the influences on Galilean Targumic, some rabbinic literature and a few private letters. It seems to have a number of distinctive features: diphthongs are never simplified into monophthongs. East of the Jordan, the various dialects of East Jordanian were spoken. In the region of Damascus and the Anti-Lebanon mountains, Damascene Aramaic was spoken (deduced mostly from Modern Western Aramaic). Finally, as far north as Aleppo, the western dialect of Orontes Aramaic was spoken.
The three languages influenced one another, especially Hebrew and Aramaic. Hebrew words entered Jewish Aramaic (mostly technical religious words but also everyday words like עץ ' "wood"). Conversely, Aramaic words entered Hebrew (not only Aramaic words like "māmmôn" "wealth" but Aramaic ways of using words like making Hebrew ראוי "rā’ûi", "seen" mean "worthy" in the sense of "seemly", which is a loan translation of Aramaic ' meaning "seen" and "worthy").
The Greek of the New Testament often preserves non-Greek "semiticisms", including transliterations of Semitic words:
The 2004 film "The Passion of the Christ" used Aramaic for much of its dialogue, specially reconstructed by a scholar, William Fulco, S.J. Where the appropriate words (in 1st century Aramaic) were no longer known, he used the Aramaic of Daniel, 4th-century Syriac and Hebrew as the basis for his work.
Middle Aramaic.
The 3rd century CE is taken as the threshold between Old and Middle Aramaic. During that century, the nature of the various Aramaic languages and dialects begins to change. The descendants of Imperial Aramaic ceased to be living languages, and the eastern and western regional languages began to form vital, new literatures. Unlike many of the dialects of Old Aramaic, much is known about the vocabulary and grammar of Middle Aramaic.
Eastern Middle Aramaic.
Only two of the Old Eastern Aramaic languages continued into this period. In the north of the region, Old Syriac moved into Middle Syriac. In the south, Jewish Old Babylonian became Jewish Middle Babylonian. The post-Achaemenid, Arsacid dialect became the background of the new Mandaic language.
Syriac.
Syriac (also "Middle Syriac") is the classical, literary, liturgical and often spoken language of Syriac Christians to this day, particularly the Assyrian church of the East, Chaldean Catholic Church, Ancient Church of the East, Syriac Orthodox and Saint Thomas Christian churches. It originated in Northern Mesopotamia. Its golden age was the 4th to 6th centuries. This period began with the translation of the Bible into the language: the Peshitta and the masterful prose and poetry of Ephrem the Syrian. Middle Syriac, unlike its forebear, is a thoroughly Christian language, although in time it became the language of those opposed to the Byzantine leadership of the Church of the East. Missionary activity by Assyrian and Nestorian Christians led to the spread of Syriac from Mesopotamia and Persia, into Central Asia, India and China.
Jewish Middle Babylonian Aramaic.
Jewish Middle Babylonian is the language employed by Jewish writers in Babylonia between the 4th century and the 11th century AD. It is most commonly identified with the language of the Babylonian Talmud (which was completed in the 7th century) and of post-Talmudic (Geonic) literature, which are the most important cultural products of Babylonian Jewry. The most important epigraphic sources for the dialect are the hundreds of Aramaic magic bowls written in the Jewish script.
Mandaic.
Mandaic, spoken by the Mandeans of Iraq, is a sister dialect to Jewish Babylonian Aramaic, though it is both linguistically and culturally distinct. Classical Mandaic is the language in which the Mandaean's Gnostic religious literature was composed. It is characterized by a highly phonetic orthography.
Western Middle Aramaic.
The dialects of Old Western Aramaic continued with Jewish Middle Palestinian (in Hebrew "square script"), Samaritan Aramaic (in the old Hebrew script) and Christian Palestinian (in cursive Syriac script). Of these three, only Jewish Middle Palestinian continued as a written language.
Jewish Middle Palestinian Aramaic.
In 135, after the Bar Kokhba revolt, many Jewish leaders, expelled from Jerusalem, moved to Galilee. The Galilean dialect thus rose from obscurity to become the standard among Jews in the west. This dialect was spoken not only in Galilee, but also in the surrounding parts. It is the linguistic setting for the Jerusalem Talmud (completed in the 5th century), Palestinian targumim (Jewish Aramaic versions of scripture), and midrashim (biblical commentaries and teaching). The standard vowel pointing for the Hebrew Bible, the Tiberian system (7th century), was developed by speakers of the Galilean dialect of Jewish Middle Palestinian. Classical Hebrew vocalisation, therefore, in representing the Hebrew of this period, probably reflects the contemporary pronunciation of this Aramaic dialect.
Middle Judaean, the descendant of Old Judaean, is no longer the dominant dialect, and was used only in southern Judaea (the variant Engedi dialect continued throughout this period). Likewise, Middle East Jordanian continues as a minor dialect from Old East Jordanian. The inscriptions in the synagogue at Dura-Europos are either in Middle East Jordanian or Middle Judaean.
Samaritan Aramaic.
The Aramaic dialect of the Samaritan community is earliest attested by a documentary tradition that can be dated back to the 4th century. Its modern pronunciation is based on the form used in the 10th century.
Christian Palestinian Aramaic.
Sometimes referred to as "Melkite Aramaic," it is the language of Western-Aramaic-speaking Christians is evidenced from the 5th-6th century, but probably existed two centuries earlier. The language itself comes from Old Christian Palestinian Aramaic, but its writing conventions were based on early Middle Syriac, and it was heavily influenced by Greek. For example, the name Jesus, although ישוע "Yešua’" in Jewish Aramaic, and "Išo" in Syriac, is written "Yesûs" (a transliteration of the Greek form) in Christian Palestinian.
Modern Aramaic.
Over 400,000 people of various communities from across the Middle East, and recent emigrants who have moved out of these communities, speak one of several varieties of Modern Aramaic (also called "Neo-Aramaic") natively, including Christians, Jews, Mandaeans, and Muslims. Having lived in remote areas as insulated communities, the remaining modern speakers of Aramaic dialects escaped the linguistic pressures experienced by others during the large-scale language shifts that saw the proliferation of other tongues among those who previously did not speak them, most recently the Arabization of the Middle East and North Africa by Muslim Arabians. Most of the people of that region who converted to Islam, and many from the remaining unconverted population, also adopted Arabic as their first language. The Aramaic-speaking peoples such as Assyrians have preserved their traditions with schools, printing presses, and now with electronic media.
The Neo-Aramaic languages are now farther apart in their mutual intelligibility than perhaps they have ever been. Instability throughout the Middle East over the past century has led to a worldwide diaspora of Aramaic-speakers. For Aramaic-speaking Jews, 1950 is a watershed year: The founding of the state of Israel (1948) and consequent Jewish exodus from Arab lands, including Iraq, led most Iraqi Jews, both Aramaic-speaking and Arabic-speaking Iraqi Jews, to emigrate to Israel. However, immigration to Israel has led to the Jewish Neo-Aramaic (and Jewish Iraqi Arabic) being replaced by Modern Hebrew (Ivrit) among children of the migrants. The practical extinction of many Jewish dialects seems imminent.
Modern Eastern Aramaic.
Modern Eastern Aramaic exists in a wide variety of dialects and languages. There is significant difference between the Aramaic spoken by Jews, Chaldo-Assyrian Christians, and Mandaeans.
The Christian languages are often called Modern Syriac (or Neo-Syriac, particularly when referring to their literature), being deeply influenced by the literary and liturgical language of Middle Syriac. However, they also have roots in numerous, previously unwritten, local Aramaic varieties, and are not purely the direct descendants of the language of Ephrem the Syrian. The varieties are not all mutually intelligible. The principal Christian varieties are Assyrian Neo-Aramaic and Chaldean Neo-Aramaic used by the ethnic Assyrians of Iraq, southeast Turkey, Iran, and northeast Syria.
The Judeo-Aramaic languages are now mostly spoken in Israel, and most are facing extinction. The Jewish varieties that have come from communities that once lived between Lake Urmia and Mosul are not all mutually intelligible. In some places, for example Urmia, Christians and Jews speak mutually unintelligible varieties of Modern Eastern Aramaic in the same place. In others, the Nineveh Plains around Mosul for example, the varieties of the two faith communities are similar enough to allow conversation.
Modern Western Syriac (also called Central Neo-Aramaic, being in between Western Neo-Aramaic and Eastern Neo-Syriac) is generally represented by Turoyo, the language of the Tur Abdin. A related language, Mlahsô, has recently become extinct.
Mandaeans, living in the Khūzestān Province of Iran and scattered throughout Iraq, speak Modern Mandaic. It is quite distinct from any other Aramaic variety.
Modern Central Aramaic.
Central Neo-Aramaic consists of Turoyo and the recently extinct Mlahsô.
Modern Western Aramaic.
Very little remains of Western Aramaic. It is still spoken in the villages of Ma'loula, Bakh'a, and Jubb'adin on Syria's side of the Anti-Lebanon mountains, as well as by some people who migrated from these villages, to Damascus and other larger towns of Syria. All these speakers of Modern Western Aramaic are fluent in Arabic, which has now become the main language in these villages.
Sounds.
Each dialect of Aramaic has its own distinctive pronunciation, and it would not be feasible here to go into all these properties. Aramaic has a phonological palette of 25 to 40 distinct phonemes. Some modern Aramaic pronunciations lack the series of "emphatic" consonants, and some have borrowed from the inventories of surrounding languages, particularly Arabic, Azerbaijani, Kurdish, Persian and Turkish.
Vowels.
As with most Semitic languages, Aramaic can be thought of as having three basic sets of vowels:
These vowel groups are relatively stable, but the exact articulation of any individual is most dependent on its consonantal setting.
The open vowel is an open near-front unrounded vowel ("short" "a", somewhat like the first vowel in the English "batter", ). It usually has a back counterpart ("long" "a", like the "a" in "father", , or even tending to the vowel in "caught", ), and a front counterpart ("short" "e", like the vowel in "head", ). There is much correspondence between these vowels between dialects. There is some evidence that Middle Babylonian dialects did not distinguish between the short "a" and short "e". In West Syriac dialects, and possibly Middle Galilean, the long "a" became the "o" sound. The open "e" and back "a" are often indicated in writing by the use of the letters א "alaph" (a glottal stop) or ה "he" (like the English "h").
The close front vowel is the "long" "i" (like the vowel in "need", ). It has a slightly more open counterpart, the "long" "e", as in the final vowel of "café" (). Both of these have shorter counterparts, which tend to be pronounced slightly more open. Thus, the short close "e" corresponds with the open "e" in some dialects. The close front vowels usually use the consonant י "y" as a mater lectionis.
The close back vowel is the "long" "u" (like the vowel in "school", ). It has a more open counterpart, the "long" "o", like the vowel in "low" (). There are shorter, and thus more open, counterparts to each of these, with the short close "o" sometimes corresponding with the long open "a". The close back vowels often use the consonant ו "w" to indicate their quality.
Two basic diphthongs exist: an open vowel followed by י "y" ("ay"), and an open vowel followed by ו "w" ("aw"). These were originally full diphthongs, but many dialects have converted them to "e" and "o" respectively.
The so-called "emphatic" consonants (see the next section) cause all vowels to become mid-centralised.
Consonants.
The various alphabets used for writing Aramaic languages have twenty-two letters (all of which are consonants). Some of these letters, though, can stand for two or three different sounds (usually a plosive and a fricative at the same point of articulation). Aramaic classically uses a series of lightly contrasted plosives and fricatives:
Each member of a certain pair is written with the same letter of the alphabet in most writing systems (that is, "p" and "f" are written with the same letter), and are near allophones.
A distinguishing feature of Aramaic phonology (and that of Semitic languages in general) is the presence of "emphatic" consonants. These are consonants that are pronounced with the root of the tongue retracted, with varying degrees of pharyngealization and velarization. Using their alphabetic names, these emphatics are:
Ancient Aramaic may have had a larger series of emphatics, and some Neo-Aramaic languages definitely do. Not all dialects of Aramaic give these consonants their historic values.
Overlapping with the set of emphatics are the "guttural" consonants. They include ח Ḥêṯ and ע ʽAyn from the emphatic set, and add א ʼĀlap̄ (a glottal stop) and ה Hê (as the English "h").
Aramaic classically has a set of four sibilants (Ancient Aramaic may have had six):
In addition to these sets, Aramaic has the nasal consonants מ "m" and נ "n", and the approximants ר "r" (usually an alveolar trill), ל "l", י "y" and ו "w".
Historical sound changes.
Six broad features of sound change can be seen as dialect differentials:
Grammar.
As with other Semitic languages, Aramaic morphology (the way words are formed) is based on the consonantal root. The root generally consists of two or three consonants and has a basic meaning, for example, כת״ב "k-t-b" has the meaning of 'writing'. This is then modified by the addition of vowels and other consonants to create different nuances of the basic meaning:
Nouns and adjectives.
Aramaic nouns and adjectives are inflected to show "gender", "number" and "state".
Aramaic has two grammatical genders: masculine and feminine. The feminine absolute singular is often marked by the ending ה- "-â".
Nouns can be either singular or plural, but an additional "dual" number exists for nouns that usually come in pairs. The dual number gradually disappeared from Aramaic over time and has little influence in Middle and Modern Aramaic.
Aramaic nouns and adjectives can exist in one of three states. To a certain extent, these states correspond to the role of articles and cases in the Indo-European languages:
Whereas other Northwest Semitic languages, like Hebrew, have the absolute and construct states, the emphatic/determined state is a unique feature to Aramaic. Case endings, as in Ugaritic, probably existed in a very early stage of the language, and glimpses of them can be seen in a few compound proper names. However, as most of those cases were expressed by short final vowels, they were never written, and the few characteristic long vowels of the masculine plural accusative and genitive are not clearly evidenced in inscriptions. Often, the direct object is marked by a prefixed -ל "l-" (the preposition "to") if it is definite.
Adjectives agree with their nouns in number and gender but agree in state only if used attributively. Predicative adjectives are in the absolute state regardless of the state of their noun (a copula may or may not be written). Thus, an attributive adjective to an emphatic noun, as in the phrase "the good king", is written also in the emphatic state מלכא טבא "malkâ ṭāḇâ"—kinggood[emph.. In comparison, the predicative adjective, as in the phrase "the king is good", is written in the absolute state טב מלכא "ṭāḇ malkâ"—goodking[emph..
The final א- "-â" in a number of these suffixes is written with the letter aleph. However, some Jewish Aramaic texts employ the letter he for the feminine absolute singular. Likewise, some Jewish Aramaic texts employ the Hebrew masculine absolute singular suffix ים- "-îm" instead of ין- "-în". The masculine determined plural suffix, יא- "-ayyâ", has an alternative version, "-ê". The alternative is sometimes called the "gentilic plural" for its prominent use in ethnonyms (יהודיא "yəhûḏāyê", 'the Jews', for example). This alternative plural is written with the letter aleph, and came to be the only plural for nouns and adjectives of this type in Syriac and some other varieties of Aramaic. The masculine construct plural, "-ê", is written with yodh. In Syriac and some other variants this ending is diphthongized to "-ai".
Possessive phrases in Aramaic can either be made with the construct state or by linking two nouns with the relative particle -[ד[י "d[î]-". As the use of the construct state almost disappears from the Middle Aramaic period on, the latter method became the main way of making possessive phrases.
For example, the various forms of possessive phrases (for "the handwriting of the queen") are:
In Modern Aramaic, the last form is by far the most common. In Biblical Aramaic, the last form is virtually absent.
Verbs.
The Aramaic verb has gradually evolved in time and place, varying between varieties of the language. Verb forms are marked for person (first, second or third), number (singular or plural), gender (masculine or feminine), tense (perfect or imperfect), mood (indicative, imperative, jussive or infinitive) and voice (active, reflexive or passive). Aramaic also employs a system of conjugations, or verbal stems, to mark intensive and extensive developments in the lexical meaning of verbs.
Aspectual tense.
Aramaic has two proper tenses: perfect and imperfect. These were originally aspectual, but developed into something more like a preterite and future. The perfect is unmarked, while the imperfect uses various preformatives that vary according to person, number and gender. In both tenses the third-person singular masculine is the unmarked form from which others are derived by addition of afformatives (and preformatives in the imperfect). In the chart below (on the root כת״ב K-T-B, meaning "to write"), the first form given is the usual form in Imperial Aramaic, while the second is Classical Syriac.
Conjugations or verbal stems.
Like other Semitic languages, Aramaic employs a number of conjugations, or verbal stems, to extend the lexical coverage of verbs. The basic conjugation of the verb is called the "ground stem", or "G-stem". Following the tradition of mediaeval Arabic grammarians, it is more often called the Pə‘al פעל (also written Pe‘al), using the form of the triliteral root פע״ל P-‘-L, meaning "to do". This stem carries the basic lexical meaning of the verb.
By doubling of the second radical, or root letter, the D-stem or פעל Pa‘‘el is formed. This is often an intensive development of the basic lexical meaning. For example, "qəṭal" means "he killed", whereas "qaṭṭel" means "he slew". The precise relationship in meaning between the two stems differs for every verb.
A preformative, which can be -ה "ha-", -א "a-" or -ש "ša-", creates the C-stem or variously the Hap̄‘el, Ap̄‘el or Šap̄‘el (also spelt הפעל Haph‘el, אפעל Aph‘el and שפעל Shaph‘el). This is often an extensive or causative development of the basic lexical meaning. For example, טעה "ṭə‘â" means "he went astray", whereas אטעי "aṭ‘î" means "he deceived". The Šap̄‘el שפעל is the least common variant of the C-stem. Because this variant is standard in Akkadian, it is possible that its use in Aramaic represents loanwords from that language. The difference between the variants הפעל Hap̄‘el and אפעל Ap̄‘el appears to be the gradual dropping of the initial ה "h" sound in later Old Aramaic. This is noted by the respelling of the older he preformative with א aleph.
These three conjugations are supplemented with three derived conjugations, produced by the preformative -הת "hiṯ-" or -את "eṯ-". The loss of the initial ה "h" sound occurs similarly to that in the form above. These three derived stems are the Gt-stem, התפעל Hiṯpə‘el or אתפעל Eṯpə‘el (also written Hithpe‘el or Ethpe‘el), the Dt-stem, התפעּל Hiṯpa‘‘al or אתפעּל Eṯpa‘‘al (also written Hithpa‘‘al or Ethpa‘‘al), and the Ct-stem, התהפעל Hiṯhap̄‘al, אתּפעל Ettap̄‘al, השתפעל Hištap̄‘al or אשתפעל Eštap̄‘al (also written Hithhaph‘al, Ettaph‘al, Hishtaph‘al or Eshtaph‘al). Their meaning is usually reflexive, but later became passive. However, as with other conjugations, actual meaning differs from verb to verb.
Not all verbs utilise all of these conjugations, and, in some, the G-stem is not used. In the chart below (on the root כת״ב K-T-B, meaning "to write"), the first form given is the usual form in Imperial Aramaic, while the second is Classical Syriac.
Aramaic also has two proper tenses: the perfect and the imperfect. In Imperial Aramaic, the participle began to be used for a historical present. Perhaps under influence from other languages, Middle Aramaic developed a system of composite tenses (combinations of forms of the verb with pronouns or an auxiliary verb), allowing for narrative that is more vivid. The syntax of Aramaic (the way sentences are put together) usually follows the order verb–subject–object (VSO). Imperial (Persian) Aramaic, however, tended to follow a S-O-V pattern (similar to Akkadian), which was the result of Persian syntactic influence.
Aramaic word processors.
The World's first Aramaic language word processing software was developed in 1986–1987 in Kuwait by information technology professional Sunil Sivanand (1953– ), who is now Managing Director and Chief Technology Architect at Acette. Sunil Sivanand did most of the character generation and programming work on a first generation, twin disk drive IBM Personal Computer. The project was sponsored by Daniel Benjamin, who was a patron of a group of individuals working worldwide to preserve and revive the Aramaic language.

</doc>
<doc id="2304" url="https://en.wikipedia.org/wiki?curid=2304" title="Saint Titus">
Saint Titus

Titus (; ) was an early Christian missionary and Church leader, a companion and disciple of Paul the Apostle, mentioned in several of the Pauline epistles including the Epistle to Titus. He is believed to be a Gentile converted to Christianity by Paul and, according to tradition, was consecrated by him as Bishop of the Island of Crete. Titus brought a fundraising letter from Paul to Corinth, to collect for the poor in Jerusalem. Later, on Crete, Titus appointed presbyters (elders) in every city and remained there into his old age, dying in the city of Candia (modern Heraklion).
Life.
Titus was a Greek, apparently from Antioch, who is said to have studied Greek philosophy and poetry in his early years. He seems to have been converted by Paul, whereupon he served as Paul's secretary and interpreter. In the year 49, Titus accompanied Paul to the council held at Jerusalem, on the subject of the Mosaic rites. Although the apostle had consented to the circumcision of Timothy, in order to render his ministry acceptable among the Jews, he would not allow the same in regard to Titus, so as not to seem in agreement with those who would require it for Gentile converts.
Towards the close of the year 56, Paul, as he himself departed from Asia, sent Titus from Ephesus to Corinth, with full commission to remedy the fallout precipitated by Timothy's delivery of 1 Corinthians () and Paul's "Painful Visit" (), particularly a significant personal offense and challenge to Paul's authority by one unnamed individual (). During this journey, Titus served as the courier for what is commonly known as the "Severe Letter," a Pauline missive that has been lost but is referred to in 2 Corinthians (). After meeting success on this mission, Titus journeyed north and met Paul in Macedonia, where the apostle, overjoyed by Titus' success (), wrote 2 Corinthians. Titus then returned to Corinth with a larger entourage, carrying 2 Corinthians with him. Paul joined Titus in Corinth later. From Corinth, Paul then sent Titus to organize the collections of alms for the Christians at Jerusalem. Titus was therefore a troubleshooter, peacemaker, administrator, and missionary.
Early church tradition holds that Paul, after his release from his first imprisonment in Rome, stopped at the island of Crete to preach. The necessities of other churches requiring his presence elsewhere, he ordained his disciple Titus bishop of that island, and left him to finish the work he had begun. Chrysostom says that this is an indication of the esteem St. Paul held for Titus.
Paul summoned Titus from Crete to join him at Nicopolis in Epirus. Later, Titus traveled to Dalmatia. The New Testament does not record his death.
It has been argued that the name "Titus" in 2 Corinthians and Galatians is nothing more than an informal name used by Timothy, implied already by the fact that even though both are said to be long-term close companions of Paul, they never appear in common scenes. The theory proposes that a number of passages—1 Cor. 4:17, 16.10; 2 Cor. 2:13, 7:6, 13-14, 12:18; and Acts 19.22—all refer to the same journey of a single individual, Titus-Timothy. 2 Timothy seems to dispute this, by claiming that Titus has gone to Dalmatia. () The fact that Paul made a point of circumcising Timothy () but refused to circumcise Titus () indicates that they are different men.
Veneration.
The feast day of Titus was not included in the Tridentine Calendar. When added in 1854, it was assigned to 6 February. In 1969, the Roman Catholic Church assigned the feast to 26 January so as to celebrate the two disciples of Paul, Titus and Timothy, on the day after the feast of the Conversion of St. Paul. The Evangelical Lutheran Church in America celebrates these two, together with Silas, on the same date. The Orthodox Church commemorates him on 25 August and on 4 January.
His relics, now consisting of only his skull, are venerated in the Church of St. Titus, Heraklion, Crete to which it was returned in 1966 after being removed to Venice during the Turkish occupation.
St. Titus is the patron saint of the United States Army Chaplain Corps. The Corps has established the Order of Titus Award. According to the Department of Defense, the "Order of Titus award is the only award presented by the Chief of Chaplains to recognize outstanding performance of ministry by chaplains and chaplain assistants. The Order of Titus is awarded for meritorious contributions to the unique and highly visible Unit Ministry Team Observer Controller Program. The award recognizes the great importance of realistic, doctrinally guided combat ministry training in ensuring the delivery of prevailing religious support to the American Soldier." 

</doc>
<doc id="2308" url="https://en.wikipedia.org/wiki?curid=2308" title="Actinide">
Actinide

The actinide or actinoid (IUPAC nomenclature) series encompasses the 15 metallic chemical elements with atomic numbers from 89 to 103, actinium through lawrencium.
The actinide series derives its name from the first element in the series, actinium. The informal chemical symbol An is used in general discussions of actinide chemistry to refer to any actinide. All but one of the actinides are f-block elements, corresponding to the filling of the 5f electron shell; lawrencium, a d-block element, is also generally considered an actinide. In comparison with the lanthanides, also mostly f-block elements, the actinides show much more variable valence. They all have very large atomic and ionic radii and exhibit an unusually large range of physical properties. While actinium and the late actinides (from americium onwards) behave similarly to the lanthanides, the elements thorium through neptunium are much more similar to transition metals in their chemistry.
All actinides are radioactive and release energy upon radioactive decay; naturally occurring uranium and thorium, and synthetically produced plutonium are the most abundant actinides on Earth. These are used in nuclear reactors and nuclear weapons. Uranium and thorium also have diverse current or historical uses, and americium is used in the ionization chambers of most modern smoke detectors.
Of the actinides, primordial thorium and uranium occur naturally in substantial quantities and small amounts of persisting natural plutonium have also been identified. The radioactive decay of uranium produces transient amounts of actinium and protactinium, and atoms of neptunium and plutonium are occasionally produced from transmutation reactions in uranium ores. The other actinides are purely synthetic elements. Nuclear weapons tests have released at least six actinides heavier than plutonium into the environment; analysis of debris from a 1952 hydrogen bomb explosion showed the presence of americium, curium, berkelium, californium, einsteinium and fermium.
In presentations of the periodic table, the lanthanides and the actinides are customarily shown as two additional rows below the main body of the table, with placeholders or else a selected single element of each series (either lanthanum or lutetium, and either actinium or lawrencium, respectively) shown in a single cell of the main table, between barium and hafnium, and radium and rutherfordium, respectively. This convention is entirely a matter of aesthetics and formatting practicality; a rarely used wide-formatted periodic table inserts the lanthanide and actinide series in their proper places, as parts of the table's sixth and seventh rows (periods).
Discovery, isolation and synthesis.
Like the lanthanides, the actinides form a family of elements with similar properties. Within the actinides, there are two overlapping groups: transuranium elements, which follow uranium in the periodic table—and transplutonium elements, which follow plutonium. Compared to the lanthanides, which (except for promethium) are found in nature in appreciable quantities, most actinides are rare. The most abundant, or easy to synthesize actinides are uranium and thorium, followed by plutonium, americium, actinium, protactinium and neptunium.
The existence of transuranium elements was suggested by Enrico Fermi based on his experiments in 1934. However, even though four actinides were known by that time, it was not yet understood that they formed a family similar to lanthanides. The prevailing view that dominated early research into transuranics was that they were regular elements in the 7th period, with thorium, protactinium and uranium corresponding to 6th-period hafnium, tantalum and tungsten, respectively. Synthesis of transuranics gradually undermined this point of view. By 1944 an observation that curium failed to exhibit oxidation states above 4 (whereas its supposed 6th period homolog, platinum, can reach oxidation state of 6) prompted Glenn Seaborg to formulate a so-called "actinide hypothesis". Studies of known actinides and discoveries of further transuranic elements provided more data in support of this point of view, but the phrase "actinide hypothesis" (the implication being that "hypothesis" is something that has not been decisively proven) remained in active use by scientists through the late 1950s.
At present, there are two major methods of producing isotopes of transplutonium elements: irradiation of the lighter elements with either neutrons or accelerated charged particles. The first method is most important for applications, as only neutron irradiation using nuclear reactors allows the production of sizeable amounts of synthetic actinides; however, it is limited to relatively light elements. The advantage of the second method is that elements heavier than plutonium, as well as neutron-deficient isotopes, can be obtained, which are not formed during neutron irradiation.
In 1962–1966, there were attempts in the United States to produce transplutonium isotopes using a series of six underground nuclear explosions. Small samples of rock were extracted from the blast area immediately after the test to study the explosion products, but no isotopes with mass number greater than 257 could be detected, despite predictions that such isotopes would have relatively long half-lives of α-decay. This inobservation was attributed to spontaneous fission owing to the large speed of the products and to other decay channels, such as neutron emission and nuclear fission.
From actinium to uranium.
Uranium and thorium were the first actinides discovered. Uranium was identified in 1789 by the German chemist Martin Heinrich Klaproth in pitchblende ore. He named it after the planet Uranus, which had been discovered only eight years earlier. Klaproth was able to precipitate a yellow compound (likely sodium diuranate) by dissolving pitchblende in nitric acid and neutralizing the solution with sodium hydroxide. He then reduced the obtained yellow powder with charcoal, and extracted a black substance that he mistook for metal. Only 60 years later, the French scientist Eugène-Melchior Péligot identified it with uranium oxide. He also isolated the first sample of uranium metal by heating uranium tetrachloride with potassium. The atomic mass of uranium was then calculated as 120, but Dmitri Mendeleev in 1872 corrected it to 240 using his periodicity laws. This value was confirmed experimentally in 1882 by K. Zimmerman.
Thorium oxide was discovered by Friedrich Wöhler in the mineral, which was found in Norway (1827). Jöns Jacob Berzelius characterized this material in more detail by in 1828. By reduction of thorium tetrachloride with potassium, he isolated the metal and named it thorium after the Norse god of thunder and lightning Thor. The same isolation method was later used by Péligot for uranium.
Actinium was discovered in 1899 by André-Louis Debierne, an assistant of Marie Curie, in the pitchblende waste left after removal of radium and polonium. He described the substance (in 1899) as similar to titanium and (in 1900) as similar to thorium. The discovery of actinium by Debierne was however questioned in 1971 and 2000, arguing that Debierne's publications in 1904 contradicted his earlier work of 1899–1900. The name actinium comes from the Greek "aktis, aktinos" (ακτίς, ακτίνος), meaning beam or ray. This metal was discovered not by its own radiation but by the radiation of the daughter products. Owing to the close similarity of actinium and lanthanum and low abundance, pure actinium could only be produced in 1950. The term actinide was probably introduced by Victor Goldschmidt in 1937.
Protactinium was possibly isolated in 1900 by William Crookes. It was first identified in 1913, when Kasimir Fajans and Oswald Helmuth Göhring encountered the short-lived isotope 234mPa (half-life 1.17 minutes) during their studies of the 238U decay. They named the new element "brevium" (from Latin "brevis" meaning brief); the name was changed to "protoactinium" (from Greek πρῶτος + ἀκτίς meaning "first beam element") in 1918 when two groups of scientists, led by the Austrian Lise Meitner and Otto Hahn of Germany and Frederick Soddy and John Cranston of Great Britain, independently discovered 231Pa. The name was shortened to "protactinium" in 1949. This element was little characterized until 1960, when A. G. Maddock and his co-workers in the U.K. produced 130 grams of protactinium from 60 tonnes of waste left after extraction of uranium from its ore.
Neptunium and above.
Neptunium (named for the planet Neptune, the next planet out from Uranus, after which uranium was named) was discovered by Edwin McMillan and Philip H. Abelson in 1940 in Berkeley, California. They produced the 239Np isotope (half-life = 2.4 days) by bombarding uranium with slow neutrons. It was the first transuranium element produced synthetically.
Transuranium elements do not occur in sizeable quantities in nature and are commonly synthesized via nuclear reactions conducted with nuclear reactors. For example, under irradiation with reactor neutrons, uranium-238 partially converts to plutonium-239:
In this way, Enrico Fermi with collaborators, using the first nuclear reactor Chicago Pile-1, obtained significant amounts of plutonium-239, which were then used in nuclear weapons.
Actinides with the highest mass numbers are synthesized by bombarding uranium, plutonium, curium and californium with ions of nitrogen, oxygen, carbon, neon or boron in a particle accelerator. So, nobelium was produced by bombarding uranium-238 with neon-22 as
Compounds.
Oxides and hydroxides.
Some actinides can exists in several oxide forms such as An2O3, AnO2, An2O5 and AnO3. For all actinides, oxides AnO3 are amphoteric and An2O3, AnO2 and An2O5 are basic, they easily react with water, forming bases:
These bases are poorly soluble in water and by their activity are close to the hydroxides of rare-earth metals. The strongest base is of actinium. All compounds of actinium are colorless, except for black actinium sulfide (Ac2S3). Dioxides of tetravalent actinides crystallize in the cubic system, same as in calcium fluoride.
Thorium reacting with oxygen exclusively forms dioxide:
Thorium dioxide is a refractory material with the highest melting point among any known oxide (3390 °C). Adding 0.8–1% ThO2 to tungsten stabilizes its structure, so the doped filaments have better mechanical stability to vibrations. To dissolve ThO2 in acids, it is heated to 500–600 °C; heating above 600 °C produces a very resistant to acids and other reagents form of ThO2. Small addition of fluoride ions catalyses dissolution of thorium dioxide in acids.
Two protactinium oxides were obtained: PaO2 (black) and Pa2O5(white); the former is isomorphic with ThO2 and the latter is easier to obtain. Both oxides are basic, and Pa(OH)5 is a weak, poorly soluble base.
Decomposition of certain salts of uranium, for example UO2(NO3)·6H2O in air at 400 °C, yields orange or yellow UO3. This oxide is amphoteric and forms several hydroxides, the most stable being UO2(OH)2.
Reaction of uranium(VI) oxide with hydrogen results in uranium dioxide, which is similar in its properties with ThO2. This oxide is also basic and corresponds to the uranium hydroxide (U(OH)4).
Plutonium, neptunium and americium form two basic oxides: An2O3 and AnO2. Neptunium trioxide is unstable; thus, only Np3O8 could be obtained so far. However, the oxides of plutonium and neptunium with the chemical formula AnO2 and An2O3 are well characterized.
Salts.
Actinides easily react with halogens forming salts with the formulas MX3 and MX4 (X = halogen). So the first berkelium compound, BkCl3, was synthesized in 1962 with an amount of 3 nanograms. Like the halogens of rare earth elements, actinide chlorides, bromides, and iodides are water-soluble, and fluorides are insoluble. Uranium easily yields a colorless hexafluoride, which sublimates at a temperature of 56.5 °C; because of its volatility, it is used in the separation of uranium isotopes with gas centrifuge or gaseous diffusion. Actinide hexafluorides have properties close to anhydrides. They are very sensitive to moisture and hydrolyze forming AnO2F2. The pentachloride and black hexachloride of uranium were synthesized, but they are both unstable.
Action of acids on actinides yields salts, and if the acids are non-oxidizing then the actinide in the salt is in low-valence state:
However, in these reactions the regenerating hydrogen can react with the metal, forming the corresponding hydride. Uranium reacts with acids and water much more easily than thorium.
Actinide salts can also be obtained by dissolving the corresponding hydroxides in acids. Nitrates, chlorides, sulfates and perchlorates of actinides are water-soluble. When crystallizing from aqueous solutions, these salts forming a hydrates, such as Th(NO3)4·6H2O, Th(SO4)2·9H2O and Pu2(SO4)3·7H2O. Salts of high-valence actinides easily hydrolyze. So, colorless sulfate, chloride, perchlorate and nitrate of thorium transform into basic salts with formulas Th(OH)2SO4 and Th(OH)3NO3. The solubility and insolubility of trivalent and tetravalent actinides is like that of lanthanide salts. So phosphates, fluorides, oxalates, iodates and carbonates of actinides are weakly soluble in water; they precipitate as hydrates, such as ThF4·3H2O and Th(CrO4)2·3H2O.
Actinides with oxidation state +6, except for the AnO22+-type cations, form [An2O72− and other complex anions. For example, uranium, neptunium and plutonium form salts of the Na2UO4 (uranate) and (NH4)2U2O7 (diuranate) types. In comparison with lanthanides, actinides more easily form coordination compounds, and this ability increases with the actinide valence. Trivalent actinides do not form fluoride coordination compounds, whereas tetravalent thorium forms K2ThF6, KThF5, and even K5ThF9 complexes. Thorium also forms the corresponding sulfates (for example Na2SO4·Th (SO4)2·5H2O), nitrates and thiocyanates. Salts with the general formula An2Th(NO3)6·"n"H2O are of coordination nature, with the coordination number of thorium equal to 12. Even easier is to produce complex salts of pentavalent and hexavalent actinides. The most stable coordination compounds of actinides – tetravalent thorium and uranium – are obtained in reactions with diketones, e.g. acetylacetone.
Applications.
While actinides have some established daily-life applications, such as in smoke detectors (americium) and gas mantles (thorium), they are mostly used in nuclear weapons and use as a fuel in nuclear reactors. The last two areas exploit the property of actinides to release enormous energy in nuclear reactions, which under certain conditions may become self-sustaining chain reaction.
The most important isotope for nuclear power applications is uranium-235. It is used in the thermal reactor, and its concentration in natural uranium does not exceed 0.72%. This isotope strongly absorbs thermal neutrons releasing much energy. One fission act of 1 gram of 235U converts into about 1 MW·day. Of importance, is that 235U emits more neutrons than it absorbs; upon reaching the critical mass, 235U enters into a self-sustaining chain reaction. Typically, uranium nucleus is divided into two fragments with the release of 2–3 neutrons, for example:

</doc>
<doc id="2310" url="https://en.wikipedia.org/wiki?curid=2310" title="Arthur Miller">
Arthur Miller

Arthur Asher Miller (October 17, 1915 – February 10, 2005) was a prolific American playwright, essayist, and prominent figure in twentieth-century American theatre. Among his most popular plays are "All My Sons" (1947), "Death of a Salesman" (1949), "The Crucible" (1953) and "A View from the Bridge" (1955, revised 1956). He also wrote several screenplays and was most noted for his work on "The Misfits" (1961). The drama "Death of a Salesman" is often numbered on the short list of finest American plays in the 20th century alongside "Long Day's Journey into Night" and "A Streetcar Named Desire".
Miller was often in the public eye, particularly during the late 1940s, 1950s and early 1960s. During this time, he was awarded the Pulitzer Prize for Drama; testified before the House Un-American Activities Committee; and was married to Marilyn Monroe. He received the Prince of Asturias Award and the Praemium Imperiale prize in 2002 and the Jerusalem Prize in 2003, as well as the Dorothy and Lillian Gish Lifetime Achievement Award and the Pulitzer Prize.
Biography.
Early life.
Arthur Asher Miller was born on October 18, 1915, in Harlem, in the New York City borough of Manhattan, the second of three children of Augusta (Barnett) and Isidore Miller. Miller was of Polish-Jewish descent. His father was born in Radomyśl Wielki, Galicia (then part of Austria-Hungary, now Poland), and his mother was a native of New York whose parents also arrived from that town. Isidore owned a women's clothing manufacturing business employing 400 people. He became a wealthy and respected man in the community. The family, including his younger sister Joan Copeland, lived on West 110th Street in Manhattan, owned a summer house in Far Rockaway, Queens, and employed a chauffeur. In the Wall Street Crash of 1929, the family lost almost everything and moved to Gravesend, Brooklyn. As a teenager, Miller delivered bread every morning before school to help the family. After graduating in 1932 from Abraham Lincoln High School, he worked at several menial jobs to pay for his college tuition.
At the University of Michigan, Miller first majored in journalism and worked for the student paper, the "Michigan Daily". It was during this time that he wrote his first play, "No Villain". Miller switched his major to English, and subsequently won the Avery Hopwood Award for "No Villain." The award brought him his first recognition and led him to begin to consider that he could have a career as a playwright. Miller enrolled in a playwriting seminar taught by the influential Professor Kenneth Rowe, who instructed him in his early forays into playwriting; Rowe emphasized how a play is built in order to achieve its intended effect, or what Miller called "the dynamics of play construction". Rowe provided realistic feedback along with much-needed encouragement, and became a lifelong friend. Miller retained strong ties to his alma mater throughout the rest of his life, establishing the university's Arthur Miller Award in 1985 and Arthur Miller Award for Dramatic Writing in 1999, and lending his name to the Arthur Miller Theatre in 2000. In 1937, Miller wrote "Honors at Dawn," which also received the Avery Hopwood Award.
After his graduation in 1938, he joined the Federal Theater Project, a New Deal agency established to provide jobs in the theater. He chose the theater project despite the more lucrative offer to work as a scriptwriter for 20th Century Fox. However, Congress, worried about possible Communist infiltration, closed the project in 1939. Miller began working in the Brooklyn Navy Yard while continuing to write radio plays, some of which were broadcast on CBS.
Early career.
In 1940, he married Mary Grace Slattery. The couple had two children, Jane and Robert (born May 31, 1947). Miller was exempted from military service during World War II because of a high-school football injury to his left kneecap.
1940 was also the year his first play was produced; "The Man Who Had All the Luck" won the Theatre Guild's National Award. The play closed after four performances with disastrous reviews.
In 1947, Miller's play "All My Sons", the writing of which had commenced in 1941, was a success on Broadway (earning him his first Tony Award, for Best Author) and his reputation as a playwright was established. Years later, in a 1994 interview with Ron Rifkin, Miller said that most contemporary critics regarded "All My Sons" as "a very depressing play in a time of great optimism" and that positive reviews from Brooks Atkinson of "The New York Times" had saved it from failure.
In 1948, Miller built a small studio in Roxbury, Connecticut. There, in less than a day, he wrote Act I of "Death of a Salesman". Within six weeks, he completed the rest of the play, one of the classics of world theater. "Death of a Salesman" premiered on Broadway on February 10, 1949 at the Morosco Theatre, directed by Elia Kazan, and starring Lee J. Cobb as Willy Loman, Mildred Dunnock as Linda, Arthur Kennedy as Biff, and Cameron Mitchell as Happy. The play was commercially successful and critically acclaimed, winning a Tony Award for Best Author, the New York Drama Circle Critics' Award, and the Pulitzer Prize for Drama. It was the first play to win all three of these major awards. The play was performed 742 times.
In 1949, Miller exchanged letters with Eugene O'Neill regarding Miller's production of "All My Sons". O'Neill had sent Miller a congratulatory telegram; in response, he wrote a letter that consisted of a few paragraphs detailing his gratitude for the telegram, apologizing for not responding earlier, and inviting Eugene to the opening of "Death of a Salesman". O'Neill replied, accepting the apology, but declining the invitation, explaining that his Parkinson's disease made it difficult to travel. He ended the letter with an invitation to Boston, which never occurred.
The critical years.
In 1956, a one-act version of Miller's verse drama "A View from the Bridge" opened on Broadway in a joint bill with one of Miller's lesser-known plays, "A Memory of Two Mondays". The following year, Miller revised "A View from the Bridge" as a two-act prose drama, which Peter Brook directed in London. A French-Italian co-production "Vu du pont", based on the play, was released in 1962.
In June 1956, Miller left his first wife Mary Slattery and on June 29 he married Marilyn Monroe. Miller and Monroe had met in April 23, 1951, when they had a brief affair, and had remained in contact since then.
Miller began work on "The Misfits", starring his wife. Miller later said that the filming was one of the lowest points in his life; shortly before the film's premiere in 1961, the pair divorced. 19 months later, Monroe died of a possible drug overdose. Miller's future wife Inge Morath worked as a photographer documenting the film's production. The film proved to be the last appearances for both Monroe and Clark Gable, and one of the last for Montgomery Clift.
Miller married photographer Inge Morath on February 17, 1962 and the first of their two children, Rebecca, was born September 15, 1962. Their son Daniel was born with Down syndrome in November 1966; he was institutionalized and excluded from the Millers' personal life at Arthur's insistence. The couple remained together until Inge's death in 2002. Arthur Miller's son-in-law, actor Daniel Day-Lewis, is said to have visited Daniel frequently, and to have persuaded Arthur Miller to reunite with his adult son, Daniel.
HUAC controversy and "The Crucible".
In 1952, Elia Kazan appeared before the House Un-American Activities Committee (HUAC); unwilling to risk his promising career in Hollywood for the Communist cause that he had come to despise, Kazan named eight members of the Group Theatre, including Clifford Odets, Paula Strasberg, Lillian Hellman, J. Edward Bromberg, and John Garfield, who in recent years had been fellow members of the Communist Party. After speaking with Kazan about his testimony, Miller traveled to Salem, Massachusetts to research the witch trials of 1692. "The Crucible", in which Miller likened the situation with the House Un-American Activities Committee to the witch hunt in Salem in 1692, opened at the Beck Theatre on Broadway on January 22, 1953. Though widely considered only somewhat successful at the time of its initial release, today "The Crucible" is Miller's most frequently produced work throughout the world and was adapted into an opera by Robert Ward, which won the Pulitzer Prize for Music in 1962. Miller and Kazan were close friends throughout the late 1940s and early 1950s, but after Kazan's testimony to the HUAC, the pair's friendship ended, and they did not speak to each other for the next ten years. The HUAC took an interest in Miller himself not long after "The Crucible" opened, denying him a passport to attend the play's London opening in 1954. Kazan defended his own actions through his film "On the Waterfront", in which a dockworker heroically testifies against a corrupt union boss.
When Miller applied in 1956 for a routine renewal of his passport, the House Unamerican Activities Committee used this opportunity to subpoena him to appear before the committee. Before appearing, Miller asked the committee not to ask him to name names, to which the chairman, Francis E. Walter (D-PA) agreed.
When Miller attended the hearing, to which Monroe accompanied him, risking her own career, he gave the committee a detailed account of his political activities. Reneging on the chairman's promise, the committee demanded the names of friends and colleagues who had participated in similar activities. Miller refused to comply, saying "I could not use the name of another person and bring trouble on him." As a result, a judge found Miller guilty of contempt of Congress in May 1957. Miller was sentenced to a fine and a prison sentence, blacklisted, and disallowed a US passport. In 1958, his conviction was overturned by the court of appeals, which ruled that Miller had been misled by the chairman of the HUAC.
Miller's experience with the HUAC affected him throughout his life. In the late 1970s he became very interested in the highly publicized Barbara Gibbons murder case, in which Gibbons' son Peter Reilly was convicted of his mother's murder based on what many felt was a coerced confession and little other evidence. "City Confidential", an A&E Network series, produced an episode about the murder, postulating that part of the reason Miller took such an active interest (including supporting Reilly's defense and using his own celebrity to bring attention to Reilly's plight) was because he had felt similarly persecuted in his run-ins with the HUAC. He sympathized with Reilly, whom he firmly believed to be innocent and to have been railroaded by the Connecticut State Police and the Attorney General who had initially prosecuted the case.
Later career.
In 1964" After the Fall" was produced, and is said to be a deeply personal view of Miller's experiences during his marriage to Monroe. The play reunited Miller with his former friend Kazan: they collaborated on both the script and the direction. "After the Fall" opened on January 23, 1964 at the ANTA Theatre in Washington Square Park amid a flurry of publicity and outrage at putting a Monroe-like character, called Maggie, on stage. Robert Brustein, in a review in the New Republic, called "After the Fall" "a three and one half hour breach of taste, a confessional autobiography of embarrassing explicitness . . . there is a misogynistic strain in the play which the author does not seem to recognize. . . . He has created a shameless piece of tabloid gossip, an act of exhibitionism which makes us all voyeurs, . . . a wretched piece of dramatic writing." That same year, Miller produced "Incident at Vichy". In 1965, Miller was elected the first American president of PEN International, a position which he held for four years. A year later, Miller organized the 1966 PEN congress in New York City. Miller also wrote the penetrating family drama, "The Price", produced in 1968. It was Miller's most successful play since "Death of a Salesman."
In 1969, Miller's works were banned in the Soviet Union after he campaigned for the freedom of dissident writers. Throughout the 1970s, Miller spent much of his time experimenting with the theatre, producing one-act plays such as "Fame" and "The Reason Why", and traveling with his wife, producing "In The Country" and "Chinese Encounters" with her. Both his 1972 comedy "The Creation of the World and Other Business" and its musical adaptation, "Up from Paradise", were critical and commercial failures.
Miller was an unusually articulate commentator on his own work. In 1978 he published a collection of his "Theater Essays", edited by Robert A. Martin and with a foreword by Miller. Highlights of the collection included Miller's introduction to his "Collected Plays", his reflections on the theory of tragedy, comments on the McCarthy Era, and pieces arguing for a publicly supported theater. Reviewing this collection in the "Chicago Tribune," Studs Terkel remarked, "in reading "Theater Essays"...you are exhilaratingly aware of a social critic, as well as a playwright, who knows what he's talking about."
In 1983, Miller traveled to China to produce and direct "Death of a Salesman" at the People's Art Theatre in Beijing. The play was a success in China and in 1984, "Salesman in Beijing," a book about Miller's experiences in Beijing, was published. Around the same time, "Death of a Salesman" was made into a TV movie starring Dustin Hoffman as Willy Loman. Shown on CBS, it attracted 25 million viewers. In late 1987, Miller's autobiographical work,
"Timebends", was published. Before it was published, it was well known that Miller would not talk about Monroe in interviews; in "Timebends" Miller talks about his experiences with Monroe in detail.
During the early-mid 1990s, Miller wrote three new plays: "The Ride Down Mt. Morgan" (1991), "The Last Yankee" (1992), and "Broken Glass" (1994). In 1996, a film of "The Crucible" starring Daniel Day-Lewis, Paul Scofield, Bruce Davison, and Winona Ryder opened. Miller spent much of 1996 working on the screenplay to the film.
"Mr. Peters' Connections" was staged Off-Broadway in 1998, and "Death of a Salesman" was revived on Broadway in 1999 to celebrate its fiftieth anniversary. The play, once again, was a large critical success, winning a Tony Award for best revival of a play.
In 1993, he was awarded the National Medal of Arts. Miller was honored with the PEN/Laura Pels International Foundation for Theater Award for a Master American Dramatist in 1998. In 2001 the National Endowment for the Humanities (NEH) selected Miller for the Jefferson Lecture, the U.S. federal government's highest honor for achievement in the humanities. Miller's lecture was entitled "On Politics and the Art of Acting."
Miller's lecture analyzed political events (including the U.S. presidential election of 2000)
in terms of the "arts of performance," and it drew attacks from some conservatives such as Jay Nordlinger, who called it "a disgrace,"
In 1999, Miller was awarded The Dorothy and Lillian Gish Prize, one of the richest prizes in the arts, given annually to "a man or woman who has made an outstanding contribution to the beauty of the world and to mankind’s enjoyment and understanding of life." In 2001, Miller received the National Book Foundation's Medal for Distinguished Contribution to American Letters. On May 1, 2002, Miller was awarded Spain's Principe de Asturias Prize for Literature as "the undisputed master of modern drama." Later that year, Ingeborg Morath died of lymphatic cancer at the age of 78. The following year Miller won the Jerusalem Prize.
In December 2004, the 89-year-old Miller announced that he had been in love with 34-year-old minimalist painter Agnes Barley and had been living with her at his Connecticut farm since 2002, and that they intended to marry. Within hours of her father's death, Rebecca Miller ordered Barley to vacate the premises, having consistently opposed the relationship. Miller's final play, "Finishing the Picture", opened at the Goodman Theatre, Chicago, in the fall of 2004, with one character said to be based on Barley. It was reported to be based on his experience during the filming "The Misfits", though Miller insisted the play is a work of fiction with independent characters that were no more than composite shadows of history.
Death.
Miller died of heart failure after suffering from cancer, pneumonia and congestive heart disease, at his home in Roxbury, Connecticut. He had been in hospice care at his sister's apartment in New York since his release from hospital the previous month. He died on the evening of February 10, 2005 (the 56th anniversary of the Broadway debut of "Death of a Salesman"), aged 89, surrounded by Barley, family and friends. He is interred at Roxbury Center Cemetery in Roxbury.
Legacy.
Arthur Miller's career as a writer spanned over seven decades, and at the time of his death, Miller was considered to be one of the greatest dramatists of the twentieth century. After his death, many respected actors, directors, and producers paid tribute to Miller, some calling him the last great practitioner of the American stage, and Broadway theatres darkened their lights in a show of respect.
Miller's Alma Mater, the University of Michigan, opened the Arthur Miller Theatre in March 2007. As per his express wish, it is the only theatre in the world that bears Miller's name.
Other notable arrangements for Miller's legacy are that his letters, notes, drafts and other papers are housed at the Harry Ransom Humanities Research Center at The University of Texas at Austin.
Arthur Miller is also a member of the American Theater Hall of Fame. He was inducted in 1979.
In 1993 he received the Four Freedom Award for Freedom of Speech
Miller's styles, themes, and characters.
Miller successfully diverse dramatic styles and movements in the belief that a play should embody a delicate balance between the individual and society, between the singular personality and the polity, and between the separate and collective elements of life. He thought himself a writer of social plays with a strong emphasis on moral problems in American society and often questioned psychological causes of behavior. He also built on the realist tradition of Henrik Ibsen in his exploration of the individual’s conflict with society but also borrowed Symbolist and expressionist techniques from Bertolt Brecht and others. Some critics attempt to interpret his work from either an exclusively political or an exclusively psychological standpoint but fail to pierce the social veil that Miller creates in his work. Miller often stressed that society made his characters what they are and how it dictated all of their fears and choices.
Themes.
All American family.
While Miller comes under criticism for his reputation, most critics note him as a dramatist of the family. One of his greatest strengths is his penetrating insight into familial relationships. Often, Miller positions his characters are living in service of their family. The conventions of the family play, such as patterns, setting, and style of representation were set canonically by Eugene O'Neill, Tennessee Williams, and Miller. In these plays, white men are privileged with their family and social responsibility; typically, these men are lower class. Miller maintained that family relationships and families must be immersed in social context.
Social responsibility.
Arthur Miller is known for the consciousness of the characters in his play. In his plays, he confronts a level of banality with the roller coaster of guilt and responsibility. Some strong examples of characters who portray this struggle between their conscious and their social responsibility are Joe Keller in All My Sons and John Proctor in The Crucible. Miller often creates consequences for characters who ignore or violate their social responsibilities.
Life, death and human purpose.
Miller's determination to deal with the eternal themes of life, death and human purpose is one of his most prominent themes across his works. This theme spans from Willy Loman's dedication to providing for his family and his inherent belief that his death would leave a legacy, to John Proctor's willingness to die to preserve his name. Mostly all of Miller's protagonists struggle with the mark they leave on life and what it means to die.
Famous characters of his works.
Willy Loman.
In "Death of a Salesman" – originally entitled “The Inside of His Head” – Miller brilliantly solves the problem of revealing his main character’s inner discord, rendering Willy Loman as solid as the society in which he tries to sell himself. Indeed, many critics believe that Miller has never surpassed his achievement in this play, which stands as his breakthrough work, distinguished by an extremely long Broadway run, by many revivals, and by many theater awards, including the Pulitzer Prize in 1949. Death of a Salesman seems destined to remain an American classic and a standard text in American classrooms.
Willy Loman desperately wants to believe that he has succeeded, that he is “well liked” as a great salesman, a fine father, and a devoted husband. That he has not really attracted the admiration and popularity at which he has aimed is evident, however, in the weariness that belabors him from the beginning of the play. Nearing retirement he suffers a drastic decrease in sales work, a dissatisfying marriage, and a turbulent relationship with his sons which inexorably leads to his suicide with the justification that the insurance will finally provide for his family.
Eddie Carbone.
Eddie Carbone is the central character in "A View From The Bridge" and is not positioned as the protagonist or the antogonist. He is a longshoreman who lives with his wife, Beatrice, and his 17-year-old niece, Catherine. When his family from Italy, Rodolpho and Marco, migrate illegally and begin to live with him, the small world that he operates in is disrupted. Eddie becomes conflicted and ultimately self-destructive over his sexual attraction to his niece and her involvement with one of his Italian tenants. His character arc culminates as he becomes an informer to the immigration authorities which leads to a confrontation with one of his tenants. Marco labels him as an informer and Eddie perceives this as a permanent blemish on his good name. This confrontation ultimately leads to his death, leaving Eddie as one of Miller's examples of tragic figures.
John Proctor.
John Proctor is the protagonist of one of Miller's most controversial works, "The Crucible". He is a faithful farmer who lives by a strict moral code that he violates by succumbing to an affair with a young girl, Abigail, who serves in his home. After rejecting her, Abigail spitefully accuses John's wife of witchcraft, involving him in a string of affairs that challenge his beliefs and convictions. In his attempts to save his wife, he is convicted of witchcraft as well, and will only be acquitted if he confesses to his crime and signs his name to a piece of paper. Proctor is a strong, vital man in the prime of his life both in his confession of witchcraft and the subsequent passion with which he defends his name at the cost of his life.
Joe Keller.
Critics have long admired the playwright’s suspenseful handling of the Keller family’s burden in the play "All My Sons". The critical character in this work is Joe Keller, who permitted defective parts to remain in warplanes that subsequently crash. Not only does Joe Keller fail to recognize his social responsibility, but also he allows his business partner to take the blame and serve the prison term for the crime. Gradually, events combine to strip Keller of his rationalizations. He argues that he never believed that the cracked engine heads would be installed and that he never admitted his mistake because it would have driven him out of business at the age of sixty-one, when he would not have another chance to “make something” for his family, his highest priority. Joe's irresponsibility is exposed through his son's questioning of his very humanity. Joe's suicide results from the tremendous guilt and self-awareness that arises during the play. This reversal from staunchly defensive over his honorable need to protect his family to discovering his social responsibility had some critics claiming that this was a theatrical trick.
Literary and public criticism.
Christopher Bigsby wrote "Arthur Miller: The Definitive Biography" based on boxes of papers Miller made available to him before his death in 2005. The book was published in November 2008, and is reported to reveal unpublished works in which Miller "bitterly attack the injustices of American racism long before it was taken up by the civil rights movement".
In his book "Trinity of Passion", author Alan M. Wald conjectures that Miller was "a member of a writer's unit of the Communist Party around 1946," using the pseudonym Matt Wayne, and editing a drama column in the magazine "The New Masses".
Two months after Miller died Peter O'Toole called him a "bore" and Roger Kimball went on record saying that Miller's artistic accomplishments were meager.
The Arthur Miller Foundation.
The Arthur Miller Foundation was founded to honor the legacy of Arthur Miller and his New York City Public School Education. The mission of the foundation is:
"Promoting increased access and equity to theater arts education in our schools and Increasing the number of students receiving theater arts education as an integral part of their academic curriculum". Other initiatives include effecting the certification of new theater teachers and their placement in public schools, increasing the number of theater teachers in the system from the current estimate of 180 teachers in 1800 schools, supporting professional development of all certified theater teachers, providing teaching artists, cultural partners, physical spaces, and theater ticket allocations for students The Foundation's primary purpose is to provide arts education in the New York City School system. The current canceller of the foundation is Carmen Farina, a large proponent of the common core. Alec Baldwin, Ellen Barkin, Katori Hall, Dustin Hoffman, Scarlett Johansson, Tony Kushner, Michael Mayer, Jim McElhinney, Julianne Moore, Liam Neeson, Lynn Nottage, David O. Russell, Liev Schreiber all serve on the Master Arts Council. Son-in-law Daniel Day-Lewis serves on the current board of directors.
The Foundation will celebrate Miller’s 100th Birthday with a star-studded, one-night-only performance of Miller’s seminal works in November 2015.
Quest to learn program.
The Arthur Miller Foundation currently supports a pilot program in theater and film at the public school Quest to Learn in partnership with the Institute of Play. The model is being used as an in-school elective theater class and lab. The objective is to create a sustainable theater education model to disseminate to teachers at professional development workshop.
Further reading.
Critical Articles

</doc>
<doc id="2313" url="https://en.wikipedia.org/wiki?curid=2313" title="Anton Diabelli">
Anton Diabelli

Anton (or Antonio) Diabelli (5 September 17817 April 1858) was an Austrian music publisher, editor and composer. Best known in his time as a publisher, he is most familiar today as the composer of the waltz on which Ludwig van Beethoven wrote his set of thirty-three "Diabelli Variations".
Early life.
Diabelli was born in Mattsee near Salzburg. A musical child, he sang in the boys' choir at the Salzburg Cathedral where he is believed to have taken music lessons with Michael Haydn. By age 19, Diabelli had already composed several important compositions, including six masses.
Diabelli was trained to enter the priesthood and in 1800 he joined the monastery at Raitenhaslach, Bavaria. He remained there until 1803, when Bavaria closed all its monasteries.
Career.
In 1803 Diabelli moved to Vienna and began teaching piano and guitar and found work as a proofreader for a music publisher. During this period he learned the music publishing business while continuing to compose. In 1809 he composed his comic opera, "Adam in der Klemme." In 1817 he started a music publishing business and 1818, partnered with Pietro Cappi to create the music publishing firm of Cappi & Diabelli.
The firm, Cappi & Diabelli became well known by arranging popular pieces so they could be played by amateurs at home. A master of promotion, Diabelli selected widely-accessible music such as famous opera tune arrangements, dance music, or hundreds of the latest popular comic theatre songs.
The firm soon established a reputation in more serious music circles by championing the works of Franz Schubert. It was Diabelli who first recognized the composer's potential, become the very first to publish Schubert's work with "Der Erlkönig" in 1821. Diabelli's firm continued to publish Schubert's work until 1823 when an argument between Cappi and Schubert terminated their business. The following year, Diabelli and Cappi parted ways, with Diabelli launching a new publishing house, Diabelli & Co, in 1824.
Following Schubert's early death in 1828, Diabelli purchased a large portion of the composer's massive musical estate from Schubert's brother Ferdinand. As Schubert's total compositions number nearly 1000, Diabelli's firm was able to publish "new" Schubert works for more than 30 years after the composer's death.
Diabelli's publishing house expanded throughout his life, before he retired in 1851, leaving it under the control of Carl Anton Spina. When Diabelli died in 1858, Spina continued to run the firm, and published much music by Johann Strauss II and Josef Strauss. In 1872, the firm was taken over by Friedrich Schreiber, and in 1876 it merged with the firm of August Cranz, who bought the company in 1879 and ran it under his name.
He died in Vienna at the age of 76.
Compositions.
Diabelli produced a number of well known works as a composer, including an operetta called "Adam in der Klemme", several masses and songs and numerous piano and classical guitar pieces. Among these are pieces for piano four hands that are popular among pianists of all ages. His music goes on to be the fundamentals of opera, and is considered by some to have set the fundamental stepping stones for classic jazz.
Diabelli's composition "Pleasures of Youth: Six Sonatinas" is a collection of six sonatinas depicting a struggle between unknown opposing forces. This is suggested by the sharp and frequent change in dynamics from forte to piano. When forte is indicated, the pianist is meant to evoke a sense of wickedness, thus depicting the antagonist. In contrast, the markings of piano represent the protagonist with its softer, more tranquil tones.
Diabelli Variations.
The composition for which Diabelli is now best known was actually written as part of an adventuring story. In 1819, as a promotional idea, he decided to try to publish a volume of variations on a "patriotic" waltz he had penned expressly for this purpose, with one variation by every important Austrian composer living at the time, as well as several significant non-Austrians. The combined contributions would be published in an anthology called "Vaterländischer Künstlerverein". Fifty-one composers responded with pieces, including Beethoven, Schubert, Archduke Rudolph of Austria, F.X. Wolfgang Mozart (jun.), Moritz Count von Dietrichstein, Heinrich Eduard Josef Baron von Lannoy, Ignaz Franz Baron von Mosel, Carl Czerny, Johann Nepomuk Hummel, Ignaz Moscheles, and the eight-year-old Franz Liszt (although it seems Liszt was not invited personally, but his teacher Czerny arranged for him to be involved). Czerny was also enlisted to write a coda. Beethoven, however, instead of providing just one variation, provided 33, and his formed Part I of "Vaterländischer Künstlerverein". They constitute what is generally regarded as one of the greatest of Beethoven's piano pieces and as the greatest set of variations of their time, and are generally known simply as the "Diabelli Variations", Op. 120. The other 50 variations were published as Part II of "Vaterländischer Künstlerverein".
Cultural references.
A sonatina of Diabelli's, presumably Sonatina in F major, Op. 168, No. 1 (I: Moderato cantabile), provides the title and a motif for the French novella "Moderato Cantabile" by Marguerite Duras.

</doc>
<doc id="2314" url="https://en.wikipedia.org/wiki?curid=2314" title="Anita Hill">
Anita Hill

Anita Faye Hill (born July 30, 1956) is an American attorney and academic. She is a University Professor of Social Policy, Law, and Women's Studies at Brandeis University and a faculty member of Brandeis' Heller School for Social Policy and Management. She became a national figure in 1991 when she accused U.S. Supreme Court nominee Clarence Thomas, her boss at the U.S. Department of Education and the Equal Employment Opportunity Commission, of sexual harassment.
Early life.
Hill was born in Lone Tree, Oklahoma, the youngest of the 13 children of Albert and Erma Hill, who were farmers. Her family came from Arkansas, where her great-grandparents and her maternal grandfather, Henry Eliot, were born into slavery. Hill was raised in the Baptist faith.
After graduating as valedictorian from Morris High School, Oklahoma she enrolled at Oklahoma State University, receiving a bachelor's degree with honors in psychology in 1977. She went on to Yale Law School, obtaining her Juris Doctor degree with honors in 1980.
She was admitted to the District of Columbia Bar in 1980 and began her law career as an associate with the Washington, D.C. firm of Wald, Harkrader & Ross. In 1981, she became an attorney-adviser to Clarence Thomas who was then the Assistant Secretary of the U.S. Department of Education's Office for Civil Rights. When Thomas became Chairman of the U.S. Equal Employment Opportunity Commission (EEOC) in 1982, Hill went along to serve as his assistant, leaving the job in 1983.
Hill then became an assistant professor at the Evangelical Christian O. W. Coburn School of Law at Oral Roberts University where she taught from 1983 to 1986. In 1986, she joined the faculty at the University of Oklahoma College of Law where she taught commercial law and contracts.
Clarence Thomas controversy.
In 1991, President George H. W. Bush nominated Clarence Thomas, by then a federal Circuit Judge, to succeed retiring Associate Justice Thurgood Marshall on the Supreme Court. Senate hearings on his confirmation were initially completed with Thomas's good character being presented as a primary qualification for the high court because he had only been a judge for slightly more than one year. There had been little organized opposition to Thomas's nomination, and his confirmation seemed assured until a report of a private interview of Hill by the FBI was leaked to the press. The hearings were then reopened, and Hill was called to publicly testify. Hill said in the October 1991 televised hearings that Thomas had sexually harassed her while he was her supervisor at the Department of Education and the EEOC. When questioned on why she followed Thomas to the second job after he had already allegedly harassed her, she said working in a reputable position within the civil rights field had been her ambition. The position was appealing enough to inhibit her to go back into private practice with her previous firm. She only realized later in her life that this ambitious venture was a poor judgement and also explained that "at that time, it appeared that the sexual overtures ... had ended."
According to Hill, during her two years of employment as Thomas's assistant, Thomas had asked her out socially many times, and after she refused, he used work situations to discuss sexual subjects. "He spoke about...such matters as women having sex with animals and films showing group sex or rape scenes," she said, adding that on several occasions Thomas graphically described "his own sexual prowess" and the details of his anatomy. Hill also recounted an instance in which Thomas examined a can of Coke on his desk and asked, "Who has put pubic hair on my Coke?" During court session, Republican Senator Orrin Hatch implied that "Hill was working in tandem with "slick lawyers" and interest groups bent on destroying Thomas' chances to join the court". Clarence said he considered Hill as a friend whom he had helped at every turn when accusations of harassment came from her made him particularly hurtful and he said, "I lost the belief that if I did my best, all would work out." John Doggett an acquaintance of both Hill and Clarence called her charge "completely unfounded" and added when she chastised him not being on her side that he felt "she was somewhat unstable" and suspects histrionic personality disorder for her attention seeking.
Four female witnesses reportedly waited in the wings to support Hill's credibility, but they were not called, due to what the "Los Angeles Times" described as a private, compromise deal between Republicans and the Senate Judiciary Committee Chair, Democrat Joe Biden. According to "Time" magazine, one of the witnesses, Angela Wright, may not have been considered credible on the issue of sexual harassment because she had been fired from the EEOC by Thomas.
Hill agreed to take a polygraph test. The results supported the veracity of her statements; Thomas declined the test. He made a vehement and complete denial, saying that he was being subjected to a "high-tech lynching for uppity blacks" by white liberals who were seeking to block a black conservative from taking a seat on the Supreme Court. After extensive debate, the United States Senate confirmed Thomas to the Supreme Court by a vote of 52–48, the narrowest margin since the 19th century.
Thomas's supporters questioned Hill's credibility, claiming she was delusional or had been spurned, leading her to seek revenge. They cited the time delay of ten years between the alleged behavior by Thomas and Hill's accusations, and noted that Hill had followed Thomas to a second job and later had personal contacts with Thomas, including giving him a ride to an airport—behavior which they said would be inexplicable if Hill's allegations were true. Hill countered that she had come forward because she felt an obligation to share information on the character and actions of a person who was being considered for the Supreme Court. She testified that after leaving the EEOC, she had had two "inconsequential" phone conversations with Thomas, and had seen him personally on two occasions; once to get a job reference and the second time when he made a public appearance in Oklahoma where she was teaching.
Doubts about the veracity of Hill's 1991 testimony persisted long after Thomas took his seat on the Court. They were furthered by "American Spectator" writer David Brock in his 1993 book "The Real Anita Hill", though he later recanted the claims he had made, described in his book as "character assassination," and apologized to Hill. After interviewing a number of women who alleged that Thomas had frequently subjected them to sexually explicit remarks, "Wall Street Journal" reporters Jane Mayer and Jill Abramson wrote a book which concluded that Thomas had lied during his confirmation process. "Time" magazine remarked in 1994, however, that "Their book doesn't quite nail that conclusion." In 2007, Kevin , a coauthor of another book on Thomas, remarked that what happened between Thomas and Hill was "ultimately unknowable" by others, but that it was clear that "one of them lied, period." Writing in 2007, Neil Lewis of "The New York Times" remarked that, "To this day, each side in the epic he-said, she-said dispute has its unmovable believers."
In 2007, Clarence Thomas published his autobiography, "My Grandfather's Son", in which he revisited the controversy, calling Hill his "most traitorous adversary" and saying that pro-choice liberals, who feared that he would vote to overturn "Roe v. Wade" if he were seated on the Supreme Court, used the scandal against him. He described Hill as touchy and apt to overreact, and her work at the EEOC as mediocre. He acknowledged that three other former EEOC employees had backed Hill's story, but said they had all left the agency on bad terms. He also wrote that Hill "was a left-winger who'd never expressed any religious sentiments whatsoever...and the only reason why she'd held a job in the Reagan administration was because I'd given it to her." Hill denied the accusations in an op-ed in the "New York Times" saying she would not "stand by silently and allow Thomas, in his anger, to reinvent me".
In October 2010, Thomas's wife Virginia, a conservative activist, left a voicemail at Hill's office asking that Hill apologize for her 1991 testimony. Hill initially believed the call was a hoax and referred the matter to the Brandeis University campus police who alerted the FBI. After being informed that the call was indeed from Virginia Thomas, Hill told the media that she did not believe the message was meant to be conciliatory and said, "I testified truthfully about my experience and I stand by that testimony." Virginia Thomas responded that the call had been intended as an "olive branch".
Effects.
Public interest in, and debate over, Hill's testimony is said to have launched modern-day public awareness and open discussion of the issue of workplace sexual harassment in the United States with the ultimate result that the behavior is less tolerated today. Shortly after the Thomas confirmation hearings, President George H. W. Bush dropped his opposition to a bill giving harassment victims the right to seek federal damage awards, back pay and reinstatement, and the law was passed by Congress. One year later, harassment complaints filed with the EEOC were up 50 percent and public opinion had shifted in Hill's favor. Private companies also started training programs to deter sexual harassment. When journalist Cinny Kennard asked Hill in 1991 if she would testify against Thomas all over again, Hill answered, "I'm not sure if I could have lived with myself if I had answered those questions any differently."
The manner in which the all-male Senate Judiciary Committee challenged and dismissed Hill's accusations of sexual harassment angered women politicians and lawyers. According to D.C. Congressional Delegate Eleanor Holmes Norton, Hill's treatment by the panel also said to be a contributing factor to the large number of women elected to Congress in 1992, "women clearly went to the polls with the notion in mind that you had to have more women in Congress", she said. In their anthology, "All the Women Are White, All the Blacks Are Men, but Some of Us Are Brave", editors Gloria T. Hull, Patricia Bell Scott and Barbara Smith described black feminists mobilizing "a remarkable national response to the Anita Hill-Clarence Thomas controversy.
In 1992, a feminist group began a nationwide fundraising campaign and then obtained matching state funds to endow a professorship at the University of Oklahoma Law School in honor of Hill. Conservative Oklahoma state legislators reacted by demanding Hill's resignation from the university, then introducing a bill to prohibit the university from accepting donations from out-of-state residents, and finally attempting to pass legislation to close down the law school. Elmer Zinn Million, a local activist and organized protester who caught up by the zeal compared Hill to the assassin of President Kennedy. He was known as the “one-armed man” by "Oklahoma Observer". Certain officials at the university attempted to revoke Hill's tenure. After five years of pressure, Hill resigned. The University of Oklahoma Law School defunded the Anita F. Hill professorship in May 1999, without the position having ever being filled.
Later career.
Hill accepted a position as a visiting scholar at the Institute for the Study of Social Change at University of California, Berkeley in January 1997, but soon joined the faculty of Brandeis University—first at the Women's Studies Program, later moving to the Heller School for Social Policy and Management. In 2011, she also took a counsel position with the Civil Rights & Employment Practice group of the plaintiffs' law firm Cohen Milstein Sellers & Toll.
Over the years, Hill has provided commentary on gender and race issues on national television programs, including "60 Minutes", "Face the Nation" and "Meet the Press". She has been a speaker on the topic of commercial law as well as race and women's rights. She is also the author of articles that have been published in the "New York Times" and "Newsweek". and has contributed to many scholarly and legal publications in the areas of international commercial law, bankruptcy, and civil rights.
In 1995 Hill co-edited "Race, Gender and Power in America: The Legacy of the Hill-Thomas Hearings" with Emma Coleman Jordan. In 1997 Hill published her autobiography, "Speaking Truth to Power", in which she chronicled her role in the Clarence Thomas confirmation controversy and wrote that creating a better society had been a motivating force in her life. She contributed the piece "The Nature of the Beast: Sexual Harassment" to the 2003 anthology "", edited by Robin Morgan. In 2011 Hill published her second book, "Reimagining Equality: Stories of Gender, Race, and Finding Home", which focuses on the sub-prime lending crisis that resulted in the foreclosure of many homes owned by African-Americans. She calls for a new understanding about the importance of a home and its place in the American Dream. On March 26, 2015, the Brandeis Board of Trustees unanimously voted to recognize Hill with a promotion to Private University Professor of Social Policy, Law, and Women's Studies.
In popular culture.
In 1999 Ernest Dickerson directed Strange Justice, a film based on Anita vs. Clarence Thomas controversy. Her case also inspired the 1994 "Law & Order" episode "Virtue", about a young lawyer who feels pressured to sleep with her supervisor at her law firm. Hill was the subject of the 2013 documentary film "Anita" by director Freida Lee Mock, which chronicles her experience during the Clarence Thomas scandal. Hill was portrayed by actress Kerry Washington in the 2016 HBO film "Confirmation".
Awards and recognitions.
In 2005 Hill was selected as a Fletcher Foundation Fellow. In 2008 she was awarded the Louis P. and Evelyn Smith First Amendment Award by the Ford Hall Forum. She also serves on the Board of Trustees for Southern Vermont College in Bennington, Vermont. Her opening statement to the Senate Judiciary Committee in 1991 is listed as #69 in American Rhetoric's Top 100 Speeches of the 20th Century (listed by rank). She was inducted into the Oklahoma Women's Hall of Fame in 1993.

</doc>
<doc id="2315" url="https://en.wikipedia.org/wiki?curid=2315" title="August 10">
August 10

The term 'the 10th of August' is widely used by historians as a shorthand for the Storming of the Tuileries Palace on the 10th of August, 1792, the effective end of the French monarchy until it was restored in 1814.

</doc>
<doc id="2316" url="https://en.wikipedia.org/wiki?curid=2316" title="Audio file format">
Audio file format

An audio file format is a file format for storing digital audio data on a computer system. The bit layout of the audio data (excluding metadata) is called the audio coding format and can be uncompressed, or compressed to reduce the file size, often using lossy compression. The data can be a raw bitstream in an audio coding format, but it is usually embedded in a container format or an audio data format with defined storage layer.
Format types.
It is important to distinguish between the audio coding format, the container containing the raw audio data, and an audio codec. A codec performs the encoding and decoding of the raw audio data while this encoded data is (usually) stored in a container file. Although most audio file formats support only one type of audio coding data (created with an audio coder), a multimedia container format (as Matroska or AVI) may support multiple types of audio and video data.
There are three major groups of audio file formats:
Uncompressed audio format.
One major uncompressed audio format, LPCM, is the same variety of PCM as used in Compact Disc Digital Audio and is the format most commonly accepted by low level audio APIs and D/A converter hardware. Although LPCM can be stored on a computer as a raw audio format, it is usually stored in a codice_4 file on Windows or in a codice_5 file on Mac OS. The AIFF format is based on the Interchange File Format (IFF), and the WAV format is based on the similar Resource Interchange File Format (RIFF). WAV and AIFF are not inherently lossless; they're designed to store a wide variety of audio formats, lossless and lossy; they just add a small, metadata-containing header before the audio data to declare the format of the audio data, such as LPCM with a particular sample rate, bit depth, endianness and number of channels. Since WAV and AIFF are widely supported and can store LPCM, they are suitable file formats for storing and archiving an original recording.
BWF (Broadcast Wave Format) is a standard audio format created by the European Broadcasting Union as a successor to WAV. Among other enhancements, BWF allows more robust metadata to be stored in the file. See "European Broadcasting Union: Specification of the Broadcast Wave Format" (EBU Technical document 3285, July 1997). This is the primary recording format used in many professional audio workstations in the television and film industry. BWF files include a standardized timestamp reference which allows for easy synchronization with a separate picture element. Stand-alone, file based, multi-track recorders from AETA, Sound Devices, Zaxcom, HHB Communications Ltd, Fostex, Nagra, Aaton, and TASCAM all use BWF as their preferred format.
Lossless compressed audio format.
A lossless compressed format stores data in less space without losing any information. The original, uncompressed data can be recreated from the compressed version.
Uncompressed audio formats encode both sound and silence with the same number of bits per unit of time. Encoding an uncompressed minute of absolute silence produces a file of the same size as encoding an uncompressed minute of music. In a lossless compressed format, however, the music would occupy a smaller file than an uncompressed format and the silence would take up almost no space at all.
Lossless compression formats include the common FLAC, WavPack, Monkey's Audio, ALAC (Apple Lossless). They provide a compression ratio of about 2:1 (i.e. their files take up half the space of PCM). Development in lossless compression formats aims to reduce processing time while maintaining a good compression ratio.
Lossy compressed audio format.
Lossy compression enables even greater reductions in file size by removing some of the audio information and simplifying the data. This of course results in a reduction in audio quality, but a variety of techniques are used, mainly by exploiting psychoacoustics, to remove the parts of the sound that have the least effect on perceived quality, and to minimize the amount of audible noise added during the process. The popular MP3 format is probably the best-known example, but the AAC format found on the iTunes Music Store is also common. Most formats offer a range of degrees of compression, generally measured in bit rate. The lower the rate, the smaller the file and the more significant the quality loss.

</doc>
<doc id="2319" url="https://en.wikipedia.org/wiki?curid=2319" title="Antipope Victor IV">
Antipope Victor IV

Two antipopes used the regnal name Victor IV:

</doc>
<doc id="2321" url="https://en.wikipedia.org/wiki?curid=2321" title="Area 51">
Area 51

The United States Air Force facility commonly known as Area 51 is a remote detachment of Edwards Air Force Base, within the Nevada Test and Training Range. According to the Central Intelligence Agency (CIA), the correct names for the facility are Homey Airport and Groom Lake, though the name Area 51 was used in a CIA document from the Vietnam War. Other names used for the facility include "Dreamland", and nicknames "Paradise Ranch", "Home Base" and "Watertown". The special use airspace around the field is referred to as a Restricted Area 4808 North (R-4808N).
The base's current primary purpose is publicly unknown; however, based on historical evidence, it most likely supports development and testing of experimental aircraft and weapons systems (black projects). The intense secrecy surrounding the base has made it the frequent subject of conspiracy theories and a central component to unidentified flying object (UFO) folklore. Although the base has never been declared a secret base, all research and occurrences in Area 51 are Top Secret/Sensitive Compartmented Information (TS/SCI). In July 2013, following an FOIA request filed in 2005, the CIA publicly acknowledged the existence of the base for the first time, declassifying documents detailing the history and purpose of Area 51.
Area 51 is located in the southern portion of Nevada in the western United States, north-northwest of Las Vegas. Situated at its center, on the southern shore of Groom Lake, is a large military airfield. The site was acquired by the United States Air Force in 1955, primarily for the flight testing of the Lockheed U-2 aircraft. The area around Area 51, including the small town of Rachel on the aptly named "Extraterrestrial Highway", is a popular tourist destination.
Geography.
Area 51.
The original rectangular base of is now part of the so-called "Groom box", a rectangular area measuring , of restricted airspace. The area is connected to the internal Nevada Test Site (NTS) road network, with paved roads leading south to Mercury and west to Yucca Flat. Leading northeast from the lake, the wide and well-maintained Groom Lake Road runs through a pass in the Jumbled Hills. The road formerly led to mines in the Groom basin, but has been improved since their closure. Its winding course runs past a security checkpoint, but the restricted area around the base extends further east. After leaving the restricted area, Groom Lake Road descends eastward to the floor of the Tikaboo Valley, passing the dirt-road entrances to several small ranches, before converging with State Route 375, the "Extraterrestrial Highway", south of Rachel.
Area 51 shares a border with the Yucca Flat region of the Nevada Test Site, the location of 739 of the 928 nuclear tests conducted by the United States Department of Energy at NTS. The Yucca Mountain nuclear waste repository is southwest of Groom Lake.
Groom Lake.
Groom Lake is a salt flat in Nevada used for runways of the Nellis Bombing Range Test Site airport (KXTA) on the north of the Area 51 USAF military installation. The lake at elevation is approximately from north to south and from east to west at its widest point. Located within the namesake Groom Lake Valley portion of the Tonopah Basin, the lake is south of Rachel, Nevada.
History.
The origin of the Area 51 name is unclear. The most accepted comes from a grid numbering system of the area by the Atomic Energy Commission (AEC); while Area 51 isn't part of this system, it is adjacent to Area 15. Another explanation is that 51 was used because it was unlikely that the AEC would use the number.
Groom Lake.
Lead and silver were discovered in the southern part of the Groom Range in 1864, and the English "Groome Lead Mines Limited" company financed the Conception Mines in the 1870s, giving the district its name (nearby mines included Maria, Willow and White Lake). The interests in Groom were acquired by J. B. Osborne and partners and patented in 1876, and his son acquired the interests in the 1890s. Claims were incorporated as two 1916 companies with mining continuing until 1918 and resuming after World War II until the early 1950s.
World War II.
The airfield on the Groom Lake site began service in 1942 as Indian Springs Air Force Auxiliary Field, and consisted of two dirt 5000 feet runways aligned NE/SW, NW/SE . The airfield may have been used for bombing and artillery practice; bomb craters are still visible in the vicinity.
U-2 program.
The Groom Lake test facility was established in April 1955 by the Central Intelligence Agency (CIA) for "Project Aquatone", the development of the Lockheed U-2 strategic reconnaissance aircraft.
As part of the project, the director, Richard M. Bissell, Jr., understood that, given the extreme secrecy enveloping the project, the flight test and pilot training programs could not be conducted at Edwards Air Force Base or Lockheed's Palmdale facility. A search for a suitable testing site for the U-2 was conducted under the same extreme security as the rest of the project.
He notified Lockheed, who sent an inspection team out to Groom Lake. According to Lockheed's U-2 designer Kelly Johnson: 
The lakebed made an ideal strip from which they could test aircraft, and the Emigrant Valley's mountain ranges and the NTS perimeter, about 100 miles north of Las Vegas, protected the test site from visitors. The CIA asked the AEC to acquire the land, designated "Area 51" on the map, and add it to the Nevada Test Site.
Johnson named the area "Paradise Ranch" to encourage workers to move to a place that the CIA's official history of the U-2 project would later describe as "the new facility in the middle of nowhere"; the name became shortened to "the Ranch". On 4 May 1955, a survey team arrived at Groom Lake and laid out a , north-south runway on the southwest corner of the lakebed and designated a site for a base support facility. "The Ranch", also known as Site II, initially consisted of little more than a few shelters, workshops and trailer homes in which to house its small team. In a little over three months, the base consisted of a single, paved runway, three hangars, a control tower, and rudimentary accommodations for test personnel. The base's few amenities included a movie theatre and volleyball court. Additionally, there was a mess hall, several water wells, and fuel storage tanks. By July 1955, CIA, Air Force, and Lockheed personnel began arriving. The Ranch received its first U-2 delivery on 24 July 1955 from Burbank on a C-124 Globemaster II cargo plane, accompanied by Lockheed technicians on a Douglas DC-3. Regular Military Air Transport Service flights were set up between Area 51 and Lockheed's Burbank, California offices. To preserve secrecy, personnel flew to Nevada on Monday mornings and returned to California on Friday evenings.
OXCART program.
Project OXCART established in August 1959 for "antiradar studies, aerodynamic structural tests, and engineering designs all later work on the" Lockheed A-12 included testing at Groom Lake, which before improvements for OXCART had inadequate facilities: buildings for only 150 people, a asphalt runway, and limited fuel, hangar, and shop space. Selected for its seclusion and climate, Groom Lake had received a new official name "Area 51" when A-12 test facility construction began in September 1960, including a new runway to replace the existing runway (completed by 15 November 1960 with "expansion joints parallel to the direction of aircraft roll" to limit vibration.)
Four years of "Project 51" construction began on 1 October 1960 by Reynolds Electrical and Engineering Company (REECo) with double-shift construction schedules. The contractor upgraded base facilities and built a new runway (14/32) diagonally across the southwest corner of the lakebed. An Archimedes curve approximately two miles across was marked on the dry lake so that an A-12 pilot approaching the end of the overrun could abort to the playa instead of plunging the aircraft into the sagebrush. Area 51 pilots called it "The Hook". For crosswind landings two unpaved airstrips (runways 9/27 and 03/21) were marked on the dry lakebed.
By August 1961, construction of the essential facilities was completed (3 surplus Navy hangars were erected on the base's north side—hangars 4, 5, and 6.) A fourth, Hangar 7, was new construction. The original U-2 hangars were converted to maintenance and machine shops. Facilities in the main cantonment area included workshops and buildings for storage and administration, a commissary, control tower, fire station, and housing. The Navy also contributed more than 130 surplus Babbitt duplex housing units for long-term occupancy facilities. Older buildings were repaired, and additional facilities were constructed as necessary. A reservoir pond, surrounded by trees, served as a recreational area one mile north of the base. Other recreational facilities included a gymnasium, movie theatre, and a baseball diamond. A permanent aircraft fuel tank farm was constructed by early 1962 for the special JP-7 fuel required by the A-12. Seven tanks were constructed, with a total capacity of 1,320,000 gallons.
For the arrival of OXCART; security was enhanced and the small civilian mine in the Groom basin was closed. In January 1962, the Federal Aviation Administration (FAA) expanded the restricted airspace in the vicinity of Groom Lake. The lakebed became the center of a 600-square-mile addition to restricted area R-4808N.
The CIA facility received eight USAF F-101 Voodoos for training, two T-33 Shooting Star trainers for proficiency flying, a C-130 Hercules for cargo transport, a U-3A for administrative purposes, a helicopter for search and rescue, and a Cessna 180 for liaison use; and Lockheed provided an F-104 Starfighter for use as a chase plane.
The first A-12 test aircraft was covertly trucked from Burbank on 26 February 1962, arrived at Groom Lake on 28 February, was assembled, and made its first flight 26 April 1962 when the base had over 1,000 personnel. Initially, all not connected with a test were herded into the mess hall before each takeoff. This was soon dropped as it disrupted activities and was impractical with the large number of flights. The closed airspace above Groom Lake was within the Nellis Air Force Range airspace, and pilots saw the A-12 20-30 times (at least one signed a secrecy agreement.).
Groom was also the site of the 1st Lockheed D-21 drone test flight on 22 December 1964 (not launched until 5 March 1966). By the end of 1963, nine A-12s were at Area 51, assigned to the CIA operated "1129th Special Activities Squadron".
Although it was decided on 10 January 1967 to phase out the CIA A-12 program, A-12s at Groom Lake occasionally deployed to Kadena AB, Okinawa, for Project Black Shield in 1967 (the 9 A-12s were stored at Palmdale in June 1968 and the 1129th SAS was inactivated.)
D-21 Tagboard.
Following the loss of Gary Powers' U-2 over the Soviet Union, there were several discussions about using the A-12 OXCART as an unpiloted drone aircraft. Although Kelly Johnson had come to support the idea of drone reconnaissance, he opposed the development of an A-12 drone, contending that the aircraft was too large and complex for such a conversion. However, the Air Force agreed to fund the study of a high-speed, high-altitude drone aircraft in October 1962. The Air Force interest seems to have moved the CIA to take action, the project designated "Q-12". By October 1963, the drone's design had been finalized. At the same time, the Q-12 underwent a name change. To separate it from the other A-12-based projects, it was renamed the "D-21". (The "12" was reversed to "21"). "Tagboard" was the project's code name.
The first D-21 was completed in the spring of 1964 by Lockheed. After four more months of checkouts and static tests, the aircraft was shipped to Groom Lake and reassembled. It was to be carried by a two-seat derivative of the A-12, designated the "M-21". When the D-21/M-21 reached the launch point, the first step would be to blow off the D-21's inlet and exhaust covers. With the D-21/M-21 at the correct speed and altitude, the LCO would start the ramjet and the other systems of the D-21. With the D-21's systems activated and running, and the launch aircraft at the correct point, the M-21 would begin a slight pushover, the LCO would push a final button, and the D-21 would come off the pylon".
Difficulties were addressed throughout 1964 and 1965 at Groom Lake with various technical issues. Captive flights showed unforeseen aerodynamic difficulties. By late January 1966, more than a year after the first captive flight, everything seemed ready. The first D-21 launch was made on 5 March 1966 with a successful flight, with the D-21 flying 120 miles with limited fuel. A second D-12 flight was successful in April 1966 with the drone flying 1,200 miles, reaching Mach 3.3 and 90,000 feet. An accident on 30 July 1966 with a fully fueled D-21, on a planned checkout flight suffered from a non-start of the drone after its separation, causing it to collide with the M-21 launch aircraft. The two crewmen ejected and landed in the ocean 150 miles offshore. One crew member was picked up by a helicopter, but the other, having survived the aircraft breakup and ejection, drowned when sea water entered his pressure suit. Kelly Johnson personally cancelled the entire program, having had serious doubts from the start of the feasibility. A number of D-21s had already been produced, and rather than scrapping the whole effort, Johnson again proposed to the Air Force that they be launched from a B-52H bomber.
By late summer of 1967, the modification work to both the D-21 (now designated D-21B) and the B-52Hs were complete. The test program could now resume. The test missions were flown out of Groom Lake, with the actual launches over the Pacific. The first D-21B to be flown was Article 501, the prototype. The first attempt was made on 28 September 1967, and ended in complete failure. As the B-52 was flying toward the launch point, the D-21B fell off the pylon. The B-52H gave a sharp lurch as the drone fell free. The booster fired and was "quite a sight from the ground". The failure was traced to a stripped nut on the forward right attachment point on the pylon. Several more tests were made, none of which met with success. However, the fact is that the resumptions of D-21 tests took place against a changing reconnaissance background. The A-12 had finally been allowed to deploy, and the SR-71 was soon to replace it. At the same time, new developments in reconnaissance satellite technology were nearing operation. Up to this point, the limited number of satellites available restricted coverage to the Soviet Union. A new generation of reconnaissance satellites could soon cover targets anywhere in the world. The satellites' resolution would be comparable to that of aircraft, but without the slightest political risk. Time was running out for the Tagboard.
Several more test flights, including two over China, were made from Beale AFB, California, in 1969 and 1970, to varying degrees of success. On 15 July 1971, Kelly Johnson received a wire canceling the D-21B program. The remaining drones were transferred by a C-5A and placed in dead storage. The tooling used to build the D-21Bs was ordered destroyed. Like the A-12 Oxcart, the D-21B Tagboard drones remained a Black airplane, even in retirement. Their existence was not suspected until August 1976, when the first group was placed in storage at the Davis-Monthan AFB Military Storage and Disposition Center. A second group arrived in 1977. They were labeled "GTD-21Bs" (GT stood for ground training).
Davis-Monthan is an open base, with public tours of the storage area at the time, so the odd-looking drones were soon spotted and photos began appearing in magazines. Speculation about the D-21Bs circulated within aviation circles for years, and it was not until 1982 that details of the Tagboard program were released. However, it was not until 1993 that the B-52/D-21B program was made public. That same year, the surviving D-21Bs were released to museums.
Foreign technology evaluation.
During the Cold War, one of the missions carried out by the United States was the test and evaluation of captured Soviet fighter aircraft. Beginning in the late 1960s, and for several decades, Area 51 played host to an assortment of Soviet-built aircraft. Under the "HAVE DOUGHNUT", "HAVE DRILL" and "HAVE FERRY" programs, the first MiGs flown in the United States were used to evaluate the aircraft in performance, technical, and operational capabilities, pitting the types against U.S. fighters.
This was not a new mission, as testing of foreign technology by the USAF began during World War II. After the war, testing of acquired foreign technology was performed by the Air Technical Intelligence Center (ATIC, which became very influential during the Korean War), under the direct command of the Air Materiel Control Department. In 1961 ATIC became the Foreign Technology Division (FTD), and was reassigned to Air Force Systems Command. ATIC personnel were sent anywhere where foreign aircraft could be found.
The focus of Air Force Systems Command limited the use of the fighter as a tool with which to train the front line tactical fighter pilots. Air Force Systems Command recruited its pilots from the Air Force Flight Test Center at Edwards Air Force Base, California, who were usually graduates from various test pilot schools. Tactical Air Command selected its pilots primarily from the ranks of the Weapons School graduates.
In August 1966, Iraqi Air Force fighter pilot Captain Munir Redfa defected, flying his MiG-21 to Israel after being ordered to attack Iraqi Kurd villages with napalm. His aircraft was transferred to the Groom Lake within a month to study. In 1968 the US Air Force and Navy jointly formed a project known as "Have Doughnut" in which Air Force Systems Command, Tactical Air Command, and the U.S. Navy's Air Test and Evaluation Squadron Four (VX-4) flew this acquired Soviet made aircraft in simulated air combat training. Because U.S. possession of the Soviet MiG-21 was, itself, secret, it was tested at Groom Lake. A joint air force-navy team was assembled for a series of dogfight tests.
Comparisons between the F-4 and the MiG-21 indicated that, on the surface, they were evenly matched. But air combat was not just about technology. In the final analysis, it was the skill of the man in the cockpit. The Have Doughnut tests showed this most strongly. When the Navy or Air Force pilots flew the MiG-21, the results were a draw; the F-4 would win some fights, the MiG-21 would win others. There were no clear advantages. The problem was not with the planes, but with the pilots flying them. The pilots would not fly either plane to its limits. One of the Navy pilots was Marland W. "Doc" Townsend, then commander of VF-121, the F-4 training squadron at NAS Miramar. He was an engineer and a Korean War veteran and had flown almost every navy aircraft. When he flew against the MiG-21, he would outmaneuver it every time. The Air Force pilots would not go vertical in the MiG-21. The Have Doughnut project officer was Tom Cassidy, a pilot with VX-4, the Navy's Air Development Squadron at Point Mugu. He had been watching as Townsend "waxed" the air force MiG-21 pilots. Cassidy climbed into the MiG-21 and went up against Townsend's F-4. This time the result was far different. Cassidy was willing to fight in the vertical, flying the plane to the point where it was buffeting, just above the stall. Cassidy was able to get on the F-4's tail. After the flight, they realized the MiG-21 turned better than the F-4 at lower speeds. The key was for the F-4 to keep its speed up. What had happened in the sky above Groom Lake was remarkable. An F-4 had defeated the MiG-21; the weakness of the Soviet plane had been found. Further test flights confirmed what was learned. It was also clear that the MiG-21 was a formidable enemy. United States pilots would have to fly much better than they had been to beat it. This would require a special school to teach advanced air combat techniques.
On 12 August 1968, two Syrian air force lieutenants, Walid Adham and Radfan Rifai, took off in a pair of MiG-17Fs on a training mission. They lost their way and, believing they were over Lebanon, landed at the Beset Landing Field in northern Israel. (One version has it that they were led astray by an Arabic-speaking Israeli). Prior to the end of 1968 these MiG-17s were transferred from Israeli stocks and added to the Area 51 test fleet. The aircraft were given USAF designations and fake serial numbers so that they could be identified in DOD standard flight logs. As in the earlier program, a small group of Air Force and Navy pilots conducted mock dogfights with the MiG-17s. Selected instructors from the Navy's Top Gun school at NAS Miramar, California, were chosen to fly against the MiGs for familiarization purposes. Very soon, the MiG-17's shortcomings became clear. It had an extremely simple, even crude, control system which lacked the power-boosted controls of American aircraft. The F-4's twin engines were so powerful it could accelerate out of range of the MiG-17's guns in thirty seconds. It was important for the F-4 to keep its distance from the MiG-17. As long as the F-4 was one and a half miles from the MiG-17, it was outside the reach of the Soviet fighter's guns, but the MiG was within reach of the F-4's missiles.
The data from the Have Doughnut and Have Drill tests were provided to the newly formed Top Gun school at NAS Miramar. By 1970, the Have Drill program was expanded; a few selected fleet F-4 crews were given the chance to fight the MiGs. The most important result of Project Have Drill is that no Navy pilot who flew in the project defeated the MiG-17 Fresco in the first engagement. The Have Drill dogfights were by invitation only. The other pilots based at Nellis Air Force Base were not to know about the U.S.-operated MiGs. To prevent any sightings, the airspace above the Groom Lake range was closed. On aeronautical maps, the exercise area was marked in red ink. The forbidden zone became known as "Red Square".
During the remainder of the Vietnam War, the Navy kill ratio climbed to 8.33 to 1. In contrast, the Air Force rate improved only slightly to 2.83 to 1. The reason for this difference was Top Gun. The Navy had revitalized its air combat training, while the Air Force had stayed stagnant. Most of the Navy MiG kills were by Top Gun graduates.
In May 1973, Project "Have Idea" was formed which took over from the older Have Doughnut, Have Ferry and Have Drill projects and the project was transferred to the Tonopah Test Range Airport. At Tonopah testing of foreign technology aircraft continued and expanded throughout the 1970s and 1980s.
Area 51 also hosted another foreign materiel evaluation program called HAVE GLIB. This involved testing Soviet tracking and missile control radar systems. A complex of actual and replica Soviet-type threat systems began to grow around "Slater Lake", a mile northwest of the main base, along with an acquired Soviet "Barlock" search radar placed at Tonopah Air Force Station. They were arranged to simulate a Soviet-style air defense complex.
The Air Force began funding improvements to Area 51 in 1977 under project SCORE EVENT. In 1979, the CIA transferred jurisdiction of the Area 51 site to the Air Force Flight Test Center at Edwards AFB, California. Mr. Sam Mitchell, the last CIA commander of Area 51, relinquished command to USAF Lt. Col. Larry D. McClain.
Have Blue/F-117 program.
The Lockheed Have Blue prototype stealth fighter (a smaller proof-of-concept model of the F-117 Nighthawk) first flew at Groom in December 1977.
In 1978, the Air Force awarded a full-scale development contract for the F-117 to Lockheed Corporation's Advanced Development Projects. On 17 January 1981 the Lockheed test team at Area 51 accepted delivery of the first full Scale Development (FSD) prototype "79–780", designated YF-117A. At 6:05 am on 18 June 1981 Lockheed Skunk Works test pilot Hal Farley lifted the nose of YF-117A "79–780"' off the runway of Area 51.
Meanwhile, Tactical Air Command (TAC) decided to set up a group-level organization to guide the F-117A to an initial operating capability. That organization became the 4450th Tactical Group (Initially designated "A Unit"), which officially activated on 15 October 1979 at Nellis AFB, Nevada, although the group was physically located at Area 51. The 4450th TG also operated the A-7D Corsair II as a surrogate trainer for the F-117A, and these operations continued until 15 October 1982 under the guise of an avionics test mission.
Flying squadrons of the 4450th TG were the 4450th Tactical Squadron (Initially designated "I Unit") activated on 11 June 1981, and 4451st Tactical Squadron (Initially designated "P Unit") on 15 January 1983. The 4450th TS, stationed at Area 51, was the first F-117A squadron, while the 4451st TS was stationed at Nellis AFB and was equipped with A-7D Corsair IIs painted in a dark motif, tail coded "LV". Lockheed test pilots put the YF-117 through its early paces. A-7Ds was used for pilot training before any F-117A's had been delivered by Lockheed to Area 51, later the A-7D's were used for F-117A chase testing and other weapon tests at the Nellis Range.
15 October 1982 is important to the program because on that date Major Alton C. Whitley, Jr. became the first USAF 4450th TG pilot to fly the F-117A.
Although ideal for testing, Area 51 was not a suitable location for an operational group, so a new covert base had to be established for F-117 operations.
Tonopah Test Range Airport was selected for operations of the first USAF F-117 unit, the 4450th Tactical Group (TG). From October 1979, the Tonopah Airport base was reconstructed and expanded. The 6,000 ft runway was lengthened to 10,000 ft. Taxiways, a concrete apron, a large maintenance hangar, and a propane storage tank were added.
By early 1982, four more YF-117A airplanes were operating out of the southern end of the base, known as the "Southend" or "Baja Groom Lake". After finding a large scorpion in their offices, the testing team (Designated "R Unit") adopted it as their mascot and dubbed themselves the "Baja Scorpions". Testing of a series of ultra-secret prototypes continued at Area 51 until mid-1981, when testing transitioned to the initial production of F-117 stealth fighters. The F-117s were moved to and from Area 51 by C-5 under the cloak of darkness, in order to maintain program security. This meant that the aircraft had to be defueled, disassembled, cradled, and then loaded aboard the C-5 at night, flown to Lockheed, and unloaded at night before the real work could begin. Of course, this meant that the reverse actions had to occur at the end of the depot work before the aircraft could be reassembled, flight-tested, and redelivered, again under the cover of darkness. In addition to flight-testing, Groom performed radar profiling, F-117 weapons testing, and was the location for training of the first group of frontline USAF F-117 pilots.
Production FSD airframes from Lockheed were shipped to Area 51 for acceptance testing. As the Baja Scorpions tested the aircraft with functional check flights and L.O. verification, the operational airplanes were then transferred to the 4450th TG.
On 17 May 1982, the move of the 4450th TG from Groom Lake to Tonopah was initiated, with the final components of the move completed in early 1983. Production FSD airframes from Lockheed were shipped to Area 51 for acceptance testing. As the Baja Scorpions tested the aircraft with functional check flights and L.O. verification, the operational airplanes were then transferred to the 4450th TG at Tonopah.
The R-Unit was inactivated on 30 May 1989. Upon inactivation, the unit was reformed as Detachment 1, 57th Fighter Weapons Wing (FWW). In 1990 the last F-117A ("843") was delivered from Lockheed. After completion of acceptance flights at Area 51 of this last new F-117A aircraft, the flight test squadron continued flight test duties of refurbished aircraft after modifications by Lockheed. In February/March 1992 the test unit moved from Area 51 to the USAF Palmdale Plant 42 and was integrated with the Air Force Systems Command 6510th Test Squadron. Some testing, especially RCS verification and other classified activity was still conducted at Area 51 throughout the operational lifetime of the F-117. The recently inactivated (2008) 410th Flight Test Squadron traces its roots, if not its formal lineage to the 4450th TG R-unit.
Later operations.
Since the F-117 became operational in 1983, operations at Groom Lake have continued. The base and its associated runway system were expanded, including expansion of housing and support facilities. In 1995, the federal government expanded the exclusionary area around the base to include nearby mountains that had hitherto afforded the only decent overlook of the base, prohibiting access to of land formerly administered by the Bureau of Land Management. On October 22, 2015 a federal judge signed an order giving land that belonged to a Nevada family since the 1870s to the United States Air Force for expanding Area 51. According to the judge, the land that overlooked the base was taken to address security and safety concerns connected with their training and testing.
Legal status.
U.S. government's positions on Area 51.
The amount of information the United States government has been willing to provide regarding Area 51 has generally been minimal. The area surrounding the lake is permanently off-limits both to civilian and normal military air traffic. Security clearances are checked regularly; cameras and weaponry are not allowed. Even military pilots training in the NAFR risk disciplinary action if they stray into the exclusionary "box" surrounding Groom's airspace. Surveillance is supplemented using buried motion sensors. Area 51 is a common destination for Janet, the "de facto" name of a small fleet of passenger aircraft operated on behalf of the United States Air Force to transport military personnel, primarily from McCarran International Airport.
The USGS topographic map for the area only shows the long-disused Groom Mine. A civil aviation chart published by the Nevada Department of Transportation shows a large restricted area, defined as part of the Nellis restricted airspace. The National Atlas page showing federal lands in Nevada shows the area as lying within the Nellis Air Force Base. Higher resolution (and more recent) images from other satellite imagery providers (including Russian providers and the IKONOS) are commercially available. These show the runway markings, base facilities, aircraft, and vehicles.
When documents that mention the Nevada Test Site (NTS) and operations at Groom are declassified, mentions of Area 51 and Groom Lake are routinely redacted. One exception is a 1967 memo from CIA director Richard Helms regarding the deployment of three OXCART aircraft from Groom to Kadena Air Base to perform reconnaissance over North Vietnam. Although most mentions of OXCART's home base are redacted in this document, as is a map showing the aircraft's route from there to Okinawa, the redactor appears to have missed one mention: page 15 (page 17 in the PDF), section No. 2 ends "Three OXCART aircraft and the necessary task force personnel will be deployed from Area 51 to Kadena."
In July 2013, CIA released an official history of the U-2 and OXCART projects that officially acknowledged the existence of Area 51. The release was in response to a Freedom of Information Act request submitted in 2005 by Jeffrey T. Richelson of George Washington University's National Security Archives, and contain numerous references to Area 51 and Groom Lake, along with a map of the area.
Environmental lawsuit.
In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency. Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom. Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat. The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza. The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials.) They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors. Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told "60 Minutes" reporter Lesley Stahl, "The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit."
Citing the State Secrets Privilege, the government petitioned trial judge U.S. District Judge Philip Pro (of the United States District Court for the District of Nevada in Las Vegas) to disallow disclosure of classified documents or examination of secret witnesses, alleging this would expose classified information and threaten national security. When Judge Pro rejected the government's argument, President Bill Clinton issued a Presidential Determination, exempting what it called, "The Air Force's Operating Location Near Groom Lake, Nevada" from environmental disclosure laws. Consequently, Pro dismissed the suit due to lack of evidence. Turley appealed to the U.S. Court of Appeals for the Ninth Circuit, on the grounds that the government was abusing its power to classify material. Secretary of the Air Force Sheila E. Widnall filed a brief that stated that disclosures of the materials present in the air and water near Groom "can reveal military operational capabilities or the nature and scope of classified operations." The Ninth Circuit rejected Turley's appeal, and the U.S. Supreme Court refused to hear it, putting an end to the complainants' case.
The President continues to annually issue a determination continuing the Groom exception. This, and similarly tacit wording used in other government communications, is the only formal recognition the U.S. Government has ever given that Groom Lake is more than simply another part of the Nellis complex.
An unclassified memo on the safe handling of F-117 Nighthawk material was posted on an Air Force web site in 2005. This discussed the same materials for which the complainants had requested information (information the government had claimed was classified). The memo was removed shortly after journalists became aware of it.
Civil Aviation identification.
In December 2007, airline pilots noticed that the base had appeared in their aircraft navigation systems' latest Jeppesen database revision with the ICAO airport identifier code of KXTA and listed as "Homey Airport". The probably inadvertent release of the airport data led to advice by the Aircraft Owners and Pilots Association (AOPA) that student pilots should be explicitly warned about KXTA, not to consider it as a waypoint or destination for any flight even though it now appears in public navigation databases.
1974 Skylab photography.
In January 2006, space historian Dwayne A. Day published an article in online aerospace magazine "The Space Review" titled "Astronauts and Area 51: the Skylab Incident". The article was based on a memo written in 1974 to CIA director William Colby by an unknown CIA official. The memo reported that astronauts on board Skylab 4 had, as part of a larger program, inadvertently photographed a location of which the memo said:
Although the name of the location was obscured, the context led Day to believe that the subject was Groom Lake. As Day noted:
The memo details debate between federal agencies regarding whether the images should be classified, with Department of Defense agencies arguing that it should, and NASA and the State Department arguing against classification. The memo itself questions the legality of unclassified images to be retroactively classified.
Remarks on the memo, handwritten apparently by DCI (Director of Central Intelligence) Colby himself, read:
The declassified documents do not disclose the outcome of discussions regarding the Skylab imagery. The behind-the-scenes debate proved moot as the photograph appeared in the Federal Government's Archive of Satellite Imagery along with the remaining Skylab 4 photographs, with no record of anyone noticing until Day identified it in 2007.
Other satellite imagery.
Other satellite imagery is also available, including images that show what appears to be F-16 Fighting Falcon aircraft stationed on the base.
UFO and other conspiracy theories.
Its secretive nature and undoubted connection to classified aircraft research, together with reports of unusual phenomena, have led Area 51 to become a focus of modern UFO and conspiracy theories. Some of the activities mentioned in such theories at Area 51 include:
Many of the hypotheses concern underground facilities at Groom or at Papoose Lake (also known as "S-4 location"), south, and include claims of a transcontinental underground railroad system, a disappearing airstrip (nicknamed the "Cheshire Airstrip", after Lewis Carroll's Cheshire cat) which briefly appears when water is sprayed onto its camouflaged asphalt, and engineering based on alien technology. Publicly available satellite imagery, however, reveals clearly visible landing strips at Groom Dry Lake, but not at Papoose Lake.
In the mid-1950s, civilian aircraft flew under 20,000 feet while military aircraft flew under 40,000 feet. Once the U-2 began flying at above 60,000 feet, an unexpected side effect was an increasing number of UFO sighting reports. Sightings occurred most often during early evenings hours, when airline pilots flying west saw the U-2's silver wings reflect the setting sun, giving the aircraft a "fiery" appearance. Many sighting reports came to the Air Force's Project Blue Book, which investigated UFO sightings, through air-traffic controllers and letters to the government. The project checked U-2 and later OXCART flight records to eliminate the majority of UFO reports it received during the late 1950s and 1960s, although it could not reveal to the letter writers the truth behind what they saw. Similarly, veterans of experimental projects such as OXCART and NERVA at Area 51 agree that their work (including 2,850 OXCART test flights alone) inadvertently prompted many of the UFO sightings and other rumors:
They believe that the rumors helped maintain secrecy over Area 51's actual operations. While the veterans deny the existence of a vast underground railroad system, many of Area 51's operations did (and presumably still do) occur underground.
In popular culture.
Novels, films, television programs, and other fictional portrayals of Area 51 describe it—or a fictional counterpart—as a haven for extraterrestrials, time travel, and sinister conspiracies, often linking it with the Roswell UFO incident.

</doc>
<doc id="2322" url="https://en.wikipedia.org/wiki?curid=2322" title="Audio signal processing">
Audio signal processing

Audio signal processing, sometimes referred to as audio processing, is the intentional alteration of auditory signals, or sound, often through an audio effect or effects unit. As audio signals may be electronically represented in either digital or analog format, signal processing may occur in either domain. Analog processors operate directly on the electrical signal, while digital processors operate mathematically on the digital representation of that signal.
History.
Audio signals are sound waves—longitudinal waves which travel through air, consisting of compressions and rarefactions. These audio signals are measured in bels or in decibels. Audio processing was necessary for early radio broadcasting, as there were many problems with studio to transmitter links.
Analog signals.
"Analog" indicates something that is mathematically represented by a set of continuous values; for example, the analog clock uses constantly moving hands on a physical clock face, where moving the hands directly alters the information that clock is providing. Thus, an analog signal is one represented by a continuous stream of data, in this case along an electrical circuit in the form of voltage, current or charge changes "(compare with digital signals below)". Analog signal processing (ASP) then involves physically altering the continuous signal by changing the voltage or current or charge via various electrical means.
Historically, before the advent of widespread digital technology, ASP was the only method by which to manipulate a signal. Since that time, as computers and software became more advanced, digital signal processing has become the method of choice.
Digital signals.
A digital representation expresses the pressure wave-form as a sequence of symbols, usually binary numbers. This permits signal processing using digital circuits such as microprocessors and computers. Although such a conversion can be prone to loss, most modern audio systems use this approach as the techniques of digital signal processing are much more powerful and efficient than analog domain signal processing.
Application areas.
Processing methods and application areas include storage, level compression, data compression, transmission, enhancement (e.g., equalization, filtering, noise cancellation, echo or reverb removal or addition, etc.)
Audio broadcasting.
Traditionally the most important audio processing (in audio broadcasting) takes place just before the transmitter. Studio audio processing is limited in the modern era due to digital audio systems ( mixers, routers) being pervasive in the studio.
In audio broadcasting, the audio processor must
Techniques.
Audio unprocessed by reverb and delay is metaphorically referred to as "dry", while processed audio is referred to as "wet".

</doc>
<doc id="2323" url="https://en.wikipedia.org/wiki?curid=2323" title="Amdahl's law">
Amdahl's law

In computer architecture, Amdahl's law (or Amdahl's argument) gives the theoretical speedup in latency of the execution of a task "at fixed workload" that can be expected of a system whose resources are improved. It is named after computer scientist Gene Amdahl, and was presented at the AFIPS Spring Joint Computer Conference in 1967.
Amdahl's law can be formulated the following way:
where
Furthermore,
show that the theoretical speedup of the execution of the whole task increases with the improvement of the resources of the system and that regardless the magnitude of the improvement, the theoretical speedup is always limited by the part of the task that cannot benefit from the improvement.
Amdahl's law is often used in parallel computing to predict the theoretical speedup when using multiple processors. For example, if a program needs 20 hours using a single processor core, and a particular part of the program which takes one hour to execute cannot be parallelized, while the remaining 19 hours () of execution time can be parallelized, then regardless of how many processors are devoted to a parallelized execution of this program, the minimum execution time cannot be less than that critical one hour. Hence, the theoretical speedup is limited to at most 20 times (). For this reason parallel computing is relevant only for a low number of processors and very parallelizable programs.
Derivation.
A task executed by a system whose resources are improved compared to an initial similar system can be split up into two parts:
"Example." — A computer program that processes files from disk. A part of that program may scan the directory of the disk and create a list of files internally in memory. After that, another part of the program passes each file to a separate thread for processing. The part that scans the directory and creates the file list cannot be sped up on a parallel computer, but the part that processes the files can.
The execution time of the whole task before the improvement of the resources of the system is denoted "T". It includes the execution time of the part that does not benefit from the improvement of the resources and the execution time of the one that benefits from it. The percentage of the execution time of the whole task concerning the part that benefits from the improvement of the resources "before the improvement" is denoted "p". The one concerning the part that does not benefit from it is therefore . Then
It is the execution of the part that benefits from the improvement of the resources that is sped up by the factor "s" after the improvement of the resources. Consequently, the execution time of the part that does not benefit from it remains the same, while that of the part that benefits from it becomes
The theoretical execution time "T"("s") of the whole task after the improvement of the resources is then
Amdahl's law gives the theoretical speedup in latency of the execution of the whole task "at fixed workload W", which yields
Examples.
If 30% of the execution time may be the subject of a speedup, "p" will be 0.3; if the improvement makes the affected part twice faster, "s" will be 2. Amdahl's law states that the overall speedup of applying the improvement will be
We are given a serial task which is split into four consecutive parts, whose percentages of execution time are , , , and respectively. Then we are told that the 1st part is not sped up, so , while the 2nd part is sped up 5 times, so , the 3rd part is sped up 20 times, so , and the 4th part is sped up 1.6 times, so . By using Amdahl's law, the overall speedup is
Notice how the 20 times and 5 times speedup on the 2nd and 3rd parts respectively don't have much effect on the overall speedup when the 4th part (48% of the execution time) is sped up only 1.6 times.
Relation to law of diminishing returns.
Amdahl's law is often conflated with the law of diminishing returns, whereas only a special case of applying Amdahl's law demonstrates law of diminishing returns. If one picks optimally (in terms of the achieved speedup) what to improve, then one will see monotonically decreasing improvements as one improves. If, however, one picks non-optimally, after improving a sub-optimal component and moving on to improve a more optimal component, one can see an increase in return. Note that it is often rational to improve a system in an order that is "non-optimal" in this sense, given that some improvements are more difficult or consuming of development time than others.
Amdahl's law does represent the law of diminishing returns if you are considering what sort of return you get by adding more processors to a machine, if you are running a fixed-size computation that will use all available processors to their capacity. Each new processor you add to the system will add less usable power than the previous one. Each time you double the number of processors the speedup ratio will diminish, as the total throughput heads toward the limit of 1/(1 − "p").
This analysis neglects other potential bottlenecks such as memory bandwidth and I/O bandwidth, if they do not scale with the number of processors; however, taking into account such bottlenecks would tend to further demonstrate the diminishing returns of only adding processors.
Speedup in a serial program.
For example, with a serial program in two parts "A" and "B" for which and ,
Therefore, making part "A" to run 2 times faster is better than making part "B" to run 5 times faster. The percentage improvement in speed can be calculated as
Limitations.
Amdahl's law only applies to cases where the problem size is fixed. In practice, as more computing resources become available, they tend to get used on larger problems (larger datasets), and the time spent in the parallelizable part often grows much faster than the inherently serial work. In this case, Gustafson's law gives a less pessimistic and more realistic assessment of parallel performance.

</doc>
