<doc id="624" url="https://en.wikipedia.org/wiki?curid=624" title="Alaska">
Alaska

Alaska () is a U.S. state situated in the northwest extremity of the Americas. The Canadian administrative divisions of British Columbia and Yukon border the state to the east; it has a maritime border with Russia to the west across the Bering Strait. To the north are the Chukchi and Beaufort Seas, the southern parts of the Arctic Ocean. The Pacific Ocean lies to the south and southwest. Alaska is the largest state in the United States by area, the 3rd least populous and the least densely populated of the 50 United States. Approximately half of Alaska's residents (the total estimated at 738,432 by the Census Bureau in 2015) live within the Anchorage metropolitan area. Alaska's economy is dominated by the fishing, natural gas, and oil industries, resources which it has in abundance. Military bases and tourism are also a significant part of the economy.
The United States purchased Alaska from the Russian Empire on March 30, 1867, for 7.2 million U.S. dollars at approximately two cents per acre ($4.74/km2). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959.
Etymology.
The name "Alaska" (Аляска) was introduced in the Russian colonial period when it was used to refer to the peninsula. It was derived from an Aleut, or Unangam idiom, which figuratively refers to the mainland of Alaska. Literally, it means "object to which the action of the sea is directed". It is also known as "Alyeska," the "great land", an Aleut word derived from the same root.
Geography.
Alaska is the northernmost and westernmost state in the United States and has the most easterly longitude in the United States because the Aleutian Islands extend into the eastern hemisphere. Alaska is the only non-contiguous U.S. state on continental North America; about of British Columbia (Canada) separates Alaska from Washington. It is technically part of the continental U.S., but is sometimes not included in colloquial use; Alaska is not part of the contiguous U.S., often called "the Lower 48". The capital city, Juneau, is situated on the mainland of the North American continent but is not connected by road to the rest of the North American highway system.
The state is bordered by Yukon and British Columbia in Canada, to the east, the Gulf of Alaska and the Pacific Ocean to the south, the Bering Sea, Bering Strait, and Chukchi Sea to the west and the Arctic Ocean to the north. Alaska's territorial waters touch Russia's territorial waters in the Bering Strait, as the Russian Big Diomede Island and Alaskan Little Diomede Island are only apart. Alaska has a longer coastline than all the other U.S. states combined.
Alaska is the largest state in the United States in land area at , over twice the size of Texas, the next largest state. Alaska is larger than all but 18 sovereign countries. Counting territorial waters, Alaska is larger than the combined area of the next three largest states: Texas, California, and Montana. It is also larger than the combined area of the 22 smallest U.S. states.
Regions.
There are no officially defined borders demarcating the various regions of Alaska, but there are six widely accepted regions:
South Central.
The most populous region of Alaska, containing Anchorage, the Matanuska-Susitna Valley and the Kenai Peninsula. Rural, mostly unpopulated areas south of the Alaska Range and west of the Wrangell Mountains also fall within the definition of South Central, as do the Prince William Sound area and the communities of Cordova and Valdez.
Southeast.
Also referred to as the Panhandle or Inside Passage, this is the region of Alaska closest to the rest of the United States. As such, this was where most of the initial non-indigenous settlement occurred in the years following the Alaska Purchase. The region is dominated by the Alexander Archipelago as well as the Tongass National Forest, the largest national forest in the United States. It contains the state capital Juneau, the former capital Sitka, and Ketchikan, at one time Alaska's largest city. The Alaska Marine Highway provides a vital surface transportation link throughout the area, as only three communities (Haines, Hyder and Skagway) enjoy direct connections to the contiguous North American road system.
Interior.
The Interior is the largest region of Alaska; much of it is uninhabited wilderness. Fairbanks is the only large city in the region. Denali National Park and Preserve is located here. "Denali" is the highest mountain in North America.
Southwest.
Southwest Alaska is a sparsely inhabited region stretching some inland from the Bering Sea. Most of the population lives along the coast. Kodiak Island is also located in Southwest. The massive Yukon–Kuskokwim Delta, one of the largest river deltas in the world, is here. Portions of the Alaska Peninsula are considered part of Southwest, with the remaining portions included with the Aleutian Islands (see below).
North Slope.
The North Slope is mostly tundra peppered with small villages. The area is known for its massive reserves of crude oil, and contains both the National Petroleum Reserve–Alaska and the Prudhoe Bay Oil Field. Barrow, the northernmost city in the United States, is located here. The Northwest Arctic area, anchored by Kotzebue and also containing the Kobuk River valley, is often regarded as being part of this region. However, the respective Inupiat of the North Slope and of the Northwest Arctic seldom consider themselves to be one people.
Aleutian Islands.
More than 300 small volcanic islands make up this chain, which stretches over into the Pacific Ocean. Some of these islands fall in the Eastern Hemisphere, but the International Date Line was drawn west of 180° to keep the whole state, and thus the entire North American continent, within the same legal day. Two of the islands, Attu and Kiska, were occupied by Japanese forces during World War II.
Natural features.
With its myriad islands, Alaska has nearly of tidal shoreline. The Aleutian Islands chain extends west from the southern tip of the Alaska Peninsula. Many active volcanoes are found in the Aleutians and in coastal regions. Unimak Island, for example, is home to Mount Shishaldin, which is an occasionally smoldering volcano that rises to above the North Pacific. It is the most perfect volcanic cone on Earth, even more symmetrical than Japan's Mount Fuji. The chain of volcanoes extends to Mount Spurr, west of Anchorage on the mainland. Geologists have identified Alaska as part of Wrangellia, a large region consisting of multiple states and Canadian provinces in the Pacific Northwest, which is actively undergoing continent building.
One of the world's largest tides occurs in Turnagain Arm, just south of Anchorage – tidal differences can be more than .
Alaska has more than three million lakes. Marshlands and wetland permafrost cover (mostly in northern, western and southwest flatlands). Glacier ice covers some of land and of tidal zone. The Bering Glacier complex near the southeastern border with Yukon covers alone. With over 100,000 glaciers, Alaska has half of all in the world.
Land ownership.
According to an October 1998 report by the United States Bureau of Land Management, approximately 65% of Alaska is owned and managed by the U.S. federal government as public lands, including a multitude of national forests, national parks, and national wildlife refuges. Of these, the Bureau of Land Management manages , or 23.8% of the state. The Arctic National Wildlife Refuge is managed by the United States Fish and Wildlife Service. It is the world's largest wildlife refuge, comprising .
Of the remaining land area, the state of Alaska owns , its entitlement under the Alaska Statehood Act. A portion of that acreage is occasionally ceded to organized boroughs, under the statutory provisions pertaining to newly formed boroughs. Smaller portions are set aside for rural subdivisions and other homesteading-related opportunities. These are not very popular due to the often remote and roadless locations. The University of Alaska, as a land grant university, also owns substantial acreage which it manages independently.
Another are owned by 12 regional, and scores of local, Native corporations created under the Alaska Native Claims Settlement Act (ANCSA) of 1971. Regional Native corporation Doyon, Limited often promotes itself as the largest private landowner in Alaska in advertisements and other communications. Provisions of ANCSA allowing the corporations' land holdings to be sold on the open market starting in 1991 were repealed before they could take effect. Effectively, the corporations hold title (including subsurface title in many cases, a privilege denied to individual Alaskans) but cannot sell the land. Individual Native allotments can be and are sold on the open market, however.
Various private interests own the remaining land, totaling about one percent of the state. Alaska is, by a large margin, the state with the smallest percentage of private land ownership when Native corporation holdings are excluded.
Climate.
The climate in Southeast Alaska is a mid-latitude oceanic climate (Köppen climate classification: "Cfb") in the southern sections and a subarctic oceanic climate (Köppen "Cfc") in the northern parts. On an annual basis, Southeast is both the wettest and warmest part of Alaska with milder temperatures in the winter and high precipitation throughout the year. Juneau averages over of precipitation a year, and Ketchikan averages over . This is also the only region in Alaska in which the average daytime high temperature is above freezing during the winter months.
The climate of Anchorage and south central Alaska is mild by Alaskan standards due to the region's proximity to the seacoast. While the area gets less rain than southeast Alaska, it gets more snow, and days tend to be clearer. On average, Anchorage receives of precipitation a year, with around of snow, although there are areas in the south central which receive far more snow. It is a subarctic climate () due to its brief, cool summers.
The climate of Western Alaska is determined in large part by the Bering Sea and the Gulf of Alaska. It is a subarctic oceanic climate in the southwest and a continental subarctic climate farther north. The temperature is somewhat moderate considering how far north the area is. This region has a tremendous amount of variety in precipitation. An area stretching from the northern side of the Seward Peninsula to the Kobuk River valley (i. e., the region around Kotzebue Sound) is technically a desert, with portions receiving less than of precipitation annually. On the other extreme, some locations between Dillingham and Bethel average around of precipitation.
The climate of the interior of Alaska is subarctic. Some of the highest and lowest temperatures in Alaska occur around the area near Fairbanks. The summers may have temperatures reaching into the 90s °F (the low-to-mid 30s °C), while in the winter, the temperature can fall below . Precipitation is sparse in the Interior, often less than a year, but what precipitation falls in the winter tends to stay the entire winter.
The highest and lowest recorded temperatures in Alaska are both in the Interior. The highest is in Fort Yukon (which is just inside the arctic circle) on June 27, 1915, making Alaska tied with Hawaii as the state with the lowest high temperature in the United States. The lowest official Alaska temperature is in Prospect Creek on January 23, 1971, one degree above the lowest temperature recorded in continental North America (in Snag, Yukon, Canada).
The climate in the extreme north of Alaska is Arctic () with long, very cold winters and short, cool summers. Even in July, the average low temperature in Barrow is . Precipitation is light in this part of Alaska, with many places averaging less than per year, mostly as snow which stays on the ground almost the entire year.
History.
Alaska Natives.
Numerous indigenous peoples occupied Alaska for thousands of years before the arrival of European peoples to the area. Linguistic and DNA studies done here have provided evidence for the settlement of North America by way of the Bering land bridge. The Tlingit people developed a society with a matrilineal kinship system of property inheritance and descent in what is today Southeast Alaska, along with parts of British Columbia and the Yukon. Also in Southeast were the Haida, now well known for their unique arts. The Tsimshian people came to Alaska from British Columbia in 1887, when President Grover Cleveland, and later the U.S. Congress, granted them permission to settle on Annette Island and found the town of Metlakatla. All three of these peoples, as well as other indigenous peoples of the Pacific Northwest Coast, experienced smallpox outbreaks from the late 18th through the mid-19th century, with the most devastating epidemics occurring in the 1830s and 1860s, resulting in high fatalities and social disruption.
The Aleutian Islands are still home to the Aleut people's seafaring society, although they were the first Native Alaskans to be exploited by Russians. Western and Southwestern Alaska are home to the Yup'ik, while their cousins the Alutiiq ~ Sugpiaq lived in what is now Southcentral Alaska. The Gwich'in people of the northern Interior region are Athabaskan and primarily known today for their dependence on the caribou within the much-contested Arctic National Wildlife Refuge. The North Slope and Little Diomede Island are occupied by the widespread Inupiat people.
Colonization.
Some researchers believe that the first Russian settlement in Alaska was established in the 17th century. According to this hypothesis, in 1648 several koches of Semyon Dezhnyov's expedition came ashore in Alaska by storm and founded this settlement. This hypothesis is based on the testimony of Chukchi geographer Nikolai Daurkin, who had visited Alaska in 1764–1765 and who had reported on a village on the Kheuveren River, populated by "bearded men" who "pray to the icons". Some modern researchers associate Kheuveren with Koyuk River.
The first European vessel to reach Alaska is generally held to be the "St. Gabriel" under the authority of the surveyor M. S. Gvozdev and assistant navigator I. Fyodorov on August 21, 1732 during an expedition of Siberian cossak A. F. Shestakov and Belorussian explorer Dmitry Pavlutsky (1729—1735).
Another European contact with Alaska occurred in 1741, when Vitus Bering led an expedition for the Russian Navy aboard the "St. Peter". After his crew returned to Russia with sea otter pelts judged to be the finest fur in the world, small associations of fur traders began to sail from the shores of Siberia toward the Aleutian Islands. The first permanent European settlement was founded in 1784.
Between 1774 and 1800, Spain sent several expeditions to Alaska in order to assert its claim over the Pacific Northwest. In 1789 a Spanish settlement and fort were built in Nootka Sound. These expeditions gave names to places such as Valdez, Bucareli Sound, and Cordova. Later, the Russian-American Company carried out an expanded colonization program during the early-to-mid-19th century.
Sitka, renamed New Archangel from 1804 to 1867, on Baranof Island in the Alexander Archipelago in what is now Southeast Alaska, became the capital of Russian America. It remained the capital after the colony was transferred to the United States. The Russians never fully colonized Alaska, and the colony was never very profitable. Evidence of Russian settlement in names and churches survive throughout southeast Alaska.
William H. Seward, the United States Secretary of State, negotiated the Alaska Purchase (also known as Seward's Folly) with the Russians in 1867 for $7.2 million. Alaska was loosely governed by the military initially, and was administered as a district starting in 1884, with a governor appointed by the President of the United States. A federal district court was headquartered in Sitka.
For most of Alaska's first decade under the United States flag, Sitka was the only community inhabited by American settlers. They organized a "provisional city government," which was Alaska's first municipal government, but not in a legal sense. Legislation allowing Alaskan communities to legally incorporate as cities did not come about until 1900, and home rule for cities was extremely limited or unavailable until statehood took effect in 1959.
U.S. Territory.
Starting in the 1890s and stretching in some places to the early 1910s, gold rushes in Alaska and the nearby Yukon Territory brought thousands of miners and settlers to Alaska. Alaska was officially incorporated as an organized territory in 1912. Alaska's capital, which had been in Sitka until 1906, was moved north to Juneau. Construction of the Alaska Governor's Mansion began that same year. European immigrants from Norway and Sweden also settled in southeast Alaska, where they entered the fishing and logging industries.
During World War II, the Aleutian Islands Campaign focused on the three outer Aleutian Islands – Attu, Agattu and Kiska – that were invaded by Japanese troops and occupied between June 1942 and August 1943. Unalaska/Dutch Harbor became a significant base for the U.S. Army Air Forces and Navy submariners.
The U.S. Lend-Lease program involved the flying of American warplanes through Canada to Fairbanks and thence Nome; Soviet pilots took possession of these aircraft, ferrying them to fight the German invasion of the Soviet Union. The construction of military bases contributed to the population growth of some Alaskan cities.
Statehood.
Statehood for Alaska was an important cause of James Wickersham early in his tenure as a congressional delegate. Decades later, the statehood movement gained its first real momentum following a territorial referendum in 1946. The Alaska Statehood Committee and Alaska's Constitutional Convention would soon follow. Statehood supporters also found themselves fighting major battles against political foes, mostly in the U.S. Congress but also within Alaska. Statehood was approved by Congress on July 7, 1958. Alaska was officially proclaimed a state on January 3, 1959.
In 1960, the Census Bureau reported Alaska's population as 77.2% White, 3% Black, and 18.8% American Indian and Alaska Native.
On March 27, 1964, the massive Good Friday earthquake killed 133 people and destroyed several villages and portions of large coastal communities, mainly by the resultant tsunamis and landslides. It was the second-most-powerful earthquake in the recorded history of the world, with a moment magnitude of 9.2. It was over one thousand times more powerful than the 1989 San Francisco earthquake. The time of day (5:36 pm), time of year and location of the epicenter were all cited as factors in potentially sparing thousands of lives, particularly in Anchorage.
The 1968 discovery of oil at Prudhoe Bay and the 1977 completion of the Trans-Alaska Pipeline System led to an oil boom. Royalty revenues from oil have funded large state budgets from 1980 onward. That same year, not coincidentally, Alaska repealed its state income tax.
In 1989, the "Exxon Valdez" hit a reef in the Prince William Sound, spilling over of crude oil over of coastline. Today, the battle between philosophies of development and conservation is seen in the contentious debate over oil drilling in the Arctic National Wildlife Refuge and the proposed Pebble Mine.
Alaska Heritage Resources Survey.
The Alaska Heritage Resources Survey (AHRS) is a restricted inventory of all reported historic and prehistoric sites within the state of Alaska; it is maintained by the Office of History and Archaeology. The survey's inventory of cultural resources includes objects, structures, buildings, sites, districts, and travel ways, with a general provision that they are over 50 years old. As of January 31, 2012, over 35,000 sites have been reported.
Demographics.
The United States Census Bureau estimates that the population of Alaska was 738,432 on July 1, 2015, a 3.97% increase since the 2010 United States Census.
In 2010, Alaska ranked as the 47th state by population, ahead of North Dakota, Vermont, and Wyoming (and Washington, D.C.) Alaska is the least densely populated state, and one of the most sparsely populated areas in the world, at , with the next state, Wyoming, at . Alaska is the largest U.S. state by area, and the tenth wealthiest (per capita income). As of November 2014, the state's unemployment rate was 6.6%.
Race and ancestry.
According to the 2010 United States Census, Alaska had a population of 710,231. In terms of race and ethnicity, the state was 66.7% White (64.1% Non-Hispanic White), 14.8% American Indian and Alaska Native, 5.4% Asian, 3.3% Black or African American, 1.0% Native Hawaiian and Other Pacific Islander, 1.6% from Some Other Race, and 7.3% from Two or More Races. Hispanics or Latinos of any race made up 5.5% of the population.
, 50.7% of Alaska's population younger than one year of age belonged to minority groups (i.e., did not have two parents of non-Hispanic white ancestry).
Languages.
According to the 2011 American Community Survey, 82.4% of people over the age of five speak only English at home. About 3.5% speak Spanish at home. About 2.2% speak another Indo-European language at home and about 4.3% speak an Asian language at home. About 5.3% speak other languages at home.
The Alaska Native Language Center at the University of Alaska Fairbanks claims that at least 20 Alaskan native languages exist and there are also some languages with different dialects. Most of Alaska's native languages belong to either the Eskimo–Aleut or Na-Dene language families however some languages are thought to be isolates (e.g. Haida) or have not yet been classified (e.g. Tsimshianic).
A total of 5.2% of Alaskans speak one of the state's 20 indigenous languages, known locally as "native languages".
In October 2014, the governor of Alaska signed a bill declaring the state's 20 indigenous languages as official languages. The 20 languages that included in the bill are:
Religion.
According to statistics collected by the Association of Religion Data Archives from 2010, about 34% of Alaska residents were members of religious congregations. 100,960 people identified as Evangelical Protestants, 50,866 as Roman Catholic, and 32,550 as mainline Protestants. Roughly 4% are Mormon, 0.5% are Jewish, 1% are Muslim, 0.5% are Buddhist, and 0.5% are Hindu. The largest religious denominations in Alaska were the Catholic Church with 50,866 adherents, non-denominational Evangelical Protestants with 38,070 adherents, The Church of Jesus Christ of Latter-day Saints with 32,170 adherents, and the Southern Baptist Convention with 19,891 adherents. Alaska has been identified, along with Pacific Northwest states Washington and Oregon, as being the least religious states of the USA, in terms of church membership.
In 1795, the First Russian Orthodox Church was established in Kodiak. Intermarriage with Alaskan Natives helped the Russian immigrants integrate into society. As a result, an increasing number of Russian Orthodox churches gradually became established within Alaska. Alaska also has the largest Quaker population (by percentage) of any state. In 2009 there were 6,000 Jews in Alaska (for whom observance of halakha may pose special problems). Alaskan Hindus often share venues and celebrations with members of other Asian religious communities, including Sikhs and Jains.
Estimates for the number of Muslims in Alaska range from 2,000 to 5,000. The Islamic Community Center of Anchorage began efforts in the late 1990s to construct a mosque in Anchorage. They broke ground on a building in south Anchorage in 2010 and were nearing completion in late 2014. When completed, the mosque will be the first in the state and one of the northernmost mosques in the world.
Economy.
The 2007 gross state product was $44.9 billion, 45th in the nation. Its per capita personal income for 2007 was $40,042, ranking 15th in the nation. According to a 2013 study by Phoenix Marketing International, Alaska had the fifth-largest number of millionaires per capita in the United States, with a ratio of 6.75 percent. The oil and gas industry dominates the Alaskan economy, with more than 80% of the state's revenues derived from petroleum extraction. Alaska's main export product (excluding oil and natural gas) is seafood, primarily salmon, cod, Pollock and crab.
Agriculture represents a very small fraction of the Alaskan economy. Agricultural production is primarily for consumption within the state and includes nursery stock, dairy products, vegetables, and livestock. Manufacturing is limited, with most foodstuffs and general goods imported from elsewhere.
Employment is primarily in government and industries such as natural resource extraction, shipping, and transportation. Military bases are a significant component of the economy in the Fairbanks North Star, Anchorage and Kodiak Island boroughs, as well as Kodiak. Federal subsidies are also an important part of the economy, allowing the state to keep taxes low. Its industrial outputs are crude petroleum, natural gas, coal, gold, precious metals, zinc and other mining, seafood processing, timber and wood products. There is also a growing service and tourism sector. Tourists have contributed to the economy by supporting local lodging.
Energy.
Alaska has vast energy resources, although its oil reserves have been largely depleted. Major oil and gas reserves were found in the Alaska North Slope (ANS) and Cook Inlet basins, but according to the Energy Information Administration, by February 2014 Alaska had fallen to fourth place in the nation in crude oil production after Texas, North Dakota, and California. Prudhoe Bay on Alaska's North Slope is still the second highest-yielding oil field in the United States, typically producing about , although by early 2014 North Dakota's Bakken Formation was producing over . Prudhoe Bay was the largest conventional oil field ever discovered in North America, but was much smaller than Canada's enormous Athabasca oil sands field, which by 2014 was producing about of unconventional oil, and had hundreds of years of producible reserves at that rate.
The Trans-Alaska Pipeline can transport and pump up to of crude oil per day, more than any other crude oil pipeline in the United States. Additionally, substantial coal deposits are found in Alaska's bituminous, sub-bituminous, and lignite coal basins. The United States Geological Survey estimates that there are of undiscovered, technically recoverable gas from natural gas hydrates on the Alaskan North Slope. Alaska also offers some of the highest hydroelectric power potential in the country from its numerous rivers. Large swaths of the Alaskan coastline offer wind and geothermal energy potential as well.
Alaska's economy depends heavily on increasingly expensive diesel fuel for heating, transportation, electric power and light. Though wind and hydroelectric power are abundant and underdeveloped, proposals for statewide energy systems (e.g. with special low-cost electric interties) were judged uneconomical (at the time of the report, 2001) due to low (less than 50¢/gal) fuel prices, long distances and low population. The cost of a gallon of gas in urban Alaska today is usually 30–60¢ higher than the national average; prices in rural areas are generally significantly higher but vary widely depending on transportation costs, seasonal usage peaks, nearby petroleum development infrastructure and many other factors.
Permanent Fund.
The Alaska Permanent Fund is a constitutionally authorized appropriation of oil revenues, established by voters in 1976 to manage a surplus in state petroleum revenues from oil, largely in anticipation of the then recently constructed Trans-Alaska Pipeline System. The fund was originally proposed by Governor Keith Miller on the eve of the 1969 Prudhoe Bay lease sale, out of fear that the legislature would spend the entire proceeds of the sale (which amounted to $900 million) at once. It was later championed by Governor Jay Hammond and Kenai state representative Hugh Malone. It has served as an attractive political prospect ever since, diverting revenues which would normally be deposited into the general fund.
The Alaska Constitution was written so as to discourage dedicating state funds for a particular purpose. The Permanent Fund has become the rare exception to this, mostly due to the political climate of distrust existing during the time of its creation. From its initial principal of $734,000, the fund has grown to $50 billion as a result of oil royalties and capital investment programs. Most if not all the principal is invested conservatively outside Alaska. This has led to frequent calls by Alaskan politicians for the Fund to make investments within Alaska, though such a stance has never gained momentum.
Starting in 1982, dividends from the fund's annual growth have been paid out each year to eligible Alaskans, ranging from an initial $1,000 in 1982 (equal to three years' payout, as the distribution of payments was held up in a lawsuit over the distribution scheme) to $3,269 in 2008 (which included a one-time $1,200 "Resource Rebate"). Every year, the state legislature takes out 8% from the earnings, puts 3% back into the principal for inflation proofing, and the remaining 5% is distributed to all qualifying Alaskans. To qualify for the Permanent Fund Dividend, one must have lived in the state for a minimum of 12 months, maintain constant residency subject to allowable absences, and not be subject to court judgments or criminal convictions which fall under various disqualifying classifications or may subject the payment amount to civil garnishment.
The Permanent Fund is often considered to be one of the leading examples of a "Basic Income" policy in the world.
Cost of living.
The cost of goods in Alaska has long been higher than in the contiguous 48 states. Federal government employees, particularly United States Postal Service (USPS) workers and active-duty military members, receive a Cost of Living Allowance usually set at 25% of base pay because, while the cost of living has gone down, it is still one of the highest in the country.
Rural Alaska suffers from extremely high prices for food and consumer goods compared to the rest of the country, due to the relatively limited transportation infrastructure.
Agriculture and fishing.
Due to the northern climate and short growing season, relatively little farming occurs in Alaska. Most farms are in either the Matanuska Valley, about northeast of Anchorage, or on the Kenai Peninsula, about southwest of Anchorage. The short 100-day growing season limits the crops that can be grown, but the long sunny summer days make for productive growing seasons. The primary crops are potatoes, carrots, lettuce, and cabbage.
The Tanana Valley is another notable agricultural locus, especially the Delta Junction area, about southeast of Fairbanks, with a sizable concentration of farms growing agronomic crops; these farms mostly lie north and east of Fort Greely. This area was largely set aside and developed under a state program spearheaded by Hammond during his second term as governor. Delta-area crops consist predominately of barley and hay. West of Fairbanks lies another concentration of small farms catering to restaurants, the hotel and tourist industry, and community-supported agriculture.
Alaskan agriculture has experienced a surge in growth of market gardeners, small farms and farmers' markets in recent years, with the highest percentage increase (46%) in the nation in growth in farmers' markets in 2011, compared to 17% nationwide. The peony industry has also taken off, as the growing season allows farmers to harvest during a gap in supply elsewhere in the world, thereby filling a niche in the flower market.
Alaska, with no counties, lacks county fairs. However, a small assortment of state and local fairs (with the Alaska State Fair in Palmer the largest), are held mostly in the late summer. The fairs are mostly located in communities with historic or current agricultural activity, and feature local farmers exhibiting produce in addition to more high-profile commercial activities such as carnival rides, concerts and food. "Alaska Grown" is used as an agricultural slogan.
Alaska has an abundance of seafood, with the primary fisheries in the Bering Sea and the North Pacific. Seafood is one of the few food items that is often cheaper within the state than outside it. Many Alaskans take advantage of salmon seasons to harvest portions of their household diet while fishing for subsistence, as well as sport. This includes fish taken by hook, net or wheel.
Hunting for subsistence, primarily caribou, moose, and Dall sheep is still common in the state, particularly in remote Bush communities. An example of a traditional native food is Akutaq, the Eskimo ice cream, which can consist of reindeer fat, seal oil, dried fish meat and local berries.
Alaska's reindeer herding is concentrated on Seward Peninsula, where wild caribou can be prevented from mingling and migrating with the domesticated reindeer.
Most food in Alaska is transported into the state from "Outside", and shipping costs make food in the cities relatively expensive. In rural areas, subsistence hunting and gathering is an essential activity because imported food is prohibitively expensive. Though most small towns and villages in Alaska lie along the coastline, the cost of importing food to remote villages can be high, because of the terrain and difficult road conditions, which change dramatically, due to varying climate and precipitation changes. The cost of transport can reach as high as 50¢ per pound ($1.10/kg) or more in some remote areas, during the most difficult times, if these locations can be reached at all during such inclement weather and terrain conditions. The cost of delivering a of milk is about $3.50 in many villages where per capita income can be $20,000 or less. Fuel cost per gallon is routinely 20–30¢ higher than the continental United States average, with only Hawaii having higher prices.
Transportation.
Roads.
Alaska has few road connections compared to the rest of the U.S. The state's road system covers a relatively small area of the state, linking the central population centers and the Alaska Highway, the principal route out of the state through Canada. The state capital, Juneau, is not accessible by road, only a car ferry, which has spurred several debates over the decades about moving the capital to a city on the road system, or building a road connection from Haines. The western part of Alaska has no road system connecting the communities with the rest of Alaska.
One unique feature of the Alaska Highway system is the Anton Anderson Memorial Tunnel, an active Alaska Railroad tunnel recently upgraded to provide a paved roadway link with the isolated community of Whittier on Prince William Sound to the Seward Highway about southeast of Anchorage at Portage. At , the tunnel was the longest road tunnel in North America until 2007. The tunnel is the longest combination road and rail tunnel in North America.
Rail.
Built around 1915, the Alaska Railroad (ARR) played a key role in the development of Alaska through the 20th century. It links north Pacific shipping through providing critical infrastructure with tracks that run from Seward to Interior Alaska by way of South Central Alaska, passing through Anchorage, Eklutna, Wasilla, Talkeetna, Denali, and Fairbanks, with spurs to Whittier, Palmer and North Pole. The cities, towns, villages, and region served by ARR tracks are known statewide as "The Railbelt". In recent years, the ever-improving paved highway system began to eclipse the railroad's importance in Alaska's economy.
The railroad played a vital role in Alaska's development, moving freight into Alaska while transporting natural resources southward (i.e., coal from the Usibelli coal mine near Healy to Seward and gravel from the Matanuska Valley to Anchorage). It is well known for its summertime tour passenger service.
The Alaska Railroad was one of the last railroads in North America to use cabooses in regular service and still uses them on some gravel trains. It continues to offer one of the last flag stop routes in the country. A stretch of about of track along an area north of Talkeetna remains inaccessible by road; the railroad provides the only transportation to rural homes and cabins in the area. Until construction of the Parks Highway in the 1970s, the railroad provided the only land access to most of the region along its entire route.
In northern Southeast Alaska, the White Pass and Yukon Route also partly runs through the state from Skagway northwards into Canada (British Columbia and Yukon Territory), crossing the border at White Pass Summit. This line is now mainly used by tourists, often arriving by cruise liner at Skagway. It was featured in the 1983 BBC television series "Great Little Railways."
The Alaska Rail network is not connected to Outside. In 2000, the U.S. Congress authorized $6 million to study the feasibility of a rail link between Alaska, Canada, and the lower 48.
Alaska Rail Marine provides car float service between Whittier and Seattle.
Marine transport.
Many cities, towns and villages in the state do not have road or highway access; the only modes of access involve travel by air, river, or the sea.
Alaska's well-developed state-owned ferry system (known as the Alaska Marine Highway) serves the cities of southeast, the Gulf Coast and the Alaska Peninsula. The ferries transport vehicles as well as passengers. The system also operates a ferry service from Bellingham, Washington and Prince Rupert, British Columbia in Canada through the Inside Passage to Skagway. The Inter-Island Ferry Authority also serves as an important marine link for many communities in the Prince of Wales Island region of Southeast and works in concert with the Alaska Marine Highway.
In recent years, cruise lines have created a summertime tourism market, mainly connecting the Pacific Northwest to Southeast Alaska and, to a lesser degree, towns along Alaska's gulf coast. The population of Ketchikan may rise by over 10,000 people on many days during the summer, as up to four large cruise ships at a time can dock, debarking thousands of passengers.
Air transport.
Cities not served by road, sea, or river can be reached only by air, foot, dogsled, or snowmachine, accounting for Alaska's extremely well developed bush air services—an Alaskan novelty. Anchorage and, to a lesser extent Fairbanks, is served by many major airlines. Because of limited highway access, air travel remains the most efficient form of transportation in and out of the state. Anchorage recently completed extensive remodeling and construction at Ted Stevens Anchorage International Airport to help accommodate the upsurge in tourism (in 2012-2013, Alaska received almost 2 million visitors).
Regular flights to most villages and towns within the state that are commercially viable are challenging to provide, so they are heavily subsidized by the federal government through the Essential Air Service program. Alaska Airlines is the only major airline offering in-state travel with jet service (sometimes in combination cargo and passenger Boeing 737-400s) from Anchorage and Fairbanks to regional hubs like Bethel, Nome, Kotzebue, Dillingham, Kodiak, and other larger communities as well as to major Southeast and Alaska Peninsula communities.
The bulk of remaining commercial flight offerings come from small regional commuter airlines such as Ravn Alaska, PenAir, and Frontier Flying Service. The smallest towns and villages must rely on scheduled or chartered bush flying services using general aviation aircraft such as the Cessna Caravan, the most popular aircraft in use in the state. Much of this service can be attributed to the Alaska bypass mail program which subsidizes bulk mail delivery to Alaskan rural communities. The program requires 70% of that subsidy to go to carriers who offer passenger service to the communities.
Many communities have small air taxi services. These operations originated from the demand for customized transport to remote areas. Perhaps the most quintessentially Alaskan plane is the bush seaplane. The world's busiest seaplane base is Lake Hood, located next to Ted Stevens Anchorage International Airport, where flights bound for remote villages without an airstrip carry passengers, cargo, and many items from stores and warehouse clubs. In 2006 Alaska had the highest number of pilots per capita of any U.S. state.
Other transport.
Another Alaskan transportation method is the dogsled. In modern times (that is, any time after the mid-late 1920s), dog mushing is more of a sport than a true means of transportation. Various races are held around the state, but the best known is the Iditarod Trail Sled Dog Race, a trail from Anchorage to Nome (although the distance varies from year to year, the official distance is set at ). The race commemorates the famous 1925 serum run to Nome in which mushers and dogs like Togo and Balto took much-needed medicine to the diphtheria-stricken community of Nome when all other means of transportation had failed. Mushers from all over the world come to Anchorage each March to compete for cash, prizes, and prestige. The "Serum Run" is another sled dog race that more accurately follows the route of the famous 1925 relay, leaving from the community of Nenana (southwest of Fairbanks) to Nome.
In areas not served by road or rail, primary transportation in summer is by all-terrain vehicle and in winter by snowmobile or "snow machine," as it is commonly referred to in Alaska.
Data transport.
Alaska's internet and other data transport systems are provided largely through the two major telecommunications companies: GCI and Alaska Communications. GCI owns and operates what it calls the Alaska United Fiber Optic system and as of late 2011 Alaska Communications advertised that it has "two fiber optic paths to the lower 48 and two more across Alaska. In January 2011, it was reported that a $1 billion project to run connect Asia and rural Alaska was being planned, aided in part by $350 million in stimulus from the federal government.
Law and government.
State government.
Like all other U.S. states, Alaska is governed as a republic, with three branches of government: an executive branch consisting of the Governor of Alaska and the other independently elected constitutional officers; a legislative branch consisting of the Alaska House of Representatives and Alaska Senate; and a judicial branch consisting of the Alaska Supreme Court and lower courts.
The state of Alaska employs approximately 16,000 people statewide.
The Alaska Legislature consists of a 40-member House of Representatives and a 20-member Senate. Senators serve four-year terms and House members two. The Governor of Alaska serves four-year terms. The lieutenant governor runs separately from the governor in the primaries, but during the general election, the nominee for governor and nominee for lieutenant governor run together on the same ticket.
Alaska's court system has four levels: the Alaska Supreme Court, the Alaska Court of Appeals, the superior courts and the district courts. The superior and district courts are trial courts. Superior courts are courts of general jurisdiction, while district courts only hear certain types of cases, including misdemeanor criminal cases and civil cases valued up to $100,000.
The Supreme Court and the Court of Appeals are appellate courts. The Court of Appeals is required to hear appeals from certain lower-court decisions, including those regarding criminal prosecutions, juvenile delinquency, and habeas corpus. The Supreme Court hears civil appeals and may in its discretion hear criminal appeals.
State politics.
Although in its early years of statehood Alaska was a Democratic state, since the early 1970s it has been characterized as Republican-leaning. Local political communities have often worked on issues related to land use development, fishing, tourism, and individual rights. Alaska Natives, while organized in and around their communities, have been active within the Native corporations. These have been given ownership over large tracts of land, which require stewardship.
Alaska was formerly the only state in which possession of one ounce or less of marijuana in one's home was completely legal under state law, though the federal law remains in force.
The state has an independence movement favoring a vote on secession from the United States, with the Alaskan Independence Party.
Six Republicans and four Democrats have served as governor of Alaska. In addition, Republican Governor Wally Hickel was elected to the office for a second term in 1990 after leaving the Republican party and briefly joining the Alaskan Independence Party ticket just long enough to be reelected. He subsequently officially rejoined the Republican party in 1994.
Alaska's voter initiative making marijuana legal takes effect 24 February 2015, placing Alaska alongside Colorado and Washington as the three U.S. states where recreational marijuana is legal. The new law means people over age 21 can consume small amounts of pot — if they can find it. Commercial sales await implementation of Alaska Measure 2 (2014).
Taxes.
To finance state government operations, Alaska depends primarily on petroleum revenues and federal subsidies. This allows it to have the lowest individual tax burden in the United States. It is one of five states with no state sales tax, one of seven states that do not levy an individual income tax, and one of the two states that has neither. The Department of Revenue Tax Division reports regularly on the state's revenue sources. The Department also issues an annual summary of its operations, including new state laws that directly affect the tax division.
While Alaska has no state sales tax, 89 municipalities collect a local sales tax, from 1.0–7.5%, typically 3–5%. Other local taxes levied include raw fish taxes, hotel, motel, and bed-and-breakfast 'bed' taxes, severance taxes, liquor and tobacco taxes, gaming (pull tabs) taxes, tire taxes and fuel transfer taxes. A part of the revenue collected from certain state taxes and license fees (such as petroleum, aviation motor fuel, telephone cooperative) is shared with municipalities in Alaska.
Fairbanks has one of the highest property taxes in the state as no sales or income taxes are assessed in the Fairbanks North Star Borough (FNSB). A sales tax for the FNSB has been voted on many times, but has yet to be approved, leading law makers to increase taxes dramatically on goods such as liquor and tobacco.
In 2014 the Tax Foundation ranked Alaska as having the fourth most "business friendly" tax policy, behind only Wyoming, South Dakota, and Nevada.
Federal politics.
Alaska regularly supports Republicans in presidential elections and has done so since statehood. Republicans have won the state's electoral college votes in all but one election that it has participated in (1964). No state has voted for a Democratic presidential candidate fewer times. Alaska was carried by Democratic nominee Lyndon B. Johnson during his landslide election in 1964, while the 1960 and 1968 elections were close. Since 1972, however, Republicans have carried the state by large margins. In 2008, Republican John McCain defeated Democrat Barack Obama in Alaska, 59.49% to 37.83%. McCain's running mate was Sarah Palin, the state's governor and the first Alaskan on a major party ticket. Obama lost Alaska again in 2012, but he captured 40% of the state's vote in that election, making him the first Democrat to do so since 1968.
The Alaska Bush, central Juneau, midtown and downtown Anchorage, and the areas surrounding the University of Alaska Fairbanks campus and Ester have been strongholds of the Democratic Party. The Matanuska-Susitna Borough, the majority of Fairbanks (including North Pole and the military base), and South Anchorage typically have the strongest Republican showing. , well over half of all registered voters have chosen "Non-Partisan" or "Undeclared" as their affiliation, despite recent attempts to close primaries to unaffiliated voters.
Because of its population relative to other U.S. states, Alaska has only one member in the U.S. House of Representatives. This seat is held by Republican Don Young, who was re-elected to his 21st consecutive term in 2012. Alaska's At-large congressional district is one of the largest parliamentary constituencies in the world.
In 2008, Governor Sarah Palin became the first Republican woman to run on a national ticket when she became John McCain's running mate. She continued to be a prominent national figure even after resigning from the governor's job in July 2009.
Alaska's United States Senators belong to Class 2 and Class 3. In 2008, Democrat Mark Begich, mayor of Anchorage, defeated long-time Republican senator Ted Stevens. Stevens had been convicted on seven felony counts of failing to report gifts on Senate financial discloser forms one week before the election. The conviction was set aside in April 2009 after evidence of prosecutorial misconduct emerged.
Republican Frank Murkowski held the state's other senatorial position. After being elected governor in 2002, he resigned from the Senate and appointed his daughter, State Representative Lisa Murkowski as his successor. She won full six-year terms in 2004 and 2010.
Cities, towns and boroughs.
Alaska is not divided into counties, as most of the other U.S. states, but it is divided into "boroughs". Many of the more densely populated parts of the state are part of Alaska's 16 boroughs, which function somewhat similarly to counties in other states. However, unlike county-equivalents in the other 49 states, the boroughs do not cover the entire land area of the state. The area not part of any borough is referred to as the Unorganized Borough.
The Unorganized Borough has no government of its own, but the U.S. Census Bureau in cooperation with the state divided the Unorganized Borough into 11 census areas solely for the purposes of statistical analysis and presentation. A "recording district" is a mechanism for administration of the public record in Alaska. The state is divided into 34 recording districts which are centrally administered under a State Recorder. All recording districts use the same acceptance criteria, fee schedule, etc., for accepting documents into the public record.
Whereas many U.S. states use a three-tiered system of decentralization—state/county/township—most of Alaska uses only two tiers—state/borough. Owing to the low population density, most of the land is located in the Unorganized Borough. As the name implies, it has no intermediate borough government but is administered directly by the state government. In 2000, 57.71% of Alaska's area has this status, with 13.05% of the population.
Anchorage merged the city government with the Greater Anchorage Area Borough in 1975 to form the Municipality of Anchorage, containing the city proper and the communities of Eagle River, Chugiak, Peters Creek, Girdwood, Bird, and Indian. Fairbanks has a separate borough (the Fairbanks North Star Borough) and municipality (the City of Fairbanks).
The state's most populous city is Anchorage, home to 278,700 people in 2006, 225,744 of whom live in the urbanized area. The richest location in Alaska by per capita income is Halibut Cove ($89,895). Yakutat City, Sitka, Juneau, and Anchorage are the four largest cities in the U.S. by area.
Cities and census-designated places (by population).
As reflected in the 2010 United States Census, Alaska has a total of 355 incorporated cities and census-designated places (CDPs). The tally of cities includes four unified municipalities, essentially the equivalent of a consolidated city–county. The majority of these communities are located in the rural expanse of Alaska known as "The Bush" and are unconnected to the contiguous North American road network. The table at the bottom of this section lists the 100 largest cities and census-designated places in Alaska, in population order.
Of Alaska's 2010 Census population figure of 710,231, 20,429 people, or 2.88% of the population, did not live in an incorporated city or census-designated place. Approximately three-quarters of that figure were people who live in urban and suburban neighborhoods on the outskirts of the city limits of Ketchikan, Kodiak, Palmer and Wasilla. CDPs have not been established for these areas by the United States Census Bureau, except that seven CDPs were established for the Ketchikan-area neighborhoods in the 1980 Census (Clover Pass, Herring Cove, Ketchikan East, Mountain Point, North Tongass Highway, Pennock Island and Saxman East), but have not been used since. The remaining population was scattered throughout Alaska, both within organized boroughs and in the Unorganized Borough, in largely remote areas.
Education.
The Alaska Department of Education and Early Development administers many school districts in Alaska. In addition, the state operates a boarding school, Mt. Edgecumbe High School in Sitka, and provides partial funding for other boarding schools, including Nenana Student Living Center in Nenana and The Galena Interior Learning Academy in Galena.
There are more than a dozen colleges and universities in Alaska. Accredited universities in Alaska include the University of Alaska Anchorage, University of Alaska Fairbanks, University of Alaska Southeast, and Alaska Pacific University. Alaska is the only state that has no institutions that are part of the NCAA Division I.
The Alaska Department of Labor and Workforce Development operates AVTEC, Alaska's Institute of Technology. Campuses in Seward and Anchorage offer 1 week to 11-month training programs in areas as diverse as Information Technology, Welding, Nursing, and Mechanics.
Alaska has had a problem with a "brain drain". Many of its young people, including most of the highest academic achievers, leave the state after high school graduation and do not return. , Alaska did not have a law school or medical school. The University of Alaska has attempted to combat this by offering partial four-year scholarships to the top 10% of Alaska high school graduates, via the Alaska Scholars Program.
Public health and public safety.
The Alaska State Troopers are Alaska's statewide police force. They have a long and storied history, but were not an official organization until 1941. Before the force was officially organized, law enforcement in Alaska was handled by various federal agencies. Larger towns usually have their own local police and some villages rely on "Public Safety Officers" who have police training but do not carry firearms. In much of the state, the troopers serve as the only police force available. In addition to enforcing traffic and criminal law, wildlife Troopers enforce hunting and fishing regulations. Due to the varied terrain and wide scope of the Troopers' duties, they employ a wide variety of land, air, and water patrol vehicles.
Many rural communities in Alaska are considered "dry," having outlawed the importation of alcoholic beverages. Suicide rates for rural residents are higher than urban.
Domestic abuse and other violent crimes are also at high levels in the state; this is in part linked to alcohol abuse. Alaska has the highest rate of sexual assault in the nation, especially in rural areas. The average age of sexually assaulted victims is 16 years old. In four out of five cases, the suspects were relatives, friends or acquaintances.
Culture.
Some of Alaska's popular annual events are the Iditarod Trail Sled Dog Race that starts in Anchorage and ends in Nome, World Ice Art Championships in Fairbanks, the Blueberry Festival and Alaska Hummingbird Festival in Ketchikan, the Sitka Whale Fest, and the Stikine River Garnet Fest in Wrangell. The Stikine River attracts the largest springtime concentration of American bald eagles in the world.
The Alaska Native Heritage Center celebrates the rich heritage of Alaska's 11 cultural groups. Their purpose is to encourage cross-cultural exchanges among all people and enhance self-esteem among Native people. The Alaska Native Arts Foundation promotes and markets Native art from all regions and cultures in the State, using the internet.
Music.
Influences on music in Alaska include the traditional music of Alaska Natives as well as folk music brought by later immigrants from Russia and Europe. Prominent musicians from Alaska include singer Jewel, traditional Aleut flautist Mary Youngblood, folk singer-songwriter Libby Roderick, Christian music singer/songwriter Lincoln Brewster, metal/post hardcore band 36 Crazyfists and the groups Pamyua and Portugal. The Man.
There are many established music festivals in Alaska, including the Alaska Folk Festival, the Fairbanks Summer Arts Festival, the Anchorage Folk Festival, the Athabascan Old-Time Fiddling Festival, the Sitka Jazz Festival, and the Sitka Summer Music Festival. The most prominent orchestra in Alaska is the Anchorage Symphony Orchestra, though the Fairbanks Symphony Orchestra and Juneau Symphony are also notable. The Anchorage Opera is currently the state's only professional opera company, though there are several volunteer and semi-professional organizations in the state as well.
The official state song of Alaska is "Alaska's Flag", which was adopted in 1955; it celebrates the flag of Alaska.
Alaska in film and on television.
Alaska's first independent picture entirely made in Alaska was "The Chechahcos", produced by Alaskan businessman Austin E. Lathrop and filmed in and around Anchorage. Released in 1924 by the Alaska Moving Picture Corporation, it was the only film the company made.
One of the most prominent movies filmed in Alaska is MGM's "Eskimo/Mala The Magnificent", starring Alaska Native Ray Mala. In 1932 an expedition set out from MGM's studios in Hollywood to Alaska to film what was then billed as "The Biggest Picture Ever Made." Upon arriving in Alaska, they set up "Camp Hollywood" in Northwest Alaska, where they lived during the duration of the filming. Louis B. Mayer spared no expense in spite of the remote location, going so far as to hire the chef from the Hotel Roosevelt in Hollywood to prepare meals.
When "Eskimo" premiered at the Astor Theatre in New York City, the studio received the largest amount of feedback in its history to that point. "Eskimo" was critically acclaimed and released worldwide; as a result, Mala became an international movie star. "Eskimo" won the first Oscar for Best Film Editing at the Academy Awards, and showcased and preserved aspects of Inupiat culture on film.
The 1983 Disney movie "Never Cry Wolf" was at least partially shot in Alaska. The 1991 film "White Fang", based on Jack London's novel and starring Ethan Hawke, was filmed in and around Haines. Steven Seagal's 1994 "On Deadly Ground", starring Michael Caine, was filmed in part at the Worthington Glacier near Valdez. The 1999 John Sayles film "Limbo", starring David Strathairn, Mary Elizabeth Mastrantonio, and Kris Kristofferson, was filmed in Juneau.
The psychological thriller "Insomnia", starring Al Pacino and Robin Williams, was shot in Canada, but was set in Alaska. The 2007 film directed by Sean Penn, "Into The Wild", was partially filmed and set in Alaska. The film, which is based on the novel of the same name, follows the adventures of Christopher McCandless, who died in a remote abandoned bus along the Stampede Trail west of Healy in 1992.
Many films and television shows set in Alaska are not filmed there; for example, "Northern Exposure", set in the fictional town of Cicely, Alaska, was filmed in Roslyn, Washington. The 2007 horror feature "30 Days of Night" is set in Barrow, but was filmed in New Zealand.
Many reality television shows are filmed in Alaska. In 2011 the "Anchorage Daily News" found ten set in the state.

</doc>
<doc id="627" url="https://en.wikipedia.org/wiki?curid=627" title="Agriculture">
Agriculture

Agriculture is the cultivation of animals, plants and fungi for food, fiber, biofuel, medicinal and other products used to sustain and enhance human life. Agriculture was the key development in the rise of sedentary human civilization, whereby farming of domesticated species created food surpluses that nurtured the development of civilization. The study of agriculture is known as agricultural science. The history of agriculture dates back thousands of years, and its development has been driven and defined by greatly different climates, cultures, and technologies. In the civilized world, industrial agriculture based on large-scale monoculture farming has become the dominant agricultural methodology.
Modern agronomy, plant breeding, agrochemicals such as pesticides and fertilizers, and technological developments have in many cases sharply increased yields from cultivation, but at the same time have caused widespread ecological damage and negative human health effects. Selective breeding and modern practices in animal husbandry have similarly increased the output of meat, but have raised concerns about animal welfare and the health effects of the antibiotics, growth hormones, and other chemicals commonly used in industrial meat production. Genetically modified organisms are an increasing component of agriculture, although they are banned in several countries. Agricultural food production and water management are increasingly becoming global issues that are fostering debate on a number of fronts. Significant degradation of land and water resources, including the depletion of aquifers, has been observed in recent decades, and the effects of global warming on agriculture and of agriculture on global warming are still not fully understood.
The major agricultural products can be broadly grouped into foods, fibers, fuels, and raw materials. Specific foods include cereals (grains), vegetables, fruits, oils, meats and spices. Fibers include cotton, wool, hemp, silk and flax. Raw materials include lumber and bamboo. Other useful materials are produced by plants, such as resins, dyes, drugs, perfumes, biofuels and ornamental products such as cut flowers and nursery plants. Over one third of the world's workers are employed in agriculture, second only to the services' sector, although the percentages of agricultural workers in developed countries has decreased significantly over the past several centuries.
Etymology and terminology.
The word "agriculture" is a late Middle English adaptation of Latin "agricultūra", from "ager", "field", and "cultūra", "cultivation" or "growing". Agriculture usually refers to human activities, although it is also observed in certain species of ant, termite and ambrosia beetle. To practice agriculture means to use natural resources to "produce commodities which maintain life, including food, fiber, forest products, horticultural crops, and their related services." This definition includes arable farming or agronomy, and horticulture, all terms for the growing of plants, animal husbandry and forestry. A distinction is sometimes made between forestry and agriculture, based on the former's longer management rotations, extensive versus intensive management practices and development mainly by nature, rather than by man. Even then, it is acknowledged that there is a large amount of knowledge transfer and overlap between silviculture (the management of forests) and agriculture. In traditional farming, the two are often combined even on small landholdings, leading to the term agroforestry.
Agriculture and civilization.
Civilization was the product of the Agricultural Neolithic Revolution. In the course of history, civilization coincided in space with fertile areas (The Fertile Crescent) and most intensive state formation took place in circumscribed agricultural lands (Carneiro's circumscription theory). The Great Wall of China and the Roman limes demarcated the same northern frontier of the basic (cereal) agriculture. This cereal belt nourished the belt of great civilizations formed in the Axial Age and connected by the famous Silk Road.
Ancient Egyptians, whose agriculture depended exclusively on Nile, deified the River, worshiped, and exalted in a great hymn. The Chinese imperial court issued numerous edicts, stating: "Agriculture is the foundation of this Empire." Egyptian, Mesopotamian, Chinese, and Inca Emperors themselves plowed ceremonial fields in order to show personal example to everyone. 
Ancient strategists, Chinese Guan Zhong and Shang Yang and Indian Kautilya, drew doctrines linking agriculture with military power. Agriculture defined the limits on how large and for how long an army could be mobilized. Shang Yang called agriculture and war the "One". In the vast human pantheon of agricultural deities there are several deities who combined the functions of agriculture and war.
As the Neolithic Agricultural Revolution produced civilization, the modern Agricultural Revolution, begun in Britain (British Agricultural Revolution), made possible the Industrial civilization. The first precondition for industry was greater yields by less manpower, resulting in greater percentage of manpower available for non-agricultural sectors. 
Types of agriculture.
Nomadic farming refers to the practice of farming in which herdsmen move from one place to another with there families and livestock,in search of pasture, fodder, and water. This type of farming is practiced in arid and semi-arid regions of Sahara,Central Asia and some parts of India like Rajasthan and Jammu and Kashmir.
In shifting cultivation, a small area of a forest is cleared by cutting down all the trees and the area is burned. Now that area is used for growing crops after some years when the area become less fertile then it is abundant. Again a patch is selected and this process is performed. This type of farming is practiced mainly area with abundant rainfall, so forest regenerate very quickly. They are practiced in North-East India, South-East Asia and the Amazon Basin.
Subsistence farming is practiced by farmer to satisfy his family needs alone nothing is left over sale in other words it is non-commercial farming they use old method and new technology for high production. It is intensively practiced in Monsoon Asia and South-East Asia.
Commercial farming cultivate the crops for commercial purpose i.e., for selling. The main motive of the farmer is to make profit. This type of farming is mainly practice in western countries like Canada and USA.
Dairy farming is the rearing of the cattle on the large scale on the outskirts of the city to meet the demands of milk and animal products is called dairy farming. It is mainly practiced in Australia, New Zealand, Denmark and in Europe.
Contemporary agriculture.
In the past century, agriculture has been characterized by increased productivity, the substitution of synthetic fertilizers and pesticides for labor, water pollution, and farm subsidies. In recent years there has been a backlash against the external environmental effects of conventional agriculture, resulting in the organic and sustainable agriculture movements. One of the major forces behind this movement has been the European Union, which first certified organic food in 1991 and began reform of its Common Agricultural Policy (CAP) in 2005 to phase out commodity-linked farm subsidies, also known as decoupling. The growth of organic farming has renewed research in alternative technologies such as integrated pest management and selective breeding. Recent mainstream technological developments include genetically modified food.
In 2007, higher incentives for farmers to grow non-food biofuel crops combined with other factors, such as over development of former farm lands, rising transportation costs, climate change, growing consumer demand in China and India, and population growth, caused food shortages in Asia, the Middle East, Africa, and Mexico, as well as rising food prices around the globe. As of December 2007, 37 countries faced food crises, and 20 had imposed some sort of food-price controls. Some of these shortages resulted in food riots and even deadly stampedes. The International Fund for Agricultural Development posits that an increase in smallholder agriculture may be part of the solution to concerns about food prices and overall food security. They in part base this on the experience of Vietnam, which went from a food importer to large food exporter and saw a significant drop in poverty, due mainly to the development of smallholder agriculture in the country.
Disease and land degradation are two of the major concerns in agriculture today. For example, an epidemic of stem rust on wheat caused by the Ug99 lineage is currently spreading across Africa and into Asia and is causing major concerns due to crop losses of 70% or more under some conditions. Approximately 40% of the world's agricultural land is seriously degraded. In Africa, if current trends of soil degradation continue, the continent might be able to feed just 25% of its population by 2025, according to United Nations University's Ghana-based Institute for Natural Resources in Africa.
Agrarian structure is a long-term structure in the Braudelian understanding of the concept. On a larger scale the agrarian structure is more dependent on the regional, social, cultural and historical factors than on the state’s undertaken activities. Like in Poland, where despite running an intense agrarian policy for many years, the agrarian structure in 2002 has much in common with that found in 1921 soon after the partitions period.
In 2009, the agricultural output of China was the largest in the world, followed by the European Union, India and the United States, according to the International Monetary Fund ("see below"). Economists measure the total factor productivity of agriculture and by this measure agriculture in the United States is roughly 1.7 times more productive than it was in 1948.
Workforce.
, the International Labour Organization states that approximately one billion people, or over 1/3 of the available work force, are employed in the global agricultural sector. Agriculture constitutes approximately 70% of the global employment of children, and in many countries employs the largest percentage of women of any industry. The service sector only overtook the agricultural sector as the largest global employer in 2007. Between 1997 and 2007, the percentage of people employed in agriculture fell by over four percentage points, a trend that is expected to continue. The number of people employed in agriculture varies widely on a per-country basis, ranging from less than 2% in countries like the US and Canada to over 80% in many African nations. In developed countries, these figures are significantly lower than in previous centuries. During the 16th century in Europe, for example, between 55 and 75 percent of the population was engaged in agriculture, depending on the country. By the 19th century in Europe, this had dropped to between 35 and 65 percent. In the same countries today, the figure is less than 10%.
Safety.
Agriculture, specifically farming, remains a hazardous industry, and farmers worldwide remain at high risk of work-related injuries, lung disease, noise-induced hearing loss, skin diseases, as well as certain cancers related to chemical use and prolonged sun exposure. On industrialized farms, injuries frequently involve the use of agricultural machinery, and a common cause of fatal agricultural injuries in developed countries is tractor rollovers. Pesticides and other chemicals used in farming can also be hazardous to worker health, and workers exposed to pesticides may experience illness or have children with birth defects. As an industry in which families commonly share in work and live on the farm itself, entire families can be at risk for injuries, illness, and death. Common causes of fatal injuries among young farm workers include drowning, machinery and motor vehicle-related accidents.
The International Labour Organization considers agriculture "one of the most hazardous of all economic sectors." It estimates that the annual work-related death toll among agricultural employees is at least 170,000, twice the average rate of other jobs. In addition, incidences of death, injury and illness related to agricultural activities often go unreported. The organization has developed the Safety and Health in Agriculture Convention, 2001, which covers the range of risks in the agriculture occupation, the prevention of these risks and the role that individuals and organizations engaged in agriculture should play.
Agricultural production systems.
Crop cultivation systems.
Cropping systems vary among farms depending on the available resources and constraints; geography and climate of the farm; government policy; economic, social and political pressures; and the philosophy and culture of the farmer.
Shifting cultivation (or slash and burn) is a system in which forests are burnt, releasing nutrients to support cultivation of annual and then perennial crops for a period of several years. Then the plot is left fallow to regrow forest, and the farmer moves to a new plot, returning after many more years (10 – 20). This fallow period is shortened if population density grows, requiring the input of nutrients (fertilizer or manure) and some manual pest control. Annual cultivation is the next phase of intensity in which there is no fallow period. This requires even greater nutrient and pest control inputs.
Further industrialization led to the use of monocultures, when one cultivar is planted on a large acreage. Because of the low biodiversity, nutrient use is uniform and pests tend to build up, necessitating the greater use of pesticides and fertilizers. Multiple cropping, in which several crops are grown sequentially in one year, and intercropping, when several crops are grown at the same time, are other kinds of annual cropping systems known as polycultures.
In subtropical and arid environments, the timing and extent of agriculture may be limited by rainfall, either not allowing multiple annual crops in a year, or requiring irrigation. In all of these environments perennial crops are grown (coffee, chocolate) and systems are practiced such as agroforestry. In temperate environments, where ecosystems were predominantly grassland or prairie, highly productive annual farming is the dominant agricultural system.
Crop statistics.
Important categories of crops include cereals and pseudocereals, pulses (legumes), forage, and fruits and vegetables. Specific crops are cultivated in distinct growing regions throughout the world. In millions of metric tons, based on FAO estimate.
Livestock production systems.
Animals, including horses, mules, oxen, water buffalo, camels, llamas, alpacas, donkeys, and dogs, are often used to help cultivate fields, harvest crops, wrangle other animals, and transport farm products to buyers. Animal husbandry not only refers to the breeding and raising of animals for meat or to harvest animal products (like milk, eggs, or wool) on a continual basis, but also to the breeding and care of species for work and companionship.
Livestock production systems can be defined based on feed source, as grassland-based, mixed, and landless. , 30% of Earth's ice- and water-free area was used for producing livestock, with the sector employing approximately 1.3 billion people. Between the 1960s and the 2000s, there was a significant increase in livestock production, both by numbers and by carcass weight, especially among beef, pigs and chickens, the latter of which had production increased by almost a factor of 10. Non-meat animals, such as milk cows and egg-producing chickens, also showed significant production increases. Global cattle, sheep and goat populations are expected to continue to increase sharply through 2050. Aquaculture or fish farming, the production of fish for human consumption in confined operations, is one of the fastest growing sectors of food production, growing at an average of 9% a year between 1975 and 2007.
During the second half of the 20th century, producers using selective breeding focused on creating livestock breeds and crossbreeds that increased production, while mostly disregarding the need to preserve genetic diversity. This trend has led to a significant decrease in genetic diversity and resources among livestock breeds, leading to a corresponding decrease in disease resistance and local adaptations previously found among traditional breeds.
Grassland based livestock production relies upon plant material such as shrubland, rangeland, and pastures for feeding ruminant animals. Outside nutrient inputs may be used, however manure is returned directly to the grassland as a major nutrient source. This system is particularly important in areas where crop production is not feasible because of climate or soil, representing 30 – 40 million pastoralists. Mixed production systems use grassland, fodder crops and grain feed crops as feed for ruminant and monogastric (one stomach; mainly chickens and pigs) livestock. Manure is typically recycled in mixed systems as a fertilizer for crops.
Landless systems rely upon feed from outside the farm, representing the de-linking of crop and livestock production found more prevalently in Organisation for Economic Co-operation and Development(OECD) member countries. Synthetic fertilizers are more heavily relied upon for crop production and manure utilization becomes a challenge as well as a source for pollution. Industrialized countries use these operations to produce much of the global supplies of poultry and pork. Scientists estimate that 75% of the growth in livestock production between 2003 and 2030 will be in confined animal feeding operations, sometimes called factory farming. Much of this growth is happening in developing countries in Asia, with much smaller amounts of growth in Africa. Some of the practices used in commercial livestock production, including the usage of growth hormones, are controversial.
Production practices.
Farming is the practice of agriculture by specialized labor in an area primarily devoted to agricultural processes, in service of a dislocated population usually in a city.
Tillage is the practice of plowing soil to prepare for planting or for nutrient incorporation or for pest control. Tillage varies in intensity from conventional to no-till. It may improve productivity by warming the soil, incorporating fertilizer and controlling weeds, but also renders soil more prone to erosion, triggers the decomposition of organic matter releasing CO2, and reduces the abundance and diversity of soil organisms.
Pest control includes the management of weeds, insects, mites, and diseases. Chemical (pesticides), biological (biocontrol), mechanical (tillage), and cultural practices are used. Cultural practices include crop rotation, culling, cover crops, intercropping, composting, avoidance, and resistance. Integrated pest management attempts to use all of these methods to keep pest populations below the number which would cause economic loss, and recommends pesticides as a last resort.
Nutrient management includes both the source of nutrient inputs for crop and livestock production, and the method of utilization of manure produced by livestock. Nutrient inputs can be chemical inorganic fertilizers, manure, green manure, compost and mined minerals. Crop nutrient use may also be managed using cultural techniques such as crop rotation or a fallow period. Manure is used either by holding livestock where the feed crop is growing, such as in managed intensive rotational grazing, or by spreading either dry or liquid formulations of manure on cropland or pastures.
Water management is needed where rainfall is insufficient or variable, which occurs to some degree in most regions of the world. Some farmers use irrigation to supplement rainfall. In other areas such as the Great Plains in the U.S. and Canada, farmers use a fallow year to conserve soil moisture to use for growing a crop in the following year. Agriculture represents 70% of freshwater use worldwide.
According to a report by the International Food Policy Research Institute, agricultural technologies will have the greatest impact on food production if adopted in combination with each other; using a model that assessed how eleven technologies could impact agricultural productivity, food security and trade by 2050, the International Food Policy Research Institute found that the number of people at risk from hunger could be reduced by as much as 40% and food prices could be reduced by almost half.
"Payment for ecosystem services (PES) can further incentivise efforts to green the agriculture sector. This is an approach that verifies values and rewards the benefits of ecosystem services provided by green agricultural practices." "Innovative PES measures could include reforestation payments made by cities to upstream communities in rural areas of shared watersheds for improved quantities and quality of fresh water for municipal users. Ecoservice payments by farmers to upstream forest stewards for properly managing the flow of soil nutrients, and methods to monetise the carbon sequestration and emission reduction credit benefits of green agriculture practices in order to compensate farmers for their efforts to restore and build SOM and employ other practices."
Crop alteration and biotechnology.
Crop alteration has been practiced by humankind for thousands of years, since the beginning of civilization. Altering crops through breeding practices changes the genetic make-up of a plant to develop crops with more beneficial characteristics for humans, for example, larger fruits or seeds, drought-tolerance, or resistance to pests. Significant advances in plant breeding ensued after the work of geneticist Gregor Mendel. His work on dominant and recessive alleles, although initially largely ignored for almost 50 years, gave plant breeders a better understanding of genetics and breeding techniques. Crop breeding includes techniques such as plant selection with desirable traits, self-pollination and cross-pollination, and molecular techniques that genetically modify the organism.
Domestication of plants has, over the centuries increased yield, improved disease resistance and drought tolerance, eased harvest and improved the taste and nutritional value of crop plants. Careful selection and breeding have had enormous effects on the characteristics of crop plants. Plant selection and breeding in the 1920s and 1930s improved pasture (grasses and clover) in New Zealand. Extensive X-ray and ultraviolet induced mutagenesis efforts (i.e. primitive genetic engineering) during the 1950s produced the modern commercial varieties of grains such as wheat, corn (maize) and barley.
The Green Revolution popularized the use of conventional hybridization to sharply increase yield by creating "high-yielding varieties". For example, average yields of corn (maize) in the USA have increased from around 2.5 tons per hectare (t/ha) (40 bushels per acre) in 1900 to about 9.4 t/ha (150 bushels per acre) in 2001. Similarly, worldwide average wheat yields have increased from less than 1 t/ha in 1900 to more than 2.5 t/ha in 1990. South American average wheat yields are around 2 t/ha, African under 1 t/ha, and Egypt and Arabia up to 3.5 to 4 t/ha with irrigation. In contrast, the average wheat yield in countries such as France is over 8 t/ha. Variations in yields are due mainly to variation in climate, genetics, and the level of intensive farming techniques (use of fertilizers, chemical pest control, growth control to avoid lodging).
Genetic engineering.
Genetically modified organisms (GMO) are organisms whose genetic material has been altered by genetic engineering techniques generally known as recombinant DNA technology. Genetic engineering has expanded the genes available to breeders to utilize in creating desired germlines for new crops. Increased durability, nutritional content, insect and virus resistance and herbicide tolerance are a few of the attributes bred into crops through genetic engineering. For some, GMO crops cause food safety and food labeling concerns. Numerous countries have placed restrictions on the production, import or use of GMO foods and crops, which have been put in place due to concerns over potential health issues, declining agricultural diversity and contamination of non-GMO crops. Currently a global treaty, the Biosafety Protocol, regulates the trade of GMOs. There is ongoing discussion regarding the labeling of foods made from GMOs, and while the EU currently requires all GMO foods to be labeled, the US does not.
Herbicide-resistant seed has a gene implanted into its genome that allows the plants to tolerate exposure to herbicides, including glyphosates. These seeds allow the farmer to grow a crop that can be sprayed with herbicides to control weeds without harming the resistant crop. Herbicide-tolerant crops are used by farmers worldwide. With the increasing use of herbicide-tolerant crops, comes an increase in the use of glyphosate-based herbicide sprays. In some areas glyphosate resistant weeds have developed, causing farmers to switch to other herbicides. Some studies also link widespread glyphosate usage to iron deficiencies in some crops, which is both a crop production and a nutritional quality concern, with potential economic and health implications.
Other GMO crops used by growers include insect-resistant crops, which have a gene from the soil bacterium "Bacillus thuringiensis" (Bt), which produces a toxin specific to insects. These crops protect plants from damage by insects. Some believe that similar or better pest-resistance traits can be acquired through traditional breeding practices, and resistance to various pests can be gained through hybridization or cross-pollination with wild species. In some cases, wild species are the primary source of resistance traits; some tomato cultivars that have gained resistance to at least 19 diseases did so through crossing with wild populations of tomatoes.
Environmental impact.
Agriculture, as implemented through the method of farming, imposes external costs upon society through pesticides, nutrient runoff, excessive water usage, loss of natural environment and assorted other problems. A 2000 assessment of agriculture in the UK determined total external costs for 1996 of £2,343 million, or £208 per hectare. A 2005 analysis of these costs in the USA concluded that cropland imposes approximately $5 to 16 billion ($30 to $96 per hectare), while livestock production imposes $714 million. Both studies, which focused solely on the fiscal impacts, concluded that more should be done to internalize external costs. Neither included subsidies in their analysis, but they noted that subsidies also influence the cost of agriculture to society. In 2010, the International Resource Panel of the United Nations Environment Programme published a report assessing the environmental impacts of consumption and production. The study found that agriculture and food consumption are two of the most important drivers of environmental pressures, particularly habitat change, climate change, water use and toxic emissions. The 2011 UNEP Green Economy report states that "gricultural operations, excluding land use changes, produce approximately 13 per cent of anthropogenic global GHG emissions. This includes GHGs emitted by the use of inorganic fertilisers agro-chemical pesticides and herbicides; (GHG emissions resulting from production of these inputs are included in industrial emissions); and fossil fuel-energy inputs. "On average we find that the total amount of fresh residues from agricultural and forestry production for second- generation biofuel production amounts to 3.8 billion tonnes per year between 2011 and 2050 (with an average annual growth rate of 11 per cent throughout the period analysed, accounting for higher growth during early years, 48 per cent for 2011–2020 and an average 2 per cent annual expansion after 2020)."
Livestock issues.
A senior UN official and co-author of a UN report detailing this problem, Henning Steinfeld, said "Livestock are one of the most significant contributors to today's most serious environmental problems". Livestock production occupies 70% of all land used for agriculture, or 30% of the land surface of the planet. It is one of the largest sources of greenhouse gases, responsible for 18% of the world's greenhouse gas emissions as measured in CO2 equivalents. By comparison, all transportation emits 13.5% of the CO2. It produces 65% of human-related nitrous oxide (which has 296 times the global warming potential of CO2,) and 37% of all human-induced methane (which is 23 times as warming as CO2.) It also generates 64% of the ammonia emission. Livestock expansion is cited as a key factor driving deforestation; in the Amazon basin 70% of previously forested area is now occupied by pastures and the remainder used for feedcrops. Through deforestation and land degradation, livestock is also driving reductions in biodiversity. Furthermore, the UNEP states that "methane emissions from global livestock are projected to increase by 60 per cent by 2030 under current practices and consumption patterns."
Land and water issues.
Land transformation, the use of land to yield goods and services, is the most substantial way humans alter the Earth's ecosystems, and is considered the driving force in the loss of biodiversity. Estimates of the amount of land transformed by humans vary from 39 to 50%. Land degradation, the long-term decline in ecosystem function and productivity, is estimated to be occurring on 24% of land worldwide, with cropland overrepresented. The UN-FAO report cites land management as the driving factor behind degradation and reports that 1.5 billion people rely upon the degrading land. Degradation can be deforestation, desertification, soil erosion, mineral depletion, or chemical degradation (acidification and salinization).
Eutrophication, excessive nutrients in aquatic ecosystems resulting in algal blooms and anoxia, leads to fish kills, loss of biodiversity, and renders water unfit for drinking and other industrial uses. Excessive fertilization and manure application to cropland, as well as high livestock stocking densities cause nutrient (mainly nitrogen and phosphorus) runoff and leaching from agricultural land. These nutrients are major nonpoint pollutants contributing to eutrophication of aquatic ecosystems.
Agriculture accounts for 70 percent of withdrawals of freshwater resources. Agriculture is a major draw on water from aquifers, and currently draws from those underground water sources at an unsustainable rate. It is long known that aquifers in areas as diverse as northern China, the Upper Ganges and the western US are being depleted, and new research extends these problems to aquifers in Iran, Mexico and Saudi Arabia. Increasing pressure is being placed on water resources by industry and urban areas, meaning that water scarcity is increasing and agriculture is facing the challenge of producing more food for the world's growing population with reduced water resources. Agricultural water usage can also cause major environmental problems, including the destruction of natural wetlands, the spread of water-borne diseases, and land degradation through salinization and waterlogging, when irrigation is performed incorrectly.
Pesticides.
Pesticide use has increased since 1950 to 2.5million short tons annually worldwide, yet crop loss from pests has remained relatively constant. The World Health Organization estimated in 1992 that 3million pesticide poisonings occur annually, causing 220,000 deaths. Pesticides select for pesticide resistance in the pest population, leading to a condition termed the "pesticide treadmill" in which pest resistance warrants the development of a new pesticide.
An alternative argument is that the way to "save the environment" and prevent famine is by using pesticides and intensive high yield farming, a view exemplified by a quote heading the Center for Global Food Issues website: 'Growing more per acre leaves more land for nature'. However, critics argue that a trade-off between the environment and a need for food is not inevitable, and that pesticides simply replace good agronomic practices such as crop rotation. The UNEP introduces the Push–pull agricultural pest management technique which involves intercropping that uses plant aromas to repel or push away pests while pulling in or attracting the right insects. "The implementation of push-pull in eastern Africa has significantly increased maize yields and the combined cultivation of N-fixing forage crops has enriched the soil and has also provided farmers with feed for livestock. With increased livestock operations, the farmers are able to produce meat, milk and other dairy products and they use the manure as organic fertiliser that returns nutrients to the fields."
Climate change.
Climate change has the potential to affect agriculture through changes in temperature, rainfall (timing and quantity), CO2, solar radiation and the interaction of these elements. Extreme events, such as droughts and floods, are forecast to increase as climate change takes hold. Agriculture is among sectors most vulnerable to the impacts of climate change; water supply for example, will be critical to sustain agricultural production and provide the increase in food output required to sustain the world's growing population. Fluctuations in the flow of rivers are likely to increase in the twenty-first century. Based on the experience of countries in the Nile river basin (Ethiopia, Kenya and Sudan) and other developing countries, depletion of water resources during seasons crucial for agriculture can lead to a decline in yield by up to 50%. Transformational approaches will be needed to manage natural resources in the future. For example, policies, practices and tools promoting climate-smart agriculture will be important, as will better use of scientific information on climate for assessing risks and vulnerability. Planners and policy-makers will need to help create suitable policies that encourage funding for such agricultural transformation.
Agriculture in its many forms can both mitigate or worsen global warming. Some of the increase in CO2 in the atmosphere comes from the decomposition of organic matter in the soil, and much of the methane emitted into the atmosphere is caused by the decomposition of organic matter in wet soils such as rice paddy fields, as well as the normal digestive activities of farm animals. Further, wet or anaerobic soils also lose nitrogen through denitrification, releasing the greenhouse gases nitric oxide and nitrous oxide. Changes in management can reduce the release of these greenhouse gases, and soil can further be used to sequester some of the CO2 in the atmosphere. Informed by the UNEP, "griculture also produces about 58 per cent of global nitrous oxide emissions and about 47 per cent of global methane emissions. Cattle and rice farms release methane, fertilized fields release nitrous oxide, and the cutting down of rainforests to grow crops or raise livestock releases carbon dioxide. Both of these gases have a far greater global warming potential per tonne than CO2 (298 times and 25 times respectively)."
There are several factors within the field of agriculture that contribute to the large amount of CO2 emissions. The diversity of the sources ranges from the production of farming tools to the transport of harvested produce. Approximately 8% of the national carbon footprint is due to agricultural sources. Of that, 75% is of the carbon emissions released from the production of crop assisting chemicals. Factories producing insecticides, herbicides, fungicides, and fertilizers are a major culprit of the greenhouse gas. Productivity on the farm itself and the use of machinery is another source of the carbon emission. Almost all the industrial machines used in modern farming are powered by fossil fuels. These instruments are burning fossil fuels from the beginning of the process to the end. Tractors are the root of this source. The tractor is going to burn fuel and release CO2 just to run. The amount of emissions from the machinery increase with the attachment of different units and need for more power. During the soil preparation stage tillers and plows will be used to disrupt the soil. During growth watering pumps and sprayers are used to keep the crops hydrated. And when the crops are ready for picking a forage or combine harvester is used. These types of machinery all require additional energy which leads to increased carbon dioxide emissions from the basic tractors. The final major contribution to CO2 emissions in agriculture is in the final transport of produce. Local farming suffered a decline over the past century due to large amounts of farm subsidies. The majority of crops are shipped hundreds of miles to various processing plants before ending up in the grocery store. These shipments are made using fossil fuel burning modes of transportation. Inevitably these transport adds to carbon dioxide emissions.
Sustainability.
Some major organizations are hailing farming within agroecosystems as the way forward for mainstream agriculture. Current farming methods have resulted in over-stretched water resources, high levels of erosion and reduced soil fertility. According to a report by the International Water Management Institute and UNEP, there is not enough water to continue farming using current practices; therefore how critical water, land, and ecosystem resources are used to boost crop yields must be reconsidered. The report suggested assigning value to ecosystems, recognizing environmental and livelihood tradeoffs, and balancing the rights of a variety of users and interests. Inequities that result when such measures are adopted would need to be addressed, such as the reallocation of water from poor to rich, the clearing of land to make way for
more productive farmland, or the preservation of a wetland system that limits fishing rights.
Technological advancements help provide farmers with tools and resources to make farming more sustainable. New technologies have given rise to innovations like conservation tillage, a farming process which helps prevent land loss to erosion, water pollution and enhances carbon sequestration.
According to a report by the International Food Policy Research Institute (IFPRI), agricultural technologies will have the greatest impact on food production if adopted in combination with each other; using a model that assessed how eleven technologies could impact agricultural productivity, food security and trade by 2050, IFPRI found that the number of people at risk from hunger could be reduced by as much as 40% and food prices could be reduced by almost half.
Agricultural economics.
Agricultural economics refers to economics as it relates to the "production, distribution and consumption of goods and services". Combining agricultural production with general theories of marketing and business as a discipline of study began in the late 1800s, and grew significantly through the 20th century. Although the study of agricultural economics is relatively recent, major trends in agriculture have significantly affected national and international economies throughout history, ranging from tenant farmers and sharecropping in the post-American Civil War Southern United States to the European feudal system of manorialism. In the United States, and elsewhere, food costs attributed to food processing, distribution, and agricultural marketing, sometimes referred to as the value chain, have risen while the costs attributed to farming have declined. This is related to the greater efficiency of farming, combined with the increased level of value addition (e.g. more highly processed products) provided by the supply chain. Market concentration has increased in the sector as well, and although the total effect of the increased market concentration is likely increased efficiency, the changes redistribute economic surplus from producers (farmers) and consumers, and may have negative implications for rural communities.
National government policies can significantly change the economic marketplace for agricultural products, in the form of taxation, subsidies, tariffs and other measures. Since at least the 1960s, a combination of import/export restrictions, exchange rate policies and subsidies have affected farmers in both the developing and developed world. In the 1980s, it was clear that non-subsidized farmers in developing countries were experiencing adverse effects from national policies that created artificially low global prices for farm products. Between the mid-1980s and the early 2000s, several international agreements were put into place that limited agricultural tariffs, subsidies and other trade restrictions.
However, , there was still a significant amount of policy-driven distortion in global agricultural product prices. The three agricultural products with the greatest amount of trade distortion were sugar, milk and rice, mainly due to taxation. Among the oilseeds, sesame had the greatest amount of taxation, but overall, feed grains and oilseeds had much lower levels of taxation than livestock products. Since the 1980s, policy-driven distortions have seen a greater decrease among livestock products than crops during the worldwide reforms in agricultural policy. Despite this progress, certain crops, such as cotton, still see subsidies in developed countries artificially deflating global prices, causing hardship in developing countries with non-subsidized farmers. Unprocessed commodities (i.e. corn, soybeans, cows) are generally graded to indicate quality. The quality affects the price the producer receives. Commodities are generally reported by production quantities, such as volume, number or weight.
Energy and agriculture.
Since the 1940s, agricultural productivity has increased dramatically, due largely to the increased use of energy-intensive mechanization, fertilizers and pesticides. The vast majority of this energy input comes from fossil fuel sources. Between the 1960–65 measuring cycle and the cycle from 1986 to 1990, the Green Revolution transformed agriculture around the globe, with world grain production increasing significantly (between 70% and 390% for wheat and 60% to 150% for rice, depending on geographic area) as world population doubled. Modern agriculture's heavy reliance on petrochemicals and mechanization has raised concerns that oil shortages could increase costs and reduce agricultural output, causing food shortages.
Modern or industrialized agriculture is dependent on fossil fuels in two fundamental ways: 1. direct consumption on the farm and 2. indirect consumption to manufacture inputs used on the farm. Direct consumption includes the use of lubricants and fuels to operate farm vehicles and machinery; and use of gasoline, liquid propane, and electricity to power dryers, pumps, lights, heaters, and coolers. American farms directly consumed about 1.2 exajoules (1.1 quadrillion BTU) in 2002, or just over 1% of the nation's total energy.
Indirect consumption is mainly oil and natural gas used to manufacture fertilizers and pesticides, which accounted for 0.6 exajoules (0.6 quadrillion BTU) in 2002. The natural gas and coal consumed by the production of nitrogen fertilizer can account for over half of the agricultural energy usage. China utilizes mostly coal in the production of nitrogen fertilizer, while most of Europe uses large amounts of natural gas and small amounts of coal. According to a 2010 report published by The Royal Society, agriculture is increasingly dependent on the direct and indirect input of fossil fuels. Overall, the fuels used in agriculture vary based on several factors, including crop, production system and location. The energy used to manufacture farm machinery is also a form of indirect agricultural energy consumption. Together, direct and indirect consumption by US farms accounts for about 2% of the nation's energy use. Direct and indirect energy consumption by U.S. farms peaked in 1979, and has gradually declined over the past 30 years. Food systems encompass not just agricultural production, but also off-farm processing, packaging, transporting, marketing, consumption, and disposal of food and food-related items. Agriculture accounts for less than one-fifth of food system energy use in the US.
Mitigation of effects of petroleum shortages.
In the event of a petroleum shortage (see peak oil for global concerns), organic agriculture can be more attractive than conventional practices that use petroleum-based pesticides, herbicides, or fertilizers. Some studies using modern organic-farming methods have reported yields as high as those available from conventional farming. In the aftermath of the fall of the Soviet Union, with shortages of conventional petroleum-based inputs, Cuba made use of mostly organic practices, including biopesticides, plant-based pesticides and sustainable cropping practices, to feed its populace. However, organic farming may be more labor-intensive and would require a shift of the workforce from urban to rural areas. The reconditioning of soil to restore nutrients lost during the use of monoculture agriculture techniques also takes time.
It has been suggested that rural communities might obtain fuel from the biochar and synfuel process, which uses agricultural "waste" to provide charcoal fertilizer, some fuel "and" food, instead of the normal food vs. fuel debate. As the synfuel would be used on-site, the process would be more efficient and might just provide enough fuel for a new organic-agriculture fusion.
It has been suggested that some transgenic plants may some day be developed which would allow for maintaining or increasing yields while requiring fewer fossil-fuel-derived inputs than conventional crops. The possibility of success of these programs is questioned by ecologists and economists concerned with unsustainable GMO practices such as terminator seeds. While there has been some research on sustainability using GMO crops, at least one prominent multi-year attempt by Monsanto Company has been unsuccessful, though during the same period traditional breeding techniques yielded a more sustainable variety of the same crop.
Policy.
Agricultural policy is the set of government decisions and actions relating to domestic agriculture and imports of foreign agricultural products. Governments usually implement agricultural policies with the goal of achieving a specific outcome in the domestic agricultural product markets. Some overarching themes include risk management and adjustment (including policies related to climate change, food safety and natural disasters), economic stability (including policies related to taxes), natural resources and environmental sustainability (especially water policy), research and development, and market access for domestic commodities (including relations with global organizations and agreements with other countries). Agricultural policy can also touch on food quality, ensuring that the food supply is of a consistent and known quality, food security, ensuring that the food supply meets the population's needs, and conservation. Policy programs can range from financial programs, such as subsidies, to encouraging producers to enroll in voluntary quality assurance programs.
There are many influences on the creation of agricultural policy, including consumers, agribusiness, trade lobbies and other groups. Agribusiness interests hold a large amount of influence over policy making, in the form of lobbying and campaign contributions. Political action groups, including those interested in environmental issues and labor unions, also provide influence, as do lobbying organizations representing individual agricultural commodities. The Food and Agriculture Organization of the United Nations (FAO) leads international efforts to defeat hunger and provides a forum for the negotiation of global agricultural regulations and agreements. Dr. Samuel Jutzi, director of FAO's animal production and health division, states that lobbying by large corporations has stopped reforms that would improve human health and the environment. For example, proposals in 2010 for a voluntary code of conduct for the livestock industry that would have provided incentives for improving standards for health, and environmental regulations, such as the number of animals an area of land can support without long-term damage, were successfully defeated due to large food company pressure.

</doc>
<doc id="628" url="https://en.wikipedia.org/wiki?curid=628" title="Aldous Huxley">
Aldous Huxley

Aldous Leonard Huxley (; 26 July 1894 – 22 November 1963) was an English writer, novelist, philosopher, and prominent member of the Huxley family. He graduated from Balliol College, Oxford with a first in English literature.
He was best known for his novels including "Brave New World", set in a dystopian London, and for non-fiction books, such as "The Doors of Perception", which recalls experiences when taking a psychedelic drug, and a wide-ranging output of essays. Early in his career Huxley edited the magazine "Oxford Poetry", and published short stories and poetry. Mid career and later, he published travel writing, film stories, and scripts. He spent the later part of his life in the U.S., living in Los Angeles from 1937 until his death. In 1962, a year before his death, he was elected Companion of Literature by the Royal Society of Literature.
Huxley was a humanist, pacifist, and satirist. He later became interested in spiritual subjects such as parapsychology and philosophical mysticism, in particular Universalism. By the end of his life, Huxley was widely acknowledged as one of the pre-eminent intellectuals of his time. He was nominated for the Nobel Prize in Literature in seven different years.
Early life.
Aldous Huxley was born in Godalming, Surrey, England, in 1894. He was the third son of the writer and schoolmaster Leonard Huxley, who edited "Cornhill Magazine", and his first wife, Julia Arnold, who founded Prior's Field School. Julia was the niece of poet and critic Matthew Arnold and the sister of Mrs. Humphrey Ward. Aldous was the grandson of Thomas Henry Huxley, the zoologist, agnostic, and controversialist ("Darwin's Bulldog"). His brother Julian Huxley and half-brother Andrew Huxley also became outstanding biologists. Aldous had another brother, Noel Trevelyan Huxley (1891–1914), who committed suicide after a period of clinical depression.
As a child, Huxley's nickname was "Ogie," short for "Ogre." He was described by his brother, Julian, as someone who frequently " the strangeness of things." According to his cousin and contemporary, Gervas Huxley, he had an early interest in drawing.
Huxley's education began in his father's well-equipped botanical laboratory, after which he enrolled at Hillside School, Malvern. He was taught there by his own mother for several years until she became terminally ill. After Hillside, he went on to Eton College. Huxley's mother died in 1908 when he was 14. In 1911, he contracted an eye disease (keratitis punctata) which "left practically blind for two to three years". This "ended his early dreams of becoming a doctor." In October 1913, Huxley went up to Balliol College, Oxford, where he read English Literature. In January 1916 he volunteered to join the British Army in the Great War, but was rejected on health grounds, being half-blind in one eye. His eyesight later partly recovered. In 1916 he edited "Oxford Poetry" and in June of that year graduated BA with First Class honours. His brother Julian wrote:
Following his years at Balliol, Huxley, being financially indebted to his father, decided to find employment. From April to July 1917, he was in charge of ordering supplies at the Air Ministry for the Royal Air Force. He taught French for a year at Eton, where Eric Blair (who was to take the pen name George Orwell) and Steven Runciman were among his pupils. He was mainly remembered as being an incompetent schoolmaster unable to keep order in class. Nevertheless, Blair and others spoke highly of his brilliant command of language.
Significantly, Huxley also worked for a time during the 1920s at Brunner and Mond, a high-tech chemical plant in Billingham, North East England. According to the introduction to the latest edition of his great science fiction novel "Brave New World" (1932), the experience he had there of "an ordered universe in a world of planless incoherence" was an important source for the novel.
Career.
Huxley completed his first (unpublished) novel at the age of 17 and began writing seriously in his early 20s, establishing himself as a successful writer and social satirist. His first published novels were social satires, "Crome Yellow" (1921), "Antic Hay" (1923), "Those Barren Leaves" (1925), and "Point Counter Point" (1928). "Brave New World" was Huxley's fifth novel and first dystopian work. In the 1920s he was also a contributor to "Vanity Fair" and British "Vogue" magazines.
Bloomsbury Set.
During World War I, Huxley spent much of his time at Garsington Manor near Oxford, home of Lady Ottoline Morrell, working as a farm labourer. There he met several Bloomsbury figures, including Bertrand Russell, Alfred North Whitehead, and Clive Bell. Later, in "Crome Yellow" (1921) he caricatured the Garsington lifestyle. Jobs were very scarce, but in 1919 John Middleton Murry was reorganising the "Athenaeum" and invited Huxley to join the staff. He accepted immediately, and quickly married the Belgian refugee Maria Nys, also at Garsington. They lived with their young son in Italy part of the time during the 1920s, where Huxley would visit his friend D. H. Lawrence. Following Lawrence's death in 1930, Huxley edited Lawrence's letters (1932).
Works of this period included important novels on the dehumanising aspects of scientific progress, most famously "Brave New World", and on pacifist themes (for example, "Eyeless in Gaza"). In "Brave New World", set in a dystopian London, Huxley portrays a society operating on the principles of mass production and Pavlovian conditioning. Huxley was strongly influenced by F. Matthias Alexander and included him as a character in "Eyeless in Gaza".
Starting from this period, Huxley began to write and edit non-fiction works on pacifist issues, including "Ends and Means", "An Encyclopedia of Pacifism", and "Pacifism and Philosophy", and was an active member of the Peace Pledge Union.
United States.
In 1937, Huxley moved to Hollywood with his wife Maria, son Matthew, and friend Gerald Heard. He lived in the US, mainly in southern California, until his death, but also for a time in Taos, New Mexico, where he wrote "Ends and Means" (published in 1937). The book contains illuminating tracts on war, religion, nationalism and ethics.
Heard introduced Huxley to Vedanta (Upanishad-centered philosophy), meditation, and vegetarianism through the principle of ahimsa. In 1938, Huxley befriended Jiddu Krishnamurti, whose teachings he greatly admired. He also became a Vedantist in the circle of Hindu Swami Prabhavananda, and introduced Christopher Isherwood to this circle. Not long after, Huxley wrote his book on widely held spiritual values and ideas, "The Perennial Philosophy", which discussed the teachings of renowned mystics of the world. Huxley's book affirmed a sensibility that insists there are realities beyond the generally accepted "five senses" and that there is genuine meaning for humans beyond both sensual satisfactions and sentimentalities.
Huxley became a close friend of Remsen Bird, president of Occidental College. He spent much time at the college, which is in the Eagle Rock neighbourhood of Los Angeles. The college appears as "Tarzana College" in his satirical novel "After Many a Summer" (1939). The novel won Huxley a British literary award, the 1939 James Tait Black Memorial Prize for fiction. Huxley also incorporated Bird into the novel.
During this period, Huxley earned a substantial income as a Hollywood screenwriter; Christopher Isherwood, in his autobiography "My Guru and His Disciple", states that Huxley earned more than $3,000 per week (an enormous sum in those days) as a screenwriter, and that he used much of it to transport Jewish and left-wing writer and artist refugees from Hitler's Germany to the U.S. In March 1938, his friend Anita Loos, a novelist and screenwriter, put him in touch with Metro-Goldwyn-Mayer who hired Huxley for "Madame Curie", which was originally to star Greta Garbo and be directed by George Cukor. (Eventually, the film was completed by MGM in 1943 with a different director and cast.) Huxley received screen credit for "Pride and Prejudice" (1940) and was paid for his work on a number of other films, including "Jane Eyre" (1944). Huxley was commissioned by Walt Disney in 1945 to write a script based on "Alice's Adventures in Wonderland" and the biography of the story's author, Lewis Carroll. The script was not used, however.
Huxley wrote an introduction to the posthumous publication of J. D. Unwin's 1940 book "Hopousia or The Sexual and Economic Foundations of a New Society".
On 21 October 1949, Huxley wrote to George Orwell, author of "Nineteen Eighty-Four", congratulating him on "how fine and how profoundly important the book is". In his letter to Orwell, he predicted:
Huxley had deeply felt apprehensions about the future the developed world might make for itself. From these, he made some warnings in his writings and talks. In a 1958 televised interview conducted by journalist Mike Wallace, Huxley outlined several major concerns: the difficulties and dangers of world overpopulation; the tendency toward distinctly hierarchical social organisation; the crucial importance of evaluating the use of technology in mass societies susceptible to wily persuasion; the tendency to promote modern politicians, to a naive public, as well-marketed commodities.
Post World War II.
After World War II, Huxley applied for United States citizenship. His application was continuously deferred on the grounds that he would not say he would take up arms to defend the U.S. He claimed a philosophical, rather than a religious objection, and therefore was not exempt under the McCarran Act. He withdrew his application. Nevertheless, he remained in the country; and in 1959 he turned down an offer of a Knight Bachelor by the Macmillan government.
Association with Vedanta.
Beginning in 1939 and continuing until his death in 1963, Huxley had an extensive association with the Vedanta Society of Southern California, founded and headed by Swami Prabhavananda. Together with Gerald Heard, Christopher Isherwood, and other followers he was initiated by the Swami and was taught meditation and spiritual practices.
In 1944, Huxley wrote the introduction to the "Bhagavad Gita: The Song of God", translated by Swami Prabhavanada and Christopher Isherwood, which was published by The Vedanta Society of Southern California.
From 1941 until 1960, Huxley contributed 48 articles to "Vedanta and the West", published by the society. He also served on the editorial board with Isherwood, Heard, and playwright John van Druten from 1951 through 1962.
Huxley also occasionally lectured at the Hollywood and Santa Barbara Vedanta temples. Two of those lectures have been released on CD: "Knowledge and Understanding" and "Who Are We?" from 1955. Nonetheless, Huxley's agnosticism, together with his speculative propensity, made it difficult for him to fully embrace any form of institutionalized religion. In spring of 1953, Huxley had his first, supervised, experience with psychedelic drugs (in this case, mescaline). After the publication of "The Doors of Perception", in which he recounted this experience, Huxley and Swami Prabhavanada disagreed about the meaning and importance of the psychedelic drug experience, which may have caused the relationship to cool, but Huxley continued to write articles for the society's journal, lecture at the temple, and attend social functions.
Eyesight.
There are differing accounts about the details of the quality of Huxley's eyesight at specific points in his life. About 1939, Huxley encountered the Bates method for better eyesight, and a teacher, Margaret Darst Corbett, who was able to teach the method to him. In 1940, Huxley relocated from Hollywood to a "ranchito" in the high desert hamlet of Llano, California, in northernmost Los Angeles County. Huxley then said that his sight improved dramatically with the Bates Method and the extreme and pure natural lighting of the southwestern American desert. He reported that, for the first time in more than 25 years, he was able to read without glasses and without strain. He even tried driving a car along the dirt road beside the ranch. He wrote a book about his successes with the Bates Method, "The Art of Seeing", which was published in 1942 (U.S.), 1943 (UK). The book contained some generally disputed theories, and its publication created a growing degree of popular controversy about Huxley's eyesight.
It was, and is, widely believed that Huxley was nearly blind since the illness in his teens, despite the partial recovery that had enabled him to study at Oxford. For example, some ten years after publication of "The Art of Seeing", in 1952, Bennett Cerf was present when Huxley spoke at a Hollywood banquet, wearing no glasses and apparently reading his paper from the lectern without difficulty: "Then suddenly he faltered — and the disturbing truth became obvious. He wasn't reading his address at all. He had learned it by heart. To refresh his memory he brought the paper closer and closer to his eyes. When it was only an inch or so away he still couldn't read it, and had to fish for a magnifying glass in his pocket to make the typing visible to him. It was an agonising moment."
On the other hand, Huxley's second wife, Laura Archera Huxley, would later emphasise in her biographical account, "This Timeless Moment": "One of the great achievements of his life: that of having regained his sight." After revealing a letter she wrote to the "Los Angeles Times" disclaiming the label of Huxley as a "poor fellow who can hardly see" by Walter C. Alvarez, she tempered this: "Although I feel it was an injustice to treat Aldous as though he were blind, it is true there were many indications of his impaired vision. For instance, although Aldous did not wear glasses, he would quite often use a magnifying lens." Laura Huxley proceeded to elaborate a few nuances of inconsistency peculiar to Huxley's vision. Her account, in this respect, is discernibly congruent with the following sample of Huxley's own words from "The Art of Seeing": "The most characteristic fact about the functioning of the total organism, or any part of the organism, is that it is not constant, but highly variable." Nevertheless, the topic of Huxley's eyesight continues to endure similar, significant controversy, regardless of how trivial a subject matter it might initially appear.
American popular science author Steven Johnson, in his book "Mind Wide Open", quotes Huxley about his difficulties with visual encoding: "I am and, for as long as I can remember, I have always been a poor visualizer. Words, even the pregnant words of poets, do not evoke pictures in my mind. No hypnagogic visions greet me on the verge of sleep. When I recall something, the memory does not present itself to me as a vividly seen event or object. By an effort of the will, I can evoke a not very vivid image of what happened yesterday afternoon ..."
Personal life.
Huxley married Maria Nys (10 September 1899 – 12 February 1955), a Belgian he met at Garsington, Oxfordshire, in 1919. They had one child, Matthew Huxley (19 April 1920 – 10 February 2005), who had a career as an author, anthropologist, and prominent epidemiologist. In 1955, Maria died of cancer.
In 1956, Huxley married Laura Archera (1911–2007), also an author as well as a violinist and psychotherapist. She wrote "This Timeless Moment", a biography of Huxley. Laura felt inspired to illuminate the story of their marriage through Mary Ann Braubach's 2010 documentary, "Huxley on Huxley".
In 1960, Huxley was diagnosed with laryngeal cancer and, in the years that followed, with his health deteriorating, he wrote the Utopian novel "Island", and gave lectures on "Human Potentialities" both at the University of California's San Francisco Medical Center and at the Esalen Institute. These lectures were fundamental to the beginning of the Human Potential Movement.
Huxley was a close friend of Jiddu Krishnamurti and Rosalind Rajagopal and was involved in the creation of the Happy Valley School (now Besant Hill School of Happy Valley) in Ojai, California.
The most substantial collection of Huxley's few remaining papers (following the destruction of most in a fire) is at the Library of the University of California, Los Angeles. Some are also at the Stanford University Libraries.
On 9 April 1962, Huxley was informed he was elected Companion of Literature by the Royal Society of Literature, the senior literary organisation in Britain, and he accepted the title via letter on 28 April 1962. The correspondence between Huxley and the society are kept at the Cambridge University Library. The society invited Huxley to appear at a banquet and give a lecture at Somerset House, London in June 1963. Huxley wrote a draft of the speech he intended to give at the society; however, his deteriorating health meant he would not be able to attend.
Death.
On his deathbed, unable to speak due to advanced laryngeal cancer, Huxley made a written request to his wife Laura for "LSD, 100 µg, intramuscular". According to her account of his death, in "This Timeless Moment", she obliged with an injection at 11:20 a.m. and a second dose an hour later; Huxley died aged 69, at 5:20 p.m. (Los Angeles time), on 22 November 1963.
Media coverage of Huxley's passing — as with that of the author C. S. Lewis – was overshadowed by the assassination of U.S. President John F. Kennedy on the same day. This coincidence served as the basis for Peter Kreeft's book "Between Heaven and Hell: A Dialog Somewhere Beyond Death with John F. Kennedy, C. S. Lewis, & Aldous Huxley", which imagines a conversation among the three men taking place in Purgatory following their deaths.
Huxley's memorial service took place in London in December 1963 which was led by his older brother Julian, and his ashes were interred in the family grave at the Watts Cemetery, home of the Watts Mortuary Chapel in Compton, a village near Guildford, Surrey, England.
Huxley had been a long-time friend of Russian composer Igor Stravinsky, who later dedicated his last orchestral composition to Huxley. Stravinsky began "Variations" in Santa Fé, New Mexico, in July 1963, and completed the composition in Hollywood on 28 October 1964. It was first performed in Chicago on 17 April 1965, by the Chicago Symphony Orchestra conducted by Robert Craft.

</doc>
<doc id="630" url="https://en.wikipedia.org/wiki?curid=630" title="Ada">
Ada

Ada may refer to:

</doc>
<doc id="632" url="https://en.wikipedia.org/wiki?curid=632" title="Aberdeen (disambiguation)">
Aberdeen (disambiguation)

Aberdeen is a city in Scotland, United Kingdom.
Aberdeen may also refer to:

</doc>
<doc id="633" url="https://en.wikipedia.org/wiki?curid=633" title="Algae">
Algae

Algae (; singular "alga" ) is an informal term for a large, diverse group of photosynthetic organisms which are not necessarily closely related and are thus polyphyletic. Included organisms range from unicellular genera, such as "Chlorella" and the diatoms, to multicellular forms, such as the giant kelp, a large brown alga which may grow up to 50 meters in length. Most are aquatic and autotrophic and lack many of the distinct cell and tissue types, such as stomata, xylem and phloem, which are found in land plants. The largest and most complex marine algae are called seaweeds, while the most complex freshwater forms are the Charophyta, a division of green algae which includes, for example, "Spirogyra" and the stoneworts.
There is no generally accepted definition of algae. One definition is that algae "have chlorophyll as their primary photosynthetic pigment and lack a sterile covering of cells around their reproductive cells". Some authors exclude all prokaryotes and thus do not consider cyanobacteria (blue-green algae) as algae.
Algae constitute a polyphyletic group since they do not include a common ancestor, and although their plastids seem to have a single origin, from cyanobacteria, they were acquired in different ways. Green algae are examples of algae that have primary chloroplasts derived from endosymbiotic cyanobacteria. Diatoms and brown algae are examples of algae with secondary chloroplasts derived from an endosymbiotic red alga.
Algae exhibit a wide range of reproductive strategies, from simple asexual cell division to complex forms of sexual reproduction.
Algae lack the various structures that characterize land plants, such as the phyllids (leaf-like structures) of bryophytes, rhizoids in nonvascular plants, and the roots, leaves, and other organs that are found in tracheophytes (vascular plants). Most are phototrophic, although some are mixotrophic, deriving energy both from photosynthesis and uptake of organic carbon either by osmotrophy, myzotrophy, or phagotrophy. Some unicellular species of green algae, many golden algae, euglenids, dinoflagellates and other algae have become heterotrophs (also called colorless or apochlorotic algae), sometimes parasitic, relying entirely on external energy sources and have limited or no photosynthetic apparatus. Some other heterotrophic organisms, like the apicomplexans, are also derived from cells whose ancestors possessed plastids, but are not traditionally considered as algae. Algae have photosynthetic machinery ultimately derived from cyanobacteria that produce oxygen as a by-product of photosynthesis, unlike other photosynthetic bacteria such as purple and green sulfur bacteria. Fossilized filamentous algae from the Vindhya basin have been dated back to 1.6 to 1.7 billion years ago.
Etymology and study.
The singular "alga" is the Latin word for "seaweed" and retains that meaning in English. The etymology is obscure. Although some speculate that it is related to Latin "algēre", "be cold", there is no known reason to associate seaweed with temperature. A more likely source is "alliga", "binding, entwining."
The Ancient Greek word for seaweed was "φῦκος" (fūkos or phykos), which could mean either the seaweed (probably red algae) or a red dye derived from it. The Latinization, "fūcus", meant primarily the cosmetic rouge. The etymology is uncertain, but a strong candidate has long been some word related to the Biblical "פוך" (pūk), "paint" (if not that word itself), a cosmetic eye-shadow used by the ancient Egyptians and other inhabitants of the eastern Mediterranean. It could be any color: black, red, green, blue.
Accordingly, the modern study of marine and freshwater algae is called either phycology or algology, depending on whether the Greek or Latin root is used. The name "Fucus" appears in a number of taxa.
Classification.
Most algae contain chloroplasts that are similar in structure to cyanobacteria. Chloroplasts contain circular DNA like that in cyanobacteria and presumably represent reduced endosymbiotic cyanobacteria. However, the exact origin of the chloroplasts is different among separate lineages of algae, reflecting their acquisition during different endosymbiotic events. The table below describes the composition of the three major groups of algae. Their lineage relationships are shown in the figure in the upper right. Many of these groups contain some members that are no longer photosynthetic. Some retain plastids, but not chloroplasts, while others have lost plastids entirely.
Phylogeny based on plastid not nucleocytoplasmic genealogy:
Linnaeus, in "Species Plantarum" (1753), In "Systema Naturae", Linnaeus described the genera "Volvox", "Corallina" and a species of "Acetabularia" (as "Madrepora"), among the animals.
In 1768, Samuel Gottlieb Gmelin (1744–1774) published the "Historia Fucorum", the first work dedicated to marine algae and the first book on marine biology to use the then new binomial nomenclature of Linnaeus. It included elaborate illustrations of seaweed and marine algae on folded leaves.
W.H.Harvey (1811—1866) and Lamouroux (1813) were the first to divide macroscopic algae into four divisions based on their pigmentation. This is the first use of a biochemical criterion in plant systematics. Harvey's four divisions are: red algae (Rhodospermae), brown algae (Melanospermae), green algae (Chlorospermae) and Diatomaceae.
At this time, microscopic algae were discovered and reported by a different group of workers (e.g., O. F. Müller and Ehrenberg) studying the Infusoria (microscopic organisms). Unlike macroalgae, which were clearly viewed as plants, microalgae were frequently considered animals because they are often motile. Even the non-motile (coccoid) microalgae were sometimes merely seen as stages of the life cycle of plants, macroalgae or animals.
Although used as a taxonomic category in some pre-Darwinian classifications, e.g., Linnaeus (1753), de Jussieu (1789), Horaninow (1843), Agassiz (1859), Wilson & Cassin (1864), in further classifications, the "algae" are seen as an artificial, polyphyletic group.
Throughout the 20th century, most classifications treated the following groups as divisions or classes of algae: cyanophytes, rhodophytes, chrysophytes, xanthophytes, bacillariophytes, phaeophytes, pyrrhophytes (cryptophytes and dinophytes), euglenophytes and chlorophytes. Later, many new groups were discovered (e.g., Bolidophyceae), and others were splintered from older groups: charophytes and glaucophytes (from chlorophytes), many heterokontophytes (e.g., synurophytes from chrysophytes, or eustigmatophytes from xanthophytes), haptophytes (from chrysophytes) and chlorarachniophytes (from xanthophytes).
With the abandonment of plant-animal dichotomous classification, most groups of algae (sometimes all) were included in Protista, later also abandoned in favour of Eukaryota. However, as a legacy of the older plant life scheme, some groups that were also treated as protozoans in the past still have duplicated classifications (see ambiregnal protists).
Some parasitic algae (e.g., the green algae "Prototheca" and "Helicosporidium", parasites of metazoans, or "Cephaleuros", parasites of plants) were originally classified as fungi, sporozoans or protistans of incertae sedis, while others (e.g., the green algae "Phyllosiphon" and "Rhodochytrium", parasites of plants, or the red algae "Pterocladiophila" and "Gelidiocolax mammillatus", parasites of other red algae, or the dinoflagellates "Oodinium", parasites of fish) had their relationship with algae conjectured early. In other cases, some groups were originally characterized as parasitic algae (e.g., "Chlorochytrium"), but later were seen as endophytic algae. Furthermore, groups like the apicomplexans are also parasites derived from ancestors that possessed plastids, but are not included in any group traditionally seen as algae.
Relationship to land plants.
The first land plants probably evolved from shallow freshwater charophyte algae much like "Chara" almost 500 million years ago. These probably had an isomorphic alternation of generations and were probably filamentous. Fossils of isolated land plant spores suggest land plants may have been around as long as 475 million years ago.
Morphology.
A range of algal morphologies are exhibited, and convergence of features in unrelated groups is common. The only groups to exhibit three-dimensional multicellular thalli are the reds and browns, and some chlorophytes. Apical growth is constrained to subsets of these groups: the florideophyte reds, various browns, and the charophytes. The form of charophytes is quite different from those of reds and browns, because they have distinct nodes, separated by internode 'stems'; whorls of branches reminiscent of the horsetails occur at the nodes. Conceptacles are another polyphyletic trait; they appear in the coralline algae and the Hildenbrandiales, as well as the browns.
Most of the simpler algae are unicellular flagellates or amoeboids, but colonial and non-motile forms have developed independently among several of the groups. Some of the more common organizational levels, more than one of which may occur in the life cycle of a species, are
In three lines, even higher levels of organization have been reached, with full tissue differentiation. These are the brown algae,—some of which may reach 50 m in length (kelps)—the red algae, and the green algae. The most complex forms are found among the green algae (see Charales and Charophyta), in a lineage that eventually led to the higher land plants. The point where these non-algal plants begin and algae stop is usually taken to be the presence of reproductive organs with protective cell layers, a characteristic not found in the other alga groups.
Physiology.
Many algae, particularly members of the Characeae, have served as model experimental organisms to understand the mechanisms of the water permeability of membranes, osmoregulation, turgor regulation, salt tolerance, cytoplasmic streaming, and the generation of action potentials.
Phytohormones are found not only in higher plants, but in algae too.
Symbiotic algae.
Some species of algae form symbiotic relationships with other organisms. In these symbioses, the algae supply photosynthates (organic substances) to the host organism providing protection to the algal cells. The host organism derives some or all of its energy requirements from the algae. Examples are as follows.
Lichens.
"Lichens" are defined by the International Association for Lichenology to be "an association of a fungus and a photosynthetic symbiont resulting in a stable vegetative body having a specific structure." The fungi, or mycobionts, are mainly from the Ascomycota with a few from the Basidiomycota. They are not found alone in nature; but when they began to associate is not known. One mycobiont associates with the same phycobiont species, rarely two, from the green algae, except that alternatively the mycobiont may associate with a species of cyanobacteria (hence "photobiont" is the more accurate term). A photobiont may be associated with many different mycobionts or may live independently; accordingly, lichens are named and classified as fungal species. The association is termed a morphogenesis because the lichen has a form and capabilities not possessed by the symbiont species alone (they can be experimentally isolated). It is possible that the photobiont triggers otherwise latent genes in the mycobiont.
Sea sponges.
Green algae live close to the surface of some sponges, for example, breadcrumb sponge ("Halichondria panicea"). The alga is thus protected from predators; the sponge is provided with oxygen and sugars which can account for 50 to 80% of sponge growth in some species.
Life-cycle.
Rhodophyta, Chlorophyta and Heterokontophyta, the three main algal divisions, have life-cycles which show considerable variation and complexity. In general, there is an asexual phase where the seaweed's cells are diploid, a sexual phase where the cells are haploid followed by fusion of the male and female gametes. Asexual reproduction permits efficient population increases, but less variation is possible. Commonly, in sexual reproduction of unicellular and colonial algae, two specialized sexually compatible haploid gametes make physical contact and fuse to form a zygote. To ensure a successful mating, the development and release of gametes is highly synchronized and regulated; pheromones may play a key role in these processes. Sexual reproduction allows for more variation and provides the benefit of efficient recombinational repair of DNA damages during meiosis, a key stage of the sexual cycle. However, sexual reproduction is more costly than asexual reproduction. Meiosis has been shown to occur in many different species of algae.
Numbers.
The "Algal Collection of the US National Herbarium" (located in the National Museum of Natural History) consists of approximately 320,500 dried specimens, which, although not exhaustive (no exhaustive collection exists), gives an idea of the order of magnitude of the number of algal species (that number remains unknown). Estimates vary widely. For example, according to one standard textbook, in the British Isles the "UK Biodiversity Steering Group Report" estimated there to be 20000 algal species in the UK. Another checklist reports only about 5000 species. Regarding the difference of about 15000 species, the text concludes: "It will require many detailed field surveys before it is possible to provide a reliable estimate of the total number of species ..."
Regional and group estimates have been made as well:
and so on, but lacking any scientific basis or reliable sources, these numbers have no more credibility than the British ones mentioned above. Most estimates also omit microscopic algae, such as phytoplankton.
The most recent estimate suggests 72,500 algal species worldwide.
Distribution.
The distribution of algal species has been fairly well studied since the founding of phytogeography in the mid-19th century AD. Algae spread mainly by the dispersal of spores analogously to the dispersal of Plantae by seeds and spores. This dispersal can be accomplished by air, water, or other organisms. Due to this, spores can be found in a variety of environments: fresh and marine waters, air, soil, and in or on other organisms. Whether a spore is to grow into an organism depends on the combination of the species and the environmental conditions of where the spore lands.
The spores of fresh-water algae are dispersed mainly by running water and wind, as well as by living carriers. However, not all bodies of water can carry all species of algae, as the chemical composition of certain water bodies will limit the algae that can survive within it. Marine spores are often spread by ocean currents. Ocean water presents many vastly-different habitats based on temperature and nutrient-availability, resulting in phytogeographic zones, regions and provinces.
To some degree, the distribution of algae is subject to floristic discontinuities caused by geographical features, such as Antarctica, long distances of ocean or general land masses. It is therefore possible to identify species occurring by locality, such as "Pacific Algae" or "North Sea Algae". When they occur out of their localities, it is usually possible to hypothesize a transport mechanism, such as the hulls of ships. For example, "Ulva reticulata" and "Ulva fasciata" travelled from the mainland to Hawaii in this manner.
Mapping is possible for select species only: "there are many valid examples of confined distribution patterns." For example, "Clathromorphum" is an arctic genus and is not mapped far south of there. On the other hand, scientists regard the overall data as insufficient due to the "difficulties of undertaking such studies."
Ecology.
Algae are prominent in bodies of water, common in terrestrial environments and are found in unusual environments, such as on snow and on ice. Seaweeds grow mostly in shallow marine waters, under ; however, some have been recorded to a depth of .
The various sorts of algae play significant roles in aquatic ecology. Microscopic forms that live suspended in the water column (phytoplankton) provide the food base for most marine food chains. In very high densities (algal blooms) these algae may discolor the water and outcompete, poison, or asphyxiate other life forms.
Algae can be used as indicator organisms to monitor pollution in various aquatic systems. In many cases, algal metabolism is sensitive to various pollutants. Due to this, the species composition of algal populations may shift in the presence of chemical pollutants. To detect these changes, algae can be sampled from the environment and maintained in laboratories with relative ease.
On the basis of their habitat, algae can be categorized as: aquatic (planktonic, benthic, marine, freshwater), terrestrial, aerial (subareial),
Cultural associations.
In Classical Chinese, the word is used both for "algae" and (in the modest tradition of the imperial scholars) for "literary talent". The third island in Kunming Lake beside the Summer Palace in Beijing is known as the Zaojian Tang Dao which thus simultaneously means "Island of the Algae-Viewing Hall" and "Island of the Hall for Reflecting on Literary Talent".
Uses.
Agar.
Agar, a gelatinous substance derived from red algae, has a number of commercial uses. It is a good medium on which to grow bacteria and fungi as most microorganisms cannot digest agar.
Alginates.
Alginic acid, or alginate, is extracted from brown algae. Its uses range from gelling agents in food, to medical dressings. Alginic acid also has been used in the field of biotechnology as a biocompatible medium for cell encapsulation and cell immobilization. Molecular cuisine is also a user of the substance for its gelling properties, by which it becomes a delivery vehicle for flavours.
Between 100,000 and 170,000 wet tons of "Macrocystis" are harvested annually in New Mexico for alginate extraction and abalone feed.
Energy source.
To be competitive and independent from fluctuating support from (local) policy on the long run, biofuels should equal or beat the cost level of fossil fuels. Here, algae based fuels hold great promise, directly related to the potential to produce more biomass per unit area in a year than any other form of biomass. The break-even point for algae-based biofuels is estimated to occur by 2025.
Fertilizer.
For centuries, seaweed has been used as a fertilizer; George Owen of Henllys writing in the 16th century referring to drift weed in South Wales:This kind of ore they often gather and lay on great heapes, where it heteth and rotteth, and will have a strong and loathsome smell; when being so rotten they cast on the land, as they do their muck, and thereof springeth good corn, especially barley ... After spring-tydes or great rigs of the sea, they fetch it in sacks on horse backes, and carie the same three, four, or five miles, and cast it on the lande, which doth very much better the ground for corn and grass.
Today, algae are used by humans in many ways; for example, as fertilizers, soil conditioners and livestock feed. Aquatic and microscopic species are cultured in clear tanks or ponds and are either harvested or used to treat effluents pumped through the ponds. Algaculture on a large scale is an important type of aquaculture in some places. Maerl is commonly used as a soil conditioner.
Nutrition.
Naturally growing seaweeds are an important source of food, especially in Asia. They provide many vitamins including: A, B1, B2, B6, niacin and C, and are rich in iodine, potassium, iron, magnesium and calcium. In addition commercially cultivated microalgae, including both algae and cyanobacteria, are marketed as nutritional supplements, such as Spirulina, Chlorella and the Vitamin-C supplement, Dunaliella, high in beta-carotene.
Algae are national foods of many nations: China consumes more than 70 species, including "fat choy", a cyanobacterium considered a vegetable; Japan, over 20 species; Ireland, dulse; Chile, cochayuyo. Laver is used to make "laver bread" in Wales where it is known as "bara lawr"; in Korea, gim; in Japan, nori and aonori. It is also used along the west coast of North America from California to British Columbia, in Hawaii and by the Māori of New Zealand. Sea lettuce and badderlocks are a salad ingredient in Scotland, Ireland, Greenland and Iceland.
The oils from some algae have high levels of unsaturated fatty acids. For example, "Parietochloris incisa" is very high in arachidonic acid, where it reaches up to 47% of the triglyceride pool. Some varieties of algae favored by vegetarianism and veganism contain the long-chain, essential omega-3 fatty acids, docosahexaenoic acid (DHA) and eicosapentaenoic acid (EPA). Fish oil contains the omega-3 fatty acids, but the original source is algae (microalgae in particular), which are eaten by marine life such as copepods and are passed up the food chain. Algae have emerged in recent years as a popular source of omega-3 fatty acids for vegetarians who cannot get long-chain EPA and DHA from other vegetarian sources such as flaxseed oil, which only contains the short-chain alpha-linolenic acid (ALA).
Pollution control.
Agricultural Research Service scientists found that 60–90% of nitrogen runoff and 70–100% of phosphorus runoff can be captured from manure effluents using a horizontal algae scrubber, also called an algal turf scrubber (ATS). Scientists developed the ATS, which consists of shallow, 100-foot raceways of nylon netting where algae colonies can form, and studied its efficacy for three years. They found that algae can readily be used to reduce the nutrient runoff from agricultural fields and increase the quality of water flowing into rivers, streams, and oceans. Researchers collected and dried the nutrient-rich algae from the ATS and studied its potential as an organic fertilizer. They found that cucumber and corn seedlings grew just as well using ATS organic fertilizer as they did with commercial fertilizers. Algae scrubbers, using bubbling upflow or vertical waterfall versions, are now also being used to filter aquariums and ponds.
Bioremediation.
The alga "Stichococcus bacillaris", has been seen to colonize silicone resins used at archaeological sites; biodegrading the synthetic substance.
Pigments.
The natural pigments (carotenoids and chlorophylls) produced by algae can be used as an alternative to chemical dyes and coloring agents.
The presence of some individual alga pigments, together with specific pigment concentrations ratios, are taxon-specific: analysis of their concentrations with various analytical methods, particularly high-performance liquid chromatography (HPLC), can therefore offer deep insight into the taxonomic composition and relative abundance of natural alga populations in sea water samples.
Stabilizing substances.
Carrageenan, from the red alga "Chondrus crispus", is used as a stabilizer in milk products.

</doc>
<doc id="634" url="https://en.wikipedia.org/wiki?curid=634" title="Analysis of variance">
Analysis of variance

Analysis of variance (ANOVA) is a collection of statistical models used to analyze the differences among group means and their associated procedures (such as "variation" among and between groups), developed by statistician and evolutionary biologist Ronald Fisher. In the ANOVA setting, the observed variance in a particular variable is partitioned into components attributable to different sources of variation. In its simplest form, ANOVA provides a statistical test of whether or not the means of several groups are equal, and therefore generalizes the "t"-test to more than two groups. ANOVAs are useful for comparing (testing) three or more means (groups or variables) for statistical significance. It is conceptually similar to multiple two-sample t-tests, but is less conservative (results in less type I error) and is therefore suited to a wide range of practical problems.
History.
While the analysis of variance reached fruition in the 20th century, antecedents extend centuries into the past according to Stigler. These include hypothesis testing, the partitioning of sums of squares, experimental techniques and the additive model. Laplace was performing hypothesis testing in the 1770s. The development of least-squares methods by Laplace and Gauss circa 1800 provided an improved method of combining observations (over the existing practices of astronomy and geodesy). It also initiated much study of the contributions to sums of squares. Laplace soon knew how to estimate a variance from a residual (rather than a total) sum of squares. By 1827 Laplace was using least squares methods to address ANOVA problems regarding measurements of atmospheric tides. Before 1800 astronomers had isolated observational errors resulting 
from reaction times (the "personal equation") and had developed methods of reducing the errors. The experimental methods used in the study of the personal equation were later accepted by the emerging field of psychology which developed strong (full factorial) experimental methods to which randomization and blinding were soon added. An eloquent non-mathematical explanation of the additive effects model was
available in 1885.
Ronald Fisher introduced the term variance and proposed its formal analysis in a 1918 article "The Correlation Between Relatives on the Supposition of Mendelian Inheritance". His first application of the analysis of variance was published in 1921. Analysis of variance became widely known after being included in Fisher's 1925 book "Statistical Methods for Research Workers".
Randomization models were developed by several researchers. The first was published in Polish by Neyman in 1923.
One of the attributes of ANOVA which ensured its early popularity was computational elegance. The structure of the additive model allows solution for the additive coefficients by simple algebra rather than by matrix calculations. In the era of mechanical calculators this simplicity was critical. The determination of statistical significance also required access to tables of the F function which were supplied by early statistics texts.
Motivating example.
In the illustrations to the right, each group is identified as "X"1, "X"2, etc. In the first illustration, we divide the dogs according to the product (interaction) of two binary groupings: young vs old, and short-haired vs long-haired (thus, group 1 is young, short-haired dogs, group 2 is young, long-haired dogs, etc.). Since the distributions of dog weight within each of the groups (shown in blue) has a large variance, and since the means are very close across groups, grouping dogs by these characteristics does not produce an effective way to explain the variation in dog weights: knowing which group a dog is in does not allow us to make any reasonable statements as to what that dog's weight is likely to be. Thus, this grouping fails to "fit" the distribution we are trying to explain (yellow-orange).
An attempt to explain the weight distribution by grouping dogs as (pet vs working breed) and (less athletic vs more athletic) would probably be somewhat more successful (fair fit). The heaviest show dogs are likely to be big strong working breeds, while breeds kept as pets tend to be smaller and thus lighter. As shown by the second illustration, the distributions have variances that are considerably smaller than in the first case, and the means are more reasonably distinguishable. However, the significant overlap of distributions, for example, means that we cannot reliably say that "X"1 and "X"2 are truly distinct (i.e., it is perhaps reasonably likely that splitting dogs according to the flip of a coin—by pure chance—might produce distributions that look similar).
An attempt to explain weight by breed is likely to produce a very good fit. All Chihuahuas are light and all St Bernards are heavy. The difference in weights between Setters and Pointers does not justify separate breeds. The analysis of variance provides the formal tools to justify these intuitive judgments. A common use of the method is the analysis of experimental data or the development of models. The method has some advantages over correlation: not all of the data must be numeric and one result of the method is a judgment in the confidence in an explanatory relationship.
Background and terminology.
ANOVA is a particular form of statistical hypothesis testing heavily used in the analysis of experimental data. A test result (calculated from the null hypothesis and the sample) is called statistically significant if it is deemed unlikely to have occurred by chance, "assuming the truth of the null hypothesis". A statistically significant result, when a probability (p-value) is less than a threshold (significance level), justifies the rejection of the null hypothesis, but only if the a priori probability of the null hypothesis is not high.
In the typical application of ANOVA, the null hypothesis is that all groups are simply random samples of the same population. For example, when studying the effect of different treatments on similar samples of patients, the null hypothesis would be that all treatments have the same effect (perhaps none). Rejecting the null hypothesis would imply that different treatments result in altered effects.
By construction, hypothesis testing limits the rate of Type I errors (false positives) to a significance level. Experimenters also wish to limit Type II errors (false negatives). 
The rate of Type II errors depends largely on sample size (the rate will increase for small numbers of samples), significance 
level (when the standard of proof is high, the chances of overlooking 
a discovery are also high) and effect size (a smaller effect size is more prone to Type II error).
The terminology of ANOVA is largely from the statistical 
design of experiments. The experimenter adjusts factors and 
measures responses in an attempt to determine an effect. Factors are 
assigned to experimental units by a combination of randomization and 
blocking to ensure the validity of the results. Blinding keeps the
weighing impartial. Responses show a variability that is partially 
the result of the effect and is partially random error.
ANOVA is the synthesis of several ideas and it is used for multiple 
purposes. As a consequence, it is difficult to define concisely or precisely.
"Classical ANOVA for balanced data does three things at once:
In short, ANOVA is a statistical tool used in several ways to develop and confirm an explanation for the observed data.
Additionally:
As a result:
ANOVA "has long enjoyed the status of being the most used (some would 
say abused) statistical technique in psychological research."
ANOVA "is probably the most useful technique in the field of 
statistical inference."
ANOVA is difficult to teach, particularly for complex experiments, with split-plot designs being notorious. In some cases the proper 
application of the method is best determined by problem pattern recognition 
followed by the consultation of a classic authoritative test.
Design-of-experiments terms.
(Condensed from the NIST Engineering Statistics handbook: Section 5.7. A 
Glossary of DOE Terminology.)
Classes of models.
There are three classes of models used in the analysis of variance, and these are outlined here.
Fixed-effects models.
The fixed-effects model (class I) of analysis of variance applies to situations in which the experimenter applies one or more treatments to the subjects of the experiment to see whether the response variable values change. This allows the experimenter to estimate the ranges of response variable values that the treatment would generate in the population as a whole.
Random-effects models.
Random effects model (class II) is used when the treatments are not fixed. This occurs when the various factor levels are sampled from a larger population. Because the levels themselves are random variables, some assumptions and the method of contrasting the treatments (a multi-variable generalization of simple differences) differ from the fixed-effects model.
Mixed-effects models.
A mixed-effects model (class III) contains experimental factors of both fixed and random-effects types, with appropriately different interpretations and analysis for the two types.
Example:
Teaching experiments could be performed by a university department 
to find a good introductory textbook, with each text considered a 
treatment. The fixed-effects model would compare a list of candidate 
texts. The random-effects model would determine whether important 
differences exist among a list of randomly selected texts. The 
mixed-effects model would compare the (fixed) incumbent texts to 
randomly selected alternatives.
Defining fixed and random effects has proven elusive, with competing 
definitions arguably leading toward a linguistic quagmire.
Assumptions of ANOVA.
The analysis of variance has been studied from several approaches, the most common of which uses a linear model that relates the response to the treatments and blocks. Note that the model is linear in parameters but may be nonlinear across factor levels. Interpretation is easy when data is balanced across factors but much deeper understanding is needed for unbalanced data.
Textbook analysis using a normal distribution.
The analysis of variance can be presented in terms of a linear model, which makes the following assumptions about the probability distribution of the responses:
The separate assumptions of the textbook model imply that the errors are independently, identically, and normally distributed for fixed effects models, that is, that the errors (formula_1) are independent and
Randomization-based analysis.
In a randomized controlled experiment, the treatments are randomly assigned to experimental units, following the experimental protocol. This randomization is objective and declared before the experiment is carried out. The objective random-assignment is used to test the significance of the null hypothesis, following the ideas of C. S. Peirce and Ronald Fisher. This design-based analysis was discussed and developed by Francis J. Anscombe at Rothamsted Experimental Station and by Oscar Kempthorne at Iowa State University. Kempthorne and his students make an assumption of "unit treatment additivity", which is discussed in the books of Kempthorne and David R. Cox.
Unit-treatment additivity.
In its simplest form, the assumption of unit-treatment additivity states that the observed response formula_3 from experimental unit formula_4 when receiving treatment formula_5 can be written as the sum of the unit's response formula_6 and the treatment-effect formula_7, that is 
The assumption of unit-treatment additivity implies that, for every treatment formula_5, the formula_5th treatment has exactly the same effect formula_11 on every experiment unit.
The assumption of unit treatment additivity usually cannot be directly falsified, according to Cox and Kempthorne. However, many "consequences" of treatment-unit additivity can be falsified. For a randomized experiment, the assumption of unit-treatment additivity "implies" that the variance is constant for all treatments. Therefore, by contraposition, a necessary condition for unit-treatment additivity is that the variance is constant.
The use of unit treatment additivity and randomization is similar to the design-based inference that is standard in finite-population survey sampling.
Derived linear model.
Kempthorne uses the randomization-distribution and the assumption of "unit treatment additivity" to produce a "derived linear model", very similar to the textbook model discussed previously. The test statistics of this derived linear model are closely approximated by the test statistics of an appropriate normal linear model, according to approximation theorems and simulation studies. However, there are differences. For example, the randomization-based analysis results in a small but (strictly) negative correlation between the observations. In the randomization-based analysis, there is "no assumption" of a "normal" distribution and certainly "no assumption" of "independence". On the contrary, "the observations are dependent"!
The randomization-based analysis has the disadvantage that its exposition involves tedious algebra and extensive time. Since the randomization-based analysis is complicated and is closely approximated by the approach using a normal linear model, most teachers emphasize the normal linear model approach. Few statisticians object to model-based analysis of balanced randomized experiments.
Statistical models for observational data.
However, when applied to data from non-randomized experiments or observational studies, model-based analysis lacks the warrant of randomization. For observational data, the derivation of confidence intervals must use "subjective" models, as emphasized by Ronald Fisher and his followers. In practice, the estimates of treatment-effects from observational studies generally are often inconsistent. In practice, "statistical models" and observational data are useful for suggesting hypotheses that should be treated very cautiously by the public.
Summary of assumptions.
The normal-model based ANOVA analysis assumes the independence, normality and 
homogeneity of the variances of the residuals. The 
randomization-based analysis assumes only the homogeneity of the 
variances of the residuals (as a consequence of unit-treatment 
additivity) and uses the randomization procedure of the experiment. 
Both these analyses require homoscedasticity, as an assumption for the normal-model analysis and as a consequence of randomization and additivity for the randomization-based analysis.
However, studies of processes that 
change variances rather than means (called dispersion effects) have 
been successfully conducted using ANOVA. There are
"no" necessary assumptions for ANOVA in its full generality, but the
F-test used for ANOVA hypothesis testing has assumptions and practical 
limitations which are of continuing interest.
Problems which do not satisfy the assumptions of ANOVA can often be transformed to satisfy the assumptions. 
The property of unit-treatment additivity is not invariant under a "change of scale", so statisticians often use transformations to achieve unit-treatment additivity. If the response variable is expected to follow a parametric family of probability distributions, then the statistician may specify (in the protocol for the experiment or observational study) that the responses be transformed to stabilize the variance. Also, a statistician may specify that logarithmic transforms be applied to the responses, which are believed to follow a multiplicative model.
According to Cauchy's functional equation theorem, the logarithm is the only continuous transformation that transforms real multiplication to addition.
Characteristics of ANOVA.
ANOVA is used in the analysis of comparative experiments, those in 
which only the difference in outcomes is of interest. The statistical
significance of the experiment is determined by a ratio of two 
variances. This ratio is independent of several possible alterations
to the experimental observations: Adding a constant to all 
observations does not alter significance. Multiplying all 
observations by a constant does not alter significance. So ANOVA 
statistical significance result is independent of constant bias and 
scaling errors as well as the units used in expressing observations. 
In the era of mechanical calculation it was common to 
subtract a constant from all observations (when equivalent to 
dropping leading digits) to simplify data entry. This is an example of data
coding.
Logic of ANOVA.
The calculations of ANOVA can be characterized as computing a number
of means and variances, dividing two variances and comparing the ratio 
to a handbook value to determine statistical significance. Calculating 
a treatment effect is then trivial, "the effect of any treatment is 
estimated by taking the difference between the mean of the 
observations which receive the treatment and the general mean."
Partitioning of the sum of squares.
ANOVA uses traditional standardized terminology. The definitional 
equation of sample variance is
formula_12, where the 
divisor is called the degrees of freedom (DF), the summation is called 
the sum of squares (SS), the result is called the mean square (MS) and 
the squared terms are deviations from the sample mean. ANOVA 
estimates 3 sample variances: a total variance based on all the 
observation deviations from the grand mean, an error variance based on 
all the observation deviations from their appropriate 
treatment means and a treatment variance. The treatment variance is
based on the deviations of treatment means from the grand mean, the 
result being multiplied by the number of observations in each 
treatment to account for the difference between the variance of 
observations and the variance of means.
The fundamental technique is a partitioning of the total sum of squares "SS" into components related to the effects used in the model. For example, the model for a simplified ANOVA with one type of treatment at different levels.
The number of degrees of freedom "DF" can be partitioned in a similar way: one of these components (that for error) specifies a chi-squared distribution which describes the associated sum of squares, while the same is true for "treatments" if there is no treatment effect.
See also Lack-of-fit sum of squares.
The F-test.
The F-test is used for comparing the factors of the total deviation. For example, in one-way, or single-factor ANOVA, statistical significance is tested for by comparing the F test statistic
where "MS" is mean square, formula_17 = number of treatments and 
formula_18 = total number of cases
to the F-distribution with formula_19, formula_20 degrees of freedom. Using the F-distribution is a natural candidate because the test statistic is the ratio of two scaled sums of squares each of which follows a scaled chi-squared distribution.
The expected value of F is formula_21 (where n is the treatment sample size)
which is 1 for no treatment effect. As values of F increase above 1, the evidence is increasingly inconsistent with the null hypothesis. Two apparent experimental methods of increasing F are increasing the sample size and reducing the error variance by tight experimental controls.
There are two methods of concluding the ANOVA hypothesis test, both of which produce the same result:
The ANOVA F-test is known to be nearly optimal in the sense of minimizing false negative errors for a fixed rate of false positive errors (i.e. maximizing power for a fixed significance level). For example, to test the hypothesis that various medical treatments have exactly the same effect, the F-test's p-values closely approximate the permutation test's p-values: The approximation is particularly close when the design is balanced. Such permutation tests characterize tests with maximum power against all alternative hypotheses, as observed by Rosenbaum. The ANOVA F–test (of the null-hypothesis that all treatments have exactly the same effect) is recommended as a practical test, because of its robustness against many alternative distributions.
Extended logic.
ANOVA consists of separable parts; partitioning sources of variance 
and hypothesis testing can be used individually. ANOVA is used to 
support other statistical tools. Regression is first used to fit more 
complex models to data, then ANOVA is used to compare models with the 
objective of selecting simple(r) models that adequately describe the 
data. "Such models could be fit without any reference to ANOVA, but 
ANOVA tools could then be used to make some sense of the fitted models, 
and to test hypotheses about batches of coefficients." 
"e think of the analysis of variance as a way of understanding and structuring 
multilevel models—not as an alternative to regression but as a tool 
for summarizing complex high-dimensional inferences ..."
ANOVA for a single factor.
The simplest experiment suitable for ANOVA analysis is the completely 
randomized experiment with a single factor. More complex experiments 
with a single factor involve constraints on randomization and include 
completely randomized blocks and Latin squares (and variants: 
Graeco-Latin squares, etc.). The more complex experiments share many 
of the complexities of multiple factors. A relatively complete 
discussion of the analysis (models, data summaries, ANOVA table) of 
the completely randomized experiment is 
available.
ANOVA for multiple factors.
ANOVA generalizes to the study of the effects of multiple factors. 
When the experiment includes observations at all combinations of 
levels of each factor, it is termed factorial. 
Factorial experiments 
are more efficient than a series of single factor experiments and the 
efficiency grows as the number of factors increases. Consequently, factorial designs are heavily used.
The use of ANOVA to study the effects of multiple factors has a complication. In a 3-way ANOVA with factors x, y and z, the ANOVA model includes terms for the main effects (x, y, z) and terms for interactions (xy, xz, yz, xyz). 
All terms require hypothesis tests. The proliferation of interaction terms increases the risk that some hypothesis test will produce a false positive by chance. Fortunately, experience says that high order interactions are rare. 
The ability to detect interactions is a major advantage of multiple 
factor ANOVA. Testing one factor at a time hides interactions, but 
produces apparently inconsistent experimental results.
Caution is advised when encountering interactions; Test 
interaction terms first and expand the analysis beyond ANOVA if 
interactions are found. Texts vary in their recommendations regarding 
the continuation of the ANOVA procedure after encountering an 
interaction. Interactions complicate the interpretation of 
experimental data. Neither the calculations of significance nor the 
estimated treatment effects can be taken at face value. "A 
significant interaction will often mask the significance of main effects." Graphical methods are recommended
to enhance understanding. Regression is often useful. A lengthy discussion of interactions is available in Cox (1958). Some interactions can be removed (by transformations) while others cannot.
A variety of techniques are used with multiple factor ANOVA to reduce expense. One technique used in factorial designs is to minimize replication (possibly no replication with support of analytical trickery) and to combine groups when effects are found to be statistically (or practically) insignificant. An experiment with many insignificant factors may collapse into one with a few factors supported by many replications.
Worked numeric examples.
Several fully worked numerical examples are available. A 
simple case uses one-way (a single factor) analysis. A more complex case uses two-way (two-factor) analysis.
Associated analysis.
Some analysis is required in support of the "design" of the experiment while other analysis is performed after changes in the factors are formally found to produce statistically significant changes in the responses. Because experimentation is iterative, the results of one experiment alter plans for following experiments.
Preparatory analysis.
The number of experimental units.
In the design of an experiment, the number of experimental units is planned to satisfy the goals of the experiment. Experimentation is often sequential.
Early experiments are often designed to provide mean-unbiased estimates of treatment effects and of experimental error. Later experiments are often designed to test a hypothesis that a treatment effect has an important magnitude; in this case, the number of experimental units is chosen so that the experiment is within budget and has adequate power, among other goals.
Reporting sample size analysis is generally required in psychology. "Provide information on sample size and the process that led to sample size decisions." The analysis, which is written in the experimental protocol before the experiment is conducted, is examined in grant applications and administrative review boards.
Besides the power analysis, there are less formal methods for selecting the number of experimental units. These include graphical methods based on limiting
the probability of false negative errors, graphical methods based on an expected variation increase (above the residuals) and methods based on achieving a desired confident interval.
Power analysis.
Power analysis is often applied in the context of ANOVA in order to assess the probability of successfully rejecting the null hypothesis if we assume a certain ANOVA design, effect size in the population, sample size and significance level. Power analysis can assist in study design by determining what sample size would be required in order to have a reasonable chance of rejecting the null hypothesis when the alternative hypothesis is true.
Effect size.
Several standardized measures of effect have been proposed for ANOVA to summarize the strength of the association between a predictor(s) and the dependent variable (e.g., η2, ω2, or ƒ2) or the overall standardized difference (Ψ) of the complete model. Standardized effect-size estimates facilitate comparison of findings across studies and disciplines. However, while standardized effect sizes are commonly used in much of the professional literature, a non-standardized measure of effect size that has immediately "meaningful" units may be preferable for reporting purposes.
Follow-up analysis.
It is always appropriate to carefully consider outliers. They have a disproportionate impact on statistical conclusions and are often the result of errors.
Model confirmation.
It is prudent to verify that the assumptions of ANOVA have been met. Residuals are examined or analyzed to confirm homoscedasticity and gross normality. Residuals should have the appearance of (zero mean normal distribution) noise when plotted as a function of anything including time and 
modeled data values. Trends hint at interactions among factors or among observations. One rule of thumb: "If the largest standard deviation is less than twice the smallest standard deviation, we can use methods based on the assumption of equal standard deviations and our results 
will still be approximately correct."
Follow-up tests.
A statistically significant effect in ANOVA is often followed up with one or more different follow-up tests. This can be done in order to assess which groups are different from which other groups or to test various other focused hypotheses. Follow-up tests are often distinguished in terms of whether they are planned (a priori) or post hoc. Planned tests are determined before looking at the data and post hoc tests are performed after looking at the data.
Often one of the "treatments" is none, so the treatment group can act as a control. Dunnett's test (a modification of the t-test) tests whether each of the other treatment groups has the same 
mean as the control.
Post hoc tests such as Tukey's range test most commonly compare every group mean with every other group mean and typically incorporate some method of controlling for Type I errors. Comparisons, which are most commonly planned, can be either simple or compound. Simple comparisons compare one group mean with one other group mean. Compound comparisons typically compare two sets of groups means where one set has two or more groups (e.g., compare average group means of group A, B and C with group D). Comparisons can also look at tests of trend, such as linear and quadratic relationships, when the independent variable involves ordered levels.
Following ANOVA with pair-wise multiple-comparison tests has been criticized on several grounds. There are many such tests (10 in one table) and recommendations regarding their use are vague or conflicting.
Study designs and ANOVAs.
There are several types of ANOVA. Many statisticians base ANOVA on the design of the experiment, especially on the protocol that specifies the random assignment of treatments to subjects; the protocol's description of the assignment mechanism should include a specification of the structure of the treatments and of any blocking. It is also common to apply ANOVA to observational data using an appropriate statistical model.
Some popular designs use the following types of ANOVA:
ANOVA cautions.
Balanced experiments (those with an equal sample size for each treatment) are relatively easy to interpret; Unbalanced 
experiments offer more complexity. For single factor (one way) ANOVA, the adjustment for unbalanced data is easy, but the unbalanced analysis lacks both robustness and power. For more complex designs the lack of balance leads to further complications. "The orthogonality property of main effects and interactions present in balanced data does not carry over to the unbalanced case. This means that the usual analysis of variance techniques do not apply. 
Consequently, the analysis of unbalanced factorials is much more difficult than that for balanced designs." In the general case, "The analysis of variance can also be applied to unbalanced data, but then the sums of squares, mean squares, and F-ratios will depend on the order in which the sources of variation 
are considered." The simplest techniques for handling unbalanced data restore balance by either throwing out data or by synthesizing missing data. More complex techniques use regression.
ANOVA is (in part) a significance test. The American Psychological Association holds the view that simply reporting significance is insufficient and that reporting confidence bounds is preferred.
While ANOVA is conservative (in maintaining a significance level) against multiple comparisons in one dimension, it is not conservative against comparisons in multiple dimensions.
Generalizations.
ANOVA is considered to be a special case of linear regression which in turn is a special case of the general linear model. All consider the observations to be the sum of a model (fit) and a residual (error) to be minimized.
The Kruskal–Wallis test and the Friedman test are nonparametric tests, which do not rely on an assumption of normality.
Connection to Linear Regression.
Below we make clear the connection between multi-way ANOVA and linear regression. Linearly re-order the data so that formula_22 observation is associated with a response formula_23 and factors formula_24 where formula_25 denotes the different factors and formula_26 is the total number of factors. In one-way ANOVA formula_27 and in two-way ANOVA formula_28. Furthermore, we assume the formula_29 factor has formula_30 levels. Now, we can one-hot encode the factors into the formula_31 dimensional vector formula_32.
The one-hot encoding function formula_33 is defined such that the formula_34 entry of formula_35 is
formula_36
The vector formula_32 is the concatenation of all of the above vectors for all formula_38. Thus, formula_39. In order to obtain a fully general formula_26-way interaction ANOVA we must also concatenate every additional interaction term in the vector formula_32 and then add an intercept term. Let that vector be formula_42.
With this notation in place, we now have the exact connection with linear regression. We simply regress response formula_23 against the vector formula_44. However, there is a concern about identifiability. In order to overcome such issues we assume that the sum of the parameters within each set of interactions is equal to zero. From here, one can use F-statistics or other methods to determine the relevance of the individual factors.
Example.
We can consider the 2-way interaction example where we assume that the first factor has 2 levels and the second factor has 3 levels.
Define formula_45 if formula_46 and formula_47 if formula_48, i.e. formula_49 is the one-hot encoding of the first factor and formula_38 is the one-hot encoding of the second factor.
With that,
formula_51
where the last term is an intercept term. For a more concrete example suppose that
formula_52
Then,
formula_53

</doc>
<doc id="639" url="https://en.wikipedia.org/wiki?curid=639" title="Alkane">
Alkane

In organic chemistry, an alkane, or paraffin (a historical name that also has other meanings), is a saturated hydrocarbon. Alkanes consist only of hydrogen and carbon atoms and all bonds are single bonds. Alkanes (technically, always acyclic or open-chain compounds) have the general chemical formula "n"2"n"+2. For example, methane is CH4, in which "n" = 1 ("n" being the number of carbon atoms). Alkanes belong to a homologous series of organic compounds in which the members differ by a molecular mass of 14.03 u (mass of a methylene group, —CH2—, one carbon atom of mass 12.01 u, and two hydrogen atoms of mass ~1.01 u each). There are two main commercial sources: petroleum (crude oil) and natural gas.
Each carbon atom has 4 bonds (either C–H or C–C bonds), and each hydrogen atom is joined to a carbon atom (H–C bonds). A series of linked carbon atoms is known as the carbon skeleton or carbon backbone. The number of carbon atoms is used to define the size of the alkane e.g., C2 alkane.
An alkyl group, generally abbreviated with the symbol R, is a functional group or side-chain that, like an alkane, consists solely of single-bonded carbon and hydrogen atoms, for example a methyl or ethyl group.
The simplest possible alkane (the parent molecule) is methane, CH4. There is no limit to the number of carbon atoms that can be linked together, the only limitation being that the molecule is acyclic, is saturated, and is a hydrocarbon. Waxes include examples of larger alkanes where the number of carbons in the carbon backbone is greater than about 17, above which the compounds are solids at standard ambient temperature and pressure (SATP).
Alkanes are not very reactive and have little biological activity. Alkanes can be viewed as a molecular tree upon which can be hung the more active/reactive functional groups of biological molecules.
Structure classification.
Saturated hydrocarbons are hydrocarbons having only single covalent bonds between their carbons. They can be:
According to the definition by IUPAC, the former two are alkanes, whereas the third group is called cycloalkanes. Saturated hydrocarbons can also combine any of the linear, cyclic (e.g., polycyclic) and branching structures; the general formula is , where "k" is the number of independent loops. Alkanes are the acyclic (loopless) ones, corresponding to "k" = 0.
Isomerism.
Alkanes with more than three carbon atoms can be arranged in various different ways, forming structural isomers. The simplest isomer of an alkane is the one in which the carbon atoms are arranged in a single chain with no branches. This isomer is sometimes called the "n"-isomer ("n" for "normal", although it is not necessarily the most common). However the chain of carbon atoms may also be branched at one or more points. The number of possible isomers increases rapidly with the number of carbon atoms. For example:
Branched alkanes can be chiral. For example, 3-methylhexane and its higher homologues are chiral due to their stereogenic center at carbon atom number 3. In addition to the alkane isomers, the chain of carbon atoms may form one or more loops. Such compounds are called cycloalkanes.
Nomenclature.
The IUPAC nomenclature (systematic way of naming compounds) for alkanes is based on identifying hydrocarbon chains. Unbranched, saturated hydrocarbon chains are named systematically with a Greek numerical prefix denoting the number of carbons and the suffix "-ane".
In 1866, August Wilhelm von Hofmann suggested systematizing nomenclature by using the whole sequence of vowels a, e, i, o and u to create suffixes -ane, -ene, -ine (or -yne), -one, -une, for the hydrocarbons CnH2"n"+2, CnH2"n", CnH2"n"−2, CnH2"n"−4, CnH2"n"−6. Now, the first three name hydrocarbons with single, double and triple bonds; "-one" represents a ketone; "-ol" represents an alcohol or OH group; "-oxy-" means an ether and refers to oxygen between two carbons, so that methoxymethane is the IUPAC name for dimethyl ether.
It is difficult or impossible to find compounds with more than one IUPAC name. This is because shorter chains attached to longer chains are prefixes and the convention includes brackets. Numbers in the name, referring to which carbon a group is attached to, should be as low as possible, so that 1- is implied and usually omitted from names of organic compounds with only one side-group. Symmetric compounds will have two ways of arriving at the same name.
Linear alkanes.
Straight-chain alkanes are sometimes indicated by the prefix ""n"-" (for "normal") where a non-linear isomer exists. Although this is not strictly necessary, the usage is still common in cases where there is an important difference in properties between the straight-chain and branched-chain isomers, e.g., "n"-hexane or 2- or 3-methylpentane. Alternative names for this group are: linear paraffins or "n"-paraffins.
The members of the series (in terms of number of carbon atoms) are named as follows:
The first four names were derived from methanol, ether, propionic acid and butyric acid, respectively. Alkanes with five or more carbon atoms are named by adding the suffix -ane to the appropriate numerical multiplier prefix with elision of any terminal vowel ("-a" or "-o") from the basic numerical term. Hence, pentane, C5H12; hexane, C6H14; heptane, C7H16; octane, C8H18; etc. The prefix is generally Greek, however alkanes with a carbon atom count ending in nine, for example nonane, use the Latin prefix non-. For a more complete list, see List of alkanes.
Branched alkanes.
Simple branched alkanes often have a common name using a prefix to distinguish them from linear alkanes, for example "n"-pentane, isopentane, and neopentane.
IUPAC naming conventions can be used to produce a systematic name.
The key steps in the naming of more complicated branched alkanes are as follows:
Cyclic alkanes.
So-called cyclic alkanes are, in the technical sense, not a subset of alkanes, but are cycloalkanes instead. They are hydrocarbons just like alkanes, but contain one or more rings.
Simple cycloalkanes have a prefix "cyclo-" to distinguish them from alkanes. Cycloalkanes are named as per their acyclic counterparts with respect to the number of carbon atoms, e.g., cyclopentane (C5H10) is a cycloalkane with 5 carbon atoms just like pentane (C5H12), but they are joined up in a five-membered ring. In a similar manner, propane and cyclopropane, butane and cyclobutane, etc.
Substituted cycloalkanes are named similarly to substituted alkanes — the cycloalkane ring is stated, and the substituents are according to their position on the ring, with the numbering decided by the Cahn–Ingold–Prelog priority rules.
Trivial/common names.
The trivial (non-systematic) name for alkanes is "paraffins". Together, alkanes are known as the "paraffin series". Trivial names for compounds are usually historical artifacts. They were coined before the development of systematic names, and have been retained due to familiar usage in industry. Cycloalkanes are also called naphthenes.
It is almost certain that the term "paraffin" stems from the petrochemical industry. Branched-chain alkanes are called "isoparaffins". The use of the term "paraffin" is a general term and often does not distinguish between pure compounds and mixtures of isomers, i.e., compounds with the same chemical formula, e.g., pentane and isopentane.
The following trivial names are retained in the IUPAC system:
Physical properties.
All alkanes are colourless and odourless.
Boiling point.
Alkanes experience intermolecular van der Waals forces. Stronger intermolecular van der Waals forces give rise to greater boiling points of alkanes.
There are two determinants for the strength of the van der Waals forces:
Under standard conditions, from CH4 to C4H10 alkanes are gaseous; from C5H12 to C17H36 they are liquids; and after C18H38 they are solids. As the boiling point of alkanes is primarily determined by weight, it should not be a surprise that the boiling point has almost a linear relationship with the size (molecular weight) of the molecule. As a rule of thumb, the boiling point rises 20–30 °C for each carbon added to the chain; this rule applies to other homologous series.
A straight-chain alkane will have a boiling point higher than a branched-chain alkane due to the greater surface area in contact, thus the greater van der Waals forces, between adjacent molecules. For example, compare isobutane (2-methylpropane) and n-butane (butane), which boil at −12 and 0 °C, and 2,2-dimethylbutane and 2,3-dimethylbutane which boil at 50 and 58 °C, respectively. For the latter case, two molecules 2,3-dimethylbutane can "lock" into each other better than the cross-shaped 2,2-dimethylbutane, hence the greater van der Waals forces.
On the other hand, cycloalkanes tend to have higher boiling points than their linear counterparts due to the locked conformations of the molecules, which give a plane of intermolecular contact.
Melting points.
The melting points of the alkanes follow a similar trend to boiling points for the same reason as outlined above. That is, (all other things being equal) the larger the molecule the higher the melting point. There is one significant difference between boiling points and melting points. Solids have more rigid and fixed structure than liquids. This rigid structure requires energy to break down. Thus the better put together solid structures will require more energy to break apart. For alkanes, this can be seen from the graph above (i.e., the blue line). The odd-numbered alkanes have a lower trend in melting points than even numbered alkanes. This is because even numbered alkanes pack well in the solid phase, forming a well-organized structure, which requires more energy to break apart. The odd-numbered alkanes pack less well and so the "looser" organized solid packing structure requires less energy to break apart.
The melting points of branched-chain alkanes can be either higher or lower than those of the corresponding straight-chain alkanes, again depending on the ability of the alkane in question to pack well in the solid phase: This is particularly true for isoalkanes (2-methyl isomers), which often have melting points higher than those of the linear analogues.
Conductivity and solubility.
Alkanes do not conduct electricity, nor are they substantially polarized by an electric field. For this reason they do not form hydrogen bonds and are insoluble in polar solvents such as water. Since the hydrogen bonds between individual water molecules are aligned away from an alkane molecule, the coexistence of an alkane and water leads to an increase in molecular order (a reduction in entropy). As there is no significant bonding between water molecules and alkane molecules, the second law of thermodynamics suggests that this reduction in entropy should be minimized by minimizing the contact between alkane and water: Alkanes are said to be hydrophobic in that they repel water.
Their solubility in nonpolar solvents is relatively good, a property that is called lipophilicity. Different alkanes are, for example, miscible in all proportions among themselves.
The density of the alkanes usually increases with the number of carbon atoms, but remains less than that of water. Hence, alkanes form the upper layer in an alkane–water mixture.
Molecular geometry.
The molecular structure of the alkanes directly affects their physical and chemical characteristics. It is derived from the electron configuration of carbon, which has four valence electrons. The carbon atoms in alkanes are always sp3 hybridized, that is to say that the valence electrons are said to be in four equivalent orbitals derived from the combination of the 2s orbital and the three 2p orbitals. These orbitals, which have identical energies, are arranged spatially in the form of a tetrahedron, the angle of cos−1(−) ≈ 109.47° between them.
Bond lengths and bond angles.
An alkane molecule has only C–H and C–C single bonds. The former result from the overlap of an sp3 orbital of carbon with the 1s orbital of a hydrogen; the latter by the overlap of two sp3 orbitals on different carbon atoms. The bond lengths amount to 1.09 × 10−10 m for a C–H bond and 1.54 × 10−10 m for a C–C bond.
The spatial arrangement of the bonds is similar to that of the four sp3 orbitals—they are tetrahedrally arranged, with an angle of 109.47° between them. Structural formulae that represent the bonds as being at right angles to one another, while both common and useful, do not correspond with the reality.
Conformation.
The structural formula and the bond angles are not usually sufficient to completely describe the geometry of a molecule. There is a further degree of freedom for each carbon–carbon bond: the torsion angle between the atoms or groups bound to the atoms at each end of the bond. The spatial arrangement described by the torsion angles of the molecule is known as its conformation.
Ethane forms the simplest case for studying the conformation of alkanes, as there is only one C–C bond. If one looks down the axis of the C–C bond, one will see the so-called Newman projection. The hydrogen atoms on both the front and rear carbon atoms have an angle of 120° between them, resulting from the projection of the base of the tetrahedron onto a flat plane. However, the torsion angle between a given hydrogen atom attached to the front carbon and a given hydrogen atom attached to the rear carbon can vary freely between 0° and 360°. This is a consequence of the free rotation about a carbon–carbon single bond. Despite this apparent freedom, only two limiting conformations are important: eclipsed conformation and staggered conformation.
The two conformations, also known as rotamers, differ in energy: The staggered conformation is 12.6 kJ/mol lower in energy (more stable) than the eclipsed conformation (the least stable).
This difference in energy between the two conformations, known as the torsion energy, is low compared to the thermal energy of an ethane molecule at ambient temperature. There is constant rotation about the C–C bond. The time taken for an ethane molecule to pass from one staggered conformation to the next, equivalent to the rotation of one CH3 group by 120° relative to the other, is of the order of 10−11 seconds.
The case of higher alkanes is more complex but based on similar principles, with the antiperiplanar conformation always being the most favored around each carbon–carbon bond. For this reason, alkanes are usually shown in a zigzag arrangement in diagrams or in models. The actual structure will always differ somewhat from these idealized forms, as the differences in energy between the conformations are small compared to the thermal energy of the molecules: Alkane molecules have no fixed structural form, whatever the models may suggest.
Spectroscopic properties.
Virtually all organic compounds contain carbon–carbon and carbon–hydrogen bonds, and so show some of the features of alkanes in their spectra. Alkanes are notable for having no other groups, and therefore for the "absence" of other characteristic spectroscopic features of different functional group like –OH, –CHO, –COOH etc.
Infrared spectroscopy.
The carbon–hydrogen stretching mode gives a strong absorption between 2850 and 2960 cm−1, while the carbon–carbon stretching mode absorbs between 800 and 1300 cm−1. The carbon–hydrogen bending modes depend on the nature of the group: methyl groups show bands at 1450 cm−1 and 1375 cm−1, while methylene groups show bands at 1465 cm−1 and 1450 cm−1. Carbon chains with more than four carbon atoms show a weak absorption at around 725 cm−1.
NMR spectroscopy.
The proton resonances of alkanes are usually found at "δ"H = 0.5–1.5. The carbon-13 resonances depend on the number of hydrogen atoms attached to the carbon: "δ"C = 8–30 (primary, methyl, –CH3), 15–55 (secondary, methylene, –CH2–), 20–60 (tertiary, methyne, C–H) and quaternary. The carbon-13 resonance of quaternary carbon atoms is characteristically weak, due to the lack of nuclear Overhauser effect and the long relaxation time, and can be missed in weak samples, or samples that have not been run for a sufficiently long time.
Mass spectrometry.
Alkanes have a high ionization energy, and the molecular ion is usually weak. The fragmentation pattern can be difficult to interpret, but, in the case of branched chain alkanes, the carbon chain is preferentially cleaved at tertiary or quaternary carbons due to the relative stability of the resulting free radicals. The fragment resulting from the loss of a single methyl group ("M" − 15) is often absent, and other fragment are often spaced by intervals of fourteen mass units, corresponding to sequential loss of CH2 groups.
Chemical properties.
Alkanes are only weakly reactive with ionic and other polar substances. The acid dissociation constant (pKa) values of all alkanes are above 60, hence they are practically inert to acids and bases (see: carbon acids). This inertness is the source of the term "paraffins" (with the meaning here of "lacking affinity"). In crude oil the alkane molecules have remained chemically unchanged for millions of years.
However redox reactions of alkanes, in particular with oxygen and the halogens, are possible as the carbon atoms are in a strongly reduced condition; in the case of methane, the lowest possible oxidation state for carbon (−4) is reached. Reaction with oxygen ("if" present in sufficient quantity to satisfy the reaction stoichiometry) leads to combustion without any smoke, producing carbon dioxide and water. Free radical halogenation reactions occur with halogens, leading to the production of haloalkanes. In addition, alkanes have been shown to interact with, and bind to, certain transition metal complexes in C–H bond activation.
Free radicals, molecules with unpaired electrons, play a large role in most reactions of alkanes, such as cracking and reformation where long-chain alkanes are converted into shorter-chain alkanes and straight-chain alkanes into branched-chain isomers.
In highly branched alkanes, the bond angle may differ significantly from the optimal value (109.5°) in order to allow the different groups sufficient space. This causes a tension in the molecule, known as steric hindrance, and can substantially increase the reactivity.
Reactions with oxygen (combustion reaction).
All alkanes react with oxygen in a combustion reaction, although they become increasingly difficult to ignite as the number of carbon atoms increases. The general equation for complete combustion is:
In the absence of sufficient oxygen, carbon monoxide or even soot can be formed, as shown below:
For example, methane:
See the alkane heat of formation table for detailed data.
The standard enthalpy change of combustion, Δc"H"o, for alkanes increases by about 650 kJ/mol per CH2 group. Branched-chain alkanes have lower values of Δc"H"o than straight-chain alkanes of the same number of carbon atoms, and so can be seen to be somewhat more stable.
Reactions with halogens.
Alkanes react with halogens in a so-called "free radical halogenation" reaction. The hydrogen atoms of the alkane are progressively replaced by halogen atoms. Free radicals are the reactive species that participate in the reaction, which usually leads to a mixture of products. The reaction is highly exothermic, and can lead to an explosion.
These reactions are an important industrial route to halogenated hydrocarbons. There are three steps:
Experiments have shown that all halogenation produces a mixture of all possible isomers, indicating that all hydrogen atoms are susceptible to reaction. The mixture produced, however, is not a statistical mixture: Secondary and tertiary hydrogen atoms are preferentially replaced due to the greater stability of secondary and tertiary free-radicals. An example can be seen in the monobromination of propane:
Cracking.
Cracking breaks larger molecules into smaller ones. This can be done with a thermal or catalytic method. The thermal cracking process follows a homolytic mechanism with formation of free-radicals. The catalytic cracking process involves the presence of acid catalysts (usually solid acids such as silica-alumina and zeolites), which promote a heterolytic (asymmetric) breakage of bonds yielding pairs of ions of opposite charges, usually a carbocation and the very unstable hydride anion. Carbon-localized free radicals and cations are both highly unstable and undergo processes of chain rearrangement, C–C scission in position beta (i.e., cracking) and intra- and intermolecular hydrogen transfer or hydride transfer. In both types of processes, the corresponding reactive intermediates (radicals, ions) are permanently regenerated, and thus they proceed by a self-propagating chain mechanism. The chain of reactions is eventually terminated by radical or ion recombination.
Isomerization and reformation.
Dragan and his colleague were the first to report about isomerization in alkanes. Isomerization and reformation are processes in which straight-chain alkanes are heated in the presence of a platinum catalyst. In isomerization, the alkanes become branched-chain isomers. In other words, it does not lose any carbons or hydrogens, keeping the same molecular weight. In reformation, the alkanes become cycloalkanes or aromatic hydrocarbons, giving off hydrogen as a by-product. Both of these processes raise the octane number of the substance. Butane is the most common alkane that is put under the process of isomerization, as it makes many branched alkanes with high octane numbers.
Other reactions.
Alkanes will react with steam in the presence of a nickel catalyst to give hydrogen. Alkanes can be chlorosulfonated and nitrated, although both reactions require special conditions. The fermentation of alkanes to carboxylic acids is of some technical importance. In the Reed reaction, sulfur dioxide, chlorine and light convert hydrocarbons to sulfonyl chlorides. Nucleophilic Abstraction can be used to separate an alkane from a metal. Alkyl groups can be transferred from one compound to another by transmetalation reactions.
Occurrence.
Occurrence of alkanes in the Universe.
Alkanes form a small portion of the atmospheres of the outer gas planets such as Jupiter (0.1% methane, 2 ppm ethane), Saturn (0.2% methane, 5 ppm ethane), Uranus (1.99% methane, 2.5 ppm ethane) and Neptune (1.5% methane, 1.5 ppm ethane). Titan (1.6% methane), a satellite of Saturn, was examined by the "Huygens" probe, which indicated that Titan's atmosphere periodically rains liquid methane onto the moon's surface. Also on Titan the Cassini mission has imaged seasonal methane/ethane lakes near the polar regions of Titan. Methane and ethane have also been detected in the tail of the comet Hyakutake. Chemical analysis showed that the abundances of ethane and methane were roughly equal, which is thought to imply that its ices formed in interstellar space, away from the Sun, which would have evaporated these volatile molecules. Alkanes have also been detected in meteorites such as carbonaceous chondrites.
Occurrence of alkanes on Earth.
Traces of methane gas (about 0.0002% or 1745 ppb) occur in the Earth's atmosphere, produced primarily by methanogenic microorganisms, such as Archaea in the gut of ruminants.
The most important commercial sources for alkanes are natural gas and oil. Natural gas contains primarily methane and ethane, with some propane and butane: oil is a mixture of liquid alkanes and other hydrocarbons. These hydrocarbons were formed when marine animals and plants (zooplankton and phytoplankton) died and sank to the bottom of ancient seas and were covered with sediments in an anoxic environment and converted over many millions of years at high temperatures and high pressure to their current form. Natural gas resulted thereby for example from the following reaction:
These hydrocarbon deposits, collected in porous rocks trapped beneath impermeable cap rocks, comprise commercial oil fields. They have formed over millions of years and once exhausted cannot be readily replaced. The depletion of these hydrocarbons reserves is the basis for what is known as the energy crisis.
Methane is also present in what is called biogas, produced by animals and decaying matter, which is a possible renewable energy source.
Alkanes have a low solubility in water, so the content in the oceans is negligible; however, at high pressures and low temperatures (such as at the bottom of the oceans), methane can co-crystallize with water to form a solid methane clathrate (methane hydrate). Although this cannot be commercially exploited at the present time, the amount of combustible energy of the known methane clathrate fields exceeds the energy content of all the natural gas and oil deposits put together. Methane extracted from methane clathrate is therefore a candidate for future fuels.
Biological occurrence.
Acyclic alkanes occur in nature in various ways.
Certain types of bacteria can metabolize alkanes: they prefer even-numbered carbon chains as they are easier to degrade than odd-numbered chains.
On the other hand, certain archaea, the methanogens, produce large quantities of methane by the metabolism of carbon dioxide or other oxidized organic compounds. The energy is released by the oxidation of hydrogen:
Methanogens are also the producers of marsh gas in wetlands, and release about two billion tonnes of methane per year—the atmospheric content of this gas is produced nearly exclusively by them. The methane output of cattle and other herbivores, which can release up to 150 liters per day, and of termites, is also due to methanogens. They also produce this simplest of all alkanes in the intestines of humans. Methanogenic archaea are, hence, at the end of the carbon cycle, with carbon being released back into the atmosphere after having been fixed by photosynthesis. It is probable that our current deposits of natural gas were formed in a similar way.
Alkanes also play a role, if a minor role, in the biology of the three eukaryotic groups of organisms: fungi, plants and animals. Some specialized yeasts, e.g., "Candida tropicale", "Pichia" sp., "Rhodotorula" sp., can use alkanes as a source of carbon or energy. The fungus "Amorphotheca resinae" prefers the longer-chain alkanes in aviation fuel, and can cause serious problems for aircraft in tropical regions.
In plants, the solid long-chain alkanes are found in the plant cuticle and epicuticular wax of many species, but are only rarely major constituents. They protect the plant against water loss, prevent the leaching of important minerals by the rain, and protect against bacteria, fungi, and harmful insects. The carbon chains in plant alkanes are usually odd-numbered, between 27 and 33 carbon atoms in length and are made by the plants by decarboxylation of even-numbered fatty acids. The exact composition of the layer of wax is not only species-dependent, but changes also with the season and such environmental factors as lighting conditions, temperature or humidity.
More volatile short-chain alkanes are also produced by and found in plant tissues. The Jeffrey pine is noted for producing exceptionally high levels of "n"-heptane in its resin, for which reason its distillate was designated as the zero point for one octane rating. Floral scents have also long been known to contain volatile alkane components, and "n"-nonane is a significant component in the scent of some roses. Emission of gaseous and volatile alkanes such as ethane, pentane, and hexane by plants has also been documented at low levels, though they are not generally considered to be a major component of biogenic air pollution.
Edible vegetable oils also typically contain small fractions of biogenic alkanes with a wide spectrum of carbon numbers, mainly 8 to 35, usually peaking in the low to upper 20s, with concentrations up to dozens of milligrams per kilogram (parts per million by weight) and sometimes over a hundred for the total alkane fraction.
Alkanes are found in animal products, although they are less important than unsaturated hydrocarbons. One example is the shark liver oil, which is approximately 14% pristane (2,6,10,14-tetramethylpentadecane, C19H40). They are important as pheromones, chemical messenger materials, on which insects depend for communication. In some species, e.g. the support beetle "Xylotrechus colonus", pentacosane (C25H52), 3-methylpentaicosane (C26H54) and 9-methylpentaicosane (C26H54) are transferred by body contact. With others like the tsetse fly "Glossina morsitans morsitans", the pheromone contains the four alkanes 2-methylheptadecane (C18H38), 17,21-dimethylheptatriacontane (C39H80), 15,19-dimethylheptatriacontane (C39H80) and 15,19,23-trimethylheptatriacontane (C40H82), and acts by smell over longer distances. Waggle-dancing honey bees produce and release two alkanes, tricosane and pentacosane.
Ecological relations.
One example, in which both plant and animal alkanes play a role, is the ecological relationship between the sand bee ("Andrena nigroaenea") and the early spider orchid ("Ophrys sphegodes"); the latter is dependent for pollination on the former. Sand bees use pheromones in order to identify a mate; in the case of "A. nigroaenea", the females emit a mixture of tricosane (C23H48), pentacosane (C25H52) and heptacosane (C27H56) in the ratio 3:3:1, and males are attracted by specifically this odor. The orchid takes advantage of this mating arrangement to get the male bee to collect and disseminate its pollen; parts of its flower not only resemble the appearance of sand bees, but also produce large quantities of the three alkanes in the same ratio as female sand bees. As a result, numerous males are lured to the blooms and attempt to copulate with their imaginary partner: although this endeavor is not crowned with success for the bee, it allows the orchid to transfer its pollen,
which will be dispersed after the departure of the frustrated male to different blooms.
Production.
Petroleum refining.
As stated earlier, the most important source of alkanes is natural gas and crude oil. Alkanes are separated in an oil refinery by fractional distillation and processed into many different products.
Fischer–Tropsch.
The Fischer–Tropsch process is a method to synthesize liquid hydrocarbons, including alkanes, from carbon monoxide and hydrogen. This method is used to produce substitutes for petroleum distillates.
Laboratory preparation.
There is usually little need for alkanes to be synthesized in the laboratory, since they are usually commercially available. Also, alkanes are generally non-reactive chemically or biologically, and do not undergo functional group interconversions cleanly. When alkanes are produced in the laboratory, it is often a side-product of a reaction. For example, the use of "n"-butyllithium as a strong base gives the conjugate acid, "n"-butane as a side-product:
However, at times it may be desirable to make a portion of a molecule into an alkane like functionality (alkyl group) using the above or similar methods. For example, an ethyl group is an alkyl group; when this is attached to a hydroxy group, it gives ethanol, which is not an alkane. To do so, the best-known methods are hydrogenation of alkenes:
Alkanes or alkyl groups can also be prepared directly from alkyl halides in the Corey–House–Posner–Whitesides reaction. The Barton–McCombie deoxygenation removes hydroxyl groups from alcohols e.g.
and the Clemmensen reduction removes carbonyl groups from aldehydes and ketones to form alkanes or alkyl-substituted compounds e.g.:
Applications.
The applications of a certain alkane can be determined quite well according to the number of carbon atoms. The first four alkanes are used mainly for heating and cooking purposes, and in some countries for electricity generation. Methane and ethane are the main components of natural gas; they are normally stored as gases under pressure. It is, however, easier to transport them as liquids: This requires both compression and cooling of the gas.
Propane and butane can be liquefied at fairly low pressures, and are well known as liquified petroleum gas (LPG). Propane, for example, is used in the propane gas burner and as a fuel for cars, butane in disposable cigarette lighters. The two alkanes are used as propellants in aerosol sprays.
From pentane to octane the alkanes are reasonably volatile liquids. They are used as fuels in internal combustion engines, as they vaporise easily on entry into the combustion chamber without forming droplets, which would impair the uniformity of the combustion. Branched-chain alkanes are preferred as they are much less prone to premature ignition, which causes knocking, than their straight-chain homologues. This propensity to premature ignition is measured by the octane rating of the fuel, where 2,2,4-trimethylpentane ("isooctane") has an arbitrary value of 100, and heptane has a value of zero. Apart from their use as fuels, the middle alkanes are also good solvents for nonpolar substances.
Alkanes from nonane to, for instance, hexadecane (an alkane with sixteen carbon atoms) are liquids of higher viscosity, less and less suitable for use in gasoline. They form instead the major part of diesel and aviation fuel. Diesel fuels are characterized by their cetane number, cetane being an old name for hexadecane. However, the higher melting points of these alkanes can cause problems at low temperatures and in polar regions, where the fuel becomes too thick to flow correctly.
Alkanes from hexadecane upwards form the most important components of fuel oil and lubricating oil. In the latter function, they work at the same time as anti-corrosive agents, as their hydrophobic nature means that water cannot reach the metal surface. Many solid alkanes find use as paraffin wax, for example, in candles. This should not be confused however with true wax, which consists primarily of esters.
Alkanes with a chain length of approximately 35 or more carbon atoms are found in bitumen, used, for example, in road surfacing. However, the higher alkanes have little value and are usually split into lower alkanes by cracking.
Some synthetic polymers such as polyethylene and polypropylene are alkanes with chains containing hundreds of thousands of carbon atoms. These materials are used in innumerable applications, and billions of kilograms of these materials are made and used each year.
Environmental transformations.
When released in the environment, alkanes don't undergo rapid biodegradation, because they have no functional groups (like hydroxyl or carbonyl) that are needed by most organisms in order to metabolize the compound.
However, some bacteria can metabolize some alkanes (especially those linear and short), by oxidizing the terminal carbon atom. The product is an alcohol, that could be next oxidized to an aldehyde, and finally to a carboxylic acid. The resulting fatty acid could be metabolized through the fatty acid degradation pathway.
Hazards.
Methane is explosive when mixed with air (1–8% CH4). Other lower alkanes can also form explosive mixtures with air. The lighter liquid alkanes are highly flammable, although this risk decreases with the length of the carbon chain. Pentane, hexane, heptane, and octane are classed as "dangerous for the environment" and "harmful".
Considerations for detection / risk control:

</doc>
<doc id="640" url="https://en.wikipedia.org/wiki?curid=640" title="Appellate procedure in the United States">
Appellate procedure in the United States

United States appellate procedure involves the rules and regulations for filing appeals in state courts and federal courts. The nature of an appeal can vary greatly depending on the type of case and the rules of the court in the jurisdiction where the case was prosecuted. There are many types of standard of review for appeals, such as "de novo" and abuse of discretion. However, most appeals begin when a party files a petition for review to a higher court for the purpose of overturning the lower court's decision.
An appellate court is a court that hears cases on appeal from another court. Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds. These grounds typically could include errors of law, fact, procedure or due process. In different jurisdictions, appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts.
The specific procedures for appealing, including even whether there is a right of appeal from a particular type of decision, can vary greatly from state to state. The right to file an appeal can also vary from state to state; for example, the New Jersey Constitution vests judicial power in a Supreme Court, a Superior Court, and other courts of limited jurisdiction, with an appellate court being part of the Superior Court.
Access to appellant status.
A party who files an appeal is called an "appellant", "plaintiff in error", "petitioner" or "pursuer", and a party on the other side is called a "appellee". A "cross-appeal" is an appeal brought by the respondent. For example, suppose at trial the judge found for the plaintiff and ordered the defendant to pay $50,000. If the defendant files an appeal arguing that he should not have to pay any money, then the plaintiff might file a cross-appeal arguing that the defendant should have to pay $200,000 instead of $50,000.
The appellant is the party who, having lost part or all their claim in a lower court decision, is appealing to a higher court to have their case reconsidered. This is usually done on the basis that the lower court judge erred in the application of law, but it may also be possible to appeal on the basis of court misconduct, or that a finding of fact was entirely unreasonable to make on the evidence.
The appellant in the new case can be either the plaintiff (or claimant), defendant, third-party intervenor, or respondent (appellee) from the lower case, depending on who was the losing party. The winning party from the lower court, however, is now the respondent. In unusual cases the appellant can be the victor in the court below, but still appeal.
An appellee is the party to an appeal in which the lower court judgment was in its favor. The appellee is required to respond to the petition, oral arguments, and legal briefs of the appellant. In general, the appellee takes the procedural posture that the lower court's decision should be affirmed.
Ability to appeal.
An appeal "as of right" is one that is guaranteed by statute or some underlying constitutional or legal principle. The appellate court cannot refuse to listen to the appeal. An appeal "by leave" or "permission" requires the appellant to obtain leave to appeal; in such a situation either or both of the lower court and the court may have the discretion to grant or refuse the appellant's demand to appeal the lower court's decision. In the Supreme Court, review in most cases is available only if the Court exercises its discretion and grants a writ of certiorari.
In tort, equity, or other civil matters either party to a previous case may file an appeal. In criminal matters, however, the state or prosecution generally has no appeal "as of right". And due to the double jeopardy principle, the state or prosecution may never appeal a jury or bench verdict of acquittal. But in some jurisdictions, the state or prosecution may appeal "as of right" from a trial court's dismissal of an indictment in whole or in part or from a trial court's granting of a defendant's suppression motion. Likewise, in some jurisdictions, the state or prosecution may appeal an issue of law "by leave" from the trial court or the appellate court. The ability of the prosecution to appeal a decision in favor of a defendant varies significantly internationally. All parties must present grounds to appeal, or it will not be heard.
By convention in some law reports, the appellant is named first. This can mean that where it is the defendant who appeals, the name of the case in the law reports reverses (in some cases twice) as the appeals work their way up the court hierarchy. This is not always true, however. In the federal courts, the parties' names always stay in the same order as the lower court when an appeal is taken to the circuit courts of appeals, and are re-ordered only if the appeal reaches the Supreme Court.
Direct or collateral: Appealing criminal convictions.
Many jurisdictions recognize two types of appeals, particularly in the criminal context. The first is the traditional "direct" appeal in which the appellant files an appeal with the next higher court of review. The second is the collateral appeal or post-conviction petition, in which the petitioner-appellant files the appeal in a court of first instance—usually the court that tried the case.
The key distinguishing factor between direct and collateral appeals is that the former occurs in state courts, and the latter in federal courts.
Relief in post-conviction is rare and is most often found in capital or violent felony cases. The typical scenario involves an incarcerated defendant locating DNA evidence demonstrating the defendant's actual innocence.
Appellate review.
"Appellate review" is the general term for the process by which courts with appellate jurisdiction take jurisdiction of matters decided by lower courts. It is distinguished from judicial review, which refers to the court's overriding constitutional or statutory right to determine if a legislative act or administrative decision is defective for jurisdictional or other reasons (which may vary by jurisdiction).
In most jurisdictions the normal and preferred way of seeking appellate review is by filing an appeal of the final judgment. Generally, an appeal of the judgment will also allow appeal of all other orders or rulings made by the trial court in the course of the case. This is because such orders cannot be appealed "as of right". However, certain critical interlocutory court orders, such as the denial of a request for an interim injunction, or an order holding a person in contempt of court, can be appealed immediately although the case may otherwise not have been fully disposed of.
There are two distinct forms of appellate review, "direct" and "collateral". For example, a criminal defendant may be convicted in state court, and lose on "direct appeal" to higher state appellate courts, and if unsuccessful, mount a "collateral" action such as filing for a writ of habeas corpus in the federal courts. Generally speaking, "appeal statutes afford defendants the opportunity to challenge the merits of a judgment and allege errors of law or fact. ... [Collateral review, on the other hand, provide an independent and civil inquiry into the validity of a conviction and sentence, and as such are generally limited to challenges to constitutional, jurisdictional, or other fundamental violations that occurred at trial." "Graham v. Borgen", 483 F 3d. 475 (7th Cir. 2007) (no. 04-4103) (slip op. at 7) (citation omitted).
In Anglo-American common law courts, appellate review of lower court decisions may also be obtained by filing a petition for review by prerogative writ in certain cases. There is no corresponding right to a writ in any pure or continental civil law legal systems, though some mixed systems such as Quebec recognize these prerogative writs.
Direct Appeal.
After exhausting the first appeal as of right, defendants usually petition the highest state court to review the decision. This appeal is known as a direct appeal. The highest state court, generally known as the Supreme Court, exercises discretion over whether it will review the case. On direct appeal, a prisoner challenges the grounds of the conviction based on an error that occurred at trial or some other stage in the adjudicative process.
Preservation Issues.
An appellant's claim(s) must usually be preserved at trial. This means that the defendant had to object to the error when it occurred in the trial. Because constitutional claims are of great magnitude, appellate courts might be more lenient to review the claim even if it was not preserved. For example, Connecticut applies the following standard to review unpreserved claims: 1.the record is adequate to review the alleged claim of error; 2. the claim is of constitutional magnitude alleging the violation of a fundamental right; 3. the alleged constitutional violation clearly exists and clearly deprived the defendant of a fair trial; 4. if subject to harmless error analysis, the state has failed to demonstrate harmlessness of the alleged constitutional violation beyond a reasonable doubt.
State Post Conviction Relief: Collateral Appeal.
All States have a post-conviction relief process. Similar to federal post-conviction relief, an appellant can petition the court to correct alleged fundamental errors that were not corrected on direct review. Typical claims might include ineffective assistance of counsel and actual innocence based on new evidence. These proceedings are normally separate from the direct appeal, however some states allow for collateral relief to be sought on direct appeal. After direct appeal, the conviction is considered final. An appeal from the post conviction court proceeds just as a direct appeal. That is, it goes to the intermediate appellate court, followed by the highest court. If the petition is granted the appellant could be released from incarceration, the sentence could be modified, or a new trial could be ordered.
Notice of appeal.
A "notice of appeal" is a form or document that in many cases is required to begin an appeal. The form is completed by the appellant or by the appellant's legal representative. The nature of this form can vary greatly from country to country and from court to court within a country.
The specific rules of the legal system will dictate exactly how the appeal is officially begun. For example, the appellant might have to file the notice of appeal with the appellate court, or with the court from which the appeal is taken, or both.
Some courts have samples of a notice of appeal on the court's own web site. In New Jersey, for example, the Administrative Office of the Court has promulgated a form of notice of appeal for use by appellants, though using this exact form is not mandatory and the failure to use it is not a jurisdictional defect provided that all pertinent information is set forth in whatever form of notice of appeal is used.
The deadline for beginning an appeal can often be very short: traditionally, it is measured in days, not months. This can vary from country to country, as well as within a country, depending on the specific rules in force. In the U.S. federal court system, criminal defendants must file a notice of appeal within 10 days of the entry of either the judgment or the order being appealed, or the right to appeal is forfeited.
Appellate procedure.
Generally speaking the appellate court examines the record of evidence presented in the trial court and the law that the lower court applied and decides whether that decision was legally sound or not. The appellate court will typically be deferential to the lower court's findings of fact (such as whether a defendant committed a particular act), unless clearly erroneous, and so will focus on the court's application of the law to those facts (such as whether the act found by the court to have occurred fits a legal definition at issue).
If the appellate court finds no defect, it "affirms" the judgment. If the appellate court does find a legal defect in the decision "below" (i.e., in the lower court), it may "modify" the ruling to correct the defect, or it may nullify ("reverse" or "vacate") the whole decision or any part of it. It may, in addition, send the case back ("remand" or "remit") to the lower court for further proceedings to remedy the defect.
In some cases, an appellate court may review a lower court decision "de novo" (or completely), challenging even the lower court's findings of fact. This might be the proper standard of review, for example, if the lower court resolved the case by granting a pre-trial motion to dismiss or motion for summary judgment which is usually based only upon written submissions to the trial court and not on any trial testimony.
Another situation is where appeal is by way of "re-hearing". Certain jurisdictions permit certain appeals to cause the trial to be heard afresh in the appellate court.
Sometimes, the appellate court finds a defect in the procedure the parties used in filing the appeal and dismisses the appeal without considering its merits, which has the same effect as affirming the judgment below. (This would happen, for example, if the appellant waited too long, under the appellate court's rules, to file the appeal.)
Generally, there is no trial in an appellate court, only consideration of the record of the evidence presented to the trial court and all the pre-trial and trial court proceedings are reviewed—unless the appeal is by way of re-hearing, new evidence will usually only be considered on appeal in "very" rare instances, for example if that material evidence was unavailable to a party for some very significant reason such as prosecutorial misconduct.
In some systems, an appellate court will only consider the written decision of the lower court, together with any written evidence that was before that court and is relevant to the appeal. In other systems, the appellate court will normally consider the record of the lower court. In those cases the record will first be certified by the lower court.
The appellant has the opportunity to present arguments for the granting of the appeal and the appellee (or respondent) can present arguments against it. Arguments of the parties to the appeal are presented through their appellate lawyers, if represented, or "pro se" if the party has not engaged legal representation. Those arguments are presented in written briefs and sometimes in oral argument to the court at a hearing. At such hearings each party is allowed a brief presentation at which the appellate judges ask questions based on their review of the record below and the submitted briefs.
In an adversarial system, appellate courts do not have the power to review lower court decisions unless a party appeals it. Therefore, if a lower court has ruled in an improper manner, or against legal precedent, that judgment will stand if not appealed – even if it might have been overturned on appeal.
The United States legal system generally recognizes two types of appeals: a trial "de novo" or an appeal on the record.
A trial de novo is usually available for review of informal proceedings conducted by some minor judicial tribunals in proceedings that do not provide all the procedural attributes of a formal judicial trial. If unchallenged, these decisions have the power to settle more minor legal disputes once and for all. If a party is dissatisfied with the finding of such a tribunal, one generally has the power to request a trial "de novo" by a court of record. In such a proceeding, all issues and evidence may be developed newly, as though never heard before, and one is not restricted to the evidence heard in the lower proceeding. Sometimes, however, the decision of the lower proceeding is itself admissible as evidence, thus helping to curb frivolous appeals.
In some cases, an application for "trial de novo" effectively erases the prior trial as if it had never taken place. The Supreme Court of Virginia has stated that '"This Court has repeatedly held that the effect of an appeal to circuit court is to "annul the judgment of the inferior tribunal as completely as if there had been no previous trial."' The only exception to this is that if a defendant appeals a conviction for a crime having multiple levels of offenses, where they are convicted on a lesser offense, the appeal is of the lesser offense; the conviction represents an acquittal of the more serious offenses. "trial on the same charges in the circuit court does not violate double jeopardy principles, . . . subject only to the limitation that conviction in [the district court for an offense lesser included in the one charged constitutes an acquittal of the greater offense,
permitting trial de novo in the circuit court only for the lesser-included offense."
In an appeal on the record from a decision in a judicial proceeding, both appellant and respondent are bound to base their arguments wholly on the proceedings and body of evidence as they were presented in the lower tribunal. Each seeks to prove to the higher court that the result they desired was the just result. Precedent and case law figure prominently in the arguments. In order for the appeal to succeed, the appellant must prove that the lower court committed reversible error, that is, an impermissible action by the court acted to cause a result that was unjust, and which would not have resulted had the court acted properly. Some examples of reversible error would be erroneously instructing the jury on the law applicable to the case, permitting seriously improper argument by an attorney, admitting or excluding evidence improperly, acting outside the court's jurisdiction, injecting bias into the proceeding or appearing to do so, juror misconduct, etc. The failure to formally object at the time, to what one views as improper action in the lower court, may result in the affirmance of the lower court's judgment on the grounds that one did not "preserve the issue for appeal" by objecting.
In cases where a judge rather than a jury decided issues of fact, an appellate court will apply an "abuse of discretion" standard of review. Under this standard, the appellate court gives deference to the lower court's view of the evidence, and reverses its decision only if it were a clear abuse of discretion. This is usually defined as a decision outside the bounds of reasonableness. On the other hand, the appellate court normally gives less deference to a lower court's decision on issues of law, and may reverse if it finds that the lower court applied the wrong legal standard.
In some cases, an appellant may successfully argue that the law under which the lower decision was rendered was unconstitutional or otherwise invalid, or may convince the higher court to order a new trial on the basis that evidence earlier sought was concealed or only recently discovered. In the case of new evidence, there must be a high probability that its presence or absence would have made a material difference in the trial. Another issue suitable for appeal in criminal cases is effective assistance of counsel. If a defendant has been convicted and can prove that his lawyer did not adequately handle his case and that there is a reasonable probability that the result of the trial would have been different had the lawyer given competent representation, he is entitled to a new trial.
A lawyer traditionally starts an oral argument to any appellate court with the words "May it please the court."
After an appeal is heard, the "mandate" is a formal notice of a decision by a court of appeal; this notice is transmitted to the trial court and, when filed by the clerk of the trial court, constitutes the final judgment on the case, unless the appeal court has directed further proceedings in the trial court. The mandate is distinguished from the appeal court's opinion, which sets out the legal reasoning for its decision. In some jurisdictions the mandate is known as the "remittitur".
Results.
The result of an appeal can be:
There can be multiple outcomes, so that the reviewing court can affirm some rulings, reverse others and remand the case all at the same time. Remand is not required where there is nothing left to do in the case. "Generally speaking, an appellate court's judgment provides 'the final directive of the appeals courts as to the matter appealed, setting out with specificity the court's determination that the action appealed from should be affirmed, reversed, remanded or modified'".
Some reviewing courts who have discretionary review may send a case back without comment other than "review improvidently granted". In other words, after looking at the case, they chose not to say anything. The result for the case of "review improvidently granted" is effectively the same as affirmed, but without that extra higher court stamp of approval.

</doc>
<doc id="642" url="https://en.wikipedia.org/wiki?curid=642" title="Answer">
Answer

Generally, an answer is a reply to a question. It can be solution, a retaliation or a response to it.
In law, an answer was originally a solemn assertion in opposition to someone or something, and thus generally any counter-statement or defense, a reply to a question or response, or objection, or a correct solution of a problem.
In the common law, an answer is the first pleading by a defendant, usually filed and served upon the plaintiff within a certain strict time limit after a civil complaint or criminal information or indictment has been served upon the defendant. It may have been preceded by an "optional" "pre-answer" motion to dismiss or demurrer; if such a motion is unsuccessful, the defendant "must" file an answer to the complaint or risk an adverse default judgment.
In a criminal case, there is usually an arraignment or some other kind of appearance before the defendant comes to court. The pleading in the criminal case, which is entered on the record in open court, is usually either guilty or not guilty. Generally speaking in private, civil cases there is no plea entered of guilt or innocence. There is only a judgment that grants money damages or some other kind of equitable remedy such as restitution or a permanent injunction. Criminal cases may lead to fines or other punishment, such as imprisonment.
The famous Latin "Responsa Prudentium" ("answers of the learned ones") were the accumulated views of many successive generations of Roman lawyers, a body of legal opinion which gradually became authoritative.
In music an "answer" (also known as countersubject) is the technical name in counterpoint for the repetition or modification by one part or instrument of a theme proposed by another.

</doc>
<doc id="643" url="https://en.wikipedia.org/wiki?curid=643" title="Appellate court">
Appellate court

An appellate court, commonly called an appeals court, court of appeals (American English), appeal court (British English), court of second instance or second instance court, is any court of law that is empowered to hear an appeal of a trial court or other lower tribunal. In most jurisdictions, the court system is divided into at least three levels: the trial court, which initially hears cases and reviews evidence and testimony to determine the facts of the case; at least one intermediate appellate court; and a supreme court (or court of last resort) which primarily reviews the decisions of the intermediate courts. A jurisdiction's supreme court is that jurisdiction's highest appellate court. Appellate courts nationwide can operate by varying rules.
The authority of appellate courts to review decisions of lower courts varies widely from one jurisdiction to another. In some places, the appellate court has limited powers of review. "Generally speaking, an appellate court's judgment provides 'the final directive of the appeals courts as to the matter appealed, setting out with specificity the court's determination that the action appealed from should be affirmed, reversed, remanded or modified'".
United States.
In the United States, both state and federal appellate courts are usually restricted to examining whether the lower court made the correct legal determinations, rather than hearing direct evidence and determining what the facts of the case were. Furthermore, U.S. appellate courts are usually restricted to hearing appeals based on matters that were originally brought up before the trial court. Hence, such an appellate court will not consider an appellant's argument if it is based on a theory that is raised for the first time in the appeal. 
In most U.S. states, and in U.S. federal courts, parties before the court are allowed one appeal as of right. This means that a party who is unsatisfied with the outcome of a trial may bring an appeal to contest that outcome. However, appeals may be costly, and the appellate court must find an error on the part of the court below that justifies upsetting the verdict. Therefore, only a small proportion of trial court decisions result in appeals. Some appellate courts, particularly supreme courts, have the power of discretionary review, meaning that they can decide whether they will hear an appeal brought in a particular case.
Institutional titles.
Many U.S. jurisdictions title their appellate court a court of appeal or court of appeals. Historically, others have titled their appellate court a court of errors (or court of errors and appeals), on the premise that it was intended to correct errors made by lower courts. Examples of such courts include the New Jersey Court of Errors and Appeals (which existed from 1844 to 1947), the Connecticut Supreme Court of Errors (which has been renamed the Connecticut Supreme Court), the Kentucky Court of Errors (renamed the Kentucky Supreme Court), and the Mississippi High Court of Errors and Appeals (since renamed the Supreme Court of Mississippi). In some jurisdictions, courts able to hear appeals are known as an appellate division.
The phrase "court of appeals" most often refers to intermediate appellate courts. However, the New York system is different: the "New York Court of Appeals" is the highest appellate court; and the phrase "New York Supreme Court" applies to the trial court of general jurisdiction.
Depending on the system, certain courts may serve as both trial courts and appellate courts, hearing appeals of decisions made by courts with more limited jurisdiction. Some jurisdictions have specialized appellate courts, such as the Texas Court of Criminal Appeals, which only hears appeals raised in criminal cases, and the United States Court of Appeals for the Federal Circuit, which has general jurisdiction but derives most of its caseload from patent cases, on one hand, and appeals from the Court of Federal Claims on the other.
New Zealand.
The Court of Appeal of New Zealand, located in Wellington, is New Zealand's principal intermediate appellate court. In practice, most appeals are resolved at this intermediate appellate level, rather than in the Supreme Court.

</doc>
<doc id="649" url="https://en.wikipedia.org/wiki?curid=649" title="Arraignment">
Arraignment

Arraignment is a formal reading of a criminal charging document in the presence of the defendant to inform the defendant of the charges against them. In response to arraignment, the accused is expected to enter a plea. Acceptable pleas vary among jurisdictions, but they generally include "guilty", "not guilty", and the peremptory pleas (or pleas in bar) setting out reasons why a trial cannot proceed. Pleas of "nolo contendere" (no contest) and the ""Alford" plea" are allowed in some circumstances.
By country.
Australia.
In Australia, arraignment is the first of eleven stages in a criminal trial, and involves the clerk of the court reading out the indictment. The judge will testify during the indictment process.
Canada.
In every province in Canada except British Columbia, defendants are arraigned on the day of their trial. In British Columbia, arraignment takes places in one of the first few court appearances by the defendant or their lawyer. The defendant is asked whether he or she pleads guilty or not guilty to each charge.
France.
In France, the general rule is that one cannot remain in police custody for more than 24 hours from the time of the arrest. However, police custody can last another 24 hours in specific circumstances, especially if the offence is punishable by at least one year's imprisonment, or if the investigation is deemed to require the extra time, and can last up to 96 hours in certain cases involving terrorism, drug trafficking or organised crime. The police needs to have the consent of the prosecutor (in the vast majority of cases, the prosecutor will consent).
Germany.
In Germany, if one has been arrested and taken into custody by the police one must be brought before a judge as soon as possible and at the latest on the day after the arrest.
New Zealand.
At the first appearance, the accused is read the charges and asked for a plea. The available pleas are, guilty, not guilty, and no plea. No plea allows the defendant to get legal advice on the plea, which must be made on the second appearance.
South Africa.
In South Africa, arraignment is defined as the calling upon the accused to appear, the informing of the accused of the crime charged against him, the demanding of the accused whether he be guilty or not guilty, and the entering of his plea. His plea having been entered he is said to stand arraigned.
United Kingdom.
In England, Wales, and Northern Ireland, arraignment is the first of eleven stages in a criminal trial, and involves the clerk of the court reading out the indictment.
In England and Wales, the police cannot legally detain anyone for more than 24 hours without charging them unless an officer with the rank of superintendent (or above) authorises detention for a further 12 hours (36 hours total), or a judge (who will be a magistrate) authorises detention by the police before charge for up to a maximum of 96 hours, but for terrorism-related offences people can be held by the police for up to 28 days before charge. If they are not released after being charged, they should be brought before a court as soon as practicable.
United States.
Under the United States Federal Rules of Criminal Procedure, "arraignment shall [...] of an open [...] reading the indictment [... to the defendant [...] and call[] on him to plead thereto. He/she shall be given a copy of the indictment [...] before he/she is called upon to plead."
In federal courts, arraignment takes place in two stages. The first is called the initial arraignment and must take place within 48 hours of an individual's arrest, 72 hours if the individual was arrested on the weekend and not able to go before a judge until Monday. During this arraignment the defendant is informed of the pending legal charges and is informed of his or her right to retain counsel. The presiding judge also decides at what amount, if any, to set bail. During the second arraignment, a post-indictment arraignment or PIA, the defendant is allowed to enter a plea.
In New York, most people arrested must be released if they are not arraigned within 24 hours.
In California, arraignments must be conducted without unnecessary delay and, in any event, within 48 hours of arrest, excluding weekends and holidays. Thus, an individual arrested without a warrant, in some cases, may be held for as long as 168 hours (7 days) without arraignment or charge.
Form of the arraignment.
The wording of the arraignment varies from jurisdiction to jurisdiction. However, it generally conforms with the following principles:
Video arraignment.
Video arraignment is the act of conducting the arraignment process using some form of videoconferencing technology. Use of video arraignment system allows the courts to conduct the requisite arraignment process without the need to transport the defendant to the courtroom by using an audio-visual link between the location where the defendant is being held and the courtroom.
Use of the video arraignment process addresses the problems associated with having to transport defendants. The transportation of defendants requires time, puts additional demands on the public safety organizations to provide for the safety of the public, court personnel and for the security of the population held in detention. It also addresses the rising costs of transportation.
Guilty and not-guilty pleas.
If the defendant pleads guilty, an evidentiary hearing usually follows. The court is not required to accept a guilty plea. During the hearing, the judge assesses the offense, the mitigating factors, and the defendant's character, and passes sentence.
If the defendant pleads not guilty, a date is set for a preliminary hearing or a trial.
In the past, a defendant who refused to plead (or "stood mute") was subject to peine forte et dure (Law French for "strong and hard punishment"). Today in common-law jurisdictions, the court enters a plea of not guilty for a defendant who refuses to enter a plea. The rationale for this is the defendant's right to silence.
Pre-trial release.
This is also often the stage at which arguments for or against pre-trial release and bail may be made, depending on the alleged crime and jurisdiction.

</doc>
<doc id="651" url="https://en.wikipedia.org/wiki?curid=651" title="America the Beautiful">
America the Beautiful

"America the Beautiful" is an American patriotic song. The lyrics were written by Katharine Lee Bates, and the music was composed by church organist and choirmaster Samuel A. Ward.
Bates originally wrote the words as a poem, "Pikes Peak", first published in the Fourth of July edition of the church periodical "The Congregationalist" in 1895. At that time, the poem was titled "America" for publication.
Ward had originally written the music, "Materna", for the hymn "O Mother dear, Jerusalem" in 1882, though it was not first published until 1892. Ward's music combined with the Bates poem was first published in 1910 and titled "America the Beautiful".
The song is one of the most popular of the many American patriotic songs.
History.
In 1893, at the age of 33, Bates, an English professor at Wellesley College, had taken a train trip to Colorado Springs, Colorado, to teach a short summer school session at Colorado College. Several of the sights on her trip inspired her, and they found their way into her poem, including the World's Columbian Exposition in Chicago, the "White City" with its promise of the future contained within its alabaster buildings; the wheat fields of America's heartland Kansas, through which her train was riding on July 16; and the majestic view of the Great Plains from high atop Zebulon's Pikes Peak.
On the pinnacle of that mountain, the words of the poem started to come to her, and she wrote them down upon returning to her hotel room at the original Antlers Hotel. The poem was initially published two years later in "The Congregationalist" to commemorate the Fourth of July. It quickly caught the public's fancy. Amended versions were published in 1904 and 1911.
Several existing pieces of music were adapted to the poem. A hymn tune composed by Samuel A. Ward was generally considered the best music as early as 1910 and is still the popular tune today. Just as Bates had been inspired to write her poem, Ward, too, was inspired to compose his tune. The tune came to him while he was on a ferryboat trip from Coney Island back to his home in New York City, after a leisurely summer day in 1882, and he immediately wrote it down. He was so anxious to capture the tune in his head, he asked fellow passenger friend Harry Martin for his shirt cuff to write the tune on. He composed the tune for the old hymn "O Mother Dear, Jerusalem", retitling the work "Materna". Ward's music combined with Bates's poem were first published together in 1910 and titled "America the Beautiful".
Ward died in 1903, not knowing the national stature his music would attain since the music was only first applied to the song in 1904. Bates was more fortunate since the song's popularity was well established by the time of her death in 1929.
At various times in the more than 100 years that have elapsed since the song was written, particularly during the John F. Kennedy administration, there have been efforts to give "America the Beautiful" legal status either as a national hymn or as a national anthem equal to, or in place of, "The Star-Spangled Banner", but so far this has not succeeded. Proponents prefer "America the Beautiful" for various reasons, saying it is easier to sing, more melodic, and more adaptable to new orchestrations while still remaining as easily recognizable as "The Star-Spangled Banner". Some prefer "America the Beautiful" over "The Star-Spangled Banner" due to the latter's war-oriented imagery. Others prefer "The Star-Spangled Banner" for the same reason. While that national dichotomy has stymied any effort at changing the tradition of the national anthem, "America the Beautiful" continues to be held in high esteem by a large number of Americans.
This song was used as the background music of the television broadcast of the Tiangong-1 launch.
The song is often included in songbooks in a wide variety of religious congregations in the United States.
Popular versions.
In 1976, while the United States celebrated its bicentennial, a soulful version popularized by Ray Charles peaked at number 98 on the US R&B Charts, and is included on the soundtrack for the movie "The Sandlot".
Three different renditions of the song have entered the Hot Country Songs charts. The first was by Charlie Rich, which went to number 22 in 1976. A second, by Mickey Newbury, peaked at number 82 in 1980. An all-star version of "America the Beautiful" performed by country singers Trace Adkins, Sherrié Austin, Billy Dean, Vince Gill, Carolyn Dawn Johnson, Toby Keith, Brenda Lee, Lonestar, Lyle Lovett, Lila McCann, Lorrie Morgan, Jamie O'Neal, The Oak Ridge Boys, Collin Raye, Kenny Rogers, Keith Urban and Phil Vassar reached number 58 in July 2001. The song re-entered the chart following the September 11 attacks.
Popularity of the song increased greatly following the September 11 attacks; at some sporting events it was sung in addition to the traditional singing of the national anthem. During the first taping of the "Late Show with David Letterman" following the attacks, CBS newsman Dan Rather cried briefly as he quoted the fourth verse.
For Super Bowl XLVIII, The Coca-Cola Company aired a multilingual version of the song, sung in several different languages. This commercial incited an outcry from quite a few Americans.
Idioms.
"From sea to shining sea", originally used in the charters of some of the English Colonies in North America, is an American idiom meaning from the Atlantic Ocean to the Pacific Ocean (or vice versa). Many songs have used this term, including the American patriotic songs "America, the Beautiful" and "God Bless the USA". In addition to these, it is also featured in Schoolhouse Rock's "Elbow Room". A term similar to this is the official Canadian (Latin) motto "" (From sea to sea).
"Purple mountain majesties" refers to the shade of the Pikes Peak in Colorado Springs, Colorado, which Bates looked at while writing the poem.
Books.
Lynn Sherr's 2001 book "America the Beautiful" discusses the origins of the song and the backgrounds of its authors in depth. The book points out that the poem has the same meter as that of "Auld Lang Syne"; the songs can be sung interchangeably. Additionally, Sherr discusses the evolution of the lyrics, for instance changes in from the original third verse written by Bates. The song appears in Ellen Raskin's "The Westing Game".

</doc>
<doc id="653" url="https://en.wikipedia.org/wiki?curid=653" title="Assistive technology">
Assistive technology

Assistive technology is an umbrella term that includes assistive, adaptive, and rehabilitative devices for people with disabilities and also includes the process used in selecting, locating, and using them. Assistive technology promotes greater independence by enabling people to perform tasks that they were formerly unable to accomplish, or had great difficulty accomplishing, by providing enhancements to, or changing methods of interacting with, the technology needed to accomplish such tasks.
Assistive technology and adaptive technology.
The term adaptive technology is often used as the synonym for assistive technology, however, they are different terms. Assistive technology refers to "any item, piece of equipment, or product system, whether acquired commercially, modified, or customized, that is used to increase, maintain, or improve functional capabilities of individuals with disabilities", while adaptive technology covers items that are specifically designed for persons with disabilities and would seldom be used by non-disabled persons. In other words, "assistive technology is any object or system that increases or maintains the capabilities of people with disabilities," while adaptive technology is "any object or system that is specifically designed for the purpose of increasing or maintaining the capabilities of people with disabilities." Consequently, adaptive technology is a subset of assistive technology. Adaptive technology often refers specifically to electronic and information technology access.
Mobility impairments.
Wheelchairs.
Wheelchairs are devices that can be manually propelled or electrically propelled and that include a seating system and are designed to be a substitute for the normal mobility that most people enjoy. Wheelchairs and other mobility devices allow people to perform mobility related activities of daily living which include feeding, toileting, dressing grooming and bathing. The devices comes in a number of variations where they can be propelled either by hand or by motors where the occupant uses electrical controls to manage motors and seating control actuators through a joystick, sip-and-puff control, or other input devices. Often there are handles behind the seat for someone else to do the pushing or input devices for caregivers. Wheelchairs are used by people for whom walking is difficult or impossible due to illness, injury, or disability. People with both sitting and walking disability often need to use a wheelchair or walker.
Transfer devices.
Patient transfer devices generally allow patients with impaired mobility to be moved by caregivers between beds, wheelchairs, commodes, toilets, chairs, stretchers, shower benches, automobiles, swimming pools, and other patient support systems (i.e., radiology, surgical, or examining tables). The most common devices are Patient lifts (for vertical transfer), Transfer benches, stretcher or convertible chairs (for lateral, supine transfer), sit-to-stand lifts (for moving patients from one seated position to another i.e., from wheelchairs to commodes), air bearing inflatable mattresses (for supine transfer i.e., transfer from a gurney to an operating room table), and sliding boards (usually used for transfer from a bed to a wheelchair). Highly dependent patients who cannot assist their caregiver in moving them often require a Patient lift (a floor or ceiling-suspended sling lift) which though invented in 1955 and in common use since the early 1960s is still considered the state-of-the-art transfer device by OSHA and the American Nursing Association.
Walkers.
A walker or walking frame or Rollator is a tool for disabled people who need additional support to maintain balance or stability while walking. It consists of a frame that is about waist high, approximately twelve inches deep and slightly wider than the user. Walkers are also available in other sizes, such as for children, or for heavy people. Modern walkers are height-adjustable. The front two legs of the walker may or may not have wheels attached depending on the strength and abilities of the person using it. It is also common to see caster wheels or glides on the back legs of a walker with wheels on the front.
Prosthesis.
A prosthesis, prosthetic, or prosthetic limb is a device that replaces a missing body part. It is part of the field of biomechatronics, the science of using mechanical devices with human muscle, skeleton, and nervous systems to assist or enhance motor control lost by trauma, disease, or defect. Prostheses are typically used to replace parts lost by injury (traumatic) or missing from birth (congenital) or to supplement defective body parts. Inside the body, artificial heart valves are in common use with artificial hearts and lungs seeing less common use but under active technology development. Other medical devices and aids that can be considered prosthetics include hearing aids, artificial eyes, palatal obturator, gastric bands, and dentures.
Prostheses are specifically "not" orthoses, although given certain circumstances a prosthesis might end up performing some or all of the same functionary benefits as an orthosis. Prostheses are technically the complete finished item. For instance, a C-Leg knee alone is "not" a prosthesis, but only a prosthetic "component". The complete prosthesis would consist of the attachment system  to the residual limb — usually a "socket", and all the attachment hardware components all the way down to and including the terminal device. Keep this in mind as nomenclature is often interchanged.
The terms "prosthetic" and "orthotic" are adjectives used to describe devices such as a prosthetic knee. The terms "prosthetics" and "orthotics" are used to describe the respective allied health fields. The devices themselves are properly referred to as "prostheses" and "orthoses" in the plural and "prosthesis" and "orthosis" in the singular.
Visual impairments.
Many people with serious visual impairments live independently, using a wide range of tools and techniques. Examples of assistive technology for visually impairment include screen readers, screen magnifiers, Braille embossers, desktop video magnifiers, and voice recorders.
Screen readers.
Screen readers allow the visually impaired to easily access electronic information. These software programs connect to a computer to read the text displayed out loud. There is a variety of platforms and applications available for a variety of costs.
Braille and braille embossers.
Braille is a system of raised dots formed into units called braille cells. A full braille cell is made up of six dots, with two parallel rows of three dots, but other combinations and quantities of dots represent other letters, numbers, punctuation marks, or words. People can then use their fingers to read the code of raised dots.
A braille embosser is, simply put, a printer for braille. Instead of a standard printer adding ink onto a page, the braille embosser imprints the raised dots of braille onto a page. Some braille embossers combine both braille and ink so the documents can be read with either sight or touch.
Desktop video magnifier.
Desktop video magnifiers are electronic devices that use a camera and a display screen to perform digital magnification of printed materials. They enlarge printed pages for those with low vision. A camera connects to a monitor that displays real time images, and the user can control settings such as magnification, focus, contrast, underlining, highlighting, and other screen preferences. They come in a variety of sizes and styles; some are small and portable with handheld cameras, while others are much larger and mounted on a fixed stand.
Screen magnification software.
A screen magnifier is software that interfaces with a computer's graphical output to present enlarged screen content. It allows users to enlarge the texts and graphics on their computer screens for easier viewing. Similar to desktop video magnifiers, this technology assists people with low vision. After the user loads the software into their computer's memory, it serves as a kind of "computer magnifying glass." Wherever the computer cursor moves, it enlarges the area around it. This allows greater computer accessibility for a wide range of visual abilities.
Personal emergency response systems.
Personal emergency response systems (PERS), or Telecare (UK term), are a particular sort of assistive technology that use electronic sensors connected to an alarm system to help caregivers manage risk and help vulnerable people stay independent at home longer. An example would be the systems being put in place for senior people such as fall detectors, thermometers (for hypothermia risk), flooding and unlit gas sensors (for people with mild dementia). Notably, these alerts can be customized to the particular person's risks. When the alert is triggered, a message is sent to a caregiver or contact center who can respond appropriately.
Accessibility software.
In human–computer interaction, computer accessibility (also known as accessible computing) refers to the accessibility of a computer system to all people, regardless of disability or severity of impairment, examples include web accessibility guidelines. Another approach is for the user to present a token to the computer terminal, such as a smart card, that has configuration information to adjust the computer speed, text size, etc. to their particular needs. This is useful where users want to access public computer based terminals in Libraries, ATM, Information kiosks etc. The concept is encompassed by the CEN EN 1332-4 Identification Card Systems - Man-Machine Interface. This development of this standard has been supported in Europe by SNAPI and has been successfully incorporated into the Lasseo specifications, but with limited success due to the lack of interest from public computer terminal suppliers.
Hearing impairments.
The deaf or hard of hearing community has a difficult time to communicate and perceive information as compared to hearing individuals. Thus, these individuals often rely on visual and tactile mediums for receiving and communicating information. The use of assistive technology and devices provides this community with various solutions to their problems by providing higher sound (for those who are hard of hearing), tactile feedback, visual cues and improved technology access. Individuals who are deaf or hard of hearing utilize a variety of assistive technologies that provide them with improved accessibility to information in numerous environments. Most devices either provide amplified sound or alternate ways to access information through vision and/or vibration. These technologies can be grouped into three general categories: Hearing Technology, alerting devices, and communication support.
Hearing aids.
A hearing aid or deaf aid is an electroacoustic device which is designed to amplify sound for the wearer, usually with the aim of making speech more intelligible, and to correct impaired hearing as measured by audiometry. This type of assistive technology helps people with hearing loss participate more fully in their communities by allowing them to hear more clearly. They amplify any and all sound waves through use of a microphone, amplifier, and speaker. There is a wide variety of hearing aids available, including digital, in-the-ear, in-the-canal, behind-the-ear, and on-the-body aids.
Assistive listening devices.
Assistive listening devices include FM, infrared, and loop assistive listening devices. This type of technology allows people with hearing difficulties to focus on a speaker or subject by getting rid of extra background noises and distractions, making places like auditoriums, classrooms, and meetings much easier to participate in. The assistive listening device usually uses a microphone to capture an audio source near to its origin and broadcast it wirelessly over an FM (Frequency Modulation) transmission, IR (Infra Red) transmission, IL (Induction Loop) transmission, or other transmission method. The person who is listening may use an FM/IR/IL Receiver to tune into the signal and listen at his/her preferred volume.
Amplified telephone equipment.
This type of assistive technology allows users to amplify the volume and clarity of their phone calls so that they can easily partake in this medium of communication. There are also options to adjust the frequency and tone of a call to suit their individual hearing needs. Additionally, there is a wide variety of amplified telephones to choose from, with different degrees of amplification. For example, a phone with 26 to 40 decibel is generally sufficient for mild hearing loss, while a phone with 71 to 90 decibel is better for more severe hearing loss.
Augmentative and alternative communication.
Augmentative and alternative communication (AAC) is an umbrella term that encompasses methods of communication for those with impairments or restrictions on the production or comprehension of spoken or written language. AAC systems are extremely diverse and depend on the capabilities of the user. They may be as basic as pictures on a board that are used to request food, drink, or other care; or they can be advanced speech generating devices, based on speech synthesis, that are capable of storing hundreds of phrases and words.
Cognitive impairments.
Assistive technology for cognition (ATC) is the use of technology (usually high tech) to augment and assistive cognitive processes such as attention, memory, self-regulation, navigation, emotion recognition and management, planning, and sequencing activity. Systematic reviews of the field have found that the number of ATC are growing rapidly, but have focused on memory and planning, that there is emerging evidence for efficacy, that a lot of scope exists to develop new ATC. Examples of ATC include: NeuroPage which prompts users about meetings, Wakamaru, which provides companionship and reminds users to take medicine and calls for help if something is wrong, and telephone Reassurance systems.
Memory aids.
Memory aids are any type of assistive technology that helps a user learn and remember certain information. Many memory aids are used for cognitive impairments such as reading, writing, or organizational difficulties. For example, a Smartpen records handwritten notes by creating both a digital copy and an audio recording of the text. Users simply tap certain parts of their notes and the pen saves it and reads it back to them. From there, the user can also download their notes onto a computer for increased accessibility. Digital voice recorders are also used to record "in the moment" information for fast and easy recall at a later time.
Educational software.
Educational software is software that assists people with reading, learning, comprehension, and organizational difficulties. Any accommodation software such as text readers, notetakers, text enlargers, organization tools, word predictions, and talking word processors falls under the category of educational software.
Assistive technology in sport.
Assistive technology in sport is an area of technology design that is growing. Assistive technology is the array of new devices created to enable sports enthusiasts who have disabilities to play. Assistive technology may be used in adaptive sports, where an existing sport is modified to enable players with a disability to participate; or, assistive technology may be used to invent completely new sports with athletes with disabilities exclusively in mind.
An increasing number of people with disabilities are participating in sports, leading to the development of new assistive technology. Assistive technology devices can be simple, or "low-tech", or they may use highly advanced technology, with some even using computers. Assistive technology for sports may also be simple, or advanced. Accordingly, assistive technology can be found in sports ranging from local community recreation to the elite Paralympic Games. More complex assistive technology devices have been developed over time, and as a result, sports for people with disabilities "have changed from being a clinical therapeutic tool to an increasingly competition-oriented activity".
Assistive technology in education.
In the United States there are two major pieces of legislation that govern the use of assistive technology within the school system. The first is Section 504 of the Rehabilitation Act of 1973 and the second being the Individuals with Disabilities Education Act (IDEA) which was first enacted in 1975 under the name The Education for All Handicapped Children Act. In 2004, during the reauthorization period for IDEA, the National Instructional Material Access Center (NIMAC) was created which provided a repository of accessible text including publisher's textbooks to students with a qualifying disability. Files provided are in XML format and used as a starting platform for braille readers, screen readers, and other digital text software. IDEA defines assistive technology as follows: "any item, piece of equipment, or product system, whether acquired commercially off the shelf, modified, or customized, that is used to increase, maintain, or improve functional capabilities of a child with a disability. (B) Exception.--The term does not include a medical device that is surgically implanted, or the replacement of such device." 
Assistive technology in this area is broken down into low, mid, and high tech categories. Low tech encompasses equipment that is often low cost and does not include batteries or requires charging. Examples include adapted paper and pencil grips for writing or masks and color overlays for reading. Mid tech supports used in the school setting include the use of handheld spelling dictionaries and portable word processors used to keyboard writing. High tech supports involve the use of tablet devices and computers with accompanying software. Software supports for writing include the use of auditory feedback while keyboarding, word prediction for spelling, and speech to text. Supports for reading include the use of text to speech (TTS) software and font modification via access to digital text. Limited supports are available for math instruction and mostly consist of grid based software to allow younger students to keyboard equations and auditory feedback of more complex equations using MathML and Daisy.
Computer accessibility.
One of the largest problems that affect people with disabilities is discomfort with prostheses. An experiment performed in Massachusetts utilized 20 people with various sensors attached to their arms. The subjects tried different arm exercises, and the sensors recorded their movements. All of the data helped engineers develop new engineering concepts for prosthetics.
Assistive technology may attempt to improve the ergonomics of the devices themselves such as Dvorak and other alternative keyboard layouts, which offer more ergonomic layouts of the keys.
Assistive technology devices have been created to enable people with disabilities to use modern touch screen mobile computers such as the iPad, iPhone and iPod touch. The Pererro is a plug and play adapter for iOS devices which uses the built in Apple VoiceOver feature in combination with a basic switch. This brings touch screen technology to those who were previously unable to use it. Apple, with the release of iOS 7 had introduced the ability to navigate apps using switch control. Switch access could be activated either through an external bluetooth connected switch, single touch of the screen, or use of right and left head turns using the device's camera. Additional accessibility features include the use of Assistive Touch which allows a user to access multi-touch gestures through pre-programmed onscreen buttons.
For users with physical disabilities a large variety of switches are available and customizable to the user's needs varying in size, shape, or amount of pressure required for activation. Switch access may be placed near any area of the body which has consistent and reliable mobility and less subject to fatigue. Common sites include the hands, head, and feet. Eye gaze and head mouse systems can also be used as an alternative mouse navigation. A user may utilize single or multiple switch sites and the process often involves a scanning through items on a screen and activating the switch once the desired object is highlighted.
Home automation.
The form of home automation called assistive domotics focuses on making it possible for elderly and disabled people to live independently. Home automation is becoming a viable option for the elderly and disabled who would prefer to stay in their own homes rather than move to a healthcare facility. This field uses much of the same technology and equipment as home automation for security, entertainment, and energy conservation but tailors it towards elderly and disabled users. For example, automated prompts and reminders utilize motion sensors and pre-recorded audio messages; an automated prompt in the kitchen may remind the resident to turn off the oven, and one by the front door may remind the resident to lock the door.
Impacts of assistive technology.
Overall, assistive technology aims to allow people with disabilities to "participate more fully in all aspects of life (home, school, and community)" and increases their opportunities for "education, social interactions, and potential for meaningful employment." It creates greater independence and control for disabled individuals. For example, in one study of 1,342 infants, toddlers and preschoolers, all with some kind of developmental, physical, sensory, or cognitive disability, the use of assistive technology created improvements in child development. These included improvements in "cognitive, social, communication, literacy, motor, adaptive, and increases in engagement in learning activities."

</doc>
<doc id="655" url="https://en.wikipedia.org/wiki?curid=655" title="Abacus">
Abacus

The abacus ("plural" abaci or abacuses), also called a counting frame, is a calculating tool that was in use in Europe, China and Russia, centuries before the adoption of the written Hindu–Arabic numeral system and is still used by merchants, traders and clerks in some parts of Eastern Europe, Russia, China and Africa. Today, abaci are often constructed as a bamboo frame with beads sliding on wires, but originally they were beans or stones moved in grooves in sand or on tablets of wood, stone, or metal.
Etymology.
The use of the word "abacus" dates before 1387 AD, when a Middle English work borrowed the word from Latin to describe a sandboard abacus. The Latin word came from Greek ἄβαξ "abax" which means something without base, and improperly, any piece of rectangular board or plank. 
Alternatively, without reference to ancient texts on etymology, it has been suggested that it means "a square tablet strewn with dust", or "drawing-board covered with dust (for the use of mathematics)" (the exact shape of the Latin perhaps reflects the genitive form of the Greek word, ἄβακoς "abakos"). Whereas the table strewn with dust definition is popular, there are those that do not place credence in this at all and in fact state that it is not proven. Greek ἄβαξ itself is probably a borrowing of a Northwest Semitic, perhaps Phoenician, word akin to Hebrew "ʾābāq" (אבק), "dust" (or in post-Biblical sense meaning "sand used as a writing surface").
The preferred plural of "abacus" is a subject of disagreement, with both "abacuses" and "abaci" in use. The user of an abacus is called an "abacist".
History.
Mesopotamian.
The period 2700–2300 BC saw the first appearance of the Sumerian abacus, a table of successive columns which delimited the successive orders of magnitude of their sexagesimal number system.
Some scholars point to a character from the Babylonian cuneiform which may have been derived from a representation of the abacus. It is the belief of Old Babylonian scholars such as Carruccio that Old Babylonians "may have used the abacus for the operations of addition and subtraction; however, this primitive device proved difficult to use for more complex calculations".
Egyptian.
The use of the abacus in Ancient Egypt is mentioned by the Greek historian Herodotus, who writes that the Egyptians manipulated the pebbles from right to left, opposite in direction to the Greek left-to-right method. Archaeologists have found ancient disks of various sizes that are thought to have been used as counters. However, wall depictions of this instrument have not been discovered.
Persian.
During the Achaemenid Empire, around 600 BC the Persians first began to use the abacus. Under the Parthian, Sassanian and Iranian empires, scholars concentrated on exchanging knowledge and inventions with the countries around them – India, China, and the Roman Empire, when it is thought to have been exported to other countries.
Greek.
The earliest archaeological evidence for the use of the Greek abacus dates to the 5th century BC. Also Demosthenes (384 BC–322 BC) talked of the need to use pebbles for calculations too difficult for your head. A play by Alexis from the 4th century BC mentions an abacus and pebbles for accounting, and both Diogenes and Polybius mention men that sometimes stood for more and sometimes for less, like the pebbles on an abacus. The Greek abacus was a table of wood or marble, pre-set with small counters in wood or metal for mathematical calculations. This Greek abacus saw use in Achaemenid Persia, the Etruscan civilization, Ancient Rome and, until the French Revolution, the Western Christian world.
A tablet found on the Greek island Salamis in 1846 AD (the Salamis Tablet), dates back to 300 BC, making it the oldest counting board discovered so far. It is a slab of white marble long, wide, and thick, on which are 5 groups of markings. In the center of the tablet is a set of 5 parallel lines equally divided by a vertical line, capped with a semicircle at the intersection of the bottom-most horizontal line and the single vertical line. Below these lines is a wide space with a horizontal crack dividing it. Below this crack is another group of eleven parallel lines, again divided into two sections by a line perpendicular to them, but with the semicircle at the top of the intersection; the third, sixth and ninth of these lines are marked with a cross where they intersect with the vertical line. Also from this time frame the "Darius Vase" was unearthed in 1851. It was covered with pictures including a "treasurer" holding a wax tablet in one hand while manipulating counters on a table with the other.
Chinese.
The earliest known written documentation of the Chinese abacus dates to the 2nd century BC.
The Chinese abacus, known as the suanpan (算盤, lit. "Counting tray", Mandarin "suàn pán", Cantonese "syun3 pun4"), is typically tall and comes in various widths depending on the operator. It usually has more than seven rods. There are two beads on each rod in the upper deck and five beads each in the bottom for both decimal and hexadecimal computation. The beads are usually rounded and made of a hardwood. The beads are counted by moving them up or down towards the beam. If you move them toward the beam, you count their value. If you move away, you don't count their value. The suanpan can be reset to the starting position instantly by a quick movement along the horizontal axis to spin all the beads away from the horizontal beam at the center.
Suanpans can be used for functions other than counting. Unlike the simple counting board used in elementary schools, very efficient suanpan techniques have been developed to do multiplication, division, addition, subtraction, square root and cube root operations at high speed. There are currently schools teaching students how to use it.
In the long scroll "Along the River During the Qingming Festival" painted by Zhang Zeduan (1085–1145 AD) during the Song dynasty (960–1297 AD), a suanpan is clearly seen lying beside an account book and doctor's prescriptions on the counter of an apothecary's (Feibao).
The similarity of the Roman abacus to the Chinese one suggests that one could have inspired the other, as there is some evidence of a trade relationship between the Roman Empire and China. However, no direct connection can be demonstrated, and the similarity of the abaci may be coincidental, both ultimately arising from counting with five fingers per hand. Where the Roman model (like most modern Korean and Japanese) has 4 plus 1 bead per decimal place, the standard suanpan has 5 plus 2. (Incidentally, this allows use with a hexadecimal numeral system.) Instead of running on wires as in the Chinese, Korean, and Japanese models, the beads of Roman model run in grooves, presumably making arithmetic calculations much slower.
Another possible source of the suanpan is Chinese counting rods, which operated with a decimal system but lacked the concept of zero as a place holder. The zero was probably introduced to the Chinese in the Tang dynasty (618-907 AD) when travel in the Indian Ocean and the Middle East would have provided direct contact with India, allowing them to acquire the concept of zero and the decimal point from Indian merchants and mathematicians.
Roman.
The normal method of calculation in ancient Rome, as in Greece, was by moving counters on a smooth table. Originally pebbles ("calculi") were used. Later, and in medieval Europe, jetons were manufactured. Marked lines indicated units, fives, tens etc. as in the Roman numeral system. This system of 'counter casting' continued into the late Roman empire and in medieval Europe, and persisted in limited use into the nineteenth century. Due to Pope Sylvester II's reintroduction of the abacus with very useful modifications, it became widely used in Europe once again during the 11th century This abacus used beads on wires, unlike the traditional Roman counting boards, which meant the abacus could be used much faster.
Writing in the 1st century BC, Horace refers to the wax abacus, a board covered with a thin layer of black wax on which columns and figures were inscribed using a stylus.
One example of archaeological evidence of the Roman abacus, shown here in reconstruction, dates to the 1st century AD. It has eight long grooves containing up to five beads in each and eight shorter grooves having either one or no beads in each. The groove marked I indicates units, X tens, and so on up to millions. The beads in the shorter grooves denote fives –five units, five tens etc., essentially in a bi-quinary coded decimal system, obviously related to the Roman numerals. The short grooves on the right may have been used for marking Roman "ounces" (i.e. fractions).
Indian.
There is no clear evidence for use of abacus in India. The decimal number system invented in India replaced use of abacus in Western Europe.
The "Abhidharmakośabhāṣya" of Vasubandhu (316-396), a Sanskrit work on Buddhist philosophy, says that the second-century CE philosopher Vasumitra said that, "placing a wick (Sanskrit "vartikā") on the number one ("ekāṅka") means it is a one, while placing the wick on the number hundred means it is called a hundred, and on the number one thousand means it is called a thousand". It is unclear exactly what this arrangement may have been. Around the 5th century, Indian clerks were already finding new ways of recording the contents of the Abacus. Hindu texts used the term "śūnya" (zero) to indicate the empty column on the abacus.
Japanese.
In Japanese, the abacus is called "soroban" (, lit. "Counting tray"), imported from China in the 14th century. It was probably in use by the working class a century or more before the ruling class started, as the class structure did not allow for devices used by the lower class to be adopted or used by the ruling class. The 1/4 abacus, which is suited to decimal calculation, appeared circa 1930, and became widespread as the Japanese abandoned hexadecimal weight calculation which was still common in China. The abacus is still manufactured in Japan today even with the proliferation, practicality, and affordability of pocket electronic calculators. The use of the soroban is still taught in Japanese primary schools as part of mathematics, primarily as an aid to faster mental calculation. Using visual imagery of a soroban, one can arrive at the answer in the same time as, or even faster than, is possible with a physical instrument.
Korean.
The Chinese abacus migrated from China to Korea around 1400 AD. Koreans call it "jupan" (주판), "supan" (수판) or "jusan-means calculating with an abacus-" (주산).
Native American.
Some sources mention the use of an abacus called a "nepohualtzintzin" in ancient Aztec culture. This Mesoamerican abacus used a 5-digit base-20 system.
The word Nepōhualtzintzin comes from Nahuatl and it is formed by the roots; "Ne" - personal -; "pōhual" or "pōhualli" - the account -; and "tzintzin" - small similar elements. Its complete meaning was taken as: counting with small similar elements by somebody. Its use was taught in the Calmecac to the "temalpouhqueh" , who were students dedicated to take the accounts of skies, from childhood.
The Nepōhualtzintzin was divided in two main parts separated by a bar or intermediate cord. In the left part there were four beads, which in the first row have unitary values (1, 2, 3, and 4), and in the right side there are three beads with values of 5, 10, and 15 respectively. In order to know the value of the respective beads of the upper rows, it is enough to multiply by 20 (by each row), the value of the corresponding account in the first row.
Altogether, there were 13 rows with 7 beads in each one, which made up 91 beads in each Nepōhualtzintzin. This was a basic number to understand, 7 times 13, a close relation conceived between natural phenomena, the underworld and the cycles of the heavens. One Nepōhualtzintzin (91) represented the number of days that a season of the year lasts, two Nepōhualtzitzin (182) is the number of days of the corn's cycle, from its sowing to its harvest, three Nepōhualtzintzin (273) is the number of days of a baby's gestation, and four Nepōhualtzintzin (364) completed a cycle and approximate a year (1 days short). When translated into modern computer arithmetic, the Nepōhualtzintzin amounted to the rank from 10 to the 18 in floating point, which calculated stellar as well as infinitesimal amounts with absolute precision, meant that no round off was allowed.
The rediscovery of the Nepōhualtzintzin was due to the Mexican engineer David Esparza Hidalgo, who in his wanderings throughout Mexico found diverse engravings and paintings of this instrument and reconstructed several of them made in gold, jade, encrustations of shell, etc. There have also been found very old Nepōhualtzintzin attributed to the Olmec culture, and even some bracelets of Mayan origin, as well as a diversity of forms and materials in other cultures.
George I. Sanchez, "Arithmetic in Maya", Austin-Texas, 1961 found another base 5, base 4 abacus in the Yucatán peninsula that also computed calendar data. This was a finger abacus, on one hand 0, 1, 2, 3, and 4 were used; and on the other hand 0, 1, 2 and 3 were used. Note the use of zero at the beginning and end of the two cycles. Sanchez worked with Sylvanus Morley, a noted Mayanist.
The quipu of the Incas was a system of colored knotted cords used to record numerical data, like advanced tally sticks – but not used to perform calculations. Calculations were carried out using a yupana (Quechua for "counting tool"; see figure) which was still in use after the conquest of Peru. The working principle of a yupana is unknown, but in 2001 an explanation of the mathematical basis of these instruments was proposed by Italian mathematician Nicolino De Pasquale. By comparing the form of several yupanas, researchers found that calculations were based using the Fibonacci sequence 1, 1, 2, 3, 5 and powers of 10, 20 and 40 as place values for the different fields in the instrument. Using the Fibonacci sequence would keep the number of grains within any one field at a minimum.
Russian.
The Russian abacus, the "schoty" (счёты), usually has a single slanted deck, with ten beads on each wire (except one wire, usually positioned near the user, with four beads for quarter-ruble fractions). Older models have another 4-bead wire for quarter-kopeks, which were minted until 1916. The Russian abacus is often used vertically, with wires from left to right in the manner of a book. The wires are usually bowed to bulge upward in the center, to keep the beads pinned to either of the two sides. It is cleared when all the beads are moved to the right. During manipulation, beads are moved to the left. For easy viewing, the middle 2 beads on each wire (the 5th and 6th bead) usually are of a different colour from the other eight beads. Likewise, the left bead of the thousands wire (and the million wire, if present) may have a different color.
As a simple, cheap and reliable device, the Russian abacus was in use in all shops and markets throughout the former Soviet Union, and the usage of it was taught in most schools until the 1990s. Even the 1874 invention of mechanical calculator, Odhner arithmometer, had not replaced them in Russia and likewise the mass production of Felix arithmometers since 1924 did not significantly reduce their use in the Soviet Union. The Russian abacus began to lose popularity only after the mass production of microcalculators had started in the Soviet Union in 1974. Today it is regarded as an archaism and replaced by the handheld calculator.
The Russian abacus was brought to France around 1820 by the mathematician Jean-Victor Poncelet, who served in Napoleon's army and had been a prisoner of war in Russia. The abacus had fallen out of use in western Europe in the 16th century with the rise of decimal notation and algorismic methods. To Poncelet's French contemporaries, it was something new. Poncelet used it, not for any applied purpose, but as a teaching and demonstration aid. The Turks and the Armenian people also used abaci similar to the Russian schoty. It was named a "coulba" by the Turks and a "choreb" by the Armenians.
School abacus.
Around the world, abaci have been used in pre-schools and elementary schools as an aid in teaching the numeral system and arithmetic.
In Western countries, a bead frame similar to the Russian abacus but with straight wires and a vertical frame has been common (see image). It is still often seen as a plastic or wooden toy.
The wire frame may be used either with positional notation like other abaci (thus the 10-wire version may represent numbers up to 9,999,999,999), or each bead may represent one unit (so that e.g. 74 can be represented by shifting all beads on 7 wires and 4 beads on the 8th wire, so numbers up to 100 may be represented). In the bead frame shown, the gap between the 5th and 6th wire, corresponding to the color change between the 5th and the 6th bead on each wire, suggests the latter use.
The red-and-white abacus is used in contemporary primary schools for a wide range of number-related lessons. The twenty bead version, referred to by its Dutch name "rekenrek", is often used, sometimes on a string of beads, sometimes on a rigid framework.
Uses by the blind.
An adapted abacus, invented by Tim Cranmer, called a Cranmer abacus is still commonly used by individuals who are blind. A piece of soft fabric or rubber is placed behind the beads so that they do not move inadvertently. This keeps the beads in place while the users feel or manipulate them. They use an abacus to perform the mathematical functions multiplication, division, addition, subtraction, square root and cube root.
Although blind students have benefited from talking calculators, the abacus is still very often taught to these students in early grades, both in public schools and state schools for the blind. The abacus teaches mathematical skills that can never be replaced with talking calculators and is an important learning tool for blind students. Blind students also complete mathematical assignments using a braille-writer and Nemeth code (a type of braille code for mathematics) but large multiplication and long division problems can be long and difficult. The abacus gives blind and visually impaired students a tool to compute mathematical problems that equals the speed and mathematical knowledge required by their sighted peers using pencil and paper. Many blind people find this number machine a very useful tool throughout life.
Binary abacus.
The binary abacus is used to explain how computers manipulate numbers. The abacus shows how numbers, letters, and signs can be stored in a binary system on a computer, or via ASCII. The device consists of a series of beads on parallel wires arranged in three separate rows. The beads represent a switch on the computer in either an 'on' or 'off' position.

</doc>
<doc id="656" url="https://en.wikipedia.org/wiki?curid=656" title="Acid">
Acid

An acid (from the Latin "acidus/acēre" meaning "sour") is a chemical substance whose aqueous solutions are characterized by a sour taste, the ability to turn blue litmus red, and the ability to react with bases and certain metals (like calcium) to form salts. An aqueous solution of an acid has a pH of less than 7 and is colloquially also referred to as 'acid' (as in 'dissolved in acid'), while the strict definition refers only to the solute. An acid usually contains a hydrogen atom bonded to a chemical structure that is still energetically favorable after loss of H+ (a positive hydrogen ion or proton). A lower pH means a higher acidity, and thus a higher concentration of positive hydrogen ions in the solution. Chemicals or substances having the property of an acid are said to be acidic.
There are two closely related definitions that apply to acids as described above: the Arrhenius definition and the Brønsted-Lowry definition; a third, the Lewis definition, is only tangentially related. The Arrhenius definition defines acids as substances which increase the concentration of hydrogen ions (H+), or more accurately, hydronium ions (H3O+), when dissolved in water. The Brønsted-Lowry definition is an expansion to include solvents other than water: an acid is a substance which can act as a proton donor. By this definition, any compound which can be deprotonated can be considered an acid. Examples include alcohols and amines which contain O-H or N-H fragments. A Lewis acid is a substance that can accept a pair of electrons to form a covalent bond. Examples of Lewis acids include all metal cations, and electron-deficient molecules such as boron trifluoride and aluminium trichloride. Many Lewis acids are not Arrhenius or Brønsted-Lowry acids, and vice versa.
Common examples of acids include hydrochloric acid (a solution of hydrogen chloride which is found in gastric acid in the stomach and activates digestive enzymes), acetic acid (vinegar is a dilute aqueous solution of this liquid), sulfuric acid (used in car batteries), and tartaric acid (a solid used in baking). As these examples show, acids can be solutions or pure substances, and can be derived from solids, liquids, or gases. Strong acids and some concentrated weak acids are corrosive, but there are exceptions such as carboranes and boric acid.
Definitions and concepts.
Modern definitions are concerned with the fundamental chemical reactions common to all acids.
Most acids encountered in everyday life are aqueous solutions, or can be dissolved in water, so the Arrhenius and Brønsted-Lowry definitions are the most relevant.
The Brønsted-Lowry definition is the most widely used definition; unless otherwise specified, acid-base reactions are assumed to involve the transfer of a proton (H+) from an acid to a base.
Hydronium ions are acids according to all three definitions. Interestingly, although alcohols and amines can be Brønsted-Lowry acids, they can also function as Lewis bases due to the lone pairs of electrons on their oxygen and nitrogen atoms.
Arrhenius acids.
The Swedish chemist Svante Arrhenius attributed the properties of acidity to hydrogen ions (H+) or protons in 1884. An Arrhenius acid is a substance that, when added to water, increases the concentration of H+ ions in the water. Note that chemists often write H+("aq") and refer to the hydrogen ion when describing acid-base reactions but the free hydrogen nucleus, a proton, does not exist alone in water, it exists as the hydronium ion, H3O+. Thus, an Arrhenius acid can also be described as a substance that increases the concentration of hydronium ions when added to water. Examples include molecular substances such as HCl and acetic acid. 
An Arrhenius base, on the other hand, is a substance which increases the concentration of hydroxide (OH−) ions when dissolved in water. This decreases the concentration of hydronium because the ions react to form H2O molecules:
H3O+(aq) + OH−(aq) ⇌ H2O(l) + H2O(l)
Due to this equilibrium, any increase in the concentration of hydronium is accompanied by a decrease in the concentration of hydroxide. Thus, an Arrhenius acid could also be said to be one that decreases hydroxide concentration, while an Arrhenius base increases it.
In an acidic solution, the concentration of hydronium ions is greater than 10−7 moles per liter. Since pH is defined as the negative logarithm of the concentration of hydronium ions, acidic solutions thus have a pH of less than 7.
Brønsted-Lowry acids.
While the Arrhenius concept is useful for describing many reactions, it is also quite limited in its scope. In 1923 chemists Johannes Nicolaus Brønsted and Thomas Martin Lowry independently recognized that acid-base reactions involve the transfer of a proton. A Brønsted-Lowry acid (or simply Brønsted acid) is a species that donates a proton to a Brønsted-Lowry base. Brønsted-Lowry acid-base theory has several advantages over Arrhenius theory. Consider the following reactions of acetic acid (CH3COOH), the organic acid that gives vinegar its characteristic taste:
Both theories easily describe the first reaction: CH3COOH acts as an Arrhenius acid because it acts as a source of H3O+ when dissolved in water, and it acts as a Brønsted acid by donating a proton to water. In the second example CH3COOH undergoes the same transformation, in this case donating a proton to ammonia (NH3), but does not relate to the Arrhenius definition of an acid because the reaction does not produce hydronium. Nevertheless, CH3COOH is both an Arrhenius and a Brønsted-Lowry acid. 
Brønsted-Lowry theory can be used to describe reactions of molecular compounds in nonaqueous solution or the gas phase. Hydrogen chloride (HCl) and ammonia combine under several different conditions to form ammonium chloride, NH4Cl. In aqueous solution HCl behaves as hydrochloric acid and exists as hydronium and chloride ions. The following reactions illustrate the limitations of Arrhenius's definition:
As with the acetic acid reactions, both definitions work for the first example, where water is the solvent and hydronium ion is formed by the HCl solute. The next two reactions do not involve the formation of ions but are still proton-transfer reactions. In the second reaction hydrogen chloride and ammonia (dissolved in benzene) react to form solid ammonium chloride in a benzene solvent and in the third gaseous HCl and NH3 combine to form the solid.
Lewis acids.
A third, only marginally related concept was proposed in 1923 by Gilbert N. Lewis, which includes reactions with acid-base characteristics that do not involve a proton transfer. A Lewis acid is a species that accepts a pair of electrons from another species; in other words, it is an electron pair acceptor. Brønsted acid-base reactions are proton transfer reactions while Lewis acid-base reactions are electron pair transfers. Many Lewis acids are not Brønsted-Lowry acids. Contrast how the following reactions are described in terms of acid-base chemistry:
In the first reaction a fluoride ion, F−, gives up an electron pair to boron trifluoride to form the product tetrafluoroborate. Fluoride "loses" a pair of valence electrons because the electrons shared in the B—F bond are located in the region of space between the two atomic nuclei and are therefore more distant from the fluoride nucleus than they are in the lone fluoride ion. BF3 is a Lewis acid because it accepts the electron pair from fluoride. This reaction cannot be described in terms of Brønsted theory because there is no proton transfer. The second reaction can be described using either theory. A proton is transferred from an unspecified Brønsted acid to ammonia, a Brønsted base; alternatively, ammonia acts as a Lewis base and transfers a lone pair of electrons to form a bond with a hydrogen ion. The species that gains the electron pair is the Lewis acid; for example, the oxygen atom in H3O+ gains a pair of electrons when one of the H—O bonds is broken and the electrons shared in the bond become localized on oxygen. Depending on the context, a Lewis acid may also be described as an oxidizer or an electrophile. Organic Brønsted acids, such as acetic, citric, or oxalic acid, are not Lewis acids. They dissociate in water to produce a Lewis acid, H+, but at the same time also yield an equal amount of a Lewis base (acetate, citrate, or oxalate, respectively, for the acids mentioned). Few, if any, of the acids discussed in the following are Lewis acids.
Dissociation and equilibrium.
Reactions of acids are often generalized in the form HA H+ + A−, where HA represents the acid and A− is the conjugate base. This reaction is the protolysis. Acid-base conjugate pairs differ by one proton, and can be interconverted by the addition or removal of a proton (protonation and deprotonation, respectively). Note that the acid can be the charged species and the conjugate base can be neutral in which case the generalized reaction scheme could be written as HA+ H+ + A. In solution there exists an equilibrium between the acid and its conjugate base. The equilibrium constant "K" is an expression of the equilibrium concentrations of the molecules or the ions in solution. Brackets indicate concentration, such that [H2O] means "the concentration of H2O". The acid dissociation constant "K"a is generally used in the context of acid-base reactions. The numerical value of "K"a is equal to the product of the concentrations of the products divided by the concentration of the reactants, where the reactant is the acid (HA) and the products are the conjugate base and H+.
The stronger of two acids will have a higher "K"a than the weaker acid; the ratio of hydrogen ions to acid will be higher for the stronger acid as the stronger acid has a greater tendency to lose its proton. Because the range of possible values for "K"a spans many orders of magnitude, a more manageable constant, p"K"a is more frequently used, where p"K"a = -log10 "K"a. Stronger acids have a smaller p"K"a than weaker acids. Experimentally determined p"K"a at 25 °C in aqueous solution are often quoted in textbooks and reference material.
Nomenclature.
In the classical naming system, acids are named according to their anions. That ionic suffix is dropped and replaced with a new suffix (and sometimes prefix), according to the table below.
For example, HCl has chloride as its anion, so the -ide suffix makes it take the form hydrochloric acid. In the IUPAC naming system, "aqueous" is simply added to the name of the ionic compound. Thus, for hydrogen chloride, the IUPAC name would be aqueous hydrogen chloride. The prefix "hydro-" is added only if the acid is made up of just hydrogen and one other element.
Classical naming system:
Acid strength.
The strength of an acid refers to its ability or tendency to lose a proton. A strong acid is one that completely dissociates in water; in other words, one mole of a strong acid HA dissolves in water yielding one mole of H+ and one mole of the conjugate base, A−, and none of the protonated acid HA. In contrast, a weak acid only partially dissociates and at equilibrium both the acid and the conjugate base are in solution. Examples of strong acids are hydrochloric acid (HCl), hydroiodic acid (HI), hydrobromic acid (HBr), perchloric acid (HClO4), nitric acid (HNO3) and sulfuric acid (H2SO4). In water each of these essentially ionizes 100%. The stronger an acid is, the more easily it loses a proton, H+. Two key factors that contribute to the ease of deprotonation are the polarity of the H—A bond and the size of atom A, which determines the strength of the H—A bond. Acid strengths are also often discussed in terms of the stability of the conjugate base.
Stronger acids have a larger "K"a and a more negative p"K"a than weaker acids.
Sulfonic acids, which are organic oxyacids, are a class of strong acids. A common example is toluenesulfonic acid (tosylic acid). Unlike sulfuric acid itself, sulfonic acids can be solids. In fact, polystyrene functionalized into polystyrene sulfonate is a solid strongly acidic plastic that is filterable.
Superacids are acids stronger than 100% sulfuric acid. Examples of superacids are fluoroantimonic acid, magic acid and perchloric acid. Superacids can permanently protonate water to give ionic, crystalline hydronium "salts". They can also quantitatively stabilize carbocations.
While "K"a measures the strength of an acid compound, the strength of an aqueous acid solution is measured by pH, which is an indication of the concentration of hydronium in the solution. The pH of a simple solution of an acid compound in water is determined by the dilution of the compound and the compound's "K"a.
Chemical characteristics.
Monoprotic acids.
Monoprotic acids are those acids that are able to donate one proton per molecule during the process of dissociation (sometimes called ionization) as shown below (symbolized by HA):
Common examples of monoprotic acids in mineral acids include hydrochloric acid (HCl) and nitric acid (HNO3). On the other hand, for organic acids the term mainly indicates the presence of one carboxylic acid group and sometimes these acids are known as monocarboxylic acid. Examples in organic acids include formic acid (HCOOH), acetic acid (CH3COOH) and benzoic acid (C6H5COOH).
Polyprotic acids.
Polyprotic acids, also known as polybasic acids, are able to donate more than one proton per acid molecule, in contrast to monoprotic acids that only donate one proton per molecule. Specific types of polyprotic acids have more specific names, such as diprotic acid (two potential protons to donate) and triprotic acid (three potential protons to donate).
A diprotic acid (here symbolized by H2A) can undergo one or two dissociations depending on the pH. Each dissociation has its own dissociation constant, Ka1 and Ka2.
The first dissociation constant is typically greater than the second; i.e., "K"a1 > "K"a2. For example, sulfuric acid (H2SO4) can donate one proton to form the bisulfate anion (HSO4−), for which "K"a1 is very large; then it can donate a second proton to form the sulfate anion (SO42−), wherein the "K"a2 is intermediate strength. The large "K"a1 for the first dissociation makes sulfuric a strong acid. In a similar manner, the weak unstable carbonic acid (H2CO3) can lose one proton to form bicarbonate anion (HCO3−) and lose a second to form carbonate anion (CO32−). Both "K"a values are small, but "K"a1 > "K"a2 .
A triprotic acid (H3A) can undergo one, two, or three dissociations and has three dissociation constants, where "K"a1 > "K"a2 > "K"a3.
An inorganic example of a triprotic acid is orthophosphoric acid (H3PO4), usually just called phosphoric acid. All three protons can be successively lost to yield H2PO4−, then HPO42−, and finally PO43−, the orthophosphate ion, usually just called phosphate. Even though the positions of the three protons on the original phosphoric acid molecule are equivalent, the successive "K"a values differ since it is energetically less favorable to lose a proton if the conjugate base is more negatively charged. An organic example of a triprotic acid is citric acid, which can successively lose three protons to finally form the citrate ion.
Although the subsequent loss of each hydrogen ion is less favorable, all of the conjugate bases are present in solution. The fractional concentration, "α" (alpha), for each species can be calculated. For example, a generic diprotic acid will generate 3 species in solution: H2A, HA−, and A2−. The fractional concentrations can be calculated as below when given either the pH (which can be converted to the [H+]) or the concentrations of the acid with all its conjugate bases:
A plot of these fractional concentrations against pH, for given "K"1 and "K"2, is known as a Bjerrum plot. A pattern is observed in the above equations and can be expanded to the general "n" -protic acid that has been deprotonated "i" -times:
\alpha_{H_{n-i} A^{i-} }= 

</doc>
<doc id="657" url="https://en.wikipedia.org/wiki?curid=657" title="Asphalt">
Asphalt

Asphalt (, , occasionally ), also known as bitumen (, The word is derived from the Ancient Greek ἄσφαλτος "ásphaltos".
The primary use (70%) of asphalt/bitumen is in road construction, where it is used as the glue or binder mixed with aggregate particles to create asphalt concrete. Its other main uses are for bituminous waterproofing products, including production of roofing felt and for sealing flat roofs.
The terms "asphalt" and "bitumen" are often used interchangeably to mean both natural and manufactured forms of the substance. In American English, asphalt (or asphalt cement) is the carefully refined residue from the distillation process of selected crude oils. Outside the United States, the product is often called bitumen. Geologists often prefer the term "bitumen". Common usage often refers to various forms of asphalt/bitumen as "tar", such as at the La Brea Tar Pits. Another archaic term for asphalt/bitumen is "pitch".
Naturally occurring asphalt/bitumen is sometimes specified by the term "crude bitumen". Its viscosity is similar to that of cold molasses while the material obtained from the fractional distillation of crude oil boiling at is sometimes referred to as "refined bitumen". The Canadian province of Alberta has most of the world's reserves of natural bitumen, covering , an area larger than England.
Composition.
The components of asphalt are classified into four classes of compounds: 
The naphthene aromatics and polar aromatics are typically the majority components. Additionally, most natural bitumens contain organosulfur compounds, resulting in an overall sulfur content of up to 4%. Nickel and vanadium are found in the <10 ppm level, as is typical of some petroleum.
The substance is soluble in carbon disulfide. It is commonly modelled as a colloid, with asphaltenes as the dispersed phase and maltenes as the continuous phase. and "it is almost impossible to separate and identify all the different molecules of asphalt, because the number of molecules with different chemical structure is extremely large".
Asphalt/bitumen can sometimes be confused with "coal tar", which is a visually similar black, thermoplastic material produced by the destructive distillation of coal. During the early and mid-20th century when town gas was produced, coal tar was a readily available byproduct and extensively used as the binder for road aggregates. The addition of tar to macadam roads led to the word tarmac, which is now used in common parlance to refer to road-making materials. However, since the 1970s, when natural gas succeeded town gas, asphalt/bitumen has completely overtaken the use of coal tar in these applications. Other examples of this confusion include the La Brea Tar Pits and the Canadian oil sands, both of which actually contain natural bitumen rather than tar. Pitch is another term sometimes used at times to refer to asphalt/bitumen, as in Pitch Lake.
Occurrence.
The great majority of asphalt used commercially is obtained from petroleum. Nonetheless, large amounts of asphalt occur in concentrated form in nature. Naturally occurring deposits of asphalt/bitumen are formed from the remains of ancient, microscopic algae (diatoms) and other once-living things. These remains were deposited in the mud on the bottom of the ocean or lake where the organisms lived. Under the heat (above 50 °C) and pressure of burial deep in the earth, the remains were transformed into materials such as asphalt/bitumen, kerogen, or petroleum.
Natural deposits of asphalt/bitumen include lakes such as the Pitch Lake in Trinidad and Tobago and Lake Bermudez in Venezuela. Natural seeps of asphalt/bitumen occur in the La Brea Tar Pits and in the Dead Sea.
Asphalt/bitumen also occurs in unconsolidated sandstones known as "oil sands" in Alberta, Canada, and the similar "tar sands" in Utah, US.
The Canadian province of Alberta has most of the world's reserves of natural bitumen, in three huge deposits covering , an area larger than England or New York state. These bituminous sands contain of commercially established oil reserves, giving Canada the third largest oil reserves in the world. and produce over of heavy crude oil and synthetic crude oil. Although historically it was used without refining to pave roads, nearly all of the bitumen is now used as raw material for oil refineries in Canada and the United States.
The world's largest deposit of natural bitumen, known as the Athabasca oil sands is located in the McMurray Formation of Northern Alberta. This formation is from the early Cretaceous, and is composed of numerous lenses of oil-bearing sand with up to 20% oil. Isotopic studies attribute the oil deposits to be about 110 million years old. Two smaller but still very large formations occur in the Peace River oil sands and the Cold Lake oil sands, to the west and southeast of the Athabasca oil sands, respectively. Of the Alberta bitumen deposits, only parts of the Athabasca oil sands are shallow enough to be suitable for surface mining. The other 80% has to be produced by oil wells using enhanced oil recovery techniques like steam-assisted gravity drainage.
Much smaller heavy oil or bitumen deposits also occur in the Uinta Basin in Utah, US. The Tar Sand Triangle deposit, for example, is roughly 6% bitumen.
Asphalt/bitumen occurs in hydrothermal veins. An example of this is within the Uinta Basin of Utah, in the US, where there is a swarm of laterally and vertically extensive veins composed of a solid hydrocarbon termed Gilsonite. These veins formed by the polymerization and solidification of hydrocarbons that were mobilized from the deeper oil shales of the Green River Formation during burial and diagenesis.
Asphalt/bitumen is similar to the organic matter in carbonaceous meteorites. However, detailed studies have shown these materials to be distinct. The vast Alberta bitumen resources are believed to have started out as living material from marine plants and animals, mainly algae, that died millions of years ago when an ancient ocean covered Alberta. They were covered by mud, buried deeply over the eons, and gently cooked into oil by geothermal heat at a temperature of . Due to pressure from the rising of the Rocky Mountains in southwestern Alberta, 80 to 55 million years ago, the oil was driven northeast hundreds of kilometres into underground sand deposits left behind by ancient river beds and ocean beaches, thus forming the oil sands.
History.
Ancient times.
The use of asphalt/bitumen for waterproofing and as an adhesive dates at least to the fifth millennium BC in the early Indus valley sites like Mehrgarh, where it was used to line the baskets in which crops were gathered.
In the ancient Middle East, the Sumerians used natural asphalt/bitumen deposits for mortar between bricks and stones, to cement parts of carvings, such as eyes, into place, for ship caulking, and for waterproofing. The Greek historian Herodotus said hot asphalt/bitumen was used as mortar in the walls of Babylon, as did Moses in reference to the Tower of Babel.
A tunnel beneath the river Euphrates at Babylon in the time of Queen Semiramis (ca. 800 BC) was reportedly constructed of burnt bricks covered with asphalt/bitumen as a waterproofing agent.
Asphalt/bitumen was used by ancient Egyptians to embalm mummies. The Persian word for asphalt is "moom", which is related to the English word mummy. The Egyptians' primary source of asphalt/bitumen was the Dead Sea, which the Romans knew as "Palus Asphaltites" (Asphalt Lake).
Approximately 40 AD, Dioscorides described the Dead Sea material as "Judaicum bitumen", and noted other places in the region where it could be found.
The Sidon bitumen is thought to refer to asphalt/bitumen found at Hasbeya. Pliny refers also to asphalt/bitumen being found in Epirus. It was a valuable strategic resource; the object of the first known battle for a hydrocarbon deposit, between the Seleucids and the Nabateans in 312 BC.
In the ancient Far East, natural asphalt/bitumen was slowly boiled to get rid of the higher fractions, leaving a thermoplastic material of higher molecular weight which when layered on objects became quite hard upon cooling. This was used to cover objects that needed waterproofing, such as scabbards and other items. Statuettes of household deities were also cast with this type of material in Japan, and probably also in China.
In North America, archaeological recovery has indicated asphalt/bitumen was sometimes used to adhere stone projectile points to wooden shafts. In Canada, aboriginal people used bitumen seeping out of the banks of the Athabasca and other rivers to waterproof birch bark canoes, and also heated it in smudge pots to ward off mosquitoes in the summer time.
Early use in Europe.
One hundred years after the fall of Constantinople in 1453, Pierre Belon described in his work "Observations" in 1553 that "pissasphalto", a mixture of pitch and bitumen, was used in Dubrovnik for tarring of ships from where it was exported to a market place in Venice where it could be bought by anyone.
An 1838 edition of "Mechanics Magazine" cites an early use of asphalt in France. A pamphlet dated 1621, by "a certain Monsieur d'Eyrinys, states that he had discovered the existence (of asphaltum) in large quantities in the vicinity of Neufchatel", and that he proposed to use it in a variety of ways – "principally in the construction of air-proof granaries, and in protecting, by means of the arches, the water-courses in the city of Paris from the intrusion of dirt and filth", which at that time made the water unusable. "He expatiates also on the excellence of this material for forming level and durable terraces" in palaces, "the notion of forming such terraces in the streets not one likely to cross the brain of a Parisian of that generation". But it was generally neglected in France until the revolution of 1830. Then, in the 1830s, there was a surge of interest, and asphalt became widely used "for pavements, flat roofs, and the lining of cisterns, and in England, some use of it had been made of it for similar purposes". Its rise in Europe was "a sudden phenomenon", after natural deposits were found "in France at Osbann (BasRhin), the Parc (l'Ain) and the Puy-de-la-Poix (Puy-de-Dome)", although it could also be made artificially. One of the earliest uses in France was the laying of about 24,000 square yards of Seyssel asphalt at the Place de la Concorde in 1835.
Photography and art.
Bitumen was used in early photographic technology. In 1826 or 1827, it was used by French scientist Joseph Nicéphore Niépce to make the oldest surviving photograph from nature. The bitumen was thinly coated onto a pewter plate which was then exposed in a camera. Exposure to light hardened the bitumen and made it insoluble, so that when it was subsequently rinsed with a solvent only the sufficiently light-struck areas remained. Many hours of exposure in the camera were required, making bitumen impractical for ordinary photography, but from the 1850s to the 1920s it was in common use as a photoresist in the production of printing plates for various photomechanical printing processes.
Bitumen was the nemesis of many artists during the 19th century. Although widely used for a time, it ultimately proved unstable for use in oil painting, especially when mixed with the most common diluents, such as linseed oil, varnish and turpentine. Unless thoroughly diluted, bitumen never fully solidifies and will in time corrupt the other pigments with which it comes into contact. The use of bitumen as a glaze to set in shadow or mixed with other colors to render a darker tone resulted in the eventual deterioration of many paintings, for instance those of Delacroix. Perhaps the most famous example of the destructiveness of bitumen is Théodore Géricault's Raft of the Medusa (1818–1819), where his use of bitumen caused the brilliant colors to degenerate into dark greens and blacks and the paint and canvas to buckle.
Early use in the United Kingdom.
Among the earlier uses of asphalt/bitumen in the United Kingdom was for etching. William Salmon's "Polygraphice" (1673) provides a recipe for varnish used in etching, consisting of three ounces of virgin wax, two ounces of mastic, and one ounce of asphaltum. By the fifth edition in 1685, he had included more asphaltum recipes from other sources.
The first British patent for the use of asphalt/bitumen was 'Cassell's patent asphalte or bitumen' in 1834. Then on 25 November 1837, Richard Tappin Claridge patented the use of Seyssel asphalt (patent #7849), for use in asphalte pavement, having seen it employed in France and Belgium when visiting with Frederick Walter Simms, who worked with him on the introduction of asphalt to Britain. Dr T. Lamb Phipson writes that his father, Samuel Ryland Phipson, a friend of Claridge, was also "instrumental in introducing the asphalte pavement (in 1836)". Indeed, mastic pavements had been previously employed at Vauxhall by a competitor of Claridge, but without success.
In 1838, Claridge obtained patents in Scotland on 27 March, and Ireland on 23 April, and in 1851 extensions were sought for all three patents, by the trustees of a company previously formed by Claridge. This was "Claridge's Patent Asphalte Company", formed in 1838 for the purpose of introducing to Britain "Asphalte in its natural state from the mine at Pyrimont Seysell in France", and "laid one of the first asphalt pavements in Whitehall". Trials were made of the pavement in 1838 on the footway in Whitehall, the stable at Knightsbridge Barracks, "and subsequently on the space at the bottom of the steps leading from Waterloo Place to St. James Park". "The formation in 1838 of Claridge's Patent Asphalte Company (with a distinguished list of aristocratic patrons, and Marc and Isambard Brunel as, respectively, a trustee and consulting engineer), gave an enormous impetus to the development of a British asphalt industry". "By the end of 1838, at least two other companies, Robinson's and the Bastenne company, were in production", with asphalt being laid as paving at Brighton, Herne Bay, Canterbury, Kensington, the Strand, and a large floor area in Bunhill-row, while meantime Claridge's Whitehall paving "continue(d) in good order".
In 1838, there was a flurry of entrepreneurial activity involving asphalt/bitumen, which had uses beyond paving. For example, asphalt could also used for flooring, damp proofing in buildings, and for waterproofing of various types of pools and baths, with these latter themselves proliferating in the 19th century. On the London stockmarket, there were various claims as to the exclusivity of asphalt quality from France, Germany and England. And numerous patents were granted in France, with similar numbers of patent applications being denied in England due to their similarity to each other. In England, "Claridge's was the type most used in the 1840s and 50s"
In 1914, Claridge's Company entered into a joint venture to produce tar-bound macadam, with materials manufactured through a subsidiary company called Clarmac Roads Ltd. Two products resulted, namely "Clarmac", and "Clarphalte", with the former being manufactured by Clarmac Roads and the latter by Claridge's Patent Asphalte Co., although "Clarmac" was more widely used. However, the First World War impacted financially on the Clarmac Company, which entered into liquidation in 1915. The failure of Clarmac Roads Ltd had a flow-on effect to Claridge's Company, which was itself compulsorily wound up, ceasing operations in 1917, having invested a substantial amount of funds into the new venture, both at the outset, and in a subsequent attempt to save the Clarmac Company.
Early use in the US.
The first use of asphalt/bitumen in the New World was by indigenous peoples. On the west coast, as early as the 13th century, the Tongva, Luiseño and Chumash peoples collected the naturally occurring asphalt/bitumen that seeped to the surface above underlying petroleum deposits. All three used the substance as an adhesive. It is found on many different artifacts of tools and ceremonial items. For example, it was used on rattles to adhere gourds or turtle shells to rattle handles. It was also used in decorations. Small round shell beads were often set in asphaltum to provide decorations. It was used as a sealant on baskets to make them watertight for carrying water. Asphaltum was used also to seal the planks on ocean-going canoes.
Roads in the US have been paved with materials that include asphalt/bitumen since at least 1870, when a street in front of the Newark, NJ City Hall was paved. In many cases, these early pavings were made from naturally occurring "bituminous rock", such as at Ritchie Mines in Macfarlan in Ritchie County, West Virginia from 1852 to 1873. In 1876, asphalt-based paving was used to pave Pennsylvania Avenue in Washington, DC, in time for the celebration of the national centennial. Asphalt/bitumen was also used for flooring, paving and waterproofing of baths and swimming pools during the early 20th century, following similar trends in Europe.
Early use in Canada.
Canada has the world's largest deposit of natural bitumen in the Athabasca oil sands and Canadian First Nations along the Athabasca River had long used it to waterproof their canoes. In 1719, a Cree Indian named Wa-Pa-Su brought a sample for trade to Henry Kelsey of the Hudson’s Bay Company, who was the first recorded European to see it. However, it wasn't until 1787 that fur trader and explorer Alexander MacKenzie saw the Athabasca oil sands and said, "At about 24 miles from the fork (of the Athabasca and Clearwater Rivers) are some bituminous fountains into which a pole of 20 feet long may be inserted without the least resistance."
The value of the deposit was obvious from the start, but the means of extracting the bitumen were not. The nearest town, Fort McMurray, Alberta was a small fur trading post, other markets were far away, and transportation costs were too high to ship the raw bituminous sand for paving. In 1915, Sidney Ells of the Federal Mines Branch experimented with separation techniques and used the bitumen to pave 600 feet of road in Edmonton, Alberta. Other roads in Alberta were paved with oil sands, but it was generally not economic. During the 1920s Dr. Karl A. Clark of the Alberta Research Council patented a hot water oil separation process and entrepreneur Robert C. Fitzsimmons built the Bitumount oil separation plant, which between 1925 and 1958 produced up to per day of bitumen using Dr. Clark's method. Most of the bitumen was used for waterproofing roofs, but other uses included fuels, lubrication oils, printers ink, medicines, rust and acid-proof paints, fireproof roofing, street paving, patent leather, and fence post preservatives. Eventually Fitzsimmons ran out of money and the plant was taken over by the Alberta government. Today the Bitumount plant is a Provincial Historic Site.
Modern use.
Rolled asphalt concrete.
The largest use of asphalt/bitumen is for making asphalt concrete for road surfaces and accounts for approximately 85% of the asphalt consumed in the United States. Asphalt concrete pavement mixes are typically composed of 5% asphalt/bitumen cement and 95% aggregates (stone, sand, and gravel). Due to its highly viscous nature, asphalt/bitumen cement must be heated so it can be mixed with the aggregates at the asphalt mixing facility. The temperature required varies depending upon characteristics of the asphalt/bitumen and the aggregates, but warm-mix asphalt technologies allow producers to reduce the temperature required. There are about 4,000 asphalt concrete mixing plants in the U.S., and a similar number in Europe.
When maintenance is performed on asphalt pavements, such as milling to remove a worn or damaged surface, the removed material can be returned to a facility for processing into new pavement mixtures. The asphalt/bitumen in the removed material can be reactivated and put back to use in new pavement mixes. With some 95% of paved roads being constructed of or surfaced with asphalt, a substantial amount of asphalt pavement material is reclaimed each year. According to industry surveys conducted annually by the Federal Highway Administration and the National Asphalt Pavement Association, more than 99% of the asphalt removed each year from road surfaces during widening and resurfacing projects is reused as part of new pavements, roadbeds, shoulders and embankments.
Asphalt concrete paving is widely used in airports around the world. Due to the sturdiness and ability to be repaired quickly, it is widely used for runways dedicated to aircraft landing and taking off.
Mastic asphalt.
Mastic asphalt is a type of asphalt which differs from dense graded asphalt (asphalt concrete) in that it has a higher asphalt/bitumen (binder) content, usually around 7–10% of the whole aggregate mix, as opposed to rolled asphalt concrete, which has only around 5% added asphalt/bitumen. This thermoplastic substance is widely used in the building industry for waterproofing flat roofs and tanking underground. Mastic asphalt is heated to a temperature of and is spread in layers to form an impervious barrier about thick.
Asphalt emulsion.
A number of technologies allow asphalt/bitumen to be mixed at much lower temperatures. These involve mixing with petroleum solvents to form "cutbacks" with reduced melting point, or mixtures with water to turn the asphalt/bitumen into an emulsion. Asphalt emulsions contain up to 70% asphalt/bitumen and typically less than 1.5% chemical additives. There are two main types of emulsions with different affinity for aggregates, cationic and anionic. Asphalt emulsions are used in a wide variety of applications. Chipseal involves spraying the road surface with asphalt emulsion followed by a layer of crushed rock, gravel or crushed slag. Slurry seal involves the creation of a mixture of asphalt emulsion and fine crushed aggregate that is spread on the surface of a road. Cold-mixed asphalt can also be made from asphalt emulsion to create pavements similar to hot-mixed asphalt, several inches in depth and asphalt emulsions are also blended into recycled hot-mix asphalt to create low-cost pavements.
Synthetic crude oil.
Synthetic crude oil, also known as syncrude, is the output from a bitumen upgrader facility used in connection with oil sand production in Canada. Bituminous sands are mined using enormous (100 ton capacity) power shovels and loaded into even larger (400 ton capacity) dump trucks for movement to an upgrading facility. The process used to extract the bitumen from the sand is a hot water process originally developed by Dr. Karl Clark of the University of Alberta during the 1920s. After extraction from the sand, the bitumen is fed into a bitumen upgrader which converts it into a light crude oil equivalent. This synthetic substance is fluid enough to be transferred through conventional oil pipelines and can be fed into conventional oil refineries without any further treatment. By 2015 Canadian bitumen upgraders were producing over per day of synthetic crude oil, of which 75% was exported to oil refineries in the United States.
In Alberta, five bitumen upgraders produce synthetic crude oil and a variety of other products: The Suncor Energy upgrader near Fort McMurray, Alberta produces synthetic crude oil plus diesel fuel; the Syncrude Canada, Canadian Natural Resources, and Nexen upgraders near Fort McMurray produce synthetic crude oil; and the Shell Scotford Upgrader near Edmonton produces synthetic crude oil plus an intermediate feedstock for the nearby Shell Oil Refinery. A sixth upgrader, under construction in 2015 near Redwater, Alberta, will upgrade half of its crude bitumen directly to diesel fuel, with the remainder of the output being sold as feedstock to nearby oil refineries and petrochemical plants.
Non-upgraded crude bitumen.
Canadian bitumen does not differ substantially from oils such as Venezuelan extra-heavy and Mexican heavy oil in chemical composition, and the real difficulty is moving the extremely viscous bitumen through oil pipelines to the refinery. Many modern oil refineries are extremely sophisticated and can process non-upgraded bitumen directly into products such as gasoline, diesel fuel, and refined asphalt without any preprocessing. This is particularly common in areas such as the US Gulf coast, where refineries were designed to process Venezuelan and Mexican oil, and in areas such as the US Midwest where refineries were rebuilt to process heavy oil as domestic light oil production declined. Given the choice, such heavy oil refineries usually prefer to buy bitumen rather than synthetic oil because the cost is lower, and in some cases because they prefer to produce more diesel fuel and less gasoline. By 2015 Canadian production and exports of non-upgraded bitumen exceeded that of synthetic crude oil at over per day, of which about 65% was exported to the United States.
Because of the difficulty of moving crude bitumen through pipelines, non-upgraded bitumen is usually diluted with natural-gas condensate in a form called dilbit or with synthetic crude oil, called synbit. However, to meet international competition, much non-upgraded bitumen is now sold as a blend of multiple grades of bitumen, conventional crude oil, synthetic crude oil, and condensate in a standardized benchmark product such as Western Canadian Select. This sour, heavy crude oil blend is designed to have uniform refining characteristics to compete with internationally marketed heavy oils such as Mexican Mayan or Arabian Dubai Crude.
Other uses.
Roofing shingles account for most of the remaining asphalt/bitumen consumption. Other uses include cattle sprays, fence-post treatments, and waterproofing for fabrics. Asphalt/bitumen is used to make Japan black, a lacquer known especially for its use on iron and steel, and it is also used in paint and marker inks by some graffiti supply companies to increase the weather resistance and permanence of the paint or ink, and to make the color much darker. Asphalt/bitumen is also used to seal some alkaline batteries during the manufacturing process.
Production.
About 40,000,000 tons were produced in 1984. It is obtained as the "heavy" (i.e., difficult to distill) fraction. Material with a boiling point greater than around 500 °C is considered asphalt. Vacuum distillation separates it from the other components in crude oil (such as naphtha, gasoline and diesel). The resulting material is typically further treated to extract small but valuable amounts of lubricants and to adjust the properties of the material to suit applications. In a de-asphalting unit, the crude asphalt is treated with either propane or butane in a supercritical phase to extract the lighter molecules, which are then separated. Further processing is possible by "blowing" the product: namely reacting it with oxygen. This step makes the product harder and more viscous.
Asphalt/bitumen is typically stored and transported at temperatures around . Sometimes diesel oil or kerosene are mixed in before shipping to retain liquidity; upon delivery, these lighter materials are separated out of the mixture. This mixture is often called "bitumen feedstock", or BFS. Some dump trucks route the hot engine exhaust through pipes in the dump body to keep the material warm. The backs of tippers carrying asphalt/bitumen, as well as some handling equipment, are also commonly sprayed with a releasing agent before filling to aid release. Diesel oil is no longer used as a release agent due to environmental concerns.
From oil sands.
Naturally occurring crude asphalt/bitumen impregnated in sedimentary rock is the prime feed stock for petroleum production from "Oil sands", currently under development in Alberta, Canada. Canada has most of the world's supply of natural asphalt/bitumen, covering 140,000 square kilometres (an area larger than England), giving it the second-largest proven oil reserves in the world. The Athabasca oil sands is the largest asphalt/bitumen deposit in Canada and the only one accessible to surface mining, although recent technological breakthroughs have resulted in deeper deposits becoming producible by "in situ" methods. Because of oil price increases after 2003, producing bitumen became highly profitable, but as a result of the decline after 2014 it became uneconomic to build new plants again. By 2014, Canadian crude asphalt/bitumen production averaged about per day and was projected to rise to per day by 2020. The total amount of crude asphalt/bitumen in Alberta which could be extracted is estimated to be about , which at a rate of would last about 200 years.
Alternatives and bioasphalt.
Although uncompetitive economically, asphalt/bitumen can be made from nonpetroleum-based renewable resources such as sugar, molasses and rice, corn and potato starches. Asphalt/bitumen can also be made from waste material by fractional distillation of used motor oil, which is sometimes otherwise disposed of by burning or dumping into landfills. Use of motor oil may cause premature cracking in colder climates, resulting in roads that need to be repaved more frequently.
Nonpetroleum-based asphalt/bitumen binders can be made light-colored. Lighter-colored roads absorb less heat from solar radiation, and have less surface heat than darker surfaces, reducing their contribution to the urban heat island effect. Parking lots that use asphalt alternatives are called green parking lots.
Natural bitumen.
Selenizza is a naturally occurring solid hydrocarbon bitumen found in the native asphalt deposit of Selenice, in Albania, the only European asphalt mine still in use. The rock asphalt is found in the form of veins, filling cracks in a more or less horizontal direction. The bitumen content varies from 83% to 92% (soluble in carbon disulphide), with a penetration value near to zero and a softening point (ring & ball) around 120 °C. The insoluble matter, consisting mainly of silica ore, ranges from 8% to 17%.
The Albanian bitumen extraction has a long history and was practiced in an organized way by the Romans. After centuries of silence, the first mentions of Albanian bitumen appeared only in 1868, when the Frenchman Coquand published the first geological description of the deposits of Albanian bitumen. In 1875, the exploitation rights were granted to the Ottoman government and in 1912, they were transferred to the Italian company Simsa. Since 1945, the mine was exploited by the Albanian government and from 2001 to date, the management passed to a French company, which organized the mining process for the manufacture of the natural bitumen on an industrial scale.
Today the mine is predominantly exploited in an open pit quarry but several of the many underground mines (deep and extending over several km) still remain viable. The bitumen Selenizza is produced primarily in granular form, after melting the asphalt pieces selected in the mine.
Selenizza is mainly used as an additive in the road construction sector. It is mixed with traditional bitumen to improve both the viscoelastic properties and the resistance to ageing. It may be blended with the hot bitumen in tanks, but its granular form allows it to be fed in the mixer or in the recycling ring of normal asphalt plants. Other typical applications include the production of mastic asphalts for sidewalks, bridges, car-parks and urban roads as well as drilling fluid additives for the oil and gas industry. Selenizza is available in powder or in granular material of various particle sizes and is packaged in big bags or in thermal fusible polyethylene bags.
A Life Cycle Assessment (LCA) study of the natural bitumen Selenizza compared with petroleum bitumen, has shown that the environmental impact of the natural bitumen is about half the impact of the road bitumen produced in oil refineries in terms of carbon dioxide emission.
Occupational safety.
People can be exposed to asphalt in the workplace by breathing in fumes or skin absorption. The National Institute for Occupational Safety and Health (NIOSH) has set a Recommended exposure limit (REL) of 5 mg/m3 over a 15-minute period. Asphalt is basically an inert material that must be heated or diluted to a point where it becomes workable for the production of materials for paving, roofing, and other applications. In examining the potential health hazards associated with asphalt, the International Agency for Research on Cancer (IARC) determined that it is the application parameters, predominantly temperature, that effect occupational exposure and the potential bioavailable carcinogenic hazard/risk of the asphalt emissions. In particular, temperatures greater than 199 °C (390 °F), were shown to produce a greater exposure risk than when asphalt was heated to lower temperatures, such as those typically used in asphalt pavement mix production and placement.
Etymology.
The word "asphalt" is derived from the late Middle English, in turn from French "asphalte", based on Late Latin "asphalton", "asphaltum", which is the latinisation of the Greek ἄσφαλτος ("ásphaltos", "ásphalton"), a word meaning "asphalt/bitumen/pitch", which perhaps derives from ἀ-, "without" and σφάλλω ("sfallō"), "make fall". Note that in French, the term "asphalte" is used for naturally occurring bitumen-soaked limestone deposits, and for specialised manufactured products with fewer voids or greater bitumen content than the "asphaltic concrete" used to pave roads. It is a significant fact that the first use of asphalt by the ancients was in the nature of a cement for securing or joining together various objects, and it thus seems likely that the name itself was expressive of this application. Specifically Herodotus mentioned that bitumen was brought to Babylon to build its gigantic fortification wall. From the Greek, the word passed into late Latin, and thence into French ("asphalte") and English ("asphaltum" and "asphalt").
The expression "bitumen" originated in the Sanskrit, where we find the words "jatu", meaning "pitch," and "jatu-krit", meaning "pitch creating", "pitch producing" (referring to coniferous or resinous trees). The Latin equivalent is claimed by some to be originally "gwitu-men" (pertaining to pitch), and by others, "pixtumens" (exuding or bubbling pitch), which was subsequently shortened to "bitumen", thence passing via French into English. From the same root is derived the Anglo Saxon word "cwidu" (mastix), the German word "Kitt" (cement or mastic) and the old Norse word "kvada".
Neither of the terms asphalt or bitumen should be confused with tar or coal tars.
Modern usage.
In British English, the word 'asphalt' is used to refer to a mixture of mineral aggregate and asphalt/bitumen (also called tarmac in common parlance). When bitumen is mixed with clay it is usually called asphaltum. The earlier word 'asphaltum' is now archaic and not commonly used. In American English, 'asphalt' is equivalent to the British 'bitumen'. However, 'asphalt' is also commonly used as a shortened form of 'asphalt concrete' (therefore equivalent to the British 'asphalt' or 'tarmac'). In Australian English, bitumen is often used as the generic term for road surfaces. In Canadian English, the word bitumen is used to refer to the vast Canadian deposits of extremely heavy crude oil, while asphalt is used for the oil refinery product used to pave roads and manufacture roof shingles and various waterproofing products. Diluted bitumen (diluted with naphtha to make it flow in pipelines) is known as dilbit in the Canadian petroleum industry, while bitumen "upgraded" to synthetic crude oil is known as syncrude and syncrude blended with bitumen as synbit.
Bitumen is still the preferred geological term for naturally occurring deposits of the solid or semi-solid form of petroleum. Bituminous rock is a form of sandstone impregnated with bitumen. The tar sands of Alberta, Canada are a similar material.

</doc>
<doc id="659" url="https://en.wikipedia.org/wiki?curid=659" title="American National Standards Institute">
American National Standards Institute

The American National Standards Institute (ANSI, ) is a private non-profit organization that oversees the development of voluntary consensus standards for products, services, processes, systems, and personnel in the United States. The organization also coordinates U.S. standards with international standards so that American products can be used worldwide.
ANSI accredits standards that are developed by representatives of other standards organizations, government agencies, consumer groups, companies, and others. These standards ensure that the characteristics and performance of products are consistent, that people use the same definitions and terms, and that products are tested the same way. ANSI also accredits organizations that carry out product or personnel certification in accordance with requirements defined in international standards.
The organization's headquarters are in Washington, DC. ANSI's operations office is located in New York City. The ANSI annual operating budget is funded by the sale of publications, membership dues and fees, accreditation services, fee-based programs, and international standards programs.
History.
ANSI was originally formed in 1918, when six Stanton engineering societies and three government agencies founded the American Engineering Standards Committee (AESC). In 1928, the AESC became the American Standards Association (ASA). In 1966, the ASA was reorganized and became United States of America Standards Institute (USASI). The present name was adopted in 1969.
Prior to 1918, these five founding engineering societies:
had been members of the United Engineering Society (UES).
At the behest of the AIEE, they invited the U.S. government Departments of War, Navy (combined in 1947 to become the Department of Defense or DOD) and Commerce to join in founding a national standards organization.
According to Adam Stanton, the first permanent secretary and head of staff in 1919, AESC started as an ambitious program and little else. Staff for the first year consisted of one executive, Clifford B. LePage, who was on loan from a founding member, ASME. An annual budget of $7,500 was provided by the founding bodies.
In 1931, the organization (renamed ASA in 1928) became affiliated with the U.S. National Committee of the International Electrotechnical Commission (IEC), which had been formed in 1904 to develop electrical and electronics standards.
Members.
ANSI's membership comprises government agencies, organizations, corporations, academic and international bodies, and individuals. In total, the Institute represents the interests of more than 125,000 companies and 3.5 million professionals.
Process.
Though ANSI itself does not develop standards, the Institute oversees the development and use of standards by accrediting the procedures of standards developing organizations. ANSI accreditation signifies that the procedures used by standards developing organizations meet the Institute's requirements for openness, balance, consensus, and due process.
ANSI also designates specific standards as American National Standards, or ANS, when the Institute determines that the standards were developed in an environment that is equitable, accessible and responsive to the requirements of various stakeholders.
Voluntary consensus standards quicken the market acceptance of products while making clear how to improve the safety of those products for the protection of consumers. There are approximately 9,500 American National Standards that carry the ANSI designation.
The American National Standards process involves:
International activities.
In addition to facilitating the formation of standards in the United States, ANSI promotes the use of U.S. standards internationally, advocates U.S. policy and technical positions in international and regional standards organizations, and encourages the adoption of international standards as national standards where appropriate.
The Institute is the official U.S. representative to the two major international standards organizations, the International Organization for Standardization (ISO), as a founding member, and the International Electrotechnical Commission (IEC), via the U.S. National Committee (USNC). ANSI participates in almost the entire technical program of both the ISO and the IEC, and administers many key committees and subgroups. In many instances, U.S. standards are taken forward to ISO and IEC, through ANSI or the USNC, where they are adopted in whole or in part as international standards.
Standards panels.
The Institute administers nine standards panels:
Each of the panels works to identify, coordinate, and harmonize voluntary standards relevant to these areas.
In 2009, ANSI and the National Institute of Standards and Technology (NIST) formed the Nuclear Energy Standards Coordination Collaborative (NESCC). NESCC is a joint initiative to identify and respond to the current need for standards in the nuclear industry.

</doc>
<doc id="661" url="https://en.wikipedia.org/wiki?curid=661" title="Argument (disambiguation)">
Argument (disambiguation)

In philosophy and logic, an argument is an attempt to persuade someone of something, or give evidence or reasons for accepting a particular conclusion.
Argument may also refer to: 

</doc>
<doc id="662" url="https://en.wikipedia.org/wiki?curid=662" title="Apollo 11">
Apollo 11

Apollo 11 was the first spaceflight that landed humans on the Moon. Americans Neil Armstrong and Buzz Aldrin landed on July 20, 1969, at 20:18 UTC ( years ago). Armstrong became the first to step onto the lunar surface six hours later on July 21 at 02:56 UTC; Aldrin joined him about 20 minutes later. They spent about two and a quarter hours together outside the spacecraft, and collected of lunar material for return to Earth. The third member of the mission, Michael Collins, piloted the command spacecraft alone in lunar orbit, until Armstrong and Aldrin returned to it just under a day later for the trip back to Earth.
Launched by a Saturn V rocket from Kennedy Space Center in Merritt Island, Florida, on July 16, Apollo 11 was the fifth manned mission of NASA's Apollo program. The Apollo spacecraft had three parts: a Command Module (CM) with a cabin for the three astronauts, and the only part that landed back on Earth; a Service Module (SM), which supported the Command Module with propulsion, electrical power, oxygen, and water; and a Lunar Module (LM) for landing on the Moon (which itself was composed of two parts). After being sent toward the Moon by the Saturn V's upper stage, the astronauts separated the spacecraft from it and traveled for three days until they entered into lunar orbit. Armstrong and Aldrin then moved into the Lunar Module and landed in the Sea of Tranquility. They stayed a total of about 21½ hours on the lunar surface. After lifting off in the upper part of the Lunar Module and rejoining Collins in the Command Module, they returned to Earth and landed in the Pacific Ocean on July 24.
Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for man, one giant leap for mankind." Apollo 11 effectively ended the Space Race and fulfilled a national goal proposed in 1961 by the U.S. President John F. Kennedy in a speech before the U.S. Congress: "before this decade is out, of landing a man on the Moon and returning him safely to the Earth."
Framework.
Crew.
Apollo 11 was the second all-veteran multi-person crew (the first being Apollo 10) in human spaceflight history. A previous solo veteran flight had been made on Soyuz 1 in 1967 by Soviet cosmonaut Vladimir Komarov.
Collins was originally slated to be the Command Module Pilot (CMP) on Apollo 8 but was removed when he required surgery on his back and was replaced by Jim Lovell, his backup for that flight. After Collins was medically cleared, he took what would have been Lovell's spot on Apollo 11; as a veteran of Apollo 8, Lovell was transferred to Apollo 11's backup crew, but promoted to backup commander.
Backup crew.
In early 1969, Anders accepted a job with the National Space Council effective August 1969 and announced that he would retire as an astronaut on that date. At that point Ken Mattingly was moved from the support crew into parallel training with Anders as backup Command Module Pilot in case Apollo 11 was delayed past its intended July launch (at which point Anders would be unavailable if needed) and would later join Lovell's crew and ultimately be assigned as the original Apollo 13 CMP.
Call signs.
After the crew of Apollo 10 named their spacecraft "Charlie Brown" and "Snoopy", assistant manager for public affairs Julian Scheer wrote to Manned Spacecraft Center director George M. Low to suggest the Apollo 11 crew be less flippant in naming their craft. During early mission planning, the names "Snowcone" and "Haystack" were used and put in the news release, but the crew later decided to change them.
The Command Module was named "Columbia" after the "Columbiad", the giant cannon shell "spacecraft" fired by a giant cannon (also from Florida) in Jules Verne's 1865 novel "From the Earth to the Moon". The Lunar Module was named "Eagle" for the national bird of the United States, the bald eagle, which is featured prominently on the mission insignia.
Insignia.
The Apollo 11 mission insignia was designed by Collins, who wanted a symbol for "peaceful lunar landing by the United States". He chose an eagle as the symbol, put an olive branch in its beak, and drew a lunar background with the Earth in the distance. NASA officials said the talons of the eagle looked too "warlike" and after some discussion, the olive branch was moved to the claws. The crew decided the Roman numeral XI would not be understood in some nations and went with "Apollo 11"; they decided not to put their names on the patch, so it would "be representative of "everyone" who had worked toward a lunar landing". All colors are natural, with blue and gold borders around the patch.
When the Eisenhower dollar coin was released in 1971, the patch design provided the eagle for its reverse side. The design was also used for the smaller Susan B. Anthony dollar unveiled in 1979, ten years after the Apollo 11 mission.
Mementos.
Neil Armstrong's personal preference kit carried a piece of wood from the Wright brothers' 1903 airplane's left propeller and a piece of fabric from its wing, along with a diamond-studded astronaut pin originally given to Deke Slayton by the widows of the Apollo 1 crew. This pin had been intended to be flown on Apollo 1 and given to Slayton after the mission but following the disastrous launch pad fire and subsequent funerals, the widows gave the pin to Slayton and Armstrong took it on Apollo 11.
Mission highlights.
Launch and flight to lunar orbit.
In addition to many people crowding highways and beaches near the launch site, millions watched the event on television, with NASA Chief of Public Information Jack King providing commentary. President Richard M. Nixon viewed the proceedings from the Oval Office of the White House.
A Saturn V launched Apollo 11 from Launch Pad 39A, part of the Launch Complex 39 site at the Kennedy Space Center on July 16, 1969 at 13:32:00 UTC (9:32:00 a.m. EDT local time). It entered Earth orbit, at an altitude of by , twelve minutes later. After one and a half orbits, the S-IVB third-stage engine pushed the spacecraft onto its trajectory toward the Moon with the trans-lunar injection (TLI) burn at 16:22:13 UTC. About 30 minutes later the command/service module pair separated from this last remaining Saturn V stage and docked with the Lunar Module still nestled in the Lunar Module Adaptor. After the Lunar Module was extracted, the combined spacecraft headed for the Moon, while the third stage booster flew on a trajectory past the Moon and into orbit around the Sun.
On July 19 at 17:21:50 UTC, Apollo 11 passed behind the Moon and fired its service propulsion engine to enter lunar orbit. In the thirty orbits that followed, the crew saw passing views of their landing site in the southern Sea of Tranquility (Mare Tranquillitatis) about southwest of the crater Sabine D (0.67408N, 23.47297E). The landing site was selected in part because it had been characterized as relatively flat and smooth by the automated "Ranger 8" and "Surveyor 5" landers along with the "Lunar Orbiter" mapping spacecraft and unlikely to present major landing or extravehicular activity (EVA) challenges.
Lunar descent.
On July 20, 1969, the Lunar Module "Eagle" separated from the Command Module "Columbia". Collins, alone aboard "Columbia", inspected "Eagle" as it pirouetted before him to ensure the craft was not damaged.
As the descent began, Armstrong and Aldrin found that they were passing landmarks on the surface four seconds early and reported that they were "long"; they would land miles west of their target point.
Five minutes into the descent burn, and above the surface of the Moon, the LM navigation and guidance computer distracted the crew with the first of several unexpected "1202" and "1201" program alarms. Inside Mission Control Center in Houston, Texas, computer engineer Jack Garman told guidance officer Steve Bales it was safe to continue the descent, and this was relayed to the crew. The program alarms indicated "executive overflows", meaning the guidance computer could not complete all of its tasks in real time and had to postpone some of them.
Landing.
When Armstrong again looked outside, he saw that the computer's landing target was in a boulder-strewn area just north and east of a diameter crater (later determined to be West crater, named for its location in the western part of the originally planned landing ellipse). Armstrong took semi-automatic control and, with Aldrin calling out altitude and velocity data, landed at 20:17:40 UTC on Sunday July 20 with about 25 seconds of fuel left.
Apollo 11 landed with less fuel than other missions, and the astronauts encountered a premature low fuel warning. This was later found to be the result of greater propellant 'slosh' than expected, uncovering a fuel sensor. On subsequent missions, extra anti-slosh baffles were added to the tanks to prevent this.
Throughout the descent Aldrin had called out navigation data to Armstrong, who was busy piloting the LM. A few moments before the landing, a light informed Aldrin that at least one of the probes hanging from "Eagle" footpads had touched the surface, and he said "Contact light!" Three seconds later, "Eagle" landed and Armstrong said "Shutdown." Aldrin immediately said "Okay, engine stop. ACA – out of detent." Armstrong acknowledged "Out of detent. Auto" and Aldrin continued "Mode control – both auto. Descent engine command override off. Engine arm – off. 413 is in."
Charles Duke, CAPCOM during the landing phase, acknowledged their landing by saying "We copy you down, Eagle."
Armstrong acknowledged Aldrin's completion of the post landing checklist with "Engine arm is off", before responding to Duke with the words, "Houston, Tranquility Base here. The "Eagle" has landed." Armstrong's unrehearsed change of call sign from "Eagle" to "Tranquility Base" emphasized to listeners that landing was complete and successful. Duke mispronounced his reply as he expressed the relief at Mission Control: "Roger, Twan— Tranquility, we copy you on the ground. You got a bunch of guys about to turn blue. We're breathing again. Thanks a lot."
Two and a half hours after landing, before preparations began for the EVA, Aldrin radioed to Earth:
The schedule for the mission called for the astronauts to follow the landing with a five-hour sleep period, since they had been awake since early morning. However, they elected to forgo the sleep period and begin the preparations for the EVA early, thinking that they would be unable to sleep.
Lunar surface operations.
The astronauts planned placement of the Early Apollo Scientific Experiment Package (EASEP) and the U.S. flag by studying their landing site through "Eagle" twin triangular windows, which gave them a 60° field of view. Preparation required longer than the two hours scheduled. Armstrong initially had some difficulties squeezing through the hatch with his Portable Life Support System (PLSS). According to veteran Moon-walker John Young, a redesign of the LM to incorporate a smaller hatch had not been followed by a redesign of the PLSS backpack, so some of the highest heart rates recorded from Apollo astronauts occurred during LM egress and ingress.
Several books indicate early mission timelines had Buzz Aldrin rather than Neil Armstrong as the first man on the Moon.
At 02:39 UTC on Monday July 21, 1969, Armstrong opened the hatch, and at 02:51 UTC began his descent to the lunar surface. The Remote Control Unit controls on his chest kept him from seeing his feet. Climbing down the nine-rung ladder, Armstrong pulled a D-ring to deploy the Modular Equipment Stowage Assembly (MESA) folded against "Eagle" side and activate the TV camera, and at 02:56:15 UTC he set his left foot on the surface. The first landing used slow-scan television incompatible with commercial TV, so it was displayed on a special monitor and a conventional TV camera viewed this monitor, significantly reducing the quality of the picture. The signal was received at Goldstone in the United States but with better fidelity by Honeysuckle Creek Tracking Station in Australia. Minutes later the feed was switched to the more sensitive Parkes radio telescope in Australia. Despite some technical and weather difficulties, ghostly black and white images of the first lunar EVA were received and broadcast to at least 600 million people on Earth. Although copies of this video in broadcast format were saved and are widely available, recordings of the original slow scan source transmission from the lunar surface were accidentally destroyed during routine magnetic tape re-use at NASA.
While still on the ladder, Armstrong uncovered a plaque mounted on the LM Descent Stage bearing two drawings of Earth (of the Western and Eastern Hemispheres), an inscription, and signatures of the astronauts and President Nixon. The inscription read:
After describing the surface dust as "very fine-grained" and "almost like a powder," six and a half hours after landing, Armstrong stepped off "Eagle" footpad and declared, "That's one small step for man, one giant leap for mankind."
Armstrong intended to say "That's one small step for a man", but the word ""a"" is not audible in the transmission, and thus was not initially reported by most observers of the live broadcast. When later asked about his quote, Armstrong said he believed he said "for a man", and subsequent printed versions of the quote included the "a" in square brackets. One explanation for the absence may be that his accent caused him to slur the words "for a" together; another is the intermittent nature of the audio and video links to Earth, partly because of storms near Parkes Observatory. More recent digital analysis of the tape claims to reveal the "a" may have been spoken but obscured by static.
About seven minutes after stepping onto the Moon's surface, Armstrong collected a contingency soil sample using a sample bag on a stick. He then folded the bag and tucked it into a pocket on his right thigh. This was to guarantee there would be some lunar soil brought back in case an emergency required the astronauts to abandon the EVA and return to the LM.
Twelve minutes after the contingency sample was collected, Aldrin joined Armstrong on the surface, and described the view with the simple phrase, "Magnificent desolation."
In addition to fulfilling President Kennedy's mandate to land a man on the Moon before the end of the 1960s, Apollo 11 was an engineering test of the Apollo system; therefore, Armstrong snapped photos of the LM so engineers would be able to judge its post-landing condition. He removed the TV camera from the MESA and made a panoramic sweep, then mounted it on a tripod from the LM. The TV camera cable remained partly coiled and presented a tripping hazard throughout the EVA.
Armstrong said that moving in the lunar gravity, one-sixth of Earth's, was "even perhaps easier than the simulations ... It's absolutely no trouble to walk around." Aldrin joined him on the surface and tested methods for moving around, including two-footed kangaroo hops. The PLSS backpack created a tendency to tip backwards, but neither astronaut had serious problems maintaining balance. Loping became the preferred method of movement. The astronauts reported that they needed to plan their movements six or seven steps ahead. The fine soil was quite slippery. Aldrin remarked that moving from sunlight into "Eagle" shadow produced no temperature change inside the suit, though the helmet was warmer in sunlight, so he felt cooler in shadow.
The astronauts planted a specially designed U.S. flag on the lunar surface, in clear view of the TV camera. Some time later, President Richard Nixon spoke to them through a telephone-radio transmission which Nixon called "the most historic phone call ever made from the White House." Nixon originally had a long speech prepared to read during the phone call, but Frank Borman, who was at the White House as a NASA liaison during Apollo 11, convinced Nixon to keep his words brief, to respect the lunar landing as Kennedy's legacy. Armstrong thanked the President, and gave a brief reflection on the significance of the moment:
Nixon: Hello, Neil and Buzz. I'm talking to you by telephone from the Oval Room at the White House. And this certainly has to be the most historic telephone call ever made. I just can't tell you how proud we all are of what you've done. For every American, this has to be the proudest day of our lives. And for people all over the world, I am sure they too join with Americans in recognizing what an immense feat this is. Because of what you have done, the heavens have become a part of man's world. And as you talk to us from the Sea of Tranquility, it inspires us to redouble our efforts to bring peace and tranquility to Earth. For one priceless moment in the whole history of man, all the people on this Earth are truly one: one in their pride in what you have done, and one in our prayers that you will return safely to Earth.
Armstrong: Thank you Mr. President. It's a great honor and privilege for us to be here, representing not only the United States, but men of peace of all nations, and with interest and curiosity, and men with a vision for the future. It's an honor for us to be able to participate here today.
The MESA failed to provide a stable work platform and was in shadow, slowing work somewhat. As they worked, the moonwalkers kicked up gray dust which soiled the outer part of their suits, the integrated thermal meteoroid garment.
They deployed the EASEP, which included a passive seismograph and a Lunar Ranging Retroreflector (LRRR). Then Armstrong walked from the LM to snap photos at the rim of Little West Crater while Aldrin collected two core tubes. He used the geological hammer to pound in the tubes – the only time the hammer was used on Apollo 11. The astronauts then collected rock samples using scoops and tongs on extension handles. Many of the surface activities took longer than expected, so they had to stop documenting sample collection halfway through the allotted 34 minutes.
Three new minerals were discovered in the rock samples collected by the astronauts: armalcolite, tranquillityite, and pyroxferroite. Armalcolite was named after Armstrong, Aldrin, and Collins.
During this period Mission Control used a coded phrase to warn Armstrong that his metabolic rates were high and that he should slow down. He was moving rapidly from task to task as time ran out. However, as metabolic rates remained generally lower than expected for both astronauts throughout the walk, Mission Control granted the astronauts a 15-minute extension. In a 2010 interview, Armstrong, who had walked a maximum of from the LM, explained that NASA limited the first moonwalk's time and distance because there was no empirical proof of how much cooling water the astronauts' PLSS backpacks would consume to handle their body heat generation while working on the Moon.
Lunar ascent and return.
Aldrin entered "Eagle" first. With some difficulty the astronauts lifted film and two sample boxes containing of lunar surface material to the LM hatch using a flat cable pulley device called the Lunar Equipment Conveyor. Armstrong reminded Aldrin of a bag of memorial items in his suit pocket sleeve, and Aldrin tossed the bag down; Armstrong then jumped to the ladder's third rung and climbed into the LM. After transferring to LM life support, the explorers lightened the ascent stage for return to lunar orbit by tossing out their PLSS backpacks, lunar overshoes, one Hasselblad camera, and other equipment. They then pressurized the LM, and settled down to sleep.
President Nixon's speech writer William Safire had prepared "In Event of Moon Disaster" for the President to read on television in the event the Apollo 11 astronauts were stranded on the Moon. The contingency plan originated in a memo from Safire to Nixon's White House Chief of Staff H. R. Haldeman, in which Safire suggested a protocol the administration might follow in reaction to such a disaster. According to the plan, Mission Control would "close down communications" with the LM, and a clergyman would "commend their souls to the deepest of the deep" in a public ritual likened to burial at sea. The last line of the prepared text contained an allusion to Rupert Brooke's First World War poem, "The Soldier". The plan included presidential telephone calls to the astronauts' wives.
While moving within the cabin, Aldrin accidentally damaged the circuit breaker that would arm the main engine for lift off from the Moon. There was concern this would prevent firing the engine, stranding them on the Moon. Fortunately a felt-tip pen was sufficient to activate the switch. Had this not worked, the Lunar Module circuitry could have been reconfigured to allow firing the ascent engine.
After about seven hours of rest, the crew was awakened by Houston to prepare for the return flight. Two and a half hours later, at 17:54 UTC, they lifted off in "Eagle" ascent stage to rejoin Collins aboard "Columbia" in lunar orbit.
After more than 21½ total hours on the lunar surface, they had left behind scientific instruments that included a retroreflector array used for the Lunar Laser Ranging Experiment and a Passive Seismic Experiment Package used to measure moonquakes. They also left an Apollo 1 mission patch, and a memorial bag containing a gold replica of an olive branch as a traditional symbol of peace and a silicon message disk. The disk carries the goodwill statements by Presidents Eisenhower, Kennedy, Johnson, and Nixon and messages from leaders of 73 countries around the world. The disc also carries a listing of the leadership of the US Congress, a listing of members of the four committees of the House and Senate responsible for the NASA legislation, and the names of NASA's past and present top management. (In his 1989 book, "Men from Earth", Aldrin says that the items included Soviet medals commemorating Cosmonauts Vladimir Komarov and Yuri Gagarin.) Also, according to Deke Slayton's book "Moonshot", Armstrong carried with him a special diamond-studded astronaut pin from Slayton.
Film taken from the LM Ascent Stage upon liftoff from the Moon reveals the American flag, planted some from the descent stage, whipping violently in the exhaust of the ascent stage engine. Aldrin looked up in time to witness the flag topple: "The ascent stage of the LM separated ... I was concentrating on the computers, and Neil was studying the attitude indicator, but I looked up long enough to see the flag fall over." Subsequent Apollo missions usually planted the American flags at least from the LM to prevent them being blown over by the ascent engine exhaust.
After rendezvous with "Columbia", "Eagle"s ascent stage was jettisoned into lunar orbit on July 21, 1969, at 23:41 UTC. Just before the Apollo 12 flight, it was noted that "Eagle" was still likely to be orbiting the Moon. Later NASA reports mentioned that "Eagle" orbit had decayed, resulting in it impacting in an "uncertain location" on the lunar surface. The location is uncertain because the "Eagle" ascent stage was not tracked after it was jettisoned, and the lunar gravity field is sufficiently non-uniform to make the orbit of the spacecraft unpredictable after a short time. NASA estimated that the orbit had decayed within months and would have impacted on the Moon.
On July 23, the last night before splashdown, the three astronauts made a television broadcast in which Collins commented: ... The Saturn V rocket which put us in orbit is an incredibly complicated piece of machinery, every piece of which worked flawlessly ... We have always had confidence that this equipment will work properly. All this is possible only through the blood, sweat, and tears of a number of a people ... All you see is the three of us, but beneath the surface are thousands and thousands of others, and to all of those, I would like to say, "Thank you very much."
Aldrin added: This has been far more than three men on a mission to the Moon; more, still, than the efforts of a government and industry team; more, even, than the efforts of one nation. We feel that this stands as a symbol of the insatiable curiosity of all mankind to explore the unknown ... Personally, in reflecting on the events of the past several days, a verse from Psalms comes to mind. "When I consider the heavens, the work of Thy fingers, the Moon and the stars, which Thou hast ordained; What is man that Thou art mindful of him?"
Armstrong concluded: The responsibility for this flight lies first with history and with the giants of science who have preceded this effort; next with the American people, who have, through their will, indicated their desire; next with four administrations and their Congresses, for implementing that will; and then, with the agency and industry teams that built our spacecraft, the Saturn, the Columbia, the Eagle, and the little EMU, the spacesuit and backpack that was our small spacecraft out on the lunar surface. We would like to give special thanks to all those Americans who built the spacecraft; who did the construction, design, the tests, and put their hearts and all their abilities into those craft. To those people tonight, we give a special thank you, and to all the other people that are listening and watching tonight, God bless you. Good night from Apollo 11.
On the return to Earth, a bearing at the Guam tracking station failed, potentially preventing communication on the last segment of the Earth return. A regular repair was not possible in the available time but the station director, Charles Force, had his ten-year-old son Greg use his small hands to reach into the housing and pack it with grease. Greg later was thanked by Armstrong.
Splashdown and quarantine.
On July 24, the astronauts returned home aboard the Command Module "Columbia" just before dawn local time (16:51 UTC) at , in the Pacific Ocean east of Wake Island, south of Johnston Atoll, and from the recovery ship, .
At 16:44 UTC the drogue parachutes had been deployed and seven minutes later the Command Module struck the water forcefully. During splashdown, the Command Module landed upside down but was righted within 10 minutes by flotation bags triggered by the astronauts. "Everything's okay. Our checklist is complete. Awaiting swimmers", was Armstrong's last official transmission from the "Columbia". A diver from the Navy helicopter hovering above attached a sea anchor to the Command Module to prevent it from drifting. Additional divers attached flotation collars to stabilize the module and position rafts for astronaut extraction. Though the chance of bringing back pathogens from the lunar surface was considered remote, it was considered a possibility and NASA took great precautions at the recovery site. Divers provided the astronauts with Biological Isolation Garments (BIGs) which were worn until they reached isolation facilities on board the "Hornet". Additionally astronauts were rubbed down with a sodium hypochlorite solution and the Command Module wiped with Betadine to remove any lunar dust that might be present. The raft containing decontamination materials was then intentionally sunk.
A second Sea King helicopter hoisted the astronauts aboard one by one, where a NASA flight surgeon gave each a brief physical check during the trip back to the "Hornet".
After touchdown on the "Hornet", the astronauts exited the helicopter, leaving the flight surgeon and three crewmen. The helicopter was then lowered into hangar bay #2 where the astronauts walked the to the Mobile Quarantine Facility (MQF) where they would begin their 21 days of quarantine. This practice would continue for two more Apollo missions, Apollo 12 and Apollo 14, before the Moon was proven to be barren of life and the quarantine process dropped.
President Richard Nixon was aboard "Hornet" to personally welcome the astronauts back to Earth. He told the astronauts, "As a result of what you've done, the world has never been closer together before." After Nixon departed, the "Hornet" was brought alongside the five-ton Command Module where it was placed aboard by the ship's crane, placed on a dolly and moved next to the MQF. The "Hornet" sailed for Pearl Harbor where the Command Module and MQF were airlifted to the Manned Spacecraft Center.
In accordance with the recently passed Extra-Terrestrial Exposure Law, the astronauts were placed in quarantine for fear that the Moon might contain undiscovered pathogens and that the astronauts might have been exposed to them during their Moon walks. However, after almost three weeks in confinement (first in their trailer and later in the Lunar Receiving Laboratory at the Manned Spacecraft Center), the astronauts were given a clean bill of health. On August 10, 1969, the astronauts exited quarantine.
Celebration.
On August 13, they rode in parades in their honor in New York, Chicago, and Los Angeles. On the same evening in Los Angeles there was an official State Dinner to celebrate the flight, attended by members of Congress, 44 governors, the Chief Justice of the United States, and ambassadors from 83 nations at the Century Plaza Hotel. President Richard Nixon and Vice President Spiro T. Agnew honored each astronaut with a presentation of the Presidential Medal of Freedom. This celebration was the beginning of a 45-day "Giant Leap" tour that brought the astronauts to 25 foreign countries and included visits with prominent leaders such as Queen Elizabeth II of the United Kingdom. Many nations honored the first manned Moon landing with special features in magazines or by issuing Apollo 11 commemorative postage stamps or coins.
On September 16, 1969, the three astronauts spoke before a joint session of Congress on Capitol Hill. They presented two US flags, one to the House of Representatives and the other to the Senate, that had been carried to the surface of the Moon with them.
Moon race.
The Soviet Union was secretly attempting to compete with the US in landing a man on the Moon but had been hampered by repeated failures in development of a launcher comparable to the Saturn V. Meanwhile, they tried to beat the US to return lunar material to the Earth by means of unmanned probes. On July 13, three days before Apollo 11's launch, they launched Luna 15, which reached lunar orbit before Apollo 11. During descent, a malfunction caused Luna 15 to crash in Mare Crisium about two hours before Armstrong and Aldrin took off from the surface. The Jodrell Bank Observatory radio telescope in England was later discovered to have recorded transmissions from Luna 15 during its descent, and this was published in July 2009 on the 40th anniversary of Apollo 11.
Spacecraft location.
The Command Module is displayed at the National Air and Space Museum, Washington, D.C. It is in the central "Milestones of Flight" exhibition hall in front of the Jefferson Drive entrance, sharing the main hall with other pioneering flight vehicles such as the Wright Flyer, the "Spirit of St. Louis", the Bell X-1, the North American X-15, Mercury spacecraft "Friendship 7", and Gemini 4. Armstrong's and Aldrin's space suits are displayed in the museum's "Apollo to the Moon" exhibit. The quarantine trailer, the flotation collar, and the righting spheres are displayed at the Smithsonian's Steven F. Udvar-Hazy Center annex near Washington Dulles International Airport in Virginia.
In 2009 the Lunar Reconnaissance Orbiter (LRO) imaged the various Apollo landing sites on the surface of the Moon, for the first time with sufficient resolution to see the descent stages of the lunar modules, scientific instruments, and foot trails made by the astronauts.
In March 2012 Amazon founder Jeff Bezos located the F-1 engines that launched Apollo 11 into space. The engines were found below the Atlantic Ocean's surface through the use of advanced sonar scanning. His team brought at least one of the five engines to the surface. In July 2013, it was confirmed through serial numbers (2044) that F-1 engine parts brought up from the depths of the Atlantic Ocean were from the Apollo 11 launch.
40th anniversary events.
On July 15, 2009, Life.com released a photo gallery of previously unpublished photos of the astronauts taken by "Life" photographer Ralph Morse prior to the Apollo 11 launch.
From July 16–24, 2009, NASA streamed the original mission audio on its website in real time 40 years to the minute after the events occurred.
In addition, it is in the process of restoring the video footage and has released a preview of key moments.
On July 20, 2009, the crew of Armstrong, Aldrin, and Collins met with U.S. President Barack Obama at the White House. "We expect that there is, as we speak, another generation of kids out there who are looking up at the sky and are going to be the next Armstrong, Collins and Aldrin", Obama said. "We want to make sure that NASA is going to be there for them when they want to take their journey."
The John F. Kennedy Presidential Library and Museum set up a Flash website that rebroadcasts the transmissions of Apollo 11 from launch to landing on the Moon.
A group of British scientists interviewed as part of the anniversary events reflected on the significance of the Moon landing:
It was carried out in a technically brilliant way with risks taken ... that would be inconceivable in the risk-averse world of today ... The Apollo programme is arguably the greatest technical achievement of mankind to date ... nothing since Apollo has come close the excitement that was generated by those astronauts – Armstrong, Aldrin and the 10 others who followed them.
On August 7, 2009, an act of Congress awarded the three astronauts a Congressional Gold Medal, the highest civilian award in the United States. The bill was sponsored by Florida Sen. Bill Nelson and Florida Rep. Alan Grayson.
In July 2010, air-to-ground voice recordings and film footage shot in Mission Control during the Apollo 11 powered descent and landing was re-synchronised and released for the first time.
Further reading.
For young readers
External links.
NASA reports
Multimedia

</doc>
<doc id="663" url="https://en.wikipedia.org/wiki?curid=663" title="Apollo 8">
Apollo 8

Apollo 8, the second human spaceflight mission in the United States Apollo space program, was launched on December 21, 1968, and became the first manned spacecraft to leave Earth orbit, reach the Earth's Moon, orbit it and return safely to Earth. The three-astronaut crew — Commander Frank Borman, Command Module Pilot James Lovell, and Lunar Module Pilot William Anders — became the first humans to travel beyond low Earth orbit, the first to see Earth as a whole planet, the first to directly see the far side of the Moon, and then the first to witness Earthrise. The 1968 mission, the third flight of the Saturn V rocket and that rocket's first manned launch, was also the first human spaceflight launch from the Kennedy Space Center, Florida, located adjacent to Cape Canaveral Air Force Station.
The mission was originally planned as Apollo 9, to be performed in early 1969 as the second test of the complete Apollo spacecraft, including the Lunar Module and the Command/Service Module in an elliptical medium Earth orbit. But when the Lunar Module proved unready to make its first test in a lower Earth orbit in December 1968, it was decided in August to fly Apollo 8 in December as a more ambitious lunar orbital flight without the Lunar Module. This meant Borman's crew was scheduled to fly two to three months sooner than originally planned, leaving them a shorter time for training and preparation, thus placing more demands than usual on their time and discipline.
Apollo 8 took three days to travel to the Moon. It orbited ten times over the course of 20 hours, during which the crew made a Christmas Eve television broadcast where they read the first 10 verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo 8's successful mission paved the way for Apollo 11 to fulfill U.S. President John F. Kennedy's goal of landing a man on the Moon before the end of the 1960s. The Apollo 8 astronauts returned to Earth on December 27, 1968, when their spacecraft splashed down in the Northern Pacific Ocean. The crew was named "Time" magazine's "Men of the Year" for 1968 upon their return.
Crew.
Lovell was originally the CMP on the back-up crew, with Michael Collins as the prime crew's CMP. However, Collins was replaced in July 1968, after suffering a cervical disc herniation that required surgery to repair.
This crew was unique among pre-shuttle era missions in that the commander was not the most experienced member of the crew, as Lovell had flown twice before, on Gemini VII and Gemini XII. This was also the first case of the rarity of an astronaut who had commanded a spaceflight mission subsequently flying as a non-commander, as Lovell had previously commanded Gemini XII.
Backup crew.
On a lunar mission, the Command Module Pilot (CMP) was assigned the role of navigator, while the Lunar Module Pilot (LMP) was assigned the role of flight engineer, responsible for monitoring all spacecraft systems, even if the flight didn't include a Lunar Module.
Edwin Aldrin was originally the backup LMP. When Lovell was rotated to the prime crew, no one with experience on CSM-103 (the specific spacecraft used for the mission) was available, so Aldrin was moved to CMP and Fred Haise brought in as backup LMP. Neil Armstrong went on to command Apollo 11, where Aldrin was returned to the LMP position and Collins was assigned as CMP. Haise was rotated out of the crew and onto the backup crew of Apollo 11 as LMP.
Mission control.
The Earth-based mission control teams for Apollo 8 consisted of astronauts assigned to the support crew, as well as non-astronaut flight directors and their staffs. The support crew members were not trained to fly the mission, but were able to stand in for astronauts in meetings and be involved in the minutiae of mission planning, while the prime and backup crews trained. They also served as CAPCOMs during the mission. For Apollo 8, these crew members included astronauts John S. Bull, Vance D. Brand, Gerald P. Carr, and Ken Mattingly. The mission control teams on Earth rotated in three shifts, each led by a flight director. The directors for Apollo 8 included Clifford E. Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team).
Mission insignia.
The triangular shape of the insignia symbolizes the shape of the Apollo Command Module (CM). It shows a red figure-8 looping around the Earth and Moon representing the mission number as well as the circumlunar nature of the mission. On the red number 8 are the names of the three astronauts.
The initial design of the insignia was developed by Jim Lovell. Lovell reportedly sketched the initial design while riding in the backseat of a T-38 flight from California to Houston, shortly after learning of the re-designation of the flight to become a lunar-orbital mission. The graphic design of the insignia was done by Houston artist and animator William Bradley.
Planning.
Apollo 4 and Apollo 6 had been "A" missions, unmanned tests of the Saturn V launch vehicle using an unmanned Block I production model of the Apollo Command and Service Module in Earth orbit. , scheduled for October 1968, would be a manned Earth-orbit flight of the CSM, completing the objectives for Mission "C".
Further missions depended on the readiness of the Lunar Module. Apollo 8 was planned as the "D" mission, to test the LM in a low Earth orbit in December 1968 by James McDivitt, David Scott and Russell Schweickart, while Borman's crew would fly the "E" mission, a more rigorous LM test in an elliptical medium Earth orbit as Apollo 9, in early 1969.
But production of the LM fell behind schedule, and when Apollo 8's LM arrived at Cape Canaveral in June 1968, significant defects were discovered, leading Grumman, the lead contractor for the LM, to predict that the first mission-ready LM would not be ready until at least February 1969. This would mean delaying the "D" and subsequent missions, endangering the program's goal of a lunar landing before the end of 1969.
George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August to keep the program on track despite the LM delay. Since the Command/Service Module (CSM) would be ready three months before the Lunar Module, a CSM-only mission could be flown in December 1968. Instead of just repeating the "C" mission flight of Apollo 7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit. The new mission would also allow NASA to test lunar landing procedures that would otherwise have to wait until Apollo 10, the scheduled "F" mission. This also meant that the medium Earth orbit "E" mission could be dispensed with. The net result was that only the "D" mission had to be delayed.
Almost every senior manager at NASA agreed with this new mission, citing both confidence in the hardware and personnel, and the potential for a significant morale boost provided by a circumlunar flight. The only person who needed some convincing was James E. Webb, the NASA administrator. With the rest of his agency in support of the new mission, Webb eventually approved the mission change. The mission was officially changed from a "D" mission to a "C-Prime" lunar-orbit mission, but was still referred to in press releases as an Earth-orbit mission at Webb's direction. No public announcement was made about the change in mission until November 12, three weeks after Apollo 7's successful Earth-orbit mission and less than 40 days before launch.
With the change in mission for Apollo 8, Director of Flight Crew Operations Deke Slayton decided to swap the crews of the D and E missions. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104.
On September 9, the crew entered the simulators to begin their preparation for the flight. By the time the mission flew, the crew had spent seven hours training for every actual hour of flight. Although all crew members were trained in all aspects of the mission, it was necessary to specialize. Borman, as commander, was given training on controlling the spacecraft during the re-entry. Lovell was trained on navigating the spacecraft in case communication was lost with the Earth. Anders was placed in charge of checking that the spacecraft was in working order.
Added pressure on the Apollo program to make its 1969 landing goal was provided by the Soviet Union's flight of some living creatures, including Russian tortoises, in a cislunar loop around the Moon on Zond 5 and return to Earth on September 21. There was speculation within NASA and the press that they might be preparing to launch cosmonauts on a similar circumlunar mission before the end of 1968.
The Apollo 8 crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how, before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total was a tenth of the amount that the Saturn V would burn every second. The next day, the Lindberghs watched the launch of Apollo 8 from a nearby dune.
Saturn V.
The Saturn V rocket used by Apollo 8 was designated SA-503, or the "03rd" model of the Saturn V ("5") Rocket to be used in the Saturn-Apollo ("SA") program. When it was erected in the Vertical Assembly Building on December 20, 1967, it was thought that the rocket would be used for an unmanned Earth-orbit test flight carrying a boilerplate Command/Service Module. Apollo 6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a manned mission until additional unmanned test flights proved that the Saturn V was ready.
Teams from the Marshall Space Flight Center (MSFC) went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system using helium gas to absorb some of these vibrations was installed.
Of equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the liquid hydrogen valve and shut down engine two, it accidentally shut down engine three's liquid oxygen due to a miswired connection. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage engine—a faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches.
The teams tested their solutions in August 1968 at the Marshall Space Flight Center. A Saturn stage IC was equipped with shock absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems were solved, they gave their approval for a manned mission using SA-503.
The Apollo 8 spacecraft was placed on top of the rocket on September 21 and the rocket made the slow 3-mile (5 km) journey to the launch pad on October 9. Testing continued all through December until the day before launch, including various levels of readiness testing from December 5 through 11. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on December 18, a mere three days before the scheduled launch.
Mission.
Parameter summary.
As the first manned spacecraft to orbit more than one celestial body, Apollo 8's profile had two different sets of orbital parameters, separated by a translunar injection maneuver.
Apollo lunar missions would begin with a nominal circular Earth parking orbit. Apollo 8 was launched into an initial orbit with an apogee of and a perigee of , with an inclination of 32.51° to the Equator, and an orbital period of 88.19 minutes. Propellant venting increased the apogee by over the 2 hours, 44 minutes and 30 seconds spent in the parking orbit.
This was followed by a Trans-Lunar Injection (TLI) burn of the S-IVB third stage for 318 seconds, accelerating the spacecraft from an orbital velocity of to the injection velocity of , which set a record for the highest speed, relative to Earth, that humans had ever traveled. This speed was slightly less than the Earth's escape velocity of , but put Apollo 8 into an elongated elliptical Earth orbit, to a point where the Moon's gravity would capture it.
The standard lunar orbit for Apollo missions was planned as a nominal circular orbit above the Moon's surface. Initial lunar orbit insertion was an ellipse with a perilune of and an apolune of , at an inclination of 12° from the lunar equator. This was then circularized at by , with an orbital period of 128.7 minutes. The effect of lunar mass concentrations ("masscons") on the orbit was found to be greater than initially predicted; over the course of the twenty-hour mission, the orbit was perturbated to by .
Apollo 8 achieved a maximum distance from Earth of .
Launch and trans-lunar injection.
Apollo 8 launched at 7:51:00 a.m. Eastern Standard Time on December 21, 1968, using the Saturn V's three stages to achieve Earth orbit. The S-IC first stage impacted the Atlantic Ocean at and the S-II second stage at . The S-IVB third stage injected the craft into Earth orbit, but remained attached to later perform the trans-lunar injection (TLI) burn that put the spacecraft on a trajectory to the Moon.
The Titan II launch vehicle used for the Gemini program had been notoriously rough-riding, and technicians promised the astronauts that the Saturn V, which was designed for the Apollo program rather than adapted from a missile, would have a much smoother ride. Lovell and Borman, both Gemini veterans, found this promise did not disappoint. During liftoff, they reported feeling nothing but a dull, muted rumble in the distance.
Once the vehicle reached Earth orbit, both the crew and Houston flight controllers spent the next 2 hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. The proper operation of the S-IVB third stage of the rocket was crucial: in the last unmanned test, it had failed to re-ignite for TLI.
During the flight, three fellow astronauts served on the ground as Capsule Communicators (usually referred to as "CAPCOMs") on a rotating schedule. The CAPCOMs were the only people who regularly communicated with the crew. Michael Collins was the first CAPCOM on duty and at 2 hours, 27 minutes and 22 seconds after launch radioed, "Apollo 8. You are Go for TLI." This communication signified that Mission Control had given official permission for Apollo 8 to go to the Moon. Over the next 12 minutes before the TLI burn, the Apollo 8 crew continued to monitor the spacecraft and the S-IVB. The engine ignited on time and performed the TLI burn perfectly.
After the S-IVB had performed its required tasks, it was jettisoned. The crew then rotated the spacecraft to take some photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from it. This marked the first time humans could view the whole Earth at once. Borman became worried that the S-IVB was staying too close to the Command/Service Module and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the Reaction Control System (RCS) thrusters on the Service Module (SM) to add away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in this direction, but at instead. These discussions put the crew an hour behind their flight plan.
Five hours after launch, Mission Control sent a command to the S-IVB booster to vent its remaining fuel through its engine bell to change the booster's trajectory. This S-IVB would then pass the Moon and enter into a solar orbit, posing no further hazard to Apollo 8. The S-IVB subsequently went into a solar orbit with an inclination of 23.47° from the plane of the ecliptic, and an orbital period of 340.80 days. After the insertion into trans-Lunar orbit, the Saturn IVB third stage became a derelict object. It will continue to orbit the Sun for many years.
The Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1 milligray (during a year, the average human receives a dose of 2 to 3 mGy). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew experienced an average radiation dose of 1.6 mGy.
Lunar trajectory.
Jim Lovell's main job as Command Module Pilot was as navigator. Although Mission Control performed all the actual navigation calculations, it was necessary to have a crew member serving as navigator so that the crew could successfully return to Earth in case of communication loss with Mission Control. Lovell navigated by star sightings using a sextant built into the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task proved to be difficult, as a large cloud of debris around the spacecraft formed by the venting S-IVB made it hard to distinguish the stars.
By seven hours into the mission, the crew was about one hour and 40 minutes behind flight plan due to the issues of moving away from the S-IVB and Lovell's obscured star sightings. The crew now placed the spacecraft into Passive Thermal Control (PTC), also known as "barbecue" roll. PTC involved the spacecraft rotating about once per hour along its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, the spacecraft could be heated to over while the parts in shadow would be . These temperatures could cause the heat shield to crack or propellant lines to burst. As it was impossible to get a perfect roll, the spacecraft actually swept out a cone as it rotated. The crew had to make minor adjustments every half-hour as the cone pattern got larger and larger.
The first mid-course correction came 11 hours into the flight. Testing on the ground had shown that the Service Propulsion System (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was "coated" first. Burning the engine for a short period would accomplish coating. This first correction burn was only 2.4 seconds and added about velocity prograde (in the direction of travel). This change was less than the planned due to a bubble of helium in the oxidizer lines causing lower than expected propellant pressure. The crew had to use the small RCS thrusters to make up the shortfall. Two later planned mid-course corrections were canceled as the Apollo 8 trajectory was found to be perfect.
Eleven hours into the flight, the crew had been awake for over 16 hours. Before launch, NASA had decided that at least one crew member should be awake at all times to deal with any issues that might arise. Borman started the first sleep shift, but between the constant radio chatter and mechanical noises, he found sleep difficult.
About an hour after starting his sleep shift, Borman requested clearance to take a Seconal sleeping pill. However, the pill had little effect. Borman eventually fell asleep but then awoke feeling ill. He vomited twice and had a bout of diarrhea that left the spacecraft full of small globules of vomit and feces that the crew cleaned up to the best of their ability. Borman initially decided that he did not want everyone to know about his medical problems, but Lovell and Anders wanted to inform Mission Control. The crew decided to use the Data Storage Equipment (DSE), which could tape voice recordings and telemetry and dump them to Mission Control at high speed. After recording a description of Borman's illness they requested that Mission Control check the recording, stating that they "would like an evaluation of the voice comments".
The Apollo 8 crew and Mission Control medical personnel held a conference using an unoccupied second floor control room (there were two identical control rooms in Houston on the second and third floor, only one of which was used during a mission). The conference participants decided that there was little to worry about and that Borman's illness was either a 24-hour flu, as Borman thought, or a reaction to the sleeping pill. Researchers now believe that he was suffering from space adaptation syndrome, which affects about a third of astronauts during their first day in space as their vestibular system adapts to weightlessness. Space adaptation syndrome had not been an issue on previous spacecraft (Mercury and Gemini), as those astronauts were unable to move freely in the comparatively smaller cabins of those spacecraft. The increased cabin space in the Apollo Command Module afforded astronauts greater freedom of movement, contributing to symptoms of space sickness for Borman and, later, astronaut Russell Schweickart during Apollo 9.
The cruise phase was a relatively uneventful part of the flight, except for the crew checking that the spacecraft was in working order and that they were on course. During this time, NASA scheduled a television broadcast at 31 hours after launch. The Apollo 8 crew used a 2 kg camera that broadcast in black-and-white only, using a Vidicon tube. The camera had two lenses, a very wide-angle (160°) lens, and a telephoto (9°) lens.
During this first broadcast, the crew gave a tour of the spacecraft and attempted to show how the Earth appeared from space. However, difficulties aiming the narrow-angle lens without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, the Earth image became saturated by any bright source without proper filters. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday.
By this time, the crew had completely abandoned the planned sleep shifts. Lovell went to sleep 32½ hours into the flight—3½ hours before he had planned to. A short while later, Anders also went to sleep after taking a sleeping pill.
The crew was unable to see the Moon for much of the outward cruise. Two factors made the Moon almost impossible to see from inside the spacecraft: three of the five windows fogging up due to out-gassed oils from the silicone sealant, and the attitude required for the PTC. It was not until the crew had gone behind the Moon that they would be able to see it for the first time.
The Apollo 8 made a second television broadcast at 55 hours into the flight. This time, the crew rigged up filters meant for the still cameras so they could acquire images of the Earth through the telephoto lens. Although difficult to aim, as they had to maneuver the entire spacecraft, the crew was able to broadcast back to Earth the first television pictures of the Earth. The crew spent the transmission describing the Earth and what was visible and the colors they could see. The transmission lasted 23 minutes.
Lunar sphere of influence.
At about 55 hours and 40 minutes into the flight, the crew of Apollo 8 became the first humans to enter the gravitational sphere of influence of another celestial body. In other words, the effect of the Moon's gravitational force on Apollo 8 became stronger than that of the Earth. At the time it happened, Apollo 8 was from the Moon and had a speed of relative to the Moon. This historic moment was of little interest to the crew since they were still calculating their trajectory with respect to the launch pad at Kennedy Space Center. They would continue to do so until they performed their last mid-course correction, switching to a reference frame based on ideal orientation for the second engine burn they would make in lunar orbit. It was only 13 hours until they would be in lunar orbit.
The last major event before Lunar Orbit Insertion (LOI) was a second mid-course correction. It was in retrograde (against direction of travel) and slowed the spacecraft down by , effectively lowering the closest distance that the spacecraft would pass the moon. At exactly 61 hours after launch, about from the Moon, the crew burned the RCS for 11 seconds. They would now pass from the lunar surface.
At 64 hours into the flight, the crew began to prepare for Lunar Orbit Insertion-1 (LOI-1). This maneuver had to be performed perfectly, and due to orbital mechanics had to be on the far side of the Moon, out of contact with the Earth. After Mission Control was polled for a "go/no go" decision, the crew was told at 68 hours, they were Go and "riding the best bird we can find". At 68 hours and 58 minutes, the spacecraft went behind the Moon and out of radio contact with the Earth.
With 10 minutes before the LOI-1, the crew began one last check of the spacecraft systems and made sure that every switch was in the correct place. At that time, they finally got their first glimpses of the Moon. They had been flying over the unlit side, and it was Lovell who saw the first shafts of sunlight obliquely illuminating the lunar surface. The LOI burn was only two minutes away, so the crew had little time to appreciate the view.
Lunar orbit.
The SPS ignited at 69 hours, 8 minutes, and 16 seconds after launch and burned for 4 minutes and 13 seconds, placing the Apollo 8 spacecraft in orbit around the Moon. The crew described the burn as being the longest four minutes of their lives. If the burn had not lasted exactly the correct amount of time, the spacecraft could have ended up in a highly elliptical lunar orbit or even flung off into space. If it lasted too long they could have struck the Moon. After making sure the spacecraft was working, they finally had a chance to look at the Moon, which they would orbit for the next 20 hours.
On Earth, Mission Control continued to wait. If the crew had not burned the engine or the burn had not lasted the planned length of time, the crew would appear early from behind the Moon. However, this time came and went without Apollo 8 reappearing. Exactly at the calculated moment, the signal was received from the spacecraft, indicating it was in a orbit about the Moon.
After reporting on the status of the spacecraft, Lovell gave the first description of what the lunar surface looked like:
Lovell continued to describe the terrain they were passing over. One of the crew's major tasks was reconnaissance of planned future landing sites on the Moon, especially one in Mare Tranquillitatis that would be the Apollo 11 landing site. The launch time of Apollo 8 had been chosen to give the best lighting conditions for examining the site. A film camera had been set up in one of the spacecraft windows to record a frame every second of the Moon below. Bill Anders spent much of the next 20 hours taking as many photographs as possible of targets of interest. By the end of the mission the crew had taken 700 photographs of the Moon and 150 of the Earth.
Throughout the hour that the spacecraft was in contact with Earth, Borman kept asking how the data for the SPS looked. He wanted to make sure that the engine was working and could be used to return early to the Earth if necessary. He also asked that they receive a "go/no go" decision before they passed behind the Moon on each orbit.
As they reappeared for their second pass in front of the Moon, the crew set up the equipment to broadcast a view of the lunar surface. Anders described the craters that they were passing over. At the end of this second orbit they performed the 11-second LOI-2 burn of the SPS to circularize the orbit to .
Through the next two orbits, the crew continued to keep check of the spacecraft and to observe and photograph the Moon. During the third pass, Borman read a small prayer for his church. He had been scheduled to participate in a service at St. Christopher's Episcopal Church near Seabrook, Texas, but due to the Apollo 8 flight he was unable to. A fellow parishioner and engineer at Mission Control, Rod Rose, suggested that Borman read the prayer which could be recorded and then replayed during the service.
In the foreword to the Millennial Edition of his novel "" Arthur C. Clarke says the crew had told him that "they had been tempted to radio back the discovery of a large black monolith", but discretion prevailed.
Earthrise.
When the spacecraft came out from behind the Moon for its fourth pass across the front, the crew witnessed "Earthrise" for the first time in human history (NASA's Lunar Orbiter 1 took the very first picture of an Earthrise from the vicinity of the Moon, on August 23, 1966). Borman saw the Earth emerging from behind the lunar horizon and called in excitement to the others, taking a black-and-white photo as he did so. In the ensuing scramble Anders took the more famous color photo, later picked by "Life" magazine as one of its hundred photos of the century. Due to the synchronous rotation of the Moon about the Earth, Earthrise is not generally visible from the lunar surface. Earthrise is generally only visible when orbiting the Moon, other than at selected places near the Moon's limb, where libration carries the Earth slightly above and below the lunar horizon.
Anders continued to take photographs while Lovell assumed control of the spacecraft so Borman could rest. Despite the difficulty resting in the cramped and noisy spacecraft, Borman was able to sleep for two orbits, awakening periodically to ask questions about their status. Borman awoke fully, however, when he started to hear his fellow crew members make mistakes. They were beginning to not understand questions and would have to ask for the answers to be repeated. Borman realized that everyone was extremely tired having not had a good night's sleep in over three days. Taking command, he ordered Anders and Lovell to get some sleep and that the rest of the flight plan regarding observing the Moon be scrubbed. At first Anders protested saying that he was fine, but Borman would not be swayed. At last Anders agreed as long as Borman would set up the camera to continue to take automatic shots of the Moon. Borman also remembered that there was a second television broadcast planned, and with so many people expected to be watching he wanted the crew to be alert. For the next two orbits Anders and Lovell slept while Borman sat at the helm. On subsequent Apollo missions, crews would avoid this situation by sleeping on the same schedule.
As they rounded the Moon for the ninth time, the second television transmission began. Borman introduced the crew, followed by each man giving his impression of the lunar surface and what it was like to be orbiting the Moon. Borman described it as being "a vast, lonely, forbidding expanse of nothing". Then, after talking about what they were flying over, Anders said that the crew had a message for all those on Earth. Each man on board read a section from the Biblical creation story from the Book of Genesis. Borman finished the broadcast by wishing a Merry Christmas to everyone on Earth. His message appeared to sum up the feelings that all three crewmen had from their vantage point in lunar orbit. Borman said, "And from the crew of Apollo 8, we close with good night, good luck, a Merry Christmas and God bless all of you—all of you on the good Earth."
The only task left for the crew at this point was to perform the Trans-Earth Injection (TEI), which was scheduled for 2½ hours after the end of the television transmission. The TEI was the most critical burn of the flight, as any failure of the SPS to ignite would strand the crew in lunar orbit, with little hope of escape. As with the previous burn, the crew had to perform the maneuver above the far side of the Moon, out of contact with Earth.
The burn occurred exactly on time. The spacecraft telemetry was reacquired as it re-emerged from behind the Moon at 89 hours, 28 minutes, and 39 seconds, the exact time calculated. When voice contact was regained, Lovell announced, "Please be informed, there is a Santa Claus", to which Ken Mattingly, the current CAPCOM, replied, "That's affirmative, you are the best ones to know." The spacecraft began its journey back to Earth on December 25, Christmas Day.
Unplanned manual re-alignment.
Later, Lovell used some otherwise idle time to do some navigational sightings, maneuvering the module to view various stars by using the computer keyboard. However, he accidentally erased some of the computer's memory, which caused the Inertial Measurement Unit (IMU) to think the module was in the same relative position it had been in before lift-off and fire the thrusters to "correct" the module's attitude.
Once the crew realized why the computer had changed the module's attitude, they realized they would have to re-enter data that would tell the computer its real position. It took Lovell ten minutes to figure out the right numbers, using the thrusters to get the stars Rigel and Sirius aligned, and another 15 minutes to enter the corrected data into the computer.
Sixteen months later, Lovell would once again have to perform a similar manual re-alignment, under more critical conditions, during the Apollo 13 mission, after that module's IMU had to be turned off to conserve energy. In his 1994 book, "Lost Moon: The Perilous Voyage of Apollo 13", Lovell wrote, "My training [on Apollo 8] came in handy!" In that book he dismissed the incident as a "planned experiment", requested by the ground crew. In subsequent interviews Lovell has acknowledged that the incident was an accident, caused by his mistake.
Cruise back to Earth and re-entry.
The cruise back to Earth was mostly a time for the crew to relax and monitor the spacecraft. As long as the trajectory specialists had calculated everything correctly, the spacecraft would re-enter two-and-half days after TEI and splashdown in the Pacific.
On Christmas afternoon, the crew made their fifth television broadcast. This time they gave a tour of the spacecraft, showing how an astronaut lived in space. When they finished broadcasting they found a small present from Deke Slayton in the food locker: a real turkey dinner with stuffing, in the same kind of pack that the troops in Vietnam received. Another Slayton surprise was a gift of three miniature bottles of brandy, that Borman ordered the crew to leave alone until after they landed. They remained unopened, even years after the flight. There were also small presents to the crew from their wives. The next day, at about 124 hours into the mission, the sixth and final TV transmission showed the mission's best video images of the earth, in a four-minute broadcast.
After two uneventful days the crew prepared for re-entry. The computer would control the re-entry and all the crew had to do was put the spacecraft in the correct attitude, blunt end forward. If the computer broke down, Borman would take over.
Once the Command Module was separated from the Service Module, the astronauts were committed to re-entry. Six minutes before they hit the top of the atmosphere, the crew saw the Moon rising above the Earth's horizon, just as had been predicted by the trajectory specialists. As they hit the thin outer atmosphere they noticed it was becoming hazy outside as glowing plasma formed around the spacecraft. The spacecraft started slowing down and the deceleration peaked at 6 g (59 m/s2). With the computer controlling the descent by changing the attitude of the spacecraft, Apollo 8 rose briefly like a skipping stone before descending to the ocean. At the drogue parachute stabilized the spacecraft and was followed at by the three main parachutes. The spacecraft splashdown position was officially reported as in the North Pacific Ocean south of Hawaii.
When it hit the water, the parachutes dragged the spacecraft over and left it upside down, in what was termed Stable 2 position. About six minutes later the Command Module was righted into its normal apex-up splashdown orientation by the inflatable bag uprighting system. As they were buffeted by a swell, Borman was sick, waiting for the three flotation balloons to right the spacecraft. It was 43 minutes after splashdown before the first frogman from the USS "Yorktown" arrived, as the spacecraft had landed before sunrise. Forty-five minutes later, the crew was safe on the deck of the aircraft carrier.
Historical importance.
Apollo 8 came at the end of 1968, a year that had seen much upheaval in the United States and most of the world. Even though the year saw political assassinations, political unrest in the streets of Europe and America, and the Prague Spring, "Time" magazine chose the crew of Apollo 8 as their Men of the Year for 1968, recognizing them as the people who most influenced events in the preceding year. They had been the first people ever to leave the gravitational influence of the Earth and orbit another celestial body. They had survived a mission that even the crew themselves had rated as only having a fifty-fifty chance of fully succeeding. The effect of Apollo 8 can be summed up by a telegram from a stranger, received by Borman after the mission, that simply stated, "Thank you Apollo 8. You saved 1968."
One of the most famous aspects of the flight was the Earthrise picture that was taken as they came around for their fourth orbit of the Moon. This was the first time that humans had taken such a picture whilst actually behind the camera, and it has been credited with a role in inspiring the first Earth Day in 1970. It was selected as the first of "Life" magazine's "100 Photographs That Changed the World". Apollo 11 astronaut Michael Collins said, "Eight's momentous historic significance was foremost"; while many space historians, such as Robert K. Poole, see Apollo 8 as the most historically significant of all the Apollo missions.
The mission was the most widely covered by the media since the first American orbital flight, Mercury-Atlas 6 by John Glenn in 1962. There were 1200 journalists covering the mission, with the BBC coverage being broadcast in 54 countries in 15 different languages. The Soviet newspaper "Pravda" featured a quote from Boris Nikolaevich Petrov, Chairman of the Soviet Interkosmos program, who described the flight as an "outstanding achievement of American space sciences and technology". It is estimated that a quarter of the people alive at the time saw—either live or delayed—the Christmas Eve transmission during the ninth orbit of the Moon. The Apollo 8 broadcasts won an Emmy Award, the highest honor given by the Academy of Television Arts & Sciences.
Madalyn Murray O'Hair, an atheist, later caused controversy by bringing a lawsuit against NASA over the reading from Genesis. O'Hair wished the courts to ban American astronauts—who were all government employees—from public prayer in space. Though the case was rejected by the Supreme Court of the United States for lack of jurisdiction, it caused NASA to be skittish about the issue of religion throughout the rest of the Apollo program. Buzz Aldrin, on Apollo 11, self-communicated Presbyterian Communion on the surface of the Moon after landing; he refrained from mentioning this publicly for several years, and only obliquely referred to it at the time.
In 1969, the United States Postal Service issued a postage stamp (Scott catalogue #1371) commemorating the Apollo 8 flight around the Moon. The stamp featured a detail of the famous photograph of the Earthrise over the Moon taken by Anders on Christmas Eve, and the words, "In the beginning God ..." Just 18 days after the crew's return to Earth, they were featured during the 1969 Super Bowl pre-game show reciting the Pledge of Allegiance prior to the national anthem being performed by Anita Bryant.
Spacecraft location.
In January 1970, the spacecraft was delivered to Osaka, Japan, for display in the U.S. pavilion at Expo '70. It is now displayed at the Chicago Museum of Science and Industry, along with a collection of personal items from the flight donated by Lovell and the space suit worn by Frank Borman. Jim Lovell's Apollo 8 space suit is on public display in the Visitor Center at NASA's Glenn Research Center. Bill Anders's space suit is on display at the Science Museum in London, United Kingdom.
In film.
Apollo 8's historic mission has been shown and referred to in several forms, both documentary and fiction. The various television transmissions and 16 mm footage shot by the crew of Apollo 8 was compiled and released by NASA in the 1969 documentary, "Debrief: Apollo 8", which was hosted by Burgess Meredith. In addition, Spacecraft Films released, in 2003, a three-disc DVD set containing all of NASA's TV and 16 mm film footage related to the mission including all TV transmissions from space, training and launch footage, and motion pictures taken in flight. Portions of the Apollo 8 Mission can be seen in the 1989 documentary "For All Mankind", which won the Grand Jury Prize Documentary at the Sundance Film Festival. The Apollo 8 mission was well-covered in the 2007 British documentary "In the Shadow of the Moon".
Portions of the Apollo 8 mission are dramatized in the 1998 miniseries "From the Earth to the Moon" episode "1968". The S-IVB stage of Apollo 8 was also portrayed as the location of an alien device in the 1970 "UFO" episode "Conflict".
At the Kennedy Space Center Visitor Complex's Apollo/Saturn V Center, the history of the U.S. space program leading up to the launch of Apollo 8 is the subject of a multi-screen multimedia presentation which also features the actual control panels used in the Firing Room for the launch.

</doc>
<doc id="664" url="https://en.wikipedia.org/wiki?curid=664" title="Astronaut">
Astronaut

An astronaut or cosmonaut is a person trained by a human spaceflight program to command, pilot, or serve as a crew member of a spacecraft. Although generally reserved for professional space travelers, the terms are sometimes applied to anyone who travels into space, including scientists, politicians, journalists, and tourists.
Starting in the 1950s up to 2002, astronauts were sponsored and trained exclusively by governments, either by the military or by civilian space agencies. With the suborbital flight of the privately funded SpaceShipOne in 2004, a new category of astronaut was created: the commercial astronaut.
Definition.
The criteria for what constitutes human spaceflight vary. The Fédération Aéronautique Internationale (FAI) Sporting Code for astronautics recognizes only flights that exceed an altitude of . In the United States, professional, military, and commercial astronauts who travel above an altitude of are awarded astronaut wings.
, a total of 532 people from 36 countries have reached or more in altitude, of which 529 reached low Earth orbit or beyond.
Of these, 24 people have traveled beyond Low Earth orbit, to either lunar or trans-lunar orbit or to the surface of the moon; three of the 24 did so twice: Jim Lovell, John Young and Eugene Cernan. The three astronauts who have not reached low Earth orbit are spaceplane pilots Joe Walker, Mike Melvill, and Brian Binnie.
, under the U.S. definition 538 people qualify as having reached space, above altitude. Of eight X-15 pilots who exceeded in altitude, only one exceeded 100 kilometers (about 62 miles).
Space travelers have spent over 41,790 man-days (114.5 man-years) in space, including over 100 astronaut-days of spacewalks.
As of 2008, the man with the longest cumulative time in space is Sergei K. Krikalev, who has spent 803 days, 9 hours and 39 minutes, or 2.2 years, in space.
Peggy A. Whitson holds the record for the most time in space by a woman, 377 days.
Terminology.
In 1959, when both the United States and Soviet Union were planning, but had yet to launch humans into space, NASA Administrator T. Keith Glennan and his Deputy Administrator, Dr. Hugh Dryden, discussed whether spacecraft crew members should be called "astronauts" or "cosmonauts". Dryden preferred "cosmonaut", on the grounds that flights would occur in the "cosmos" (near space), while the "astro" prefix suggested flight to the stars. Most NASA Space Task Group members preferred "astronaut", which survived by common usage as the preferred American term. When the Soviet Union launched the first man into space, Yuri Gagarin in 1961, they chose a term which anglicizes to "cosmonaut".
English.
In English-speaking nations, a professional space traveler is called an "astronaut". The term derives from the Greek words "ástron" (ἄστρον), meaning "star", and "nautes" (ναύτης), meaning "sailor". The first known use of the term "astronaut" in the modern sense was by Neil R. Jones in his short story "The Death's Head Meteor" in 1930. The word itself had been known earlier. For example, in Percy Greg's 1880 book "Across the Zodiac", "astronaut" referred to a spacecraft. In "Les Navigateurs de l'Infini" (1925) of J.-H. Rosny aîné, the word "astronautique" (astronautic) was used. The word may have been inspired by "aeronaut", an older term for an air traveler first applied (in 1784) to balloonists. An early use in a non-fiction publication is Eric Frank Russell's poem "The Astronaut" in the November 1934 "Bulletin of the British Interplanetary Society".
The first known formal use of the term astronautics in the scientific community was the establishment of the annual International Astronautical Congress in 1950 and the subsequent founding of the International Astronautical Federation the following year.
NASA applies the term astronaut to any crew member aboard NASA spacecraft bound for Earth orbit or beyond. NASA also uses the term as a title for those selected to join its Astronaut Corps. The European Space Agency similarly uses the term astronaut for members of its Astronaut Corps.
Russian.
By convention, an astronaut employed by the Russian Federal Space Agency (or its Soviet predecessor) is called a "cosmonaut" in English texts. The word is an anglicisation of the Russian word "kosmonavt" ( ), one who works in space outside the Earth's atmosphere, a space traveler, which derives from the Greek words "kosmos" (κόσμος), meaning "universe", and "nautes" (ναύτης), meaning "sailor". Other countries of the former Eastern Bloc use variations of the Russian word "kosmonavt", such as the Polish "kosmonauta".
Coinage of the term "kosmonavt" has been credited to Soviet aeronautics pioneer Mikhail Tikhonravov (1900–1974). The first cosmonaut was Soviet Air Force pilot Yuri Gagarin, also the first person in space. Valentina Tereshkova, a Russian factory worker, was the first woman in space, as well as the first civilian among the Soviet cosmonaut or NASA astronaut corps to make a spaceflight. On March 14, 1995, Norman Thagard became the first American to ride to space on board a Russian launch vehicle, and thus became the first "American cosmonaut".
Chinese.
Official English-language texts issued by the government of China use "astronaut" while texts in Russian use космонавт ("cosmonaut"). In official Chinese-language texts, "yǔ háng yuán" (, "space navigating personnel") is used for astronauts and cosmonauts, and "háng tiān yuán" (, "space navigating personnel") is used for Chinese astronauts. The phrase "tài kōng rén" (, "spaceman") is often used in Hong Kong and Taiwan.
The term "taikonaut" is used by some English-language news media organizations for professional space travelers from China. The word has featured in the Longman and Oxford English dictionaries, the latter of which describes it as "a hybrid of the Chinese term "taikong" (space) and the Greek "naut" (sailor)"; the term became more common in 2003 when China sent its first astronaut Yang Liwei into space aboard the "Shenzhou 5" spacecraft. This is the term used by Xinhua News Agency in the English version of the Chinese "People's Daily" since the advent of the Chinese space program. The origin of the term is unclear; as early as May 1998, Chiew Lee Yih () from Malaysia, used it in newsgroups.
Other terms.
With the rise of space tourism, NASA and the Russian Federal Space Agency agreed to use the term "spaceflight participant" to distinguish those space travelers from professional astronauts on missions coordinated by those two agencies.
While no nation other than the Russian Federation (and previously the former Soviet Union), the United States, and China have launched a manned spacecraft, several other nations have sent people into space in cooperation with one of these countries. Inspired partly by these missions, other synonyms for astronaut have entered occasional English usage. For example, the term "spationaut" (French spelling: "spationaute") is sometimes used to describe French space travelers, from the Latin word "spatium" for "space", the Malay term "angkasawan" was used to describe participants in the Angkasawan program, and the Indian Space Research Organisation hope to launch a spacecraft in 2018 that would carry "vyomanauts", coined from the Sanskrit word for space.
Space travel milestones.
The first human in space was Soviet Yuri Gagarin, who was launched on April 12, 1961 aboard Vostok 1 and orbited around the Earth for 108 minutes. The first woman in space was Soviet Valentina Tereshkova, who launched on June 16, 1963 aboard Vostok 6 and orbited Earth for almost three days.
Alan Shepard became the first American and second person in space on May 5, 1961 on a 15-minute sub-orbital flight. The first American woman in space was Sally Ride, during Space Shuttle Challenger's mission STS-7, on June 18, 1983. In 1992 Mae Jemison became the first African American woman to travel in space aboard STS-47.
Cosmonaut Alexei Leonov was the first person to conduct an extravehicular activity (EVA), (commonly called a "spacewalk"), on March 18, 1965, on the Soviet Union's Voskhod 2 mission. This was followed two and a half months later by astronaut Ed White who made the first American EVA on NASA's Gemini 4 mission.
The first manned mission to orbit the Moon, "Apollo 8", included American William Anders who was born in Hong Kong, making him the first Asian-born astronaut in 1968.
The Soviet Union, through its Intercosmos program, allowed people from other "socialist" (i.e. Warsaw Pact and other Soviet-allied) countries to fly on its missions, with the notable exception of France participating in Soyuz TM-7. An example is Czechoslovak Vladimír Remek, the first cosmonaut from a country other than the Soviet Union or the United States, who flew to space in 1978 on a Soyuz-U rocket.
On July 23, 1980, Pham Tuan of Vietnam became the first Asian in space when he flew aboard Soyuz 37. Also in 1980, Cuban Arnaldo Tamayo Méndez became the first person of Hispanic and black African descent to fly in space, and in 1983, Guion Bluford became the first African American to fly into space. In April 1985, Taylor Wang became the first ethnic Chinese person in space. The first person born in Africa to fly in space was Patrick Baudry (France), in 1985. In 1985, Saudi Arabian Prince Sultan Bin Salman Bin AbdulAziz Al-Saud became the first Arab Muslim astronaut in space. In 1988, Abdul Ahad Mohmand became the first Afghan to reach space, spending nine days aboard the Mir space station.
With the larger number of seats available on the Space Shuttle, the U.S. began taking international astronauts. In 1983, Ulf Merbold of West Germany became the first non-US citizen to fly in a US spacecraft. In 1984, Marc Garneau became the first of 8 Canadian astronauts to fly in space (through 2010).
In 1985, Rodolfo Neri Vela became the first Mexican-born person in space. In 1991, Helen Sharman became the first Briton to fly in space.
In 2002, Mark Shuttleworth became the first citizen of an African country to fly in space, as a paying spaceflight participant. In 2003, Ilan Ramon became the first Israeli to fly in space, although he died during a re-entry accident.
On October 15, 2003, Yang Liwei became China's first astronaut on the Shenzhou 5 spacecraft.
Age milestones.
The youngest person to fly in space is Gherman Titov, who was 25 years old when he flew Vostok 2. (Titov was also the first person to suffer space sickness).
The oldest person who has flown in space is John Glenn, who was 77 when he flew on STS-95.
Duration and distance milestones.
The longest stay in space thus far has been 438 days, by Russian Valeri Polyakov.
As of 2006, the most spaceflights by an individual astronaut is seven, a record held by both Jerry L. Ross and Franklin Chang-Diaz. The farthest distance from Earth an astronaut has traveled was , when Jim Lovell, Jack Swigert, and Fred Haise went around the Moon during the Apollo 13 emergency.
Civilian and non-government milestones.
The first civilian in space was Valentina Tereshkova aboard Vostok 6 (she also became the first woman in space on that mission).
Tereshkova was only honorarily inducted into the USSR's Air Force, which had no female pilots whatsoever at that time. A month later, Joseph Albert Walker became the first American civilian in space when his X-15 Flight 90 crossed the line, qualifying him by the international definition of spaceflight. Walker had joined the US Army Air Force but was not a member during his flight. 
The first people in space who had never been a member of any country's armed forces were both Konstantin Feoktistov and Boris Yegorov aboard Voskhod 1.
The first non-governmental space traveler was Byron K. Lichtenberg, a researcher from the Massachusetts Institute of Technology who flew on STS-9 in 1983. In December 1990, Toyohiro Akiyama became the first paying space traveler as a reporter for Tokyo Broadcasting System, a visit to Mir as part of an estimated $12 million (USD) deal with a Japanese TV station, although at the time, the term used to refer to Akiyama was "Research Cosmonaut". Akiyama suffered severe space sickness during his mission, which affected his productivity.
The first self-funded space tourist was Dennis Tito on board the Russian spacecraft Soyuz TM-3 on April 28, 2001.
Self-funded travelers.
The first person to fly on an entirely privately funded mission was Mike Melvill, piloting SpaceShipOne flight 15P on a suborbital journey, although he was a test pilot employed by Scaled Composites and not an actual paying space tourist. Seven others have paid the Russian Space Agency to fly into space:
Training.
The first NASA astronauts were selected for training in 1959. Early in the space program, military jet test piloting and engineering training were often cited as prerequisites for selection as an astronaut at NASA, although neither John Glenn nor Scott Carpenter (of the Mercury Seven) had any university degree, in engineering or any other discipline at the time of their selection. Selection was initially limited to military pilots. The earliest astronauts for both America and the USSR tended to be jet fighter pilots, and were often test pilots.
Once selected, NASA astronauts go through twenty months of training in a variety of areas, including training for extravehicular activity in a facility such as NASA's Neutral Buoyancy Laboratory. Astronauts-in-training may also experience short periods of weightlessness in aircraft called the "vomit comet", the nickname given to a pair of modified KC-135s (retired in 2000 and 2004 respectively, and replaced in 2005 with a C-9) which perform parabolic flights. Astronauts are also required to accumulate a number of flight hours in high-performance jet aircraft. This is mostly done in T-38 jet aircraft out of Ellington Field, due to its proximity to the Johnson Space Center. Ellington Field is also where the Shuttle Training Aircraft is maintained and developed, although most flights of the aircraft are done out of Edwards Air Force Base.
NASA candidacy requirements.
Mission Specialist Educator.
Mission Specialist Educators, or "Educator Astronauts", were first selected in 2004, and as of 2007, there are three NASA Educator astronauts: Joseph M. Acaba, Richard R. Arnold, and Dorothy Metcalf-Lindenburger.
Barbara Morgan, selected as back-up teacher to Christa McAuliffe in 1985, is considered to be the first Educator astronaut by the media, but she trained as a mission specialist.
The Educator Astronaut program is a successor to the Teacher in Space program from the 1980s.
Health risks of space travel.
Astronauts are susceptible to a variety of health risks including decompression sickness, barotrauma, immunodeficiencies, loss of bone and muscle, loss of eyesight, orthostatic intolerance, sleep disturbances, and radiation injury. A variety of large scale medical studies are being conducted in space via the National Space and Biomedical Research Institute (NSBRI) to address these issues. Prominent among these is the Advanced Diagnostic Ultrasound in Microgravity Study in which astronauts (including former ISS commanders Leroy Chiao and Gennady Padalka) perform ultrasound scans under the guidance of remote experts to diagnose and potentially treat hundreds of medical conditions in space. This study's techniques are now being applied to cover professional and Olympic sports injuries as well as ultrasound performed by non-expert operators in medical and high school students. It is anticipated that remote guided ultrasound will have application on Earth in emergency and rural care situations, where access to a trained physician is often rare.
On December 31, 2012, a NASA-supported study reported that manned spaceflight may harm the brain and accelerate the onset of Alzheimer's disease.
In October 2015, the NASA Office of Inspector General issued a health hazards report related to space exploration, including a human mission to Mars.
Food and drink.
An astronaut on the International Space Station requires about 0.83 kilograms (1.83 pounds) weight of food inclusive of food packaging per meal each day. (The packaging for each meal weighs around 0.12 kilograms - 0.27 pounds) Longer-duration missions require more food.
Shuttle astronauts worked with nutritionists to select menus that appeal to their individual tastes. Five months before flight, menus are selected and analyzed for nutritional content by the shuttle dietician. Foods are tested to see how they will react in a reduced gravity environment. Caloric requirements are determined using a basal energy expenditure (BEE) formula.
On Earth, the average American uses about 35 gallons (132 liters) of water every day. On board the ISS astronauts limit water use to only about three gallons (11 liters) per day.
Insignia.
In Russia, cosmonauts are awarded Pilot-Cosmonaut of the Russian Federation upon completion of their missions, often accompanied with the award of Hero of the Russian Federation. This follows the practice established in the USSR where cosmonauts were usually awarded the title Hero of the Soviet Union.
At NASA, those who complete astronaut candidate training receive a silver lapel pin. Once they have flown in space, they receive a gold pin. U.S. astronauts who also have active-duty military status receive a special qualification badge, known as the Astronaut Badge, after participation on a spaceflight. The United States Air Force also presents an Astronaut Badge to its pilots who exceed in altitude.
Deaths.
Eighteen astronauts (fourteen men and four women) have lost their lives during four space flights. By nationality, thirteen were American (including one of Indian origin), four were Russian (Soviet Union), and one was Israeli.
Eleven people (all men) have lost their lives training for spaceflight: eight Americans and three Russians. Six of these were in crashes of training jet aircraft, one drowned during water recovery training, and four were due to fires in pure oxygen environments.
The Space Mirror Memorial, which stands on the grounds of the John F. Kennedy Space Center Visitor Complex, commemorates the lives of the men and women who have died during spaceflight and during training in the space programs of the United States. In addition to twenty NASA career astronauts, the memorial includes the names of a U.S. Air Force X-15 test pilot, a U.S. Air Force officer who died while training for a then-classified military space program, and a civilian spaceflight participant.

</doc>
<doc id="665" url="https://en.wikipedia.org/wiki?curid=665" title="A Modest Proposal">
A Modest Proposal

A Modest Proposal for Preventing the Children of Poor People From Being a Burthen to Their Parents or Country, and for Making Them Beneficial to the Publick, commonly referred to as A Modest Proposal, is a Juvenalian satirical essay written and published anonymously by Jonathan Swift in 1729. Swift suggests that the impoverished Irish might ease their economic troubles by selling their children as food for rich gentlemen and ladies. This satirical hyperbole mocks heartless attitudes towards the poor, as well as British policy toward Ireland in general.
In English writing, the phrase "a modest proposal" is now conventionally an allusion to this style of straight-faced satire.
Details.
Swift goes to great lengths to support his argument, including a list of possible preparation styles for the children, and calculations showing the financial benefits of his suggestion. He uses methods of argument throughout his essay which lampoon the then-influential William Petty and the social engineering popular among followers of Francis Bacon. These lampoons include appealing to the authority of "a very knowing American of my acquaintance in London" and "the famous Psalmanazar, a native of the island Formosa" (who had already confessed to "not" being from Formosa in 1706). This essay is widely held to be one of the greatest examples of sustained irony in the history of the English language. Much of its shock value derives from the fact that the first portion of the essay describes the plight of starving beggars in Ireland, so that the reader is unprepared for the surprise of Swift's solution when he states, "A young healthy child well nursed, is, at a year old, a most delicious nourishing and wholesome food, whether stewed, roasted, baked, or boiled; and I make no doubt that it will equally serve in a fricassee, or a ragout."
In the tradition of Roman satire, Swift introduces the reforms he is actually suggesting by paralipsis:
Population solutions.
George Wittkowsky argued that Swift’s main target in "A Modest Proposal" was not the conditions in Ireland, but rather the can-do spirit of the times that led people to devise a number of illogical schemes that would purportedly solve social and economic ills. Swift was especially insulted by projects that tried to fix population and labour issues with a simple cure-all solution. A memorable example of these sorts of schemes "involved the idea of running the poor through a joint-stock company". In response, Swift's "Modest Proposal" was "a burlesque of projects concerning the poor" that were in vogue during the early 18th century.
"A Modest Proposal" also targets the calculating way people perceived the poor in designing their projects. The pamphlet targets reformers who "regard people as commodities". In the piece, Swift adopts the "technique of a political arithmetician" to show the utter ridiculousness of trying to prove any proposal with dispassionate statistics.
Critics differ about Swift's intentions in using this faux-mathematical philosophy. Edmund Wilson argues that statistically "the logic of the 'Modest proposal' can be compared with defense of crime (arrogated to Marx) in which he argues that crime takes care of the superfluous population". Wittkowsky counters that Swift's satiric use of statistical analysis is an effort to enhance his satire that "springs from a spirit of bitter mockery, not from the delight in calculations for their own sake".
Rhetoric.
Charles K. Smith argues that Swift's rhetorical style persuades the reader to detest the speaker and pity the Irish. Swift's specific strategy is twofold, using a "trap" to create sympathy for the Irish and a dislike of the narrator who, in the span of one sentence, "details vividly and with rhetorical emphasis the grinding poverty" but feels emotion solely for members of his own class. Swift's use of gripping details of poverty and his narrator's cool approach towards them create "two opposing points of view" that "alienate the reader, perhaps unconsciously, from a narrator who can view with 'melancholy' detachment a subject that Swift has directed us, rhetorically, to see in a much less detached way."
Swift has his proposer further degrade the Irish by using language ordinarily reserved for animals. Lewis argues that the speaker uses "the vocabulary of animal husbandry" to describe the Irish. Once the children have been commodified, Swift's rhetoric can easily turn "people into animals, then meat, and from meat, logically, into tonnage worth a price per pound".
Swift uses the proposer's serious tone to highlight the absurdity of his proposal. In making his argument, the speaker uses the conventional, text book approved order of argument from Swift's time (which was derived from the Latin rhetorician Quintilian). The contrast between the "careful control against the almost inconceivable perversion of his scheme" and "the ridiculousness of the proposal" create a situation in which the reader has "to consider just what perverted values and assumptions would allow such a diligent, thoughtful, and conventional man to propose so perverse a plan".
Influences.
Scholars have speculated about which earlier works Swift may have had in mind when he wrote "A Modest Proposal".
Tertullian's "Apology".
James Johnson argued that "A Modest Proposal" was largely influenced and inspired by Tertullian's "Apology": a satirical attack against early Roman persecution of Christianity. James William Johnson believes that Swift saw major similarities between the two situations. Johnson notes Swift's obvious affinity for Tertullian and the bold stylistic and structural similarities between the works "A Modest Proposal" and "Apology". In structure, Johnson points out the same central theme, that of cannibalism and the eating of babies as well as the same final argument, that "human depravity is such that men will attempt to justify their own cruelty by accusing their victims of being lower than human." Stylistically, Swift and Tertullian share the same command of sarcasm and language. In agreement with Johnson, Donald C. Baker points out the similarity between both authors' tones and use of irony. Baker notes the uncanny way that both authors imply an ironic "justification by ownership" over the subject of sacrificing children—Tertullian while attacking pagan parents, and Swift while attacking the English mistreatment of the Irish poor.
Defoe's "The Generous Projector".
It has also been argued that "A Modest Proposal" was, at least in part, a response to the 1728 essay "The Generous Projector or, A Friendly Proposal to Prevent Murder and Other Enormous Abuses, By Erecting an Hospital for Foundlings and Bastard Children" by Swift's rival Daniel Defoe.
Economic themes.
Robert Phiddian's article "Have you eaten yet? The Reader in A Modest Proposal" focuses on two aspects of "A Modest Proposal": the voice of Swift and the voice of the Proposer. Phiddian stresses that a reader of the pamphlet must learn to distinguish between the satiric voice of Jonathan Swift and the apparent economic projections of the Proposer. He reminds readers that "there is a gap between the narrator's meaning and the text's, and that a moral-political argument is being carried out by means of parody".
While Swift's proposal is obviously not a serious economic proposal, George Wittkowsky, author of "Swift's Modest Proposal: The Biography of an Early Georgian Pamphlet", argues that to understand the piece fully, it is important to understand the economics of Swift’s time. Wittowsky argues that not enough critics have taken the time to focus directly on the mercantilism and theories of labour in 18th century England. "f one regards the "Modest Proposal" simply as a criticism of condition, about all one can say is that conditions were bad and that Swift's irony brilliantly underscored this fact".
"People are the riches of a nation".
At the start of a new industrial age in the 18th century, it was believed that "people are the riches of the nation", and there was a general faith in an economy that paid its workers low wages because high wages meant workers would work less. Furthermore, "in the mercantilist view no child was too young to go into industry". In those times, the "somewhat more humane attitudes of an earlier day had all but disappeared and the laborer had come to be regarded as a commodity".
Louis A. Landa presents Swift's "A Modest Proposal" as a critique of the popular and unjustified maxim of mercantilism in the 18th century that "people are the riches of a nation". Swift presents the dire state of Ireland and shows that mere population itself, in Ireland's case, did not always mean greater wealth and economy. The uncontrolled maxim fails to take into account that a person who does not produce in an economic or political way makes a country poorer, not richer. Swift also recognises the implications of such a fact in making mercantilist philosophy a paradox: the wealth of a country is based on the poverty of the majority of its citizens. Swift however, Landa argues, is not merely criticising economic maxims but also addressing the fact that England was denying Irish citizens their natural rights and dehumanising them by viewing them as a mere commodity.
Modern usage.
"A Modest Proposal" is included in many literature programs as an example of early modern western satire. It also serves as an exceptional introduction to the concept and use of argumentative language, lending itself well to secondary and post-secondary essay courses. Outside of the realm of English studies, "A Modest Proposal" is a relevant piece included in many comparative and global literature and history courses, as well as those of numerous other disciplines in the arts, humanities, and even the social sciences.
The essay has been emulated many times. In his book "A Modest Proposal" (1984), evangelical author Frank Schaeffer emulated Swift's work in social conservative polemic against abortion and euthanasia in a future dystopia that advocated recycling of aborted embryos and fetuses, as well as some disabled infants with compound intellectual, physical and physiological difficulties. (Such Baby Doe Rules cases were then a major concern of the pro-life movement of the early 1980s, which viewed selective treatment of those infants as disability discrimination.) In his book "A Modest Proposal for America" (2013), statistician Howard Friedman opens with a satirical reflection of the extreme drive to fiscal stability by ultra-conservatives.
Hunter S. Thompson's "Fear and Loathing in America: The Brutal Odyssey of an Outlaw Journalist", which contains hundreds of private letters written by Thompson over the years, contains a letter in which he uses "A Modest Proposal"'s satire technique against the Vietnam War. Thompson writes a letter to a local Aspen newspaper informing them that, on Christmas Eve, he was going to use napalm to burn a number of dogs and hopefully any humans they find. This letter protests the burning of Vietnamese people occurring overseas.

</doc>
