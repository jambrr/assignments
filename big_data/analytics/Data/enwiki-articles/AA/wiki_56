<doc id="4200" url="https://en.wikipedia.org/wiki?curid=4200" title="Boötes">
Boötes

Boötes is a constellation in the northern sky, located between 0° and +60° declination, and 13 and 16 hours of right ascension on the celestial sphere. The name comes from the Greek Βοώτης, "Boōtēs", meaning herdsman or plowman (literally, ox-driver; from βοῦς "bous" “cow”). The "ö" in the name is a diaeresis, not an umlaut, meaning that each 'o' is to be pronounced separately.
One of the 48 constellations described by the 2nd century astronomer Ptolemy, Boötes is now one of the 88 modern constellations. It contains the fourth brightest star in the night sky, the orange-hued Arcturus. Boötes is home to many other bright stars, including eight above the fourth magnitude and an additional 21 above the fifth magnitude, making a total of 29 stars easily visible to the naked eye.
History and mythology.
In ancient Babylon the stars of Boötes were known as SHU.PA. They were apparently depicted as the god Enlil, who was the leader of the Babylonian pantheon and special patron of farmers.
The name "Boötes" was first used by Homer in his Odyssey as a celestial reference point for navigation, described as "late-setting" or "slow to set", translated as the "Plowman". Exactly whom Boötes is supposed to represent in Greek mythology is not clear. According to one version, he was a son of Demeter, Philomenus, twin brother of Plutus, a ploughman who drove the oxen in the constellation Ursa Major. This is corroborated by the constellation's name, which itself means "ox-driver" or "herdsman." The ancient Greeks saw the asterism now called the "Big Dipper" or "Plough" as a cart with oxen. This influenced the name's etymology, derived from the Greek for "noisy" or "ox-driver". Another myth associated with Boötes tells that he invented the plow and was memorialized for his ingenuity as a constellation.
Another myth associated with Boötes by Hyginus is that of Icarius, who was schooled as a grape farmer and winemaker by Dionysus. Icarius made wine so strong that those who drank it appeared poisoned, which caused shepherds to avenge their supposedly poisoned friends by killing Icarius. Maera, Icarius's dog, brought his daughter Erigone to her father's body, whereupon both she and the dog committed suicide. Zeus then chose to honor all three by placing them in the sky as constellations: Icarius as Boötes, Erigone as Virgo, and Maera as Canis Major or Canis Minor.
Following another reading, the constellation is identified with Arcas and also referred to as Arcas and Arcturus, son of Zeus and Callisto. Arcas was brought up by his maternal grandfather Lycaon, to whom one day Zeus went and had a meal. To verify that the guest was really the king of the gods, Lycaon killed his grandson and prepared a meal made from his flesh. Zeus noticed and became very angry, transforming Lycaon into a wolf and gave back life to his son. In the meantime Callisto had been transformed into a she-bear, by Zeus's wife, Hera, who was angry at Zeus's infidelity. This is corroborated by the Greek name for Boötes, "Arctophylax", which means "Bear Watcher". Callisto in form of a bear was almost killed by her son who was out hunting. Zeus rescued her, taking her into the sky where she became Ursa Major, "the Great Bear". The name Arcturus (the constellation's brightest star) comes from the Greek word meaning "guardian of the bear". Sometimes Arcturus is depicted as leading the hunting dogs of nearby Canes Venatici and driving the bears of Ursa Major and Ursa Minor.
Several former constellations were formed from stars now included in Boötes. Quadrans Muralis, the Quadrant, was a constellation created near Beta Boötis from faint stars. It was invented in 1795 by Jérôme Lalande, an astronomer who used a quadrant to perform detailed astronometric measurements. Lalande worked with Nicole-Reine Lepaute and others to predict the 1758 return of Halley's Comet. Quadrans Muralis was formed from the stars of eastern Boötes, western Hercules, and Draco. It was originally called "Le Mural" by Jean Fortin in his 1795 Atlas Céleste; it was not given the name "Quadrans Muralis" until Johann Bode's 1801 "Uranographia". The constellation was quite faint, with its brightest stars reaching the 5th magnitude. Mons Maenalus, representing the Maenalus mountains, was created by Johannes Hevelius in 1687 at the foot of the constellation's figure. The mountain was named for the son of Lycaon, Maenalus. The mountain, one of Diana's hunting grounds, was also holy to Pan.
Non-Western astronomy.
The stars of Boötes were incorporated into many different Chinese constellations. Arcturus was part of the most prominent of these, variously designated as the celestial king's throne ("Tian Wang") or the Blue Dragon's horn ("Daijiao"); the name "Daijiao", meaning "great horn", is more common. Arcturus was given such importance in Chinese celestial mythology because of its status marking the beginning of the lunar calendar, as well as its status as the brightest star in the northern night sky. Two constellations flanked "Daijiao", "Yousheti" to the right and "Zuosheti" to the left; they represented companions that orchestrated the seasons. "Zuosheti" was formed from modern Zeta, Omicron, and Pi Boötis, while "Yousheti" was formed from modern Eta, Tau, and Upsilon Boötis. "Dixi", the Emperor's ceremonial banquet mat, was north of Arcturus, consisting of the stars 12, 11, and 9 Boötis. Another northern constellation was "Qigong", the Seven Dukes, which was mostly across the Boötes-Hercules border. It included either Delta Boötis or Beta Boötis as its terminus.
The other Chinese constellations made up of the stars of Boötes existed in the modern constellation's north; they are all representations of weapons. "Tianqiang", the spear, was formed from Iota, Kappa, and Theta Boötis; "Genghe", variously representing a lance or shield, was formed from Epsilon, Rho, and Sigma Boötis. There were also two weapons made up of a singular star. "Xuange", the halberd, was represented by Lambda Boötis, and "Zhaoyao", either the sword or the spear, was represented by Gamma Boötis.
Two Chinese constellations have an uncertain placement in Boötes. "Kangchi", the lake, was placed south of Arcturus, though its specific location is disputed. It may have been placed entirely in Boötes, on either side of the Boötes-Virgo border, or on either side of the Virgo-Libra border. The constellation "Zhouding", a bronze tripod-mounted container used for food, was sometimes cited as the stars 1, 2, and 6 Boötis. However, it has also been associated with three stars in Coma Berenices.
Characteristics.
Boötes is a constellation bordered by Virgo to the south, Coma Berenices and Canes Venatici to the west, Ursa Major to the northwest, Draco to the northeast, and Hercules, Corona Borealis and Serpens Caput to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'Boo'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 16 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates stretch from +7.36° to +55.1°. Covering 907 square degrees, Boötes culminates at midnight around 2 May and ranks 13th in area.
Colloquially, its pattern of stars has been likened to a kite or ice cream cone. However, depictions of Boötes have varied historically. Aratus described him circling the north pole, herding the two bears. Later ancient Greek depictions, described by Ptolemy, have him holding the reins of his hunting dogs (Canes Venatici) in his left hand, with a spear, club, or staff in his right hand. After Hevelius introduced Mons Maenalus in 1681, Boötes was often depicted standing on the Peloponnese mountain. By 1801, when Johann Bode published his "Uranographia", Boötes had acquired a sickle, which was also held in his left hand.
The placement of Arcturus has also been mutable through the centuries. Traditionally, Arcturus lay between his thighs, as Ptolemy depicted him. However, Germanicus Caesar deviated from this tradition by placing Arcturus "where his garment is fastened by a knot".
Notable features.
Stars.
In his "Uranometria", Johann Bayer used the Greek letters Alpha through to Omega and then A to k to label what he saw as the most prominent 35 stars in the constellation, with subsequent astronomers splitting Kappa, Mu, Nu and Pi as two stars each. Nu is also the same star as Psi Herculis. John Flamsteed numbered 54 stars for the constellation.
Located 36.7 light-years from Earth, Arcturus, or Alpha Boötis, is the brightest star in Boötes and the fourth brightest star in the sky at an apparent magnitude of −0.05; It is also the brightest star north of the celestial equator, just shading out Vega and Capella. Its name comes from the Greek for "bear-keeper". An orange giant of spectral class K1.5III, Arcturus is an ageing star that has exhausted its core supply of hydrogen and cooled and expanded to a diameter of 27 solar diameters, equivalent to approximately 32 million kilometers. Though its mass is approximately one solar mass (), Arcturus shines with 133 times the luminosity of the Sun (). Bayer located Arcturus above the herdsman's left knee in his "Uranometria". Nearby Eta Boötis, or Muphrid, is the uppermost star denoting the left leg. It is a 2.68-magnitude star 37 light-years distant with a spectral class of G0IV, indicating it has just exhausted its core hydrogen and is beginning to expand and cool. It is 9 times as luminous as the Sun and has 2.7 times its diameter. Analysis of its spectrum reveals that it is a spectroscopic binary. Muphrid and Arcturus lie only 3.3 light years away from each other. Viewed from Arcturus, Muphrid would have a visual magnitude of -2½, while Arcturus would be around visual magnitude -4½ when seen from Muphrid.
Marking the herdsman's head is Beta Boötis, or Nekkar, a yellow giant of magnitude 3.5 and spectral type G8IIIa. Like Arcturus, it has expanded and cooled off the main sequence—likely to have lived most of its stellar life as a blue-white B-type main sequence star. Its common name comes from the Arabic phrase for "ox-driver". It is 219 light-years away and has a luminosity of . Located 86 light-years distant, Gamma Boötis, or Seginus, is a white giant star of spectral class A7III, with a luminosity 34 times and diameter 3.5 times that of the Sun. It is a Delta Scuti variable, ranging between magnitudes 3.02 and 3.07 every 7 hours. Thes stars are short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. Delta Boötis is a wide double star with a primary of magnitude 3.5 and a secondary of magnitude 7.8. The primary is a yellow giant that has cooled and expanded to 10.4 times the diameter of the Sun. Of spectral class G8IV, it is around 121 light-years away, while the secondary is a yellow main sequence star of spectral type G0V. The two are thought to take 120,000 years to orbit each other. Mu Boötis, known as Alkalurops, is a triple star popular with amateur astronomers. It has an overall magnitude of 4.3 and is 121 light-years away. Its name is from the Arabic phrase for "club" or "staff". The primary appears to be of magnitude 4.3 and is blue-white. The secondary appears to be of magnitude 6.5, but is actually a close double star itself with a primary of magnitude 7.0 and a secondary of magnitude 7.6. The secondary and tertiary stars have an orbital period of 260 years. The primary has an absolute magnitude of 2.6 and is of spectral class F0. The secondary and tertiary stars are separated by 2 arcseconds; the primary and secondary are separated by 109.1 arcseconds at an angle of 171 degrees. Nu Boötis is an optical double star. The primary is an orange giant of magnitude 5.0 and the secondary is a white star of magnitude 5.0. The primary is 870 light-years away and the secondary is 430 light-years.
Epsilon Boötis, also known as "Izar" or "Pulcherrima", is a close triple star popular with amateur astronomers and the most prominent binary star in Boötes. The primary is a yellow- or orange-hued magnitude 2.5 giant star, the secondary is a magnitude 4.6 blue-hued main-sequence star, and the tertiary is a magnitude 12.0 star. The system is 210 light-years away. The name "Izar" comes from the Arabic word for "girdle" or "loincloth", referring to its location in the constellation. The name "Pulcherrima" comes from the Latin phrase for "most beautiful", referring to its contrasting colors in a telescope. The primary and secondary stars are separated by 2.9 arcseconds at an angle of 341 degrees; the primary's spectral class is K0 and it has a luminosity of . To the naked eye, Izar has a magnitude of 2.37. Nearby Rho and Sigma Boötis denote the herdsman's waist. Rho is an orange giant of spectral type K3III located around 160 light-years from Earth. It is ever so slightly variable, wavering by 0.003 of a magnitude from its average of 3.57. Sigma, a yellow-white main sequence star of spectral type F3V, is suspected of varying in brightness from 4.45 to 4.49. It is around 52 light-years distant.
Traditionally known as "Al Aulād al Dhiʼbah" (ألعولد ألذعب - "al aulād al dhiʼb"), "the Whelps of the Hyenas", Theta, Iota, Kappa and Lambda Boötis are a small group of stars in the far north of the constellation. The magnitude 4.05 Theta Boötis has a spectral type of F7 and an absolute magnitude of 3.8. Iota Boötis is a triple star with a primary of magnitude 4.8 and spectral class of A7, a secondary of magnitude 7.5, and a tertiary of magnitude 12.6. The primary is 97 light-years away. The primary and secondary stars are separated by 38.5 arcseconds, at an angle of 33 degrees. The primary and tertiary stars are separated by 86.7 arcseconds at an angle of 194 degrees. Both the primary and tertiary appear white in a telescope, but the secondary appears yellow-hued. Kappa Boötis is another wide double star. The primary is 155 light-years away and has a magnitude of 4.5. The secondary is 196 light-years away and has a magnitude of 6.6. The two components are separated by 13.4 arcseconds, at an angle of 236 degrees. The primary, with spectral class A7, appears white and the secondary appears bluish. An apparent magnitude 4.18 type A0p star, Lambda Boötis is the prototype of a class of chemically peculiar stars, only some of which pulsate as Delta Scuti type stars. The distinction between the Lambda Boötis stars as a class of stars with peculiar spectra, and the delta Scuti stars whose class describes pulsation in low-overtone pressure modes, is an important one. While many Lambda Boötis stars pulsate and are delta Scuti stars, not many delta Scuti stars have Lambda Boötis peculiarities, since the Lambda Boötis stars are a much rarer class whose members can be found both inside and outside the delta Scuti instability strip. Lambda Boötis stars are dwarf stars that can be either spectral class A or F. Like BL Boötis-type stars they are metal-poor. Scientists have had difficulty explaining the characteristics of Lambda Boötis stars, partly because only around 60 confirmed members exist, but also due to heterogeneity in the literature. Lambda has an absolute magnitude of 1.8.
There are two dimmer F-type stars, magnitude 4.83 12 Boötis, class F8; and magnitude 4.93 45 Boötis, class F5. Xi Boötis is a G8 yellow dwarf of magnitude 4.55, and absolute magnitude is 5.5. Two dimmer G-type stars are magnitude 4.86 31 Boötis, class G8, and magnitude 4.76 44 Boötis, class G0.
Of apparent magnitude 4.06, Upsilon Boötis has a spectral class of K5 and an absolute magnitude of −0.3. Dimmer than Upsilon Boötis is magnitude 4.54 Phi Boötis, with a spectral class of K2 and an absolute magnitude of −0.1. Just slightly dimmer than Phi at magnitude 4.60 is O Boötis, which, like Izar, has a spectral class of K0. O Boötis has an absolute magnitude of 0.2. The other four dim stars are magnitude 4.91 6 Boötis, class K4; magnitude 4.86 20 Boötis, class K3; magnitude 4.81 Omega Boötis, class K4; and magnitude 4.83 A Boötis, class K1.
There is one bright B-class star in Boötes; magnitude 4.93 Pi1 Boötis, also called Alazal. It has a spectral class of B9 and is 40 parsecs from Earth. There is also one M-type star, magnitude 4.81 34 Boötis. It is of class gM0.
Multiple stars.
Besides Pulcherrima and Alkalurops, there are several other binary stars in Boötes:
44 Boötis (i Boötis) is a double variable star 42 light-years away. It has an overall magnitude of 4.8 and appears yellow to the naked eye. The primary is of magnitude 5.3 and the secondary is of magnitude 6.1; their orbital period is 220 years. The secondary is itself an eclipsing variable star with a range of 0.6 magnitudes; its orbital period is 6.4 hours. It is a W Ursae Majoris variable that ranges in magnitude from a minimum of 7.1 to a maximum of 6.5 every 0.27 days. Both stars are G-type stars. Another eclipsing binary star is ZZ Boötis, which has two F2-type components of almost equal mass, and ranges in magnitude from a minimum of 6.79 to a maximum of 7.44 over a period of 5.0 days.
Variable stars.
Two of the brighter Mira-type variable stars in the constellation are R and S Boötis. Both are red giants that range greatly in magnitude—from 6.2 to 13.1 over 223.4 days, and 7.8 to 13.8 over a period of 270.7 days respectively. Also red giants, V and W Boötis are semi-regular variable stars that range in magnitude from 7.0 to 12.0 over a period of 258 days, and magnitude 4.7 to 5.4 over 450 days respectively.
BL Boötis is the prototype of its class of pulsating variable stars, the anomalous Cepheids. These stars are somewhat similar to Cepheid variables, but they do not have the same relationship between their period and luminosity. Their periods are similar to RRAB variables; however, they are far brighter than these stars. BL Boötis is a member of the cluster NGC 5466. Anomalous Cepheids are metal poor and have masses not much larger than the Sun's, on average, . BL Boötis type stars are a subtype of RR Lyrae variables.
T Boötis was a nova observed in April 1860 at a magnitude of 9.7. It has never been observed since, but that does not preclude the possibility of it being a highly irregular variable star or a recurrent nova.
Stars with planetary systems.
Extrasolar planets have been discovered encircling ten stars in Boötes as of 2012. Tau Boötis is orbited by a large planet, discovered in 1999. The host star itself is a magnitude 4.5 star of type F7V, 15.6 parsecs from Earth. It has a mass of and a radius of 1.331 solar radii (); a companion, GJ527B, orbits at a distance of 240 AU. Tau Boötis b, the sole planet discovered in the system, orbits at a distance of 0.046 AU every 3.31 days. Discovered through radial velocity measurements, it has a mass of 5.95 Jupiter masses (). This makes it a hot Jupiter. The host star and planet are tidally locked, meaning that the planet's orbit and the star's particularly high rotation are synchronized. Furthermore, a slight variability in the host star's light may be caused by magnetic interactions with the planet. Carbon monoxide is present in the planet's atmosphere. Tau Boötis b does not transit its star, rather, its orbit is inclined 46 degrees. Like Tau Boötis b, HAT-P-4 b is also a hot Jupiter. It is noted for orbiting a particularly metal-rich host star and being of low density. Discovered in 2007, HAT-P-4 b has a mass of and a radius of . It orbits every 3.05 days at a distance of 0.04 AU. HAT-P-4, the host star, is an F-type star of magnitude 11.2, 310 parsecs from Earth. It is larger than the Sun, with a mass of and a radius of .
Boötes is also home to multiple-planet systems. HD 128311 is the host star for a two-planet system, consisting of HD 128311 b and HD 128311 c, discovered in 2002 and 2005, respectively. HD 128311 b is the smaller planet, with a mass of ; it was discovered through radial velocity observations. It orbits at almost the same distance as Earth, at 1.099 AU; however, its orbital period is significantly longer at 448.6 days. The larger of the two, HD 128311 c, has a mass of and was discovered in the same manner. It orbits every 919 days inclined at 50°, and is 1.76 AU from the host star. The host star, HD 128311, is a K0V-type star located 16.6 parsecs from Earth. It is smaller than the Sun, with a mass of and a radius of ; it also appears below the threshold of naked-eye visibility at an apparent magnitude of 7.51.
There are several single-planet systems in Boötes. HD 132406 is a Sun-like star of spectral type G0V with an apparent magnitude of 8.45, 231.5 light-years from Earth. It has a mass of and a radius of . The star is orbited by a gas giant, HD 132406 b, discovered in 2007. HD 132406 orbits 1.98 AU from its host star with a period of 974 days and has a mass of . The planet was discovered by the radial velocity method. WASP-23 is a star with one orbiting planet, WASP-23 b. The planet, discovered by the transit method in 2010, orbits every 2.944 very close to its Sun, at 0.0376 AU. It is smaller than Jupiter, at and . Its star is a K1V type star of apparent magnitude 12.7, far below naked-eye visibility, and smaller than the Sun at and . HD 131496 is also encircled by one planet, HD 131496 b. The star is of type K0 and is located 110 parsecs from Earth; it appears at a visual magnitude of 7.96. It is significantly larger than the Sun, with a mass of and a radius of 4.6 solar radii. Its one planet, discovered in 2011 by the radial velocity method, has a mass of ; its radius is as yet undetermined. HD 131496 b orbits at a distance of 2.09 AU with a period of 883 days.
Another single planetary system in Boötes is the HD 132563 system, a triple star system. The parent star, technically HD 132563B, is a star of magnitude 9.47, 96 parsecs from Earth. It is almost exactly the size of the Sun, with the same radius and a mass only 1% greater. Its planet, HD 132563B b, was discovered in 2011 by the radial velocity method. , it orbits 2.62 AU from its star with a period of 1544 days. Its orbit is somewhat elliptical, with an eccentricity of 0.22. HD 132563B b is one of very few planets found in triple star systems; it orbits the isolated member of the system, which is separated from the other components, a spectroscopic binary, by 400 AU. Also discovered through the radial velocity method, albeit a year earlier, is HD 136418 b, a 2-Jupiter mass planet that orbits the star HD 136418 at a distance of 1.32 AU with a period of 464.3 days. Its host star is a magnitude 7.88 G5-type star, 98.2 parsecs from Earth. It has a radius of and a mass of .
WASP-14 b is one of the most massive and dense exoplanets known, with a mass of and a radius of . Discovered via the transit method, it orbits 0.036 AU from its host star with a period of 2.24 days. WASP-14 b has a density of 4.6 grams per cubic centimeter, making it one of the densest exoplanets known. Its host star, WASP-14, is an F5V-type star of magnitude 9.75, 160 parsecs from Earth. It has a radius of and a mass of . It also has a very high proportion of lithium.
Deep-sky objects.
Boötes is in a part of the celestial sphere facing away from the plane of our home Milky Way galaxy, and so does not have open clusters or nebulae. Instead, it has one bright globular cluster and many faint galaxies. The globular cluster NGC 5466 has an overall magnitude of 9.1 and a diameter of 11 arcminutes. It is a very loose globular cluster with fairly few stars and may appear as a rich, concentrated open cluster in a telescope. NGC 5466 is classified as a Shapley-Sawyer Concentration Class 12 cluster, reflecting its sparsity. Its fairly large diameter means that it has a low surface brightness, so it appears far dimmer than the catalogued magnitude of 9.1 and requires a large amateur telescope to view. Only approximately 12 stars are resolved by an amateur instrument.
Boötes has two bright galaxies. NGC 5248 (Caldwell 45) is a type Sc galaxy (a variety of spiral galaxy) of magnitude 10.2. It measures 6.5 by 4.9 arcminutes. 50 million light-years from Earth, NGC 5248 is a member of the Virgo Cluster of galaxies; it has dim outer arms and obvious H II regions, dust lanes, and young star clusters. NGC 5676 is another type Sc galaxy of magnitude 10.9. It measures 3.9 by 2.0 arcminutes. Other galaxies include NGC 5008, a type Sc emission-line galaxy, NGC 5548, a type S Seyfert galaxy, NGC 5653, a type S HII galaxy, NGC 5778 (also classified as NGC 5825), a type E galaxy that is the brightest of its cluster, NGC 5886, and NGC 5888, a type SBb galaxy. NGC 5698 is a barred spiral galaxy, notable for being the host of the 2005 supernova SN 2005bc, which peaked at magnitude 15.3.
Further away lies the 250 million light-year diameter Boötes void, a huge space largely empty of galaxies. Discovered by Robert Kirshner and colleagues in 1981, it is roughly 700 million light years from Earth.Beyond it and within the bounds of the constellation, lie two superclusters at around 830 million and 1 billion light years distant.
The Hercules–Corona Borealis Great Wall, the largest known structure in the Universe, covers a significant part of Boötes.
Meteor showers.
Boötes is home to the Quadrantid meteor shower, the most prolific annual meteor shower. It was discovered in January 1835 and named in 1864 by Alexander Hershell. The radiant is located in northern Boötes near Kappa Boötis, in its namesake former constellation of Quadrans Muralis. Quadrantid meteors are dim, but have a peak visible hourly rate of approximately 100 per hour on January 3–4. The zenithal hourly rate of the Quadrantids is approximately 130 meteors per hour at their peak; it is also a very narrow shower. The Quadrantids are notoriously difficult to observe because of a low radiant and often inclement weather. The parent body of the meteor shower has been disputed for decades; however, Peter Jenniskens has proposed 2003 EH1, a minor planet, as the parent. 2003 EH1 may be linked to C/1490 Y1, a comet previously thought to be a potential parent body for the Quadrantids. 2003 EH1 is a short-period comet of the Jupiter family; 500 years ago, it experienced a catastrophic breakup event. It is now dormant. The Quadrantids had notable displays in 1982, 1985, and 2004. Meteors from this shower often appear to have a blue hue and travel at a moderate speed of 41.5–43 kilometers per second.
On April 28, 1984, a remarkable outburst of the normally placid Alpha Bootids was observed by visual observer Frank Witte from 00:00 to 2:30 UTC. In a 6 cm telescope, he observed 433 meteors in a field of view near Arcturus with a diameter of less than 1°. Peter Jenniskens comments that this outburst resembled a "typical dust trail crossing". The Alpha Bootids normally begin on April 14, peaking on April 27 and 28, and finishing on May 12. Its meteors are slow-moving, with a velocity of 20.9 kilometers per second. They may be related to Comet 73P/Schwassmann-Wachmann 3, but this connection is only theorized.
The June Bootids, also known as the Iota Draconids, is a meteor shower associated with the comet 7P/Pons-Winnecke, first recognized on May 27, 1916, by William F. Denning. The shower, with its slow meteors, was not observed prior to 1916 because Earth did not cross the comet's dust trail until Jupiter perturbed Pons-Winnecke's orbit, causing it to come within 0.03 AU of Earth's orbit the first year the June Bootids were observed. In 1982, E. A. Reznikov discovered that the 1916 outburst was caused by material released from the comet in 1819. Another outburst of the June Bootids was not observed until 1998, because Comet Pons-Winnecke's orbit was not in a favorable position. However, on June 27, 1998, an outburst of meteors radiating from Boötes, later confirmed to be associated with Pons-Winnecke, was observed. They were incredibly long-lived, with trails of the brightest meteors lasting several seconds at times. Many fireballs, green-hued trails, and even some meteors that cast shadows were observed throughout the outburst, which had a maximum zenithal hourly rate of 200–300 meteors per hour. In 2002, two Russian astronomers determined that material ejected from the comet in 1825 was responsible for the 1998 outburst. Ejecta from the comet dating to 1819, 1825, and 1830 was predicted to enter Earth's atmosphere on June 23, 2004. The predictions of a shower less spectacular than the 1998 showing were borne out in a display that had a maximum zenithal hourly rate of 16–20 meteors per hour that night. The June Bootids are not expected to have another outburst in the next 50 years. Typically, only 1–2 dim, very slow meteors are visible per hour; the average June Bootid has a magnitude of 5.0. It is related to the Alpha Draconids and the Bootids-Draconids. The shower lasts from June 27 to July 5, with a peak on the night of June 28. The June Bootids are classified as a class III shower (variable), and has an average entry velocity of 18 kilometers per second. Its radiant is located 7 degrees north of Beta Boötis.
The Beta Bootids is a weak shower that begins on January 5, peaks on January 16, and ends on January 18. Its meteors travel at 43 kilometers/second. The January Bootids is a short, young meteor shower that begins on January 9, peaks from January 16 to January 18, and ends on January 18. The Phi Bootids is another weak shower radiating from Boötes. It begins on April 16, peaks on April 30 and May 1, and ends on May 12. Its meteors are slow-moving, with a velocity of 15.1 km/s. They were discovered in 2006. The shower's peak hourly rate can be as high as 6 meteors per hour. Though named for a star in Boötes, the Phi Bootid radiant has moved into Hercules. The meteor stream is associated with three different asteroids: 1620 Geographos, 2062 Aten, and 1978 CA. The Lambda Bootids, part of the Bootid-Coronae Borealid Complex, are a weak annual shower with moderately fast meteors; 41.75 km/s. The complex includes the Lambda Bootids, as well as the Theta Coronae Borealids and Xi Coronae Borealids. All of the Bootid-Coronae Borealid showers are Jupiter family comet showers; the streams in the complex have highly inclined orbits.
There are several minor showers in Boötes, some of whose existence is yet to be verified. The Rho Bootids radiate from near the namesake star, and were hypothesized in 2010. The average Rho Bootid has an entry velocity of 43 km/s. It peaks in November and lasts for 3 days. The Rho Bootid shower is part of the SMA complex, a group of meteor showers related to the Taurids, which is in turn linked to the comet 2P/Encke. However, the link to the Taurid shower remains unconfirmed and may be a chance correlation. Another such shower is the Gamma Bootids, which were hypothesized in 2006. Gamma Bootids have an entry velocity of 50.3 km/s. The Nu Bootids, hypothesized in 2012, have faster meteors, with an entry velocity of 62.8 km/s.
References.
Citations
References

</doc>
<doc id="4203" url="https://en.wikipedia.org/wiki?curid=4203" title="Bernardino Ochino">
Bernardino Ochino

Bernardino Ochino (1487–1564) was an Italian, who was raised a Roman Catholic and later turned to Protestantism.
Biography.
Bernardino Ochino was born in Siena, the son of the barber Domenico Ochino, and at the age of 7 or 8, in around 1504, was entrusted to the order of Franciscan Friars. From 1510 he studied medicine at Perugia.
Transfer to the Capuchins.
At the age of 38, Ochino transferred himself in 1534 to the newly founded Order of Friars Minor Capuchin. By then he was the close friend of Juan de Valdés, Pietro Bembo, Vittoria Colonna, Pietro Martire, Carnesecchi. In 1538 he was elected vicar-general of his order. In 1539, urged by Bembo, he visited Venice and delivered a course of sermons showing a sympathy with justification by faith, which appeared more clearly in his "Dialogues" published the same year. He was suspected and denounced, but nothing ensued until the establishment of the Inquisition in Rome in June 1542, at the instigation of Cardinal Giovanni Pietro Carafa. Ochino received a citation to Rome, and set out to obey it about the middle of August. According to his own statement, he was deterred from presenting himself at Rome by the warnings of Cardinal Contarini, whom he found at Bologna, dying of poison administered by the reactionary party.
Escape to Geneva.
Ochino turned aside to Florence, and after some hesitation went across the Alps to Geneva. He was cordially received by John Calvin, and published within two years several volumes of "Prediche", controversial tracts rationalizing his change of religion. He also addressed replies to marchioness Vittoria Colonna, Claudio Tolomei, and other Italian sympathizers who were reluctant to go to the same length as himself. His own breach with the Roman Catholic Church was final.
Augsburg and England.
In 1545 Ochino became minister of the Italian Protestant congregation at Augsburg. From this time dates his contact with Caspar Schwenckfeld. He was compelled to flee when, in January 1547, the city was occupied by the imperial forces for the Diet of Augsburg.
Ochino found asylum in England, where he was made a prebendary of Canterbury Cathedral, received a pension from Edward VI's privy purse, and composed his major work, the "Tragoedie or Dialoge of the unjuste usurped primacie of the Bishop of Rome". This text, originally written in Latin, is extant only in the 1549 translation of Bishop John Ponet. The form is a series of dialogues. Lucifer, enraged at the spread of Jesus's kingdom, convokes the fiends in council, and resolves to set up the pope as antichrist. The state, represented by the emperor Phocas, is persuaded to connive at the pope's assumption of spiritual authority; the other churches are intimidated into acquiescence; Lucifer's projects seem fully accomplished, when Heaven raises up Henry VIII of England and his son for their overthrow.
Several of Ochino's "Prediche" were translated into English by Anna Cooke; and he published numerous controversial treatises on the Continent.
Zürich.
In 1553 the accession of Mary I drove Ochino from England. He went to Basel, where Lelio Sozzini and the lawyer Martino Muralto were sent to secure Ochino as pastor of the Italian church at Zürich, which Ochino accepted. The Italian congregation there was composed mainly of refugees from Locarno. There for 10 years Ochino wrote books which gave increasing evidence of his alienation from the orthodoxy around him. The most important of these was the "Labyrinth", a discussion of the freedom of the will, covertly undermining the Calvinistic doctrine of predestination.
In 1563 a long simmering storm burst on Ochino with the publication of his "Thirty Dialogues", in one of which his adversaries maintained that he had justified polygamy under the disguise of a pretended refutation. His dialogues on divorce and against the Trinity were also considered heretical.
Poland, and death.
Ochino was not given opportunity to defend himself, and was banished from Zürich. After being refused admission by other Protestant cities, he directed his steps towards Poland, at that time the most tolerant state in Europe. He had not resided there long when an edict appeared (August 8, 1564) banishing all foreign dissidents. Fleeing the country, he encountered the plague at Pińczów; three of his four children were carried off; and he himself, worn out by misfortune, died in solitude and obscurity at Slavkov in Moravia, about the end of 1564.
Legacy.
Ochino's reputation among Protestants was low. He was charged by Thomas Browne in 1643 with the authorship of the legendary-apocryphal heretical treatise "De tribus Impostoribus", as well as with having carried his alleged approval of polygamy into practice.
His biographer Karl Benrath justified him, representing him as a fervent evangelist and at the same time as a speculative thinker with a passion for free inquiry. The picture is of Ochino always learning and unlearning and arguing out difficult questions with himself in his dialogues, frequently without attaining to any absolute conviction. 

</doc>
<doc id="4204" url="https://en.wikipedia.org/wiki?curid=4204" title="Bay of Quinte">
Bay of Quinte

The Bay of Quinte is a long, narrow bay shaped like the letter "Z" on the northern shore of Lake Ontario in the province of Ontario, Canada. It is just west of the head of the Saint Lawrence River that drains the Great Lakes into the Gulf of Saint Lawrence. It is located about east of Toronto and west of Montreal.
The name "Quinte" is derived from ""Kente"", which was the name of an early French Catholic mission located on the north shore of what is now Prince Edward County. Officially, in the Mohawk language, the community is called "Kenhtè:ke" which means "the place of the bay". The Cayuga name is "Tayęda:ne:gęˀ or Detgayę:da:negęˀ", "land of two logs."
The Bay, as it is known locally, provides some of the best trophy Walleye angling in North America as well as most sport fish common to the great lakes. The bay is subject to algae blooms in late summer which are a naturally occurring phenomenon and do not indicate pollution other than from agricultural runoff. Zebra mussels as well as the other invasive species found in the great lakes are present.
The Quinte area played a vital role in bootlegging during Prohibition in the United States, with large volumes of booze being produced in the area, and shipped via boat on the Bay to Lake Ontario finally arriving in New York State where it was distributed. Illegal sales of liquor accounted for many fortunes in and around Belleville.
Tourism in the area is significant, especially in the summer months due to the Bay of Quinte and its fishing, local golf courses, provincial parks, and wineries.
Geography.
The northern side of the bay is defined by Ontario's mainland, while the southern side follows the shore of the Prince Edward County headland. Beginning in the east with the outlet to Lake Ontario, the bay runs west-southwest for to Picton (although this section is also called Adolphus Reach), where it turns north-northwest for another as far as Deseronto. From there it turns south-southwest again for another , running past Big Island on the south and Belleville on the north. The width of the bay rarely exceeds two kilometers. The bay ends at Trenton (Quinte West) and the Trent River, both also on the north side. The Murray Canal has been cut through the "Carrying Place", the few miles separating the end of the bay and Lake Ontario on the west side. The Trent River is part of the Trent-Severn Waterway, a canal connecting Lake Ontario to Lake Simcoe and then Georgian Bay on Lake Huron.
There are several sub-bays off the Bay of Quinte, including Hay Bay, Big Bay, and Muscote Bay.
Quinte Region.
Quinte is also a region comprising several communities situated along the Bay of Quinte, including Belleville which is the largest city in the Quinte Region, and represents a midpoint between Montreal, Ottawa, and Toronto.
The Greater Bay of Quinte area includes the municipalities of Brighton, Quinte West, Belleville, Prince Edward County, and Greater Napanee as well as the Native Tyendinaga Mohawk Territory. Overall population of the area exceeds 200,000.
Mohawks of the Bay of Quinte.
The Mohawks of the Bay of Quinte (Kenhtè:ke Kanyen'kehá:ka) on traditional Tyendinaga Mohawk Territory. Their reserve Band number 244, their current land base, is a 73 km² (18000-acre) on the Bay of Quinte in southeastern Ontario, Canada, east of Belleville and immediately to the west of Deseronto.
The community takes its name from a variant spelling of Mohawk leader Joseph Brant's traditional Mohawk name, Thayendanegea (standardized spelling Thayentiné:ken), which means 'two pieces of fire wood beside each other'. Officially, in the Mohawk language, the community is called "Kenhtè:ke" (Tyendinaga) which means "on the bay" the birthplace of Tekanawí:ta. The Cayuga name is Tyendinaga, "Tayęda:ne:gęˀ or Detgayę:da:negęˀ", "land of two logs.")
Education.
The Quinte Region, specifically the City of Belleville, is home to "Loyalist College of Applied Arts and Technology." Other post-secondary schools in the region include; "Maxwell College of Advanced Technology," "CDI College," "Ontario Business College," and "Quinte Literacy." Secondary Schools in the region include "Albert College" (private school) and "Sir James Whitney" (a school for the deaf and severely hearing-impaired).
Industry and employment.
The Quinte Region is home to a large number of national and international food processing manufacturers. Quinte also houses a large number of industries in the plastics & packaging sector, transportation sector, logistics sector and advanced manufacturing sector, including the following (just a few of over 350 industries located in the Bay of Quinte Region) :

</doc>
<doc id="4207" url="https://en.wikipedia.org/wiki?curid=4207" title="Bassoon">
Bassoon

The bassoon is a woodwind instrument in the double reed family that typically plays music written in the bass and tenor clefs, and occasionally the treble. Appearing in its modern form in the 19th century, the bassoon figures prominently in orchestral, concert band, and chamber music literature. The bassoon is a non-transposing instrument known for its distinctive tone color, wide range, variety of character and agility. Listeners often compare its warm, dark, reedy timbre to that of a male baritone voice. Someone who plays the bassoon is called a bassoonist.
Etymology.
The word bassoon comes from French "basson" and from Italian "bassone" ("basso" with the augmentative suffix "-one").
Range.
The range of the bassoon begins at B1 (the first one below the bass staff) and extends upward over three octaves, roughly to the G above the treble staff (G5). Higher notes are possible but difficult to produce, and rarely called for: orchestral and concert band parts rarely go higher than C5 or D5. Even Stravinsky's famously difficult opening solo in "The Rite of Spring" only ascends to D5.
A1 is possible with a special extension to the instrument—see "Extended techniques" below.
Construction.
The bassoon disassembles into six main pieces, including the reed. The bell (6), extending upward; the bass joint (or long joint) (5), connecting the bell and the boot; the boot (or butt) (4), at the bottom of the instrument and folding over on itself; the wing joint (or tenor joint) (3), which extends from boot to bocal; and the bocal (or crook) (2), a crooked metal tube that attaches the wing joint to a reed (1) (). Bassoons are double reed instruments like the oboe and the English horn.
A modern beginner's bassoon is generally made of maple, with medium-hardness types such as sycamore maple and sugar maple preferred. Less-expensive models are also made of materials such as polypropylene and ebonite, primarily for student and outdoor use; metal bassoons were made in the past but have not been produced by any major manufacturer since 1889. The bore of the bassoon is conical, like that of the oboe and the saxophone, and the two adjoining bores of the boot joint are connected at the bottom of the instrument with a U-shaped metal connector. Both bore and tone holes are precision-machined, and each instrument is finished by hand for proper tuning. The walls of the bassoon are thicker at various points along the bore; here, the tone holes are drilled at an angle to the axis of the bore, which reduces the distance between the holes on the exterior. This ensures coverage by the fingers of the average adult hand. Wooden instruments are lined with hard rubber along the interior of the wing and boot joints to prevent damage from moisture; wooden instruments are also stained and varnished. The end of the bell is usually fitted with a ring, either of metal, plastic or ivory. The joints between sections consist of a tenon fitting into a socket; the tenons are wrapped in either cork or string as a seal against air leaks. The bocal connects the reed to the rest of the instrument and is inserted into a socket at the top of the wing joint. Bocals come in many different lengths and styles, depending on the desired tuning and playing characteristics.
Folded upon itself, the bassoon stands tall, but the total sounding length is . Playing is facilitated by doubling the tube back on itself and by closing the distance between the widely spaced holes with a complex system of key work, which extends throughout nearly the entire length of the instrument. There are also short-reach bassoons made for the benefit of young or petite players.
Development.
Early history.
Music historians generally consider the dulcian to be the forerunner of the modern bassoon, as the two instruments share many characteristics: a double reed fitted to a metal crook, obliquely drilled tone holes and a conical bore that doubles back on itself. The origins of the dulcian are obscure, but by the mid-16th century it was available in as many as eight different sizes, from soprano to great bass. A full consort of dulcians was a rarity; its primary function seems to have been to provide the bass in the typical wind band of the time, either loud (shawms) or soft (recorders), indicating a remarkable ability to vary dynamics to suit the need. Otherwise, dulcian technique was rather primitive, with eight finger holes and two keys, indicating that it could play in only a limited number of key signatures.
The dulcian came to be known as "fagotto" in Italy. However, the usual etymology that equates "fagotto" with "bundle of sticks" is somewhat misleading, as the latter term did not come into general use until later. Some think it may resemble the Roman Fasces, a standard of bound sticks with an ax. A further discrepancy lies in the fact that the dulcian was carved out of a single block of wood—in other words, a single "stick" and not a bundle.
Circumstantial evidence indicates that the baroque bassoon was a newly invented instrument, rather than a simple modification of the old dulcian. The dulcian was not immediately supplanted, but continued to be used well into the 18th century by Bach and others. The man most likely responsible for developing the true bassoon was Martin Hotteterre (d.1712), who may also have invented the three-piece "flûte traversière" and the "hautbois" (baroque oboe). Some historians believe that sometime in the 1650s, Hotteterre conceived the bassoon in four sections (bell, bass joint, boot and wing joint), an arrangement that allowed greater accuracy in machining the bore compared to the one-piece dulcian. He also extended the compass down to B by adding two keys. An alternate view maintains Hotteterre was one of several craftsmen responsible for the development of the early bassoon. These may have included additional members of the Hotteterre family, as well as other French makers active around the same time. No original French bassoon from this period survives, but if it did, it would most likely resemble the earliest extant bassoons of Johann Christoph Denner and Richard Haka from the 1680s. Sometime around 1700, a fourth key (G♯) was added, and it was for this type of instrument that composers such as Antonio Vivaldi, Bach, and Georg Philipp Telemann wrote their demanding music. A fifth key, for the low E, was added during the first half of the 18th century. Notable makers of the 4-key and 5-key baroque bassoon include J.H. Eichentopf (c. 1678–1769), J. Poerschmann (1680–1757), Thomas Stanesby, Jr. (1668–1734), G.H. Scherer (1703–1778), and Prudent Thieriot (1732–1786).
Modern history.
Increasing demands on capabilities of instruments and players in the 19th century—particularly larger concert halls requiring greater volume and the rise of virtuoso composer-performers—spurred further refinement. Increased sophistication, both in manufacturing techniques and acoustical knowledge, made possible great improvements in the instrument's playability.
The modern bassoon exists in two distinct primary forms, the Buffet system and the Heckel system. Most of the world plays the Heckel system, while the Buffet system is primarily played in France, Belgium, and parts of Latin America.
Heckel (German) system.
The design of the modern bassoon owes a great deal to the performer, teacher, and composer Carl Almenräder. Assisted by the German acoustic researcher Gottfried Weber, he developed the 17-key bassoon with a range spanning four octaves. Almenräder's improvements to the bassoon began with an 1823 treatise describing ways of improving intonation, response, and technical ease of playing by augmenting and rearranging the keywork. Subsequent articles further developed his ideas. His employment at Schott gave him the freedom to construct and test instruments according to these new designs, and he published the results in "Caecilia", Schott's house journal. Almenräder continued publishing and building instruments until his death in 1846, and Ludwig van Beethoven himself requested one of the newly made instruments after hearing of the papers. In 1831, Almenräder left Schott to start his own factory with a partner, Johann Adam Heckel.
Heckel and two generations of descendants continued to refine the bassoon, and their instruments became the standard, with other makers following. Because of their superior singing tone quality (an improvement upon one of the main drawbacks of the Almenräder instruments), the Heckel instruments competed for prominence with the reformed Wiener system, a Boehm-style bassoon, and a completely keyed instrument devised by Charles-Joseph Sax, father of Adolphe Sax. F.W. Kruspe implemented a latecomer attempt in 1893 to reform the fingering system, but it failed to catch on. Other attempts to improve the instrument included a 24-keyed model and a single-reed mouthpiece, but both these had adverse effects on tone and were abandoned.
Coming into the 20th century, the Heckel-style German model of bassoon dominated the field. Heckel himself had made over 1,100 instruments by the turn of the 20th century (serial numbers begin at 3,000), and the British makers' instruments were no longer desirable for the changing pitch requirements of the symphony orchestra, remaining primarily in military band use.
Except for a brief 1940s wartime conversion to ball bearing manufacture, the Heckel concern has produced instruments continuously to the present day. Heckel bassoons are considered by many to be the best, although a range of Heckel-style instruments is available from several other manufacturers, all with slightly different playing characteristics. Companies that manufacture Heckel-system bassoons include: Wilhelm Heckel, Yamaha, Fox Products, W. Schreiber & Söhne, Püchner, Conn-Selmer, Linton, Moosmann Kohlert, Moennig/Adler, B.H. Bell, Walter, and Guntram Wolf. In addition, several factories in the People's Republic of China are producing inexpensive instruments under such labels as Laval, Haydn, and Lark, and these have been available in the West for some time now. However, they are generally of marginal quality and are usually avoided by serious players.
Because its mechanism is primitive compared to most modern woodwinds, makers have occasionally attempted to "reinvent" the bassoon. In the 1960s, Giles Brindley began to develop what he called the "logical bassoon," which aimed to improve intonation and evenness of tone through use of an electrically activated mechanism, making possible key combinations too complex for the human hand to manage. Brindley's logical bassoon was never marketed.
Buffet (French) system.
The Buffet system bassoon achieved its basic acoustical properties somewhat earlier than the Heckel. Thereafter, it continued to develop in a more conservative manner. While the early history of the Heckel bassoon included a complete overhaul of the instrument in both acoustics and key work, the development of the Buffet system consisted primarily of incremental improvements to the key work. This minimalist approach of the Buffet deprived it of improved consistency of intonation, ease of operation, and increased power, which is found in Heckel bassoons, but the Buffet is considered by some to have a more vocal and expressive quality. The conductor John Foulds lamented in 1934 the dominance of the Heckel-style bassoon, considering them too homogeneous in sound with the horn. The modern Buffet system has 22 keys with its range being about the same as the Heckel.
Compared to the Heckel bassoon, Buffet system bassoons have a narrower bore and simpler mechanism, requiring different fingerings for many notes. Switching between Heckel and Buffet requires extensive retraining. Buffet instruments are known for a reedier sound and greater facility in the upper registers, reaching e" and f" with far greater ease and less air resistance. French woodwind instruments' tone in general exhibits a certain amount of "edge," with more of a vocal quality than is usual elsewhere, and the Buffet bassoon is no exception. This type of sound can be beneficial in music by French composers, but has drawn criticism for being too intrusive. As with all bassoons, the tone varies considerably, depending on individual instrument and performer. In the hands of a lesser player, the Heckel bassoon can sound flat and woody, but good players succeed in producing a vibrant, singing tone. Conversely, a poorly played Buffet can sound buzzy and nasal, but good players succeed in producing a warm, expressive sound, different from—but not inferior to—the Heckel.
Though the United Kingdom once favored the French system, Buffet-system instruments are no longer made there and the last prominent British player of the French system retired in the 1980s. However, with continued use in some regions and its distinctive tone, the Buffet continues to have a place in modern bassoon playing, particularly in France, where it is originated. Buffet-model bassoons are currently made in Paris by Buffet Crampon and the atelier Ducasse (Romainville, France). The Selmer Company stopped fabrication of French system bassoons a few years ago. Some players, for example the late Gerald Corey in Canada, have learned to play both types and will alternate between them depending on the repertoire.
Use in ensembles.
Earlier ensembles.
Orchestras first used the bassoon to reinforce the bass line, and as the bass of the double reed choir (oboes and taille). Baroque composer Jean-Baptiste Lully and his "Les Petits Violons" included oboes and bassoons along with the strings in the 16-piece (later 21-piece) ensemble, as one of the first orchestras to include the newly invented double reeds. Antonio Cesti included a bassoon in his 1668 opera "Il pomo d'oro" (The Golden Apple). However, use of bassoons in concert orchestras was sporadic until the late 17th century when double reeds began to make their way into standard instrumentation. This was largely due to the spread of the "hautbois" to countries outside France. Increasing use of the bassoon as a "basso continuo" instrument meant that it began to be included in opera orchestras, first in France and later in Italy, Germany and England. Meanwhile, composers such as Joseph Bodin de Boismortier, Michel Corrette, Johann Ernst Galliard, Jan Dismas Zelenka, Johann Friedrich Fasch and Telemann wrote demanding solo and ensemble music for the instrument. Antonio Vivaldi brought the bassoon to prominence by featuring it in 37 concerti for the instrument.
By the mid-18th century, the bassoon's function in the orchestra was still mostly limited to that of a continuo instrument—since scores often made no specific mention of the bassoon, its use was implied, particularly if there were parts for oboes or other winds. Beginning in the early Rococo era, composers such as Joseph Haydn, Michael Haydn, Johann Christian Bach, Giovanni Battista Sammartini and Johann Stamitz included parts that exploited the bassoon for its unique color, rather than for its perfunctory ability to double the bass line. Orchestral works with fully independent parts for the bassoon would not become commonplace until the Classical era. Wolfgang Amadeus Mozart's "Jupiter" symphony is a prime example, with its famous bassoon solos in the first movement. The bassoons were generally paired, as in current practice, though the famed Mannheim orchestra boasted four.
Another important use of the bassoon during the Classical era was in the "Harmonie", a chamber ensemble consisting of pairs of oboes, horns and bassoons; later, two clarinets would be added to form an octet. The "Harmonie" was an ensemble maintained by German and Austrian noblemen for private music-making, and was a cost-effective alternative to a full orchestra. Haydn, Mozart, Ludwig van Beethoven and Franz Krommer all wrote considerable amounts of music for the "Harmonie".
Modern ensembles.
The modern symphony orchestra typically calls for two bassoons, often with a third playing the contrabassoon. Some works call for four or more players. The first player is frequently called upon to perform solo passages. The bassoon's distinctive tone suits it for both plaintive, lyrical solos such as Maurice Ravel's "Boléro" and more comical ones, such as the grandfather's theme in "Peter and the Wolf". Its agility suits it for passages such as the famous running line (doubled in the violas and cellos) in the overture to "The Marriage of Figaro". In addition to its solo role, the bassoon is an effective bass to a woodwind choir, a bass line along with the cellos and double basses, and harmonic support along with the French horns.
A wind ensemble will usually also include two bassoons and sometimes contrabassoon, each with independent parts; other types of concert wind ensembles will often have larger sections, with many players on each of first or second parts; in simpler arrangements there will be only one bassoon part and no contrabassoon. The bassoon's role in the concert band is similar to its role in the orchestra, though when scoring is thick it often cannot be heard above the brass instruments also in its range. "La Fiesta Mexicana", by H. Owen Reed, features the instrument prominently, as does the transcription of Malcolm Arnold's "Four Scottish Dances", which has become a staple of the concert band repertoire.
The bassoon is part of the standard wind quintet instrumentation, along with the flute, oboe, clarinet, and horn; it is also frequently combined in various ways with other woodwinds. Richard Strauss's "Duet-Concertino" pairs it with the clarinet as "concertante" instruments, with string orchestra in support. An ensemble known as the "reed quintet" also makes use of the bassoon. A reed quintet is made up of an oboe, clarinet, saxophone, bass clarinet, and bassoon.
The bassoon quartet has also gained favor in recent times. The bassoon's wide range and variety of tone colors make it well suited to grouping in a like-instrument ensemble. Peter Schickele's "Last Tango in Bayreuth" (after themes from "Tristan und Isolde") is a popular work; Schickele's fictional alter ego P. D. Q. Bach exploits the more humorous aspects with his quartet "Lip My Reeds," which at one point calls for players to perform on the reed alone. It also calls for a low A at the very end of the prelude section in the fourth bassoon part. It is written so that the first bassoon does not play; instead, the player's role is to place an extension in the bell of the fourth bassoon so that the note can be played.
Jazz.
The bassoon is infrequently used as a jazz instrument and rarely seen in a jazz ensemble. It first began appearing in the 1920s, including specific calls for its use in Paul Whiteman's group, the unusual octets of Alec Wilder, and a few other session appearances. The next few decades saw the instrument used only sporadically, as symphonic jazz fell out of favor, but the 1960s saw artists such as Yusef Lateef and Chick Corea incorporate bassoon into their recordings; Lateef's diverse and eclectic instrumentation saw the bassoon as a natural addition, while Corea employed the bassoon in combination with flautist Hubert Laws.
More recently, Illinois Jacquet, Ray Pizzi, Frank Tiberi, and Marshall Allen have both doubled on bassoon in addition to their saxophone performances. Bassoonist Karen Borca, a performer of free jazz, is one of the few jazz musicians to play only bassoon; Michael Rabinowitz, the Spanish bassoonist Javier Abad, and James Lassen, an American resident in Bergen, Norway, are others. Katherine Young plays the bassoon in the ensembles of Anthony Braxton. Lindsay Cooper, Paul Hanson, the Brazilian bassoonist Alexandre Silverio, Trent Jacobs and Daniel Smith are also currently using the bassoon in jazz. French bassoonists Jean-Jacques Decreux and Alexandre Ouzounoff have both recorded jazz, exploiting the flexibility of the Buffet system instrument to good effect.
Popular music.
The bassoon is even rarer as a regular member of rock bands. However, several 1960s pop music hits feature the bassoon, including "The Tears of a Clown" by Smokey Robinson and the Miracles (the bassoonist was Charles R. Sirard), "Jennifer Juniper" by Donovan, "The Turtles" "Happy Together"(third verse,overdub), "59th Street Bridge Song" by Harpers Bizarre, and the oompah bassoon underlying The New Vaudeville Band's "Winchester Cathedral". From 1974 to 1978, the bassoon was played by Lindsay Cooper in the British avant-garde band Henry Cow. In the 1970s it was played, in the British medieval/progressive rock band Gryphon, by Brian Gulland, as well as by the American band Ambrosia, where it was played by drummer Burleigh Drummond. The Belgian Rock in Opposition-band Univers Zero is also known for its use of the bassoon.
In the 1990s, Madonna Wayne Gacy provided bassoon for the alternative metal band Marilyn Manson as did Aimee DeFoe, in what is self-described as "grouchily lilting garage bassoon" in the indie-rock band Blogurt from Pittsburgh, Pennsylvania. More recently, These New Puritans's 2010 album Hidden makes heavy use of the instrument throughout; their principal songwriter, Jack Barnett, claimed repeatedly to be ""writing a lot of music for bassoon"" in the run-up to its recording. In early 2011, American hip-hop artist Kanye West updated his Twitter account to inform followers that he recently added the bassoon to a yet unnamed song.
The rock band Better Than Ezra took their name from a passage in Ernest Hemingway's "A Moveable Feast" in which the author comments that listening to an annoyingly talkative person is still “better than Ezra learning how to play the bassoon,” referring to Ezra Pound.
British psychedelic/progressive rock band Knifeworld features the bassoon playing of Chloe Herrington, who also plays for experimental chamber rock orchestra Chrome Hoof.
Technique.
The bassoon is held diagonally in front of the player, but unlike the flute, oboe and clarinet, it cannot be easily supported by the player's hands alone. Some means of additional support is usually required; the most common ones are a seat strap attached to the base of the boot joint, which is laid across the chair seat prior to sitting down, or a neck strap or shoulder harness attached to the top of the boot joint. Occasionally a spike similar to those used for the cello or the bass clarinet is attached to the bottom of the boot joint and rests on the floor. It is possible to play while standing up if the player uses a neck strap or similar harness, or if the seat strap is tied to the belt. Sometimes a device called a "balance hanger" is used when playing in a standing position. This is installed between the instrument and the neck strap, and shifts the point of support closer to the center of gravity, adjusting the distribution of weight between the two hands.
The bassoon is played with both hands in a stationary position, the left above the right, with five main finger holes on the front of the instrument (nearest the audience) plus a sixth that is activated by an open-standing key. Five additional keys on the front are controlled by the little fingers of each hand. The back of the instrument (nearest the player) has twelve or more keys to be controlled by the thumbs, the exact number varying depending on model.
To stabilize the right hand, many bassoonists use an adjustable comma-shaped apparatus called a "crutch," or a hand rest, which mounts to the boot joint. The crutch is secured with a thumb screw, which also allows the distance that it protrudes from the bassoon to be adjusted. Players rest the curve of the right hand where the thumb joins the palm against the crutch. The crutch also keeps the right hand from tiring and enables the player to keep the finger pads flat on the finger holes and keys.
An aspect of bassoon technique not found on any other woodwind is called "flicking". It involves the left hand thumb momentarily pressing, or 'flicking' the high A, C and D keys at the beginning of certain notes in the middle octave to achieve a clean slur from a lower note. This eliminates cracking, or brief multiphonics that happens without the use of this technique.
Flicking is not universal amongst bassoonists; some American players, principally on the East Coast, use it sparingly, if at all. The rest use it virtually 100% of the time—it has become in essence part of the fingering.
The alternative method is "venting", which requires that the register key be used as part of the full fingering as opposed to being open momentarily at the start of the note. This is sometimes called the "European Style."
While flicking is used to higher notes, the whisper key is used for lower notes. From the A right below middle C and lower, the whisper key is pressed with the left thumb and held for the duration of the note. This prevents cracking, as low notes can sometimes crack into a higher octave. Both flicking and using the whisper key is especially important to ensure notes speak properly during slurring between high and low registers.
While bassoons are usually critically tuned at the factory, the player nonetheless has a great degree of flexibility of pitch control through the use of breath support, embouchure, and reed profile. Players can also use alternate fingerings to adjust the pitch of many notes. Similar to other woodwind instruments, the length of the bassoon can be increased to lower pitch or decreased to raise pitch. On the bassoon, this is done preferably by changing the bocal to one of a different length, (lengths are denoted by a number on the bocal, usually starting at 0 for the shortest length, and 3 for the longest, but there are some manufacturers who will use other numbers) but it is possible to push the bocal in or out to adjust the pitch.
Embouchure.
The bassoon embouchure is a very important aspect of producing a full, round bassoon tone, but can be difficult to obtain as a beginner. The bassoon embouchure is made by putting one's lips together as if one were whistling and then dropping the jaw down as in a yawning motion (without actually yawning or opening the mouth). Both sets of teeth should be covered by the lips in order to protect the reed and control applied pressure. The reed is then placed in the mouth, forming a seal around the reed with the lips and facial muscles.
Extended techniques.
Many extended techniques can be performed on the bassoon, such as multiphonics, flutter-tonguing, circular breathing, double tonguing, and harmonics. In the case of the bassoon, flutter-tonguing may be accomplished by "gargling" in the back of the throat as well as by the conventional method of rolling Rs. Multiphonics on the bassoon can be achieved by using particular alternative fingerings.
Also, using certain fingerings, notes may be produced on the instrument that sound lower pitches than the actual range of the instrument. These "impossible notes" tend to sound very gravelly and out of tune, but technically sound below the low B. Alternatively, lower notes can be produced by inserting a small paper or rubber tube into the end of the bell, which converts the lower B into a lower note such as an A natural; this lowers the pitch of the instrument, but has the positive effect of bringing the lowest register (which is typically quite sharp) into tune. A notable piece that calls for the use of a low A bell is Carl Nielsen's Wind Quintet, op. 43, which includes an optional low A for the final cadence of the work. Bassoonists sometimes use the end bell segment of an English horn or clarinet if one is available instead of a specially made extension. This often yields unsatisfactory results, though, as the resultant A can be quite sharp. The idea of using low A was begun by Richard Wagner, who wanted to extend the range of the bassoon. Many passages in his later operas require the low A as well as the B-flat above. (This is impossible on a normal bassoon using an A extension as the fingering for the B-flat yields the low A.) These passages are typically realized on the contrabassoon, as recommended by the composer. Some bassoons have been made to allow bassoonists to realize similar passages. These bassoons are made with a "Wagner bell" which is an extended bell with a key for both the low A and the low B-flat. Bassoons with Wagner bells suffer similar intonational deficiencies as a bassoon with an A extension. Another composer who has required the bassoon to be chromatic down to low A is Gustav Mahler. Richard Strauss also calls for the low A in his opera "Intermezzo".
Modern Fingering.
The left thumb alone operates nine keys. B1, B1, C1, D1, D4, C4 (also B4), two keys when combined create A4, and the whisper pad. Additional notes can be created with these keys. The D1 and bottom key above whisper key on the tenor joint creates both C#2 and C#3. The same bottom tenor-joint key is also used, with additional fingering setup on the instrument, to create E4 and F4. D4 and C4 together create C#4. When the two keys on the tenor joint to create A4 are used with slightly altered fingering on the boot join, B4 is created. The whisper pad is used throughout the instrument's register, as well as in fingerings to create a muted or more piercing sound. The right thumb operates four keys. The top lever, which is very thin, is used in creating B2 and 3, and is used in B4, C4, D4, F4, and E4. The large, circular key (otherwise known as the "pancake key"), is used in mostly the bass register. From B1 to E1, it is held constantly. It is also used, like the whisper pad, in additional fingerings for muting the sound. For example, in Ravel's "Boléro", the bassoon is asked to play the ostinto on G4. This is easy to perform with the normal fingering for G4, but with the E1 key (pancake key). The next key assigned to the right thumb is known as the "spatula key". Its primary use is F#1 and F#2. The bottom key is used the least often than the other ones. With the combination of the back-most key of the smallest finger of the right hand, makes G#1 and G#2. This is most advantageous in pieces like Dukas's "The Sorcerer's Apprentice". The four fingers on left hand all have at least two assignments each. The index fingers has three assignments. The top-most key on the back side of the tenor join is primarily used for E4. Rarely is it used as a trill key. Its main assignment has three different options. It is a key with a small hole drilled into it. The player can lift the finger completely off the key. The player can also slide the finger down, so the key is closed, but the hole is open. The player can also close the hole with the key pressed down. The middle finger typically stays on the centre hole on the tenor joint. It can also move to a lever used for E4 and a rarely-used trill key. The ring finger operates, on most models, one key. Some models, like a Polisi Artist bassoon has two assignments. The upper assignment is used for alternate fingerings in the alto register. The smallest finger operates two side keys on the bass joint. The lower key is typically used for C#1. The upper key is used for E1, E3, F3, F#3, A4, B4, B4, C4, C#4, and D4. The four fingers of the right hand have at least one assignment each. The index finger stays over one hole, except when E4 is played. A side key at the top of the boot is used. The middle finger remains stationary over a whole with a ring around. The ring, with other pads, are lifted when the smallest finger on the right hands pushes a lever. The ring finger typically remains stationary on the lower ring-finger-key. However, the upper-ring-finger key can be used in place of the top thumb key on the front of the boot joint. The smallest finger operates three keys. The back-most one, closest to the bassoonist, is held down throughout most of the bass register. The key is not used after F1 is played. F#2 is created with this key, as well as G4, B4, B4, and C4. The lowest key for the smallest finger on the right hand is primarily used for G#1 and 2, but can be used E4, and F4.The front-most key is used with the bottom thumb key on the boot joint to create G#1 and 2.
Learning the bassoon.
The complicated fingering and the problem of reeds make the bassoon more of a challenge to learn than some of the other woodwind instruments. Cost is another big factor in a person's decision to pursue the bassoon. Prices range from $3,000 up to $250,000 for a good-quality instrument. In North America, schoolchildren typically take up bassoon only after starting on another reed instrument, such as clarinet or saxophone.
Students in America often begin to pursue the study of bassoon performance and technique in the middle years of their music education. Students are often provided with a school instrument and encouraged to pursue lessons with private instructors. Students typically receive instruction in proper posture, hand position, embouchure, tone production, and reed making.
Reeds and reed construction.
Modern reeds.
Bassoon reeds, made of "Arundo donax" cane, are often made by the players themselves, although beginner bassoonists tend to buy their reeds from professional reed makers or use reeds made by their teachers. Reeds begin with a length of tube cane that is split into three or four pieces using a tool called a cane splitter. The cane is then trimmed and "gouged" to the desired thickness, leaving the bark attached. After soaking, the gouged cane is cut to the proper shape and milled to the desired thickness, or "profiled", by removing material from the bark side. This can be done by hand with a file; more frequently it is done with a machine or tool designed for the purpose. After the profiled cane has soaked once again it is folded over in the middle. Prior to soaking, the reed maker will have lightly scored the bark with parallel lines with a knife; this ensures that the cane will assume a cylindrical shape during the forming stage. On the bark portion, the reed maker binds on one, two, or three coils or loops of brass wire to aid in the final forming process. The exact placement of these loops can vary somewhat depending on the reed maker. The bound reed blank is then wrapped with thick cotton or linen thread to protect it, and a conical steel mandrel (which sometimes has been heated in a flame) is quickly inserted in between the blades. Using a special pair of pliers, the reed maker presses down the cane, making it conform to the shape of the mandrel. (The steam generated by the heated mandrel causes the cane to permanently assume the shape of the mandrel.) The upper portion of the cavity thus created is called the "throat," and its shape has an influence on the final playing characteristics of the reed. The lower, mostly cylindrical portion will be reamed out with a special tool called a reamer, allowing the reed to fit on the bocal.
After the reed has dried, the wires are tightened around the reed, which has shrunk after drying, or replaced completely. The lower part is sealed (a nitrocellulose-based cement such as Duco may be used) and then wrapped with thread to ensure both that no air leaks out through the bottom of the reed and that the reed maintains its shape. The wrapping itself is often sealed with Duco or clear nail varnish (polish). Electrical tape can also be used as a wrapping for amateur reed makers. The bulge in the wrapping is sometimes referred to as the "Turk's head"—it serves as a convenient handle when inserting the reed on the bocal.
Recently, more players are choosing the more modern heat-shrink tubing instead of the time-consuming and fiddly thread.
To finish the reed, the end of the reed blank, originally at the center of the unfolded piece of cane, is cut off, creating an opening. The blades above the first wire are now roughly long. For the reed to play, a slight bevel must be created at the tip with a knife, although there is also a machine that can perform this function. Other adjustments with the reed knife may be necessary, depending on the hardness, the profile of the cane, and the requirements of the player. The reed opening may also need to be adjusted by squeezing either the first or second wire with the pliers. Additional material may be removed from the sides (the "channels") or tip to balance the reed. Additionally, if the "e" in the bass clef staff is sagging in pitch, it may be necessary to "clip" the reed by removing from its length using a pair of very sharp scissors or the equivalent.
Playing styles of individual bassoonists vary greatly; because of this, most advanced players will make their own reeds, in the process customizing them to their individual playing requirements. Many companies and individuals do offer reeds for sale, but even with store-bought reeds, players must know how to make adjustments to suit their particular playing style.
The tools used for adjusting reeds are very similar to those used to make the reeds themselves.
Early reeds.
Little is known about the early construction of the bassoon reed, as few examples survive, and much of what is known is only what can be gathered from artistic representations. The earliest known written instructions date from the middle of the 17th century, describing the reed as being held together by wire or resined thread; the earliest actual reeds that survive are more than a century younger, a collection of 21 reeds from the late 18th-century Spanish "bajon".

</doc>
<doc id="4210" url="https://en.wikipedia.org/wiki?curid=4210" title="Bipedalism">
Bipedalism

Bipedalism is a form of terrestrial locomotion where an organism moves by means of its two rear limbs or legs. An animal or machine that usually moves in a bipedal manner is known as a biped , meaning "two feet" (from the Latin "bis" for "double" and "pes" for "foot"). Types of bipedal movement include walking, running, or hopping.
Few modern species are habitual bipeds whose normal method of locomotion is two-legged. Within mammals, habitual bipedalism has evolved multiple times, with the macropods, kangaroo rats and mice, springhare, hopping mice, pangolins and homininan apes, as well as various other extinct groups evolving the trait independently. In the Triassic period some groups of archosaurs (a group that includes the ancestors of crocodiles) developed bipedalism; among their descendants the dinosaurs, all the early forms and many later groups were habitual or exclusive bipeds; the birds descended from one group of exclusively bipedal dinosaurs.
A larger number of modern species intermittently or briefly use a bipedal gait. Several non-archosaurian lizard species move bipedally when running, usually to escape from threats. Many primate and bear species will adopt a bipedal gait in order to reach food or explore their environment. Several arboreal primate species, such as gibbons and indriids, exclusively walk on two legs during the brief periods they spend on the ground. Many animals rear up on their hind legs whilst fighting or copulating. Some animals commonly stand on their hind legs, in order to reach food, to keep watch, to threaten a competitor or predator, or to pose in courtship, but do not move bipedally.
Definition.
The word is derived from the Latin words "bi(s)" 'two' and "ped-" 'foot', as contrasted with quadruped 'four feet'.
Advantages.
Limited and exclusive bipedalism can offer a species several advantages. Bipedalism raises the head; this allows a greater field of vision with improved detection of distant dangers or resources, access to deeper water for wading animals and allows the animals to reach higher food sources with their mouths. While upright, non-locomotory limbs become free for other uses, including manipulation (in primates and rodents), flight (in birds), digging (in giant pangolin), combat (in bears, great apes and the large monitor lizard) or camouflage (in certain species of octopus). The maximum bipedal speed appears less fast than the maximum speed of quadrupedal movement with a flexible backbone – both the ostrich and the red kangaroo can reach speeds of , while the cheetah can exceed .
Bipedality in kangaroo rats has been hypothesized to improve locomotor performance, which could aid in escaping from predators.
Facultative and obligate bipedalism.
Zoologists often label behaviors, including bipedalism, as "facultative" (i.e. optional) or "obligate" (the animal has no reasonable alternative). Even this distinction is not completely clear-cut — for example, humans normally walk and run in biped fashion, but almost all can crawl on hands and knees when necessary. There are even reports of humans who normally walk on all fours with their feet but not their knees on the ground, but these cases are a result of conditions such as Uner Tan syndrome — very rare genetic neurological disorders rather than normal behavior. Even if one ignores exceptions caused by some kind of injury or illness, there are many unclear cases, including the fact that "normal" humans can crawl on hands and knees. This article therefore avoids the terms "facultative" and "obligate", and focuses on the range of styles of locomotion "normally" used by various groups of animals.
Movement.
There are a number of states of movement commonly associated with bipedalism.
Bipedal animals.
The great majority of living terrestrial vertebrates are quadrupeds, with bipedalism exhibited by only a handful of living groups. Humans, gibbons and large birds walk by raising one foot at a time. On the other hand, most macropods, smaller birds, lemurs and bipedal rodents move by hopping on both legs simultaneously. Tree kangaroos are able to walk or hop, most commonly alternating feet when moving arboreally and hopping on both feet simultaneously when on the ground.
Amphibians.
There are no known living or fossil bipedal amphibians.
Extant reptiles.
Many species of lizards become bipedal during high-speed, sprint locomotion, including the world's fastest lizard, the spiny-tailed iguana (genus "Ctenosaura").
Early reptiles and lizards.
The first known biped is the bolosaurid "Eudibamus" whose fossils date from 290 million years ago. Its long hindlegs, short forelegs, and distinctive joints all suggest bipedalism. The species was extinct before the dinosaurs appeared.
Archosaurs (include birds, crocodiles, and dinosaurs).
Birds.
All birds are bipeds when on the ground, a feature inherited from their dinosaur ancestors.
Other archosaurs.
Bipedalism evolved more than once in archosaurs, the group that includes both dinosaurs and crocodilians. All dinosaurs are thought to be descended from a fully bipedal ancestor, perhaps similar to "Eoraptor". Bipedal movement also re-evolved in a number of other dinosaur lineages such as the iguanodons. Some extinct members of the crocodilian line, a sister group to the dinosaurs and birds, also evolved bipedal forms - a crocodile relative from the triassic, "Effigia okeeffeae", is thought to be bipedal. Pterosaurs were previously thought to have been bipedal, but recent trackways have all shown quadrupedal locomotion. Bipedalism also evolved independently among the dinosaurs. Dinosaurs diverged from their archosaur ancestors approximately 230 million years ago during the Middle to Late Triassic period, roughly 20 million years after the Permian-Triassic extinction event wiped out an estimated 95% of all life on Earth. Radiometric dating of fossils from the early dinosaur genus "Eoraptor" establishes its presence in the fossil record at this time. Paleontologists suspect "Eoraptor" resembles the common ancestor of all dinosaurs; if this is true, its traits suggest that the first dinosaurs were small, bipedal predators. The discovery of primitive, dinosaur-like ornithodirans such as "Marasuchus" and "Lagerpeton" in Argentinian Middle Triassic strata supports this view; analysis of recovered fossils suggests that these animals were indeed small, bipedal predators.
Mammals.
A number of groups of extant mammals have independently evolved bipedalism as their main form of locomotion - for example humans, giant pangolins, the extinct giant ground sloths, numerous species of jumping rodents and macropods. Humans, as their bipedalism has been extensively studied, are documented in the next section. Macropods are believed to have evolved bipedal hopping only once in their evolution, at some time no later than 45 million years ago.
Bipedal movement is less common among mammals, most of which are quadrupedal. All primates possess some bipedal ability, though most species primarily use quadrupedal locomotion on land. Primates aside, the macropods (kangaroos, wallabies and their relatives), kangaroo rats and mice, hopping mice and springhare move bipedally by hopping. Very few mammals other than primates commonly move bipedally by an alternating gait rather than hopping. Exceptions are the ground pangolin and in some circumstances the tree kangaroo. [http://blogs.scientificamerican.com/tetrapod-zoology/2011/10/17/tree-kangaroos-come-first/]
Primates.
Most bipedal animals move with their backs close to horizontal, using a long tail to balance the weight of their bodies. The primate version of bipedalism is unusual because the back is close to upright (completely upright in humans). Many primates can stand upright on their hind legs without any support. 
Chimpanzees, bonobos, gibbons and baboons exhibit forms of bipedalism. Injured chimpanzees and bonobos have been capable of sustained bipedalism.
Geladas, although often quadrupedal, will move between adjacent feeding patches with a squatting, shuffling bipedal form of locomotion [http://pin.primate.wisc.edu/factsheets/entry/gelada_baboon/].
Three captive primates, one macaque Natasha and two chimps, Oliver and Poko (chimpanzee), were found to move bipedally . Natasha switched to exclusive bipedalism after an illness, while Poko was discovered in captivity in a tall, narrow cage. Oliver reverted to knuckle-walking after developing arthritis.
In addition, non-human primates often use bipedal locomotion when carrying food. One hypothesis for human bipedalism is thus that it evolved as a result of differentially successful survival from carrying food to share with group members, although there are other hypotheses, as discussed below.
Limited bipedalism.
Limited bipedalism in mammals.
Other mammals engage in limited, non-locomotory, bipedalism. A number of other animals, such as rats, raccoons, and beavers will squat on their hindlegs to manipulate some objects but revert to four limbs when moving (the beaver will move bipedally if transporting wood for their dams, as will the raccoon when holding food). Bears will fight in a bipedal stance to use their forelegs as weapons. A number of mammals will adopt a bipedal stance in specific situations such as for feeding or fighting. Ground squirrels and meerkats will stand on hind legs to survey their surroundings, but will not walk bipedally. Dogs can stand or move on two legs if trained, or if birth defect or injury precludes quadrupedalism. The gerenuk antelope stands on its hind legs while eating from trees, as did the extinct giant ground sloth and chalicotheres. The spotted skunk will walk on its front legs when threatened, rearing up on its front legs while facing the attacker so that its anal glands, capable of spraying an offensive oil, face its attacker.
Limited bipedalism in non-mammals.
Bipedalism is unknown among the amphibians. Among the non-archosaur reptiles bipedalism is rare, but it is found in the 'reared-up' running of lizards such as agamids and monitor lizards. Many reptile species will also temporarily adopt bipedalism while fighting. One genus of basilisk lizard can run bipedally across the surface of water for some distance. Among arthropods, cockroaches are known to move bipedally at high speeds. Bipedalism is rarely found outside terrestrial animals, though at least two types of octopus walk bipedally on the sea floor using two of their arms, allowing the remaining arms to be used to camouflage the octopus as a mat of algae or a floating coconut.
Evolution of human bipedalism.
There are at least twelve distinct hypotheses as to how and why bipedalism evolved in humans, and also some debate as to when. Bipedalism evolved well before the large human brain or the development of stone tools. Bipedal specializations are found in "Australopithecus" fossils from 4.2-3.9 million years ago. The evolution of bipedalism was accompanied by significant evolutions in the spine including the forward movement in position of the foramen magnum, where the spinal cord leaves the cranium. Recent evidence regarding modern human sexual dimorphism (physical differences between male and female) in the lumbar spine has been seen in pre-modern primates such as "Australopithecus africanus". This dimorphism has been seen as an evolutionary adaptation of females to bear lumbar load better during pregnancy, an adaptation that non-bipedal primates would not need to make. Adapting bipedalism would have required less shoulder stability, which allowed the shoulder and other limbs to become more independent of each other and adapt for specific suspensory behaviors. In addition to the change in shoulder stability, changing locomotion would have increased the demand for shoulder mobility, which would have propelled the evolution of bipedalism forward. The different hypotheses are not necessarily mutually exclusive and a number of selective forces may have acted together to lead to human bipedalism. It is important to distinguish between adaptations for bipedalism and adaptations for running, which came later still.
Possible reasons for the evolution of human bipedalism include freeing the hands for tool use and carrying, sexual dimorphism in food gathering, changes in climate and habitat (from jungle to savanna) that favored a more elevated eye-position, and to reduce the amount of skin exposed to the tropical sun. It is possible that bipedalism provided a variety of benefits to the hominin species, and scientists have suggested multiple reasons for evolution of human bipedalism. There also is not only question of why were the earliest hominins partially bipedal but also why did hominins become more bipedal over time. For example, the postural feeding hypothesis (reaching for food/balancing) provides an explanation for how earliest hominins became for the benefit of reaching out for food in trees while the savannah-based theory describes how the late hominins that started to settle on the ground became increasingly bipedal.
Multiple Factors.
Napier (1964) argued that it was very unlikely that single factor drove the evolution of Bipedalism. He stated ""It seems unlikely that any single factor was responsible for such a dramatic change in behaviour. In addition to the advantages of accruing from ability to carry objects - food or otherwise - the improvement of the visual range and the freeing of the hands for purposes of defence and offence must equally have played their part as catalysts.”" Sigmon argued that chimpanzees demonstrate bipedalism in different contexts, and one single factor should be used to explain bipedalism. preadaptation for human bipedalism. Day (1986) emphasized three major pressures that drove evolution of bipedalism 1.food acquisition 2. predator avoidance 3. Reproductive success. Kwang Hyun Ko (2015) states there are two questions regarding bipedalism 1. Why were the earliest hominins partially bipedal 2. why did hominins become more bipedal over time. He argues that these questions can be answered with combination of prominent theories such as Savanna-based, Postural feeding, and Provisioning.
Savanna-based theory.
According to the savanna-based theory, hominines descended from the trees and adapted to life on the savanna by walking erect on two feet. The theory suggests that early hominids were forced to adapt to bipedal locomotion on the open savanna after they left the trees. This theory is closely related to the knuckle-walking hypothesis, which states that human ancestors used quadrupedal locomotion on the savanna, as evidenced by morphological characteristics found in "Australopithecus anamensis" and "Australopithecus afarensis" forelimbs, and that it is less parsimonious to assume that knuckle walking developed twice in Genus' Pan and Gorilla instead of evolving it once as synapomorphy for Pan and Gorilla before losing it in Australopithecus. The evolution of an orthograde posture would have been very helpful on a savanna as it would allow the ability to look over tall grasses in order to watch out for predators, or terrestrially hunt and sneak up on prey. It was also suggested in P.E. Wheeler's "The evolution of bipedality and loss of functional body hair in hominids", that a possible advantage of bipedalism in the savanna was reducing the amount of surface area of the body exposed to the sun, helping regulate body temperature. In fact, Elizabeth Vrba’s turnover pulse hypothesis supports the savanna-based theory by explaining the shrinking of forested areas due to global warming and cooling, which forced animals out into the open grasslands and caused the need for hominids to acquire bipedality.
Rather, the bipedal adaptation hominines had already achieved was used in the savanna. The fossil record shows that early bipedal hominines were still adapted to climbing trees at the time they were also walking upright. It is possible that Bipedalism evolved in the trees, and was later applied to the Savannah as a vestigial trait. Humans and orangutans are both unique to a bipedal reactive adaptation when climbing on thin branches, in which they have increased hip and knee extension in relation to the diameter of the branch, which can increase an arboreal feeding range and can be attributed to a convergent evolution of bipedalism evolving in arboreal environments. Hominine fossils found in dry grassland environments led anthropologists to believe hominines lived, slept, walked upright, and died only in those environments because no hominine fossils were found in forested areas. However, fossilization is a rare occurrence—the conditions must be just right in order for an organism that dies to become fossilized for somebody to find later, which is also a rare occurrence. The fact that no hominine fossils were found in forests does not ultimately lead to the conclusion that no hominines ever died there. The convenience of the savanna-based theory caused this point to be overlooked for over a hundred years.
Some of the fossils found actually showed that there was still an adaptation to arboreal life. For example, Lucy, the famous "Australopithecus afarensis", found in Hadar in Ethiopia, which may have been forested at the time of Lucy’s death, had curved fingers that would still give her the ability to grasp tree branches, but she walked bipedally. “Little Foot,” the collection of "Australopithecus africanus" foot bones, has a divergent big toe as well as the ankle strength to walk upright. “Little Foot” could grasp things using his feet like an ape, perhaps tree branches, and he was bipedal. Ancient pollen found in the soil in the locations in which these fossils were found suggest that the area used to be much more wet and covered in thick vegetation and has only recently become the arid desert it is now.
Traveling efficiency hypothesis.
An alternative explanation is the mixture of savanna and scattered forests increased terrestrial travel by proto-humans between clusters of trees, and bipedalism offered greater efficiency for long-distance travel between these clusters than quadrupedalism. In an experiment monitoring chimpanzee metabolic rate via oxygen consumption, it was found that the quadrupedal and bipedal energy costs were very similar, implying that this transition in early ape-like ancestors would have not have been very difficult or energetically costing. This increased travel efficiency is likely to have been selected for as it assisted the wide dispersal of early hominids across the Savannah to create start populations.
Postural feeding hypothesis.
The postural feeding hypothesis has been recently supported by Dr. Kevin Hunt, a professor at Indiana University. This hypothesis asserts that chimpanzees were only bipedal when they eat. While on the ground, they would reach up for fruit hanging from small trees and while in trees, bipedalism was used to reach up to grab for an overhead branch. These bipedal movements may have evolved into regular habits because they were so convenient in obtaining food. Also, Hunt's hypotheses states that these movements coevolved with chimpanzee arm-hanging, as this movement was very effective and efficient in harvesting food. When analyzing fossil anatomy, "Australopithecus afarensis" has very similar features of the hand and shoulder to the chimpanzee, which indicates hanging arms. Also, the "Australopithecus" hip and hind limb very clearly indicate bipedalism, but these fossils also indicate very inefficient locomotive movement when compared to humans. For this reason, Hunt argues that bipedalism evolved more as a terrestrial feeding posture than as a walking posture.
A similar study conducted by Thorpe et al. looked at how the most arboreal great ape, the orangutan, held onto supporting branches in order to navigate branches that were too flexible or unstable otherwise. They found that in more than 75% of locomotive instances the orangutans used their hands to stabilize themselves while they navigated thinner branches. They hypothesized that increased fragmentation of forests where A. afarensis as well as other ancestors of modern humans and other apes resided could have contributed to this increase of bipedalism in order to navigate the diminishing forests. Their findings also shed light on a couple of discrepancies observed in the anatomy of A. afarensis, such as the ankle joint, which allowed it to “wobble” and long, highly flexible forelimbs. The idea that bipedalism started from walking in trees explains both the increased flexibility in the ankle as well as the long limbs which would be used to grab hold of branches.
Provisioning model.
One theory on the origin of bipedalism is the behavioral model presented by C. Owen Lovejoy, known as "male provisioning". Lovejoy theorizes that the evolution of bipedalism was linked to monogamy. In the face of long inter-birth intervals and low reproductive rates typical of the apes, early hominids engaged in pair-bonding that enabled greater parental effort directed towards rearing offspring. Lovejoy proposes that male provisioning of food would improve the offspring survivorship and increase the pair's reproductive rate. Thus the male would leave his mate and offspring to search for food and return carrying the food in his arms walking on his legs. This model is supported by the reduction ("feminization") of the male canine teeth in early hominids such as "Sahelanthropus tchadensis" and "Ardipithecus ramidus", which along with low body size dimorphism in "Ardipithecus" and "Australopithecus", suggests a reduction in inter-male antagonistic behavior in early hominids. In addition, this model is supported by a number of modern human traits associated with concealed ovulation (permanently enlarged breasts, lack of sexual swelling) and low sperm competition (moderate sized testes, low sperm mid-piece volume) that argues against recent adaptation to a polygynous reproductive system.
However, this model has generated some controversy, as others have argued that early bipedal hominids were instead polygynous. Among most monogamous primates, males and females are about the same size. That is sexual dimorphism is minimal, and other studies have suggested that Australopithecus afarensis males were nearly twice the weight of females. However, Lovejoy's model posits that the larger range a provisioning male would have to cover (to avoid competing with the female for resources she could attain herself) would select for increased male body size to limit predation risk. Furthermore, as the species became more bipedal, specialized feet would prevent the infant from conveniently clinging to the mother - hampering the mother's freedom and thus make her and her offspring more dependent on resources collected by others. Modern monogamous primates such as gibbons tend to be also territorial, but fossil evidence indicates that "Australopithecus afarensis" lived in large groups. However, while both gibbons and hominids have reduced canine sexual dimorphism, female gibbons enlarge ('masculinize') their canines so they can actively share in the defense of their home territory. Instead, the reduction of the male hominid canine is consistent with reduced inter-male aggression in a group living primate.
Early bipedalism in homininae model.
Recent studies of 4.4 million years old "Ardipithecus ramidus" suggest bipedalism, it is thus possible that bipedalism evolved very early in homininae and was reduced in chimpanzee and gorilla when they became more specialized. According to Richard Dawkins in his book "The Ancestor's Tale", chimps and bonobos are descended from "Australopithecus" gracile type species while gorillas are descended from Paranthropus. These apes may have once been bipedal, but then lost this ability when they were forced back into an arboreal habitat, presumably by those australopithecines who eventually became us (see Homininae). Early homininaes such as "Ardipithecus ramidus" may have possessed an arboreal type of bipedalism that later independently evolved towards knuckle-walking in chimpanzees and gorillas and towards efficient walking and running in modern humans (see figure). It is also proposed that one cause of Neanderthal extinction was a less efficient running.
Warning display (aposematic) model.
Joseph Jordania from the University of Melbourne recently (2011) suggested that bipedalism was one of the central elements of the general defense strategy of early hominids, based on aposematism, or warning display and intimidation of potential predators and competitors with exaggerated visual and audio signals. According to this model, hominids were trying to stay as visible and as loud as possible all the time. Several morphological and behavioral developments were employed to achieve this goal: upright bipedal posture, longer legs, long tightly coiled hair on the top of the head, body painting, threatening synchronous body movements, loud voice and extremely loud rhythmic singing/stomping/drumming on external subjects. Slow locomotion and strong body odor (both characteristic for hominids and humans) are other features often employed by aposematic species to advertise their non-profitability for potential predators.
Other behavioural models.
There are a variety of ideas which promote a specific change in behaviour as the key driver for the evolution of hominid bipedalism. For example, Wescott (1967) and later Jablonski & Chaplin (1993) suggest that bipedal threat displays could have been the transitional behaviour which led to some groups of apes beginning to adopt bipedal postures more often. Others ("e.g." Dart 1925) have offered the idea that the need for more vigilance against predators could have provided the initial motivation. Dawkins ("e.g." 2004) has argued that it could have begun as a kind of fashion that just caught on and then escalated through sexual selection. And it has even been suggested ("e.g." Tanner 1981:165) that male phallic display could have been the initial incentive, as well as increased sexual signaling in upright female posture.
Thermoregulatory model.
The thermoregulatory model explaining the origin of bipedalism is one of the simplest theories so far advanced, but it is a viable explanation. Dr. Peter Wheeler, a professor of evolutionary biology, proposes that bipedalism raises the amount of body surface area higher above the ground which results in a reduction in heat gain and helps heat dissipation. When a hominid is higher above the ground, the organism accesses more favorable wind speeds and temperatures. During heat seasons, greater wind flow results in a higher heat loss, which makes the organism more comfortable. Also, Wheeler explains that a vertical posture minimizes the direct exposure to the sun whereas quadrupedalism exposes more of the body to direct exposure. Analysis and interpretations of Ardipithecus reveal that this hypothesis needs modification to consider that the forest and woodland environmental preadaptation of early-stage hominid bipedalism preceded further refinement of bipedalism by the pressure of natural selection. This then allowed for the more efficient exploitation of the hotter conditions ecological niche, rather than the hotter conditions being hypothetically bipedalism's initial stimulus. A feedback mechanism from the advantages of bipedality in hot and open habitats would then in turn make a forest preadaptation solidify as a permanent state.
Carrying models.
Charles Darwin wrote that "Man could not have attained his present dominant position in the world without the use of his hands, which are so admirably adapted to the act of obedience of his will" Darwin (1871:52) and many models on bipedal origins are based on this line of thought. Gordon Hewes (1961) suggested that the carrying of meat "over considerable distances" (Hewes 1961:689) was the key factor. Isaac (1978) and Sinclair et al. (1986) offered modifications of this idea as indeed did Lovejoy (1981) with his 'provisioning model' described above. Others, such as Nancy Tanner (1981) have suggested that infant carrying was key, whilst others have suggested stone tools and weapons drove the change. This stone tools theory is very unlikely, as though ancient humans were known to hunt, the discovery of tools was not discovered for thousands of years after the origin of bipedalism, temporally preventing it from being a driving force of evolution.
Wading models.
The observation that large Primates, including especially the great apes, that predominantly move quadrupedally on dry land, tend to switch to bipedal locomotion in waist deep water, has led to the idea that the origin of human bipedalism may have been influenced by waterside environments. This idea, labelled "The Wading Hypothesis", has been promoted for several decades by Elaine Morgan, as part of the aquatic ape hypothesis, which also proposes that swimming, diving and aquatic food sources exerted a strong influence on many aspects of human evolution, including bipedalism. The "aquatic ape hypothesis" is not accepted by or considered a serious theory within the anthropological scholarly community. Others, however, cite bipedalism among a cluster of other adaptations unique among primates, including voluntary control of breathing, hairlessness, subcutaneous fat and several other traits that are difficult to explain with more conventional theories.
Since 2000 Carsten Niemitz has published a series of papers and a book on a variant of the wading hypothesis, which he calls The Amphibian Generalist Theory. ("Amphibische Generalistentheorie").
Other theories have been proposed that suggest wading and the exploitation of aquatic food sources (providing essential nutrients for human brain evolution or critical fallback foods) may have exerted evolutionary pressures on human ancestors promoting adaptations which later assisted full-time bipedalism. It has also been thought that consistent water-based food sources had developed early hominid dependency and facilitated dispersal along seas and rivers.
Physiology.
Bipedal movement occurs in a number of ways, and requires many mechanical and neurological adaptations. Some of these are described below.
Biomechanics.
Standing.
Energy-efficient means of standing bipedally involve constant adjustment of balance, and of course these must avoid overcorrection. The difficulties associated with simple standing in upright humans are highlighted by the greatly increased risk of falling present in the elderly, even with minimal reductions in control system effectiveness.
Shoulder stability.
Shoulder stability would decrease with the evolution of bipedalism. Shoulder mobility would increase because the need for a stable shoulder is only present in arboreal habitats. Shoulder mobility would support suspensory locomotion behaviors which are present in human bipedalism. The forelimbs are freed from weight bearing capabilities which makes the shoulder a place of evidence for the evolution of bipedalism.
Walking.
Walking is characterized by an "inverted pendulum" movement in which the center of gravity vaults over a stiff leg with each step. Force plates can be used to quantify the whole-body kinetic & potential energy, with walking displaying an out-of-phase relationship indicating exchange between the two. Interestingly, this model applies to all walking organisms regardless of the number of legs, and thus bipedal locomotion does not differ in terms of whole-body kinetics.
In humans, walking is composed of several separate processes:
Running.
Running is characterized by a spring-mass movement. Kinetic and potential energy are in phase, and the energy is stored & released from a spring-like limb during foot contact. Again, the whole-body kinetics are similar to animals with more limbs.
Musculature.
Bipedalism requires strong leg muscles, particularly in the thighs. Contrast in domesticated poultry the well muscled legs, against the small and bony wings. Likewise in humans, the quadriceps and hamstring muscles of the thigh are both so crucial to bipedal activities that each alone is much larger than the well-developed biceps of the arms.
Respiration.
A biped has the ability to breathe while running, without strong coupling to stride cycle. Humans usually take a breath every other stride when their aerobic system is functioning. During a sprint the anaerobic system kicks in and breathing slows until the anaerobic system can no longer sustain a sprint.
Bipedal robots.
For nearly the whole of the 20th century, bipedal robots were very difficult to construct and robot locomotion involved only wheels, treads, or multiple legs. Recent cheap and compact computing power has made two-legged robots more feasible. Some notable biped robots are ASIMO, HUBO, MABEL and QRIO. Recently, spurred by the success of creating a fully passive, un-powered bipedal walking robot, those working on such machines have begun using principles gleaned from the study of human and animal locomotion, which often relies on passive mechanisms to minimize power consumption.

</doc>
<doc id="4211" url="https://en.wikipedia.org/wiki?curid=4211" title="Bootstrapping">
Bootstrapping

In general parlance, bootstrapping usually refers to a self-starting process that is supposed to proceed without external input. In computer technology the term (usually shortened to booting) usually refers to the process of loading the basic software into the memory of a computer after power-on or general reset, especially the operating system which will then take care of loading other software as needed.
The term appears to have originated in the early 19th century United States (particularly in the phrase "pull oneself over a fence by one's bootstraps"), to mean an absurdly impossible action, an adynaton.
Etymology.
Tall boots may have a tab, loop or handle at the top known as a bootstrap, allowing one to use fingers or a boot hook tool to help pulling the boots on. The saying "to pull oneself up by one's bootstraps" was already in use during the 19th century as an example of an impossible task. The idiom dates at least to 1834, when it appeared in the "Workingman's Advocate": "It is conjectured that Mr. Murphee will now be enabled to hand himself over the Cumberland river or a barn yard fence by the straps of his boots." In 1860 it appeared in a comment on metaphysical philosophy: "The attempt of the mind to analyze itself an effort analogous to one who would lift himself by his own bootstraps." Bootstrap as a metaphor, meaning to better oneself by one's own unaided efforts, was in use in 1922. This metaphor spawned additional metaphors for a series of self-sustaining processes that proceed without external help.
The term is sometimes attributed to a story in Rudolf Erich Raspe's "", but in that story Baron Munchausen pulls himself (and his horse) out of a swamp by his hair (specifically, his pigtail), not by his bootstraps and no explicit reference to bootstraps has been found elsewhere in the various versions of the Munchausen tales.
Applications.
Computing.
Software loading and execution.
Booting is the process of starting a computer, specifically with regard to starting its software. The process involves a chain of stages, in which at each stage a smaller simpler program loads and then executes the larger more complicated program of the next stage. It is in this sense that the computer "pulls itself up by its bootstraps", i.e. it improves itself by its own efforts. Booting is a chain of events that starts with execution of hardware-based procedures and may then hand-off to firmware and software which is loaded into main memory. Booting often involves processes such as performing self-tests, loading configuration settings, loading a BIOS, resident monitors, a hypervisor, an operating system, or utility software.
The computer term bootstrap began as a metaphor in the 1950s. In computers, pressing a bootstrap button caused a hardwired program to read a bootstrap program from an input unit. The computer would then execute the bootstrap program, which caused it to read more program instructions. It became a self-sustaining process that proceeded without external help from manually entered instructions. As a computing term, bootstrap has been used since at least 1953.
Software development.
Bootstrapping can also refer to the development of successively more complex, faster programming environments. The simplest environment will be, perhaps, a very basic text editor (e.g., ed) and an assembler program. Using these tools, one can write a more complex text editor, and a simple compiler for a higher-level language and so on, until one can have a graphical IDE and an extremely high-level programming language.
Historically, bootstrapping also refers to an early technique for computer program development on new hardware. The technique described in this paragraph has been replaced by the use of a cross compiler executed by a pre-existing computer. Bootstrapping in program development began during the 1950s when each program was constructed on paper in decimal code or in binary code, bit by bit (1s and 0s), because there was no high-level computer language, no compiler, no assembler, and no linker. A tiny assembler program was hand-coded for a new computer (for example the IBM 650) which converted a few instructions into binary or decimal code: A1. This simple assembler program was then rewritten in its just-defined assembly language but with extensions that would enable the use of some additional mnemonics for more complex operation codes. The enhanced assembler's source program was then assembled by its predecessor's executable (A1) into binary or decimal code to give A2, and the cycle repeated (now with those enhancements available), until the entire instruction set was coded, branch addresses were automatically calculated, and other conveniences (such as conditional assembly, macros, optimisations, etc.) established. This was how the early assembly program SOAP (Symbolic Optimal Assembly Program) was developed. Compilers, linkers, loaders, and utilities were then coded in assembly language, further continuing the bootstrapping process of developing complex software systems by using simpler software.
The term was also championed by Doug Engelbart to refer to his belief that organizations could better evolve by improving the process they use for improvement (thus obtaining a compounding effect over time). His SRI team that developed the NLS hypertext system applied this strategy by using the tool they had developed to improve the tool.
Compilers.
The development of compilers for new programming languages first developed in an existing language but then rewritten in the new language and compiled by itself, is another example of the bootstrapping notion. Using an existing language to bootstrap a new language is one way to solve the "chicken or the egg" causality dilemma.
Installers.
During the installation of computer programs it is sometimes necessary to update the installer or package manager itself. The common pattern for this is to use a small executable bootstrapper file (e.g. setup.exe) which updates the installer and starts the real installation after the update. Sometimes the bootstrapper also installs other prerequisites for the software during the bootstrapping process.
Overlay networks.
A bootstrapping node, also known as a rendezvous host, is a node in an overlay network that provides initial configuration information to newly joining nodes so that they may successfully join the overlay network.
Discrete event simulation.
A type of computer simulation called discrete event simulation represents the operation of a system as a chronological sequence of events. A technique called "bootstrapping the simulation model" is used, which bootstraps initial data points using a pseudorandom number generator to schedule an initial set of pending events, which schedule additional events, and with time, the distribution of event times approaches its steady state—the bootstrapping behavior is overwhelmed by steady-state behavior.
Artificial intelligence and machine learning.
Bootstrapping is a technique used to iteratively improve a classifier's performance. Seed AI is a hypothesized type of artificial intelligence capable of recursive self-improvement. Having improved itself, it would become better at improving itself, potentially leading to an exponential increase in intelligence. No such AI is known to exist, but it remains an active field of research.
Seed AI is a significant part of some theories about the technological singularity: proponents believe that the development of seed AI will rapidly yield ever-smarter intelligence (via bootstrapping) and thus a new era.
Statistics.
Bootstrapping is a resampling technique used to obtain estimates of summary statistics.
Business.
Bootstrapping in business means starting a business without external help or capital. Such startups fund the development of their company through internal cash flow and are cautious with their expenses. Generally at the start of a venture, a small amount of money will be set aside for the bootstrap process. Bootstrapping can also be a supplement for econometric models. Bootstrapping was also expanded upon in the book "Bootstrap Business", by Richard Christiansen. and the article in the Harvard Business Review "The Art of Bootstrapping," and the followup book "The Origin and Evolution of New Businesses" by Amar Bhide. 
Biology.
Richard Dawkins in his book "River Out of Eden" used the computer bootstrapping concept to explain how biological cells differentiate: "Different cells receive different combinations of chemicals, which switch on different combinations of genes, and some genes work to switch other genes on or off. And so the bootstrapping continues, until we have the full repertoire of different kinds of cells."
Phylogenetics.
Bootstrapping analysis gives a way to judge the strength of support for clades on phylogenetic trees. A number is written by a node, which reflects the percentage of bootstrap trees which also resolve the clade at the endpoints of that branch.
Law.
Bootstrapping is a rule preventing the admission of hearsay evidence in conspiracy cases.
Linguistics.
Bootstrapping is a theory of language acquisition.
Physics.
Bootstrapping is using very general consistency criteria to determine the form of a quantum theory from some assumptions on the spectrum of particles.
Electronics.
Bootstrapping is a form of positive feedback in analog circuit design.
Electric power grid.
An electric power grid is almost never brought down intentionally. Generators and power stations are started and shut down as necessary. A typical power station requires power for start up prior to being able to generate power. This power is obtained from the grid, so if the entire grid is down these stations cannot be started.
Therefore, to get a grid started, there must be at least a small number of power stations that can start entirely on their own. A black start is the process of restoring a power station to operation without relying on external power. In the absence of grid power, one or more black starts are used to bootstrap the grid.
Cellular networks.
A Bootstrapping Server Function (BSF) is an intermediary element in cellular networks which provides application independent functions for mutual authentication of user equipment and servers unknown to each other and for 'bootstrapping' the exchange of secret session keys afterwards. The term 'bootstrapping' is related to building a security relation with a previously unknown device first and to allow installing security elements (keys) in the device and the BSF afterwards.
Media.
A media bootstrap is the process whereby a story or meme is deliberately (but artificially) produced by self and peer-referential journalism, originally within a tight circle of media content originators, often commencing with stories written within the same media organization. This story is then expanded into a general media "accepted wisdom" with the aim of having it accepted as self-evident "common knowledge" by the reading, listening and viewing publics. The key feature of a media bootstrap is that as little hard, verifiable, external evidence as possible is used to support the story, preference being given to the citation (often unattributed) of other media stories, i.e. "journalists interviewing journalists".
Because the campaign is usually originated and at least initially concocted internally by a media organization with a particular agenda in mind, within a closed loop of reportage and opinionation, the campaign is said to have "pulled itself up by its own bootstraps".
A bootstrap campaign should be distinguished from a genuine news story of genuine interest, such as a natural disaster that kills thousands, or the death of a respected public figure. It is legitimate for these stories to be given coverage across all media platforms. What distinguishes a bootstrap from a real story is the contrived and organized manner in which the bootstrap appears to come out of nowhere. A bootstrap commonly claims to be tapping a hitherto unrecognized phenomenon within society.
As self-levitating by pulling on one's bootstraps is physically impossible, this is often used by the bootstrappers themselves to deny the possibility that the bootstrap campaign is indeed concocted and artificial. They assert that it has arisen via a groundswell of public opinion. Media campaigns that are openly admitted as concocted (e.g. a public service campaign titled "Let's Clean Up Our City") are usually ignored by other media organizations for reasons related to competition. On the other hand, the true bootstrap welcomes the participation of other media organizations, indeed encourages it, as this participation gains the bootstrap notoriety and, most importantly, legitimacy.

</doc>
<doc id="4213" url="https://en.wikipedia.org/wiki?curid=4213" title="Baltic languages">
Baltic languages

The Baltic languages belong to the Balto-Slavic branch of the Indo-European language family. Baltic languages are spoken by the Balts, mainly in areas extending east and southeast of the Baltic Sea in Northern Europe. 
Scholars usually regard them as a single language family divided into two groups: Western Baltic (containing only extinct languages), and Eastern Baltic (containing two living languages, Lithuanian and Latvian). The range of the Eastern Balts once reached to the Ural mountains. 
Old Prussian, a Western Baltic language which became extinct in the 18th century, ranks as the most archaic of the Baltic languages.
Although related, the Lithuanian, the Latvian, and particularly the Old Prussian vocabularies differ substantially from one another and are not mutually intelligible.
Branches.
The Baltic languages are generally thought to form a single family with two branches, Eastern and Western. However, these two branches are sometimes classified as independent branches of Balto-Slavic.
Eastern Baltic languages.
"("†"—Extinct language)"
Geographic distribution.
Speakers of modern Baltic languages are generally concentrated within the borders of Lithuania and Latvia, and in emigrant communities in the United States, Canada, Australia and the countries within the former borders of the Soviet Union. 
Historically the languages were spoken over a larger area: west to the mouth of the Vistula river in present-day Poland, at least as far east as the Dniepr river in present-day Belarus, perhaps even to Moscow, and perhaps as far south as Kiev. Key evidence of Baltic language presence in these regions is found in hydronyms (names of bodies of water) that are characteristically Baltic. Use of hydronyms is generally accepted to determine the extent of a culture's influence, but "not" the date of such influence. 
Eventual expansion of the usage of Slavic languages in the south and east, and Germanic languages in the west reduced the geographic distribution of Baltic languages to a fraction of the area that they formerly covered.
Though included among the Baltic states due to its location, the language of Estonia, Estonian, is a Uralic language and is not related to the Baltic languages, which are Indo-European.
Prehistory and history.
It is believed that the Baltic languages are among the most archaic of the currently remaining Indo-European languages, despite their late attestation. 
Although the various Baltic tribes were mentioned by ancient historians as early as 98 B.C., the first attestation of a Baltic language was in about 1350, with the creation of the "Elbing Prussian Vocabulary", a German to Prussian translation dictionary. Lithuanian was first attested in a hymnal translation in 1545; the first printed book in Lithuanian, a Catechism by Martynas Mažvydas was published in 1547 in Königsberg, Prussia (now Kaliningrad, Russia). Latvian appeared in a hymnal in 1530 and in a printed Catechism in 1585. 
One reason for the late attestation is that the Baltic peoples resisted Christianization longer than any other Europeans, which delayed the introduction of writing and isolated their languages from outside influence.
With the establishment of a German state in Prussia, and the eradication or flight of much of the Baltic Prussian population in the 13th century, the remaining Prussians began to be assimilated, and by the end of the 17th century, the Prussian language had become extinct.
During the years of the Polish–Lithuanian Commonwealth (1569–1795), official documents were written in Polish, Ruthenian and Latin. 
After the Partitions of Commonwealth, most of the Baltic lands were under the rule of the Russian Empire, where the native languages or alphabets were sometimes prohibited from being written down or used publicly in a Russification effort (see Lithuanian press ban for the ban in force from 1865 to 1904).
Relationship with other Indo-European languages.
The Baltic languages are of particular interest to linguists because they retain many archaic features, which are believed to have been present in the early stages of the Proto-Indo-European language. However, linguists have had a hard time establishing the precise relationship of the Baltic languages to other languages in the Indo-European family. Several of the extinct Baltic languages have a limited or nonexistent written record, their existence being known only from the records of ancient historians and personal or place names. All of the languages in the Baltic group (including the living ones) were first written down relatively late in their probable existence as distinct languages. These two factors combined with others have obscured the history of the Baltic languages, leading to a number of theories regarding their position in the Indo-European family.
The Baltic languages show a close relationship with the Slavic languages, and are grouped with them in a Balto-Slavic family by most scholars. This family is considered to have developed from a common ancestor, Proto-Balto-Slavic. Later on, several lexical, phonological and morphological dialectisms developed, separating the various Balto-Slavic languages from each other. Although it is generally agreed upon that the Slavic languages developed from a single more-or-less unified dialect (Proto-Slavic) that split off from common Balto-Slavic, there is more disagreement about the relationship between the Baltic languages.
The traditional view is that the Balto-Slavic languages split into two branches, Baltic and Slavic, with each branch developing as a single common language (Proto-Baltic and Proto-Slavic) for some time afterwards. Proto-Baltic is then thought to have split into East Baltic and West Baltic branches. However, more recent scholarship has suggested that there was no unified Proto-Baltic stage, but that Proto-Balto-Slavic split directly into three groups: Slavic, East Baltic and West Baltic. Under this view, the Baltic family is paraphyletic, and consists of all Balto-Slavic languages that are not Slavic. This would imply that Proto-Baltic, the last common ancestor of all Baltic languages, would be identical to Proto-Balto-Slavic itself, rather than distinct from it.
Finally, there is a minority of scholars who argue that Baltic descended directly from Proto-Indo-European, without an intermediate common Balto-Slavic stage. They argue that the many similarities and shared innovations between Baltic and Slavic are due to several millennia of contact between the groups, rather than shared heritage.

</doc>
<doc id="4214" url="https://en.wikipedia.org/wiki?curid=4214" title="Bioinformatics">
Bioinformatics

Bioinformatics is an interdisciplinary field that develops methods and software tools for understanding biological data. As an interdisciplinary field of science, bioinformatics combines computer science, statistics, mathematics, and engineering to analyze and interpret biological data. Bioinformatics has been used for "in silico" analyses of biological queries using mathematical and statistical techniques.
Bioinformatics is both an umbrella term for the body of biological studies that use computer programming as part of their methodology, as well as a reference to specific analysis "pipelines" that are repeatedly used, particularly in the field of genomics. Common uses of bioinformatics include the identification of candidate genes and nucleotides (SNPs). Often, such identification is made with the aim of better understanding the genetic basis of disease, unique adaptations, desirable properties (esp. in agricultural species), or differences between populations. In a less formal way, bioinformatics also tries to understand the organisational principles within nucleic acid and protein sequences.
Introduction.
Bioinformatics has become an important part of many areas of biology. In experimental molecular biology, bioinformatics techniques such as image and signal processing allow, extraction of useful results from large amounts of raw data. In the field of genetics and genomics, it aids in sequencing and annotating genomes and their observed mutations. It plays a role in the text mining of biological literature and the development of biological and gene ontologies to organize and query biological data. It also plays a role in the analysis of gene and protein expression and regulation. Bioinformatics tools aid in the comparison of genetic and genomic data and more generally in the understanding of evolutionary aspects of molecular biology. At a more integrative level, it helps analyze and catalogue the biological pathways and networks that are an important part of systems biology. In structural biology, it aids in the simulation and modeling of DNA, RNA, and protein structures as well as molecular interactions.
History.
Historically, the term "bioinformatics" did not mean what it means today. Paulien Hogeweg and Ben Hesper coined it in 1970 to refer to the study of information processes in biotic systems. This definition placed bioinformatics as a field parallel to biophysics (the study of physical processes in biological systems) or biochemistry (the study of chemical processes in biological systems).
Sequences.
Computers became essential in molecular biology when protein sequences became available after Frederick Sanger determined the sequence of insulin in the early 1950s. Comparing multiple sequences manually turned out to be impractical. A pioneer in the field was Margaret Oakley Dayhoff, who has been hailed by David Lipman, director of the National Center for Biotechnology Information, as the "mother and father of bioinformatics." Dayhoff compiled one of the first protein sequence databases, initially published as books and pioneered methods of sequence alignment and molecular evolution. Another early contributor to bioinformatics was Elvin A. Kabat, who pioneered biological sequence analysis in 1970 with his comprehensive volumes of antibody sequences released with Tai Te Wu between 1980 and 1991.
Goals.
To study how normal cellular activities are altered in different disease states, the biological data must be combined to form a comprehensive picture of these activities. Therefore, the field of bioinformatics has evolved such that the most pressing task now involves the analysis and interpretation of various types of data. This includes nucleotide and amino acid sequences, protein domains, and protein structures. The actual process of analyzing and interpreting data is referred to as computational biology. Important sub-disciplines within bioinformatics and computational biology include:
The primary goal of bioinformatics is to increase the understanding of biological processes. What sets it apart from other approaches, however, is its focus on developing and applying computationally intensive techniques to achieve this goal. Examples include: pattern recognition, data mining, machine learning algorithms, and visualization. Major research efforts in the field include sequence alignment, gene finding, genome assembly, drug design, drug discovery, protein structure alignment, protein structure prediction, prediction of gene expression and protein–protein interactions, genome-wide association studies, the modeling of evolution and cell division/mitosis.
Bioinformatics now entails the creation and advancement of databases, algorithms, computational and statistical techniques, and theory to solve formal and practical problems arising from the management and analysis of biological data.
Over the past few decades, rapid developments in genomic and other molecular research technologies and developments in information technologies have combined to produce a tremendous amount of information related to molecular biology. Bioinformatics is the name given to these mathematical and computing approaches used to glean understanding of biological processes.
Common activities in bioinformatics include mapping and analyzing DNA and protein sequences, aligning DNA and protein sequences to compare them, and creating and viewing 3-D models of protein structures.
Relation to other fields.
Bioinformatics is a science field that is similar to but distinct from biological computation and computational biology. Biological computation uses bioengineering and biology to build biological computers, whereas bioinformatics uses computation to better understand biology. Bioinformatics and computational biology have similar aims and approaches, but they differ in scale: bioinformatics organizes and analyzes basic biological data, whereas computational biology builds theoretical models of biological systems, just as mathematical biology does with mathematical models.
Analyzing biological data to produce meaningful information involves writing and running software programs that use algorithms from graph theory, artificial intelligence, soft computing, data mining, image processing, and computer simulation. The algorithms in turn depend on theoretical foundations such as discrete mathematics, control theory, system theory, information theory, and statistics.
Sequence analysis.
Since the Phage Φ-X174 was sequenced in 1977, the DNA sequences of thousands of organisms have been decoded and stored in databases. This sequence information is analyzed to determine genes that encode proteins, RNA genes, regulatory sequences, structural motifs, and repetitive sequences. A comparison of genes within a species or between different species can show similarities between protein functions, or relations between species (the use of molecular systematics to construct phylogenetic trees). With the growing amount of data, it long ago became impractical to analyze DNA sequences manually. Today, computer programs such as BLAST are used daily to search sequences from more than 260 000 organisms, containing over 190 billion nucleotides. These programs can compensate for mutations (exchanged, deleted or inserted bases) in the DNA sequence, to identify sequences that are related, but not identical. A variant of this sequence alignment is used in the sequencing process itself. The so-called shotgun sequencing technique (which was used, for example, by The Institute for Genomic Research (TIGR) to sequence the first bacterial genome, "Haemophilus influenzae") does not produce entire chromosomes. Instead it generates the sequences of many thousands of small DNA fragments (ranging from 35 to 900 nucleotides long, depending on the sequencing technology). The ends of these fragments overlap and, when aligned properly by a genome assembly program, can be used to reconstruct the complete genome. Shotgun sequencing yields sequence data quickly, but the task of assembling the fragments can be quite complicated for larger genomes. For a genome as large as the human genome, it may take many days of CPU time on large-memory, multiprocessor computers to assemble the fragments, and the resulting assembly usually contains numerous gaps that must be filled in later. Shotgun sequencing is the method of choice for virtually all genomes sequenced today, and genome assembly algorithms are a critical area of bioinformatics research.
Following the goals that the Human Genome Project left to achieve after its closure in 2003, a new project developed by the National Human Genome Research Institute in the U.S appeared. The so-called ENCODE project is a collaborative data collection of the functional elements of the human genome that uses next-generation DNA-sequencing technologies and genomic tiling arrays, technologies able to generate automatically large amounts of data with lower research costs but with the same quality and viability.
Another aspect of bioinformatics in sequence analysis is annotation. This involves computational gene finding to search for protein-coding genes, RNA genes, and other functional sequences within a genome. Not all of the nucleotides within a genome are part of genes. Within the genomes of higher organisms, large parts of the DNA do not serve any obvious purpose.
Genome annotation.
In the context of genomics, annotation is the process of marking the genes and other biological features in a DNA sequence. This process needs to be automated because most genomes are too large to annotate by hand, not to mention the desire to annotate as many genomes as possible, as the rate of sequencing has ceased to pose a bottleneck. Annotation is made possible by the fact that genes have recognisable start and stop regions, although the exact sequence found in these regions can vary between genes.
The first genome annotation software system was designed in 1995 by Owen White, who was part of the team at The Institute for Genomic Research that sequenced and analyzed the first genome of a free-living organism to be decoded, the bacterium "Haemophilus influenzae". White built a software system to find the genes (fragments of genomic sequence that encode proteins), the transfer RNAs, and to make initial assignments of function to those genes. Most current genome annotation systems work similarly, but the programs available for analysis of genomic DNA, such as the GeneMark program trained and used to find protein-coding genes in "Haemophilus influenzae", are constantly changing and improving.
Computational evolutionary biology.
Evolutionary biology is the study of the origin and descent of species, as well as their change over time. Informatics has assisted evolutionary biologists by enabling researchers to:
Future work endeavours to reconstruct the now more complex tree of life.
The area of research within computer science that uses genetic algorithms is sometimes confused with computational evolutionary biology, but the two areas are not necessarily related.
Comparative genomics.
The core of comparative genome analysis is the establishment of the correspondence between genes (orthology analysis) or other genomic features in different organisms. It is these intergenomic maps that make it possible to trace the evolutionary processes responsible for the divergence of two genomes. A multitude of evolutionary events acting at various organizational levels shape genome evolution. At the lowest level, point mutations affect individual nucleotides. At a higher level, large chromosomal segments undergo duplication, lateral transfer, inversion, transposition, deletion and insertion.
Ultimately, whole genomes are involved in processes of hybridization, polyploidization and endosymbiosis, often leading to rapid speciation. The complexity of genome evolution poses many exciting challenges to developers of mathematical models and algorithms, who have recourse to a spectra of algorithmic, statistical and mathematical techniques, ranging from exact, heuristics, fixed parameter and approximation algorithms for problems based on parsimony models to Markov Chain Monte Carlo algorithms for Bayesian analysis of problems based on probabilistic models.
Many of these studies are based on the homology detection and protein families computation.
Pan genomics.
Pan genomics is a concept introduced in 2005 by Tettelin and Medini which eventually took root in bioinformatics. Pan genome is the complete gene repertoire of a particular taxonomic group: although initially applied to closely related strains of a species, it can be applied to a larger context like genus, phylum etc. It is divided in two parts- The Core genome: Set of genes common to all the genomes under study (These are often housekeeping genes vital for survival) and The Dispensable/Flexible Genome: Set of genes not present in all but one or some genomes under study.
Genetics of disease.
With the advent of next-generation sequencing we are obtaining enough sequence data to map the genes of complex diseases such as diabetes, infertility, breast cancer or Alzheimer's Disease. Genome-wide association studies are a useful approach to pinpoint the mutations responsible for such complex diseases. Through these studies, thousands of DNA variants have been identified that are associated with similar diseases and traits. Furthermore, the possibility for genes to be used at prognosis, diagnosis or treatment is one of the most essential applications. Many studies are discussing both the promising ways to choose the genes to be used and the problems and pitfalls of using genes to predict disease presence or prognosis.
Analysis of mutations in cancer.
In cancer, the genomes of affected cells are rearranged in complex or even unpredictable ways. Massive sequencing efforts are used to identify previously unknown point mutations in a variety of genes in cancer. Bioinformaticians continue to produce specialized automated systems to manage the sheer volume of sequence data produced, and they create new algorithms and software to compare the sequencing results to the growing collection of human genome sequences and germline polymorphisms. New physical detection technologies are employed, such as oligonucleotide microarrays to identify chromosomal gains and losses (called comparative genomic hybridization), and single-nucleotide polymorphism arrays to detect known "point mutations". These detection methods simultaneously measure several hundred thousand sites throughout the genome, and when used in high-throughput to measure thousands of samples, generate terabytes of data per experiment. Again the massive amounts and new types of data generate new opportunities for bioinformaticians. The data is often found to contain considerable variability, or noise, and thus Hidden Markov model and change-point analysis methods are being developed to infer real copy number changes.
With the breakthroughs that this next-generation sequencing technology is providing to the field of Bioinformatics, cancer genomics could drastically change. These new methods and software allow bioinformaticians to sequence many cancer genomes quickly and affordably. This could create a more flexible process for classifying types of cancer by analysis of cancer driven mutations in the genome. Furthermore, tracking of patients while the disease progresses may be possible in the future with the sequence of cancer samples.
Another type of data that requires novel informatics development is the analysis of lesions found to be recurrent among many tumors.
Gene and protein expression.
Analysis of gene expression.
The expression of many genes can be determined by measuring mRNA levels with multiple techniques including microarrays, expressed cDNA sequence tag (EST) sequencing, serial analysis of gene expression (SAGE) tag sequencing, massively parallel signature sequencing (MPSS), RNA-Seq, also known as "Whole Transcriptome Shotgun Sequencing" (WTSS), or various applications of multiplexed in-situ hybridization. All of these techniques are extremely noise-prone and/or subject to bias in the biological measurement, and a major research area in computational biology involves developing statistical tools to separate signal from noise in high-throughput gene expression studies. Such studies are often used to determine the genes implicated in a disorder: one might compare microarray data from cancerous epithelial cells to data from non-cancerous cells to determine the transcripts that are up-regulated and down-regulated in a particular population of cancer cells.
Analysis of protein expression.
Protein microarrays and high throughput (HT) mass spectrometry (MS) can provide a snapshot of the proteins present in a biological sample. Bioinformatics is very much involved in making sense of protein microarray and HT MS data; the former approach faces similar problems as with microarrays targeted at mRNA, the latter involves the problem of matching large amounts of mass data against predicted masses from protein sequence databases, and the complicated statistical analysis of samples where multiple, but incomplete peptides from each protein are detected.
Analysis of regulation.
Regulation is the complex orchestration of events starting with an extracellular signal such as a hormone and leading to an increase or decrease in the activity of one or more proteins. Bioinformatics techniques have been applied to explore various steps in this process. For example, promoter analysis involves the identification and study of sequence motifs in the DNA surrounding the coding region of a gene. These motifs influence the extent to which that region is transcribed into mRNA. Expression data can be used to infer gene regulation: one might compare microarray data from a wide variety of states of an organism to form hypotheses about the genes involved in each state. In a single-cell organism, one might compare stages of the cell cycle, along with various stress conditions (heat shock, starvation, etc.). One can then apply clustering algorithms to that expression data to determine which genes are co-expressed. For example, the upstream regions (promoters) of co-expressed genes can be searched for over-represented regulatory elements. Examples of clustering algorithms applied in gene clustering are k-means clustering, self-organizing maps (SOMs), hierarchical clustering, and consensus clustering methods such as the Bi-CoPaM. The later, namely Bi-CoPaM, has been actually proposed to address various issues specific to gene discovery problems such as consistent co-expression of genes over multiple microarray datasets.
Structural bioinformatics.
Protein structure prediction is another important application of bioinformatics. The amino acid sequence of a protein, the so-called primary structure, can be easily determined from the sequence on the gene that codes for it. In the vast majority of cases, this primary structure uniquely determines a structure in its native environment. (Of course, there are exceptions, such as the bovine spongiform encephalopathy – a.k.a. Mad Cow Disease – prion.) Knowledge of this structure is vital in understanding the function of the protein. Structural information is usually classified as one of "secondary", "tertiary" and "quaternary" structure. A viable general solution to such predictions remains an open problem. Most efforts have so far been directed towards heuristics that work most of the time.
One of the key ideas in bioinformatics is the notion of homology. In the genomic branch of bioinformatics, homology is used to predict the function of a gene: if the sequence of gene "A", whose function is known, is homologous to the sequence of gene "B," whose function is unknown, one could infer that B may share A's function. In the structural branch of bioinformatics, homology is used to determine which parts of a protein are important in structure formation and interaction with other proteins. In a technique called homology modeling, this information is used to predict the structure of a protein once the structure of a homologous protein is known. This currently remains the only way to predict protein structures reliably.
One example of this is the similar protein homology between hemoglobin in humans and the hemoglobin in legumes (leghemoglobin). Both serve the same purpose of transporting oxygen in the organism. Though both of these proteins have completely different amino acid sequences, their protein structures are virtually identical, which reflects their near identical purposes.
Other techniques for predicting protein structure include protein threading and "de novo" (from scratch) physics-based modeling.
Network and systems biology.
"Network analysis" seeks to understand the relationships within biological networks such as metabolic or protein–protein interaction networks. Although biological networks can be constructed from a single type of molecule or entity (such as genes), network biology often attempts to integrate many different data types, such as proteins, small molecules, gene expression data, and others, which are all connected physically, functionally, or both.
"Systems biology" involves the use of computer simulations of cellular subsystems (such as the networks of metabolites and enzymes that comprise metabolism, signal transduction pathways and gene regulatory networks) to both analyze and visualize the complex connections of these cellular processes. Artificial life or virtual evolution attempts to understand evolutionary processes via the computer simulation of simple (artificial) life forms.
Molecular interaction networks.
Tens of thousands of three-dimensional protein structures have been determined by X-ray crystallography and protein nuclear magnetic resonance spectroscopy (protein NMR) and a central question in structural bioinformatics is whether it is practical to predict possible protein–protein interactions only based on these 3D shapes, without performing protein–protein interaction experiments. A variety of methods have been developed to tackle the protein–protein docking problem, though it seems that there is still much work to be done in this field.
Other interactions encountered in the field include Protein–ligand (including drug) and protein–peptide. Molecular dynamic simulation of movement of atoms about rotatable bonds is the fundamental principle behind computational algorithms, termed docking algorithms, for studying molecular interactions.
Others.
Literature analysis.
The growth in the number of published literature makes it virtually impossible to read every paper, resulting in disjointed sub-fields of research. Literature analysis aims to employ computational and statistical linguistics to mine this growing library of text resources. For example:
The area of research draws from statistics and computational linguistics.
High-throughput image analysis.
Computational technologies are used to accelerate or fully automate the processing, quantification and analysis of large amounts of high-information-content biomedical imagery. Modern image analysis systems augment an observer's ability to make measurements from a large or complex set of images, by improving accuracy, objectivity, or speed. A fully developed analysis system may completely replace the observer. Although these systems are not unique to biomedical imagery, biomedical imaging is becoming more important for both diagnostics and research. Some examples are:
High-throughput single cell data analysis.
Computational techniques are used to analyse high-throughput, low-measurement single cell data, such as that obtained from flow cytometry. These methods typically involve finding populations of cells that are relevant to a particular disease state or experimental condition.
Biodiversity informatics.
Biodiversity informatics deals with the collection and analysis of biodiversity data, such as taxonomic databases, or microbiome data. Examples of such analyses include phylogenetics, niche modelling, species richness mapping, or species identification tools.
Databases.
Databases are essential for bioinformatics research and applications. There is a huge number of available databases covering almost everything from DNA and protein sequences, molecular structures, to phenotypes and biodiversity. Databases generally fall into one of three types. Some contain data resulting directly from empirical methods such as gene knockouts. Others consist of predicted data, and most contain data from both sources. There are meta-databases that incorporate data compiled from multiple other databases. Some others are specialized, such as those specific to an organism. These databases vary in their format, way of accession and whether they are public or not. Some of the most commonly used databases are listed below. For a more comprehensive list, please check the link at the beginning of the subsection.
Please keep in mind that this is a quick sampling and generally most computation data is supported by wet lab data as well.
Software and tools.
Software tools for bioinformatics range from simple command-line tools, to more complex graphical programs and standalone web-services available from various bioinformatics companies or public institutions.
Open-source bioinformatics software.
Many free and open-source software tools have existed and continued to grow since the 1980s. The combination of a continued need for new algorithms for the analysis of emerging types of biological readouts, the potential for innovative "in silico" experiments, and freely available open code bases have helped to create opportunities for all research groups to contribute to both bioinformatics and the range of open-source software available, regardless of their funding arrangements. The open source tools often act as incubators of ideas, or community-supported plug-ins in commercial applications. They may also provide "de facto" standards and shared object models for assisting with the challenge of bioinformation integration.
The range of open-source software packages includes titles such as Bioconductor, BioPerl, Biopython, BioJava, BioJS, BioRuby, Bioclipse, EMBOSS, .NET Bio, Orange with its bioinformatics add-on, Apache Taverna, UGENE and GenoCAD. To maintain this tradition and create further opportunities, the non-profit Open Bioinformatics Foundation have supported the annual Bioinformatics Open Source Conference (BOSC) since 2000.
An alternative method to build public bioinformatics databases is to use the MediaWiki engine with the "WikiOpener" extension. This system allows the database to be accessed and updated by all experts in the field.
Web services in bioinformatics.
SOAP- and REST-based interfaces have been developed for a wide variety of bioinformatics applications allowing an application running on one computer in one part of the world to use algorithms, data and computing resources on servers in other parts of the world. The main advantages derive from the fact that end users do not have to deal with software and database maintenance overheads.
Basic bioinformatics services are classified by the EBI into three categories: SSS (Sequence Search Services), MSA (Multiple Sequence Alignment), and BSA (Biological Sequence Analysis). The availability of these service-oriented bioinformatics resources demonstrate the applicability of web-based bioinformatics solutions, and range from a collection of standalone tools with a common data format under a single, standalone or web-based interface, to integrative, distributed and extensible bioinformatics workflow management systems.
Bioinformatics workflow management systems.
A Bioinformatics workflow management system is a specialized form of a workflow management system designed specifically to compose and execute a series of computational or data manipulation steps, or a workflow, in a Bioinformatics application. Such systems are designed to
Some of the platforms giving this service: Galaxy, Kepler, Taverna, UGENE, Anduril.
Education platforms.
Software platforms designed to teach bioinformatics concepts and methods include Rosalind and online courses offered through the Swiss Institute of Bioinformatics Training Portal. The Canadian Bioinformatics Workshops provides videos and slides from training workshops on their website under a Creative Commons license. The 4273π project or 4273pi project also offers open source educational materials for free. The course runs on low cost raspberry pi computers and has been used to teach adults and school pupils. 4273π is actively developed by a consortium of academics and research staff who have run research level bioinformatics using raspberry pi computers and the 4273π operating system.
Conferences.
There are several large conferences that are concerned with bioinformatics. Some of the most notable examples are Intelligent Systems for Molecular Biology (ISMB), European Conference on Computational Biology (ECCB), and Research in Computational Molecular Biology (RECOMB).

</doc>
<doc id="4216" url="https://en.wikipedia.org/wiki?curid=4216" title="Brian De Palma">
Brian De Palma

Brian Russell De Palma (born September 11, 1940) is an American film director and screenwriter. He is considered part of the New Hollywood wave of filmmaking.
In a career spanning over 40 years, he is best known for his suspense, psychological thriller and crime films. He directed successful and popular films such as the supernatural horror "Carrie", the erotic crime thriller "Dressed to Kill", the thriller "Blow Out", the crime dramas "Scarface", "The Untouchables" and "Carlito's Way", and the action spy film "".
Early life.
De Palma, who is of Italian ancestry, was born in Newark, New Jersey, the son of Vivienne (née Muti) and Anthony Federico De Palma, an orthopedic surgeon. He was raised in Philadelphia, Pennsylvania and New Hampshire, and attended various Protestant and Quaker schools, eventually graduating from Friends' Central School. When he was in high school, he built computers. He won a regional science-fair prize for a project titled "An Analog Computer to Solve Differential Equations".
1960s and early career.
Enrolled at Columbia as a physics student, De Palma became enraptured with the filmmaking process after viewing "Citizen Kane" and "Vertigo". De Palma subsequently enrolled at the newly coed Sarah Lawrence College as a graduate student in their theater department in the early 1960s, becoming one of the first male students among a female population. Once there, influences as various as drama teacher Wilford Leach, the Maysles brothers, Michelangelo Antonioni, Jean-Luc Godard, Andy Warhol and Alfred Hitchcock impressed upon De Palma the many styles and themes that would shape his own cinema in the coming decades. An early association with a young Robert De Niro resulted in "The Wedding Party". The film, which was co-directed with Leach and producer Cynthia Munroe, had been shot in 1963 but remained unreleased until 1969, when De Palma's star had risen sufficiently within the Greenwich Village filmmaking scene. De Niro was unknown at the time; the credits mistakenly display his name as "Robert ." The film is noteworthy for its invocation of silent film techniques and an insistence on the jump-cut for effect. De Palma followed this with various small films for the NAACP and The Treasury Department.
During the 1960s, De Palma began making a living producing documentary films, notably "The Responsive Eye", a 1966 movie about "The Responsive Eye" op-art exhibit curated by William Seitz for Museum of Modern Art in 1965. In an interview with Gelmis from 1969, De Palma described the film as "very good and very successful. It's distributed by Pathe Contemporary and makes lots of money. I shot it in four hours, with synched sound. I had two other guys shooting people's reactions to the paintings, and the paintings themselves."
"Dionysus in 69" (1969) was De Palma's other major documentary from this period. The film records The Performance Group's performance of Euripides' The Bacchae, starring, amongst others, De Palma regular William Finley. The play is noted for breaking traditional barriers between performers and audience. The film's most striking quality is its extensive use of the split-screen. De Palma recalls that he was "floored" by this performance upon first sight, and in 1973 recounts how he "began to try and figure out a way to capture it on film. I came up with the idea of split-screen, to be able to show the actual audience involvement, to trace the life of the audience and that of the play as they merge in and out of each other."
De Palma's most significant features from this decade are "Greetings" (1968) and "Hi, Mom!" (1970). Both films star Robert De Niro and espouse a Leftist revolutionary viewpoint common to their era. "Greetings" was entered into the 19th Berlin International Film Festival, where it won a Silver Bear award. His other major film from this period is the slasher comedy "Murder a la Mod". Each of these films contains experiments in narrative and intertextuality, reflecting De Palma's stated intention to become the "American Godard" while integrating several of the themes which permeated Hitchcock's work.
"Greetings" is about three New Yorkers dealing with the draft. The film is often considered the first to deal explicitly with the draft. The film is noteworthy for its use of various experimental techniques to convey its narrative in ultimately unconventional ways. Footage was sped up, rapid cutting was used to distance the audience from the narrative, and it was difficult to discern with whom the audience must ultimately align. "Greetings" ultimately grossed over $1 million at the box office and cemented De Palma's position as a bankable filmmaker.
After the success of his 1968 breakthrough, De Palma and his producing partner, Charles Hirsch, were given the opportunity by Sigma 3 to make an unofficial sequel of sorts, initially entitled "Son of Greetings", and subsequently released as "Hi, Mom!". While "Greetings" accentuated its varied cast, "Hi, Mom!" focuses on De Niro's character, Jon Rubin, an essential carry-over from the previous film. The film is ultimately significant insofar as it displays the first enunciation of De Palma's style in all its major traits – voyeurism, guilt, and a hyper-consciousness of the medium are all on full display, not just as hallmarks, but built into this formal, material apparatus itself.
These traits come to the fore in "Hi, Mom!"'s "Be Black, Baby" sequence. This sequence parodies cinéma vérité, the dominant documentary tradition of the 1960s, while simultaneously providing the audience with a visceral and disturbingly emotional experience. De Palma describes the sequence as a constant invocation of Brechtian distanciation: “First of all, I am interested in the medium of film itself, and I am constantly standing outside and making people aware that they are always watching a film. At the same time I am evolving it. In "Hi, Mom!" for instance, there is a sequence where you are obviously watching a ridiculous documentary and you are told that and you are aware of it, but it still sucks you in. There is a kind of Brechtian alienation idea here: you are aware of what you are watching at the same time that you are emotionally involved with it.”
"Be Black, Baby" was filmed in black and white stock on 16 mm, in low-light conditions that stress the crudity of the direct cinema aesthetic. It is precisely from this crudity that the film itself gains a credibility of “realism.” In an interview with Michael Bliss, De Palma notes “Black, Baby was rehearsed for almost three weeks... In fact, it's all scripted. But once the thing starts, they just go with the way it's going. I specifically got a very good documentary camera filmmaker (Robert Elfstrom) to just shoot it like a documentary to follow the action." Furthermore, "I wanted to show in "Hi, Mom!" how you can really involve an audience. You take an absurd premise – "Be Black, Baby" – and totally involve them and really frighten them at the same time. It's very Brechtian. You suck 'em in and annihilate 'em. Then you say, "It's just a movie, right? It's not real." It's just like television. You're sucked in all the time, and you're being lied to in a very documentary-like setting. The "Be Black, Baby" section of "Hi, Mom!" is probably the most important piece of film I've ever done."
Transition to Hollywood.
In the 1970s, De Palma went to Hollywood where he worked on bigger budget films. In 1970, De Palma left New York for Hollywood at age thirty to make "Get to Know Your Rabbit", starring Orson Welles and Tommy Smothers. Making the film was a crushing experience for De Palma as Tommy Smothers didn't like a lot of De Palma's ideas.
After several small, studio and independent released films that included stand-outs "Sisters", "Phantom of the Paradise", and "Obsession", a small film based on a novel called "Carrie" was released directed by Brian De Palma. The psychic thriller "Carrie" is seen by some as De Palma's bid for a blockbuster. In fact, the project was small, underfunded by United Artists, and well under the cultural radar during the early months of production, as Stephen King's source novel had yet to climb the bestseller list. De Palma gravitated toward the project and changed crucial plot elements based upon his own predilections, not the saleability of the novel. The cast was young and relatively new, though the stars Sissy Spacek and John Travolta had gained considerable attention for previous work in, respectively, film and episodic sitcoms. "Carrie" became a hit, the first genuine box-office success for De Palma. It garnered Spacek and Piper Laurie Oscar nominations for their performances. Preproduction for the film had coincided with the casting process for George Lucas's "Star Wars", and many of the actors cast in De Palma's film had been earmarked as contenders for Lucas's movie, and vice versa. The "shock ending" finale is effective even while it upholds horror-film convention, its suspense sequences are buttressed by teen comedy tropes, and its use of split-screen, split-diopter and slow motion shots tell the story visually rather than through dialogue.
The financial and critical success of "Carrie" allowed De Palma to pursue more personal material. "The Demolished Man" was a novel that had fascinated De Palma since the late 1950s and appealed to his background in mathematics and avant-garde storytelling. Its unconventional unfolding of plot (exemplified in its mathematical layout of dialogue) and its stress on perception have analogs in De Palma's filmmaking. He sought to adapt it on numerous occasions, though the project would carry a substantial price tag, and has yet to appear onscreen (Steven Spielberg's adaptation of Philip K. Dick's "Minority Report" bears striking similarities to De Palma's visual style and some of the themes of "The Demolished Man"). The result of his experience with adapting "The Demolished Man" was "The Fury", a science fiction psychic thriller that starred Kirk Douglas, Carrie Snodgress, John Cassavetes and Amy Irving. The film was admired by Jean-Luc Godard, who featured a clip in his mammoth Histoire(s) du cinéma, and Pauline Kael who championed both "The Fury" and De Palma. The film boasted a larger budget than "Carrie", though the consensus view at the time was that De Palma was repeating himself, with diminishing returns. As a film it retains De Palma's considerable visual flair, but points more toward his work in mainstream entertainments such as "The Untouchables" and "", the thematic complex thrillers for which he is now better known.
For many film-goers, De Palma's gangster films, most notably "Scarface" and "Carlito's Way", pushed the envelope of violence and depravity, and yet greatly vary from one another in both style and content and also illustrate De Palma's evolution as a film-maker. In essence, the excesses of "Scarface" contrast with the more emotional tragedy of "Carlito's Way". Both films feature Al Pacino in what has become a fruitful working relationship. In 1984, he directed the music video of Bruce Springsteen's song "Dancing in the Dark".
Later into the 1990s and 2000s, De Palma did other films. He attempted to do dramas and a few thrillers plus science fiction. Some of these movies ("Mission: Impossible", "Carlito's Way") worked and some others ("The Bonfire of the Vanities", "Raising Cain", "Mission to Mars") failed at the box office. Of these films, "The Bonfire of the Vanities" would be De Palma's biggest box office disaster, losing millions. Another later movie from De Palma, "Redacted", unleashed a controversy over its subject of American involvement in Iraq, and supposed atrocities committed there. It received limited release in the United States.
In 2012, his film "Passion" was selected to compete for the Golden Lion at the 69th Venice International Film Festival. In 2015, he was the subject of a documentary film, "De Palma".
Trademarks and style.
Themes.
De Palma's films can fall into two categories, his psychological thrillers ("Sisters", "Body Double", "Obsession", "Dressed to Kill", "Blow Out", "Raising Cain") and his mainly commercial films ("Scarface", "The Untouchables", "Carlito's Way", and "Mission: Impossible"). He has often produced "De Palma" films one after the other before going on to direct a different genre, but would always return to his familiar territory. Because of the subject matter and graphic violence of some of De Palma's films, such as "Dressed to Kill", "Scarface" and "Body Double", they are often at the center of controversy with the Motion Picture Association of America, film critics and the viewing public.
De Palma is known for quoting and referencing other directors' work throughout his career. Michelangelo Antonioni's "Blowup" and Francis Ford Coppola's "The Conversation" plots were used for the basis of "Blow Out". "The Untouchables" finale shoot out in the train station is a clear borrow from the Odessa Steps sequence in Sergei Eisenstein's "The Battleship Potemkin". The main plot from "Rear Window" was used for "Body Double", while it also used elements of "Vertigo". "Vertigo" was also the basis for "Obsession". "Dressed to Kill" was a note-for-note homage to Hitchcock's "Psycho", including such moments as the surprise death of the lead actress and the exposition scene by the psychiatrist at the end.
Camera shots.
Film critics have often noted De Palma's penchant for unusual camera angles and compositions throughout his career. He often frames characters against the background using a canted angle shot. Split-screen techniques have been used to show two separate events happening simultaneously. To emphasize the dramatic impact of a certain scene De Palma has employed a 360-degree camera pan. Slow sweeping, panning and tracking shots are often used throughout his films, often through precisely-choreographed long takes lasting for minutes without cutting. Split focus shots, often referred to as "di-opt", are used by De Palma to emphasize the foreground person/object while simultaneously keeping a background person/object in focus. Slow-motion is frequently used in his films to increase suspense.
Personal life.
De Palma dated actress Margot Kidder in the early 1970s. He has been married and divorced three times, to actress Nancy Allen (1979–1983), producer Gale Anne Hurd (1991–1993), and Darnell Gregorio (1995–1997). He has one daughter from his marriage to Gale Anne Hurd, Lolita de Palma, born in 1991, and one daughter from his marriage to Darnell Gregorio, Piper De Palma, born in 1996. He resides in Manhattan, New York.
Legacy.
De Palma is often cited as a leading member of the New Hollywood generation of film directors, a distinct pedigree who either emerged from film schools or are overtly cine-literate. His contemporaries include Martin Scorsese, Paul Schrader, John Milius, George Lucas, Francis Ford Coppola, Steven Spielberg, John Carpenter, and Ridley Scott. His artistry in directing and use of cinematography and suspense in several of his films has often been compared to the work of Alfred Hitchcock. Psychologists have been intrigued by De Palma's fascination with pathology, by the aberrant behavior aroused in characters who find themselves manipulated by others.
De Palma has encouraged and fostered the filmmaking careers of directors such as Mark Romanek and Keith Gordon. During an interview with De Palma, Tarantino said that "Blow Out" is one of his all-time favorite films, and that after watching "Scarface" he knew how to make his own film. Terrence Malick credits seeing De Palma's early films on college campus tours as a validation of independent film, and subsequently switched his attention from philosophy to filmmaking. Other filmmakers influenced by De Palma include Quentin Tarantino, Ronny Yu, Don Mancini, Nacho Vigalondo, and Jack Thomas Smith.
Critics who frequently admire De Palma's work include Pauline Kael and Roger Ebert, among others. Kael wrote in her review of "Blow Out", "At forty, Brian De Palma has more than twenty years of moviemaking behind him, and he has been growing better and better. Each time a new film of his opens, everything he has done before seems to have been preparation for it." In his review of "Femme Fatale", Roger Ebert wrote about the director: "De Palma deserves more honor as a director. Consider also these titles: "Sisters", "Blow Out", "The Fury", "Dressed to Kill", "Carrie", "Scarface", "Wise Guys", "Casualties of War", "Carlito's Way", "Mission: Impossible". Yes, there are a few failures along the way ("Snake Eyes", "Mission to Mars", "The Bonfire of the Vanities"), but look at the range here, and reflect that these movies contain treasure for those who admire the craft as well as the story, who sense the glee with which De Palma manipulates images and characters for the simple joy of being good at it. It's not just that he sometimes works in the style of Hitchcock, but that he has the nerve to."
Criticism.
Julie Salamon has written that De Palma was "a perverse misogynist." De Palma has responded to accusations of misogyny by saying: "I'm always attacked for having an erotic, sexist approach-- chopping up women, putting women in peril. I'm making suspense movies! What else is going to happen to them?"
David Thomson wrote in his entry for De Palma, "There is a self-conscious cunning in De Palma's work, ready to control everything except his own cruelty and indifference."
References.
Notes
Bibliography
Further reading

</doc>
<doc id="4218" url="https://en.wikipedia.org/wiki?curid=4218" title="North American B-25 Mitchell">
North American B-25 Mitchell

The North American B-25 Mitchell is an American twin-engine, medium bomber manufactured by North American Aviation (NAA). It was named in honor of Major General William "Billy" Mitchell, a pioneer of U.S. military aviation. Used by many Allied air forces, the B-25 served in every theater of World War II and after the war ended many remained in service, operating across four decades. Produced in numerous variants, nearly 10,000 Mitchells rolled from NAA factories. These included a few limited models, such as the United States Marine Corps' PBJ-1 patrol bomber and the United States Army Air Forces' F-10 reconnaissance aircraft and AT-24 trainers.
Design and development.
The Air Corps issued a circular (Number 38-385) in March 1938 describing the performance they required from the next bombers — a payload of with a range of at more than . Those performance specifications led NAA to submit their NA-40 design. The NA-40 had benefited from the North American XB-21 (NA-39) of 1936 which was the company's partly-successful design for an earlier medium bomber that had been initially accepted and ordered but then cancelled. However, the company's experience from the XB-21 contributed to the design and development of the NA-40. The single NA-40 built flew first at the end of January 1939. It went through several modifications to correct problems. These improvements included fitting 1,600 hp Wright R-2600 "Double Cyclone" radial engines, in March 1939 which solved the lack of power.
In March 1939, North American delivered the substantially redesigned and improved NA-40 (as NA-40B) to the United States Army Air Corps for evaluation. It was in competition with other manufacturers' designs (Douglas 7B, Stearman X-100, and the Martin Model 167F) but failed to win orders. The aircraft was originally intended to be an attack bomber for export to the United Kingdom and France, both of which had a pressing requirement for such aircraft in the early stages of World War II. However, the French had already opted for a revised Douglas 7B (as the DB-7). Unfortunately, the NA-40B was destroyed in a crash on 11 April 1939 while undergoing testing. Although the crash was not considered due to a fault with the aircraft design, the Army ordered the DB-7 as the A-20.
The Air Corps issued a specification for a medium bomber in March 1939: over at NAA used the NA-40B design to develop the NA-62 which competed for the medium bomber contract. There was no YB-25 for prototype service tests. In September 1939, the Air Corps ordered the NA-62 into production as the B-25, along with the other new Air Corps medium bomber, the Martin B-26 Marauder "off the drawing board".
The NA-40 lost out to the Douglas A-20 in the attack type competition, but NAA developed a more advanced design, the NA-40B, which in turn led to the NA-62, B-25 Mitchell bomber.
Early into B-25 production, NAA incorporated a significant redesign to the wing dihedral. The first nine aircraft had a constant-dihedral, meaning the wing had a consistent, upward angle from the fuselage to the wingtip. This design caused stability problems. "Flattening" the outer wing panels by giving them a slight anhedral angle just outboard of the engine nacelles nullified the problem, and gave the B-25 its gull wing configuration. Less noticeable changes during this period included an increase in the size of the tail fins and a decrease in their inward tilt at their tops.
NAA continued design and development in 1940 and 1941. Both the B-25A and B-25B series entered AAF service. The B-25B was operational in 1942. Combat requirements lead to further developments. Before the year was over, NAA was producing the B-25C and B-25D series at different plants. Also in 1942, the manufacturer began design work on the cannon-armed B-25G series. The NA-100 of 1943 and 1944 was an interim armament development at the Kansas City complex known as the B-25D2. Similar armament upgrades by U.S-based commercial modification centers involved about half of the B-25G series. Further development led to the B-25H, B-25J and B-25J2. The gunship design concept dates to late 1942 and NAA sent a field technical representative to the SWPA. The factory produced B-25G entered production during the NA-96 order followed by the redesigned B-25H gunship. The B-25J reverted to the bomber role, but it, too, could be outfitted as a strafer.
North American Aviation manufactured the greatest number of aircraft in World War II. It was the first time a company had produced trainers, bombers and fighters simultaneously (the AT-6/SNJ Texan, B-25 Mitchell, and the P-51 Mustang). It produced B-25s at both its Inglewood main plant and an additional 6,608 aircraft at its Kansas City, Kansas plant at Fairfax Airport.
Postwar, the USAF placed a contract for the TB-25L trainer in 1952. This was a modification program by Hayes of Birmingham, Alabama. Its primary role was reciprocal engine pilot training.
A development of the B-25 was the North American XB-28, designed as a high-altitude bomber. Two prototypes were built with the second prototype, the XB-28A, evaluated as a photo-reconnaissance platform but the aircraft did not enter production.
Operational history.
Asia-Pacific.
The majority of B-25s in American service were used in the war against Japan in Asia and the Pacific. The Mitchell fought from the Northern Pacific to the South Pacific and the Far East. These areas included the campaigns in the Aleutian Islands, Papua New Guinea, the Solomon Islands, New Britain, China, Burma and the island hopping campaign in the Central Pacific. The aircraft’s potential as a ground-attack aircraft emerged during the Pacific war. The jungle environment reduced the usefulness of medium-level bombing, and made low-level attack the best tactic. Using similar mast height level tactics and skip bombing, the B-25 proved itself to be a capable anti-shipping weapon and sank many enemy sea vessels of various types. An ever-increasing number of forward firing guns made the B-25 a formidable strafing aircraft for island warfare. The strafer versions were the B-25C1/D1, the B-25J1 and with the NAA strafer nose, the J2 sub-series.
In Burma, the B-25 was often used to attack Japanese communication links, especially bridges in central Burma. It also helped supply the besieged troops at Imphal in 1944. The China Air Task Force, the Chinese American Composite Wing, the First Air Commando Group, the 341st Bomb Group, and eventually, the relocated 12th Bomb Group, all operated the B-25 in the China Burma India Theater (CBI). Many of these missions involved battle field isolation, interdiction and close air support.
Later in the war, as the AAF acquired bases in other parts of the Pacific, the Mitchell could strike targets in Indochina, Formosa and Kyushu, increasing the usefulness of the B-25. It was also used in some of the shortest raids of the Pacific War, striking from Saipan against Guam and Tinian. The 41st Bomb Group used it against Japanese-occupied islands that had been bypassed by the main campaign, such as happened in the Marshall Islands.
Middle East and Italy.
The first B-25s arrived in Egypt and were carrying out independent operations by October 1942. There operations against Axis airfields and motorized vehicle columns supported the ground actions of the Second Battle of El Alamein. From there, the aircraft took part in the rest of the campaign in North Africa, the invasion of Sicily and the advance up Italy. In the Strait of Messina to the Aegean Sea the B-25 conducted sea sweeps as part of the coastal air forces. In Italy, the B-25 was used in the ground attack role, concentrating on attacks against road and rail links in Italy, Austria and the Balkans. The B-25 had a longer range than the Douglas A-20 Havoc and Douglas A-26 Invaders, allowing it to reach further into occupied Europe. The five bombardment groups - 20 squadrons - of the Ninth and Twelfth Air Forces that used the B-25 in the Mediterranean Theater of Operations were the only U.S. units to employ the B-25 in Europe.
Europe.
The RAF received nearly 900 Mitchells, using them to replace Douglas Bostons, Lockheed Venturas and Vickers Wellington bombers. The Mitchell entered active RAF service on 22 January 1943. At first, it was used to bomb targets in occupied Europe. After the Normandy invasion, the RAF and France used Mitchells in support of the Allies in Europe. Several squadrons moved to forward airbases on the continent. The AAF did not use the B-25 in combat in the ETO.
USAAF.
The B-25B first gained fame as the bomber used in the 18 April 1942 Doolittle Raid, in which 16 B-25Bs led by Lieutenant Colonel Jimmy Doolittle attacked mainland Japan, four months after the bombing of Pearl Harbor. The mission gave a much-needed lift in spirits to the Americans, and alarmed the Japanese, who had believed their home islands to be inviolable by enemy forces. Although the amount of actual damage done was relatively minor, it forced the Japanese to divert troops for home defense for the remainder of the war.
The raiders took off from the carrier and successfully bombed Tokyo and four other Japanese cities without loss. Fifteen of the bombers subsequently crash-landed en route to recovery fields in eastern China. These losses were the result of the task force being spotted by a Japanese vessel, forcing the bombers to take off early, fuel exhaustion, stormy nighttime conditions with zero visibility, and lack of electronic homing aids at the recovery bases. Only one B-25 bomber landed intact, in Siberia where its five-man crew was interned and the aircraft confiscated. Of the 80 aircrew, 69 survived their historic mission and eventually made it back to American lines.
Following a number of additional modifications, including the addition of Plexiglas dome for navigational sightings to replace the overhead window for the navigator and heavier nose armament, de-icing and anti-icing equipment, the B-25C entered AAF operations. Through block 20 the B-25C and B-25D differed only in location of manufacture: C series at Inglewood, California; D series at Kansas City, Kansas. After block 20 some NA-96 began the transition to the G series while some NA-87 acquired interim modifications eventually produced as the B-25D2 and ordered as the NA-100. NAA built a total of 3,915 B-25Cs and Ds during World War II.
Although the B-25 was originally designed to bomb from medium altitudes in level flight, it was used frequently in the Southwest Pacific theatre in treetop-level strafing and missions with parachute-retarded fragmentation bombs against Japanese airfields in New Guinea and the Philippines. These heavily armed Mitchells were field-modified at Townsville, Australia, under the diirection of Major Paul I. "Pappy" Gunn and North American tech rep Jack Fox, These "commerce destroyers" were also used on strafing and skip bombing missions against Japanese shipping trying to resupply their armies.
Under the leadership of Lieutenant General George C. Kenney, Mitchells of the Far East Air Forces and its exising components, the Fifth and Thirteenth Air Forces devastated Japanese targets in the Southwest Pacific Theater during 1944 to 1945. The USAAF played a significant role in pushing the Japanese back to their home islands. The type operated with great effect in the Central Pacific, Alaska, North Africa, Mediterranean and China-Burma-India (CBI) theaters.
The AAF Antisubmarine Command made great use of the B-25 in 1942 and 1943. Some of the earliest B-25 Bomb Groups also flew the Mitchell on coastal patrols after the Pearl Harbor attack, prior to the AAFAC organization. Many of the two dozen or so Antisubmarine Squadrons flew the B-25C, D and G series in the American Theater Antisubmarine campaign, often in the distinctive, white sea search camouflage.
Combat developments.
Use as a gunship.
In anti-shipping operations, the AAF had urgent need for hard-hitting aircraft, and North American responded with the B-25G. In this series the transparent nose and bombardier/navigator position was changed for a shorter, hatched nose with two fixed .50 in (12.7 mm) machine guns and a 75 mm (2.95 in) M4 cannon, one of the largest weapons fitted to an aircraft, similar to the experimental British 57 mm gun-armed Mosquito Mk. XVIII and the German Ju 88P heavy cannon (up to a 75 mm long-barrel "Bordkanone BK 7,5"). The shorter nose placed the cannon breech behind the pilot where it could be manually loaded and serviced by the navigator; his crew station was moved to just behind the pilot. The navigator signalled the pilot when the gun was ready and the pilot fired the weapon using a button on his control wheel.
The RAF, USN and USSR each conducted trials with this series but none adopted it. The G series comprised one prototype, five pre-production C conversions, 58 C series modifications and 400 production aircraft for a total of 464 B-25G. In its final version, the G-12, an interim armament modification, eliminated the lower Bendix turret and added a starboard dual gun pack, waist guns and a canopy for the tail gunner to improve the view when firing the single tail gun. In April 1945 the air depots in Hawaii refurbished about two dozen of these and included the eight gun nose and rocket launchers in the upgrade.
The B-25H series continued the development of the gunship concept. NAA Inglewood produced 1000. The H had even more firepower. Most replaced the M4 gun with the lighter T13E1, designed specifically for the aircraft but 20-odd H-1 block aircraft completed by the Republic Aviation modification center at Evansville had the M4 and two machine gun nose armament. The 75 mm (2.95 in) gun fired at a muzzle velocity of . Due to its low rate of fire (about four rounds could be fired in a single strafing run), relative ineffectiveness against ground targets, and the substantial recoil, the 75 mm gun was sometimes removed from both G and H models and replaced with two additional .50 in (12.7 mm) machine guns as a field modification. In the new FEAF these were re-designated the G1 and H1 series respectively.
The H series normally came from the factory mounting four fixed, forward-firing .50  (12.7 mm) machine guns in the nose; four more fixed guns in forward-firing, individual gun packages; two more in the manned dorsal turret, re-located forward to a position just behind the cockpit; one each in a pair of new waist positions, introduced simultaneously with the forward-relocated dorsal turret; and lastly, a pair of guns in a new tail gunner's position. Company promotional material bragged that the B-25H could "bring to bear 10 machine guns coming and four going, in addition to the 75 mm cannon, eight rockets and 3,000 lb (1,360 kg) of bombs."
The H had a modified cockpit with single flight controls operated by pilot. The co-pilot's station and controls were deleted, and instead had a smaller seat used by the navigator/cannoneer, The radio operator crew position was aft the bomb bay with access to the waist guns. Factory production total were 405 B-25Gs and 1,000 B-25Hs, with 248 of the latter being used by the Navy as PBJ-1H. Elimination of the co-pilot saved weight, moving the dorsal turret forward counterbalanced in part the waist guns and the manned rear turret.
Return to medium bomber.
Following the two gunship series NAA again produced the medium bomber configuration with the B-25J series.. It optimized the mix of the interim NA-100 and the H series having both the bombardier's station and fixed guns of the D and the forward turret and refined armament of the H series. NAA also produced a strafer nose first shipped to air depots as kits, then introduced on the production line in alternating blocks with the bombardier nose. The solid-metal "strafer" nose housed eight centerline Browning M2 .50 calibre machine guns. The remainder of the armament was as in the H-5. NAA also supplied kits to mount eight underwing 5 "high velocity airborne rockets" (HVAR) just outside the propeller arcs. These were mounted on zero length launch rails, four to a wing.
The final, and the most built, series of the Mitchell, the B-25J, looked less like earlier series apart from the well-glazed bombardier's nose of nearly-identical appearance to the earliest B-25 subtypes. Instead, the J followed the overall configuration of the H series from the cockpit aft. It had the forward dorsal turret and other armament and airframe advancements. All J models included four .50 in (12.7 mm) light-barrel Browning AN/M2 guns in a pair of "fuselage package", conformal gun pods each flanking the lower cockpit, each pod containing two Browning M2s. By 1945, however, combat squadrons removed these. The J series restored the co-pilot's seat and dual flight controls. The factory made available kits to the Air Depot system to create the strafer-nose B-25J-2. This configuration carried a total of 18 .50 in (12.7 mm) light-barrel AN/M2 Browning M2 machine guns: eight in the nose, four in the flank-mount conformal gun pod packages, two in the dorsal turret, one each in the pair of waist positions, and a pair in the tail – with 14 of the guns either aimed directly forward, or aimed to fire directly forward for strafing missions. Some aircraft had eight 5 in (130 mm) high-velocity aircraft rockets (HVAR). NAA introduced the J-2 into production in alternating blocks at the J-22. Total J series production was 4,318.
Flight characteristics.
The B-25 was a safe and forgiving aircraft to fly. With one engine out, 60° banking turns into the dead engine were possible, and control could be easily maintained down to 145 mph (230 km/h). The pilot had to remember to maintain engine-out directional control at low speeds after takeoff with rudder; if this maneuver was attempted with ailerons, the aircraft could snap out of control. The tricycle landing gear made for excellent visibility while taxiing. The only significant complaint about the B-25 was the extremely high noise level produced by its engines; as a result, many pilots eventually suffered from varying degrees of hearing loss.
The high noise level was due to design and space restrictions in the engine cowlings which resulted in the exhaust "stacks" protruding directly from the cowling ring and partly covered by a small triangular fairing. This arrangement directed exhaust and noise directly at the pilot and crew compartments. Crew members and operators on the air show circuit frequently commented that "the B-25 is the fastest way to turn aviation fuel directly into noise".
Durability.
The Mitchell was an exceptionally sturdy aircraft that could withstand tremendous punishment. One B-25C of the 321st Bomb Group was nicknamed "Patches" because its crew chief painted all the aircraft's flak hole patches with high-visibility zinc chromate primer. By the end of the war, this aircraft had completed over 300 missions, had been belly-landed six times and had over 400 patched holes. The airframe of "Patches" was so distorted from battle damage that straight-and-level flight required 8° of left aileron trim and 6° of right rudder, causing the aircraft to "crab" sideways across the sky.
Post war (USAF) use.
In 1947 legislation created an independent United States Air Force and by that time the B-25 inventory numbered only a few hundred. Some B-25s continued in service into the 1950s in a variety of training, reconnaissance and support roles. The principal use during this period was undergraduate training of multi-engine aircraft pilots slated for reciprocating engine or turboprop cargo, aerial refuelling or reconnaissance aircraft. Others were assigned to units of the Air National Guard in training roles in support of Northrop F-89 Scorpion and Lockheed F-94 Starfire operations. 
In its USAF tenure, many B-25s received the so-called "Hayes modification" and as a result, surviving B-25 often have exhaust system with a semi-collector ring that splits emissions into two different systems. The upper seven cylinders are collected by a ring while the other cylinders remain directed to individual ports.
TB-25J-25-NC Mitchell, "44-30854", the last B-25 in the USAF inventory, assigned at March AFB, California as of March 1960, was flown to Eglin AFB, Florida, from Turner Air Force Base, Georgia, on 21 May 1960, the last flight by a USAF B-25, and presented by Brigadier General A. J. Russell, Commander of SAC's 822d Air Division at Turner AFB, to the Air Proving Ground Center Commander, Brigadier General Robert H. Warren, who in turn presented the bomber to Valparaiso, Florida Mayor Randall Roberts on behalf of the Niceville-Valparaiso Chamber of Commerce. Four of the original Tokyo Raiders were present for the ceremony, Colonel Davy Jones, Colonel Jack Simms, Lieutenant Colonel Joseph Manske, and retired Master Sergeant Edwin W. Horton. It was donated back to the Air Force Armament Museum c. 1974 and marked as Doolittle's "40-2344".
U.S. Navy and USMC.
The U.S. Navy designation for the Mitchell as the PBJ-1 and apart from increased use of radar, it was configured like its Army counterparts series. The designation standing for Patrol (P) Bomber (B) built by North American Aviation (J), first variant (-1) under the existing American naval aircraft designation system of the era. The PBJ had its origin in an inter-service agreement of mid-1942 between the Navy and the USAAF exchanging the Boeing Renton plant for the Kansas plant for B-29 production. The Boeing XPBB Sea Ranger flying boat competing for B-29 engines, was cancelled in exchange for part of the Kansas City Mitchell production. Other terms included the inter-service transfer of 50 B-25C and 152 B-25D to the Navy. The bombers carried Navy bureau numbers (BuNos), beginning with BuNo 34998. The first PBJ-1 arrived in February 1943 and nearly all reached Marine Corps squadrons, beginning with Marine Bombing Squadron 413 (VMB-413). Following the AAFAC format, the Marine Mitchells had search radar in a retractable radome replacing the ventral turret. Later D and J series had nose mounted APS-3 radar; and later still, J and H series mounted radar in the starboard wingtip. The large quantities of B-25H and J series became known as PBJ-1H and PBJ-1J respectively. These aircraft often operated along with earlier PBJ series in Marine squadrons.
The PBJs were operated almost exclusively by the Marine Corps as land-based bombers. To operate them, the U.S. Marine Corps established a number of Marine bomber squadrons (VMB), beginning with VMB-413, in March 1943 at MCAS Cherry Point, North Carolina. Eight VMB squadrons were flying PBJs by the end of 1943, forming the initial Marine medium bombardment group. Four more squadrons were in the process of formation in late 1945, but had not yet deployed by the time the war ended.
Operational use of the Marine Corps PBJ-1s began in March 1944. The Marine PBJs operated from the Philippines, Saipan, Iwo Jima and Okinawa during the last few months of the Pacific war. Their primary mission was the long range interdiction of enemy shipping trying to run the blockade which was strangling Japan. The weapon of choice during these missions was usually the five-inch HVAR rocket, eight of which could be carried. Some VMB-612 intruder PBJ-1D and J series flew without top turrets to save weight and increase range on night patrols, especially towards the end of the war when air superiority existed.
During the war the Navy tested the cannon-armed G series and conducted carrier trial with an H equipped with arresting gear. After World War II, some PBJs stationed at the Navy's rocket laboratory in Inyokern, California, the present-day Naval Air Weapons Station China Lake, tested various air-to-ground rockets and arrangements. One arrangement was a twin-barrel nose arrangement that could fire 10 spin-stabilized five-inch rockets in one salvo.
Royal Air Force.
The Royal Air Force (RAF) was an early customer for the B-25 via Lend-Lease. The first Mitchells were given the service name Mitchell I by the RAF and were delivered in August 1941, to No. 111 Operational Training Unit based in the Bahamas. These bombers were used exclusively for training and familiarization and never achieved operational status. The B-25Cs and Ds were designated Mitchell II. Altogether, 167 B-25Cs and 371 B-25Ds were delivered to the RAF. The RAF tested the cannon-armed G series but did not adopt the series nor the follow on H series.
By the end of 1942 the RAF had taken delivery of a total of 93 Mitchell marks I and II. Some served with squadrons of No. 2 Group RAF, the RAF's tactical medium bomber force. The first RAF operation with the Mitchell II took place on 22 January 1943, when six aircraft from No. 180 Squadron RAF attacked oil installations at Ghent. After the invasion of Europe (by which point 2 Group was part of Second Tactical Air Force), all four Mitchell squadrons moved to bases in France and Belgium (Melsbroek) to support Allied ground forces. The British Mitchell squadrons were joined by No. 342 (Lorraine) Squadron of the French Air Force in April 1945.
As part of its move from Bomber Command, No 305 (Polish) Squadron flew Mitchell IIs from September to December 1943 before converting to the de Havilland Mosquito. In addition to No. 2 Group, the B-25 was used by various second-line RAF units in the UK and abroad. In the Far East, No. 3 PRU, which consisted of Nos. 681 and 684 Squadrons, flew the Mitchell (primarily Mk IIs) on photographic reconnaissance sorties.
The RAF was allocated 316 B-25J which entered service as the Mitchell III. Deliveries took place between August 1944 and August 1945. However, only about 240 of these bombers actually reached Britain, with some being diverted to No. 111 OTU in the Bahamas, some crashing during delivery and some being retained in the United States.
Royal Canadian Air Force.
The Royal Canadian Air Force (RCAF) used the B-25 Mitchell for training during the war. Post-war use saw continued operations with most of 162 Mitchells received. The first B-25s had originally been diverted to Canada from RAF orders. These included one Mitchell I, 42 Mitchell IIs, and 19 Mitchell IIIs. No 13 (P) Squadron was formed unofficially at RCAF Rockcliffe in May 1944 and used Mitchell IIs on high-altitude aerial photography sorties. No. 5 OTU (Operational Training Unit) at Boundary Bay, British Columbia and Abbotsford, British Columbia, operated the B-25D Mitchell in the training role together with B-24 Liberators for Heavy Conversion as part of the BCATP. The RCAF retained the Mitchell until October 1963.
No 418 (Auxiliary) Squadron received its first Mitchell IIs in January 1947. It was followed by No 406 (auxiliary), which flew Mitchell IIs and IIIs from April 1947 to June 1958. No 418 Operated a mix of IIs and IIIs until March 1958. No 12 Squadron of Air Transport Command also flew Mitchell IIIs along with other types from September 1956 to November 1960. In 1951, the RCAF received an additional 75 B-25Js from USAF stocks to make up for attrition and to equip various second-line units.
Royal Australian Air Force.
The Australians received Mitchells by the spring of 1944. The joint Australian-Dutch No. 18 (Netherlands East Indies) Squadron RAAF had more than enough Mitchells for one squadron, so the surplus went to re-equip the RAAF's No. 2 Squadron, replacing their Beauforts.
Dutch Air Force.
During World War II, the Mitchell served in fairly large numbers with the Air Force of the Dutch government-in-exile. They participated in combat in the East Indies as well as on the European front. On 30 June 1941, the Netherlands Purchasing Commission, acting on behalf of the Dutch government-in-exile in London, signed a contract with North American Aviation for 162 B-25C aircraft. The bombers were to be delivered to the Netherlands East Indies to help deter any Japanese aggression into the region.
In February 1942, the British Overseas Airways Corporation (BOAC) agreed to ferry 20 Dutch B-25s from Florida to Australia travelling via Africa and India, and an additional ten via the South Pacific route from California. During March, five of the bombers on the Dutch order had reached Bangalore, India and 12 had reached Archerfield in Australia. It was agreed that the B-25s in Australia would be used as the nucleus of a new squadron, designated No. 18. This squadron was staffed jointly by Australian and Dutch aircrews plus a smattering of aircrews from other nations, and operated - at least initially - under Royal Australian Air Force command.
The B-25s of No. 18 Squadron were painted with the Dutch national insignia (at this time a rectangular Netherlands flag) and carried NEIAF serials. Discounting the ten "temporary" B-25s delivered to 18 Squadron in early 1942, a total of 150 Mitchells were taken on strength by the NEIAF, 19 in 1942, 16 in 1943, 87 in 1944, and 28 in 1945. They flew bombing raids against Japanese targets in the East Indies. In 1944, the more capable B-25J Mitchell replaced most of the earlier C and D models.
In June 1940, No. 320 Squadron RAF had been formed from personnel formerly serving with the Royal Dutch Naval Air Service who had escaped to England after the German occupation of the Netherlands. Equipped with various British aircraft, No. 320 Squadron flew anti-submarine patrols, convoy escort missions, and performed air-sea rescue duties. They acquired the Mitchell II in September 1943, performing operations over Europe against gun emplacements, railway yards, bridges, troops and other tactical targets. They moved to Belgium in October 1944, and transitioned to the Mitchell III in 1945. No. 320 Squadron was disbanded in August 1945. Following the war, B-25s were used in Indonesia.
Soviet Air Force.
The U.S. supplied 862 B-25s (B, D, G, and J types) to the Soviet Union under Lend-Lease during World War II via the Alaska–Siberia ALSIB ferry route.
Other damaged aircraft arrived or crashed in the Far East of Russia, and one Doolittle Raid aircraft landed there short of fuel after attacking Japan. The lone airworthy aircraft to reach the Soviet Union was lost in a hangar fire in the early 50s while undergoing routine maintenance. In general, the B-25 was operated as a ground-support and tactical daylight bomber (as similar Douglas A-20 Havocs were used). It saw action in fights from Stalingrad (with B/D models) to the German surrender during May 1945 (with G/J types).
B-25s that remained in Soviet Air Force service after the war were assigned the NATO reporting name "Bank".
China.
Well over 100 B-25Cs and Ds were supplied to the Nationalist Chinese during the Second Sino-Japanese War. In addition, a total of 131 B-25Js were supplied to China under Lend-Lease.
The four squadrons of the 1st BG (1st, 2nd, 3rd, and 4th) of the 1st Medium Bomber Group were formed during the war. They formerly operated Russian-built Tupolev SB bombers, then transferred to the B-25. The 1st BG was under the command of CACW (Chinese-American Composite Wing) while operating B-25s. Following the end of the war in the Pacific, these four bombardment squadrons were established to fight against the Communist insurgency that was rapidly spreading throughout the country. During the Chinese Civil War, Chinese Mitchells fought alongside de Havilland Mosquitos.
In December 1948, the Nationalists were forced to retreat to the island of Taiwan, taking many of their Mitchells with them. However, some B-25s were left behind and were impressed into service with the air force of the new People's Republic of China.
Brazilian Air Force.
During the war, the Força Aérea Brasileira (FAB) received a few B-25s under Lend-Lease. Brazil declared war against the Axis powers in August 1942 and participated in the war against the U-boats in the southern Atlantic. The last Brazilian B-25 was finally declared surplus in 1970.
Free French.
The Royal Air Force issued at least 21 Mitchell IIIs to No 342 Squadron, which was made up primarily of Free French aircrews. Following the liberation of France, this squadron transferred to the newly formed French Air Force ("Armée de l'Air") as GB I/20 Lorraine. The aircraft continued in operation after the war, with some being converted into fast VIP transports. They were struck off charge in June 1947.
Variants.
Trainer variants.
Most models of the B-25 were used at some point as training aircraft.
Survivors.
Today, many B-25s are kept in airworthy condition by air museums and collectors.
Accidents and incidents.
At 9:40 on Saturday, 28 July 1945, a USAAF B-25D crashed in thick fog into the north side of the Empire State Building between the 79th and 80th floors. Fourteen people died — 11 in the building and the three occupants of the aircraft, including the pilot, Colonel William F. Smith. Betty Lou Oliver, an elevator attendant, survived the impact and a subsequent uncontrolled descent in the elevator.

</doc>
<doc id="4219" url="https://en.wikipedia.org/wiki?curid=4219" title="British Open (disambiguation)">
British Open (disambiguation)

The British Open is the Open Championship men's golf tournament.
British Open may also refer to:

</doc>
<doc id="4224" url="https://en.wikipedia.org/wiki?curid=4224" title="Bobby Charlton">
Bobby Charlton

Sir Robert "Bobby" Charlton CBE (born 11 October 1937) is an English former football player, regarded as one of the greatest midfielders of all time, and an essential member of the England team who won the World Cup in 1966, the year he also won the Ballon d'Or. He played almost all of his club football at Manchester United, where he became renowned for his attacking instincts and passing abilities from midfield and his ferocious long-range shot. He was also well known for his fitness and stamina. He was cautioned only twice in his career; once against Argentina in the 1966 World Cup, and once in a league match against Chelsea. His elder brother Jack, who was also in the World Cup-winning team, is a former defender for Leeds United and international manager.
Born in Ashington, Northumberland, Charlton made his debut for the Manchester United first-team in 1956, and over the next two seasons gained a regular place in the team, during which time he survived the Munich air disaster of 1958 after being rescued by Harry Gregg. After helping United to win the Football League in 1965, he won a World Cup medal with England in 1966 and another Football League title with United the following year. In 1968, he captained the Manchester United team that won the European Cup, scoring two goals in the final to help his team be the first English side to win the competition. He has scored more goals for United (249) than any other player and held the distinction of being England's all-time top goal scorer (49) from May 1968 to September 2015, when Wayne Rooney beat his England goal scoring record. Charlton held the record for most appearances for Manchester United (758), before being surpassed by Ryan Giggs.
He was selected for four World Cups (1958, 1962, 1966, and 1970), and helped England to win the competition in 1966. At the time of his retirement from the England team in 1970, he was the nation's most capped player, having turned out 106 times at the highest level. This record has since been held by Bobby Moore and Peter Shilton.
He left Manchester United to become manager of Preston North End for the 1973–74 season. He changed to player-manager the following season. He next accepted a post as a director with Wigan Athletic, then became a member of Manchester United's board of directors in 1984 and remains one as of the 2015/16 season.
Early life.
Charlton is related to several professional footballers on his mother's side of the family: his uncles were Jack Milburn (Leeds United and Bradford City), George Milburn (Leeds United and Chesterfield), Jim Milburn (Leeds United and Bradford City) and Stan Milburn (Chesterfield, Leicester City and Rochdale), and legendary Newcastle United and England footballer Jackie Milburn, was his mother's cousin. However, Charlton credits much of the early development of his career to his grandfather Tanner and his mother Cissie. His elder brother, Jack, initially went to work applying to the Police Service before also becoming a professional footballer with Leeds United.
Club career.
On 9 February 1953, then a Bedlington Grammar School pupil, Charlton was spotted playing for East Northumberland schools by Manchester United chief scout Joe Armstrong. Charlton went on to play for England schoolboys and the 15-year-old signed with United on 1 January 1953, along with Wilf McGuinness, also aged 15. Initially his mother was reluctant to let him commit to an insecure football career, so he began an apprenticeship as an electrical engineer; however he went on to turn professional in October 1954.
Charlton became one of the famed Busby Babes, the collection of talented footballers who emerged through the system at Old Trafford in the 1940s, 1950s and 1960s as Matt Busby set about a long-term plan of rebuilding the club after the Second World War. He worked his way through the pecking order of teams, scoring regularly for the youth and reserve sides before he was handed his first team debut against Charlton Athletic in October 1956. At the same time, he was doing his National service with the Royal Army Ordnance Corps in Shrewsbury, where Busby had advised him to apply as it meant he could still play for Manchester United at the weekend. Also doing his army service in Shrewsbury at the same time was his United team-mate Duncan Edwards.
Charlton played 14 times for United in that first season, scoring twice on his debut and managing a total of 12 goals in all competitions, and including a hat-trick in a 5–1 away win over Charlton Athletic in the February. United won the league championship but were denied the 20th century's first "double" when they controversially lost the 1957 FA Cup Final to Aston Villa. Charlton, still only 19, was selected for the game, which saw United goalkeeper Ray Wood carried off with a broken cheekbone after a clash with Villa centre forward Peter McParland. Though Charlton was a candidate to go in goal to replace Wood (in the days before substitutes, and certainly before goalkeeping substitutes), it was teammate Jackie Blanchflower who ended up between the posts.
Charlton was an established player by the time the next season was fully underway, which saw United, as current League champions, become the first English team to compete in the European Cup. Previously, the Football Association had scorned the competition but United made progress, reaching the semi-finals where they lost to holders Real Madrid. Their reputation was further enhanced the next season as they reached the quarter finals to play Red Star Belgrade. In the first leg at home, United won 2–1. The return in Yugoslavia saw Charlton score twice as United stormed 3–0 ahead, although the hosts came back to earn a 3–3 draw. However, United maintained their aggregate lead to reach the last four and were in jubilant mood as they left to catch their flight home, thinking of an important League game against Wolves at the weekend.
Munich air disaster.
The aeroplane which took the United players and staff home from Zemun Airport needed to stop in Munich to refuel. This was carried out in worsening weather, and by the time the refuelling was complete and the call was made for the passengers to re-board the aircraft, the wintry showers had taken hold and snow had settled heavily on the runway and around the airport. There were two aborted take-offs which led to concern on board, and the passengers were advised by a stewardess to disembark again while a minor technical error was fixed.
The team was back in the airport terminal barely ten minutes when the call to reconvene on the plane came, and a number of passengers began to feel nervous. Charlton and teammate Dennis Viollet swapped places with Tommy Taylor and David Pegg, who had decided they would be safer at the back of the plane.
The plane clipped the fence at the end of the runway on its next take-off attempt and a wing tore through a nearby house, setting it alight. The wing and part of the tail came off and hit a tree and a wooden hut, the plane spinning along the snow until coming to a halt. It had been cut in half.
Charlton, strapped into his seat, had fallen out of the cabin and when United goalkeeper Harry Gregg (who had somehow got through a hole in the plane unscathed and begun a one-man rescue mission) found him, he thought he was dead. That said, he grabbed both Charlton and Viollet by their trouser waistbands and dragged them away from the plane in constant fear that it would explode. Gregg returned to the plane to try to help the appallingly injured Busby and Blanchflower, and when he turned around again, he was relieved to see that Charlton and Viollet, both of whom he had presumed to be dead, had got out of their detached seats and were looking into the wreckage.
Charlton suffered cuts to his head and severe shock and was in hospital for a week. Seven of his teammates had perished at the scene, including Taylor and Pegg, with whom he and Viollet had swapped seats prior to the fatal take-off attempt. Club captain Roger Byrne was also killed, along with Mark Jones, Billy Whelan, Eddie Colman and Geoff Bent. Duncan Edwards died a fortnight later from the injuries he had sustained. In total, the crash claimed 23 lives. Initially, ice on the wings was blamed, but a later inquiry declared that slush on the runway had made a safe take-off almost impossible.
Of the 44 passengers and crew (including the 17-strong Manchester United squad), 23 people (eight of them Manchester United players) died as a result of their injures in the crash. Charlton survived with minor injuries. Of the eight other players who survived, two of them were injured so badly that they never played again.
Charlton was the first injured survivor to leave hospital. Harry Gregg and Bill Foulkes were not hospitalized since they escaped uninjured. He arrived back in England on 14 February 1958, eight days after the crash. As he convalesced with family in Ashington, he spent some time kicking a ball around with local youths, and a famous photograph of him was taken. He was still only 20 years old, yet now there was an expectation that he would help with the rebuilding of the club as Busby's aides tried to piece together what remained of the season.
Resuming his career.
Charlton returned to playing in an FA cup tie against West Bromwich Albion on 1 March; the game was a draw and United won the replay 1–0. Not unexpectedly, United went out of the European Cup to Milan in the semi-finals to a 5–2 aggregate defeat and fell behind in the League. Yet somehow they reached their second consecutive FA Cup final, and the big day at Wembley coincided with Busby's return to work. However, his words could not inspire a side which was playing on a nation's goodwill and sentiment, and Nat Lofthouse scored twice to give Bolton Wanderers side a 2–0 win.
Further success with Manchester United came at last when they beat Leicester City 3–1 in the FA Cup final of 1963, with Charlton finally earning a winners' medal in his third final. Busby's post-Munich rebuilding programme continued to progress with two League championships within three seasons, with United taking the title in 1965 and 1967. A successful (though trophyless) season with Manchester United had seen him take the honours of "Football Writers' Association Footballer of the Year" and "European Footballer Of The Year" into the competition.
In 1968, Manchester United reached the European Cup final, ten seasons after Munich. Even though other clubs had taken part in the competition in the intervening decade, the team which got to this final was still the first English side to do so. On a highly emotional night at Wembley, Charlton scored twice in a 4–1 win after extra time against Benfica and, as United captain, lifted the trophy.
During the early 1970s, Manchester United were no longer competing among the top teams in England, and at several stages were battling against relegation. At times, Charlton was not on speaking terms with United's other superstars George Best and Denis Law, and Best refused to play in Charlton's testimonial match against Celtic, saying that "to do so would be hypocritical". Charlton left Manchester United at the end of the 1972–73 season, having scored 249 goals and set a club record of 758 appearances, a record which Ryan Giggs broke in the 2008 UEFA Champions League Final.
His last game was against Chelsea at Stamford Bridge on 28 April 1973, and before the game the BBC cameras for "Match of the Day" captured the Chelsea chairman handing Charlton a commemorative cigarette case. The match ended in a 1-0 defeat. His final goal came a month earlier, on 31 March, in a 2-0 win at Southampton, also in the First Division.
International career.
Charlton's emergence as the country's leading young football talent was completed when he was called up to join the England squad for a British Home Championship game against Scotland at Hampden Park on 19 April 1958, just over two months after he had survived the Munich air disaster.
Charlton was handed his debut as England romped home 4–0, with the new player gaining even more admirers after scoring a magnificent thumping volley dispatched with authority after a cross by the left winger Tom Finney. He scored both goals in his second game as England beat Portugal 2–1 in a friendly at Wembley; and overcame obvious nerves on a return to Belgrade to play his third match against Yugoslavia. England lost that game 5–0 and Charlton played poorly.
1958 World Cup.
He was selected for the squad which competed at the 1958 World Cup in Sweden, but did not kick a ball, something at which critics expressed surprise and bewilderment, even allowing for his lacklustre performance in Belgrade.
In 1959 he scored a hat-trick as England demolished the US 8–1; and his second England hat-trick came in 1961 in an 8–0 thrashing of Mexico. He also managed to score in every British Home Championship tournament he played in except 1963 in an association with the tournament which lasted from 1958 to 1970 and included 16 goals and ten tournament victories (five shared).
1962 World Cup.
He played in qualifiers for the 1962 World Cup in Chile against Luxembourg and Portugal and was named in the squad for the finals themselves. His goal in the 3–1 group win over Argentina was his 25th for England in just 38 appearances, and he was still only 24 years old, but his individual success could not be replicated by that of the team, which was eliminated in the quarter final by Brazil, who went on to win the tournament.
By now, England were coached by Alf Ramsey who had managed to gain sole control of the recruitment and team selection procedure from the committee-based call-up system which had lasted up to the previous World Cup. Ramsey had already cleared out some of the older players who had been reliant on the loyalty of the committee for their continued selection – it was well known that decorum on the pitch at club level had been just as big a factor in playing for England as ability and form. Luckily for Charlton, he had all three.
A hat-trick in the 8–1 rout of Switzerland in June 1963 took Charlton's England goal tally to 30, equalling the record jointly held by Tom Finney and Nat Lofthouse and Charlton's 31st goal against Wales in October the same year gave him the record alone.
Charlton's role was developing from traditional inside-forward to what today would be termed an attacking midfield player, with Ramsey planning to build the team for the 1966 World Cup around him. When England beat the USA 10-0 in a friendly on 27 May 1964, he scored one goal, his 33rd at senior level for England.
His goals became a little less frequent, and indeed Jimmy Greaves, playing purely as a striker, would overtake Charlton's England tally in October 1964. Nevertheless, he was still scoring and creating freely and as the tournament was about to start, he was expected to become one of its stars and galvanise his established reputation as one of the world's best footballers.
1966 World Cup.
England drew the opening game of the tournament 0–0 with Uruguay, and Charlton scored the first goal in the 2–0 win over Mexico. This was followed by an identical scoreline against France, allowing England to qualify for the quarter finals.
England defeated Argentina 1–0 – the game was the only international match in which Charlton received a caution – and faced Portugal in the semi finals. This turned out to be one of Charlton's most important games for England.
Charlton opened the scoring with a crisp side-footed finish after a run by Roger Hunt had forced the Portuguese goalkeeper out of his net; his second was a sweetly struck shot after a run and pull-back from Geoff Hurst. Charlton and Hunt were now England's joint-highest scorers in the tournament with three each, and a final against West Germany beckoned.
The final turned out to be one of Charlton's quieter days; he and a young Franz Beckenbauer effectively marked each other out of the game. England won 4–2 after extra time.
Euro 1968.
Charlton's next England game was his 75th as England beat Northern Ireland; 2 caps later and he had become England's second most-capped player, behind the veteran Billy Wright, who was approaching his 100th appearance when Charlton was starting out and ended with 105 caps.
Weeks later he scored his 45th England goal in a friendly against Sweden, breaking the record of 44 set the previous year by Jimmy Greaves. He was then in the England team which made it to the semi-finals of the 1968 European Championships where they were knocked out by Yugoslavia in Florence. During the match Charlton struck a Yugoslav post. England defeated the Soviet Union 2–0 in the third place match.
In 1969, Charlton was appointed an OBE for services to football. More milestones followed as he won his 100th England cap on 21 April 1970 against Northern Ireland, and was made captain by Ramsey for the occasion. Inevitably, he scored. This was his 48th goal for his country – his 49th and final goal would follow a month later in a 4–0 win over Colombia during a warm-up tour for the 1970 World Cup, designed to get the players adapted to altitude conditions. Charlton's inevitable selection by Ramsey for the tournament made him the first – and still, to date, only – England player to feature in four World Cup squads.
1970 World Cup.
Shortly before the World Cup Charlton was involved in the Bogotá Bracelet incident in which he and Bobby Moore were accused of stealing a bracelet from a jewellery store. Moore was later arrested and detained for four days before being granted a conditional release, while Charlton was not arrested.
England began the tournament with two victories in the group stages, plus a memorable defeat against Brazil. Charlton played in all three, though was substituted for Alan Ball in the final game of the group against Czechoslovakia. Ramsey, confident of victory and progress to the quarter final, wanted Charlton to rest.
England duly reached the last eight where they again faced West Germany. Charlton controlled the midfield and suppressed Franz Beckenbauer's runs from deep as England coasted to a 2–0 lead. Beckenbauer pulled a goal back for the Germans and Ramsey replaced the ageing and tired Charlton with Colin Bell who further tested the German keeper Maier and also provided a great cross for Geoff Hurst who uncharacteristically squandered the chance. West Germany, who had a habit of coming back from behind, eventually scored twice – a back header from Uwe Seeler made it 2–2. In extra-time, Geoff Hurst had a goal mysteriously ruled out after which Gerd Müller's goal won the match 3–2. England were out and, after a record 106 caps and 49 goals, Charlton decided to end his international career at the age of 32. On the flight home from Mexico, he asked Ramsey not to consider him again. His brother Jack, two years his senior but 71 caps his junior, did likewise.
Despite popular opinion the substitution did not change the game as Franz Beckenbauer had scored before Charlton left the field, hence Charlton had failed to cancel out the German. Charlton himself conceded that the substitution did not affect the game in a BBC documentary. His caps record lasted until 1973 when Bobby Moore overtook him, and Charlton currently lies seventh in the all-time England appearances list behind Moore, Wayne Rooney, Ashley Cole, Steven Gerrard, David Beckham and Peter Shilton, whose own England career began in the first game after Charlton's had ended. Charlton's goalscoring record was surpassed by Wayne Rooney on 8 September 2015, when Rooney scored a penalty in a 2–0 win over Switzerland in a qualifying match for UEFA Euro 2016.
Management career and directorships.
Charlton became the manager of Preston North End in 1973, signing his former United and England team-mate Nobby Stiles as player-coach. His first season ended in relegation and although he began playing again he left Preston early in the 1975–76 season after a disagreement with the board over the transfer of John Bird to Newcastle United. He was awarded the CBE that year and began a casual association with the BBC for punditry on matches which continued for many years. In early 1976, he scored once in 3 league appearances for Waterford United.
He joined Wigan Athletic as a director, and was briefly caretaker manager there in 1983. He then spent some time playing in South Africa. He also built up several businesses in areas such as travel, jewellery and hampers, and ran soccer schools in the UK, the US, Canada, Australia and China. In 1984, he was invited to become member of the board of directors at Manchester United, partly because of his football knowledge and partly because it was felt that the club needed a "name" on the board after the resignation of Sir Matt Busby. He remains a director of Manchester United as of 2014 and his continued presence was a factor in placating many fans opposed to the club's takeover by Malcolm Glazer.
Personal life and retirement.
He met his wife, Norma Ball, at an ice rink in Manchester in 1959 and they married in 1961. They have two daughters – Suzanne and Andrea. Suzanne was a weather forecaster for the BBC during the 1990s. They now have grandchildren, including Suzanne's son Robert, who is named in honour of his grandfather.
In 2007, while publicising his forthcoming autobiography, Charlton revealed that he had a long-running feud with his brother, Jack. They have rarely spoken since a falling-out between his wife Norma and his mother Cissie (who died on 25 March 1996 at the age of 83). Charlton did not see his mother after 1992 as a result of the feud.
Jack presented him with his BBC Sports Personality of the Year Lifetime Achievement Award on 14 December 2008. He said that he was 'knocked out' as he was presented the award by his brother. He received a standing ovation as he stood waiting for his prize.
Charlton helped to promote Manchester's bids for the 1996 and 2000 Olympic Games and the 2002 Commonwealth Games, England's bid for the 2006 FIFA World Cup and London's successful bid for the 2012 Summer Olympics. He received a knighthood in 1994 and was an Inaugural Inductee to the English Football Hall of Fame in 2002. On accepting his award he commented "I'm really proud to be included in the National Football Museum's Hall of Fame. It's a great honour. If you look at the names included I have to say I couldn't argue with them. They are all great players and people I would love to have played with." He is also the (honorary) president of the National Football Museum, an organisation about which he said "I can't think of a better Museum anywhere in the world." On 14 December 2008 Charlton was awarded the prestigious BBC Sports Personality of the Year Lifetime Achievement Award.
On 2 March 2009, Charlton was given the freedom of the city of Manchester, stating "I'm just so proud, it's fantastic. It's a great city. I have always been very proud of it."
Charlton is involved in a number of charitable activities including fund raising for cancer hospitals. Charlton became involved in the cause of land mine clearance after visits to Bosnia and Cambodia and supports the Mines Advisory Group as well as founding his own charity Find a Better Way which funds research into improved civilian landmine clearance.
In January 2011 Charlton was voted the 4th greatest Manchester United player of all time by the readers of Inside United and ManUtd.com, behind Ryan Giggs (who topped the poll), Eric Cantona and George Best.
He is a member of the Laureus World Sports Academy. On 6 February 2012 Sir Bobby Charlton was taken to hospital after falling ill, and subsequently had a gallstone removed. This prevented him from collecting a Lifetime Achievement award at the Laureus World Sports Awards.
On 15 February 2016 Manchester United announced the South Stand of Old Trafford would be renamed in honour of Sir Bobby Charlton. The unveiling took place at the home game against Everton on 3 April 2016.
Honours.
Club.
ref:
National.
ref:
Individual.
ref:

</doc>
<doc id="4227" url="https://en.wikipedia.org/wiki?curid=4227" title="Barry Lyndon">
Barry Lyndon

Barry Lyndon is a 1975 British-American period drama film written, produced, and directed by Stanley Kubrick, based on the 1844 novel "The Luck of Barry Lyndon" by William Makepeace Thackeray. It stars Ryan O'Neal, Marisa Berenson, Patrick Magee, and Hardy Krüger. The film recounts the exploits of a fictional 18th-century Irish adventurer. Exteriors were shot on location in Ireland, England and Germany. 
At the 1975 Academy Awards, the film won four Oscars in production categories. Although having had a modest commercial success and a mixed reception from critics on release, "Barry Lyndon" is today regarded as one of Kubrick's finest films. In numerous polls, including those of "Village Voice" (1999), "Sight & Sound" (2002), "Time" (2005) and BBC, it has been named one of the greatest films ever made.
Plot.
Act I.
An omniscient (though possibly unreliable) narrator relates that in 1750s Ireland, the father of Redmond Barry is killed in a duel over a sale of some horses. The widow, disdaining offers of marriage, devotes herself to her only son.
As a teenager, Barry becomes strongly attached to his older cousin, Nora Brady. Though she charms him during a card game, she later shows interest in a well-off British Army captain, John Quin, much to Barry's dismay. Nora and her family plan to leverage their position through marriage, while Barry holds Quin in contempt and shoots him in a duel. Barry heads through the countryside towards Dublin, but is robbed of purse pistol and sword by Captain Feeney, an infamous highwayman. Dejected, Barry enlists in the British army after hearing a promotional spiel, where he encounters Captain Grogan, a family friend. Grogan informs him that he did not in fact kill Quin—Barry's dueling pistol was loaded with tow. The duel was staged by Nora's family to be rid of Barry so that their finances would be secured through the impending marriage.
Barry’s regiment is sent to Germany to fight in the Seven Years' War, where Captain Grogan is fatally wounded by the French in a skirmish at the Battle of Minden. Barry deserts the army, stealing an officer courier's uniform, horse, and identification papers. En route to neutral Holland he encounters the Prussian Captain Potzdorf, who, seeing through his disguise, offers him the choice of being turned back over to the British where he will be shot as a deserter, or enlisting in the Prussian Army. Barry enlists in his second army and later receives a special commendation from Frederick the Great for saving Potzdorf's life in a battle.
After the war ends in 1763, Barry is employed by Captain Potzdorf's uncle in the Prussian Ministry of Police to become the servant of the Chevalier de Balibari, a professional gambler. The Prussians suspect he is a spy and send Barry as an undercover agent to verify this. Barry reveals himself to the Chevalier right away and they become confederates in cheating at cards. After he and the Chevalier cheat the Prince of Tübingen at the card table, the Prince accuses the Chevalier (without proof) and refuses to pay his debt and demands satisfaction. When Barry relays this to his Prussian handlers, they (still suspecting that the Chevalier is a spy) are wary of allowing another meeting between the Chevalier and the Prince. So, the Prussians arrange for the Chevalier to be expelled from the country. Barry conveys this plan to the Chevalier, who flees in the night. The next morning, Barry, under disguise as the Chevalier, is escorted from Prussian territory by Prussian officers.
For the next few years, Barry and the Chevalier travel the spas and parlors of Europe, profiting from their gambling with Barry forcing payment from reluctant debtors with duels. Seeing that his life is going nowhere, Barry decides to marry into wealth. At a gambling table in Spa, Belgium, he encounters the beautiful and wealthy Countess of Lyndon (Marisa Berenson). He seduces and later marries her after the death of her elderly husband, Sir Charles Lyndon (Frank Middlemass).
Act II.
In 1773, Barry takes the Countess' last name in marriage and settles in England to enjoy her wealth, still with no money of his own. Lord Bullingdon, Lady Lyndon's 10-year-old son by Sir Charles, does not approve of the marriage and quickly comes to hate Barry, calling him a "common opportunist" who does not love his mother. Barry retaliates by subjecting Bullingdon to systematic physical abuse. 
The Countess bears Barry a son, Bryan Patrick, but the marriage is unhappy: Barry is openly unfaithful and enjoys spending his wife's money in self-indulgent spending sprees while keeping his wife in seclusion.
Some years later, Barry's mother comes to live with him at the Lyndon estate. She warns her son that if Lady Lyndon were to die, all her wealth would go to her first-born son Lord Bullingdon, leaving Barry and Patrick penniless. Barry's mother advises him to obtain a noble title to protect himself. To further this goal, he cultivates the acquaintance of the influential Lord Wendover and begins to expend even larger sums of money to ingratiate himself to high society. All this effort is wasted, however, during a birthday party for Lady Lyndon. A now adult Lord Bullingdon publicly lists the reasons for his hatred of his stepfather and his intention to leave the family estate for as long as Barry remains alive. Seething with hatred, Barry savagely assaults Bullingdon until he is pulled off him by the guests. This loses Barry all the powerful friends he has worked so hard to make and he is cast out of polite society. Bullingdon leaves the estate and England itself for parts unknown.
In contrast to his mistreatment of his stepson, Barry proves an overindulgent and doting father to Bryan, with whom he spends all his time after Bullingdon's departure. He cannot refuse his son anything, and succumbs to Bryan's insistence on receiving a full-grown horse for his ninth birthday. The spoiled Bryan disobeys his parents' direct instructions that Bryan ride the horse only in the presence of his father, is thrown by the horse, and dies a few days later from his injuries.
The grief-stricken Barry turns to alcohol, while Lady Lyndon seeks solace in religion, assisted by the Reverend Samuel Runt, who had been tutor first to Lord Bullingdon and then to Bryan. Left in charge of the families' affairs while Barry and Lady Lyndon grieve, Barry's mother dismisses the Reverend, both because the family no longer needs (nor can afford, due to Barry's spending debts) a tutor and for fear that his influence worsens Lady Lyndon's condition. Plunging even deeper into grief, Lady Lyndon later attempts suicide (though she ingests only enough poison to make herself ill). The Reverend and the family's accountant and emissary Graham then seek out Lord Bullingdon. Upon hearing of these events, Lord Bullingdon returns to England where he finds Barry drunk in a gentlemen's club, mourning the loss of his son rather than being with Lady Lyndon. Bullingdon demands satisfaction for Barry's public assault, challenging him to a duel.
The duel with pistols is held in a tithe barn. A coin-toss gives Bullingdon the right of first fire, but he nervously misfires his pistol as he prepares to shoot. Barry, reluctant to shoot Bullingdon, magnanimously fires into the ground, but the unmoved Bullingdon refuses to let the duel end, claiming he has not received "satisfaction". In the second round, Bullingdon shoots Barry in his left leg. At a nearby inn, a surgeon informs Barry that the leg will need to be amputated below the knee if he is to survive.
While Barry is recovering, Bullingdon takes control of the estate. He sends a very nervous Graham to the inn with a proposition: Lord Bullingdon will grant Barry an annuity of 500 guineas per year on the condition that he leave England forever and separate from Lady Lyndon. Otherwise, with his credit and bank accounts exhausted, Barry's creditors and bill collectors will assuredly see that he is jailed. Defeated, Barry accepts. 
The narrator states that Barry went first to Ireland with his mother, then to the European continent to resume his former profession of gambler (though without his former success) and that he never saw Lady Lyndon again. The final scene (set in December 1789) shows a middle-aged Lady Lyndon signing Barry's annuity cheque as her son looks on.
Cast.
Critic Tim Robey suggests that the film "makes you realise that the most undervalued aspect of Kubrick's genius could well be his way with actors." He adds that the supporting cast is a "glittering procession of cameos, not from star names but from vital character players."
The cast featured Leon Vitali as the older Lord Bullingdon, who would then become Kubrick's personal assistant, working as the casting director on his following films, and supervising film-to-video transfers for Kubrick. Their relationship lasted until Kubrick's death. The film's cinematographer, John Alcott, appears at the men's club in the non-speaking role of the man asleep in a chair near the title character when Lord Bullingdon challenges Barry to a duel. Kubrick's daughter Vivian also appears (in an uncredited role) as a guest at Bryan's birthday party.
Kubrick stalwarts Patrick Magee (who had played the handicapped writer in "A Clockwork Orange") and Philip Stone (who had played Alex's father in "A Clockwork Orange", and would go on to play the dead caretaker Grady in "The Shining") are featured as the Chevalier du Balibari and as Graham, respectively.
Production.
Development.
After "", Kubrick made plans for a film about Napoleon Bonaparte. During pre-production, however, Sergei Bondarchuk and Dino De Laurentiis' "Waterloo" was released and subsequently failed at the box office. As a result, Kubrick's financiers pulled their funding for the film and he turned his attention to his next film, "A Clockwork Orange". Subsequently, Kubrick showed an interest in Thackeray's "Vanity Fair" but dropped the project when a serialised version for television was produced. He told an interviewer, "At one time, "Vanity Fair" interested me as a possible film but, in the end, I decided the story could not be successfully compressed into the relatively short time-span of a feature film...as soon as I read "Barry Lyndon" I became very excited about it."
Having garnered Oscar nominations for "Dr. Strangelove", "2001: A Space Odyssey" and "A Clockwork Orange", Kubrick's reputation in the early 1970s was that of "a perfectionist auteur who loomed larger over his movies than any concept or star." His studio—Warner Bros.—was therefore "eager to bankroll" his next project, which Kubrick kept "shrouded in secrecy" from the press partly due to the furor surrounding the controversially violent "A Clockwork Orange" (particularly in the UK) and partly due to his "long-standing paranoia about the tabloid press."
Having felt compelled to set aside his plans for a film about Napoleon Bonaparte, Kubrick set his sights on Thackeray's 1844 "satirical picaresque about the fortune-hunting of an Irish rogue," "Barry Lyndon", the setting of which allowed Kubrick to take advantage of the copious period research he had done for the now-aborted "Napoleon". At the time, Kubrick merely announced that his next film would star Ryan O'Neal (deemed "a seemingly un-Kubricky choice of leading man") and Marisa Berenson, a former "Vogue" and "Time" magazine cover model, and be shot largely in Ireland. So heightened was the secrecy surrounding the film that "Even Berenson, when Kubrick first approached her, was told only that it was to be an 18th-century costume piece she was instructed to keep out of the sun in the months before production, to achieve the period-specific pallor he required."
Principal photography.
Principal photography took 300 days, from spring 1973 through early 1974, with a break for Christmas.
Many of the film's exteriors were shot in Ireland, playing "itself, England, and Prussia during the Seven Years' War." Drawing inspiration from "the landscapes of Watteau and Gainsborough," Kubrick and cinematographer Alcott also relied on the "scrupulously researched art direction" of Ken Adam and Roy Walker. Alcott, Adam and Walker would be among those who would win Oscars for their "amazing work" on the film.
Several of the interior scenes were filmed in Powerscourt House, a famous 18th-century mansion in County Wicklow, Republic of Ireland. The house was destroyed in an accidental fire several months after filming (November 1974), so the film serves as a record of the lost interiors, particularly the "Saloon" which was used for more than one scene. The Wicklow Mountains are visible, for example, through the window of the Saloon during a scene set in Berlin. Other locations included Kells Priory (the English Redcoat encampment) Blenheim Palace, Castle Howard (exteriors of the Lyndon estate), Huntington Castle, Clonegal (exterior), Corsham Court (various interiors and the music room scene), Petworth House (chapel, and so on.), Stourhead (lake and temple), Longleat, and Wilton House (interior and exterior) in England, Dunrobin Castle (exterior and garden as Spa) in Scotland, Dublin Castle in Ireland (the chevalier's home), Ludwigsburg Palace near Stuttgart and Frederick the Great's Neues Palais at Potsdam near Berlin (suggesting Berlin's main street Unter den Linden as construction in Potsdam had just begun in 1763). Some exterior shots were also filmed at Waterford Castle (now a luxury hotel and golf course) and Little Island, Waterford. Moorstown Castle in Tipperary also featured. Several scenes were filmed at Castletown House outside Carrick-on-Suir, Co. Tipperary, and at Youghal, Co. Cork.
Cinematography.
The film—as with "almost every Kubrick film"—is a "showcase for major innovation in technique." While "2001: A Space Odyssey" had featured "revolutionary effects," and "The Shining" would later feature heavy use of the Steadicam, "Barry Lyndon" saw a considerable number of sequences shot "without recourse to electric light." Cinematography was overseen by director of photography John Alcott (who won an Oscar for his work), and is particularly noted for the technical innovations that made some of its most spectacular images possible. To achieve photography without electric lighting "[for the many densely furnished interior scenes... meant shooting by candlelight," which is known to be difficult in still photography, "let alone with moving images."
Kubrick was "determined not to reproduce the set-bound, artificially lit look of other costume dramas from that time." After "tinkerwith different combinations of lenses and film stock," the production got hold of three super-fast 50mm lenses (Carl Zeiss Planar 50mm f/0.7) developed by Zeiss for use by NASA in the Apollo moon landings, which Kubrick had discovered. These super-fast lenses "with their huge aperture (the film actually features the lowest f-stop in film history) and fixed focal length" were problematic to mount, and were extensively modified into three versions by Cinema Products Corp. for Kubrick so to gain a wider angle of view, with input from optics expert Richard Vetter of Todd-AO. The rear element of the lens had to be 2.5mm away from the film plane, requiring special modification to the rotating camera shutter. This allowed Kubrick and Alcott to shoot scenes lit with actual candles to an average lighting volume of only three candela, "recreating the huddle and glow of a pre-electrical age." In addition, Kubrick had the entire film push-developed by one stop.
Although Kubrick's express desire was to avoid electric lighting where possible, most shots were achieved with conventional lenses and lighting, but were lit to deliberately mimic natural light rather than for compositional reasons. In addition to potentially seeming more realistic, these methods also gave a particular period look to the film which has often been likened to 18th-century paintings (which were, of course, depicting a world devoid of electric lighting), in particular owing "a lot to William Hogarth, with whom Thackeray had always been fascinated."
According to critic Tim Robey, the film has a "stately, painterly, often determinedly static quality." For example, to help light some interior scenes, lights were placed outside and aimed through the windows, which were covered in a diffuse material to scatter the light evenly through the room rather than being placed inside for maximum use as most conventional films do. A sign of this method occurs in the scene where Barry duels Lord Bullingdon. Though it appears to be lit entirely with natural light, one can see that the light coming in through the cross-shaped windows in the tithe barn appears blue in color, while the main lighting of the scene coming in from the side is not. This is because the light through the cross-shaped windows is daylight from the sun, which when recorded on the film stock used by Kubrick showed up as blue-tinted compared to the incandescent electric light coming in from the side.
Despite such slight tinting effects, this method of lighting not only gave the look of natural daylight coming in through the windows, but it also protected the historic locations from the damage caused by mounting the lights on walls or ceilings and the heat from the lights. This helped the film "fit... perfectly with Kubrick's gilded-cage aesthetic – the film is consciously a museum piece, its characters pinned to the frame like butterflies."
Music.
The film's period setting allowed Kubrick to indulge his penchant for classical music, and the film score uses pieces by Johann Sebastian Bach (an arrangement of the Concerto for violin and oboe in C minor), Antonio Vivaldi (Cello Concerto in E-Minor, a transcription of the Cello Sonata in E Minor RV 40), Giovanni Paisiello, Wolfgang Amadeus Mozart, and Franz Schubert (German Dance No. 1 in C major, Piano Trio in E-Flat, Opus 100 and Impromptu No. 1 in C minor), as well as the Hohenfriedberger March. The piece most associated with the film, however, is the main title music: George Frideric Handel's stately "Sarabande" from the Suite in D minor HWV 437. Originally for solo harpsichord, the versions for the main and end titles are performed very romantically with orchestral strings, harpsichord, and timpani. It is used at various points in the film, in various arrangements, to indicate the implacable working of impersonal fate.
The score also includes Irish folk music, including Seán Ó Riada's song "Women of Ireland", arranged by Paddy Moloney and performed by The Chieftains.
Reception.
The film "was not the commercial success Warner Bros. had been hoping for" within the United States, although it fared better in Europe. This mixed reaction saw the film (in the words of one retrospective review) "greeted, on its release, with dutiful admiration – but not love. Critics... rail against the perceived coldness of Kubrick's style, the film's self-conscious artistry and slow pace. Audiences, on the whole, rather agreed..." This "air of disappointment" factored into Kubrick's decision to next film Stephen King's "The Shining" – a project that would not only please him artistically, but also be more likely to succeed financially. Still, several other critics, including Gene Siskel, praised the film's technical quality and strong narrative, and Siskel himself counted it as one of the five best films of the year.
In recent years, the film has gained a more positive reaction. it holds a 96% "Certified Fresh" rating on Rotten Tomatoes based on 52 reviews, eight of which are from the site's "top critics." Roger Ebert added the film to his 'Great Movies' list on 9 September 2009, writing, "It defies us to care, it asks us to remain only observers of its stately elegance", and it "must be one of the most beautiful films ever made."
Director Martin Scorsese has named "Barry Lyndon" as his favorite Kubrick film. Quotations from its script have also appeared in such disparate works as Ridley Scott's "The Duellists", Scorsese's "The Age of Innocence", and Wes Anderson's "Rushmore".
Awards.
In 1976, at the 48th Academy Awards, the film won four awards, for Best Art Direction (Ken Adam, Roy Walker, Vernon Dixon), Best Cinematography (John Alcott), Best Costume Design (Milena Canonero, Ulla-Britt Söderlund) and Best Musical Score (Leonard Rosenman, "for his arrangements of Schubert and Handel".) Kubrick was nominated three times, for Best Director, Best Picture, and Best Adapted Screenplay.
Kubrick won the British Academy of Film and Television Arts Award for Best Direction. John Alcott won for Best Cinematography. "Barry Lyndon" was also nominated for Best Film, Art Direction, and Costume Design.
Source novel.
Kubrick based his adapted screenplay on William Makepeace Thackeray's "The Luck of Barry Lyndon" (republished as the novel "Memoirs of Barry Lyndon, Esq.)," a picaresque tale written and published in serial form in 1844.
The film departs from the novel in several ways. In Thackeray's writings, events are related in the first person by Barry himself. A comic tone pervades the work, as Barry proves both a raconteur and an unreliable narrator. Kubrick's film, by contrast, presents the story objectively. Though the film contains voice-over (by actor Michael Hordern), the comments expressed are not Barry's, but those of an omniscient, although not entirely impartial, narrator. This change in perspective alters the tone of the story; Thackeray tells a jaunty, humorous tale, but Kubrick's telling is essentially tragic, albeit with a satirical tone. Kubrick felt that using a first-person narrative would not be useful in a film adaptation:
Kubrick also changed the plot. For example, the novel does not include a final duel. The film begins with a duel where Barry's father is shot dead, and duels recur throughout the film.

</doc>
<doc id="4230" url="https://en.wikipedia.org/wiki?curid=4230" title="Cell (biology)">
Cell (biology)

The cell (from Latin "cella", meaning "small room") is the basic structural, functional, and biological unit of all known living organisms. A cell is the smallest unit of life that can replicate independently, and cells are often called the "building blocks of life". The study of cells is called cell biology.
Cells consist of cytoplasm enclosed within a membrane, which contains many biomolecules such as proteins and nucleic acids. The Alberts text discusses how the "cellular building blocks" move to shape developing embryos. It is also common to describe small molecules such as amino acids as "molecular building blocks".</ref> Organisms can be classified as unicellular (consisting of a single cell; including bacteria) or multicellular (including plants and animals). While the number of cells in plants and animals varies from species to species, humans contain more than 10 trillion (1013) cells. Most plant and animal cells are visible only under the microscope, with dimensions between 1 and 100 micrometres.
The cell was discovered by Robert Hooke in 1665, who named the biological unit for its resemblance to cells inhabited by Christian monks in a monastery. Cell theory, first developed in 1839 by Matthias Jakob Schleiden and Theodor Schwann, states that all organisms are composed of one or more cells, that cells are the fundamental unit of structure and function in all living organisms, that all cells come from preexisting cells, and that all cells contain the hereditary information necessary for regulating cell functions and for transmitting information to the next generation of cells. Cells emerged on Earth at least 3.5 billion years ago.
Anatomy.
Cells are of two types, eukaryotic, which contain a nucleus, and prokaryotic, which do not. Prokaryotes are single-celled organisms, while eukaryotes can be either single-celled or multicellular.
Prokaryotic cells.
Prokaryotic cells were the first form of life on Earth, characterised by having vital biological processes including cell signaling and being self-sustaining. They are simpler and smaller than eukaryotic cells, and lack membrane-bound organelles such as the nucleus. Prokaryotes include two of the domains of life, bacteria and archaea. The DNA of a prokaryotic cell consists of a single chromosome that is in direct contact with the cytoplasm. The nuclear region in the cytoplasm is called the nucleoid. Most prokaryotes are the smallest of all organisms ranging from 0.5 to 2.0 µm in diameter.
A prokaryotic cell has three architectural regions:
Eukaryotic cells.
Plants, animals, fungi, slime moulds, protozoa, and algae are all eukaryotic. These cells are about fifteen times wider than a typical prokaryote and can be as much as a thousand times greater in volume. The main distinguishing feature of eukaryotes as compared to prokaryotes is compartmentalization: the presence of membrane-bound organelles (compartments) in which specific metabolic activities take place. Most important among these is a cell nucleus, an organelle that houses the cell's DNA. This nucleus gives the eukaryote its name, which means "true kernel (nucleus)". Other differences include:
Subcellular components.
All cells, whether prokaryotic or eukaryotic, have a membrane that envelops the cell, regulates what moves in and out (selectively permeable), and maintains the electric potential of the cell. Inside the membrane, the cytoplasm takes up most of the cell's volume. All cells (except red blood cells which lack a cell nucleus and most organelles to accommodate maximum space for hemoglobin) possess DNA, the hereditary material of genes, and RNA, containing the information necessary to build various proteins such as enzymes, the cell's primary machinery. There are also other kinds of biomolecules in cells. This article lists these primary components of the cell, then briefly describes their function.
Membrane.
The cell membrane, or plasma membrane, is a biological membrane that surrounds the cytoplasm of a cell. In animals, the plasma membrane is the outer boundary of the cell, while in plants and prokaryotes it is usually covered by a cell wall. This membrane serves to separate and protect a cell from its surrounding environment and is made mostly from a double layer of phospholipids, which are amphiphilic (partly hydrophobic and partly hydrophilic). Hence, the layer is called a phospholipid bilayer, or sometimes a fluid mosaic membrane. Embedded within this membrane is a variety of protein molecules that act as channels and pumps that move different molecules into and out of the cell. The membrane is said to be 'semi-permeable', in that it can either let a substance (molecule or ion) pass through freely, pass through to a limited extent or not pass through at all. Cell surface membranes also contain receptor proteins that allow cells to detect external signaling molecules such as hormones.
Cytoskeleton.
The cytoskeleton acts to organize and maintain the cell's shape; anchors organelles in place; helps during endocytosis, the uptake of external materials by a cell, and cytokinesis, the separation of daughter cells after cell division; and moves parts of the cell in processes of growth and mobility. The eukaryotic cytoskeleton is composed of microfilaments, intermediate filaments and microtubules. There are a great number of proteins associated with them, each controlling a cell's structure by directing, bundling, and aligning filaments. The prokaryotic cytoskeleton is less well-studied but is involved in the maintenance of cell shape, polarity and cytokinesis. The subunit protein of microfilaments is a small, monomeric protein called actin. The subunit of microtubules is a dimeric molecule called tubulin. Intermediate filaments are heteropolymers whose subunits vary among the cell types in different tissues. But some of the subunit protein of intermediate filaments include vimentin, desmin, lamin (lamins A, B and C), keratin (multiple acidic and basic keratins), neurofilament proteins (NF - L, NF - M).
Genetic material.
Two different kinds of genetic material exist: deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). Cells use DNA for their long-term information storage. The biological information contained in an organism is encoded in its DNA sequence. RNA is used for information transport (e.g., mRNA) and enzymatic functions (e.g., ribosomal RNA). Transfer RNA (tRNA) molecules are used to add amino acids during protein translation.
Prokaryotic genetic material is organized in a simple circular DNA molecule (the bacterial chromosome) in the nucleoid region of the cytoplasm. Eukaryotic genetic material is divided into different, linear molecules called chromosomes inside a discrete nucleus, usually with additional genetic material in some organelles like mitochondria and chloroplasts (see endosymbiotic theory).
A human cell has genetic material contained in the cell nucleus (the nuclear genome) and in the mitochondria (the mitochondrial genome). In humans the nuclear genome is divided into 46 linear DNA molecules called chromosomes, including 22 homologous chromosome pairs and a pair of sex chromosomes. The mitochondrial genome is a circular DNA molecule distinct from the nuclear DNA. Although the mitochondrial DNA is very small compared to nuclear chromosomes, it codes for 13 proteins involved in mitochondrial energy production and specific tRNAs.
Foreign genetic material (most commonly DNA) can also be artificially introduced into the cell by a process called transfection. This can be transient, if the DNA is not inserted into the cell's genome, or stable, if it is. Certain viruses also insert their genetic material into the genome.
Organelles.
Organelles are parts of the cell which are adapted and/or specialized for carrying out one or more vital functions, analogous to the organs of the human body (such as the heart, lung, and kidney, with each organ performing a different function). Both eukaryotic and prokaryotic cells have organelles, but prokaryotic organelles are generally simpler and are not membrane-bound.
There are several types of organelles in a cell. Some (such as the nucleus and golgi apparatus) are typically solitary, while others (such as mitochondria, chloroplasts, peroxisomes and lysosomes) can be numerous (hundreds to thousands). The cytosol is the gelatinous fluid that fills the cell and surrounds the organelles.
Structures outside the cell membrane.
Many cells also have structures which exist wholly or partially outside the cell membrane. These structures are notable because they are not protected from the external environment by the semipermeable cell membrane. In order to assemble these structures, their components must be carried across the cell membrane by export processes.
Cell wall.
Many types of prokaryotic and eukaryotic cells have a cell wall. The cell wall acts to protect the cell mechanically and chemically from its environment, and is an additional layer of protection to the cell membrane. Different types of cell have cell walls made up of different materials; plant cell walls are primarily made up of cellulose, fungi cell walls are made up of chitin and bacteria cell walls are made up of peptidoglycan.
Prokaryotic.
Capsule.
A gelatinous capsule is present in some bacteria outside the cell membrane and cell wall. The capsule may be polysaccharide as in pneumococci, meningococci or polypeptide as "Bacillus anthracis" or hyaluronic acid as in streptococci.
Capsules are not marked by normal staining protocols and can be detected by India ink or methyl blue; which allows for higher contrast between the cells for observation.
Flagella.
Flagella are organelles for cellular mobility. The bacterial flagellum stretches from cytoplasm through the cell membrane(s) and extrudes through the cell wall. They are long and thick thread-like appendages, protein in nature. A different type of flagellum is found in archaea and a different type is found in eukaryotes.
Fimbria.
A fimbria also known as a pilus is a short, thin, hair-like filament found on the surface of bacteria. Fimbriae, or pili are formed of a protein called pilin (antigenic) and are responsible for attachment of bacteria to specific receptors of human cell (cell adhesion). There are special types of specific pili involved in bacterial conjugation.
Cellular processes.
Growth and metabolism.
Between successive cell divisions, cells grow through the functioning of cellular metabolism. Cell metabolism is the process by which individual cells process nutrient molecules. Metabolism has two distinct divisions: catabolism, in which the cell breaks down complex molecules to produce energy and reducing power, and anabolism, in which the cell uses energy and reducing power to construct complex molecules and perform other biological functions.
Complex sugars consumed by the organism can be broken down into simpler sugar molecules called monosaccharides such as glucose. Once inside the cell, glucose is broken down to make adenosine triphosphate (ATP), a molecule that possesses readily available energy, through two different pathways.
Replication.
Cell division involves a single cell (called a "mother cell") dividing into two daughter cells. This leads to growth in multicellular organisms (the growth of tissue) and to procreation (vegetative reproduction) in unicellular organisms. Prokaryotic cells divide by binary fission, while eukaryotic cells usually undergo a process of nuclear division, called mitosis, followed by division of the cell, called cytokinesis. A diploid cell may also undergo meiosis to produce haploid cells, usually four. Haploid cells serve as gametes in multicellular organisms, fusing to form new diploid cells.
DNA replication, or the process of duplicating a cell's genome, always happens when a cell divides through mitosis or binary fission. This occurs during the S phase of the cell cycle.
In meiosis, the DNA is replicated only once, while the cell divides twice. DNA replication only occurs before meiosis I. DNA replication does not occur when the cells divide the second time, in meiosis II. Replication, like all cellular activities, requires specialized proteins for carrying out the job.
Protein synthesis.
Cells are capable of synthesizing new proteins, which are essential for the modulation and maintenance of cellular activities. This process involves the formation of new protein molecules from amino acid building blocks based on information encoded in DNA/RNA. Protein synthesis generally consists of two major steps: transcription and translation.
Transcription is the process where genetic information in DNA is used to produce a complementary RNA strand. This RNA strand is then processed to give messenger RNA (mRNA), which is free to migrate through the cell. mRNA molecules bind to protein-RNA complexes called ribosomes located in the cytosol, where they are translated into polypeptide sequences. The ribosome mediates the formation of a polypeptide sequence based on the mRNA sequence. The mRNA sequence directly relates to the polypeptide sequence by binding to transfer RNA (tRNA) adapter molecules in binding pockets within the ribosome. The new polypeptide then folds into a functional three-dimensional protein molecule.
Movement or motility.
Unicellular organisms can move in order to find food or escape predators. Common mechanisms of motion include flagella and cilia.
In multicellular organisms, cells can move during processes such as wound healing, the immune response and cancer metastasis. For example, in wound healing in animals, white blood cells move to the wound site to kill the microorganisms that cause infection. Cell motility involves many receptors, crosslinking, bundling, binding, adhesion, motor and other proteins. The process is divided into three steps – protrusion of the leading edge of the cell, adhesion of the leading edge and de-adhesion at the cell body and rear, and cytoskeletal contraction to pull the cell forward. Each step is driven by physical forces generated by unique segments of the cytoskeleton.
Multicellularity.
Cell specialization.
Multicellular organisms are organisms that consist of more than one cell, in contrast to single-celled organisms.
In complex multicellular organisms, cells specialize into different cell types that are adapted to particular functions. In mammals, major cell types include skin cells, muscle cells, neurons, blood cells, fibroblasts, stem cells, and others. Cell types differ both in appearance and function, yet are genetically identical. Cells are able to be of the same genotype but of different cell type due to the differential expression of the genes they contain.
Most distinct cell types arise from a single totipotent cell, called a zygote, that differentiates into hundreds of different cell types during the course of development. Differentiation of cells is driven by different environmental cues (such as cell–cell interaction) and intrinsic differences (such as those caused by the uneven distribution of molecules during division).
Origin of multicellularity.
Multicellularity has evolved independently at least 25 times, including in some prokaryotes, like cyanobacteria, myxobacteria, actinomycetes, "Magnetoglobus multicellularis" or "Methanosarcina". However, complex multicellular organisms evolved only in six eukaryotic groups: animals, fungi, brown algae, red algae, green algae, and plants. It evolved repeatedly for plants (Chloroplastida), once or twice for animals, once for brown algae, and perhaps several times for fungi, slime molds, and red algae. Multicellularity may have evolved from colonies of interdependent organisms, from cellularization, or from organisms in symbiotic relationships.
The first evidence of multicellularity is from cyanobacteria-like organisms that lived between 3 and 3.5 billion years ago. Other early fossils of multicellular organisms include the contested Grypania spiralis and the fossils of the black shales of the Palaeoproterozoic Francevillian Group Fossil B Formation in Gabon.
The evolution of multicellularity from unicellular ancestors has been replicated in the laboratory, in evolution experiments using predation as the selective pressure.
Origins.
The origin of cells has to do with the origin of life, which began the history of life on Earth.
Origin of the first cell.
There are several theories about the origin of small molecules that led to life on the early Earth. They may have been carried to Earth on meteorites (see Murchison meteorite), created at deep-sea vents, or synthesized by lightning in a reducing atmosphere (see Miller–Urey experiment). There is little experimental data defining what the first self-replicating forms were. RNA is thought to be the earliest self-replicating molecule, as it is capable of both storing genetic information and catalyzing chemical reactions (see RNA world hypothesis), but some other entity with the potential to self-replicate could have preceded RNA, such as clay or peptide nucleic acid.
Cells emerged at least 3.5 billion years ago. The current belief is that these cells were heterotrophs. The early cell membranes were probably more simple and permeable than modern ones, with only a single fatty acid chain per lipid. Lipids are known to spontaneously form bilayered vesicles in water, and could have preceded RNA, but the first cell membranes could also have been produced by catalytic RNA, or even have required structural proteins before they could form.
Origin of eukaryotic cells.
The eukaryotic cell seems to have evolved from a symbiotic community of prokaryotic cells. DNA-bearing organelles like the mitochondria and the chloroplasts are descended from ancient symbiotic oxygen-breathing proteobacteria and cyanobacteria, respectively, which were endosymbiosed by an ancestral archaean prokaryote.
There is still considerable debate about whether organelles like the hydrogenosome predated the origin of mitochondria, or vice versa: see the hydrogen hypothesis for the origin of eukaryotic cells.

</doc>
<doc id="4231" url="https://en.wikipedia.org/wiki?curid=4231" title="Buffy the Vampire Slayer (film)">
Buffy the Vampire Slayer (film)

Buffy the Vampire Slayer is a 1992 American comedy horror film about a Valley girl cheerleader named Buffy who learns that it is her fate to hunt vampires. The film starred Kristy Swanson, Donald Sutherland, Paul Reubens, Rutger Hauer, Luke Perry and Hilary Swank. It was a moderate success at the box office, but received mixed reception from critics. The film was taken in a different direction from the one its writer Joss Whedon intended, and five years later he created the darker and acclaimed TV series of the same name.
Plot.
High school senior Buffy Summers (Kristy Swanson) is introduced as a stereotypical, shallow cheerleader at Hemery High School in Los Angeles. She is a carefree popular mean girl whose main concerns are shopping and spending time with her rich, snooty friends and her boyfriend, Jeffrey. While at school one day, she is approached by a man who calls himself Merrick (Donald Sutherland). He informs her that she is The Slayer, or Chosen One, destined to kill vampires, and he is a Watcher whose duty it is to guide and train her. She initially rebukes his claims, but is convinced that he is right when he is able to describe a recurring dream of hers in detail. In addition, Buffy is exhibiting uncanny abilities not known to her, including heightened agility, senses, and endurance, yet she repeatedly tries Merrick's patience with her frivolous nature and sharp-tongued remarks.
Meanwhile Oliver Pike (Luke Perry), and best friend Benny (David Arquette), who resented Buffy and her friends due to differing social circles, are out drinking when they are attacked by vampires. Benny is turned but Oliver is saved by Merrick. As a vampire, Benny visits Oliver and tries to get him to join him. Later, when Oliver and his boss are discussing Benny, Oliver tells him to run if he sees him. Not only this, but a studious girl from Buffy's class, Cassandra, is abducted one night by Amilyn (Paul Reubens), acolyte of a local vampire king Lothos (Rutger Hauer), to whom she is sacrificed. When her body is found, the news spreads through LA and Hemery High, but her murder is met with indifference from Buffy's clique.
When Oliver encounters Amilyn and his tribe of vampires, he attempts to run them over with his vehicle, which causes Amilyn to lose his arm, but he is still unable to escape from them, and Buffy and Merrick arrive to rescue him. Amilyn flees the fight to talk to Lothos who now realizes Buffy is the slayer. After this encounter, Buffy and Oliver start a friendship, which eventually becomes romantic and Oliver becomes Buffy's partner in fighting the undead.
During a basketball game, Buffy finds out that one of the players is a vampire. After a quick chase to a parade float storage yard, Buffy finally confronts Lothos, shortly after she and Oliver take down his gang. Lothos puts Buffy in a hypnotic trance, which is broken due to Merrick's intervention. Lothos turns on Merrick and impales him with the stake he attempted to use on him. Lothos leaves, saying that Buffy is not ready. As Merrick dies, he tells Buffy to do things her own way rather than live by the rules of others. Because of her new life, responsibilities, and heartbreak, Buffy becomes emotionally shocked and starts dropping her Slayer duties. When she arrives at school, she attempts to explain everything to her friends, but they refuse to understand her as they are more concerned with their upcoming school dance, and Buffy falls out with them as she realizes she is outgrowing their immature, selfish behavior.
At the senior dance, Buffy tries to patch things up with her friends but they turn against her, and she is dismayed to find Jeffrey has dumped her for one of her friends. However, she meets up with Oliver and as they start to dance and eventually kiss, Lothos leads the remainder of his minions to the school and attacks the students and the attending faculty. Buffy confronts the vampires outside while Oliver fights the vampiric Benny. After overpowering the vampires, she confronts Lothos inside the school and stabs Amilyn. Lothos hypnotises Buffy again but she uses a cross and hairspray to create a makeshift flame-thrower and burns Lothos before escaping back into the gym. Buffy sees everybody recover from the attack, but Lothos emerges again getting into a fight with Buffy, who then stakes him.
As all of the survivors leave, Buffy and Oliver decide to finish their dance. The film then ends with the two of them leaving the dance on a motorcycle, and a news crew interviewing the students and the principal about the attack during the credits.
Continuity with the television show.
Many of the details given in the film differ from the continuity of the later television series. For example, Buffy's age and history is dissimilar; she is a senior in high school in the film, but the series starts with her as a sophomore. In the film, her parents are wealthy but negligent socialites who care little for her and spend their time at parties and golf tournaments; in the TV show, Buffy has a caring, single mother named Joyce. Both the vampires' and Slayer's abilities are depicted differently. The vampires in the film die like humans, while in the TV show they turn to dust, and unlike the TV show their faces remain human, albeit pale and fanged, whereas in the series they are able to take on a demonic aspect. Joss Whedon has expressed his disapproval with the movie's interpretation of the script, stating "I finally sat down and had written it and somebody had made it into a movie, and I felt like — well, that's not quite her. It's a start, but it's not quite the girl. On the movie, Merrick never mentioned he was a watcher, here he was just a mysterious guy who was more of a guide or never helped her and was very strict with her. The TV series, they mentioned a watcher when Rupert Giles mentions it to Buffy in Welcome to Hellmouth and what they do."
According to the "Official Buffy Watcher's Guide", Whedon wrote the pilot to the TV series as a sequel to his original script, which is why the show makes references to events that did not occur in the film. In 1999, Dark Horse Comics released a graphic novel adaptation of Whedon's original script under the title "The Origin". Whedon stated: "The "Origin" comic, though I have issues with it, CAN pretty much be accepted as canonical. They did a cool job of combining the movie script with the series, that was nice, and using the series Merrick and not a certain OTHER thespian who shall remain hated."
Box office.
The film debuted at #5 at the North American box office and eventually grossed a modest $16,624,456 against a $7 million production budget.
Home releases.
The film was released on VHS and Laserdisc in the U.S. in 1992 by Fox Video and re-released in 1995 under the "Twentieth Century Fox Selections" banner. It was released on DVD in the US in 2001 and on Blu-ray in 2011.
Soundtrack.
The soundtrack does not include every song played in the film, which also included "In the Wind" by War Babies and "Inner Mind" by Eon.
Possible remake.
On May 25, 2009, "The Hollywood Reporter" reported that Roy Lee and Doug Davison of Vertigo Entertainment were working with Fran Rubel Kuzui and Kaz Kuzui on a re-envisioning or relaunch of the "Buffy" film for the big screen. The film would not be a sequel or prequel to the existing film or television franchise and Joss Whedon would have no involvement in the project. None of the characters, cast, or crew from the television series would be featured. Television series executive producer Marti Noxon later reflected that this story might have been produced by the studio in order to frighten Whedon into taking the reins of the project. On November 22, 2010, "The Hollywood Reporter" confirmed that Warner Bros. had picked up the movie rights to the remake. The film was set for release sometime in 2012. 20th Century Fox, which usually holds rights to the more successful "Buffy"/"Angel" television franchise, will retain merchandising and some distribution rights.
The idea of the remake caused wrath among fans of the TV series, since Whedon is not involved and the project does not have any connection with the show and will not conform to the continuity maintained with the "Buffy the Vampire Slayer Season Eight" and "Season Nine" comic book titles. Not only the fandom, but the main cast members of both "Buffy" and "Angel" series, expressed disagreement with the report on Twitter and in recent interviews. Sarah Michelle Gellar said, "I think it's a horrible idea. To try to do a "Buffy" without Joss Whedon... to be incredibly non-eloquent: that's the dumbest idea I've ever heard." Proposed shooting locations included Black Wood and other areas in rural England, due to budgetary constraints and the potential setting as being outside of the city, an unusual change for the franchise.
In December 2011, more than a year after the official reboot announcement, the "Los Angeles Times" site reported that Whit Anderson, the writer picked for the new "Buffy" movie, had her script rejected by the producers behind the project, and that a new writer was being sought. Sources also stated that "If you're going to bring it back, you have to do it right. came in with some great ideas and she had reinvented some of the lore and it was pretty cool but in the end there just wasn't enough on the page."
As of May 2015, there have been no further developments of the reboot.

</doc>
<doc id="4232" url="https://en.wikipedia.org/wiki?curid=4232" title="Barter">
Barter

Barter is a system of exchange where goods or services are directly exchanged for other goods or services without using a medium of exchange, such as money. It is distinguishable from gift economies in many ways; one of them is that the reciprocal exchange is immediate and not delayed in time. It is usually bilateral, but may be multilateral (i.e., mediated through barter organizations) and, in most developed countries, usually only exists parallel to monetary systems to a very limited extent. Barter, as a replacement for money as the method of exchange, is used in times of monetary crisis, such as when the currency may be either unstable (e.g., hyperinflation or deflationary spiral) or simply unavailable for conducting commerce.
Economists since Adam Smith, looking at non-specific archaic societies as examples, have used the inefficiency of barter to explain the emergence of money, the economy, and hence the discipline of economics itself. However, ethnographic studies have shown no present or past society has used barter without any other medium of exchange or measurement, nor have anthropologists found evidence that money emerged from barter, instead finding that gift-giving (credit extended on a personal basis with an inter-personal balance maintained over the long term) was the most usual means of exchange of gifts and services.
Since the 1830s, barter in some western market economies has been aided by exchanges that use alternative currencies based on the labour theory of value, and are designed to prevent profit taking by intermediators. Examples include the Owenite socialists, the Cincinnati Time store, and more recently Ithaca HOURS (Time banking) and the LETS system.
Economic theory.
Adam Smith on the origin of money.
Adam Smith, the father of modern economics, sought to demonstrate that markets (and economies) pre-existed the state, and hence should be free of government regulation. He argued (against conventional wisdom) that money was not the creation of governments. Markets emerged, in his view, out of the division of labour, by which individuals began to specialize in specific crafts and hence had to depend on others for subsistence goods. These goods were first exchanged by barter. Specialization depended on trade, but was hindered by the "double coincidence of wants" which barter requires, i.e., for the exchange to occur, each participant must want what the other has. To complete this hypothetical history, craftsmen would stockpile one particular good, be it salt or metal, that they thought no one would refuse. This is the origin of money according to Smith. Money, as a universally desired medium of exchange, allows each half of the transaction to be separated.
Barter is characterized in Adam Smith's ""The Wealth of Nations"" by a disparaging vocabulary: "higgling, haggling, swapping, dickering." It has also been characterized as negative reciprocity, or "selfish profiteering."
Anthropologists have argued, in contrast, "that when something resembling barter "does" occur in stateless societies it is almost always between strangers." Barter occurred between strangers, not fellow villagers, and hence cannot be used to naturalistically explain the origin of money without the state. Since most people engaged in trade knew each other, exchange was fostered through the extension of credit. Marcel Mauss, author of 'The Gift', argued that the first economic contracts were to "not" act in one's economic self-interest, and that before money, exchange was fostered through the processes of reciprocity and redistribution, not barter. Everyday exchange relations in such societies are characterized by generalized reciprocity, or a non-calculative familial "communism" where each takes according to their needs, and gives as they have.
Limitations.
The limitations of barter are often explained in terms of its inefficiencies in facilitating exchange in comparison to money.
It is said that barter is 'inefficient' because:
History.
Silent trade.
Other anthropologists have questioned whether barter is typically between "total" strangers, a form of barter known as "silent trade". Silent trade, also called silent barter, dumb barter ("dumb" here used in its old meaning of "mute"), or depot trade, is a method by which traders who cannot speak each other's language can trade without talking. However, Benjamin Orlove has shown that while barter occurs through "silent trade" (between strangers), it also occurs in commercial markets as well. "Because barter is a difficult way of conducting trade, it will occur only where there are strong institutional constraints on the use of money or where the barter symbolically denotes a special social relationship and is used in well-defined conditions. To sum up, multipurpose money in markets is like lubrication for machines - necessary for the most efficient function, but not necessary for the existence of the market itself."
In his analysis of barter between coastal and inland villages in the Trobriand Islands, Keith Hart highlighted the difference between highly ceremonial gift exchange between community leaders, and the barter that occurs between individual households. The haggling that takes place between strangers is possible because of the larger temporary political order established by the gift exchanges of leaders. From this he concludes that barter is "an atomized interaction predicated upon the presence of society" (i.e. that social order established by gift exchange), and not typical between complete strangers.
Times of monetary crisis.
As Orlove noted, barter may occur in commercial economies, usually during periods of monetary crisis. During such a crisis, currency may be in short supply, or highly devalued through hyperinflation. In such cases, money ceases to be the universal medium of exchange or standard of value. Money may be in such short supply that it becomes an item of barter itself rather than the means of exchange. Barter may also occur when people cannot afford to keep money (as when hyperinflation quickly devalues it).
Exchanges.
Economic historian Karl Polanyi has argued that where barter is widespread, and cash supplies limited, barter is aided by the use of credit, brokerage, and money as a unit of account (i.e. used to price items). All of these strategies are found in ancient economies including Ptolemaic Egypt. They are also the basis for more recent barter exchange systems.
While one-to-one bartering is practiced between individuals and businesses on an informal basis, organized barter exchanges have developed to conduct third party bartering which helps overcome some of the limitations of barter. A barter exchange operates as a broker and bank in which each participating member has an account that is debited when purchases are made, and credited when sales are made.
Modern barter and trade has evolved considerably to become an effective method of increasing sales, conserving cash, moving inventory, and making use of excess production capacity for businesses around the world. Businesses in a barter earn trade credits (instead of cash) that are deposited into their account. They then have the ability to purchase goods and services from other members utilizing their trade credits – they are not obligated to purchase from those whom they sold to, and vice versa. The exchange plays an important role because they provide the record-keeping, brokering expertise and monthly statements to each member. Commercial exchanges make money by charging a commission on each transaction either all on the buy side, all on the sell side, or a combination of both. Transaction fees typically run between 8 and 15%.
Utopian socialism.
The Owenite socialists in Britain and the United States in the 1830s were the first to attempt to organize barter exchanges. Owenism developed a "theory of equitable exchange" as a critique of the exploitative wage relationship between capitalist and labourer, by which all profit accrued to the capitalist. To counteract the uneven playing field between employers and employed, they proposed "schemes of labour notes based on labour time, thus institutionalizing Owen's demand that human labour, not money, be made the standard of value." This alternate currency eliminated price variability between markets, as well as the role of merchants who bought low and sold high. The system arose in a period where paper currency was an innovation. Paper currency was an I.O.U. circulated by a bank (a promise to pay, not a payment in itself). Both merchants and an unstable paper currency created difficulties for direct producers.
An alternate currency, denominated in labour time, would prevent profit taking by middlemen; all goods exchanged would be priced only in terms of the amount of labour that went into them as expressed in the maxim 'Cost the limit of price'. It became the basis of exchanges in London, and in America, where the idea was implemented at the New Harmony communal settlement by Josiah Warren in 1826, and in his Cincinnati 'Time store' in 1827. Warren ideas were adopted by other Owenites and currency reformers, even though the labour exchanges were relatively short lived.
In England, about 30 to 40 cooperative societies sent their surplus goods to an "exchange bazaar" for direct barter in London, which later adopted a similar labour note. The British Association for Promoting Cooperative Knowledge established an "equitable labour exchange" in 1830. This was expanded as the National Equitable Labour Exchange in 1832 on Grays Inn Road in London. These efforts became the basis of the British cooperative movement of the 1840s. In 1848, the socialist and first self-designated anarchist Pierre-Joseph Proudhon postulated a system of "time chits". In 1875, Karl Marx wrote of "Labor Certificates" ("Arbeitszertifikaten") in his Critique of the Gotha Program of a "certificate from society that labourer has furnished such and such an amount of labour", which can be used to draw "from the social stock of means of consumption as much as costs the same amount of labour."
Twentieth century experiments.
The first exchange system was the Swiss WIR Bank. It was founded in 1934 as a result of currency shortages after the stock market crash of 1929. "WIR" is both an abbreviation of Wirtschaftsring and the word for "we" in German, reminding participants that the economic circle is also a community.
In Spain (particularly the Catalonia region) there is a growing number of exchange markets. These barter markets or swap meets work without money. Participants bring things they do not need and exchange them for the unwanted goods of another participant. Swapping among three parties often helps satisfy tastes when trying to get around the rule that money is not allowed.
Michael Linton originated the term "local exchange trading system" (LETS) in 1983 and for a time ran the Comox Valley LETSystems in Courtenay, British Columbia. LETS networks use interest-free local credit so direct swaps do not need to be made. For instance, a member may earn credit by doing childcare for one person and spend it later on carpentry with another person in the same network. In LETS, unlike other local currencies, no scrip is issued, but rather transactions are recorded in a central location open to all members. As credit is issued by the network members, for the benefit of the members themselves, LETS are considered mutual credit systems.
Modern developments.
According to the International Reciprocal Trade Association, the industry trade body, more than 450,000 businesses transacted $10 billion globally in 2008 – and officials expect trade volume to grow by 15% in 2009.
It is estimated that over 450,000 businesses in the United States were involved in barter exchange activities in 2010. There are approximately 400 commercial and corporate barter companies serving all parts of the world. There are many opportunities for entrepreneurs to start a barter exchange. Several major cities in the U.S. and Canada do not currently have a local barter exchange. There are two industry groups in the United States, the National Association of Trade Exchanges (NATE) and the International Reciprocal Trade Association (IRTA). Both offer training and promote high ethical standards among their members. Moreover, each has created its own currency through which its member barter companies can trade. NATE's currency is the known as the BANC and IRTA's currency is called Universal Currency (UC).
In Canada, the largest barter exchange is Tradebank, founded in 1987.
In the United States, the largest barter exchange and corporate trade group is International Monetary Systems, founded in 1985, now with representation in various countries.
In Australia and New Zealand the largest barter exchange is Bartercard, founded in 1991, with offices in the United Kingdom,United States, Cyprus,UAE and Thailand.
Corporate barter focuses on larger transactions, which is different from a traditional, retail oriented barter exchange. Corporate barter exchanges typically use media and advertising as leverage for their larger transactions. It entails the use of a currency unit called a "trade-credit". The trade-credit must not only be known and guaranteed, but also be valued in an amount the media and advertising could have been purchased for had the "client" bought it themselves (contract to eliminate ambiguity and risk).
Soviet bilateral trade is occasionally called "barter trade", because although the purchases were denominated in U.S. dollars, the transactions were credited to an international clearing account, avoiding the use of hard cash.
Tax implications.
In the United States, Karl Hess used bartering to make it harder for the IRS to seize his wages and as a form of tax resistance. Hess explained how he turned to barter in an op-ed for "The New York Times" in 1975. However the IRS now requires barter exchanges to be reported as per the Tax Equity and Fiscal Responsibility Act of 1982. Barter exchanges are considered taxable revenue by the IRS and must be reported on a 1099-B form. According to the IRS, "The fair market value of goods and services exchanged must be included in the income of both parties."
Other countries, though, do not have the reporting requirement that the U.S. does concerning proceeds from barter transactions, but taxation is handled the same way as a cash transaction. If one barters for a profit, one pays the appropriate tax; if one generates a loss in the transaction, they have a loss. Bartering for business is also taxed accordingly as business income or business expense. Many barter exchanges require that one register as a business.

</doc>
<doc id="4233" url="https://en.wikipedia.org/wiki?curid=4233" title="Berthe Morisot">
Berthe Morisot

Berthe Marie Pauline Morisot (; January 14, 1841 – March 2, 1895) was a painter and a member of the circle of painters in Paris who became known as the Impressionists. She was described by Gustave Geffroy in 1894 as one of "les trois grandes dames" of Impressionism alongside Marie Bracquemond and Mary Cassatt.
In 1864, she exhibited for the first time in the highly esteemed Salon de Paris. Sponsored by the government, and judged by Academicians, the Salon was the official, annual exhibition of the Académie des beaux-arts in Paris. Her work was selected for exhibition in six subsequent Salons until, in 1874, she joined the ""rejected"" Impressionists in the first of their own exhibitions, which included Paul Cézanne, Edgar Degas, Claude Monet, Camille Pissarro, Pierre-Auguste Renoir, and Alfred Sisley. It was held at the studio of the photographer Nadar.
She was married to Eugène Manet, the brother of her friend and colleague Édouard Manet.
Early life and education.
Morisot was born in Bourges, France, into an affluent bourgeois family. Her father, Edmé Tiburce Morisot, was the prefect (senior administrator) of the department of Cher. Her mother, Marie-Joséphine-Cornélie Thomas, was the great-niece of Jean-Honoré Fragonard, one of the most prolific Rococo painters of the ancien régime. She had two older sisters, Yves (1838–1893) and Edma (1839–1921), plus a younger brother, Tiburce, born in 1848. The family moved to Paris in 1852, when Morisot was a child.
It was common practice for daughters of bourgeois families to receive art education, so Berthe and her sisters Yves and Edma were taught privately by Geoffroy-Alphonse Chocarne and Joseph Guichard. In 1857 Guichard introduced Berthe and Edma to the Louvre gallery where they could learn by looking, and from 1858 they learned by copying paintings. He also introduced them to the works of Gavarni.
As art students, Berthe and Edma worked closely together until Edma married Adolphe Pontillon, a naval officer, moved to Cherbourg, had children, and had less time to paint. Letters between the sisters show a loving relationship, underscored by Berthe's regret at the distance between them and Edma's withdrawal from painting. Edma wholeheartedly supported Berthe's continued work and their families always remained close. Edma wrote "“… I am often with you in thought, dear Berthe. I’m in your studio and I like to slip away, if only for a quarter of an hour, to breathe that atmosphere that we shared for many years…”".
Her sister Yves married Theodore Gobillard, a tax inspector, in 1866, and was painted by Edgar Degas as "Mrs Theodore Gobillard" (Metropolitan Museum of Art, New York).
Morisot registered as a copyist at the Louvre where she befriended other artists and teachers including Camille Corot, the pivotal landscape painter of the Barbizon School who also excelled in figure painting. In 1860, under Corot's influence she took up the plein air (outdoors) method of working. By 1863 she was studying under Achille Oudinot, another Barbizon painter. In the winter of 1863–64 she studied sculpture under Aimé Millet, but none of her sculpture is known to survive.
Impressionism.
Morisot's first appearance in the Salon de Paris came at the age of twenty-three in 1864, with the acceptance of two landscape paintings. She continued to show regularly in the Salon, to generally favorable reviews, until 1873, the year before the first Impressionist exhibition. She exhibited with the Impressionists from 1874 onwards, only missing the exhibition in 1878 when her daughter was born.
Morisot's mature career began in 1872. She found an audience for her work with Durand-Ruel, the private dealer, who bought twenty-two paintings. In 1877, she was described by the critic for "Le Temps" as the "one real Impressionist in this group." She chose to exhibit under her full maiden name instead of using a pseudonym or her married name. In the 1880 exhibition, many reviews judged Morisot among the best, including "Le Figaro" critic Albert Wolff.
Manet.
In 1868 Morisot became friends with Édouard Manet who painted several portraits of her, including a striking study in a black veil while in mourning for her father. Correspondence between them shows warm affection, and Manet gave her an easel as a Christmas present. To her dismay he interfered with one of her Salon submissions whilst he was engaged to transport it, mistaking her self-criticism as an invitation to add corrections.
Although Manet is regarded as the master and Morisot as the follower, there is evidence that their relationship was reciprocal. Records show Manet's appreciation of her distinctive original style and compositional decisions, some of which he incorporated into his own work. It was Morisot who persuaded Manet to attempt plein air painting, which she had been practising since having been introduced to it by Corot.
Morisot drew Manet into the circle of painters who became known as the Impressionists. In 1874, she married Manet's brother, Eugène, and they had one daughter, Julie, who became the subject for many of her mother's paintings. Julie's memoirs, "Growing Up with the Impressionists: The Diary of Julie Manet", were published in 1987.
Style and technique.
Morisot’s works are almost always small in scale. She worked in oil paint, watercolors, or pastel, and sketched using various drawing media. Around 1880 she began painting on unprimed canvases—a technique Manet and Eva Gonzalès also experimented with at the time—and her brushwork became looser. In 1888–89, her brushstrokes transitioned from short, rapid strokes to long, sinuous ones that define form. The outer edges of her paintings were often left unfinished, allowing the canvas to show through and increasing the sense of spontaneity. After 1885, she worked mostly from preliminary drawings before beginning her oil paintings.
Morisot creates a sense of space and depth through the use of color. Although her color palette was somewhat limited, her fellow impressionists regarded her as a "virtuoso colorist". She typically made expansive use of white, whether used as a pure white or mixed with other colors. In her large painting, "The Cherry Tree", colors are more vivid but are still used to emphasize form.
Subjects.
Morisot painted what she experienced on a daily basis. Her paintings reflect the 19th-century cultural restrictions of her class and gender. She avoided urban and street scenes and seldom painted the nude figure. Like her fellow Impressionist Mary Cassatt, she focused on domestic life and portraits in which she could use family and personal friends as models, including her daughter Julie. Prior to the 1860s, Morisot painted subjects in line with the Barbizon school before turning to scenes of contemporary femininity. Paintings like "The Cradle" (1872), in which she depicted current trends for nursery furniture, reflect her sensitivity to fashion and advertising, both of which would have been apparent to her female audience. Her works also include landscapes, portraits, garden settings and boating scenes. Later in her career Morisot worked with more ambitious themes, such as nudes. Corresponding with Morisot's interest in nude subjects, Morisot also began to focus more on preliminary drawings, completing many drypoints, charcoal, and color pencil drawings.
Personal life.
Morisot was married to Eugène Manet, the brother of her friend and colleague Édouard Manet, from 1874 until his death in 1892. In 1878 she gave birth to her only child, Julie, who posed frequently for her mother and other Impressionist artists, including Renoir and her uncle Édouard.
Death.
Morisot died on 2 March 1895, in Paris, of pneumonia contracted while attending to her daughter Julie's similar illness, and thus orphaning her at the age of 16. She was interred in the Cimetière de Passy.
Popular culture.
She was portrayed by actress Marine Delterme in the eponymous 2012 French biographical TV film directed by Caroline Champetier. The character of Beatrice de Clerval in Elizabeth Kostova's "The Swan Thieves" is largerly based on Morisot.
Art market.
Morisot's work sold comparatively well. She achieved the two highest prices at a Hôtel Drouot auction in 1875, the "Interior (Young Woman with Mirror)" sold for 480 francs, and her pastel "On the Lawn" sold for 320 francs. Her works averaged 250 francs, the best relative prices at the auction.
In February 2013, Morisot became the highest priced female artist, when "After Lunch" (1881), a portrait of a young redhead in a straw hat and purple dress, sold for $10.9 million at a Christie's auction. The painting achieved roughly three times its upper estimate, exceeding the $10.7 million for a sculpture by Louise Bourgeois in 2012.
Works.
Selection of Works.
This limited selection is based on the book "Berthe Morisot" by Charles F. Stuckey, William P. Scott and Susan G. Lindsay, which is in turn drawn from the 1961 catalogue by Marie-Louise Bataille, Rouaart Denis and Georges Wildenstein. There are variations between the dates of execution, first showing and purchase. Titles may vary between sources.

</doc>
<doc id="4237" url="https://en.wikipedia.org/wiki?curid=4237" title="Barnard College">
Barnard College

Barnard College is a private women's liberal arts college in the United States and one of the Seven Sisters. Founded in 1889, it has been affiliated with Columbia University since 1900. Barnard's campus stretches along Broadway between 116th and 120th Streets in the Morningside Heights neighborhood in the borough of Manhattan, in New York City. It is directly across Broadway from Columbia's campus and near several other academic institutions and has been used by Barnard since 1898.
History.
Columbia College, Columbia University admitted only men for undergraduate study for 229 years. Barnard College was founded to provide an undergraduate education for women comparable to that of Columbia and other Ivy League schools. The college was named after Frederick Augustus Porter Barnard, a Deaf American educator and mathematician, who served as the tenth president of Columbia from 1864 to 1889. Barnard was adept with American Sign Language. He advocated equal educational privileges for men and women, preferably in a coeducational setting, and began proposing in 1879 that Columbia admit women.
The board of trustees repeatedly rejected Barnard's suggestion, but in 1883 agreed to create a detailed syllabus of study for women. While they could not attend Columbia classes, those who passed examinations based on the syllabus would receive a degree. The first such woman graduate received her bachelor's degree in 1887. A former student of the program, Annie Nathan Meyer, and other prominent New York women persuaded the board in 1889 to create a women's college connected to Columbia.
Barnard College's original 1889 home was a rented brownstone at 343 Madison Avenue, where a faculty of six offered instruction to 14 students in the School of Arts, as well as to 22 "specials", who lacked the entrance requirements in Greek and so enrolled in science. When Columbia University announced in 1892 its impending move to Morningside Heights, Barnard built a new campus on 119th-120th Streets with gifts from Mary E. Brinckerhoff, Elizabeth Milbank Anderson and Martha T. Fiske. Milbank, Brinckerhoff, and Fiske Halls, built in 1897–1898, were listed on the National Register of Historic Places in 2003.
Ella Weed supervised the college in its first four years; Emily James Smith succeeded her as Barnard's first dean. As the college grew it needed additional space, and in 1903 it received the three blocks south of 119th Street from Anderson who had purchased a former portion of the Bloomingdale Asylum site from the New York Hospital. By the mid-20th century Barnard had succeeded in its original goal of providing an elite education to women. Between 1920 and 1974, only the much larger Hunter College and University of California, Berkeley produced more women graduates who later received doctorate degrees.
Students' Hall, now known as Barnard Hall, was built in 1916. Brooks and Hewitt Halls were built in 1906–1907 and 1926–1927, respectively. They were listed on the National Register of Historic Places in 2003.
Jessica Garretson Finch is credited with coining the phrase, "current events," while teaching at Barnard College in the 1890s.
Relationship with Columbia University.
The "Barnard Bulletin" in 1976 described the relationship between the college and Columbia University as "intricate and ambiguous". Barnard president Debora Spar said in 2012 that "the relationship is admittedly a complicated one, a unique one and one that may take a few sentences to explain to the outside community".
The college's front gates state Barnard College of Columbia University. Barnard describes itself as "both an independently incorporated educational institution and an official college of Columbia University", and advises students to state "Barnard College, Columbia University" or "Barnard College of Columbia University" on résumés. Columbia describes Barnard as an affiliated institution that is a faculty of the university or is "in partnership with" it.
"The New York Times" in 2013 called Barnard "an undergraduate women's college of Columbia University", and an academic journal described Barnard in 1991 as a former affiliate that became a school within the university. Facebook includes Barnard students and alumnae within the Columbia interest group. Both the college and Columbia evaluate Barnard faculty for tenure, and Barnard graduates receive Columbia University diplomas signed by both the Barnard and Columbia presidents.
Smith and Columbia president Seth Low worked to open Columbia classes to Barnard students. By 1900 they could attend Columbia classes in philosophy, political science, and several scientific fields. That year Barnard formalized an affiliation with the university which made available to its students the instruction and facilities of Columbia. Franz Boas, who taught at both Columbia and Barnard in the early 1900s, was among those faculty members who reportedly found Barnard students superior to their male Columbia counterparts. From 1955 Columbia and Barnard students could register for the other school's classes with the permission of the instructor; from 1973 no permission was needed.
By the 1940s other undergraduate and graduate divisions of Columbia University admitted women. Columbia president William J. McGill predicted in 1970 that Barnard College and Columbia College would merge within five years, and by the mid-1970s most Columbia dormitories were coed. The university's financial difficulties during the decade increased its desire to merge, but Barnard resisted doing so because of Columbia's large debt. The college's marketing emphasized the Columbia relationship, however, the "Bulletin" in 1976 stating that Barnard described it as identical to the one between Harvard College and Radcliffe College ("who are merged in practically everything but name at this point").
After a decade of failed negotiations for a merger with Barnard akin to Harvard and Radcliffe, Columbia College instead began admitting women in 1983. Applications to Columbia rose 56% that year, making admission more selective, and nine Barnard students transferred to Columbia. Eight students admitted to both Columbia and Barnard chose Barnard, while 78 chose Columbia. Within a few years, however, selectivity rose at both schools as they received more women applicants than expected.
The Columbia-Barnard affiliation continued. Barnard pays Columbia about $5 million a year under the terms of the "interoperate relationship", which the two schools renegotiate every 15 years. Despite the affiliation Barnard is legally and financially separate from Columbia, with an independent faculty and board of trustees. It is responsible for its own separate admissions, health, security, guidance and placement services, and has its own alumnae association. Nonetheless, Barnard students participate in the academic, social, athletic and extracurricular life of the broader University community on a reciprocal basis. The affiliation permits the two schools to share some academic resources; for example, only Barnard has an urban studies department, and only Columbia has a computer science department. Most Columbia classes are open to Barnard students and vice versa. Barnard students and faculty are represented in the University Senate, and student organizations such as the "Columbia Daily Spectator" are open to all students. Barnard students play on Columbia athletics teams, and Barnard uses Columbia email, telephone and network services.
Admissions.
Admissions to Barnard is considered most selective by "U.S. News & World Report". It is the most selective women's college in the nation; in 2008, Barnard had the lowest acceptance rate of the five Seven Sisters that remain single-sex in admissions.
The class of 2020's admission rate was 16% of the 7,071 applicants, the lowest acceptance rate in the institution's history. The early-decision admission rate for the class of 2019 was 47.7%, out of 392 applications. The median SAT Combined was 2060, with median subscores of 660 in Math, 690 in Critical Reading, and 700 in Writing. The Median ACT score was 30. Of the women in the class of 2012, 89.4% ranked in first or second decile at their high school (of the 41.3% ranked by their schools). The average GPA of the class of 2012 was 94.3 on a 100-point scale and 3.88 on a 4.0 scale.
In 2015 Barnard announced that it would admit transgender women who "consistently live and identify as women, regardless of the gender assigned to them at birth", and would continue to support and enroll those students who transitioned to males after they had already been admitted.
Academic ranking.
In the 2014 U.S. News & World Report rankings, Barnard was ranked as the 32nd best liberal arts college in the country. The ranking came under widespread criticism, as it only accounted for institution-specific resources. Greg Brown, chief operating officer at Barnard, said, "I believe that our ranking is lower than it should be, primarily because the methodology simply can't account for the Barnard-Columbia relationship. Because the Columbia relationship doesn't fit neatly into any of the survey categories, it is essentially ignored. Rankings are inherently limited in this way."
In 1998, then president Judith Shapiro compared the ranking service to the "equivalent of "Sport's Illustrated" swimsuit issue." According to Shapiro's letter, "Such a ranking system certainly does more harm than good in terms of educating the public." On June 19, 2007, following a meeting of the Annapolis Group, which represents over 100 liberal arts colleges, Barnard announced that it would no longer participate in the U.S. News annual survey, and that they would fashion their own way to collect and report common data.
Barnard Library.
Barnard's Wollman Library is located in Adele Lehman Hall. Its collection includes nearly 200,000 volumes in support of the undergraduate curriculum. It also houses an archival collection of official and student publications, photographs, letters, alumnae scrapbooks and other material that documents Barnard's history from its founding in 1889 to the present day. Among the special collections are the Overbury Collection and a small collection of other rare books. The Overbury Collection consists of 3,300 items, including special and first edition books as well as manuscript materials by and about American women authors. Alumnae Books is a collection of books donated by Barnard alumnae authors. Conflicting accounts list either Richard B. Snow or Philip M. Chu as the architect of Lehman Hall... as well as of the Amherst College library and one of the libraries at Princeton University. The building opened in 1959.
Zine Collection.
Birthed from a proposal by longtime zinester Jenna Freedman, Barnard collects zines in an effort to document third-wave feminism and Riot Grrrl culture. The Zine Collection complements Barnard's women's studies research holdings, giving room to voices of girls and women otherwise under or not at all represented in the book stacks. According to its library collection development policy, "Barnard's zines are written by women (cis- and transgender) with an emphasis on zines by women of color. We collect zines on feminism and femme identity by people of all genders. The zines are personal and political publications on activism, anarchism, body image, third wave feminism, gender, parenting, queer community, riot grrrl, sexual assault, trans experience, and other topics."
Barnard's collection documents movements and trends in feminist thought through the personal work of artists, writers, and activists. Currently, the Barnard Zine Collection has approximately 7,000 items, including zines about race, gender, sexuality, childbirth, motherhood, politics, and relationships. Barnard attempts to collect two copies of each zine, one of which circulates with the second copy archived for preservation. To facilitate circulation, Barnard zines are cataloged in CLIO (the Columbia/Barnard OPAC) and OCLC's Worldcat.
Culture and student life.
Student organizations.
Every Barnard student is part of the Student Government Association (SGA), which elects a representative student government. SGA aims to facilitate the expression of opinions on matters that directly affect the Barnard community. Members of the Executive Board and the Representative Council of SGA promote these goals through active communication between students, faculty, and administration. The Executive Board includes the President of SGA, Vice President, Vice President for Campus Life, Vice President for Communications,and Vice President of Finance. Members of the Representative Council include the Senior Representative to the Board of Trustees, Junior Representative to the Board of Trustees, University Senator, Representative for Campus Policy, Representative for Academic Affairs, Representative for Diversity, Representative for Student Services, Representative for Student Interests, Representative for College Relations, Representative for Arts and Culture, Representative for Campus Affairs, and Representative for Information and Technology. In addition to these members the President and Vice President of each Class Council also sit on the Representative Council.
Student groups include theatre and vocal music groups, language clubs, literary magazines, a freeform radio station called WBAR, a biweekly magazine called the "Barnard Bulletin", community service groups, and others. Barnard students can also join extracurricular activities or organizations at Columbia University, while Columbia University students are allowed in most, but not all, Barnard organizations.
Barnard's McIntosh Activities Council (commonly known as McAC), named after the first President of Barnard, Millicent McIntosh, organizes various community focused events on campus, such as Big Sub and Midnight Breakfast. McAC is made up of five sub-committees which are the Mosaic committee (formerly known as Multicultural), the Wellness committee, the Network committee, the Community committee, and the Action committee. Each committee has a different focus, such as hosting and publicizing identity and cultural events (Mosaic), having health and wellness related events (Wellness), giving students opportunities to be involved with Alumnae and various professionals (Network), planning events that bring the entire student body together (Community), and planning community service events that give back to the surrounding community (Action).
In 2011, Barnard's SGA and McAC will work together to bring back the Greek Games, an old but quite famous Barnard tradition.
Barnard College officially banned sororities in 1913, but Barnard students continue to participate in Columbia's five National Panhellenic Conference sororities—Alpha Chi Omega, Alpha Omicron Pi, Delta Gamma, Kappa Alpha Theta, and Sigma Delta Tau—and the National Pan-Hellenic Council Sororities- Alpha Kappa Alpha (Lambda chapter) and Delta Sigma Theta (Rho chapter) as well as other sororities in the Multicultural Greek Council. Two National Panhellenic Conference organizations were founded at Barnard College. The Alpha Omicron Pi Fraternity, founded on January 2, 1897, left campus during the 1913 ban but returned to establish its Alpha chapter in 2013. The Alpha Epsilon Phi, founded on October 24, 1909, is no longer on campus. As of 2010, Barnard does not fully recognize the National Panhellenic Conference sororities at Columbia, but it does provide some funding to account for Barnard students living in Columbia housing through these organizations.
Athletics.
Barnard athletes compete in the Ivy League (NCAA Division I) through the Columbia/Barnard Athletic Consortium, which was established in 1983. Through this arrangement, Barnard is the only women's college offering Division I athletics. There are 15 intercollegiate teams, and students also compete at the intramural and club levels.
From 1975–1983, before the establishment of the Columbia/Barnard Athletic Consortium, Barnard students competed as the "Barnard Bears". Prior to 1975, students referred to themselves as the "Barnard honeybears".
Seven Sisters—student collaborations.
Established within the Barnard Student Government Association (SGA), The Seven Sisters Governing Board represents Barnard College as part of the Seven Sisters Coalition, which is a group of representatives from student councils of the historic Seven Sisters colleges. The reps on the coordinating board of Seven Sisters Coalition are rotating every year to hold the annual Seven Sisters Conference in a serious but informal setting. The first Seven Sisters Conference was hosted by SGA student representatives at Barnard College in 2009. In fall 2013, the conference was hosted by Vassar college during the first weekend of November. The major topic focused on inner college collaborations and differences in student government structures among Seven Sisters Colleges. The Seven Sisters Coordinating Board of Barnard brought six Barnard student representatives to attend the Fall Semester conference, which was hosted at Vassar College in the past fall semester. Based on the Coalition Coordinating Board Constitution established in February 2013, Students delegates were initiating projects in the aspects of public relations,alumni outreach and website management to promote the presence and development of the seven sisters culture. Meanwhile, The Barnard delegates engaged in discussions about the various structures of the student governments among the historic seven sisters colleges.
Sustainability.
Barnard College has issued a statement affirming its commitment to environmental sustainability, a major part of which is the goal of reducing its greenhouse gas emissions by 30% by 2017. Student EcoReps work as a resource on environmental issues for students in Barnard's residence halls, while the student-run Earth Coalition works on outreach initiatives such as local park clean-ups, tutoring elementary school students in environmental education, and sponsoring environmental forums. Barnard earned a "C-" for its sustainability efforts on the College Sustainability Report Card 2009 published by the Sustainable Endowments Institute. Its highest marks were in Student Involvement and Food and Recycling, receiving a "B" in both categories.
Liberal arts requirements.
The liberal arts requirements are called the Nine Ways of Knowing. Students must take one year of one laboratory science, study a single foreign language for four semesters, and complete one 3-credit course in each of the following categories: reason and value, social analysis, historical studies, cultures in comparison, quantitative and deductive reasoning, literature, and visual and performing arts. The use of AP or IB credit to fulfill these requirements is very limited, but Nine Ways of Knowing courses may overlap with major or minor requirements. In addition to the Nine Ways of Knowing, students must complete a first-year seminar, a first-year English course, and one semester of physical education.
Controversies.
In the spring of 1960 Columbia University president Grayson Kirk complained to the president of Barnard that Barnard students were wearing inappropriate clothing. The garments in question were pants and Bermuda shorts. The administration forced the student council to institute a dress code. Students would be allowed to wear shorts and pants only at Barnard and only if the shorts were no more than two inches above the knee and the pants were not tight. Barnard women crossing the street to enter the Columbia campus wearing shorts or pants were required to cover themselves with a long coat similar to a jilbab.
In March 1968, "The New York Times" ran an article on students who cohabited, identifying one of the persons they interviewed as a student at Barnard College from New Hampshire named "Susan". Barnard officials searched their records for women from New Hampshire and were able to determine that "Susan" was the pseudonym of a student (Linda LeClair) who was living with her boyfriend, a student at Columbia University. She was called before Barnard's student-faculty administration judicial committee, where she faced the possibility of expulsion. A student protest included a petition signed by 300 other Barnard women, admitting that they too had broken the regulations against cohabitating. The judicial committee reached a compromise and the student was allowed to remain in school, but was denied use of the college cafeteria and barred from all social activities. The student briefly became a focus of intense national attention. She eventually dropped out of Barnard.
References.
Notes
Sources

</doc>
<doc id="4240" url="https://en.wikipedia.org/wiki?curid=4240" title="Order of Saint Benedict">
Order of Saint Benedict

The Order of Saint Benedict (OSB; Latin: "Ordo Sancti Benedicti"), also knownin reference to the color of its members' habitsas the Black Monks, is a Catholic religious order of independent monastic communities that observe the Rule of Saint Benedict. Each community (monastery, priory or abbey) within the order maintains its own autonomy, while the order itself represents their mutual interests. The terms "Order of Saint Benedict" and "Benedictine Order" are, however, also used to refer to "all" Benedictine communities collectively, sometimes giving the incorrect impression that there exists a generalate or motherhouse with jurisdiction over them.
Internationally, the order is governed by the Benedictine Confederation, a body, established in 1883 by Pope Leo XIII's Brief "Summum semper", whose head is known as the Abbot Primate. Individuals whose communities are members of the order generally add the initials "OSB" after their names.
Historical development.
The monastery at Subiaco in Italy, established by Saint Benedict of Nursia circa 529, was the first of the dozen monasteries he founded. He later founded the Abbey of Monte Cassino. There is no evidence, however, that he intended to found an order and the Rule of Saint Benedict presupposes the autonomy of each community. When Monte Cassino was sacked by the Lombards about the year 580, the monks fled to Rome, and it seems probable that this constituted an important factor in the diffusion of a knowledge of Benedictine monasticism.
It was from the monastery of St. Andrew in Rome that Augustine, the prior, and his forty companions set forth in 595 on their mission for the evangelization of England. At various stopping places during the journey, the monks left behind them traditions concerning their rule and form of life, and probably also some copies of the Rule. Lérins Abbey, for instance, founded by Honoratus in 375, probably received its first knowledge of the Benedictine Rule from the visit of St. Augustine and his companions in 596.
Gregory of Tours says that at Ainay, in the sixth century, the monks "followed the rules of Basil, Cassian, Caesarius, and other fathers, taking and using whatever seemed proper to the conditions of time and place", and doubtless the same liberty was taken with the Benedictine Rule when it reached them. In Gaul and Switzerland, it supplemented the much stricter Irish or Celtic Rule introduced by Columbanus and others. In many monasteries it eventually entirely displaced the earlier codes.
By the ninth century, however, the Benedictine had become the standard form of monastic life throughout the whole of Western Europe, excepting Scotland, Wales, and Ireland, where the Celtic observance still prevailed for another century or two. Largely through the work of Benedict of Aniane, it became the rule of choice for monasteries throughout the Carolingian empire.
Monastic scriptoria flourished from the ninth through the twelfth centuries. Sacred Scripture was always at the heart of every monastic scriptorium. As a general rule those of the monks who possessed skill as writers made this their chief, if not their sole active work. An anonymous writer of the ninth or tenth century speaks of six hours a day as the usual task of a scribe, which would absorb almost all the time available for active work in the day of a medieval monk.
In the Middle Ages monasteries were often founded by the nobility. Cluny Abbey was founded by William I, Duke of Aquitaine in 910. The abbey was noted for its strict adherence to the Rule of St. Benedict. The abbot of Cluny was the superior of all the daughter houses, through appointed priors.
One of the earliest reforms of Benedictine practice was that initiated in 980 by Romuald, who founded the Camaldolese community.
England.
The English Benedictine Congregation is the oldest of the nineteen Benedictine congregations. Augustine of Canterbury and his monks established the first English Benedictine monastery at Canterbury soon after their arrival in 597. Other foundations quickly followed. Through the influence of Wilfrid, Benedict Biscop, and Dunstan, the Benedictine Rule spread with extraordinary rapidity, and in the North it was adopted in most of the monasteries that had been founded by the Celtic missionaries from Iona. Many of the episcopal sees of England were founded and governed by the Benedictines, and no less than nine of the old cathedrals were served by the black monks of the priories attached to them. Monasteries served as hospitals and places of refuge for the weak and homeless. The monks studied the healing properties of plants and minerals to alleviate the sufferings of the sick.
Germany was evangelized by English Benedictines. Willibrord and Boniface preached there in the seventh and eighth centuries and founded several abbeys.
In the English Reformation, all monasteries were dissolved and their lands confiscated by the Crown, forcing their Catholic members to flee into exile on the Continent. During the 19th century they were able to return to England, including to Selby Abbey in Yorkshire, one of the few great monastic churches to survive the Dissolution.
St. Mildred's Priory, on the Isle of Thanet, Kent, was built in 1027 on the site of an abbey founded in 670 by the daughter of the first Christian King of Kent. Currently the priory is home to a community of Benedictine nuns. Five of the most notable English abbeys are the Basilica of St Gregory the Great at Downside, commonly known as Downside Abbey, The Abbey of St Edmund, King and Martyr commonly known as Douai Abbey in Upper Woolhampton, Reading, Berkshire, Ealing Abbey in Ealing, West London, St. Lawrence's in Yorkshire (Ampleforth Abbey), and Worth Abbey. Prinknash Abbey, used by Henry VIII as a hunting lodge, was officially returned to the Benedictines four hundred years later, in 1928. During the next few years, so-called Prinknash Park was used as a home until it was returned to the order.
Since the Oxford Movement, there has also been a modest flourishing of Benedictine monasticism in the Anglican Church and Protestant Churches. Anglican Benedictine Abbots are invited guests of the Benedictine Abbot Primate in Rome at Abbatial gatherings at Sant'Anselmo. There are an estimated 2,400 celibate Anglican Religious (1,080 men and 1,320 women) in the Anglican Communion as a whole, some of whom have adopted the Rule of St. Benedict.
As of 2015, the English Congregation consists of three abbeys of nuns and ten abbeys of monks. Members of the congregation are found in England, Wales, the United States of America, Peru and Zimbabwe.
Monastic Libraries in England.
The forty-eighth rule of Saint Benedict prescribes extensive and habitual "holy reading" for the brethren. Three primary types of reading were done by the monks during this time. Monks would read privately during their personal time, as well as publicly during services and at meal times. In addition to these three mentioned in the Rule, monks would also read in the infirmary.
However, Benedictine monks were disallowed worldly possessions, thus necessitating the preservation and collection of sacred texts in monastic libraries for communal use. For the sake of convenience, the books in the monastery were housed in a few different places, namely the sacristy, which contained books for the choir and other liturgical books, the rectory, which housed books for public reading such as sermons and lives of the saints, and the library, which contained the largest collection of books and was typically in the cloister.
The first record of a monastic library in England is in Canterbury. To assist with Augustine of Canterbury's English mission, Pope Gregory the Great gave him nine books which included the Gregorian Bible in two volumes, the Psalter of Augustine, two copies of the Gospels, two martyrologies, an Exposition of the Gospels and Epistles, and a Psalter. Theodore of Tarsus brought Greek books to Canterbury more than seventy years later, when he founded a school for the study of Greek.
France.
Monasteries were among the institutions of the Catholic Church swept away during the French Revolution. Monasteries were again allowed to form in the 19th century under the Bourbon Restoration. Later that century, under the Third French Republic, laws were enacted preventing religious teaching. The original intent was to allow secular schools. Thus in 1880 and 1882, Benedictine teaching monks were effectively exiled; this was not completed until 1901.
United States.
The first Benedictine to live in the United States was Pierre-Joseph Didier. He came to the United States in 1790 from Paris and served in the Ohio and St. Louis areas until his death. The first actual Benedictine monastery founded was St. Vincent, located in Latrobe, Pennsylvania. It was founded in 1832 by Bonifice Wimmer, a German monk, who sought to serve German immigrants in America. In 1856, Wimmer started to lay the foundations for St. John's Abbey in Minnesota. By his death in 1887, Wimmer had sent Benedictine monks to Kansas, New Jersey, North Carolina, Georgia, Florida, Alabama, Illinois, and Colorado.
Wilmer also asked for Benedictine sisters to be sent to America by St. Walburg's Convent in Eichstätt, Bavaria. In 1852, St. Benedict Riepp and two others sisters founded St. Mary's in Pennsylvania. Soon they would send sisters to Michigan, New Jersey, and Minnesota.
By 1854, Swiss monks began to arrive and founded St. Meinrad's Abbey in Indiana, and they soon spread to Arkansas and Louisiana. They were soon followed by Swiss sisters.
There are now over 100 Benedictine houses across America. Most Benedictine houses are part of one of four large Federations: American-Cassinese, Swiss-American, St. Scholastica, and St. Benedict. The federations mostly are made up of monasteries that share the same lineage. For instance the American-Cassinese Federation included the 22 monasteries that descended from Boniface Wimmer.
Organization.
Today, Benedictine monasticism is fundamentally different from other Western religious orders insofar as its individual communities are not part of a religious order with "Generalates" and "Superiors General". Rather, in modern times, the various autonomous houses have formed themselves loosely into congregations (for example, Cassinese, English, Solesmes, Subiaco, Camaldolese, Sylvestrines) that in turn are represented in the Benedictine Confederation that came into existence through Pope Leo XIII's Apostolic Brief "Summum semper" on 12 July 1883. This organization facilitates dialogue of Benedictine communities with each other and the relationship between Benedictine communities and other religious orders and the church at large. 
The Rule of Saint Benedict is also used by a number of religious orders that began as reforms of the Benedictine tradition such as the Cistercians and Trappists although none of these groups are part of the Benedictine Confederation. 
The largest number of Benedictines are Roman Catholics, but there are also some within the Anglican Communion and occasionally within other Christian denominations as well, for example, within the Lutheran Church. 
Benedictine vow and life.
Section 17 in chapter 58 of the Rule of Saint Benedict states the solemn promise candidates for reception into a Benedictine community are required to make: a promise of stability (i.e. to remain in the same community), "conversatio morum" (an idiomatic Latin phrase suggesting "conversion of manners"; see below) and obedience (to the community's superior, seen as holding the place of Christ within it). This solemn commitment tends to be referred to as the "Benedictine vow" and is the Benedictine antecedent and equivalent of the evangelical counsels professed by candidates for reception into a religious order.
Much scholarship over the last fifty years has been dedicated to the translation and interpretation of ""conversatio morum"". The older translation "conversion of life" has generally been replaced with phrases such as "to a monastic manner of life", drawing from the Vulgate's use of "conversatio" as a translation of "citizenship" or "homeland" in Philippians 3:20. Some scholars have claimed that the vow formula of the Rule is best translated as "to live in this place as a monk, in obedience to its rule and abbot."
Benedictine abbots and abbesses have full jurisdiction of their abbey and thus absolute authority over the monks or nuns who are resident. This authority includes the power to assign duties, to decide which books may or may not be read, to regulate comings and goings, and to punish and to excommunicate, in the sense of an enforced isolation from the monastic community.
A tight communal timetablethe horariumis meant to ensure that the time given by God is not wasted but used in God's service, whether for prayer, work, meals, spiritual reading or sleep.
Although Benedictines do not take a vow of silence, hours of strict silence are set, and at other times silence is maintained as much as is practically possible. Social conversations tend to be limited to communal recreation times. But such details, like the many other details of the daily routine of a Benedictine house that the Rule of St Benedict leaves to the discretion of the superior, are set out in its 'customary'. A ' customary' is the code adopted by a particular Benedictine house, adapting the Rule to local conditions.
In the Roman Catholic Church, according to the nuns of the 1983 Code of Canon Law, a Benedictine abbey is a "religious institute" and its members are therefore members of the consecrated life. While Canon Law 588 §1 explains that Benedictine monks are "neither clerical nor lay", they can, however, be ordained. Benedictine Oblates endeavor to embrace the spirit of the Benedictine vow in their own life in the world.

</doc>
<doc id="4241" url="https://en.wikipedia.org/wiki?curid=4241" title="Bayezid I">
Bayezid I

Bayezid I (; ; nicknamed "Yıldırım" (Ottoman Turkish: ییلدیرم), "The Thunderbolt"; 1360 – 8 March 1403) was the Ottoman Sultan from 1389 to 1402. He was the son of Murad I and Gülçiçek Hatun. He built one of the largest armies in the known world at the time and unsuccessfully besieged Constantinople. He was defeated and captured by Timur at the Battle of Ankara in 1402 and died in captivity in March 1403.
Biography.
The first major role of Bayezid was as governor of Kütahya, city that was conquered from the Germiyanids. He was an impetuous soldier, earning the nickname of Lightning in a battle against the Karamanids.
Bayezid ascended to the throne following the death of his father Murad I, who was killed by Serbian knight Miloš Obilić during (15 June), or immediately after (16 June), the Battle of Kosovo in 1389, by which Serbia became a vassal of the Ottoman Sultanate. Immediately after obtaining the throne, he had his younger brother strangled to avoid a plot. In 1390, Bayezid took as a wife Princess Olivera Despina, the daughter of Prince Lazar of Serbia, who also lost his life in Kosovo. Bayezid recognized Stefan Lazarević, the son of Lazar, as the new Serbian leader (later despot), with considerable autonomy.
The upper Serbia resisted the Ottomans until general Pashayigit captured the city of Skopje in 1391, converting the city to an important base of operations.
Meanwhile, the sultan began unifying Anatolia under his rule. Forcible expansion into Muslim territories could endanger the Ottoman relationship with the gazis, who were an important source of warriors for this ruling house on the European frontier. So Bayezid began the practice to first secure "fatwa"s, or legal rulings from Islamic scholars, justifying their wars against these Muslim states. However he suspected the loyalty of his Muslim Turkoman followers, for Bayezid relied heavily on his Serbian and Byzantine vassal troops to perform these conquests.
In a single campaign over the summer and fall of 1390, Bayezid conquered the beyliks of Aydin, Saruhan and Menteşe. His major rival Sulayman, the emir of Karaman, responded by allying himself with the ruler of Sivas, Kadi Burhan al-Din and the remaining Turkish beyliks. Nevertheless, Bayezid pushed on and in the fall and winter of 1390 overwhelmed the remaining beyliks -- Hamid, Teke, and Germiyan—as well as taking the cities of Akşehir and Niğde, as well as their capital Konya from the Karaman. At this point, Bayezid accepted peace proposals from Karaman (1391), concerned that further advances would antagonize his Turkoman followers and lead them to ally with Kadi Burhan al-Din. Once peace had been made with Karaman, Bayezid moved north against Kastamonu which had given refuge to many fleeing from his forces, and conquered both that city as well as Sinop.
From 1389 to 1395 he conquered Bulgaria and northern Greece. In 1394 Bayezid crossed the River Danube to attack Wallachia, ruled at that time by Mircea the Elder. The Ottomans were superior in number, but on 10 October 1394 (or 17 May 1395), in the Battle of Rovine, on forested and swampy terrain, the Wallachians won the fierce battle and prevented Bayezid's army from advancing beyond the Danube.
In 1394, Bayezid laid siege to Constantinople, the capital of the Byzantine Empire. Anadoluhisarı fortress was built between 1393 and 1394 as part of preparations for the Second Ottoman Siege of Constantinople, which took place in 1395. On the urgings of the Byzantine emperor Manuel II Palaeologus a new crusade was organized to defeat him. This proved unsuccessful: in 1396 the Christian allies, under the leadership of the King of Hungary and future Holy Roman Emperor (in 1433) Sigismund, were defeated in the Battle of Nicopolis. Bayezid built the magnificent Ulu Cami in Bursa, to celebrate this victory.
Thus the siege of Constantinople continued, lasting until 1402. The beleaguered Byzantines had their reprieve when Bayezid fought the Timurid Empire in the East. At this time, the empire of Bayezid included Thrace (except Constantinople), Macedonia, Bulgaria, and parts of Serbia in Europe. In Asia, his domains extended to the Taurus Mountains. His army was considered one of the best in the Islamic world. In 1400, the Central Asian warlord Timur succeeded in rousing the local Turkic beyliks who had been vassals of the Ottomans to join him in his attack on Bayezid, who was also considered one of the most powerful rulers in the Muslim world during that period. In the fateful Battle of Ankara, on 20 July 1402, Bayezid was captured by Timur and the Ottoman army was defeated. Many writers claim that Bayezid was mistreated by the Timurids. However, writers and historians from Timur's own court reported that Bayezid was treated well, and that Timur even mourned his death. One of Bayezid's sons, Mustafa Çelebi, was captured with him and held captive in Samarkand until 1405.
Four of Bayezid's sons, specifically Süleyman Çelebi, İsa Çelebi, Mehmed Çelebi, and Musa Çelebi, however, escaped from the battlefield and later started a civil war for the Ottoman throne known as the Ottoman Interregnum. After Mehmed's victory, his coronation as Mehmed I, and the death of all four but Mehmed, Bayezid's other son Mustafa Çelebi emerged from hiding and began two failed rebellions against his brother Mehmed and, after Mehmed's death, his nephew Murat II.
Legacy.
A commando battalion in the Pakistan Army is named Yaldaram Battalion after him.
Yildirim Beyazit University, a state university in Turkey, is also named after him.
Marriages and progeny.
His mother was Gülçiçek Hatun who was of ethnic Greek descent.
In fiction.
The defeat of Bayezid became a popular subject for later Western writers, composers, and painters. They embellished the legend that he was taken by Timur to Samarkand with a cast of characters to create an oriental fantasy that has maintained its appeal. Christopher Marlowe's play "Tamburlaine the Great" was first performed in London in 1587, three years after the formal opening of English-Ottoman trade relations when William Harborne sailed for Constantinople as an agent of the Levant Company.
In 1648, the play "Le Gran Tamerlan et Bejezet" by Jean Magnon appeared in London, and in 1725, Handel's "Tamerlano" was first performed and published in London; Vivaldi's version of the story, "Bajazet", was written in 1735. Magnon had given Bayezid an intriguing wife and daughter; the Handel and Vivaldi renditions included, as well as Tamerlane and Bayezid and his daughter, a prince of Byzantium and a princess of Trebizond (Trabzon) in a passionate love story. A cycle of paintings in Schloss Eggenberg, near Graz in Austria, translated the theme to a different medium; this was completed in the 1670s shortly before the Ottoman army attacked the Habsburgs in central Europe.
Bayezid (spelled Bayazid) is a central character in the Robert E. Howard story "Lord of Samarcand."
External links.
47–48

</doc>
<doc id="4242" url="https://en.wikipedia.org/wiki?curid=4242" title="Bayezid II">
Bayezid II

Bayezid II or Sultân Bayezid-î Velî (December 3, 1447 – May 26, 1512) (Ottoman Turkish: بايزيد ثانى "Bāyezīd-i sānī", Turkish:"II. Bayezid" or "II. Beyazıt") was the eldest son and successor of Mehmed II, ruling as Sultan of the Ottoman Empire from 1481 to 1512. During his reign, Bayezid II consolidated the Ottoman Empire and thwarted a Safavid rebellion soon before abdicating his throne to his son, Selim I. He is most notable for evacuating Jews from Spain after the proclamation of the Alhambra Decree and resettling them throughout the Ottoman Empire.
Early life.
Bayezid II was the son of Mehmed II (1432–81). His mother's identity is undetermined; there are two main theories, that she was Emine Gülbahar Hatun or Sitti Mükrime Hatun.
Bayezid II married Gülbahar Hatun, who was the mother of his eldest son Şehzade Ahmet, as well as Bayezid II's heir and successor, Selim I and nephew of Sitti Mükrime Hatun.
Fight for the throne.
Bayezid II's overriding concern was the quarrel with his brother Cem, who claimed the throne and sought military backing from the Mamluks in Egypt. Having been defeated by his brother's armies, Cem sought protection from the Knights of St. John in Rhodes. Eventually, the Knights handed Cem over to Pope Innocent VIII (1484–1492). The Pope thought of using Cem as a tool to drive the Turks out of Europe, but, as the papal crusade failed to come to fruition, Cem was left to languish and die in a Neapolitan prison. Bayezid II paid both the Knights Hospitaller and the pope to keep his brother prisoner.
Reign.
Bayezid II ascended the Ottoman throne in 1481. Like his father, Bayezid II was a patron of western and eastern culture and unlike many other Sultans, worked hard to ensure a smooth running of domestic politics, which earned him the epithet of "the Just". Throughout his reign, Bayezid II engaged in numerous campaigns to conquer the Venetian possessions in Morea, accurately defining this region as the key to future Ottoman naval power in the Eastern Mediterranean. The last of these wars ended in 1501 with Bayezid II in control of the whole Peloponnese. Rebellions in the east, such as that of the Qizilbash, plagued much of Bayezid II's reign and were often backed by the Shah of Persia, Ismail, who was eager to promote Shi'ism to undermine the authority of the Ottoman state. Ottoman authority in Anatolia was indeed seriously threatened during this period, and at one point Bayezid II's grand vizier, Ali Pasha, was killed in battle against rebels.
Jewish and Muslim immigration.
In July 1492, the new state of Spain expelled its Jewish and Muslim populations as part of the Spanish Inquisition. Bayezid II sent out the Ottoman Navy under the command of Admiral Kemal Reis to Spain in 1492 in order to evacuate them safely to Ottoman lands. He sent out proclamations throughout the empire that the refugees were to be welcomed. He granted the refugees the permission to settle in the Ottoman Empire and become Ottoman citizens. He ridiculed the conduct of Ferdinand II of Aragon and Isabella I of Castile in expelling a class of people so useful to their subjects. "You venture to call Ferdinand a wise ruler," he said to his courtiers — "he who has impoverished his own country and enriched mine!" Bayezid addressed a firman to all the governors of his European provinces, ordering them not only to refrain from repelling the Spanish refugees, but to give them a friendly and welcome reception. He threatened with death all those who treated the Jews harshly or refused them admission into the empire. Moses Capsali, who probably helped to arouse the sultan's friendship for the Jews, was most energetic in his assistance to the exiles. He made a tour of the communities, and was instrumental in imposing a tax upon the rich, to ransom the Jewish victims of the persecutions then prevalent.
The Muslims and Jews of al-Andalus (Iberia) contributed much to the rising power of the Ottoman Empire by introducing new ideas, methods and craftsmanship. The first printing press in Constantinople was established by the Sephardic Jews in 1493. It is reported that under Bayezid's reign, Jews enjoyed a period of cultural flourishing, with the presence of such scholars as the Talmudist and scientist Mordecai Comtino; astronomer and poet Solomon ben Elijah Sharbiṭ ha-Zahab; Shabbethai ben Malkiel Cohen, and the liturgical poet Menahem Tamar.
Succession.
On September 14, 1509, Constantinople was devastated by an earthquake. Bayezid II's final years saw a succession battle between his sons Selim I and Ahmet. Ahmet unexpectedly captured Karaman, an Ottoman city, and began marching to Constantinople to exploit his triumph. Fearing for his safety, Selim staged a revolt in Thrace but was defeated by Bayezid and forced to flee back to the Crimean Peninsula. Bayezid II developed fears that Ahmet might in turn kill him to gain the throne and refused to allow his son to enter Constantinople.
Selim returned from Crimea and, with support from the Janissaries, forced his father to abdicate the throne on April 25, 1512. Beyazid departed for retirement in his native Demotika, but he died on May 26, 1512 at Büyükçekmece before reaching his destination, and only a month after his abdication. He was buried next to the Bayezid Mosque in Istanbul.

</doc>
<doc id="4243" url="https://en.wikipedia.org/wiki?curid=4243" title="Boxing">
Boxing

Boxing is a martial art and combat sport in which two people wearing protective gloves throw punches at each other for a predetermined set of time in a boxing ring. Historically, the goal is to amass points each round by inflicting the most damage to the opponent while mitigating the opponent's attacks to secure the most points each round.
Amateur boxing is both an Olympic and Commonwealth sport and is a common fixture in most international games—it also has its own World Championships. Boxing is supervised by a referee over a series of one- to three-minute intervals called rounds. The result is decided when an opponent is deemed incapable to continue by a referee, is disqualified for breaking a rule, resigns by throwing in a towel, or is pronounced the winner or loser based on the judges' scorecards at the end of the contest. In the event that both fighters gain equal scores from the judges, the fight is considered a draw (professional boxing). In Olympic boxing, due to the fact that a winner must be declared, in the case of a draw - the judges use technical criteria to choose the most deserving winner of the bout.
While people have fought in hand-to-hand combat since before the dawn of history, the origin of boxing as an organized sport may be its acceptance by the ancient Greeks as an Olympic game in BC 688. Boxing evolved from 16th- and 18th-century prizefights, largely in Great Britain, to the forerunner of modern boxing in the mid-19th century, again initially in Great Britain and later in the United States.
History.
Ancient history.
"See also Ancient Greek boxing
The earliest known depiction of boxing comes from a Sumerian relief in Iraq from the 3rd millennium BCE Later depictions from the 2nd millennium BC are found in reliefs from the Mesopotamian nations of Assyria and Babylonia, and in Hittite art from Asia Minor. The earliest evidence for fist fighting with any kind of gloves can be found on Minoan Crete (c.1650–1400 BCE), and on Sardinia, if we consider the boxing statues of Prama mountains (c. 2000–1000 BC).
Boxing was a popular spectator sport in Ancient Rome. In order for the fighters to protect themselves against their opponents they wrapped leather thongs around their fists. Eventually harder leather was used and the thong soon became a weapon. The Romans even introduced metal studs to the thongs to make the cestus which then led to a more sinister weapon called the myrmex ('limb piercer'). Fighting events were held at Roman Amphitheatres. The Roman form of boxing was often a fight until death to please the spectators who gathered at such events. However, especially in later times, purchased slaves and trained combat performers were valuable commodities, and their lives were not given up without due consideration. Often slaves were used against one another in a circle marked on the floor. This is where the term ring came from. In AD 393, during the Roman gladiator period, boxing was abolished due to excessive brutality. It was not until the late 17th century that boxing re-surfaced in London.
Early London prize ring rules.
Records of Classical boxing activity disappeared after the fall of the Western Roman Empire when the wearing of weapons became common once again and interest in fighting with the fists waned. However, there are detailed records of various fist-fighting sports that were maintained in different cities and provinces of Italy between the 12th and 17th centuries. There was also a sport in ancient Rus called Kulachniy Boy or "Fist Fighting".
As the wearing of swords became less common, there was renewed interest in fencing with the fists. The sport would later resurface in England during the early 16th century in the form of bare-knuckle boxing sometimes referred to as prizefighting. The first documented account of a bare-knuckle fight in England appeared in 1681 in the "London Protestant Mercury", and the first English bare-knuckle champion was James Figg in 1719. This is also the time when the word "boxing" first came to be used. It should be noted, that this earliest form of modern boxing was very different. Contests in Mr. Figg's time, in addition to fist fighting, also contained fencing and cudgeling. On 6 January 1681, the first recorded boxing match took place in Britain when Christopher Monck, 2nd Duke of Albemarle (and later Lieutenant Governor of Jamaica) engineered a bout between his butler and his butcher with the latter winning the prize.
Early fighting had no written rules. There were no weight divisions or round limits, and no referee. In general, it was extremely chaotic. An early article on boxing was published in Nottingham, 1713, by Sir Thomas Parkyns, a successful Wrestler from Bunny, Nottinghamshire, who had practised the techniques he described. The article, a single page in his manual of wrestling and fencing, "Progymnasmata: The inn-play, or Cornish-hugg wrestler", described a system of headbutting, punching, eye-gouging, chokes, and hard throws, not recognized in boxing today.
The first boxing rules, called the Broughton's rules, were introduced by champion Jack Broughton in 1743 to protect fighters in the ring where deaths sometimes occurred. Under these rules, if a man went down and could not continue after a count of 30 seconds, the fight was over. Hitting a downed fighter and grasping below the waist were prohibited. Broughton encouraged the use of 'mufflers', a form of padded bandage or mitten, to be used in 'jousting' or sparring sessions in training, and in exhibition matches.
These rules did allow the fighters an advantage not enjoyed by today's boxers; they permitted the fighter to drop to one knee to begin a 30-second count at any time. Thus a fighter realizing he or she was in trouble had an opportunity to recover. However, this was considered "unmanly" and was frequently disallowed by additional rules negotiated by the Seconds of the Boxers. Intentionally going down in modern boxing will cause the recovering fighter to lose points in the scoring system. Furthermore, as the contestants did not have heavy leather gloves and wristwraps to protect their hands, they used different punching technique to preserve their hands because the head was a common target to hit full out as almost all period manuals have powerful straight punches with the whole body behind them to the face (including forehead) as the basic blows.
Marquess of Queensberry rules (1867).
In 1867, the Marquess of Queensberry rules were drafted by John Chambers for amateur championships held at Lillie Bridge in London for Lightweights, Middleweights and Heavyweights. The rules were published under the patronage of the Marquess of Queensberry, whose name has always been associated with them.
There were twelve rules in all, and they specified that fights should be "a fair stand-up boxing match" in a 24-foot-square or similar ring. Rounds were three minutes with one-minute rest intervals between rounds. Each fighter was given a ten-second count if he was knocked down, and wrestling was banned.
The introduction of gloves of "fair-size" also changed the nature of the bouts. An average pair of boxing gloves resembles a bloated pair of mittens and are laced up around the wrists.
The gloves can be used to block an opponent's blows. As a result of their introduction, bouts became longer and more strategic with greater importance attached to defensive maneuvers such as slipping, bobbing, countering and angling. Because less defensive emphasis was placed on the use of the forearms and more on the gloves, the classical forearms outwards, torso leaning back stance of the bare knuckle boxer was modified to a more modern stance in which the torso is tilted forward and the hands are held closer to the face.
Late 19th and early 20th centuries.
Through the late nineteenth century, the martial art of boxing or prizefighting was primarily a sport of dubious legitimacy. Outlawed in England and much of the United States, prizefights were often held at gambling venues and broken up by police. Brawling and wrestling tactics continued, and riots at prizefights were common occurrences. Still, throughout this period, there arose some notable bare knuckle champions who developed fairly sophisticated fighting tactics.
The English case of "R v. Coney" in 1882 found that a bare-knuckle fight was an assault occasioning actual bodily harm, despite the consent of the participants. This marked the end of widespread public bare-knuckle contests in England.
The first world heavyweight champion under the Queensberry Rules was "Gentleman Jim" Corbett, who defeated John L. Sullivan in 1892 at the Pelican Athletic Club in New Orleans.
The first instance of film censorship in the United States occurred in 1897 when several states banned the showing of prize fighting films from the state of Nevada, where it was legal at the time.
Throughout the early twentieth century, boxers struggled to achieve legitimacy. They were aided by the influence of promoters like Tex Rickard and the popularity of great champions such as John L. Sullivan.
Rules.
The "Marquess of Queensberry rules" have been the general rules governing modern boxing since their publication in 1867.
A boxing match typically consists of a determined number of three-minute rounds, a total of up to 9 to 12 rounds. A minute is typically spent between each round with the fighters in their assigned corners receiving advice and attention from their coach and staff. The fight is controlled by a referee who works within the ring to judge and control the conduct of the fighters, rule on their ability to fight safely, count knocked-down fighters, and rule on fouls.
Up to three judges are typically present at ringside to score the bout and assign points to the boxers, based on punches that connect, defense, knockdowns, and other, more subjective, measures. Because of the open-ended style of boxing judging, many fights have controversial results, in which one or both fighters believe they have been "robbed" or unfairly denied a victory. Each fighter has an assigned corner of the ring, where his or her coach, as well as one or more "seconds" may administer to the fighter at the beginning of the fight and between rounds. Each boxer enters into the ring from their assigned corners at the beginning of each round and must cease fighting and return to their corner at the signaled end of each round.
A bout in which the predetermined number of rounds passes is decided by the judges, and is said to "go the distance". The fighter with the higher score at the end of the fight is ruled the winner. With three judges, unanimous and split decisions are possible, as are draws. A boxer may win the bout before a decision is reached through a knock-out ; such bouts are said to have ended "inside the distance". If a fighter is knocked down during the fight, determined by whether the boxer touches the canvas floor of the ring with any part of their body other than the feet as a result of the opponent's punch and not a slip, as determined by the referee, the referee begins counting until the fighter returns to his or her feet and can continue.
Should the referee count to ten, then the knocked-down boxer is ruled "knocked out" (whether unconscious or not) and the other boxer is ruled the winner by knockout (KO). A "technical knock-out" (TKO) is possible as well, and is ruled by the referee, fight doctor, or a fighter's corner if a fighter is unable to safely continue to fight, based upon injuries or being judged unable to effectively defend themselves. Many jurisdictions and sanctioning agencies also have a "three-knockdown rule", in which three knockdowns in a given round result in a TKO. A TKO is considered a knockout in a fighter's record. A "standing eight" count rule may also be in effect. This gives the referee the right to step in and administer a count of eight to a fighter that he feels may be in danger, even if no knockdown has taken place. After counting the referee will observe the fighter, and decide if he is fit to continue. For scoring purposes, a standing eight count is treated as a knockdown.
In general, boxers are prohibited from hitting below the belt, holding, tripping, pushing, biting, or spitting. The boxer's shorts are raised so the opponent is not allowed to hit to the groin area with intent to cause pain or injury. Failure to abide by the former may result in a foul. They also are prohibited from kicking, head-butting, or hitting with any part of the arm other than the knuckles of a closed fist (including hitting with the elbow, shoulder or forearm, as well as with open gloves, the wrist, the inside, back or side of the hand). They are prohibited as well from hitting the back, back of the neck or head (called a "rabbit-punch") or the kidneys. They are prohibited from holding the ropes for support when punching, holding an opponent while punching, or ducking below the belt of their opponent (dropping below the waist of your opponent, no matter the distance between).
If a "clinch" – a defensive move in which a boxer wraps his or her opponents arms and holds on to create a pause – is broken by the referee, each fighter must take a full step back before punching again (alternatively, the referee may direct the fighters to "punch out" of the clinch). When a boxer is knocked down, the other boxer must immediately cease fighting and move to the furthest neutral corner of the ring until the referee has either ruled a knockout or called for the fight to continue.
Violations of these rules may be ruled "fouls" by the referee, who may issue warnings, deduct points, or disqualify an offending boxer, causing an automatic loss, depending on the seriousness and intentionality of the foul. An intentional foul that causes injury that prevents a fight from continuing usually causes the boxer who committed it to be disqualified. A fighter who suffers an accidental low-blow may be given up to five minutes to recover, after which they may be ruled knocked out if they are unable to continue. Accidental fouls that cause injury ending a bout may lead to a "no contest" result, or else cause the fight to go to a decision if enough rounds (typically four or more, or at least three in a four-round fight) have passed.
Unheard of these days, but common during the early 20th Century in North America, a "newspaper decision (NWS)" might be made after a no decision bout had ended. A "no decision" bout occurred when, by law or by pre-arrangement of the fighters, if both boxers were still standing at the fight's conclusion and there was no knockout, no official decision was rendered and neither boxer was declared the winner. But this did not prevent the pool of ringside newspaper reporters from declaring a consensus result among themselves and printing a newspaper decision in their publications. Officially, however, a "no decision" bout resulted in neither boxer winning or losing. Boxing historians sometimes use these unofficial newspaper decisions in compiling fight records for illustrative purposes only. Often, media outlets covering a match will personally score the match, and post their scores as an independent sentence in their report.
Professional vs. amateur boxing.
Throughout the 17th to 19th centuries, boxing bouts were motivated by money, as the fighters competed for prize money, promoters controlled the gate, and spectators bet on the result. The modern Olympic movement revived interest in amateur sports, and amateur boxing became an Olympic sport in 1908. In their current form, Olympic and other amateur bouts are typically limited to three or four rounds, scoring is computed by points based on the number of clean blows landed, regardless of impact, and fighters wear protective headgear, reducing the number of injuries, knockdowns, and knockouts. Currently scoring blows in amateur boxing are subjectively counted by ringside judges, but the Australian Institute for Sport has demonstrated a prototype of an Automated Boxing Scoring System, which introduces scoring objectivity, improves safety, and arguably makes the sport more interesting to spectators. Professional boxing remains by far the most popular form of the sport globally, though amateur boxing is dominant in Cuba and some former Soviet republics. For most fighters, an amateur career, especially at the Olympics, serves to develop skills and gain experience in preparation for a professional career.
Amateur boxing.
Amateur boxing may be found at the collegiate level, at the Olympic Games and Commonwealth Games, and in many other venues sanctioned by amateur boxing associations. Amateur boxing has a point scoring system that measures the number of clean blows landed rather than physical damage. Bouts consist of three rounds of three minutes in the Olympic and Commonwealth Games, and three rounds of three minutes in a national ABA (Amateur Boxing Association) bout, each with a one-minute interval between rounds.
Competitors wear protective headgear and gloves with a white strip or circle across the knuckle. There are cases however, where white ended gloves are not required but any solid color may be worn. The white end just is a way to make it easier for judges to score clean hits. Each competitor must have their hands properly wrapped, pre-fight, for added protection on their hands and for added cushion under the gloves. Gloves worn by the fighters must be twelve ounces in weight unless, the fighters weigh under 165 pounds, thus allowing them to wear 10 ounce gloves. A punch is considered a scoring punch only when the boxers connect with the white portion of the gloves. Each punch that lands cleanly on the head or torso with sufficient force is awarded a point. A referee monitors the fight to ensure that competitors use only legal blows. A belt worn over the torso represents the lower limit of punches – any boxer repeatedly landing low blows below the belt is disqualified. Referees also ensure that the boxers don't use holding tactics to prevent the opponent from swinging. If this occurs, the referee separates the opponents and orders them to continue boxing. Repeated holding can result in a boxer being penalized or ultimately disqualified. Referees will stop the bout if a boxer is seriously injured, if one boxer is significantly dominating the other or if the score is severely imbalanced. Amateur bouts which end this way may be noted as "RSC" (referee stopped contest) with notations for an outclassed opponent (RSCO), outscored opponent (RSCOS), injury (RSCI) or head injury (RSCH).
Professional boxing.
Professional bouts are usually much longer than amateur bouts, typically ranging from ten to twelve rounds, though four-round fights are common for less experienced fighters or club fighters. There are also some two- and three-round professional bouts, especially in Australia. Through the early twentieth century, it was common for fights to have unlimited rounds, ending only when one fighter quit, benefiting high-energy fighters like Jack Dempsey. Fifteen rounds remained the internationally recognized limit for championship fights for most of the twentieth century until the early 1980s, when the death of boxer Duk Koo Kim eventually prompted the World Boxing Council and other organizations sanctioning professional boxing to reduce the limit to twelve rounds.
Headgear is not permitted in professional bouts, and boxers are generally allowed to take much more damage before a fight is halted. At any time, the referee may stop the contest if he believes that one participant cannot defend himself due to injury. In that case, the other participant is awarded a technical knockout win. A technical knockout would also be awarded if a fighter lands a punch that opens a cut on the opponent, and the opponent is later deemed not fit to continue by a doctor because of the cut. For this reason, fighters often employ cutmen, whose job is to treat cuts between rounds so that the boxer is able to continue despite the cut. If a boxer simply quits fighting, or if his corner stops the fight, then the winning boxer is also awarded a technical knockout victory. In contrast with amateur boxing, professional male boxers have to be bare-chested.
Boxing styles.
Definition of style.
"Style" is often defined as the strategic approach a fighter takes during a bout. No two fighters' styles are alike, as it is determined by that individual's physical and mental attributes. Three main styles exist in boxing: outside fighter ("boxer"), brawler (or "slugger"), and Inside fighter ("swarmer"). These styles may be divided into several special subgroups, such as counter puncher, etc. The main philosophy of the styles is, that each style has an advantage over one, but disadvantage over the other one. It follows the rock-paper-scissors scenario - boxer beats brawler, brawler beats swarmer, and swarmer beats boxer.
Boxer/out-fighter.
A classic "boxer" or stylist (also known as an "out-fighter") seeks to maintain distance between himself and his opponent, fighting with faster, longer range punches, most notably the jab, and gradually wearing his opponent down. Due to this reliance on weaker punches, out-fighters tend to win by point decisions rather than by knockout, though some out-fighters have notable knockout records. They are often regarded as the best boxing strategists due to their ability to control the pace of the fight and lead their opponent, methodically wearing him down and exhibiting more skill and finesse than a brawler. Out-fighters need reach, hand speed, reflexes, and footwork.
Notable out-fighters include Muhammad Ali, Larry Holmes, Joe Calzaghe Wilfredo Gómez, 
Salvador Sanchez, Cecilia Brækhus, Gene Tunney, Ezzard Charles, Willie Pep, Meldrick Taylor, Ricardo Lopez, Floyd Mayweather, Roy Jones, Jr., Sugar Ray Leonard, Miguel Vazquez, Sergio "Maravilla" Martínez, Vitali Klitschko, Wladimir Klitschko, and Guillermo Rigondeaux. This style was also used by fictional boxer Apollo Creed.
Boxer-puncher.
A boxer-puncher is a well-rounded boxer who is able to fight at close range with a combination of technique and power, often with the ability to knock opponents out with a combination and in some instances a single shot. Their movement and tactics are similar to that of an out-fighter (although they are generally not as mobile as an out-fighter), but instead of winning by decision, they tend to wear their opponents down using combinations and then move in to score the knockout. A boxer must be well rounded to be effective using this style.
Notable boxer-punchers include Muhammad Ali, Wladimir Klitschko, Lennox Lewis, Joe Louis, Wilfredo Gómez, Oscar de la Hoya, Archie Moore, Miguel Cotto, Nonito Donaire, Sam Langford, Henry Armstrong, Sugar Ray Robinson, Tony Zale, Carlos Monzón, Alexis Argüello, Erik Morales, Terry Norris, Marco Antonio Barrera, Naseem Hamed, Thomas Hearns ,
Counter puncher.
Counter punchers are slippery, defensive style fighters who often rely on their opponent's mistakes in order to gain the advantage, whether it be on the score cards or more preferably a knockout. They use their well-rounded defense to avoid or block shots and then immediately catch the opponent off guard with a well placed and timed punch. A fight with a skilled counter-puncher can turn into a war of attrition, where each shot landed is a battle in itself. Thus, fighting against counter punchers requires constant feinting and the ability to avoid telegraphing one's attacks. To be truly successful using this style they must have good reflexes, a high level of prediction and awareness, pinpoint accuracy and speed, both in striking and in footwork.
Notable counter punchers include Muhammad Ali, Vitali Klitschko, Evander Holyfield, Max Schmeling, Chris Byrd, Jim Corbett, Jack Johnson, Bernard Hopkins, Laszlo Papp, Jerry Quarry, Anselmo Moreno, James Toney, Marvin Hagler, Juan Manuel Márquez, Humberto Soto, Floyd Mayweather, Jr., Roger Mayweather, Pernell Whitaker, Sergio Gabriel Martinez and Guillermo Rigondeaux.
Counter punchers usually wear their opponents down by causing them to miss their punches. The more the opponent misses, the faster they tire, and the psychological effects of being unable to land a hit will start to sink in. The counter puncher often tries to outplay their opponent entirely, not just in a physical sense, but also in a mental and emotional sense. This style can be incredibly difficult, especially against seasoned fighters, but winning a fight without getting hit is often worth the pay-off. They usually try to stay away from the center of the ring, in order to outmaneuver and chip away at their opponents. A large advantage in counter-hitting is the forward momentum of the attacker, which drives them further into your return strike. As such, knockouts are more common than one would expect from a defensive style.
Brawler/slugger.
A brawler is a fighter who generally lacks finesse and footwork in the ring, but makes up for it through sheer punching power. Mainly Irish, Irish-American, Puerto Rican, Mexican, and Mexican-American boxers popularized this style. Many brawlers tend to lack mobility, preferring a less mobile, more stable platform and have difficulty pursuing fighters who are fast on their feet. They may also have a tendency to ignore combination punching in favor of continuous beat-downs with one hand and by throwing slower, more powerful single punches (such as hooks and uppercuts). Their slowness and predictable punching pattern (single punches with obvious leads) often leaves them open to counter punches, so successful brawlers must be able to absorb substantial amounts of punishment. However, not all brawler/slugger fighters are not mobile; some can move around and switch styles if needed but still have the brawler/slugger style such as Wilfredo Gómez, Prince Naseem Hamed and Danny García.
A brawler's most important assets are power and chin (the ability to absorb punishment while remaining able to continue boxing). Examples of this style include George Foreman, Rocky Marciano, Julio Cesar Chavez, Roberto Duran, Danny García, Wilfredo Gómez, Sonny Liston, John L. Sullivan, Max Baer, Prince Naseem Hamed, Ray Mancini, David Tua, Arturo Gatti, Micky Ward, Brandon Ríos, Ruslan Provodnikov, Michael Katsidis, James Kirkland, Marcos Maidana, Jake Lamotta, Manny Pacquiao, and Ireland's John Duddy. This style of boxing was also used by fictional boxers Rocky Balboa and James "Clubber" Lang.
Brawlers tend to be more predictable and easy to hit but usually fare well enough against other fighting styles because they train to take punches very well. They often have a higher chance than other fighting styles to score a knockout against their opponents because they focus on landing big, powerful hits, instead of smaller, faster attacks. Oftentimes they place focus on training on their upper body instead of their entire body, to increase power and endurance. They also aim to intimidate their opponents because of their power, stature and ability to take a punch.
Swarmer/in-fighter.
In-fighters/swarmers (sometimes called "pressure fighters") attempt to stay close to an opponent, throwing intense flurries and combinations of hooks and uppercuts. A successful in-fighter often needs a good "chin" because swarming usually involves being hit with many jabs before they can maneuver inside where they are more effective. In-fighters operate best at close range because they are generally shorter and have less reach than their opponents and thus are more effective at a short distance where the longer arms of their opponents make punching awkward. However, several fighters tall for their division have been relatively adept at in-fighting as well as out-fighting.
The essence of a swarmer is non-stop aggression. Many short in-fighters utilize their stature to their advantage, employing a bob-and-weave defense by bending at the waist to slip underneath or to the sides of incoming punches. Unlike blocking, causing an opponent to miss a punch disrupts his balance, permits forward movement past the opponent's extended arm and keeps the hands free to counter. A distinct advantage that in-fighters have is when throwing uppercuts where they can channel their entire bodyweight behind the punch; Mike Tyson was famous for throwing devastating uppercuts. Marvin Hagler was known for his hard "chin", punching power, body attack and the stalking of his opponents. Some in-fighters, like Mike Tyson, have been known for being notoriously hard to hit. The key to a swarmer is aggression, endurance, chin, and bobbing-and-weaving.
Notable in-fighters include Julio César Chávez, Miguel Cotto, Joe Frazier, Danny García, Mike Tyson, Manny Pacquiao, Saúl Álvarez, Rocky Marciano, Jack Dempsey, Wayne McCullough, Gerry Penalosa, Harry Greb, David Tua, Ricky Hatton and Gennady Golovkin.
Combinations of styles.
All fighters have primary skills with which they feel most comfortable, but truly elite fighters are often able to incorporate auxiliary styles when presented with a particular challenge. For example, an out-fighter will sometimes plant his feet and counter punch, or a slugger may have the stamina to pressure fight with his power punches.
Style matchups.
There is a generally accepted rule of thumb about the success each of these boxing styles has against the others. In general, an in-fighter has an advantage over an out-fighter, an out-fighter has an advantage over a brawler, and a brawler has an advantage over an in-fighter; these form a cycle with each style being stronger relative to one, and weaker relative to another, with none dominating, as in rock-paper-scissors. Naturally, many other factors, such as the skill level and training of the combatants, determine the outcome of a fight, but the widely held belief in this relationship among the styles is embodied in the cliché amongst boxing fans and writers that "styles make fights."
Brawlers tend to overcome swarmers or in-fighters because, in trying to get close to the slugger, the in-fighter will invariably have to walk straight into the guns of the much harder-hitting brawler, so, unless the former has a very good chin and the latter's stamina is poor, the brawler's superior power will carry the day. A famous example of this type of match-up advantage would be George Foreman's knockout victory over Joe Frazier in their original bout "The Sunshine Showdown".
Although in-fighters struggle against heavy sluggers, they typically enjoy more success against out-fighters or boxers. Out-fighters prefer a slower fight, with some distance between themselves and the opponent. The in-fighter tries to close that gap and unleash furious flurries. On the inside, the out-fighter loses a lot of his combat effectiveness, because he cannot throw the hard punches. The in-fighter is generally successful in this case, due to his intensity in advancing on his opponent and his good agility, which makes him difficult to evade. For example, the swarming Joe Frazier, though easily dominated by the slugger George Foreman, was able to create many more problems for the boxer Muhammad Ali in their three fights. Joe Louis, after retirement, admitted that he hated being crowded, and that swarmers like untied/undefeated champ Rocky Marciano would have caused him style problems even in his prime.
The boxer or out-fighter tends to be most successful against a brawler, whose slow speed (both hand and foot) and poor technique makes him an easy target to hit for the faster out-fighter. The out-fighter's main concern is to stay alert, as the brawler only needs to land one good punch to finish the fight. If the out-fighter can avoid those power punches, he can often wear the brawler down with fast jabs, tiring him out. If he is successful enough, he may even apply extra pressure in the later rounds in an attempt to achieve a knockout. Most classic boxers, such as Muhammad Ali, enjoyed their best successes against sluggers.
An example of a style matchup was the historical fight of Julio César Chávez, a swarmer or in-fighter, against Meldrick Taylor, the boxer or out-fighter (see Julio César Chávez vs. Meldrick Taylor). The match was nicknamed "Thunder Meets Lightning" as an allusion to punching power of Chávez and blinding speed of Taylor. Chávez was the epitome of the "Mexican" style of boxing. Taylor's hand and foot speed and boxing abilities gave him the early advantage, allowing him to begin building a large lead on points. Chávez remained relentless in his pursuit of Taylor and due to his greater punching power Chávez slowly punished Taylor. Coming into the later rounds, Taylor was bleeding from the mouth, his entire face was swollen, the bones around his eye socket had been broken, he had swallowed a considerable amount of his own blood, and as he grew tired, Taylor was increasingly forced into exchanging blows with Chávez, which only gave Chávez a greater chance to cause damage. While there was little doubt that Taylor had solidly won the first three quarters of the fight, the question at hand was whether he would survive the final quarter. Going into the final round, Taylor held a secure lead on the scorecards of two of the three judges. Chávez would have to knock Taylor out to claim a victory, whereas Taylor merely needed to stay away from the Mexican legend. However, Taylor did not stay away, but continued to trade blows with Chávez. As he did so, Taylor showed signs of extreme exhaustion, and every tick of the clock brought Taylor closer to victory unless Chávez could knock him out.
With about a minute left in the round, Chávez hit Taylor squarely with several hard punches and stayed on the attack, continuing to hit Taylor with well-placed shots. Finally, with about 25 seconds to go, Chávez landed a hard right hand that caused Taylor to stagger forward towards a corner, forcing Chávez back ahead of him. Suddenly Chávez stepped around Taylor, positioning him so that Taylor was trapped in the corner, with no way to escape from Chávez' desperate final flurry. Chávez then nailed Taylor with a tremendous right hand that dropped the younger man. By using the ring ropes to pull himself up, Taylor managed to return to his feet and was given the mandatory 8-count. Referee Richard Steele asked Taylor twice if he was able to continue fighting, but Taylor failed to answer. Steele then concluded that Taylor was unfit to continue and signaled that he was ending the fight, resulting in a TKO victory for Chávez with only two seconds to go in the bout.
Equipment.
Since boxing involves forceful, repetitive punching, precautions must be taken to prevent damage to bones in the hand. Most trainers do not allow boxers to train and spar without wrist wraps and boxing gloves. Hand wraps are used to secure the bones in the hand, and the gloves are used to protect the hands from blunt injury, allowing boxers to throw punches with more force than if they did not utilize them. Gloves have been required in competition since the late nineteenth century, though modern boxing gloves are much heavier than those worn by early twentieth-century fighters. Prior to a bout, both boxers agree upon the weight of gloves to be used in the bout, with the understanding that lighter gloves allow heavy punchers to inflict more damage. The brand of gloves can also affect the impact of punches, so this too is usually stipulated before a bout. Both sides are allowed to inspect the wraps and gloves of the opponent to help ensure both are within agreed upon specifications and no tampering has taken place.
A mouth guard is important to protect the teeth and gums from injury, and to cushion the jaw, resulting in a decreased chance of knockout. Both fighters must wear soft soled shoes to reduce the damage from accidental (or intentional) stepping on feet. While older boxing boots more commonly resembled those of a professional wrestler, modern boxing shoes and boots tend to be quite similar to their amateur wrestling counterparts.
Boxers practice their skills on two basic types of punching bags. A small, tear-drop-shaped "speed bag" is used to hone reflexes and repetitive punching skills, while a large cylindrical "heavy bag" filled with sand, a synthetic substitute, or water is used to practice power punching and body blows. In addition to these distinctive pieces of equipment, boxers also utilize sport-nonspecific training equipment to build strength, speed, agility, and stamina. Common training equipment includes free weights, rowing machines, jump rope, and medicine balls.
Boxing matches typically take place in a boxing ring, a raised platform surrounded by ropes attached to posts rising in each corner. The term "ring" has come to be used as a metaphor for many aspects of prize fighting in general.
Technique.
Stance.
The modern boxing stance differs substantially from the typical boxing stances of the 19th and early 20th centuries. The modern stance has a more upright vertical-armed guard, as opposed to the more horizontal, knuckles-facing-forward guard adopted by early 20th century hook users such as Jack Johnson.
In a fully upright stance, the boxer stands with the legs shoulder-width apart and the rear foot a half-step in front of the lead man. Right-handed or orthodox boxers lead with the left foot and fist (for most penetration power). Both feet are parallel, and the right heel is off the ground. The lead (left) fist is held vertically about six inches in front of the face at eye level. The rear (right) fist is held beside the chin and the elbow tucked against the ribcage to protect the body. The chin is tucked into the chest to avoid punches to the jaw which commonly cause knock-outs and is often kept slightly off-center. Wrists are slightly bent to avoid damage when punching and the elbows are kept tucked in to protect the ribcage. Some boxers fight from a crouch, leaning forward and keeping their feet closer together. The stance described is considered the "textbook" stance and fighters are encouraged to change it around once it's been mastered as a base. Case in point, many fast fighters have their hands down and have almost exaggerated footwork, while brawlers or bully fighters tend to slowly stalk their opponents.
Left-handed or southpaw fighters use a mirror image of the orthodox stance, which can create problems for orthodox fighters unaccustomed to receiving jabs, hooks, or crosses from the opposite side. The southpaw stance, conversely, is vulnerable to a straight right hand.
North American fighters tend to favor a more balanced stance, facing the opponent almost squarely, while many European fighters stand with their torso turned more to the side. The positioning of the hands may also vary, as some fighters prefer to have both hands raised in front of the face, risking exposure to body shots.
Modern boxers can sometimes be seen tapping their cheeks or foreheads with their fists in order to remind themselves to keep their hands up (which becomes difficult during long bouts). Boxers are taught to push off with their feet in order to move effectively. Forward motion involves lifting the lead leg and pushing with the rear leg. Rearward motion involves lifting the rear leg and pushing with the lead leg. During lateral motion the leg in the direction of the movement moves first while the opposite leg provides the force needed to move the body.
Punches.
There are four basic punches in boxing: the jab, cross, hook and uppercut. Any punch other than a jab is considered a power punch. If a boxer is right-handed (orthodox), his left hand is the lead hand and his right hand is the rear hand. For a left-handed boxer or southpaw, the hand positions are reversed. For clarity, the following discussion will assume a right-handed boxer.
These different punch types can be thrown in rapid succession to form combinations or "combos." The most common is the jab and cross combination, nicknamed the "one-two combo." This is usually an effective combination, because the jab blocks the opponent's view of the cross, making it easier to land cleanly and forcefully.
A large, swinging circular punch starting from a cocked-back position with the arm at a longer extension than the hook and all of the fighter's weight behind it is sometimes referred to as a "roundhouse," "haymaker," or sucker-punch. Relying on body weight and centripetal force within a wide arc, the roundhouse can be a powerful blow, but it is often a wild and uncontrolled punch that leaves the fighter delivering it off balance and with an open guard.
Wide, looping punches have the further disadvantage of taking more time to deliver, giving the opponent ample warning to react and counter. For this reason, the haymaker or roundhouse is not a conventional punch, and is regarded by trainers as a mark of poor technique or desperation. Sometimes it has been used, because of its immense potential power, to finish off an already staggering opponent who seems unable or unlikely to take advantage of the poor position it leaves the puncher in.
Another unconventional punch is the rarely used bolo punch, in which the opponent swings an arm out several times in a wide arc, usually as a distraction, before delivering with either that or the other arm.
An illegal punch to the back of the head or neck is known as a rabbit punch.
Defense.
There are several basic maneuvers a boxer can use in order to evade or block punches, depicted and discussed below.
Less common strategies.
Floyd Mayweather, Jr. employed the use of a check hook against Ricky Hatton, which sent Hatton flying head first into the corner post and being knocked down. Hatton managed to get himself to his feet after the knockdown but was clearly dazed and it was only a matter of moments before Mayweather landed a flurry of punches which sent Hatton crashing to the canvas, giving Mayweather a TKO victory in the 10th round and handing Hatton his first defeat.
Ring corner.
In boxing, each fighter is given a corner of the ring where he rests in between rounds for 1 minute and where his trainers stand. Typically, three men stand in the corner besides the boxer himself; these are the trainer, the assistant trainer and the cutman. The trainer and assistant typically give advice to the boxer on what he is doing wrong as well as encouraging him if he is losing. The cutman is a cutaneous doctor responsible for keeping the boxer's face and eyes free of cuts and blood. This is of particular importance because many fights are stopped because of cuts that threaten the boxer's eyes.
In addition, the corner is responsible for stopping the fight if they feel their fighter is in grave danger of permanent injury. The corner will occasionally throw in a white towel to signify a boxer's surrender (the idiomatic phrase "to throw in the towel", meaning to give up, derives from this practice). This can be seen in the fight between Diego Corrales and Floyd Mayweather. In that fight, Corrales' corner surrendered despite Corrales' steadfast refusal.
Medical concerns.
Knocking a person unconscious or even causing concussion may cause permanent brain damage. There is no clear division between the force required to knock a person out and the force likely to kill a person. Since 1980, more than 200 amateur boxers, professional boxers and Toughman fighters have died due to ring or training injuries. In 1983, the "Journal of the American Medical Association" called for a ban on boxing. The editor, Dr. George Lundberg, called boxing an "obscenity" that "should not be sanctioned by any civilized society." Since then, the British, Canadian and Australian Medical Associations also have called for bans on boxing.
Supporters of the ban state that boxing is the only sport where hurting the other athlete is the goal. Dr. Bill O'Neill, boxing spokesman for the British Medical Association, has supported the BMA's proposed ban on boxing: "It is the only sport where the intention is to inflict serious injury on your opponent, and we feel that we must have a total ban on boxing." Opponents respond that such a position is misguided opinion, stating that amateur boxing is scored solely according to total connecting blows with no award for "injury". They observe that many skilled professional boxers have had rewarding careers without inflicting injury on opponents by accumulating scoring blows and avoiding punches winning rounds scored 10-9 by the 10-point must system, and they note that there are many other sports where concussions are much more prevalent.
In 2007, one study of amateur boxers showed that protective headgear did not prevent brain damage, and another found that amateur boxers faced a high risk of brain damage. The Gothenburg study analyzed temporary levels of neurofiliment light in cerebral spinal fluid which they conclude is evidence of damage, even though the levels soon subside. More comprehensive studies of neurologiocal function on larger samples performed by Johns Hopkins University and accident rates analyzed by National Safety Council show amateur boxing is a comparatively safe sport.
In 1997, the American Association of Professional Ringside Physicians was established to create medical protocols through research and education to prevent injuries in boxing.
Professional boxing is forbidden in Iceland, Iran and North Korea. It was banned in Sweden until 2007 when the ban was lifted but strict restrictions, including four three-minute rounds for fights, were imposed. It was banned in Albania from 1965 till the fall of Communism in 1991; it is now legal there. Norway legalized professional boxing in December 2014.
Boxing Hall of Fame.
The sport of boxing has two internationally recognized boxing halls of fame; the International Boxing Hall of Fame (IBHOF) and the World Boxing Hall of Fame (WBHF), with the IBHOF being the more widely recognized boxing hall of fame.
The WBHF was founded by Everett L. Sanders in 1980. Since its inception the WBHOF has never had a permanent location or museum, which has allowed the more recent IBHOF to garner more publicity and prestige. Among the notable names in the WBHF are Ricardo "Finito" Lopez, Gabriel "Flash" Elorde, Michael Carbajal, Khaosai Galaxy, Henry Armstrong, Jack Johnson, Roberto Durán, George Foreman, Ceferino Garcia and Salvador Sanchez. Boxing's International Hall of Fame was inspired by a tribute an American town held for two local heroes in 1982. The town, Canastota, New York, (which is about east of Syracuse, via the New York State Thruway), honored former world welterweight/middleweight champion Carmen Basilio and his nephew, former world welterweight champion Billy Backus. The people of Canastota raised money for the tribute which inspired the idea of creating an official, annual hall of fame for notable boxers.
The International Boxing Hall of Fame opened in Canastota in 1989. The first inductees in 1990 included Jack Johnson, Benny Leonard, Jack Dempsey, Henry Armstrong, Sugar Ray Robinson, Archie Moore, and Muhammad Ali. Other world-class figures include Salvador Sanchez, Jose Napoles, Roberto "Manos de Piedra" Durán, Ricardo Lopez, Gabriel "Flash" Elorde, Vicente Saldivar, Ismael Laguna, Eusebio Pedroza, Carlos Monzón, Azumah Nelson, Rocky Marciano, Pipino Cuevas and Ken Buchanan. The Hall of Fame's induction ceremony is held every June as part of a four-day event.
The fans who come to Canastota for the Induction Weekend are treated to a number of events, including scheduled autograph sessions, boxing exhibitions, a parade featuring past and present inductees, and the induction ceremony itself.
Boxer rankings.
There are various organizations and websites, that rank boxers in both weight class and pound-for-pound manner.

</doc>
<doc id="4246" url="https://en.wikipedia.org/wiki?curid=4246" title="Bollywood">
Bollywood

Bollywood is the sobriquet for the Hindi language film industry based in Mumbai, the most populous city of the Republic of India. The term is often loosely used as a synecdoche to refer to the whole of Indian cinema; however, Bollywood proper is only a part of the large Indian film industry, which includes other production centres producing films in many languages. 
Bollywood is one of the largest film producers in India, representing 43% of net box office revenue, while Telugu cinema, and Tamil cinema representing 36%, and rest of the regional cinema constitutes 21% as of 2014, Bollywood is also one of the largest centers of film production in the world. It is more formally referred to as Hindi cinema. Bollywood is one of the biggest movie industry in the world in terms of amount of people employed and number of films produced. In 2011, over 3.5 billion tickets were sold across the globe which in comparison is 900,000 tickets more than Hollywood. Bollywood produced 252 films in 2014 out of the total 1969 films produced in India.
Etymology.
The name "Bollywood" is a portmanteau derived from Bombay (the former name for Mumbai) and Hollywood, the center of the American film industry. However, unlike Hollywood, Bollywood does not exist as a physical place. Some deplore the name, arguing that it makes the industry look like a poor cousin to Hollywood.
The naming scheme for "Bollywood" was inspired by "Tollywood", the name that was used to refer to the cinema of West Bengal. Dating back to 1932, "Tollywood" was the earliest Hollywood-inspired name, referring to the Bengali film industry based in Tollygunge, Calcutta, whose name is reminiscent of "Hollywood" and was the centre of the cinema of India at the time. It was this "chance juxtaposition of two pairs of rhyming syllables," Holly and Tolly, that led to the portmanteau name "Tollywood" being coined. The name "Tollywood" went on to be used as a nickname for the Bengali film industry by the popular Kolkata-based "Junior Statesman" youth magazine, establishing a precedent for other film industries to use similar-sounding names, eventually leading to the term "Bollywood" being coined. However, more popularly, Tollywood is now used to refer to the Telugu Film Industry in Telangana & Andhra Pradesh. The term "Bollywood" itself has origins in the 1970s, when India overtook America as the world's largest film producer. Credit for the term has been claimed by several different people, including the lyricist, filmmaker and scholar Amit Khanna, and the journalist Bevinda Collaco.
History.
"Raja Harishchandra" (1913), by Dadasaheb Phalke, is known as the first silent feature film made in India. By the 1930s, the industry was producing over 200 films per annum. The first Indian sound film, Ardeshir Irani's "Alam Ara" (1931), was a major commercial success. There was clearly a huge market for talkies and musicals; Bollywood and all the regional film industries quickly switched to sound filming.
The 1930s and 1940s were tumultuous times: India was buffeted by the Great Depression, World War II, the Indian independence movement, and the violence of the Partition. Most Bollywood films were unabashedly escapist, but there were also a number of filmmakers who tackled tough social issues, or used the struggle for Indian independence as a backdrop for their plots.
In 1937, Ardeshir Irani, of "Alam Ara" fame, made the first colour film in Hindi, "Kisan Kanya". The next year, he made another colour film, a version of "Mother India". However, colour did not become a popular feature until the late 1950s. At this time, lavish romantic musicals and melodramas were the staple fare at the cinema.
Golden Age.
Following India's independence, the period from the late 1940s to the 1960s is regarded by film historians as the "Golden Age" of Hindi cinema. Some of the most critically acclaimed Hindi films of all time were produced during this period. Examples include the Guru Dutt films "Pyaasa" (1957) and "Kaagaz Ke Phool" (1959) and the Raj Kapoor films "Awaara" (1951), "Shree 420" (1955) and Dilip Kumar's "Aan" (1952). These films expressed social themes mainly dealing with working-class urban life in India; "Awaara" presented the city as both a nightmare and a dream, while "Pyaasa" critiqued the unreality of city life. Some of the most famous epic films of Hindi cinema were also produced at the time, including Mehboob Khan's "Mother India" (1957), which was nominated for the Academy Award for Best Foreign Language Film, and K. Asif's "Mughal-e-Azam" (1960). "Madhumati" (1958), directed by Bimal Roy and written by Ritwik Ghatak, popularised the theme of reincarnation in Western popular culture. Other acclaimed mainstream Hindi filmmakers at the time included Kamal Amrohi and Vijay Bhatt. Successful actors at the time included Dev Anand, Dilip Kumar, Raj Kapoor and Guru Dutt, while successful actresses included Nargis, Vyjayanthimala, Meena Kumari, Nutan, Madhubala, Waheeda Rehman and Mala Sinha.
While commercial Hindi cinema was thriving, the 1950s also saw the emergence of a new Parallel Cinema movement. Though the movement was mainly led by Bengali cinema, it also began gaining prominence in Hindi cinema. Early examples of Hindi films in this movement include Chetan Anand's "Neecha Nagar" (1946) and Bimal Roy's "Do Bigha Zamin" (1953). Their critical acclaim, as well as the latter's commercial success, paved the way for Indian neorealism and the "Indian New Wave". Some of the internationally acclaimed Hindi filmmakers involved in the movement included Mani Kaul, Kumar Shahani, Ketan Mehta, Govind Nihalani, Shyam Benegal and Vijaya Mehta.
Ever since the social realist film "Neecha Nagar" won the Grand Prize at the first Cannes Film Festival, Hindi films were frequently in competition for the Palme d'Or at the Cannes Film Festival throughout the 1950s and early 1960s, with some of them winning major prizes at the festival. Guru Dutt, while overlooked in his own lifetime, had belatedly generated international recognition much later in the 1980s. Dutt is now regarded as one of the greatest Asian filmmakers of all time, alongside the more famous Indian Bengali filmmaker Satyajit Ray. The 2002 "Sight & Sound" critics' and directors' poll of greatest filmmakers ranked Dutt at No. 73 on the list. Some of his films are now included among the greatest films of all time, with "Pyaasa" (1957) being featured in Time magazine's "All-TIME" 100 best movies list, and with both "Pyaasa" and "Kaagaz Ke Phool" (1959) tied at No. 160 in the 2002 "Sight & Sound" critics' and directors' poll of all-time greatest films. Several other Hindi films from this era were also ranked in the "Sight & Sound" poll, including Raj Kapoor's "Awaara" (1951), Vijay Bhatt's "Baiju Bawra" (1952), Mehboob Khan's "Mother India" (1957) and K. Asif's "Mughal-e-Azam" (1960) all tied at No. 346 on the list.
Modern cinema.
In the late 1960s and early 1970s, romance movies and action films starred actors like Rajesh Khanna, Dharmendra, Sanjeev Kumar and Shashi Kapoor and actresses like Sharmila Tagore, Mumtaz and Asha Parekh. In the mid-1970s, romantic confections made way for gritty, violent films about gangsters (see Indian mafia) and bandits. Amitabh Bachchan, the star known for his "angry young man" roles, rode the crest of this trend with actors like Mithun Chakraborty, Anil Kapoor and Sunny Deol, which lasted into the early 1990s. Actresses from this era included Hema Malini, Jaya Bachchan and Rekha.
Some Hindi filmmakers such as Shyam Benegal continued to produce realistic Parallel Cinema throughout the 1970s, alongside Mani Kaul, Kumar Shahani, Ketan Mehta, Govind Nihalani and Vijaya Mehta. However, the 'art film' bent of the Film Finance Corporation came under criticism during a Committee on Public Undertakings investigation in 1976, which accused the body of not doing enough to encourage commercial cinema. The 1970s thus saw the rise of commercial cinema in the form of enduring films such as "Sholay" (1975), which consolidated Amitabh Bachchan's position as a lead actor. The devotional classic "Jai Santoshi Ma" was also released in 1975. Another important film from 1975 was "Deewar", directed by Yash Chopra and written by Salim-Javed. A crime film pitting "a policeman against his brother, a gang leader based on real-life smuggler Haji Mastan", portrayed by Amitabh Bachchan; it was described as being "absolutely key to Indian cinema" by Danny Boyle. The most internationally acclaimed Hindi film of the 1980s was Mira Nair's "Salaam Bombay!" (1988), which won the Camera d'Or at the 1988 Cannes Film Festival and was nominated for the Academy Award for Best Foreign Language Film.
During the late 1980s and early 1990s, the pendulum swung back toward family-centric romantic musicals with the success of such films as "Qayamat Se Qayamat Tak" (1988), "Maine Pyar Kiya" (1989), "Dil" (1990), "Hum Aapke Hain Kaun" (1994), "Dilwale Dulhania Le Jayenge" (1995) and "Kuch Kuch Hota Hai" (1998) making stars of a new generation of actors (such as Aamir Khan, Salman Khan and Shahrukh Khan) and actresses (such as Madhuri Dixit, Sridevi, Juhi Chawla). In that point of time, action and comedy films were also successful, with actors like Govinda and actresses such as Raveena Tandon and Karisma Kapoor appearing in popular comedy films, and stunt actor Akshay Kumar gaining popularity for performing dangerous stunts in action films in his well known Khiladi (film series) and other action films. Furthermore, this decade marked the entry of new performers in arthouse and independent films, some of which succeeded commercially, the most influential example being "Satya" (1998), directed by Ram Gopal Varma and written by Anurag Kashyap. The critical and commercial success of "Satya" led to the emergence of a distinct genre known as "Mumbai noir", urban films reflecting social problems in the city of Mumbai. This led to a resurgence of Parallel Cinema by the end of the decade. These films often featured actors like Nana Patekar, Manoj Bajpai, Manisha Koirala, Tabu and Urmila Matondkar, whose performances were usually critically acclaimed.
The 2000s saw a growth in Bollywood's popularity across the world. This led the nation's filmmaking to new heights in terms of production values, cinematography and innovative story lines as well as technical advances in areas such as special effects and animation. Some of the largest production houses, among them Yash Raj Films and Dharma Productions were the producers of new modern films. Some popular films of the decade were "Koi... Mil Gaya" (2003), "Kal Ho Naa Ho" (2003), "Veer-Zaara" (2004), "Dhoom" (2004), "Hum Tum" (2004), "Dhoom 2" (2006), "Krrish" (2006), and "Jab We Met" (2007). These films starred established actors. However, the mid-2000s also saw the rise of popular actors like Hrithik Roshan, Saif Ali Khan, Shahid Kapoor, and Abhishek Bachchan, as well as actresses like Rani Mukerji, Preity Zinta, Aishwarya Rai, Kareena Kapoor, and Priyanka Chopra.
In the early 2010s, established actors like Salman Khan and Akshay Kumar became known for making big-budget "masala" entertainers like "Dabangg" and "Rowdy Rathore" opposite younger actresses like Sonakshi Sinha. These films were often not the subject of critical acclaim, but were nonetheless major commercial successes. While most stars from the 2000s continued their successful careers into the next decade, the 2010s also saw the rise of a new generation of actors like Ranbir Kapoor, Imran Khan, Ranveer Singh, and Arjun Kapoor, as well as actresses like Vidya Balan, Katrina Kaif, Deepika Padukone, Kangana Ranaut, Anushka Sharma, and Parineeti Chopra.
Hindi films can achieve distribution across at least 22 of India’s 29 states. The Hindi film industry has preferred films that appeal to all segments of the audience (see the discussion in Ganti, 2004, cited in references), and has resisted making films that target narrower audiences. It was believed that aiming for a broad spectrum would maximise box office receipts. However, filmmakers may be moving towards accepting some box-office segmentation, between films that appeal to rural Indians, and films that appeal to urban and international audiences.
Influences for Bollywood.
Gokulsing and Dissanayake identify six major influences that have shaped the conventions of Indian popular cinema:
Influence of Bollywood.
Perhaps the biggest influence of Bollywood has been on nationalism in India itself, where along with rest of Indian cinema, it has become part and parcel of the 'Indian story'. In the words of the economist and Bollywood biographer Lord Meghnad Desai,
Cinema actually has been the most vibrant medium for telling India its own story, the story of its struggle for independence, its constant struggle to achieve national integration and to emerge as a global presence.
In the 2000s, Bollywood began influencing musical films in the Western world, and played a particularly instrumental role in the revival of the American musical film genre. Baz Luhrmann stated that his musical film "Moulin Rouge!" (2001) was directly inspired by Bollywood musicals. The film incorporated an Indian-themed play based on the ancient Sanskrit drama "Mṛcchakatika" and a Bollywood-style dance sequence with a song from the film "China Gate". The critical and financial success of "Moulin Rouge!" renewed interest in the then-moribund Western musical genre, and subsequently films such as "Chicago, The Producers, Rent", "Dreamgirls", "Hairspray", "", "Across the Universe", "The Phantom of the Opera", "Enchanted" and "Mamma Mia!" were produced, fuelling a renaissance of the genre.
A. R. Rahman, an Indian film composer, wrote the music for Andrew Lloyd Webber's "Bombay Dreams", and a musical version of "Hum Aapke Hain Koun" has played in London's West End. The Bollywood musical "Lagaan" (2001) was nominated for the Academy Award for Best Foreign Language Film, and two other Bollywood films "Devdas" (2002) and "Rang De Basanti" (2006) were nominated for the BAFTA Award for Best Film Not in the English Language. Danny Boyle's "Slumdog Millionaire" (2008), which has won four Golden Globes and eight Academy Awards, was also directly inspired by Bollywood films, and is considered to be a "homage to Hindi commercial cinema". The theme of reincarnation was also popularised in Western popular culture through Bollywood films, with "Madhumati" (1958) inspiring the Hollywood film "The Reincarnation of Peter Proud" (1975), which in turn inspired the Bollywood film "Karz" (1980), which in turn influenced another Hollywood film "Chances Are" (1989). The 1975 film "Chhoti Si Baat" is believed to have inspired "Hitch" (2005), which in turn inspired the Bollywood film "Partner" (2007).
The influence of Bollywood "filmi" music can also be seen in popular music elsewhere in the world. In 1978, technopop pioneers Haruomi Hosono and Ryuichi Sakamoto of the Yellow Magic Orchestra produced an electronic album "Cochin Moon" based on an experimental fusion between electronic music and Bollywood-inspired Indian music. Devo's 1988 hit song "Disco Dancer" was inspired by the song "I am a Disco Dancer" from the Bollywood film "Disco Dancer" (1982). The 2002 song "Addictive", sung by Truth Hurts and produced by DJ Quik and Dr. Dre, was lifted from Lata Mangeshkar's "Thoda Resham Lagta Hai" from "Jyoti" (1981). The Black Eyed Peas' Grammy Award winning 2005 song "Don't Phunk with My Heart" was inspired by two 1970s Bollywood songs: "Ye Mera Dil Yaar Ka Diwana" from "Don" (1978) and "Ae Nujawan Hai Sub" from "Apradh" (1972). Both songs were originally composed by Kalyanji Anandji, sung by Asha Bhosle, and featured the dancer Helen. Also in 2005, the Kronos Quartet re-recorded several R. D. Burman compositions, with Asha Bhosle as the singer, into an album "You've Stolen My Heart: Songs from R.D. Burman's Bollywood", which was nominated for "Best Contemporary World Music Album" at the 2006 Grammy Awards. "Filmi" music composed by A. R. Rahman (who would later win two Academy Awards for the "Slumdog Millionaire" soundtrack) has frequently been sampled by musicians elsewhere in the world, including the Singaporean artist Kelly Poon, the Uzbek artist Iroda Dilroz, the French rap group La Caution, the American artist Ciara, and the German band Löwenherz, among others. Many Asian Underground artists, particularly those among the overseas Indian diaspora, have also been inspired by Bollywood music.
Genre conventions.
Bollywood films are mostly musicals and are expected to contain catchy music in the form of song-and-dance numbers woven into the script. A film's success often depends on the quality of such musical numbers. Indeed, a film's music is often released before the movie and helps increase the audience.
Indian audiences expect full value for their money, with a good entertainer generally referred to as "paisa" "vasool", (literally, "money's worth"). Songs and dances, love triangles, comedy and dare-devil thrills are all mixed up in a three-hour extravaganza with an intermission. They are called "masala" films, after the Hindi word for a spice mixture. Like "masalas", these movies are a mixture of many things such as action, comedy, romance and so on. Most films have heroes who are able to fight off villains all by themselves.
Bollywood plots have tended to be melodramatic. They frequently employ formulaic ingredients such as star-crossed lovers and angry parents, love triangles, family ties, sacrifice, corrupt politicians, kidnappers, conniving villains, courtesans with hearts of gold, long-lost relatives and siblings separated by fate, dramatic reversals of fortune, and convenient coincidences.
There have always been Indian films with more artistic aims and more sophisticated stories, both inside and outside the Bollywood tradition (see Parallel Cinema). They often lost out at the box office to movies with more mass appeal. Bollywood conventions are changing, however. A large Indian diaspora in English-speaking countries, and increased Western influence at home, have nudged Bollywood films closer to Hollywood models.
Film critic Lata Khubchandani writes, "our earliest films ... had liberal doses of sex and kissing scenes in them. Strangely, it was after Independence the censor board came into being and so did all the strictures." Plots now tend to feature Westernised urbanites dating and dancing in clubs rather than centring on pre-arranged marriages. Though these changes can widely be seen in contemporary Bollywood, traditional conservative ways of Indian culture continue to exist in India outside the industry and an element of resistance by some to western-based influences. Despite this, Bollywood continues to play a major role in fashion in India. Some studies into fashion in India have revealed that some people are unaware that the changing nature of fashion in Bollywood films are often influenced by globalisation; many consider the clothes worn by Bollywood actors as authentically Indian.
Cast and crew.
Bollywood employs people from all parts of India. It attracts thousands of aspiring actors and actresses, all hoping for a break in the industry. Models and beauty contestants, television actors, theatre actors and even common people come to Mumbai with the hope and dream of becoming a star. Just as in Hollywood, very few succeed. Since many Bollywood films are shot abroad, many foreign extras are employed too.
Very few non-Indian actors are able to make a mark in Bollywood, though many have tried from time to time. There have been some exceptions, of which one recent example is the hit film "Rang De Basanti", where the lead actress is Alice Patten, an Englishwoman. "Kisna", "Lagaan", and "" also featured foreign actors. Of late, Emma Brown Garett, an Australian born actress, has starred in a few Indian films.
Bollywood can be very clannish, and the relatives of film-industry insiders have an edge in getting coveted roles in films or being part of a film's crew. However, industry connections are no guarantee of a long career: competition is fierce and if film industry scions do not succeed at the box office, their careers will falter. Some of the biggest stars, such as Shah Rukh Khan, Madhuri Dixit, Rajesh Khanna, Dharmendra, and Akshay Kumar have succeeded despite a lack of any show business connections. For film clans, see List of Hindi film clans.
Sound.
Sound in Bollywood films was once rarely recorded on location (otherwise known as sync sound). Therefore, the sound was usually created (or re-created) entirely in the studio, with the actors reciting their lines as their images appear on-screen in the studio in the process known as "looping in the sound" or ADR—with the foley and sound effects added later. This created several problems, since the sound in these films usually occurs a frame or two earlier or later than the mouth movements or gestures. The actors had to act twice: once on-location, once in the studio—and the emotional level on set is often very difficult to re-create. Commercial Indian films, not just the Hindi-language variety, are known for their lack of ambient sound, so there is a silence underlying everything instead of the background sound and noises usually employed in films to create aurally perceivable depth and environment.
The ubiquity of ADR in Bollywood cinema became prevalent in the early 1960s with the arrival of the Arriflex 3 camera, which required a blimp (cover) to shield the sound of the camera, for which it was notorious, from on-location filming. Commercial Indian filmmakers, known for their speed, never bothered to blimp the camera, and its excessive noise required that everything had to be re-created in the studio. Eventually, this became the standard for Indian films.
The trend was bucked in 2001, after a 30-year hiatus of synchronised sound, with the film "Lagaan", in which producer-star Aamir Khan insisted that the sound be done on location. This opened up a heated debate on the use and economic feasibility of on-location sound, and several Bollywood films have employed on-location sound since then.
Makeup.
In 1955 the Bollywood group Cine Costume Make-Up Artist & Hair Dressers' Association (CCMAA) created a rule that did not allow women to obtain memberships as makeup artists. However, in 2014 the Supreme Court of India ruled that this rule was in violation of the Indian constitutional guarantees granted under Article 14 (right to equality), 19(1)(g) (freedom to carry out any profession) and Article 21 (right to liberty). The judges of the Supreme Court of India stated that the ban on women makeup artist members had no "rationale nexus" to the cause sought to be achieved and was "unacceptable, impermissible and inconsistent" with the constitutional rights guaranteed to the citizens. The Court also found illegal the rule which mandated that for any artist, female or male, to work in the industry, they must have domicile status of five years in the state where they intend to work. In 2015 it was announced that Charu Khurana had become the first woman to be registered by the Cine Costume Make-Up Artist & Hair Dressers' Association.
Bollywood song and dance.
Bollywood film music is called filmi music (from Hindi, meaning "of films"). Songs from Bollywood movies are generally pre-recorded by professional playback singers, with the actors then lip synching the words to the song on-screen, often while dancing. While most actors, especially today, are excellent dancers, few are also singers. One notable exception was Kishore Kumar, who starred in several major films in the 1950s while also having a stellar career as a playback singer. K. L. Saigal, Suraiyya, and Noor Jehan were also known as both singers and actors. Some actors in the last thirty years have sung one or more songs themselves; for a list, see Singing actors and actresses in Indian cinema.
Songs are what make and break the movie; they determine if it is going to be a flop or a hit: “Few films without successful musical tracks, and even fewer without any songs and dances, succeed” With the increase of globalization, there has also been a change in the type of music that Bollywood films entail; the lyrics of the songs have increasingly been a mix of Hindi and English languages, as opposed to the strict Hindi prior to Globalization. Also, with the inspiration of global trends, such as Salsa, Pop and Hip Hop, there has been a modification of the type of music heard in Bollywood films.
Playback singers are prominently featured in the opening credits and have their own fans who will go to an otherwise lackluster movie just to hear their favourites. Going by the quality as well as the quantity of the songs they rendered, most notable singers of Bollywood are Lata Mangeshkar, Asha Bhosle, Geeta Dutt, Shamshad Begum, Kavita Krishnamurthy, Sadhana Sargam and Alka Yagnik among female playback singers; and K. L. Saigal, Talat Mahmood, Mukesh, Mohammed Rafi, Manna Dey, Hemant Kumar, Kishore Kumar, Kumar Sanu, Udit Narayan and Sonu Nigam among male playback singers. Kishore Kumar and Mohammed Rafi are often considered arguably the finest of the singers that have lent their voice to Bollywood songs, followed by Lata Mangeshkar, who, through the course of a career spanning over six decades, has recorded thousands of songs for Indian movies. The composers of film music, known as music directors, are also well-known. Their songs can make or break a film and usually do. Remixing of film songs with modern beats and rhythms is a common occurrence today, and producers may even release remixed versions of some of their films' songs along with the films' regular soundtrack albums.
The dancing in Bollywood films, especially older ones, is primarily modelled on Indian dance: classical dance styles, dances of historic northern Indian courtesans (tawaif), or folk dances. In modern films, Indian dance elements often blend with Western dance styles (as seen on MTV or in Broadway musicals), though it is usual to see Western pop "and" pure classical dance numbers side by side in the same film. The hero or heroine will often perform with a troupe of supporting dancers. Many song-and-dance routines in Indian films feature unrealistically instantaneous shifts of location or changes of costume between verses of a song. If the hero and heroine dance and sing a duet, it is often staged in beautiful natural surroundings or architecturally grand settings. This staging is referred to as a "picturisation".
Songs typically comment on the action taking place in the movie, in several ways. Sometimes, a song is worked into the plot, so that a character has a reason to sing. Other times, a song is an externalisation of a character's thoughts, or presages an event that has not occurred yet in the plot of the movie. In this case, the event is often two characters falling in love. The songs are also often referred to as a "dream sequence", and anything can happen that would not normally happen in the real world.
Previously song and dance scenes often used to be shot in Kashmir, but due to political unrest in Kashmir since the end of the 1980s, those scenes have since then often been shot in Western Europe, particularly in Switzerland and Austria.
Renowned contemporary Bollywood dancers include Hrithik Roshan, Ranbir Kapoor, Aishwarya Rai Bachchan, Madhuri Dixit, Malaika Arora Khan, and Shahid Kapoor. Older Bollywood dancers are people such as Helen, known for her cabaret numbers, Cuckoo Moray, Parveen Babi, Waheeda Rahman, Meena Kumari, and Shammi Kapoor.
For the last few decades Bollywood producers have been releasing the film's soundtrack, as tapes or CDs, before the main movie release, hoping that the music will pull audiences into the cinema later. Often the soundtrack is more popular than the movie. In the last few years some producers have also been releasing music videos, usually featuring a song from the film. However, some promotional videos feature a song which is not included in the movie.
Dialogues and lyrics.
The film script or lines of dialogue (called "dialogues" in Indian English) and the song lyrics are often written by different people.
Dialogues are usually written in an unadorned Hindi that would be understood by the largest possible audience. Some movies, however, have used regional dialects to evoke a village setting, or old-fashioned, courtly, Persian-influenced Urdu in Mughal era historical films. Jyotika Virdi, in her book "The cinematic imagiNation" , wrote about the presence of Urdu in Hindi films: "Urdu is often used in film titles, screenplay, lyrics, the language of love, war, and martyrdom." However, she further discussed its decline over the years: "The extent of Urdu used in commercial Hindi cinema has not been stable ... the decline of Urdu is mirrored in Hindi films ... It is true that many Urdu words have survived and have become part of Hindi cinema's popular vocabulary. But that is as far as it goes." Contemporary mainstream movies also make great use of English. According to "Bollywood Audiences Editorial", "English has begun to challenge the ideological work done by Urdu." Some movie scripts are first written in Latin script. Characters may shift from one language to the other to express a certain atmosphere (for example, English in a business setting and Hindi in an informal one).
Cinematic language, whether in dialogues or lyrics, is often melodramatic and invokes God, family, mother, duty, and self-sacrifice liberally. Song lyrics are often about love. Bollywood song lyrics, especially in the old movies, frequently use the poetic vocabulary of court Urdu, with many Persian loanwords. Another source for love lyrics is the long Hindu tradition of poetry about the amours of Krishna, Radha, and the gopis, as referenced in films such as "Jhanak Jhanak Payal Baje" and "Lagaan".
Music directors often prefer working with certain lyricists, to the point that the lyricist and composer are seen as a team. This phenomenon is compared to the pairings of American composers and songwriters that created old-time Broadway musicals.
Finances.
Bollywood films are multi-million dollar productions, with the most expensive productions costing up to 1 billion rupees (roughly USD 20 million). The latest Science fiction movie "Ra.One" was made at an immense budget of 1.35 billion (roughly USD 27 million), making it the most expensive movie ever produced in Bollywood. Sets, costumes, special effects, and cinematography were less than world-class up until the mid-to-late 1990s, although with some notable exceptions. As Western films and television gain wider distribution in India itself, there is an increasing pressure for Bollywood films to attain the same production levels, particularly in areas such as action and special effects. Recent Bollywood films have employed international technicians to improve in these areas, such as "Krrish" (2006) which has action choreographed by Hong Kong based Tony Ching. The increasing accessibility to professional action and special effects, coupled with rising film budgets, has seen an explosion in the action and sci-fi genres.
Sequences shot overseas have proved a real box office draw, so Mumbai film crews are increasingly filming in Australia, Canada, New Zealand, the United Kingdom, the United States, continental Europe and elsewhere. Nowadays, Indian producers are winning more and more funding for big-budget films shot within India as well, such as "Lagaan", "Devdas" and other recent films.
Funding for Bollywood films often comes from private distributors and a few large studios. Indian banks and financial institutions were forbidden from lending money to movie studios. However, this ban has now been lifted. As finances are not regulated, some funding also comes from illegitimate sources, such as the Mumbai underworld. The Mumbai underworld has been known to be involved in the production of several films, and are notorious for patronising several prominent film personalities. On occasion, they have been known to use money and muscle power to get their way in cinematic deals. In January 2000, Mumbai mafia hitmen shot Rakesh Roshan, a film director and father of star Hrithik Roshan. In 2001, the Central Bureau of Investigation seized all prints of the movie "Chori Chori Chupke Chupke" after the movie was found to be funded by members of the Mumbai underworld.
Another problem facing Bollywood is widespread copyright infringement of its films. Often, bootleg DVD copies of movies are available before the prints are officially released in cinemas. Manufacturing of bootleg DVD, VCD, and VHS copies of the latest movie titles is a well established 'small scale industry' in parts of South Asia and South East Asia. The Federation of Indian Chambers of Commerce and Industry (FICCI) estimates that the Bollywood industry loses $100 million annually in loss of revenue from unlicensed home videos and DVDs. Besides catering to the homegrown market, demand for these copies is large amongst some sections of the Indian diaspora, too. (In fact, bootleg copies are the only way people in Pakistan can watch Bollywood movies, since the Government of Pakistan has banned their sale, distribution and telecast). Films are frequently broadcast without compensation by countless small cable TV companies in India and other parts of South Asia. Small convenience stores run by members of the Indian diaspora in the US and the UK regularly stock tapes and DVDs of dubious provenance, while consumer copying adds to the problem. The availability of illegal copies of movies on the Internet also contributes to the industry's losses.
Satellite TV, television and imported foreign films are making huge inroads into the domestic Indian entertainment market. In the past, most Bollywood films could make money; now fewer tend to do so. However, most Bollywood producers make money, recouping their investments from many sources of revenue, including selling ancillary rights. There are also increasing returns from theatres in Western countries like the United Kingdom, Canada, and the United States, where Bollywood is slowly getting noticed. As more Indians migrate to these countries, they form a growing market for upscale Indian films.
For a comparison of Hollywood and Bollywood financial figures, see chart. It shows tickets sold in 2002 and total revenue estimates. Bollywood sold 3.6 billion tickets and had total revenues (theatre tickets, DVDs, television and so on.) of US$1.3 billion, whereas Hollywood films sold 2.6 billion tickets and generated total revenues (again from all formats) of US$51 billion.
Advertising.
Many Indian artists used to make a living by hand-painting movie billboards and posters (The well-known artist M.F. Hussain used to paint film posters early in his career). This was because human labour was found to be cheaper than printing and distributing publicity material. Now, a majority of the huge and ubiquitous billboards in India's major cities are created with computer-printed vinyl. The old hand-painted posters, once regarded as ephemera, are becoming increasingly collectible as folk art.
Releasing the film music, or music videos, before the actual release of the film can also be considered a form of advertising. A popular tune is believed to help pull audiences into the theatres.
Bollywood publicists have begun to use the Internet as a venue for advertising. Most of the better-funded film releases now have their own websites, where browsers can view trailers, stills, and information about the story, cast, and crew.
Bollywood is also used to advertise other products. Product placement, as used in Hollywood, is widely practised in Bollywood.
Bollywood movie stars appear in print and television advertisements for other products, such as watches or soap (see Celebrity endorsement). Advertisers say that a star endorsement boosts sales.
International Shoots.
With the increasing prominence of international setting such as Switzerland, Paris, New York and so on, it does not entail that the people and cultures residing in these exotic settings are represented. Contrary to these spaces and geographies being filmed as they are, they are actually Indianized by adding Bollywood actors and Hindi speaking extras to them. While immersing in Bollywood films, viewers get to see their local experiences duplicated in different locations around the world.
Rao states that “Media representation can depict India’s shifting relation with the world economy, but must retain its ‘‘Indianness’’ in moments of dynamic hybridity” , where “Indianness” refers to the cultural identity and political affiliation. With Bollywood’s popularity among diasporic audiences, “Indianness” poses a problem, but at the same time, it gives back to its homeland audience, a sense of uniqueness from other immigrant groups.
Awards.
The Filmfare Awards ceremony is one of the most prominent film events given for Hindi films in India. The Indian screen magazine "Filmfare" started the first Filmfare Awards in 1954, and awards were given to the best films of 1953. The ceremony was referred to as the "Clare Awards" after the magazine's editor. Modelled after the poll-based merit format of the Academy of Motion Picture Arts and Sciences, individuals may submit their votes in separate categories. A dual voting system was developed in 1956. The Filmfare awards are frequently accused of bias towards commercial success rather than artistic merit.
As the Filmfare, the National Film Awards were introduced in 1954. Since 1973, the Indian government has sponsored the National Film Awards, awarded by the government run Directorate of Film Festivals (DFF). The DFF screens not only Bollywood films, but films from all the other regional movie industries and independent/art films. These awards are handed out at an annual ceremony presided over by the President of India. Under this system, in contrast to the National Film Awards, which are decided by a panel appointed by Indian Government, the Filmfare Awards are voted for by both the public and a committee of experts.
Prestigious Film Awards ceremonies held within India are:
Prestigious Film Awards Ceremonies held overseas are:
Most of these award ceremonies are lavishly staged spectacles, featuring singing, dancing, and numerous celebrities.
Popularity and appeal.
Besides being popular among the India diaspora, such far off locations as Nigeria to Egypt to Senegal and to Russia generations of non-Indian fans have grown up with Bollywood during the years, bearing witness to the cross-cultural appeal of Indian movies. Over the last years of the 20th century and beyond, Bollywood progressed in its popularity as it entered the consciousness of Western audiences and producers, with Western actors now actively seeking roles in Bollywood movies.
Africa.
Historically, Hindi films have been distributed to some parts of Africa, largely by Lebanese businessmen. "Mother India" (1957), for example, continued to be played in Nigeria decades after its release. Indian movies have also gained ground so as to alter the style of Hausa fashions, songs have also been copied by Hausa singers and stories have influenced the writings of Nigerian novelists. Stickers of Indian films and stars decorate taxis and buses in Northern Nigeria, while posters of Indian films adorn the walls of tailor shops and mechanics' garages in the country. Unlike in Europe and North America where Indian films largely cater to the expatriate Indian market yearning to keep in touch with their homeland, in West Africa, as in many other parts of the world, such movies rose in popularity despite the lack of a significant Indian audience, where movies are about an alien culture, based on a religion wholly different, and, for the most part, a language that is unintelligible to the viewers. One such explanation for this lies in the similarities between the two cultures. Other similarities include wearing turbans; the presence of animals in markets; porters carrying large bundles, chewing sugar cane; youths riding Bajaj motor scooters; wedding celebrations, and so forth. With the strict Muslim culture, Indian movies were said to show "respect" toward women, where Hollywood movies were seen to have "no shame". In Indian movies women were modestly dressed, men and women rarely kiss, and there is no nudity, thus Indian movies are said to "have culture" that Hollywood films lack. The latter choice was a failure because "they don't base themselves on the problems of the people," where the former is based socialist values and on the reality of developing countries emerging from years of colonialism. Indian movies also allowed for a new youth culture to follow without such ideological baggage as "becoming western."
Several Bollywood personalities have avenued to the continent for both shooting movies and off-camera projects. The film "Padmashree Laloo Prasad Yadav" (2005) was one of many movies shot in South Africa. "Dil Jo Bhi Kahey" (2005) was shot almost entirely in Mauritius, which has a large ethnically Indian population.
Ominously, however, the popularity of old Bollywood versus a new, changing Bollywood seems to be diminishing the popularity on the continent. The changing style of Bollywood has begun to question such an acceptance. The new era features more sexually explicit and violent films. Nigerian viewers, for example, commented that older films of the 1950s and 1960s had culture to the newer, more westernised picturisations. The old days of India avidly "advocating decolonization ... and India's policy was wholly influenced by his missionary zeal to end racial domination and discrimination in the African territories" were replaced by newer realities. The emergence of Nollywood, Africa's local movie industry has also contributed to the declining popularity of Bollywood films. A greater globalised world worked in tandem with the sexualisation of Indian films so as to become more like American films, thus negating the preferred values of an old Bollywood and diminishing Indian soft power.
Additionally, classic Bollywood actors like Kishore Kumar and Amitabh Bachchan have historically enjoyed popularity in Egypt and Somalia. In Ethiopia, Bollwood movies are shown alongside Hollywood productions in Piazza theatres, such as the Cinema Ethiopia in Addis Ababa. In the Maghreb, Bollywood films are also broadcast, though local aesthetics tend much more toward expressive or auteur cinema than commercial fare.
Asia.
Bollywood films are widely watched in South Asian countries, including Afghanistan, Bangladesh, Nepal, Pakistan and Sri Lanka.
Many Pakistanis watch Bollywood films, as they understand Hindi (due to its linguistic similarity to Urdu). Pakistan banned the legal import of Bollywood movies in 1965. However, trade in unlicensed DVDs and illegal cable broadcasts ensured the continued popularity of Bollywood releases in Pakistan. Exceptions were made for a few films, such as the 2006 colorised re-release of the classic "Mughal-e-Azam" or the 2006 film "Taj Mahal". Early in 2008, the Pakistani government eased the ban and allowed the import of even more movies; 16 were screened in 2008. Continued easing followed in 2009 and 2010. The new policy is opposed by nationalists and representatives of Pakistan's small film industry but is embraced by cinema owners, who are making profits after years of low receipts.
Bollywood movies are so much popular in Nepal that, Bollywood movies earn more than Nepali movies. Actors like Shah Rukh Khan, Salman Khan, Akshay Kumar are most popular in Nepal and their movies sees the audience full pack all over the Cinema halls and also are so popular in Afghanistan due to the country's proximity to the Indian subcontinent and cultural perspectives present in the movies. A number of Bollywood movies were filmed inside Afghanistan while some dealt with the country, including "Dharmatma", "Kabul Express", "Khuda Gawah" and "Escape From Taliban". Hindi films have been popular in Arab countries, including Palestine, Jordan, Egypt and the Gulf countries.
Imported Indian films are usually subtitled in Arabic upon the film's release. Since the early 2000s, Bollywood has progressed in Israel. Special channels dedicated to Indian films have been displayed on cable television. Bollywood films are popular in Southeast Asia (particularly in Maritime Southeast Asia) and Central Asia (particularly in Uzbekistan and Tajikistan).
Bollywood films are widely appreciated in East Asian countries such as China, Japan, and South Korea. Some Hindi movies had success in the China and South Korea, Japan in the 1940s and 1950s and are popular till today. The most popular Hindi films in that country were "Dr. Kotnis Ki Amar Kahani" (1946), "Awaara" (1951) and "Do Bigha Zamin" (1953). Raj Kapoor was a famous movie star in China, and the song "Awara Hoon" ("I am a Tramp") was popular in the country. Since then, Hindi films significantly declined in popularity in China, until the Academy Award nominated "Lagaan" (2001) became the first Indian film to have a nationwide release there in decades. The Chinese filmmaker He Ping was impressed by "Lagaan", especially its soundtrack, and thus hired the film's music composer A. R. Rahman to score the soundtrack for his film "Warriors of Heaven and Earth" (2003). Several older Hindi films have a cult following in Japan, particularly the films directed by Guru Dutt.
Indian films are the most popular foreign films in Tajikistan, and Hindi-Urdu departments are very large in the country.
Middle East/North Africa.
Bollywood movies and celebrities enjoy wide popularity and appeal in the Arab world. There are channels such as MBC Bollywood and Zee Aflam, which show Hindi movies and serials. In Egypt, Bollywood movies used to be massively popular in the 1970's and 1980's. In 1987 however, Bollywood films were restricted to only a handful of films by the Egyptian Government. Bollywood movies are regularly screened in Dubai cinemas because of the high demand. Recently in Turkey, Bollywood has been gaining popularity as Barfi! was the first Hindi film to have a wide theatrical release.
Europe.
The awareness of Hindi cinema is substantial in the United Kingdom, where they frequently enter the UK top ten. Many films, such as "Kabhi Khushi Kabhie Gham" (2001) have been set in London. Bollywood is also appreciated in France, Germany, the Netherlands, and the Scandinavian countries. Various Bollywood movies are dubbed in German and shown on the German television channel RTL II on a regular basis.
Bollywood films are particularly popular in the former Soviet Union. Bollywood films have been dubbed into Russian, and shown in prominent theatres such as Mosfilm and Lenfilm.
Ashok Sharma, Indian Ambassador to Suriname, who has served three times in the Commonwealth of Independent States region during his diplomatic career said:
The film "Mera Naam Joker" (1970), sought to cater to such an appeal and the popularity of Raj Kapoor in Russia, when it recruited Russian actress Kseniya Ryabinkina for the movie. In the contemporary era, "" (2005) was shot entirely in Russia. After the collapse of the Soviet film distribution system, Hollywood occupied the void created in the Russian film market. This made things difficult for Bollywood as it was losing market share to Hollywood. However, Russian newspapers report that there is a renewed interest in Bollywood among young Russians.
North America.
Bollywood has experienced a marked growth in revenue in Canada and the United States, particularly popular amongst the South Asian communities in large cities, such as Toronto, Chicago, and New York City. Yash Raj Films, one of India's largest production houses and distributors, reported in September 2005 that Bollywood films in the United States earn around $100 million a year through theatre screenings, video sales and the sale of movie soundtracks. In other words, films from India do more business in the United States than films from any other non-English speaking country. Numerous films in the mid-1990s and onwards have been largely, or entirely, shot in New York, Los Angeles, Vancouver and Toronto. Bollywood's immersion in the traditional Hollywood domain was further tied with such films as "The Guru" (2002) and "" (2007) trying to popularise the Bollywood-theme for Hollywood.
Oceania.
Bollywood is not as successful in the Oceanic countries and Pacific Islands such as New Guinea. However, it ranks second to Hollywood in countries such as Fiji, with its large Indian minority, Australia and New Zealand.
Australia is one of the countries where there is a large South Asian Diaspora. Bollywood is popular amongst non-Asians in the country as well. Since 1997 the country has provided a backdrop for an increasing number of Bollywood films. Indian filmmakers have been attracted to Australia's diverse locations and landscapes, and initially used it as the setting for song-and-dance sequences, which demonstrated the contrast between the values. However, nowadays, Australian locations are becoming more important to the plot of Bollywood films. Hindi films shot in Australia usually incorporate aspects of Australian lifestyle. The Yash Raj Film "Salaam Namaste" (2005) became the first Indian film to be shot entirely in Australia and was the most successful Bollywood film of 2005 in the country. This was followed by "Heyy Babyy" (2007) "Chak De! India" (2007) and "Singh Is Kinng" (2008) which turned out to be box office successes. Following the release of "Salaam Namaste", on a visit to India the then prime minister John Howard also sought, having seen the film, to have more Indian movies shooting in the country to boost tourism, where the Bollywood and cricket nexus, was further tightened with Steve Waugh's appointment as tourism ambassador to India. Australian actress Tania Zaetta, who co-starred in "Salaam Namaste", among other Bollywood films, expressed her keenness to expand her career in Bollywood.
South America.
Bollywood movies are not influential in many countries of South America, though Bollywood culture and dance is recognised. However, due to significant South Asian diasporic communities in Suriname and Guyana, Hindi-language movies are popular. In 2006, "Dhoom 2" became the first Bollywood film to be shot in Rio de Janeiro, Brazil.
In January 2012, it was announced that UTV Motion Pictures would be releasing movies in Peru, starting with "Guzaarish".
Plagiarism.
Constrained by rushed production schedules and small budgets, some Bollywood writers and musicians have been known to resort to plagiarism. Ideas, plot lines, tunes or riffs have been copied from other Indian film industries or foreign films (including Hollywood and other Asian films) without acknowledgement of the original source. This has led to criticism towards the film industry.
Before the 1990s, this could be done with impunity. Copyright enforcement was lax in India and few actors or directors ever saw an official contract. The Hindi film industry was not widely known to non-Indian audiences (excluding the Soviet states), who would not even be aware that their material was being copied. Audiences may also not have been aware of the plagiarism since many audiences in India were unfamiliar with foreign films and music. While copyright enforcement in India is still somewhat lenient, Bollywood and other film industries are much more aware of each other now and Indian audiences are more familiar with foreign movies and music. Organisations like the India EU Film Initiative seek to foster a community between film makers and industry professional between India and the EU.
One of the common justifications of plagiarism in Bollywood in the media is that producers often play a safer option by remaking popular Hollywood films in an Indian context. Screenwriters generally produce original scripts, but due to financial uncertainty and insecurity over the success of a film many were rejected. Screenwriters themselves have been criticised for lack of creativity which happened due to tight schedules and restricted funds in the industry to employ better screenwriters. Certain filmmakers see plagiarism in Bollywood as an integral part of globalisation where American and western cultures are firmly embedding themselves into Indian culture, which is manifested, amongst other mediums, in Bollywood films. Vikram Bhatt, director of films such as "Raaz", a remake of "What Lies Beneath", and "Kasoor", a remake of "Jagged Edge", has spoken about the strong influence of American culture and desire to produce box office hits based along the same lines in Bollywood. He said, "Financially, I would be more secure knowing that a particular piece of work has already done well at the box office. Copying is endemic everywhere in India. Our TV shows are adaptations of American programmes. We want their films, their cars, their planes, their Diet Cokes and also their attitude. The American way of life is creeping into our culture." Mahesh Bhatt has said, "If you hide the source, you're a genius. There's no such thing as originality in the creative sphere".
There have been very few cases of film copyright violations taken to court because of serious delays in the legal process, and due to the long time they take to decide a case. There have been some notable cases of conflict though. The makers of "Partner" (2007) and "Zinda" (2005) have been targeted by the owners and distributors of the original films, "Hitch" and "Oldboy". American Studio Twentieth Century Fox brought the Mumbai-based B.R. Films to court over its forthcoming "Banda Yeh Bindaas Hai", allegedly an illegal remake of its 1992 film "My Cousin Vinny". B.R. Films eventually settled out of court by paying the studio at a cost of about $200,000, paving the way for the film's release. Some on the other hand do comply with copyright law, with Orion Pictures in 2008 securing the rights to remake the Hollywood film "Wedding Crashers".

</doc>
<doc id="4248" url="https://en.wikipedia.org/wiki?curid=4248" title="Bowls">
Bowls

Bowls or lawn bowls is a sport in which the objective is to roll biased balls so that they stop close to a smaller ball called a "jack" or "kitty". It is played on a bowling green which may be flat (for "flat-green bowls") or convex or uneven (for "crown green bowls"). It is normally played outdoors (although there are many indoor venues) and the outdoor surface is either natural grass, artificial turf, or cotula (in New Zealand).
History.
It has been traced certainly to the 13th century, and conjecturally to the 12th. William Fitzstephen (d. about 1190), in his biography of Thomas Becket, gives a graphic sketch of the London of his day and, writing of the summer amusements of the young men, says that on holidays they were "exercised in Leaping, Shooting, Wrestling, Casting of Stones jactu lapidum, and Throwing of Javelins fitted with Loops for the Purpose, which they strive to fling before the Mark; they also use Bucklers, like fighting Men." It is commonly supposed that by jactus lapidum, Fitzstephen meant the game of bowls, but though it is possible that round stones may sometimes have been employed in an early variety of the game - and there is a record of iron bowls being used, though at a much later date, on festive occasions at Nairn, - nevertheless the inference seems unwarranted. The jactus lapidum of which he speaks may have been more akin to shotput. It is beyond dispute, however, that the game, at any rate in a rudimentary form, was played in the 13th century. A manuscript of that period in the royal library, Windsor (No. 20, E iv.), contains a drawing representing two players aiming at a small cone instead of an earthenware ball or jack. The world's oldest surviving bowling green is the Southampton Old Bowling Green, which was first used in 1299.
Another manuscript of the same century has a crude but spirited picture which brings us into close touch with the existing game. Three figures are introduced and a jack. The first player's bowl has come to rest just in front of the jack; the second has delivered his bowl and is following after it with one of those eccentric contortions still not unusual on modern greens, the first player meanwhile making a repressive gesture with his hand, as if to urge the bowl to stop short of his own; the third player is depicted as in the act of delivering his bowl. A 14th-century manuscript, Book of Prayers, in the Francis Douce collection in the Bodleian Library at Oxford contains a drawing in which two persons are shown, but they bowl to no mark. Strutt (Sports and Pastimes) suggests that the first player's bowl may have been regarded by the second player as a species of jack; but in that case it is not clear what was the first player's target. In these three earliest illustrations of the pastime it is worth noting that each player has one bowl only, and that the attitude in delivering it was as various five or six hundred years ago as it is today. In the third he stands almost upright; in the first he kneels; in the second he stoops, halfway between the upright and the kneeling position.
The game eventually came under the ban of king and parliament, both fearing it might jeopardise the practice of archery, then so important in battle. Statutes forbidding it and other sports were enacted in the reigns of Edward III, Richard II and other monarchs. Even when, on the invention of gunpowder and firearms, the bow had fallen into disuse as a weapon of war, the prohibition was continued. The discredit attaching to bowling alleys, first established in London in 1455, probably encouraged subsequent repressive legislation, for many of the alleys were connected with taverns frequented by the dissolute and gamesters. The word "bowls" occurs for the first time in the statute of 1511 in which Henry VIII confirmed previous enactments against unlawful games. By a further act of 1541—which was not repealed until 1845—artificers, labourers, apprentices, servants and the like were forbidden to play bowls at any time except Christmas, and then only in their master's house and presence. It was further enjoined that any one playing bowls outside his own garden or orchard was liable to a penalty of 6s. 8d.(6 shillings and 8 pence), while those possessed of lands of the yearly value of £100 might obtain licences to play on their own private greens.
In 1864 William Wallace Mitchell (1803–1884), a Glasgow Cotton Merchant, published his "Manual of Bowls Playing" following his work as the secretary formed in 1849 by Scottish bowling clubs which became the basis of the rules of the modern game.
Young Mitchell was only 11 when he played on Kilmarnock Bowling green, the oldest club in Scotland, instituted in 1740.
The patenting of the first lawn mower in 1830, in Britain, is strongly believed to have been the catalyst, world-wide, for the preparation of modern-style greens, sporting ovals, playing fields, pitches, grass courts, etc. This is turn led to the codification of modern rules for many sports, including lawn bowls, most football codes, lawn tennis and others.
National Bowling Associations were established in the late 1800s. In the then Victorian Colony (now State of Victoria in Australia), the (Royal) Victorian Bowling Association was formed in 1880 and The Scottish Bowling Association was established in 1892, although there had been a failed attempt in 1848 by 200 Scottish clubs.
Today the sport is played in over 40 countries with more than 50 member national authorities.
The home of the modern game is still Scotland with the World Bowls centre in Edinburgh at Caledonia House,1 Redheughs Rigg, South Gyle, Edinburgh, EH12 9DQ.
Game.
Lawn bowls is usually played on a large, rectangular, precisely levelled and manicured grass or synthetic surface known as a bowling green which is divided into parallel playing strips called rinks. In the simplest competition, singles, one of the two opponents flips a coin to see who wins the "mat" and begins a segment of the competition (in bowling parlance, an "end"), by placing the mat and rolling the jack to the other end of the green to serve as a target. Once it has come to rest, the jack is aligned to the centre of the rink and the players take turns to roll their bowls from the mat towards the jack and thereby build up the "head".
A bowl may curve outside the rink boundary on its path, but must come to rest within the rink boundary to remain in play. Bowls falling into the ditch are dead and removed from play, except in the event when one has "touched" the jack on its way. "Touchers" are marked with chalk and remain alive in play even though they are in the ditch. Similarly if the jack is knocked into the ditch it is still alive unless it is out of bounds to the side resulting in a "dead" end which is replayed, though according to international rules the jack is "respotted" to the centre of the rink and the end is continued. After each competitor has delivered all of their bowls (four each in singles and pairs, three each in triples, and two bowls each in fours), the distance of the closest bowls to the jack is determined (the jack may have been displaced) and points, called "shots", are awarded for each bowl which a competitor has closer than the opponent's nearest to the jack. For instance, if a competitor has bowled two bowls closer to the jack than their opponent's nearest, they are awarded two shots. The exercise is then repeated for the next end, a game of bowls typically being of twenty-one ends.
Lawn bowls is played on grass and variations from green to green are common. Greens come in all shapes and sizes, fast, slow, big crown, small crown and so on.
Scoring.
Scoring systems vary from competition to competition. Games can be decided when:
Games to a specified number of ends may also be drawn. The draw may stand, or the opponents may be required to play an extra end to decide the winner. These provisions are always published beforehand in the event's Conditions of Play.
In the Laws of the Sport of Bowls
the winner in a singles game is the first player to score 21 shots. In all other disciplines (pairs, triples, fours) the winner is the team who has scored the most shots after 21/25 ends of play. Often local tournaments will play shorter games (often 10 or 12 ends). Some competitions use a "set" scoring system, with the first to seven points awarded a set in a best-or-three or best-of-five set match. As well as singles competition, there can be two (pairs), three (triples) and four-player (fours) teams. In these, teams bowl alternately, with each player within a team bowling all their bowls, then handing over to the next player. The team captain or "skip" always plays last and is instrumental in directing his team's shots and tactics. The current method of scoring in the professional tour (World Bowls Tour) is sets. Each set consists of nine ends and the player with the most shots at the end of a set wins the set. If the score is tied the set is halved. If a player wins two sets, or gets a win and a tie, that player wins the game. If each player wins a set, or both sets end tied, there is a 3-end tiebreaker to determine a winner.
Bias of bowls.
Bowls are designed to travel a curved path because of a weight bias which was originally produced by inserting weights in one side of the bowl. This is no longer permitted by the rules and bias is now produced entirely by the shape of the bowl. A bowler determines the bias direction of the bowl in his hand by a dimple or symbol on one side. Regulations determine the minimum bias allowed, and the range of diameters (11.6 to 13.1 cm), but within these rules bowlers can and do choose bowls to suit their own preference. They were originally made from lignum vitae, a dense wood giving rise to the term "woods" for bowls, but are now more typically made of a hard plastic composite material.
Bowls were once only available coloured black or brown but they are now available in a variety of colours. They have unique symbol markings engraved on them for identification. Since many bowls look the same, coloured, adhesive stickers or labels are also used to mark the bowls of each team in bowls matches. Some local associations agree on specific colours for stickers for each of the clubs in their area. Provincial or national colours are often assigned in national and international competitions. These stickers are used by officials to distinguish teams.
Bowls have symbols unique to the set of four for identification. The side of the bowl with a larger symbol within a circle indicates the side away from the bias. That side with a smaller symbol within a smaller circle is the bias side toward which the bowl will turn. It is not uncommon for players to deliver a "wrong bias" shot from time to time and see their carefully aimed bowl crossing neighbouring rinks rather than heading towards their jack.
When bowling there are several types of delivery. "Draw" shots are those where the bowl is rolled to a specific location without causing too much disturbance of bowls already in the head. For a right-handed bowler, "forehand draw" or "finger peg" is initially aimed to the right of the jack, and curves in to the left. The same bowler can deliver a "backhand draw" or "thumb peg" by turning the bowl over in his hand and curving it the opposite way, from left to right. In both cases, the bowl is rolled as close to the jack as possible, unless tactics demand otherwise. A "drive" or "fire" or "strike" involves bowling with force with the aim of knocking either the jack or a specific bowl out of play - and with the drive's speed, there is virtually no noticeable (or, at least, much less) curve on the shot. An "upshot" or "yard on" shot involves delivering the bowl with an extra degree of weight (often referred to as "controlled" weight or "rambler"), enough to displace the jack or disturb other bowls in the head without killing the end. A "block" shot is one that is intentionally placed short to defend from a drive or to stop an oppositions draw shot. The challenge in all these shots is to be able to adjust line and length accordingly, the faster the delivery, the narrower the line or "green".
Variations of play.
Particularly in team competition there can be a large number of bowls on the green towards the conclusion of the end, and this gives rise to complex tactics. Teams "holding shot" with the closest bowl will often make their subsequent shots not with the goal of placing the bowl near the jack, but in positions to make it difficult for opponents to get their bowls into the head, or to places where the jack might be deflected to if the opponent attempts to disturb the head.
There are many different ways to set up the game. Crown Green Bowling utilises the entire green. A player can send the jack anywhere on the green in this game and the green itself is more akin to a golf green, with lots of undulation. It is only played with two bowls each, the Jack also has a bias and is only slightly smaller than the Bowls. The game is played usually to 21-up in Singles and Doubles format with some competitions playing to 31-up. The Panel (Professional Crown Green Bowls) is played at the Red Lion, Westhoughton daily and is played to 41-up with greenside betting throughout play.
Singles, triples and fours and Australian pairs are some ways the game can be played. In singles, two people play against each other and the first to reach 21, 25 or 31 shots (as decided by the controlling body) is the winner. In one variation of singles play, each player uses two bowls only and the game is played over 21 ends. A player concedes the game before the 21st end if the score difference is such that it is impossible to draw equal or win within the 21 ends. If the score is equal after 21 ends, an extra end is played to decide the winner. An additional scoring method is set play. This comprises two sets over nine ends. Should a player win a set each, they then play a further 3 ends that will decide the winner.
Pairs allows both people on a team to play Skip and Lead. The lead throws two bowls, the skip delivers two, then the lead delivers his remaining two, the skip then delivers his remaining two bowls. Each end, the leads and skips switch positions. This is played over 21 ends or sets play. Triples is with three players while Fours is with four players in each team and is played over 21 ends.
Another pairs variation is 242 pairs (also known as Australian Pairs). In the first end of the game the A players lead off with 2 bowls each, then the B players play 4 bowls each, before the A players complete the end with their final 2 bowls. The A players act as lead and skip in the same end. In the second end the roles are reversed with the A players being in the middle. This alternating pattern continues through the game which is typically over 15 ends.
Short Mat Bowls is an all-year sport unaffected by weather conditions and it does not require a permanent location as the rink mats can be rolled up and stowed away. This makes it particularly appropriate for small communities as it can be played in village halls, schools, sports and social clubs, hotels and so on. where space is restricted and is also required for other purposes: it is even played on North Sea oil rigs where space is really at a premium.
Bowls are played by the blind and paraplegic. Blind bowlers are extremely skilful. A string is run out down the centre of the lane & wherever the jack lands it is moved across to the string and the length is called out by a sighted marker, when the woods are sent the distance from the jack is called out, in yards, feet and inches-the position in relation to the jack is given using the clock, 12.00 is behind the jack..
Tra bowls.
In the province of West-Flanders (and surrounding regions), tra bowls is the most popular variation of bowls. As opposed to playing it on a flat or uneven terrain, the terrain is made smooth but hollow (tra just means "hollow road" in Flemish). The hollow road causes the path to be curving even more.
The balls are biased in the same way as the lawn bowls balls but with a diameter of about 20 cm, a thickness of 12 cm and a weight of about 2 kg, they are a bit bigger than usual bowls. The target is an unmovable feather or metal plate on the ground, instead of a small ball. The length of the tra is about 18 m.
The scoring is also different, as a point is awarded for every shot that brings the ball closer to the target than any opponent's ball. This causes pure blocking strategies to be less effective.
In 1972, the West-Flemish tra bowls federation was founded to uniform the local differing rules and to organise a match calendar. Meanwhile, they also organise championships and tournaments.
Competitions.
There is a World Indoor Bowls Championships and also World Bowls Events.
Bowls is one of the "core sports" that must be included at each edition of the Commonwealth Games. With the exception of the 1966 Games, the sport has been included in all Games since their inception in 1930. Glasgow, Scotland hosted the 2014 Commonwealth Games, with Jo Edwards (New Zealand) and Darren Burnett (Scotland) winning the singles gold medals. Gold Coast, Australia will host the 2018 Commonwealth Games.

</doc>
<doc id="4249" url="https://en.wikipedia.org/wiki?curid=4249" title="Barcelonnette">
Barcelonnette

Barcelonnette (; ) is a commune of France and a subprefecture in the department of Alpes-de-Haute-Provence, in the Provence-Alpes-Côte d'Azur region. It is located in the southern French Alps, at the crossroads between Provence, Piedmont and the Dauphiné, and is the largest town in the Ubaye Valley. The town's inhabitants are known as "Barcelonnettes".
Toponymy.
Barcelonnette was founded and named in 1231, by Ramon Berenguer IV, Count of Provence. While the town's name is generally seen as a diminutive form of Barcelona in Catalonia, Albert Dauzat and Charles Rostaing point out an earlier attestation of the name "Barcilona" in Barcelonnette in around 1200, and suggest that it is derived instead from two earlier stems signifying a mountain, *"bar" and *"cin" (the latter of which is also seen in the name of Mont Cenis).
In the Vivaro-Alpine dialect of Occitan, the town is known as "Barcilona de Provença" or more rarely "Barciloneta" according to the classical norm; under the Mistralian norm it is called "Barcilouna de Prouvença" or "Barcilouneto". In "Valéian" (the dialect of Occitan spoken in the Ubaye Valley), it is called "Barcilouna de Prouvença" or "Barcilounéta". "Barcino Nova" is the town's Latin name meaning "new Barcelona"; "Barcino" was the Roman name for Barcelona in Catalonia from its foundation by Emperor Augustus in 10 BC, and it was only changed to "Barcelona" in the Middle Ages.
The inhabitants of the town are called "Barcelonnettes", or "Vilandroises" in Valéian.
History.
Origins.
The Barcelonnette region was populated by Ligures from the 1st millennium BC onwards, and the arrival of the Celts several centuries later led to the formation of a mixed Celto-Ligurian people, the Vesubians. Polybius described the Vesubians as belligerent but nonetheless civilised and mercantile, and Julius Caesar praised their bravery. The work "History of the Gauls" also places the Vesubians in the Ubaye Valley.
Following the Roman conquest of Provence, Barcelonnette was included in a small province with modern Embrun as its capital and governed by Albanus Bassalus. This was integrated soon afterwards into Gallia Narbonensis. In 36 AD, Emperor Nero transferred Barcelonnette to the province of the Cottian Alps. The town was known as "Rigomagensium" under the Roman Empire and was the capital of a civitas (a provincial subdivision), though no Roman money has yet been found in the canton of Barcelonnette.
Medieval town.
The town of Barcelonnette was founded in 1231 by Ramon Berenguer IV, Count of Provence. According to Charles Rostaing, this act of formal "foundation", according certain privileges to the town, was a means of regenerating the destroyed town of "Barcilona". The town was afforded a "consulat" (giving it the power to administer and defend itself) in 1240.
Control of the area in the Middle Ages swung between the Counts of Savoy and of Provence. In 1388, after Count Louis II of Provence had left to conquer Naples, the Count of Savoy Amadeus VIII took control of Barcelonnette; however, it returned to Provençal control in 1390, with the d'Audiffret family as its lords. On the death of Louis II in 1417 it reverted to Savoy, and, although Count René again retook the area for Provence in 1471, it had returned to Savoyard dominance by the start of the 16th century, by which point the County of Provence had become united with the Kingdom of France due to the death of Count Charles V in 1481.
Ancien Régime.
During Charles V's invasion of Provence in 1536, Francis I of France sent the Count of Fürstenberg's 6000 "Landsknechte" to ravage the area in a scorched earth policy. Barcelonnette and the Ubaye Valley remained under French sovereignty until the second Treaty of Cateau-Cambrésis on 3 April 1559.
In 1588 the troops of François, Duke of Lesdiguières entered the town and set fire to the church and convent during their campaign against the Duke of Savoy. In 1600, after the Treaty of Vervins, conflict returned between Henry IV of France and Savoy, and Lesdiguières retook Barcelonnette until the conclusion of the Treaty of Lyon on 17 January the following year. In 1628, during the War of the Mantuan Succession, Barcelonnette and the other towns of the Ubaye Valley were pillaged and burned by Jacques du Blé d'Uxelles and his troops, as they passed through towards Italy to the Duke of Mantua's aid. The town was retaken by the Duke of Savoy in 1630; and in 1691 it was captured by the troops of the Marquis de Vins during the War of the League of Augsburg.
Between 1614 and 1713, Barcelonnette was the seat of one of the four prefectures under the jurisdiction of the Senate of Nice. At this time, the community of Barcelonnette successfully purchased the "seigneurie" of the town as it was put to auction by the Duke of Savoy; it thereby gained its own justicial powers. In 1646, a college was founded in Barcelonnette.
A "significant" part of the town's inhabitants had, by the 16th century, converted to Protestantism, and were repressed during the French Wars of Religion.
The "viguerie" of Barcelonnette (also comprising Saint-Martin and Entraunes) was reattached to France in 1713 as part of a territorial exchange with the Duchy of Savoy during the Treaties of Utrecht. The town remained the site of a "viguerie" until the French Revolution. A decree of the council of state on 25 December 1714 reunited Barcelonnete with the general government of Provence.
Revolution.
Barcelonnette was one of few settlements in Haute-Provence to acquire a Masonic Lodge before the Revolution, in fact having two:
In March 1789, riots took place as a result of a crisis in wheat production. In July, the Great Fear of aristocratic reprisal against the ongoing French Revolution struck France, arriving in the Barcelonnette area on 31 July 1789 (when the news of the storming of the Bastille first reached the town) before spreading towards Digne.
This agitation continued in the Ubaye Valley; a new revolt broke out on 14 June, and famine was declared in April 1792. The patriotic society of the commune was one of the first 21 created in Alpes-de-Haute-Provence, in spring 1792, by the envoys of the departmental administration. Around a third of the male population attended at the club. Another episode of political violence occurred in August 1792.
Barcelonnette was the seat of the District of Barcelonnette from 1790 to 1800.
Modern history.
In December 1851, the town was home to a movement of republican resistance towards Napoleon III's coup. Though only a minority of the population, the movement rebelled on Sunday 7 December, the day after the news of the coup arrived. Town officials and gendarmes were disarmed and placed in the maison d'arrêt. A committee of public health was created on 8 December; on 9 December the inhabitants of Jausiers and its surroundings formed a colony under the direction of general councillor Brès, and Mayor Signoret of Saint-Paul-sur-Ubaye. This was stopped, however, on 10 December before it could reach Barcelonnette, as the priest of the subprefecture had intervened. On 11 December, several officials escaped and found refuge in L'Argentière in Piedmont. The arrival of troops on 16 December put a final end to the republican resistance without bloodshed, and 57 insurgents were tried; 38 were condemned to deportation (though several were pardoned in April).
Between 1850 and 1950, Barcelonnette was the source of a wave of emigration to Mexico. Among these emigrants was Jean Baptiste Ebrard, founder of the Liverpool department store chain in Mexico; Marcelo Ebrard, the head of government of Mexico City from 2006 to 2012, is also descended from them. On the edges of Barcelonnette and Jausiers there are several houses and villas of colonial style (known as "maisons mexicaines"), constructed by emigrants to Mexico who returned to France between 1870 and 1930. A plaque in the town commemorates the deaths of ten Mexican citizens who returned to Barcelonnette to fight in the First World War.
During the Second World War, 26 Jews were arrested in Barcelonnette before being deported. The 89th "compagnie de travailleurs étrangers" (Company of Foreign Workers), consisting of foreigners judged as undesirable by the Third Republic and the Vichy regime and committed to forced labour, was established in Barcelonnette.
The 11th Battalion of "Chasseurs alpins" was garrisoned at Barcelonnette between 1948 and 1990.
Geography.
Barcelonnette is situated in the wide and fertile Ubaye Valley, of which it is the largest town. It lies at an elevation of 1132 m (3717 ft) on the right bank of the Ubaye River, and is surrounded by mountains which reach peaks of over 3000 m; the tallest of these is the Needle of Chambeyron at 3412 m. Barcelonnette is situated 210 km from Turin, 91 km from Nice and 68 km from Gap.
Biodiversity.
As a result of its relief and geographic situation, the Ubaye Valley has an "abundance of plant and animal species". The fauna is largely constituted of golden eagles, marmots, ibex and vultures, and the flora includes a large proportion of larches, génépis and white asphodels.
Climate.
The Ubaye Valley has an alpine climate and winters are harsh as a result of the altitude, but there are only light winds as a result of the relief. There are on average almost 300 days of sun and 700 mm of rain per year.
Hazards.
None of the 200 communes of the department is entirely free of seismic risk; the canton of Barcelonnette is placed in zone 1b (low risk) by the determinist classification of 1991 based on seismic history, and zone 4 (average risk) according to the probabilistic EC8 classification of 2011. The commune is also vulnerable to avalanches, forest fires, floods, and landslides. Barcelonnette is also exposed to the possibility of a technological hazard in that road transport of dangerous materials is allowed to pass through on the RD900.
The town has been subject to several orders of natural disaster: floods and mudslides in 1994 and 2008, and landslides in 1996 and 1999. The strongest recorded earthquakes in the region occurred on 5 April 1959, with its epicentre at Saint-Paul-sur-Ubaye and a recorded intensity of 6.5 at Barcelonnette, and on 17 February 1947, with its epicentre at Prazzo over the Italian border.
Architecture.
The subprefecture has been situated since 1978 in a "maison mexicaine", the Villa l'Ubayette, constructed between 1901 and 1903.
Population.
In 1471, the community of Barcelonnette (including several surrounding parishes) comprised 421 fires (households). In 1765, it had 6674 inhabitants, but emigration, particularly to Mexico, slowed the town's growth in the period before the Second World War. According to the census of 2007, Barcelonnette has a population of 2766 (municipal population) or 2939 (total) across a total of 16.42 km2. The town is characterised by low population density. Between 1990 and 1999 the town's annual mean population growth was -0.6%, though between 1999 and 2007 this increased to an average of -0.1%.
Economy.
The city is mainly a tourist and resort centre, serving many ski lodges. The Pra Loup resort is 7 km from Barcelonnette; Le Sauze is 5 km away. It and the Ubaye Valley are served by the Barcelonnette - Saint-Pons Airport. Notably, Barcelonnette is the only subprefecture of France not be served by rail transport; the Ubaye line which would have linked Chorges to Barcelonnette was never completed as a result of the First World War and the construction of the Serre-Ponçon Dam between 1955 and 1961.
Education.
An "école normale" (an institute for training primary school teachers) was founded in Barcelonnette in 1833, and remained there until 1888 when it was transferred to Digne. The "lycée André-Honnorat de Barcelonnette", originally the "collège Saint-Maurice" and renamed after the politician André Honnorat in 1919, is located in the town; Pierre-Gilles de Gennes and Carole Merle both studied there. Currently, three schools exist in Barcelonnette: a public nursery school, a public elementary school, and a private school (under a contract by which the teachers are paid by the national education system).
In 2010 the "lycée André-Honnorat" opened a boarding school aimed at gifted students of poorer social backgrounds, in order to give them better conditions in which to study. It is located in the "Quartier Craplet", formerly the garrison of the 11th Battalion of "Chasseurs Alpins" and then the French Army's "Centre d'instruction et d'entraînement au combat en montagne" (CIECM).
International links.
Barcelonnette is twinned with:
It is also the site of a Mexican honorary consulate.

</doc>
