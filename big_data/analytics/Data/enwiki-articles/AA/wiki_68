<doc id="4764" url="https://en.wikipedia.org/wiki?curid=4764" title="Borzoi">
Borzoi

The Borzoi (, literally "fast"), also called the Russian wolfhound (), is a breed of domestic dog ("Canis lupus familiaris"). Descended from dogs brought to Russia from central Asian countries, it is similar in shape to a greyhound, and is also a member of the sighthound family.
The system by which Russians over the ages named their sighthounds was a series of descriptive terms, not actual names. "Borzói" is the masculine singular form of an archaic Russian adjective that means "fast". "Borzáya sobáka" ("fast dog") is the basic term used by Russians, though "sobáka" is usually dropped. The name "Psovaya" derived from the word Psovina, which means "wavy, silky coat", just as "Hortaya" (as in Hortaya Borzaya) means shorthaired. In Russia today the breed we know as the borzoi is officially known as "Russkaya Psovaya Borzaya". Other Russian sighthound breeds are "Stepnaya Borzaya" (from the steppe), called "Stepnoi"; and "Krimskaya Borzaya" (from the Crimea), called "Krimskoi".
The most commonly used plural form is the regular formation "borzois", which is the only plural cited in most dictionaries. However, the Borzoi Club of America and the Borzoi Club UK both prefer "borzoi" as the form for both singular and plural forms.
Description.
Appearance.
Borzois are large Russian sighthounds that resemble some central Asian breeds such as the Afghan hound, Saluki, and the Kyrgyz Taigan. Borzois can generally be described as "long-haired greyhounds". Borzois come in virtually any colour. The borzoi coat is silky and flat, often wavy or slightly curly. The long top-coat is quite flat, with varying degrees of waviness or curling. The soft undercoat thickens during winter or in cold climates, but is shed in hot weather to prevent overheating. In its texture and distribution over the body, the borzoi coat is unique. There should be a frill on its neck, as well as feathering on its hindquarters and tail.
Borzoi males frequently weigh more than . Males stand at least at the shoulder, while the height of females is around . Despite their size, the overall impression is of streamlining and grace, with a curvy shapeliness and compact strength.
Temperament.
The borzoi is a quiet, but athletic and independent dog. Most borzois are almost silent, barking only very rarely. They do not have strong territorial drives and cannot be relied on to raise the alarm upon sighting a human intruder. The borzoi is extremely smart and requires patient, experienced handling. They are gentle and highly sensitive dogs with a natural respect for humans, and as adults they are decorative couch potatoes with remarkably gracious house manners. Borzois do not generally display dominance or aggression towards people, but will turn aggressive if handled roughly. Typically however, they are rather reserved with strangers but affectionate with people they know well. Their sensitivity to invasion of their personal space can make them nervous around children unless they are brought up with them. Despite their size, borzois adapt very well to suburban life, provided they have a spacious yard and regular opportunities for free exercise.
A common misunderstanding about the intelligence of breeds in the Hound group stems from their independent nature, which conflicts with the frequent confusion between the concepts of "intelligence" and "obedience" in discussions of canine brainpower. Stanley Coren's survey of canine obedience trainers published in "The Intelligence of Dogs" reported that borzois obeyed the first command less than 25% of the time. Coren's test, however, was by his own admission heavily weighted towards the "obedience" interpretation of intelligence and based on a better understanding of "working" breeds than hounds. Unfortunately, the publicity given to this report has led to unfair denigration of breeds which are under-represented in obedience clubs and poorly understood by the average obedience trainer. "Work" for hound breeds is done out of hearing and often out of sight of the human companion; it is an activity for which the dogs are "released", rather than an activity which is "commanded".
In terms of obedience, borzois are selective learners who quickly become bored with repetitive, apparently pointless, activity, and they can be very stubborn when they are not properly motivated. For example, food rewards, or "baiting", may work well for some individuals, but not at all for others. Nevertheless, borzois are definitely capable of enjoying and performing well in competitive obedience and agility trials with the right kind of training. Like other sighthounds, they are very sensitive and do not cope well with harsh treatment or training based on punishment, and will be extremely unhappy if raised voices and threats are a part of their daily life. However, like any intelligent dog, borzois respond extremely well to the guidance, support, and clear communication of a benevolent human leadership.
Borzois were bred to pursue or "course" game and have a powerful instinct to chase things that run from them, including cats and small dogs. Built for speed and endurance, they can cover long distances in a very short time. A fully fenced yard is a necessity for maintaining any sighthound. They are highly independent and will range far and wide without containment, with little regard for road traffic. For off-lead exercise, a borzoi needs a very large field or park, either fully fenced or well away from any roads, to ensure its safety. 
Borzois are born with specialized coursing skills, but these are quite different from the dog-fighting instincts seen in some breeds. It is quite common for borzois at play to course (i.e., run down) another dog, seize it by the neck and hold it immobile. Young pups do this with their littermates, trading off as to who is the prey. It is a specific hunting behavior, not a fighting or territorial domination behavior.
Borzois can be raised very successfully to live with cats and other small animals provided they are introduced to them when they are puppies. Some, however, will possess the hunting instinct to such a degree that they find it impossible not to chase a cat that is moving quickly. The hunting instinct is triggered by movement and much depends on how the cat behaves.
Health.
Stated life expectancy is 10 to 12 years. Median lifespan based on a UK Kennel Club survey is 9 years 1 month. 1 in 5 died of old age, at an average of 10 to 11.5 years. The longest lived dog lived to 14 years 3 months. Dogs that are physically fit and vigorous in their youth through middle age are more vigorous and healthy as elderly dogs, all other factors being equal. In the UK, cancer and cardiac problems seem to be the most frequent causes of premature death.
Like its native relative the Hortaya Borzaya, the borzoi is basically a very sound breed. OCD, hip and elbow dysplasia have remained almost unknown, as were congenital eye and heart diseases before the 1970s. However, in some countries modern breeding practices have introduced a few problems.
As with other very deep-chested breeds, gastric torsion is the most common serious health problem in the borzoi. Also known as bloat, this life-threatening condition is believed to be anatomical rather than strictly genetic in origin. One common recommendation in the past has been to raise the food bowl of the dog when it eats. However, studies have shown that this may actually increase the risk of bloat.
Less common are cardiac problems including cardiomyopathy and cardiac arrhythmia disorders. A controversy exists as to the presence of progressive retinal atrophy in the breed. A condition identified as borzoi retinopathy is seen in some individuals, usually active dogs, which differs from progressive retinal atrophy in several ways. First, it is unilateral, and rarely seen in animals less than three years of age; second, a clear-cut pattern of inheritance has not been demonstrated; and finally, most affected individuals do not go blind.
Correct nutrition during puppyhood is also debatable for borzois. These dogs naturally experience enormous growth surges in the first year or two of their lives. It is now widely accepted that forcing even faster growth by feeding a highly concentrated, high-energy diet is dangerous for skeletal development, causing unsoundness and increased tendency to joint problems and injury. Being built primarily for speed, borzois do not carry large amounts of body fat or muscle, and therefore have a rather different physiology to other dogs of similar size (such as the Newfoundland, St. Bernard, or Alaskan Malamute). Laboratory-formulated diets designed for a generic "large" or "giant" breed are unlikely to take the needs of the big sighthounds into account.
The issues involved in raw feeding may be particularly relevant to tall, streamlined breeds such as the borzoi. It is interesting to note that the Hortaya Borzaya, undoubtedly a very close relative, is traditionally raised on a meager diet of oats and table scraps. The Hortaya is also said to be intolerant of highly concentrated kibble feeds. Basically, a lean body weight in itself is nothing to be concerned about, and force-feeding of healthy young borzoi is definitely not recommended.
History.
It was long thought that Saluki type sighthounds were originally brought to Russia from Byzantium in the South about the 9th and 10th centuries and again later by the Mongol invaders from the East. However, now that the archeological archives and research results of the former USSR are open to scientists, it has become quite clear that the primal sighthound type evolved between the Kyrgyzstan, the lower Kazakhstan part of Altai and the Afghan plains, and that the earliest actual sighthound breeds were the plains Afghan hounds and the Kyrgyz Taigan.
These ancient breeds then migrated South (founding the Tazi/Saluki branch) and West (founding the Stepnaya, Krimskaya and Hortaya branches) to develop into breeds adapted to those regions. This was a slow process which happened naturally through normal spreading of trade, with the silk and spice trade via the Silk Road being the prime vector.
The more modern Psovaya Borzaya was founded on Stepnaya, Hortaya and the Ukrainian-Polish version of the old Hort. There were also imports of Western sighthound breeds to add to the height and weight. It was crossed as well with the Russian Laika specifically and singularly to add resistance against Northern cold and a longer and thicker coat than the Southern sighthounds were equipped with.
All of these foundation types—Tazi, Hortaya, Stepnaya, Krimskaya, and Hort—already possessed the instincts and agility necessary for hunting and bringing down wolves.
The Psovoi was popular with the Tsars before the 1917 revolution. For centuries, Psovoi could not be purchased but only given as gifts from the Tsar. Grand Duke Nicholas Nicolaievich of Russia bred countless Psovoi at Perchino, his private estate.
The Russian concept of hunting trials was instituted during the era of the Tsars. As well as providing exciting sport, the tests were used for selecting borzoi breeding stock; only the quickest and most intelligent hunting dogs went on to produce progeny. For the aristocracy these trials were a well-organized ceremony, sometimes going on for days, with the borzois accompanied by mounted hunters and Foxhounds on the Russian steppe. Hares and other small game were by far the most numerous kills, but the hunters especially loved to test their dogs on wolf. If a wolf was sighted, the hunter would release a team of two or three borzois. The dogs would pursue the wolf, attack its neck from both sides, and hold it until the hunter arrived. The classic kill was by the human hunter with a knife. Wolf trials are still a regular part of the hunting diploma for all Russian sightdog breeds of the relevant type, either singly or in pairs or trios, in their native country.
After the 1917 Revolution, wolf hunting with sighthounds has soon gone out of fashion as an "aristocratic" and a means- and -time-taking way of hunting.
A necessity in a wolf-catching sighthound didn't exist, in addition to the old proved technique of batue with the use of baits, flags and other appeared new, way more effective—from airplanes, from propeller sleighs, with electronic lure whistles. For decades the generations of few remaining sighthounds were regarded as hunting-suited, when showing enough attacking initiative for fox hunting. The rumours about prosecution of sighthounds in post-revolutionary Russia is a legend of modern time, possibly based on similar incidents in Maoist China.
In the late 1940s, a Soviet soldier named Constantin Esmont made detailed records of the various types of borzoi he found in Cossack villages. Esmont's illustrations were recently published and can be viewed by clicking on the link below.
Esmont was concerned that the distinct types of borzaya were in danger of degenerating without a controlled system of breeding. He convinced the Soviet government that borzois were a valuable asset to the hunters who supported the fur industry and henceforth, their breeding was officially regulated. To this day short-haired Hortaya Borzaya are highly valued hunting dogs on the steppes, while the long-haired Psovaya Borzaya, is going through a hard period of restoration of its working qualities after decades of shadow, mainly show existence.
Exports of borzois to other countries were extremely rare during the Soviet era. However, enough had been taken to England, Scandinavia, Western Europe, and America in the late 19th century for the breed to establish itself outside its native country.
In art.
In 2004, the UK Kennel Club held its fourth temporary exhibition, "The Borzoi in Art," which offered unique insights into the borzoi and how the breed has been depicted in art throughout the 19th and 20th centuries. The exhibition included paintings, bronzes, and porcelain which had previously not been available to the public. The exhibition ran from 27 September to 3 December. The borzoi is frequently found in art deco-period works.

</doc>
<doc id="4765" url="https://en.wikipedia.org/wiki?curid=4765" title="Basenji">
Basenji

The Basenji is a breed of hunting dog. It was bred from stock that originated in central Africa. Most of the major kennel clubs in the English-speaking world place the breed in the Hound Group—more specifically, in the sighthound type. The Fédération Cynologique Internationale places the breed in group five, spitz and primitive types, and the United Kennel Club (US) places the breed in the Sighthound & Pariah Group.
The Basenji produces an unusual yodel-like sound commonly called a barroo, due to its unusually shaped larynx. This trait also gives the Basenji the nickname "soundless dog"
Basenjis share many unique traits with pariah dog types. Basenjis, like dingoes and some other breeds of dog, come into estrus only once annually—as compared to other dog breeds, which may have two or more breeding seasons every year. Both dingoes and Basenji lack a distinctive odor, and are prone to howls, yodels, and other vocalizations over the characteristic bark of modern dog breeds. One theory holds that the latter trait is the result of selecting against dogs that frequently bark—in the traditional Central African context—because barking could lead enemies to humans' forest encampments. While dogs that resemble the Basenji in some respects are commonplace over much of Africa, the breed's original foundation stock came from the old growth forest regions of the Congo Basin, where its structure and type were fixed by adaptation to its habitat, as well as use (primarily net hunting in extremely dense old-growth forest vegetation). 
Characteristics.
Appearance.
Basenjis are small, short-haired dogs with erect ears, tightly curled tails and graceful necks. A Basenji's forehead is wrinkled, even more so when they are young or extremely excited. A Basenji's eyes are typically almond-shaped. Basenjis typically weigh about and stand at the shoulder. They are a square breed, which means they are as long as they are tall with males usually larger than females. Basenjis are athletic dogs, and deceptively powerful for their size. They have a graceful, confident gait like a trotting horse, and skim the ground in a double suspension gallop, with their characteristic curled tail straightened out for greater balance when running at their top speed. Basenjis come in a few different colorations: red, black, tricolor, and brindle, and they all have white feet, chests and tail tips. They can also come in "trundle", which is a tricolor with brindle points, a rare combination.
Temperament.
The Basenji is alert, energetic, curious and reserved with strangers. The Basenji tends to become emotionally attached to a single human. Basenjis may not get along with non-canine pets. Basenjis dislike wet weather, like to climb, and can easily get over chain wire fences.
Basenjis often stand on their hind legs, somewhat like a meerkat, by themselves or leaning on something; this behavior is often observed when the dog is curious about something. Basenjis have a strong prey drive. According to the book "The Intelligence of Dogs", they are the second least trainable dog. However, Basenjis are extremely intelligent and respond to training that is consistent and positive with plenty of treats. Basenjis do not respond well to punishment, such as yelling and hitting, which can cause them to utter a warning growl.
Health.
There is apparently only one completed health survey of Basenjis, a 2004 UK Kennel Club survey.
Basenjis are prone to blindness from PRA (progressive retinal atrophy)and Fanconi syndrome. They can also suffer from Hypothyroidism, IPSID (immunoproliferative systemic intestinal disease), and HA (Hemolytic Anemia). Basenjis are also sensitive to environmental and household chemicals, which may cause liver problems.
Longevity.
Basenjis in the 2004 UK Kennel Club survey had a median lifespan of 13.6 years (sample size of 46 deceased dogs), which is 1–2 years longer than the median lifespan of other breeds of similar size. The oldest dog in the survey was 17.5 years. Most common causes of death were old age (30%), urologic (incontinence, Fanconi syndrome, chronic kidney failure 13%), behavior ("unspecified" and aggression 9%), and cancer. (9%).
Among 78 live dogs in the 2004 UKC survey, the most common health issues noted by owners were dermatologic and urologic (urologic issues in Basenjis can be signs of Fanconi syndrome).
Fanconi Syndrome.
Fanconi syndrome, an inheritable disorder in which the renal (kidney) tubes fail to reabsorb electrolytes and nutrients, is unusually common in Basenjis. Symptoms include excessive drinking, excessive urination, and glucose in the urine, which may lead to a misdiagnosis of diabetes. Fanconi syndrome usually presents between 4 and 8 years of age, but sometimes as early as 3 years or as late as 10 years. Fanconi syndrome is treatable and organ damage is reduced if treatment begins early. Basenji owners are advised to test their dog's urine for glucose once a month beginning at the age of 3 years. Glucose testing strips designed for human diabetics are inexpensive and available at most pharmacies. Steve Gonto, M.M.Sc., Ph.D., has a 'Fanconi Disease Management Protocol for Veterinarians' that is commonly used by many veterinarians with Fanconi syndrome afflicted dogs. The current DNA test for Fanconi syndrome may be ordered from offa.org.
Fanconi DNA Linkage Test.
In July 2007, Dr. Gary Johnson of the University of Missouri released the linked marker DNA test for Fanconi Syndrome in Basenjis. It is the first predictive test available for Fanconi Syndrome. With this test, it is possible to more accurately determine the probability of a dog carrying the gene for Fanconi Syndrome.
Dogs tested using this "linkage test" return one of the following statuses:
This linkage test is being provided as a tool to assist breeders whilst research continues towards the development of the direct fanconi test.
The direct Fanconi DNA test has now been developed and may be ordered from the Orthopedic Foundation for Animals at http://www.offa.org/dnatesting/fanconi.html .
For more information about the linkage test visit: Basenji Health Endowment Fanconi Test FAQ.
Other Basenji health issues.
Basenjis sometimes carry a simple recessive gene that, when homozygous for the defect, causes genetic Hemolytic Anemia. Most 21st-century Basenjis are descended from ancestors that have tested clean. When lineage from a fully tested line (set of ancestors) cannot be completely verified, the dog should be tested before breeding. As this is a non-invasive DNA test, a Basenji can be tested for HA at any time.
Basenjis sometimes suffer from hip dysplasia, resulting in loss of mobility and arthritis-like symptoms. All dogs should be tested by either OFA or PennHIP prior to breeding.
Malabsorption, or immunoproliferative enteropathy, is an autoimmune intestinal disease that leads to anorexia, chronic diarrhea, and even death. A special diet can improve the quality of life for afflicted dogs.
The breed can also fall victim to progressive retinal atrophy (a degeneration of the retina causing blindness) and several less serious hereditary eye problems such as coloboma (a hole in the eye structure), and persistent pupillary membrane (tiny threads across the pupil).
History.
The Basenji is an ancient breed. It has been identified as a basal breed that predates the emergence of the modern breeds in the 19th century.
Although the modern Basenji is from central Africa, at some point long ago its ancestor arrived there from eastern Asia, having evolved from either Chinese or southeast Asian wolves. In November 2013, a study analysed the complete and partial mitochondrial genome sequences of 18 fossil canids dating from 1,000 to 36,000 BC from the Old and New Worlds, and compared these with the complete mitochondrial genome sequences from modern wolves and dogs. The data indicate that 22% of the dogs sampled are sister to modern wolves from Sweden and the Ukraine with a most recent common ancestor 9,200 years ago (else admixture with wolves as dogs were clearly domesticated by this time), and that 78% are sister to one or more ancient canids from Europe. Some 64% of the dogs, including the Basenji, are sister to a 14,500 BC wolf sequence with a most recent common ancestor 32,100 BC.
Originating on the continent of Africa, basenji-like dogs have lived with humans for thousands of years. Dogs resembling modern Basenjis, the Tesem, can be seen on stelae in the tombs of Egyptian pharaohs, sitting at the feet of their masters, looking just as they do today, with pricked ears and tightly curled tails. Dogs of this type were originally kept for hunting small game by tracking and driving the game into nets.
Europeans first described the type of dog the Basenji breed derives from in 1895—in the Congo. These local dogs, which Europeans identified as a unique breed and called "basenji," were prized by locals for their intelligence, courage, speed, and silence. An article published called The Intelligence of Dogs by Stanley Coren, Ph.D. questions this. It ranks the breed at #78 out of 79, which is the second to lowest rank in intelligence. Some consider this an unreliable list, as it only focuses on ability to listen to a first command. Some consider independent dogs such as Basenjis and Afghan Hounds more intelligent than obedient breeds because of their ability to recognize which actions benefit them, and which simply please another.
Basenjis were assistants to the hunt, chasing wild game into nets for their masters. The Azande and Mangbetu people from the northeastern Congo region describe Basenjis, in the local Lingala language, as "mbwá na basɛ́nzi". Translated, this means "dogs of the savages", or "dogs of the villagers". In the Congo, the Basenji is also known as "dog of the bush." The dogs are also known to the Azande of southern Sudan as Ango Angari. The word "basɛ́nzi" itself is the plural form of "mosɛ́nzi". In Swahili, another Bantu language, from East Africa, "mbwa shenzi" translates to “wild dog”. Another local name is "m’bwa m’kube m’bwa wamwitu", or “jumping up and down dog”, a reference to their tendency to jump straight up to spot their quarry.
Several attempts were made to bring the breed to England, but the earliest imports succumbed to disease. In 1923, for example, Lady Helen Nutting brought six Basenjis with her from Sudan, but all six died from distemper shots they received in quarantine. It was not until the 1930s that foundation stock was successfully established in England, and then to the United States by animal importer Henry Trefflich. So it is likely that nearly all the Basenjis in the Western world are descended from these few original imports. The breed was officially accepted into the AKC in 1943. In 1990, the AKC stud book was reopened to 14 new imports at the request of the Basenji Club of America. The stud book was reopened again to selected imported dogs from 1 January 2009 to 31 December 2013. An American-led expedition collected breeding stock in villages in the Basankusu area of the Democratic Republic of Congo, in 2010. Basenjis are also registered with the UKC.
The popularity of the Basenji in the United States, according to the American Kennel Club, has declined over the past decade, with the breed ranked 71st in 1999, decreasing to 84th in 2006, and to 93rd in 2011.

</doc>
<doc id="4768" url="https://en.wikipedia.org/wiki?curid=4768" title="Brit milah">
Brit milah

The brit milah (, ; Ashkenazi pronunciation: , "covenant of circumcision"; Yiddish pronunciation: "bris" ) is a Jewish religious male circumcision ceremony performed by a mohel ("circumciser") on the eighth day of a male infant's life. The "brit milah" is followed by a celebratory meal ("seudat mitzvah"). Some Jewish families practice brit shalom instead.
Biblical references.
According to the Hebrew Bible () God commanded the Biblical patriarch Abraham to be circumcised, an act to be followed by his descendants:
Also, provides: "And in the eighth day the flesh of his foreskin shall be circumcised."
According to the Hebrew Bible, it was "a reproach" for an Israelite to be uncircumcised (Joshua 5:9.) The term "arelim" ("uncircumcised" is used opprobriously, denoting the Philistines and other non-Israelites (I Samuel 14:6, 31:4; II Samuel 1:20) and used in conjunction with "tameh" (unpure) for heathen (Isaiah 52:1). The word "arel" ("uncircumcised" [singular) is also employed for "impermeable" (Leviticus 26:41, "their uncircumcised hearts"; compare Jeremiah 9:25; Ezekiel 44:7,9); it is also applied to the first three years' fruit of a tree, which is forbidden (Leviticus 19:23).
However, the Israelites born in the wilderness after the Exodus from Egypt were not circumcised. Joshua 5:2-9, explains, "all the people that came out" of Egypt were circumcised, but those "born in the wilderness" were not. Therefore, Joshua, before the celebration of the Passover, had them circumcised at Gilgal specifically before they entered Canaan. Abraham, too, was circumcised when he moved into Canaan.
The prophetic tradition emphasizes that God expects people to be good as well as pious, and that non-Jews will be judged based on their ethical behavior, see Noahide Law. Thus, Jeremiah 9:25-26 says that circumcised and uncircumcised will be punished alike by the Lord; for "all the nations are uncircumcised, and all the house of Israel are uncircumcised in heart."
The penalty of non-observance is "kareth" (spiritual excision from the Jewish nation), as noted in . Conversion to Judaism for non-Israelites in Biblical times necessitated circumcision, otherwise one could not partake in the Passover offering (). Today, as in the time of Abraham, it is required of converts in Orthodox, Conservative and Reform Judaism. ().
As found in Genesis 17:1-14, "brit milah" is considered to be so important that should the eighth day fall on the Sabbath, actions that would normally be forbidden because of the sanctity of the day are permitted in order to fulfill the requirement to circumcise. The Talmud, when discussing the importance of Milah, compares it to being equal to all other mitzvot (commandments) based on the gematria for "brit" of 612 (Tractate Nedarim 32a).
Covenants in ancient times were sometimes sealed by severing an animal, with the implication that the party who breaks the covenant will suffer a similar fate. In Hebrew, the verb meaning "to seal a covenant" translates literally as "to cut". It is presumed by Jewish scholars that the removal of the foreskin symbolically represents such a sealing of the covenant.
Memory of this tradition has been preserved in traditional Christian churches according to the Gospel of Luke. The Feast of the Circumcision of Christ is kept as a feast eight days after Nativity in a number of churches including the Eastern Orthodox Church, Catholic Church, Lutheran and some Anglican Communion churches. In Orthodox Christian tradition, children are officially named on the eighth day after birth with special naming prayers.
Significantly, the tradition of baptism universally replaced circumcision amongst Christians as the primary rite of passage as found in Paul's Epistle to the Colossians and in Acts of the Apostles.
Ceremony.
Mohel.
A mohel is a Jew trained in the practice of "brit milah", the "covenant of circumcision." According to traditional Jewish law, in the absence of a grown free Jewish male expert, a woman, a slave, or a child, who has the required skills, is also authorized to perform the circumcision, provided that she or he is Jewish. However, most streams of non-Orthodox Judaism allow female mohels, called "mohalot" (, plural of "mohelet", feminine of "mohel"), without restriction. In 1984, Dr. Deborah Cohen became the first certified Reform mohelet; she was certified by the Berit Mila program of Reform Judaism.
Time and place.
It is customary for the brit to be held in a synagogue, but it can also be held at home or any other suitable location. The brit is performed on the eighth day from the baby's birth, taking into consideration that according to the Jewish calendar, the day begins at the sunset of the day before. If the baby is born on Sunday before sunset, the Brit will be held the following Sunday. However, if the baby is born on Sunday night after sunset, the Brit is on the following Monday. The brit takes place on the eighth day following birth even if that day is Shabbat or a holiday. A brit is traditionally performed in the morning, but it may be performed any time during daylight hours.
Postponement for health reasons.
The Talmud explicitly instructs that a boy must not be circumcised if he had two brothers who died due to complications arising from their circumcisions; this may be due to a concern about haemophilia.
An Israeli study found a high rate of urinary tract infections if the bandage is left on too long.
If the child is born prematurely or has other serious medical problems, the brit milah will be postponed until the doctors and mohel deem the child strong enough.
Adult circumcision.
In recent years, the circumcision of adult Jews who were not circumcised as infants has become more common than previously. In such cases, the brit milah will be done at the earliest date that can be arranged. The actual circumcision will be private, and other elements of the ceremony (e.g. the celebratory meal) may be modified to accommodate the desires of the one being circumcised.
Anesthetic.
Most prominent "acharonim" rule that the "mitzvah" of brit milah lies in the pain it causes, and anesthetic, sedation, or ointment should generally not be used.
Eliezer Waldenberg, Yechiel Yaakov Weinberg, Shmuel Wosner, Moshe Feinstein and others agree that the child should not be sedated, although pain relieving ointment may be used under certain conditions; Shmuel Wosner particularly asserts that the act ought to be painful, as per Psalms 44:23.
Regarding an adult circumcision, pain is ideal, but not mandatory. In a letter-to-the-editor published in The New York Times on January 3, 1998, Rabbi Moshe David Tendler disagrees with the above and writes, "It is a biblical prohibition to cause anyone unnecessary pain". Rabbi Tendler recommends the use of an analgesic cream. Lidocaine should not be used, however, because Lidocaine has been linked to several pediatric near-death episodes.
Kvater.
The title of "kvater" (male) or "kvaterin" (female) among Ashkenazi Jews is for the person who carries the baby from the mother to the father, who in turn carries him to the "mohel." This honor is usually given to a couple without children, as a merit or "segula" (efficacious remedy) that they should have children of their own. The origin of the term may simply be "Gevatter", an archaic German word for godfather, but it is also said to be a Yiddish erroneous combination of the words "kavod" ("honor" in Hebrew) and "tor" ("door" in Yiddish), meaning "The person honored by bringing the baby". Another source is a mix of Hebrew and Yiddish meaning 'like the father'.
Seudat mitzvah.
After the ceremony, a celebratory meal takes place. At the "birkat hamazon", additional introductory lines, known as "Nodeh Leshimcha", are added. These lines praise God and request the permission of God, the Torah, Kohanim and distinguished people present to proceed with the grace. When the four main blessings are concluded, special "ha-Rachaman" prayers are recited. They request various blessings by God that include:
Ritual components.
Uncovering, "priah".
At the neonatal stage, the inner preputial epithelium is still linked with the surface of the glans.
The "mitzvah" is executed only when this epithelium is either removed, or permanently peeled back to uncover the glans.
On medical circumcisions performed by surgeons, the epithelium is removed along with the foreskin, to prevent post operative penile adhesion and its complications.
However, on ritual circumcisions performed by a mohel, the epithelium is most commonly peeled off only after the foreskin has been amputated. This procedure is called "priah" (), which means: 'uncovering'. The main goal of "priah" (also known as "bris periah"), is to remove as much of the inner layer of the foreskin as possible and prevent the movement of the shaft skin, what creates the look and function of what is known as a "low and tight" circumcision.
According to Rabbinic interpretation of traditional Jewish sources, the 'priah' has been performed as part of the Jewish circumcision since the Israelites first inhabited the Land of Israel.
However, the "Oxford Dictionary of the Jewish Religion", states that many Hellenistic Jews attempted to restore their foreskins, and that similar action was taken during the Hadrianic persecution, a period in which a prohibition against circumcision was issued. Thus, the writers of the dictionary hypothesize that the more severe method practiced today was probably begun in order to prevent the possibility of restoring the foreskin after circumcision, and therefore the rabbis added the requirement of cutting the foreskin in periah. The frenulum may also be cut away at the same time, in a procedure called frenectomy.
According to Shaye J. D. Cohen, in Why Aren't Jewish Women Circumcised?: Gender and Covenant in Judaism, pg 25, the Torah only commands circumcision (milah.) David Gollaher has written that the rabbis added the procedure of priah to discourage men from trying to restore their foreskins: ‘Once established, priah was deemed essential to circumcision; if the mohel failed to cut away enough tissue, the operation was deemed insufficient to comply with God's covenant’ and ‘Depending on the strictness of individual rabbis, boys (or men thought to have been inadequately cut) were subjected to additional operations.’
"".
The guard (top center) is slid over the foreskin as close to the glans as possible to allow for maximum removal of the former without any injury to the latter. The scalpel is used to detach the foreskin, and the underlying blue bag is a sterilization pouch for the metal tools. The tube (center left) was used for "metzitzah"
In addition to ' (the actual circumcision) and ', mentioned above, the Talmud (Mishnah Shabbat 19:2) mentions a third step, "", translated as suction, as one of the steps involved in the circumcision rite. The Talmud writes that a "Mohel (Circumciser) who does not suck, creates a danger and should be dismissed from practice". Rashi on that Talmudic passage explains that this step is in order to draw some blood from deep inside the wound to prevent danger to the baby, and current medical knowledge confirms the benefits of the practice.
There are other modern antiseptic and antibiotic techniques—all used as part of the "brit milah" today—which many say accomplish the intended purpose of "metzitzah", however, since "metzitzah" is one of the four steps to fulfill Mitzvah, it continues to be practiced by many Orthodox and Hassidic Jews.
The ancient method of performing "metzitzah"—"metzitzah b'peh", or oral suction—has become controversial. The process has the "mohel" place his mouth directly on the circumcision wound to draw blood away from the cut. The majority of Jewish circumcision ceremonies do not use metzitzah b'peh, but some Haredi Jews use it. It has been documented that the practice poses a serious risk of spreading herpes to the infant. Proponents maintain that there is no conclusive evidence that links herpes to "Metzitza", and that attempts to limit this practice infringe on religious freedom.
The practice has become a controversy in both secular and Jewish medical ethics. The ritual of "metzitzah" is found in Mishnah Shabbat 19:2, which lists it as one of the four steps involved in the circumcision rite. Rabbi Moses Sofer (1762–1839) observed that the Talmud states that the rationale for this part of the ritual was hygienic — i.e., to protect the health of the child. The Chasam Sofer issued a leniency (Heter) that some consider to have been conditional to perform "metzitzah" with a sponge to be used instead of oral suction in a letter to his student, Rabbi Lazar Horowitz of Vienna. This letter was never published among Rabbi Sofer's responsa but rather in the secular journal "Kochvei Yitzchok." along with letters from Dr. Wertheimer, the chief doctor of the Viennese General Hospital. It relates the story that a mohel (who was suspected of transmitting herpes via metzizah to infants) was checked several times and never found to have signs of the disease and that a ban was requested because of the "possibility of future infections". Moshe Schick (1807–1879), a student of Moses Sofer, states in his book of Responsa, "She’eilos u’teshuvos Maharam Schick" (Orach Chaim 152,) that Moses Sofer gave the ruling in that specific instance only because the mohel refused to step down and had secular Government connections that prevented his removal in favor of another mohel and the Heter may not be applied elsewhere. He also states ("Yoreh Deah" 244) that the practice is possibly a Sinaitic tradition, i.e., Halacha l'Moshe m'Sinai. Other sources contradict this claim, with copies of Moses Sofer's responsa making no mention of the legal case or of his ruling applying in only one situation. Rather, that responsa makes quite clear that "metzizah" was a health measure and should never be employed where there is a health risk to the infant.
Chaim Hezekiah Medini, after corresponding with the greatest Jewish sages of the generation, concluded the practice to be Halacha l'Moshe m'Sinai and elaborates on what prompted Moses Sofer to give the above ruling. He tells the story that a student of Moses Sofer, Lazar Horowitz, Chief Rabbi of Vienna at the time and author of the responsa "Yad Elazer", needed the ruling because of a governmental attempt to ban circumcision completely if it included "metztitzah b'peh." He therefore asked Sofer to give him permission to do "brit milah" without "metzitzah b’peh." When he presented the defense in secular court, his testimony was erroneously recorded to mean that Sofer stated it as a general ruling. The Rabbinical Council of America, (RCA) which claims to be the largest American organization of Orthodox rabbis, published an article by mohel Dr Yehudi Pesach Shields in its summer 1972 issue of Tradition magazine, calling for the abandonment of Metzitzah b'peh. Since then the RCA has issued an opinion that advocates methods that do not involve contact between the mohel's mouth and the open wound, such as the use of a sterile syringe, thereby eliminating the risk of infection. According to the Chief Rabbinate of Israel and the Edah HaChareidis "metzitzah b'peh" should still be performed.
The practice of "metzitzah b'peh" was alleged to pose a serious risk in the transfer of herpes from mohelim to eight Israeli infants, one of whom suffered brain damage. When three New York City infants contracted herpes after "metzizah b'peh" by one "mohel" and one of them died, New York authorities took out a restraining order against the "mohel" requiring use of a sterile glass tube, or pipette. The mohel's attorney argued that the New York Department of Health had not supplied conclusive medical evidence linking his client with the disease. In September 2005, the city withdrew the restraining order and turned the matter over to a rabbinical court. Dr. Thomas Frieden, the Health Commissioner of New York City, wrote, "There exists no reasonable doubt that ‘metzitzah b'peh’ can and has caused neonatal herpes infection...The Health Department recommends that infants being circumcised not undergo metzitzah b'peh." In May 2006, the Department of Health for New York State issued a protocol for the performance of metzitzah b'peh. Dr. Antonia C. Novello, Commissioner of Health for New York State, together with a board of rabbis and doctors, worked, she said, to "allow the practice of metzizah b'peh to continue while still meeting the Department of Health's responsibility to protect the public health."
In three medical papers done in Israel, Canada, and the USA, oral suction following circumcision was suggested as a cause in 11 cases of neonatal herpes. Researchers noted that prior to 1997, neonatal herpes reports in Israel were rare, and that the late incidences were correlated with the mothers carrying the virus themselves. Rabbi Doctor Mordechai Halperin implicates the "better hygiene and living conditions that prevail among the younger generation", which lowered to 60% the rate of young Israeli Chareidi mothers who carry the virus. He explains that an "absence of antibodies in the mothers’ blood means that their newborn sons received no such antibodies through the placenta, and therefore are vulnerable to infection by HSV-1."
Barriers.
Because of the risk of infection, some rabbinical authorities have ruled that the traditional practice of direct contact should be replaced by using a glass tube between the wound and the mohel's mouth, so there is no direct oral contact. The Rabbinical Council of America, the largest group of Modern Orthodox rabbis, endorses this method. The RCA paper states: ""Rabbi Schachter even reports that Rav Yosef Dov Soloveitchik reports that his father, Rav Moshe Soloveitchik, would not permit a mohel to perform metzitza be’peh with direct oral contact, and that his grandfather, Rav Chaim Soloveitchik, instructed mohelim in Brisk not to do metzitza be’peh with direct oral contact. However, although Rav Yosef Dov Soloveitchik also generally prohibited metzitza be’peh with direct oral contact, he did not ban it by those who insisted upon it...". " The sefer Mitzvas Hametzitzah by Rabbi Sinai Schiffer of Baden, Germany, states that he is in possession of letters from 36 major Russian (Lithuanian) rabbis that categorically prohibit Metzitzah with a sponge and require it to be done orally. Among them is Rabbi Chaim Halevi Soloveitchik of Brisk.
In September 2012, the New York Department of Health unanimously ruled that the practice of metztizah b'peh should require informed consent from the parent or guardian of the child undergoing the ritual. Prior to the ruling, several hundred rabbis, including Rabbi David Neiderman, the executive director of the United Jewish Organization of Williamsburg, signed a declaration stating that they would not inform parents of the potential dangers that came with metzitzah b'peh, even if informed consent became law.
In a Motion for preliminary injunction with intent to sue, filed against New York City Department of Health & Mental Hygiene, affidavits by Doctors Awi Federgruen Professor at the Columbia University Graduate School of Business. Brenda Breuer, Director of Epidemiologic Research at the Department of Pain Medicine and Palliative Care at the Beth Israel Medical Center, and an Associate Professor of Clinical Neurology at the Albert Einstein College of Medicine. Daniel S. Berman, Chief of Infectious-Disease at New York Westchester Square Hospital, argues that the study on which the department passed its conclusions is flawed.
The “informed consent” regulation was challenged in court. In January 2013 the U.S. District court ruled that the law did not specifically target religion and therefore must not pass strict scrutiny.
The ruling was appealed to the Court of Appeals. On August 15, 2014 the Second Circuit Court of Appeals reversed the decision by the lower court, and ruled that the regulation does have to be reviewed under strict scrutiny to determine whether it infringes on Orthodox Jews freedom of religion.
On September 9, 2015 after coming to an agreement with the community The New York City Board of Health voted to repeal the informed consent regulation.
Hatafat dam brit.
A brit milah is more than circumcision, it is a sacred ritual in Judaism, as distinguished from its non-ritual requirement in Islam. One ramification is that the brit is not considered complete unless a drop of blood is actually drawn. The standard medical methods of circumcision through constriction do not meet the requirements of the halakhah for brit milah, because they cause hemostasis, "i.e.", they stop the flow of blood. Morever, circumcision alone, in the absence of the brit milah ceremony, does not fulfill the requirements of the mitzvah. Therefore, in cases where a Jew who was circumcised outside of a brit milah, an already-circumcised convert, or an aposthetic (born without a foreskin) individual, the mohel draws a symbolic drop of blood (, )from the penis at the point where the foreskin would have been or was attached.
"Milah l'shem giur".
A "Milah L'shem giur" is a "Circumcision for the purpose of conversion". In Orthodox Judaism, this procedure is usually done by adoptive parents for adopted boys who are being converted as part of the adoption or by families with young children converting together. It is also required for adult converts who were not previously circumcised, e.g. those born in countries where circumcision at birth is not common. The conversion of a minor is valid in both Orthodox and Conservative Judaism until a child reaches the age of majority (13 for a boy, 12 for a girl); at that time the child has the option of renouncing his conversion and Judaism, and the conversion will then be considered retroactively invalid. He must be informed of his right to renounce his conversion if he wishes. If he does not make such a statement, it is accepted that the boy is halakhically Jewish. Orthodox rabbis will generally not convert a non-Jewish child raised by a mother who has not converted to Judaism.
The laws of conversion and conversion-related circumcision in Orthodox Judaism have numerous complications, and authorities recommend that a rabbi be consulted well in advance.
In Conservative Judaism, the Milah l'Shem giur procedure is also performed for a boy whose mother has not converted, but with the intention that the child be raised Jewish. This conversion of a child to Judaism without the conversion of the mother is allowed by Conservative interpretations of halakha. Conservative Rabbis will authorize it only under the condition that the child be raised as a Jew in a single-faith household. Should the mother convert, and if the boy has not yet reached his third birthday, the child may be immersed in the mikveh with the mother, after the mother has already immersed, to become Jewish. If the mother does not convert, the child may be immersed in a mikveh, or body of natural waters, to complete the child's conversion to Judaism. This can be done before the child is even one year old. If the child did not immerse in the mikveh, or the boy was too old, then the child may choose of their own accord to become Jewish at age 13 as a Bar Mitzvah, and complete the conversion then.
Where the procedure was performed but not followed by immersion or other requirements of the conversion procedure (e.g., in Conservative Judaism, where the mother has not converted), if the boy chooses to complete the conversion at Bar Mitzvah, a "Milah l'shem giur" performed when the boy was an infant removes the obligation to undergo either a full brit milah or "hatafat dam brit".
Reasons for circumcision.
In "Of the Special Laws, Book 1", the Jewish philosopher Philo (20 BCE - CE 50) gives six reasons for the practice of circumcision. He attributes four of the reasons to "men of divine spirit and wisdom". These include the idea that circumcision:
To these, Philo added two of his own reasons, including the idea that circumcision 
Rabbi Saadia Gaon considers something to be 'complete', if it lacks nothing, but also has nothing that is unneeded. He regards the foreskin an unneeded organ that God created in man, and so by amputating it, the man is completed.
Maimonides (Moses ben Maimon "Rambam", CE 1135-1204), who apart from being a great Torah scholar was also a physician and philosopher, argued that circumcision serves as a common bodily sign to members of the same faith. He also asserted that the main purpose of the act is to repress sexual pleasure, with the strongest reason being that it is difficult for a woman to separate from an uncircumcised man with whom she has had sex.
The author of Sefer ha-Chinuch provides three reasons for the practice of circumcision:
Talmud professor Daniel Boyarin offered two explanations for circumcision. One is that it is a literal inscription on the Jewish body of the name of God in the form of the letter "yud" (from "yesod"). The second is that the act of bleeding represents a feminization of Jewish men, significant in the sense that the covenant represents a marriage between Jews and (a symbolically male) God.
Reform Judaism.
The radical, lay Reform societies established in Frankfurt and Berlin regarded circumcision as barbaric and wished to abolish it. However, while prominent rabbis such as Abraham Geiger believed the ritual to be barbaric and outdated, they refrained from instituting any change in this matter. In 1843, when a father in Frankfurt refused to circumcise his son, rabbis of all shades in Germany stated it was mandated by Jewish law; even Samuel Holdheim affirmed this. By 1871, Reform rabbinic leadership in Germany reasserted "the supreme importance of circumcision in Judaism", while affirming the traditional viewpoint that non-circumcised are Jews nonetheless. Although the issue of circumcision of converts continues to be debated, the necessity of Brit Milah for Jewish infant boys has been stressed in every subsequent Reform rabbis manual or guide. Since 1984 Reform Judaism has trained and certified over 300 of their own practicing "mohalim" in this ritual.
The anti-circumcision movement and "brit shalom".
Some contemporary Jews choose not to circumcise their sons. They are assisted by a small number of Reform and Reconstructionist rabbis, and have developed a welcoming ceremony that they call the "brit shalom" ("Covenant Peace") for such children, also accepted by Humanistic Judaism.
This ceremony of "brit shalom" is not officially approved of by the Reform or Reconstructionist rabbinical organizations, who make the recommendation that male infants should be circumcised, though the issue of converts remains controversial and circumcision of converts is not mandatory in either movement.
However, the connection of the Reform movement to an anti-circumcision, pro-symbolic stance is a historical one. From the early days of the movement in Germany, some classical Reformers hoped to replace ritual circumcision "with a symbolic act, as has been done for other bloody practices, such as the sacrifices." In the US, an official Reform resolution in 1893 announced converts are no longer mandated to undergo the ritual, and this ambivalence towards the practice has carried over to classical-minded Reform Jews today. In Elyse Wechterman's essay "A Plea for Inclusion", she argues that, even in the absence of circumcision, committed Jews should never be turned away, especially by a movement "where no other ritual observance is mandated". She goes on to advocate an alternate covenant ceremony, "brit atifah", for both boys and girls as a welcoming ritual into Judaism. With a continuing negativity towards circumcision still present within a minority of modern-day Reform, Judaic scholar Jon Levenson has warned that if they "continue to judge "brit milah" to be not only medically unnecessary but also brutalizing and mutilating...the abhorrence of it expressed by some early Reform leaders will return with a vengeance", proclaiming that circumcision will be "the latest front in the battle over the Jewish future in America."
Many European Jewish fathers during the nineteenth century chose not to circumcise their sons, including Theodor Herzl. However, unlike many other forms of religious observance, it remained one of the last rituals Jewish communities could enforce. In most Europe, both the government and the unlearned Jewish masses believed that circumcision was a rite akin to baptism, and the law allowed communities not to register uncircumcised children as Jewish. However, several debated were held on the question whether it is advisable, since many parents then chose to convert to Christianity. In early 20th-century Russia, Chaim Soloveitchik advised his colleagues not adopt this measure: he stated that the uncircumcised was as much Jewish as other transgressors.
In Israel, a small number of families who have chosen not to have their sons circumcised formed a support group in the year 2000. Over two and a half years, 200 couples have enlisted. According to the Leadership Conference of Secular and Humanistic Jews, "circumcision is not required for Jewish identity."

</doc>
<doc id="4770" url="https://en.wikipedia.org/wiki?curid=4770" title="Business ethics">
Business ethics

Business ethics (also corporate ethics) is a form of applied ethics or professional ethics that examines ethical principles and moral or ethical problems that arise in a business environment. It applies to all aspects of business conduct and is relevant to the conduct of individuals and entire organizations.
Business ethics refers to contemporary standards or sets of values that govern the actions and behaviour of an individual in the business organisation.
Business ethics has normative and descriptive dimensions. As a corporate practice and a career specialization, the field is primarily normative. Academics attempting to understand business behavior employ descriptive methods. The range and quantity of business ethical issues reflects the interaction of profit-maximizing behavior with non-economic concerns.
Interest in business ethics accelerated dramatically during the 1980s and 1990s, both within major corporations and within academia. For example, most major corporations today promote their commitment to non-economic values under headings such as ethics codes and social responsibility charters.
Adam Smith said, "People of the same trade seldom meet together, even for merriment and diversion, but the conversation ends in a conspiracy against the public, or in some contrivance to raise prices." Governments use laws and regulations to point business behavior in what they perceive to be beneficial directions. Ethics implicitly regulates areas and details of behavior that lie beyond governmental control. The emergence of large corporations with limited relationships and sensitivity to the communities in which they operate accelerated the development of formal ethics regimes.
History.
Business ethical norms reflect the norms of each historical period. As time passes norms evolve, causing accepted behaviors to become objectionable. Business ethics and the resulting behavior evolved as well. Business was involved in slavery, colonialism, and the cold war.
The term 'business ethics' came into common use in the United States in the early 1970s. By the mid-1980s at least 500 courses in business ethics reached 40,000 students, using some twenty textbooks and at least ten casebooks along supported by professional societies, centers and journals of business ethics. The Society for Business Ethics was started in 1980. European business schools adopted business ethics after 1987 commencing with the European Business Ethics Network (EBEN). In 1982 the first single-authored books in the field appeared.
Firms started highlighting their ethical stature in the late 1980s and early 1990s, possibly trying to distance themselves from the business scandals of the day, such as the savings and loan crisis. The idea of business ethics caught the attention of academics, media and business firms by the end of the Cold War. However, criticism of business practices was attacked for infringing the freedom of entrepreneurs and critics were accused of supporting communists. This scuttled the discourse of business ethics both in media and academia.
Overview.
Business ethics reflects the philosophy of business, of which one aim is to determine the fundamental purposes of a company. If a company's purpose is to maximize shareholder returns, then sacrificing profits to other concerns is a violation of its fiduciary responsibility. Corporate entities are legally considered as persons in USA and in most nations. The 'corporate persons' are legally entitled to the rights and liabilities due to citizens as persons.
Ethics are the rules or standards that govern our decisions on a daily basis. Many equate “ethics” with conscience or a simplistic sense of “right” and “wrong.” Others would say that ethics is an internal code that governs an individual’s conduct, ingrained into each person by family, faith, tradition, community, laws, and personal mores. Corporations and professional organizations, particularly licensing boards, generally will have a written “Code of Ethics” that governs standards of professional conduct expected of all in the field. 
It is important to note that “law” and “ethics” are not synonymous, nor are the “legal” and “ethical” courses of action in a given situation necessarily the same. Statutes and regulations passed by legislative bodies and administrative boards set forth the “law.” Slavery once was legal in the US, but one certainly wouldn’t say forcibly enslaving humans was an “ethical” act.
Economist Milton Friedman writes that corporate executives' "responsibility... generally will be to make as much money as possible while conforming to their basic rules of the society, both those embodied in law and those embodied in ethical custom". Friedman also said, "the only entities who can have responsibilities are individuals ... A business cannot have responsibilities. So the question is, do corporate executives, provided they stay within the law, have responsibilities in their business activities other than to make as much money for their stockholders as possible? And my answer to that is, no, they do not." A multi-country 2011 survey found support for this view among the "informed public" ranging from 30 to 80%. Ronald Duska views Friedman's argument as consequentialist rather than pragmatic, implying that unrestrained corporate freedom would benefit the most in long term. Similarly author business consultant Peter Drucker observed, "There is neither a separate ethics of business nor is one needed", implying that standards of personal ethics cover all business situations. However, Peter Drucker in another instance observed that the ultimate responsibility of company directors is not to harm—"primum non nocere".
Another view of business is that it must exhibit corporate social responsibility (CSR): an umbrella term indicating that an ethical business must act as a responsible citizen of the communities in which it operates even at the cost of profits or other goals. In the US and most other nations corporate entities are legally treated as persons in some respects. For example, they can hold title to property, sue and be sued and are subject to taxation, although their free speech rights are limited. This can be interpreted to imply that they have independent ethical responsibilities. Duska argues that stakeholders have the right to expect a business to be ethical; if business has no ethical obligations, other institutions could make the same claim which would be counterproductive to the corporation.
Ethical issues include the rights and duties between a company and its employees, suppliers, customers and neighbors, its fiduciary responsibility to its shareholders. Issues concerning relations between different companies include hostile take-overs and industrial espionage. Related issues include corporate governance;corporate social entrepreneurship; political contributions; legal issues such as the ethical debate over introducing a crime of corporate manslaughter; and the marketing of corporations' ethics policies.
According to IBE/ Ipsos MORI research published in late 2012, the three major areas of public concern regarding business ethics in Britain are executive pay, corporate tax avoidance and bribery and corruption.
Ethical standards of an entire organisation can be badly damaged if a corporate psychopath is in charge.
Functional business areas.
Finance.
Fundamentally finance is a social science discipline. The discipline borders behavioral economics, sociology, economics, accounting and management. It concerns technical issues such as the mix of debt and equity, dividend policy, the evaluation of alternative investment projects, options, futures, swaps, and other derivatives, portfolio diversification and many others. It is often mistaken by the people to be a discipline free from ethical burdens. The 2008 financial crisis caused critics to challenge the ethics of the executives in charge of U.S. and European financial institutions and financial regulatory bodies. Finance ethics is overlooked for another reason—issues in finance are often addressed as matters of law rather than ethics.
Finance paradigm.
Aristotle said, "the end and purpose of the polis is the good life". Adam Smith characterized the good life in terms of material goods and intellectual and moral excellences of character. Smith in his "The Wealth of Nations" commented, "All for ourselves, and nothing for other people, seems, in every age of the world, to have been the vile maxim of the masters of mankind." However, a section of economists influenced by the ideology of neoliberalism, interpreted the objective of economics to be maximization of economic growth through accelerated consumption and production of goods and services. Neoliberal ideology promoted finance from its position as a component of economics to its core. Proponents of the ideology hold that unrestricted financial flows, if redeemed from the shackles of "financial repressions", best help impoverished nations to grow. The theory holds that open financial systems accelerate economic growth by encouraging foreign capital inﬂows, thereby enabling higher levels of savings, investment, employment, productivity and "welfare", along with containing corruption. Neoliberals recommended that governments open their financial systems to the global market with minimal regulation over capital flows. The recommendations however, met with criticisms from various schools of ethical philosophy. Some pragmatic ethicists, found these claims to unfalsifiable and a priori, although neither of these makes the recommendations false or unethical per se. Raising economic growth to the highest value necessarily means that welfare is subordinate, although advocates dispute this saying that economic growth provides more welfare than known alternatives. Since history shows that neither regulated nor unregulated firms always behave ethically, neither regime offers an ethical panacea.
Neoliberal recommendations to developing countries to unconditionally open up their economies to transnational finance corporations was fiercely contested by some ethicists. The claim that deregulation and the opening up of economies would reduce corruption was also contested.
Dobson observes, "a rational agent is simply one who pursues personal material advantage ad infinitum. In essence, to be rational in finance is to be individualistic, materialistic, and competitive. Business is a game played by individuals, as with all games the object is to win, and winning is measured in terms solely of material wealth. Within the discipline this rationality concept is never questioned, and has indeed become the theory-of-the-firm's sine qua non". Financial ethics is in this view a mathematical function of shareholder wealth. Such simplifying assumptions were once necessary for the construction of mathematically robust models. However signalling theory and agency theory extended the paradigm to greater realism.
Other issues.
Fairness in trading practices, trading conditions, financial contracting, sales practices, consultancy services, tax payments, internal audit, external audit and executive compensation also fall under the umbrella of finance and accounting. Particular corporate ethical/legal abuses include: creative accounting, earnings management, misleading financial analysis, insider trading, securities fraud, bribery/kickbacks and facilitation payments. Outside of corporations, bucket shops and forex scams are criminal manipulations of financial markets. Cases include accounting scandals, Enron, WorldCom and Satyam.
Human resource management.
Human resource management occupies the sphere of activity of recruitment selection, orientation, performance appraisal, training and development, industrial relations and health and safety issues. Business Ethicists differ in their orientation towards labour ethics. Some assess human resource policies according to whether they support an egalitarian workplace and the dignity of labor.
Issues including employment itself, privacy, compensation in accord with comparable worth, collective bargaining (and/or its opposite) can be seen either as inalienable rights or as negotiable.
Discrimination by age (preferring the young or the old), gender/sexual harassment, race, religion, disability, weight and attractiveness. A common approach to remedying discrimination is affirmative action.
Once hired, employees have the right to occasional cost of living increases, as well as raises based on merit. Promotions, however, are not a right, and there are often fewer openings than qualified applicants. It may seem unfair if an employee who has been with a company longer is passed over for a promotion, but it is not unethical. It is only unethical if the employer did not give the employee proper consideration or used improper criteria for the promotion.
Potential employees have ethical obligations to employers, involving intellectual property protection and whistle-blowing.
Employers must consider workplace safety, which may involve modifying the workplace, or providing appropriate training or hazard disclosure.
Larger economic issues such as immigration, trade policy, globalization and trade unionism affect workplaces and have an ethical dimension, but are often beyond the purview of individual companies.
Trade unions.
Unions for example, may push employers to establish due process for workers, but may also cost jobs by demanding unsustainable compensation and work rules.
Unionized workplaces may confront union busting and strike breaking and face the ethical implications of work rules that advantage some workers over others.
Management strategy.
Among the many people management strategies that companies employ are a "soft" approach that regards employees as a source of creative energy and participants in workplace decision making, a "hard" version explicitly focused on control and Theory Z that emphasizes philosophy, culture and consensus. None ensure ethical behavior. Some studies claim that sustainable success requires a humanely treated and satisfied workforce.
Sales and marketing.
Marketing ethics came of age only as late as 1990s. Marketing ethics was approached from ethical perspectives of virtue or virtue ethics, deontology, consequentialism, pragmatism and relativism.
Ethics in marketing deals with the principles, values and/or ideals by which marketers (and marketing institutions) ought to act. Marketing ethics is also contested terrain, beyond the previously described issue of potential conflicts between profitability and other concerns.
Ethical marketing issues include marketing redundant or dangerous products/services transparency about environmental risks, transparency about product ingredients such as genetically modified organisms possible health risks, financial risks, security risks, etc., respect for consumer privacy and autonomy, advertising truthfulness and fairness in pricing & distribution.
According to Borgerson, and Schroeder (2008), marketing can influence individuals' perceptions of and interactions with other people, implying an ethical responsibility to avoid distorting those perceptions and interactions.
Marketing ethics involves pricing practices, including illegal actions such as price fixing and legal actions including price discrimination and price skimming. Certain promotional activities have drawn fire, including greenwashing, bait and switch, shilling, viral marketing, spam (electronic), pyramid schemes and multi-level marketing. Advertising has raised objections about attack ads, subliminal messages, sex in advertising and marketing in schools.
Production.
This area of business ethics usually deals with the duties of a company to ensure that products and production processes do not needlessly cause harm. Since few goods and services can be produced and consumed with zero risk, determining the ethical course can be problematic. In some case consumers demand products that harm them, such as tobacco products. Production may have environmental impacts, including pollution, habitat destruction and urban sprawl. The downstream effects of technologies nuclear power, genetically modified food and mobile phones may not be well understood. While the precautionary principle may prohibit introducing new technology whose consequences are not fully understood, that principle would have prohibited most new technology introduced since the industrial revolution. Product testing protocols have been attacked for violating the rights of both humans and animals.
Property.
The etymological root of property is the Latin 'proprius' which refers to 'nature', 'quality', 'one's own', 'special characteristic', 'proper', 'intrinsic', 'inherent', 'regular', 'normal', 'genuine', 'thorough, complete, perfect' etc. The word property is value loaded and associated with the personal qualities of propriety and respectability, also implies questions relating to ownership. A 'proper' person owns and is true to herself or himself, and is thus genuine, perfect and pure.
Modern history of property rights.
Modern discourse on property emerged by the turn of 17th century within theological discussions of that time. For instance, John Locke justified property rights saying that God had made "the earth, and all inferior creatures, common to all men".
In 1802 Utilitarian Jeremy Bentham stated, "property and law are born together and die together".
One argument for property ownership is that it enhances individual liberty by extending the line of non-interference by the state or others around the person. Seen from this perspective, property right is absolute and property has a special and distinctive character that precedes its legal protection. Blackstone conceptualized property as the "sole and despotic dominion which one man claims and exercises over the external things of the world, in total exclusion of the right of any other individual in the universe".
Slaves as property.
During the seventeenth and eighteenth centuries, slavery spread to European colonies including America, where colonial legislatures defined the legal status of slaves as a form of property. During this time settlers began the centuries-long process of dispossessing the natives of America of millions of acres of land. Ironically, the natives lost about of land in the Louisiana Territory under the leadership of Thomas Jefferson, who championed property rights.
Combined with theological justification, property was taken to be essentially natural ordained by God. Property, which later gained meaning as ownership and appeared natural to Locke, Jefferson and to many of the 18th and 19th century intellectuals as land, labour or idea and property right over slaves had the same theological and essentialized justification It was even held that the property in slaves was a sacred right. Wiecek noted, "slavery was more clearly and explicitly established under the Constitution as it had been under the Articles". Accordingly, US Supreme Court Chief Justice Roger B. Taney in his 1857 judgment stated, "The right of property in a slave is distinctly and expressly affirmed in the Constitution".
Natural right vs social construct.
Neoliberals hold that private property rights are a non-negotiable natural right. Davies counters with "property is no different from other legal categories in that it is simply a consequence of the significance attached by law to the relationships between legal persons." Singer claims, "Property is a form of power, and the distribution of power is a political problem of the highest order". Rose finds, "'Property' is only an effect, a construction, of relationships between people, meaning that its objective character is contestable. Persons and things, are 'constituted' or 'fabricated' by legal and other normative techniques.". Singer observes, "A private property regime is not, after all, a Hobbesian state of nature; it requires a working legal system that can define, allocate, and enforce property rights." Davis claims that common law theory generally favors the view that "property is not essentially a 'right to a thing', but rather a separable bundle of rights subsisting between persons which may vary according to the context and the object which is at stake".
In common parlance property rights involve a 'bundle of rights' including occupancy, use and enjoyment, and the right to sell, devise, give, or lease all or part of these rights. Custodians of property have obligations as well as rights. Michelman writes, "A property regime thus depends on a great deal of cooperation, trustworthiness, and self-restraint among the people who enjoy it."
Menon claims that the autonomous individual, responsible for his/her own existence is a cultural construct moulded by Western culture rather than the truth about the human condition. Penner views property as an "illusion"—a "normative phantasm" without substance.
In the neoliberal literature, property is part of the private side of a public/private dichotomy and acts a counterweight to state power. Davies counters that "any space may be subject to plural meanings or appropriations which do not necessarily come into conflict".
Private property has never been a universal doctrine, although since the end of the Cold War is it has become nearly so. Some societies, e.g., Native American bands, held land, if not all property, in common. When groups came into conflict, the victor often appropriated the loser's property. The rights paradigm tended to stabilize the distribution of property holdings on the presumption that title had been lawfully acquired.
Property does not exist in isolation, and so property rights too. Bryan claimed that property rights describe relations among people and not just relations between people and things Singer holds that the idea that owners have no legal obligations to others wrongly supposes that property rights hardly ever conflict with other legally protected interests. Singer continues implying that legal realists "did not take the character and structure of social relations as an important independent factor in choosing the rules that govern market life". Ethics of property rights begins with recognizing the vacuous nature of the notion of property.
Intellectual property.
Intellectual property (IP) encompasses expressions of ideas, thoughts, codes and information. "Intellectual property rights" (IPR) treat IP as a kind of real property, subject to analogous protections, rather than as a reproducible good or service. Boldrin and Levine argue that "government does not ordinarily enforce monopolies for producers of other goods. This is because it is widely recognized that monopoly creates many social costs. Intellectual monopoly is no different in this respect. The question we address is whether it also creates social benefits commensurate with these social costs."
International standards relating to Intellectual Property Rights are enforced through Agreement on Trade Related Aspects of Intellectual Property Rights (TRIPS). In the US, IP other than copyrights is regulated by the United States Patent and Trademark Office.
The US Constitution included the power to protect intellectual property, empowering the Federal government ""to promote the progress of science and useful arts, by securing for limited times to authors and inventors the exclusive right to their respective writings and discoveries"". Boldrin and Levine see no value in such state-enforced monopolies stating, "we ordinarily think of innovative monopoly as an oxymoron. Further they comment, 'intellectual property' "is not like ordinary property at all, but constitutes a government grant of a costly and dangerous private monopoly over ideas. We show through theory and example that intellectual monopoly is not necessary for innovation and as a practical matter is damaging to growth, prosperity, and liberty" . Steelman defends patent monopolies, writing, "Consider prescription drugs, for instance. Such drugs have benefited millions of people, improving or extending their lives. Patent protection enables drug companies to recoup their development costs because for a specific period of time they have the sole right to manufacture and distribute the products they have invented." The court cases by 39 pharmaceutical companies against South Africa's 1997 Medicines and Related Substances Control Amendment Act, which intended to provide affordable HIV medicines has been cited as a harmful effect of patents.
One attack on IPR is moral rather than utilitarian, claiming that inventions are mostly a collective, cumulative, path dependent, social creation and therefore, no one person or ﬁrm should be able to monopolize them even for a limited period. The opposing argument is that the benefits of innovation arrive sooner when patents encourage innovators and their investors to increase their commitments. Roderick Long, a libertarian philosopher, observes, "Ethically, property rights of any kind have to be justified as extensions of the right of individuals to control their own lives. Thus any alleged property rights that conflict with this moral basis—like the "right" to own slaves—are invalidated. In my judgment, intellectual property rights also fail to pass this test. To enforce copyright laws and the like is to prevent people from making peaceful use of the information they possess. If you have acquired the information legitimately (say, by buying a book), then on what grounds can you be prevented from using it, reproducing it, trading it? Is this not a violation of the freedom of speech and press? It may be objected that the person who originated the information deserves ownership rights over it. But information is not a concrete thing an individual can control; it is a universal, existing in other people's minds and other people's property, and over these the originator has no legitimate sovereignty. You cannot own information without owning other people". Machlup concluded that patents do not have the intended effect of enhancing innovation. Self-declared anarchist Proudhon, in his 1847 seminal work noted, "Monopoly is the natural opposite of competition," and continued, "Competition is the vital force which animates the collective being: to destroy it, if such a supposition were possible, would be to kill society"
Mindeli and Pipiya hold that the knowledge economy is an economy of abundance because it relies on the "infinite potential" of knowledge and ideas rather than on the limited resources of natural resources, labor and capital. Allison envisioned an egalitarian distribution of knowledge. Kinsella claims that IPR create artificial scarcity and reduce equality. Bouckaert wrote, "Natural scarcity is that which follows from the relationship between man and nature. Scarcity is natural when it is possible to conceive of it before any human, institutional, contractual arrangement. Artificial scarcity, on the other hand, is the outcome of such arrangements. Artificial scarcity can hardly serve as a justification for the legal framework that causes that scarcity. Such an argument would be completely circular. On the contrary, artificial scarcity itself needs a justification" Corporations fund much IP creation and can acquire IP they do not create, to which Menon and others object. Andersen claims that IPR has increasingly become an instrument in eroding public domain.
Ethical and legal issues include: Patent infringement, copyright infringement, trademark infringement, patent and copyright misuse, submarine patents, biological patents, patent, copyright and trademark trolling, Employee raiding and monopolizing talent, Bioprospecting, biopiracy and industrial espionage, digital rights management.
Notable IP copyright cases include Napster, Eldred v. Ashcroft and Air Pirates.
International issues.
While business ethics emerged as a field in the 1970s, international business ethics did not emerge until the late 1990s, looking back on the international developments of that decade. Many new practical issues arose out of the international context of business. Theoretical issues such as cultural relativity of ethical values receive more emphasis in this field. Other, older issues can be grouped here as well. Issues and subfields include:
The success of any business depends on its financial performance. Financial accounting helps the management to report and also control the business performance.
The information regarding the financial performance of the company plays an important role in enabling people to take right decision about the company. Therefore, it becomes necessary to understand how to record based on accounting conventions and concepts ensure unambling and accurate records.
Foreign countries often use dumping as a competitive threat, selling products at prices lower than their normal value. This can lead to problems in domestic markets. It becomes difficult for these markets to compete with the pricing set by foreign markets. In 2009, the International Trade Commission has been researching anti-dumping laws. Dumping is often seen as an ethical issue, as larger companies are taking advantage of other less economically advanced companies.
Economic systems.
Political economy and political philosophy have ethical implications, particularly regarding the distribution of economic benefits. John Rawls and Robert Nozick are both notable contributors. For example, Rawls has been interpreted as offering a critique of offshore outsourcing on social contract grounds, whereas Nozick's libertarian philosophy rejects the notion of any positive corporate social obligation.
Law and regulation.
“Laws” are the written statutes, codes, and opinions of government organizations by which citizens, businesses, and persons present within a jurisdiction are expected to govern themselves or face legal sanction. Sanctions for violating the law can include (a) civil penalties, such as fines, pecuniary damages, and loss of licenses, property, rights, or privileges; (b) criminal penalties, such as fines, probation, imprisonment, or a combination thereof; or (c) both civil and criminal penalties.
Very often it is held that business is not bound by any ethics other than abiding by the law. Milton Friedman is the pioneer of the view. He held that corporations have the obligation to make a profit within the framework of the legal system, nothing more. Friedman made it explicit that the duty of the business leaders is, "to make as much money as possible while conforming to the basic rules of the society, both those embodied in the law and those embodied in ethical custom". Ethics for Friedman is nothing more than abiding by 'customs' and 'laws'. The reduction of ethics to abidance to laws and customs however have drawn serious criticisms.
Counter to Friedman's logic it is observed that legal procedures are technocratic, bureaucratic, rigid and obligatory where as ethical act is conscientious, voluntary choice beyond normativity. Law is retroactive. Crime precedes law. Law against a crime, to be passed, the crime must have happened. Laws are blind to the crimes undefined in it. Further, as per law, "conduct is not criminal unless forbidden by law which gives advance warning that such conduct is criminal". Also, law presumes the accused is innocent until proven guilty and that the state must establish the guilt of the accused beyond reasonable doubt. As per liberal laws followed in most of the democracies, until the government prosecutor proves the firm guilty with the limited resources available to her, the accused is considered to be innocent. Though the liberal premises of law is necessary to protect individuals from being persecuted by Government, it is not a sufficient mechanism to make firms morally accountable.
Implementation.
Corporate policies.
As part of more comprehensive compliance and ethics programs, many companies have formulated internal policies pertaining to the ethical conduct of employees. These policies can be simple exhortations in broad, highly generalized language (typically called a corporate ethics statement), or they can be more detailed policies, containing specific behavioural requirements (typically called corporate ethics codes). They are generally meant to identify the company's expectations of workers and to offer guidance on handling some of the more common ethical problems that might arise in the course of doing business. It is hoped that having such a policy will lead to greater ethical awareness, consistency in application, and the avoidance of ethical disasters.
An increasing number of companies also require employees to attend seminars regarding business conduct, which often include discussion of the company's policies, specific case studies, and legal requirements. Some companies even require their employees to sign agreements stating that they will abide by the company's rules of conduct.
Many companies are assessing the environmental factors that can lead employees to engage in unethical conduct. A competitive business environment may call for unethical behaviour. Lying has become expected in fields such as trading. An example of this are the issues surrounding the unethical actions of the Saloman Brothers.
Not everyone supports corporate policies that govern ethical conduct. Some claim that ethical problems are better dealt with by depending upon employees to use their own judgment.
Others believe that corporate ethics policies are primarily rooted in utilitarian concerns, and that they are mainly to limit the company's legal liability, or to curry public favour by giving the appearance of being a good corporate citizen. Ideally, the company will avoid a lawsuit because its employees will follow the rules. Should a lawsuit occur, the company can claim that the problem would not have arisen if the employee had only followed the code properly.
Sometimes there is disconnection between the company's code of ethics and the company's actual practices. Thus, whether or not such conduct is explicitly sanctioned by management, at worst, this makes the policy duplicitous, and, at best, it is merely a marketing tool.
Jones and Parker write, "Most of what we read under the name business ethics is either sentimental common sense, or a set of excuses for being unpleasant." Many manuals are procedural form filling exercises unconcerned about the real ethical dilemmas. For instance, US Department of Commerce ethics program treats business ethics as a set of instructions and procedures to be followed by 'ethics officers'., some others claim being ethical is just for the sake of being ethical. Business ethicists may trivialize the subject, offering standard answers that do not reflect the situation's complexity.
Author of 'Business Ethics,' Richard DeGeorge writes in regard to the importance of maintaining a corporate code, "Corporate codes have a certain usefulness and there are several advantages to developing them. First, the very exercise of doing so in itself is worthwhile, especially if it forces a large number of people in the firm to think through, in a fresh way, their mission and the important obligations they as a group and as individuals have to the firm, to each other, to their clients and customers, and to society as a whole. Second, once adopted a code can be used to generate continuing discussion and possible modification to the code. Third, it could help to inculcate in new employees at all levels the perspective of responsibility, the need to think in moral terms about their actions, and the importance of developing the virtues appropriate to their position."
Ethics officers.
Ethics officers (sometimes called "compliance" or "business conduct officers") have been appointed formally by organizations since the mid-1980s. One of the catalysts for the creation of this new role was a series of fraud, corruption, and abuse scandals that afflicted the U.S. defense industry at that time. This led to the creation of the Defense Industry Initiative (DII), a pan-industry initiative to promote and ensure ethical business practices. The DII set an early benchmark for ethics management in corporations. In 1991, the Ethics & Compliance Officer Association (ECOA)—originally the Ethics Officer Association (EOA)—was founded at the Center for Business Ethics (at Bentley College, Waltham, MA) as a professional association for those responsible for managing organizations' efforts to achieve ethical best practices. The membership grew rapidly (the ECOA now has over 1,200 members) and was soon established as an independent organization.
Another critical factor in the decisions of companies to appoint ethics/compliance officers was the passing of the Federal Sentencing Guidelines for Organizations in 1991, which set standards that organizations (large or small, commercial and non-commercial) had to follow to obtain a reduction in sentence if they should be convicted of a federal offense. Although intended to assist judges with sentencing, the influence in helping to establish best practices has been far-reaching.
In the wake of numerous corporate scandals between 2001 and 2004 (affecting large corporations like Enron, WorldCom and Tyco), even small and medium-sized companies have begun to appoint ethics officers. They often report to the Chief Executive Officer and are responsible for assessing the ethical implications of the company's activities, making recommendations regarding the company's ethical policies, and disseminating information to employees. They are particularly interested in uncovering or preventing unethical and illegal actions. This trend is partly due to the Sarbanes–Oxley Act in the United States, which was enacted in reaction to the above scandals. A related trend is the introduction of risk assessment officers that monitor how shareholders' investments might be affected by the company's decisions.
The effectiveness of ethics officers is not clear. If the appointment is made primarily as a reaction to legislative requirements, one might expect little impact, at least over the short term. In part, this is because ethical business practices result from a corporate culture that consistently places value on ethical behaviour, a culture and climate that usually emanates from the top of the organization. The mere establishment of a position to oversee ethics will most likely be insufficient to inculcate ethical behaviour: a more systemic programme with consistent support from general management will be necessary.
The foundation for ethical behaviour goes well beyond corporate culture and the policies of any given company, for it also depends greatly upon an individual's early moral training, the other institutions that affect an individual, the competitive business environment the company is in and, indeed, society as a whole.
Sustainability Initiatives.
Many corporate and business strategies now include sustainability. In addition to the traditional environmental 'green' sustainability concerns, business ethics practices have expanded to include social sustainability. Social sustainability focuses on issues related to human capital in the business supply chain, such as worker's rights, working conditions, child labor, and human trafficking. Incorporation of these considerations is increasing, as consumers and procurement officials demand documentation of a business' compliance with national and international initiatives, guidelines, and standards. Many industries have organizations dedicated to verifying ethical delivery of products from start to finish, such as the Kimberly Process, which aims to stop the flow of conflict diamonds into international markets, or the Fair Wear Foundation, dedicated to sustainability and fairness in the garment industry.
Academic discipline.
As an academic discipline, business ethics emerged in the 1970s. Since no academic business ethics journals or conferences existed, researchers published in general management journals, and attended general conferences. Over time, specialized peer-reviewed journals appeared, and more researchers entered the field. Corporate scandals in the earlier 2000s increased the field's popularity. As of 2009, sixteen academic journals devoted to various business ethics issues existed, with Journal of Business Ethics and Business Ethics Quarterly considered the leaders.
The International Business Development Institute is a global non-profit organization that represents 217 nations and all 50 United States. It offers a Charter in Business Development (CBD) that focuses on ethical business practices and standards. The Charter is directed by Harvard, MIT, and Fulbright Scholars, and it includes graduate-level coursework in economics, politics, marketing, management, technology, and legal aspects of business development as it pertains to business ethics. IBDI also oversees the International Business Development Institute of Asia which provides individuals living in 20 Asian nations the opportunity to earn the Charter.
Religious views.
In Sharia law, followed by many Muslims, banking specifically prohibits charging interest on loans. Traditional Confucian thought discourages profit-seeking. Christianity offers the Golden Rule command, "Therefore all things whatsoever ye would that men should do to you, do ye even so to them: for this is the law and the prophets."
According to the article "Theory of the real economy", there is a more narrow point of view from the Christianity faith towards the relationship between ethics and religious traditions. This article stresses about how capable is Christianity of establishing reliable boundaries for financial institutions. One criticism comes from Pope Benedict by describing the "damaging effects of the real economy of badly managed and largely speculative financial dealing." It is mentioned that Christianity has the potential to transform the nature of finance and investment but only if theologians and ethicist provide more evidence of what is real in the economic life. Business ethics receives an extensive treatment in Jewish thought and Rabbinic literature, both from an ethical ("Mussar") and a legal ("Halakha") perspective; see article "Jewish business ethics" for further discussion.
Related disciplines.
Business ethics is part of the philosophy of economics, the branch of philosophy that deals with the philosophical, political, and ethical underpinnings of business and economics. Business ethics operates on the premise, for example, that the ethical operation of a private business is possible—those who dispute that premise, such as libertarian socialists, (who contend that "business ethics" is an oxymoron) do so by definition outside of the domain of business ethics proper.
The philosophy of economics also deals with questions such as what, if any, are the social responsibilities of a business; business management theory; theories of individualism vs. collectivism; free will among participants in the marketplace; the role of self interest; invisible hand theories; the requirements of social justice; and natural rights, especially property rights, in relation to the business enterprise.
Business ethics is also related to political economy, which is economic analysis from political and historical perspectives. Political economy deals with the distributive consequences of economic actions.

</doc>
<doc id="4772" url="https://en.wikipedia.org/wiki?curid=4772" title="BBS">
BBS

BBS may refer to:

</doc>
<doc id="4775" url="https://en.wikipedia.org/wiki?curid=4775" title="British Standards">
British Standards

British Standards are the standards produced by BSI Group which is incorporated under a Royal Charter (and which is formally designated as the National Standards Body (NSB) for the UK). The BSI Group produces British Standards under the authority of the Charter, which lays down as one of the BSI's objectives to:
Formally, as per the 2002 Memorandum of Understanding between the BSI and the United Kingdom Government, British Standards are defined as:
Products and services which BSI certifies as having met the requirements of specific standards within designated schemes are awarded the Kitemark.
How British Standards are made.
The BSI Group as a whole does not produce British Standards, as standards work within the BSI is decentralized. The governing Board of BSI establishes a Standards Board. The Standards Board does little apart from setting up Sector Boards (a Sector in BSI parlance being a field of standardization such as ICT, Quality, Agriculture, Manufacturing, or Fire). Each Sector Board in turn constitutes several Technical Committees. It is the Technical Committees that, formally, approve a British Standard, which is then presented to the Secretary of the supervisory Sector Board for endorsement of the fact that the Technical Committee has indeed completed a task for which it was constituted.
The standards.
The standards produced are titled British Standard XXXX[-P]:YYYY where XXXX is the number of the standard, P is the number of the part of the standard (where the standard is split into multiple parts) and YYYY is the year in which the standard came into effect. BSI Group currently has over 27,000 active standards. Products are commonly specified as meeting a particular British Standard, and in general this can be done without any certification or independent testing. The standard simply provides a shorthand way of claiming that certain specifications are met, while encouraging manufacturers to adhere to a common method for such a specification.
The Kitemark can be used to indicate certification by BSI, but only where a Kitemark scheme has been set up around a particular standard. It is mainly applicable to safety and quality management standards. There is a common misunderstanding that Kitemarks are necessary to prove compliance with any BS standard, but in general it is neither desirable nor possible that every standard be 'policed' in this way.
Following the move on harmonisation of the standard in Europe, some British Standards are gradually superseded or replaced by the relevant European Standards (EN).
Status of standards.
Standards are continuously reviewed and developed and are periodically allocated one or more of the following status keywords.
History.
BSI Group began in 1901 as the "Engineering Standards Committee", led by James Mansergh, to standardise the number and type of steel sections, in order to make British manufacturers more efficient and competitive.
Over time the standards developed to cover many aspects of tangible engineering, and then engineering methodologies including quality systems, safety and security.
PAS Documents.
BSI also publishes a series of PAS documents.
PAS documents are a flexible and rapid standards development model that is open to all organizations. A PAS is a sponsored piece of work allowing organizations flexibility in the rapid creation of a standard while also allowing for a greater degree of control over the document's development. A typical development time frame for a PAS is around 6–9 months. Once published by BSI a PAS has all the functionality of a British Standard for the purposes of creating schemes such as management systems and product benchmarks as well as codes of practice. A PAS is a living document and after two years the document will be reviewed and a decision made with the client as to whether or not this should be taken forward to become a formal British standard. The term PAS was originally an acronym derived from "product approval specification", a name which was subsequently changed to “publicly available specification”. However, according to BSI, not all PAS documents are structured as specifications and the term is now sufficiently well established not to require any further amplification.
Availability.
Copies of British Standards are sold at the BSI Online Shop or can be accessed via subscription to British Standards Online (BSOL). They can also be ordered via the publishing units of many other national standards bodies (ANSI, DIN, etc.) and from several specialized suppliers of technical specifications.
British Standards, including European and International adoptions are available in many university and public libraries that subscribe to the BSOL platform. Librarians and lecturers at UK-based subscribing universities have full access rights to the collection while students can copy/paste and print but not download a standard. Up to 10% of the content of a standard can be copy/pasted for personal or internal use and up to 5% of the collection made available as a paper or electronic reference collection at the subscribing university. Because of their reference material status standards are not available for interlibrary loan. Public Library users in the UK may have access to BSOL on a view-only basis if their library service subscribes to the BSOL platform. Users may also be able to access the collection remotely if they have a valid library card and the library offers secure access to its resources.
The BSI Knowledge Centre in Chiswick can be contacted directly about viewing standards in their Members’ Reading Room.

</doc>
<doc id="4776" url="https://en.wikipedia.org/wiki?curid=4776" title="Building society">
Building society

A building society is a financial institution owned by its members as a mutual organization. Building societies offer banking and related financial services, especially savings and mortgage lending. These institutions are found in the United Kingdom (UK) and several other countries.
The term "building society" first arose in the 18th century in Great Britain from cooperative savings groups. In the UK today, building societies actively compete with banks for most consumer banking services, especially mortgage lending and savings accounts.
Every building society in the UK is a member of the Building Societies Association. At the start of 2008, there were 59 building societies in the UK, with total assets exceeding £360 billion. The number of societies in the UK fell by four during 2008 due to a series of mergers brought about, to a large extent, by the consequences of the financial crisis of 2007-2010. With three further mergers in each of 2009 and 2010, and a demutualisation and a merger in 2011, there are now 45 building societies.
History.
The origins of the building society as an institution lie in late-18th century Birmingham - a town which was undergoing rapid economic and physical expansion driven by a multiplicity of small metalworking firms, whose many highly skilled and prosperous owners readily invested in property. Many of the early building societies were based in taverns or coffeehouses, which had become the focus for a network of clubs and societies for co-operation and the exchange of ideas among Birmingham's highly active citizenry as part of the movement known as the Midlands Enlightenment. The first building society to be established was Ketley's Building Society, founded by Richard Ketley, the landlord of the "Golden Cross" inn, in 1775. Members of Ketley's society paid a monthly subscription to a central pool of funds which was used to finance the building of houses for members, which in turn acted as collateral to attract further funding to the society, enabling further construction. By 1781 three more societies had been established in Birmingham, with a fourth in the nearby town of Dudley; and 19 more formed in Birmingham between 1782 and 1795. The first outside the English Midlands was established in Leeds in 1785.
Most of the original societies were fully "terminating", where they would be dissolved when all members had a house: the last of them, First Salisbury and District Perfect Thrift Building Society, was wound up in March 1980. In the 1830s and 1840s a new development took place with the "permanent building society", where the society continued on a rolling basis, continually taking in new members as earlier ones completed purchases, such as Leek United Building Society. The main legislative framework for the building society was the Building Societies Act 1874, with subsequent amending legislation in 1894, 1939 (see Coney Hall), and 1960.
In their heyday, there were hundreds of building societies: just about every town in the country had a building society named after that town. Over succeeding decades the number of societies has decreased, as various societies merged to form larger ones, often renaming in the process, and other societies opted for demutualisation followed by – in the great majority of cases – eventual takeover by a listed bank. Most of the existing larger building societies are the end result of the mergers of many smaller societies.
1980s and 1990s.
In the 1980s, British banking laws were changed to allow building societies to offer banking services equivalent to normal banks. The management of a number of societies still felt that they were unable to compete with the banks, and a new Building Societies Act was passed in 1986 in response to their concerns. This permitted societies to 'demutualise'. If more than 75% of members voted in favour, the building society would then become a limited company like any other. Members' mutual rights were exchanged for shares in this new company. A number of the larger societies made such proposals to their members and all were accepted. Some became independent companies quoted on the London Stock Exchange, others were acquired by larger financial groups.
The process began with the demutualisation of the Abbey National Building Society in 1989. Then, from 1995 to late-1999, eight societies demutualised accounting for two-thirds of building societies assets as at 1994. Five of these societies became joint stock banks (plc), one merged with another and the other four were taken over by plcs (in two cases after the mutual had previously converted to a plc).
As Tayler (2003) refers, demutualisation moves succeeded immediately because neither Conservative nor Labour party UK governments created a framework which put obstacles in the way of demutualisation. Political acquiescence in demutualisation was clearest in the case of the position on 'carpet baggers', that is those who joined societies by lodging minimum amounts of £100 or so in the hope of profiting from a distribution of surplus after demutualisation. The deregulating Building Societies Act 1986 contained an anti-carpet bagger provision in the form of a two-year rule. This prescribed a qualifying period of two years before savers could participate in a residual claim. But, before the 1989 Abbey National Building Society demutualisation, the courts found against the two-year rule after legal action brought by Abbey National itself to circumvent the intent of the legislators. After this the legislation did prevent a cash distribution to members of less than two years standing, but the same result was obtained by permitting the issue of 'free' shares in the acquiring plc, saleable for cash. The Thatcher Conservative government declined to introduce amending legislation to make good the defect in the 'two-year rule'.
Building societies, like mutual life insurers, arose as people clubbed together to address a common need interest; in the case of the building societies, this was housing and members were originally both savers and borrowers. But it very quickly became clear that 'outsider' savers were needed whose motive was profit through interest on deposits. Thus permanent building societies quickly became mortgage banks and in such institutions there always existed a conflict of interest between borrowers and savers. It was the task of the movement to reconcile that conflict of interest so as to enable savers to conclude that their interests and those of borrowers were to some extent complementary rather than conflictive. Conflict of interest between savers and borrowers was never fully reconciled in the building societies but upon deregulation that reconciliation became something of a lost cause. The management of building societies apparently could expend considerable time and resources (which belonged the organisation) planning their effective capture—of as much of the assets as they could. If so, this is arguably insider dealing on a grand scale with the benefit of inside specialist knowledge of the business and resources of the firm not shared with outsiders like politicians and members (and, perhaps, regulators). Once the opportunity to claim was presented by management the savers in particular could be relied upon to seize it. There were sufficient hard up borrowers to take the inducement offered them by management (in spite of few simple sums sufficing to demonstrate that they were probably going to end up effectively paying back the inducement). (Tayler 2003)
Managements promoting demutualisation also thereby met managerial objectives because the end of mutuality brought joint stock company (plc) style remuneration committee pay standards and share options. Share options for management of converting societies appear to be a powerful factor in management calculation. Rasmusen (1988) refers to this in the following terms:
" ... perks do not rise in proportion to bank size. If a mutual is large, or is expected to grow if it can raise capital by a conversion, its managers derive more value from a conversion but do not suffer much loss of perks than if the bank were small. Their benefit is in the right to purchase the new stock, which are valuable because the new issues are consistently underpriced [referring to USA mutual bank conversions. Moreover, by no means are all mutual managers incompetent, and conversions allows the bank to expand more easily and to grant executive stock options that are valuable to skilled managers".
Instead of deploying their margin advantage as a defence of mutuality, around 1980 building societies began setting mortgage rates with reference to market clearing levels. In sum they began behaving more like banks, seeking to maximise profit instead of the advantages of a mutual organisation. Thus, according to the Bank of England's Boxall and Gallagher (1997), "... there was virtually no difference between banks and building society 'listed' interest rates for home finance mortgage lending between 1984 and 1997. This behaviour resulted in a return on assets for building societies which was at least as high as Plc banks and, in the absence of distribution, led to rapid accumulation of reserves". As Boxall and Gallagher (1997) also observe; "... accumulation of reserves in the early-1990s, beyond regulatory and future growth requirements, is difficult to reconcile with conventional theories of mutual behaviour".
Llewellyn (1996) draws a rather more direct and cynical conclusion:
Some of these managements ended up in dispute with their own members. Of the first major conversion of the Abbey in 1989, Kay (1991) observed:
In the end, after a number of large demutualisations, and pressure from carpetbaggers moving from one building society to another to cream off the windfalls, most of the remaining societies modified their rules of membership in the late 1990s. The method usually adopted were membership rules to ensure that anyone newly joining a society would, for the first few years, be unable to get any profit out of a demutualisation. With the chance of a quick profit removed, the wave of demutualisations came to an end in 2000.
One academic study (Heffernan, 2003) found that demutualised societies' pricing behaviour on deposits and mortgages was more favourable to shareholders than to customers, with the remaining mutual building societies offering consistently better rates.
2000s and 2010s.
The Butterfill Act was passed in 2007 giving building societies greater powers to merge with other companies. These powers have been used by the Britannia in 2009 and Kent Reliance in 2011 leading to their demutualisation.
Prior to 31 December 2010, deposits with building societies of up to £50,000 per individual, per institution, were normally protected by the Financial Services Compensation Scheme (FSCS), but Nationwide and Yorkshire Building Societies negotiated a temporary change to the terms of the FSCS to protect members of the societies they acquired in late 2008/early 2009. The amended terms allowed former members of multiple societies which merge into one to maintain multiple entitlements to FSCS protection until 30 September 2009 (later extended to 30 December 2010), so (for example) a member with £50,000 in each of Nationwide, Cheshire and Derbyshire at the time of the respective mergers would retain £150,000 of FSCS protection for their funds in the merged Nationwide. On 31 December 2010 the general FSCS limit for retail deposits was increased to £85,000 for banks and building societies and the transitional arrangements in respect of building society mergers came to an end.
List of building societies.
United Kingdom.
Current.
The remaining building societies are:
Source: Building Societies Association updated for subsequent mergers
Demutualised.
Ten building societies of the United Kingdom demutualised between 1989 and 2000, either becoming a bank or being acquired by a larger bank. By 2008, every building society that floated on the stock market in the wave of demutualisations of the 1980s and 1990s had either been sold to a conventional bank, or been nationalised.
No longer exist.
The following is an incomplete list of building societies in the United Kingdom that no longer exist independently, since they either merged with or were taken over by other building societies or mutuals. However, they may still have an active presence on the high street (or online) as a trading name or as a distinct brand. This is typically because brands will often build up specific reputations and attract certain clientele, and this can continue to be marketed successfully.
Australia.
In Australia, building societies evolved along British lines. Because of strict regulations on banks, building societies flourished until the deregulation of the Australian financial industry in the 1980s. Eventually many of the smaller building societies disappeared, while some of the largest (such as St. George) officially attained the status of banks. Recent conversions have included Heritage Bank which converted from building society to bank in 2011, Hume in 2014, while Wide Bay Building Society became Auswide Bank and IMB followed suit in 2015. Building societies converting to banks are no longer required to demutualise.
A particular difference between Australian building societies and those elsewhere, is that Australian building societies are required to incorporate as limited companies.
Current building societies are
Ireland.
The Republic of Ireland had around 40 building societies at the mid-20th century peak. Many of these were very small and, as the Irish commercial banks began to originate residential mortgages, the small building societies ceased to be competitive. Most merged or dissolved or, in the case of First Active plc, converted into conventional banks. The last remaining building societies, EBS Building Society and Irish Nationwide Building Society, demutualised and were transferred or acquired into Bank subsidiaries in 2011 following the effects of the Irish financial crisis.
Leeds Building Society Ireland and Nationwide UK (Ireland) are Irish branches of building societies based in the United Kingdom.
Jamaica.
In Jamaica, three building societies compete with commercial banks and credit unions for most consumer financial services:
New Zealand.
Regulation.
In New Zealand, building societies are registered with the Registrar of Building Societies under the Building Societies Act 1965. Registration as a building society is merely a process of establishing the entity as a corporation. It is largely a formality, and easily achieved, as the capital requirement is minimal (20 members must be issued shares of not less than NZ$1,000 each, for a total minimum foundation share capital of NZ$200,000).
As regards prudential supervision, a divide exists between building societies that operate in New Zealand, on the one hand, and those that (although formally registered in New Zealand) operate offshore:
Building societies' registration details and filed documents are available in the Register of Building Societies held at the New Zealand Companies Office.
Individual building societies.
Over the years, a number of building societies were established.
Some, including Countrywide Building Society and United Building Society, became banks in the 1980s and 1990s. Heartland Building Society (created in 2011 through a merger of Canterbury Building Society, Southern Cross Building Society, and two other financial institutions) became Heartland Bank on 17 December 2012.
Remaining building societies include:
Zimbabwe.
In Zimbabwe, "Central Africa Building Society" (CABS) is the leading building society offering a diverse range of financial products and services that include transaction and savings accounts, mobile banking, mortgage loans, money market investments, term deposits and pay-roll loans.
Similar organisations in other countries.
In other countries there are mutual organisations similar to building societies:
Operational differences from banks.
Because most building societies were not direct members of the UK clearing system, it was common for them to use a roll number to identify accounts rather than to allocate a six-digit sort-code and eight-digit account number to the BACS standards.
More recently, building societies have tended to obtain sort-code and account number allocations within the clearing system, and hence the use of roll numbers has diminished. When using BACS, one needs to enter roll numbers for the reference field and the building society's generic sort code and account number would be entered in the standard BACS fields.

</doc>
<doc id="4777" url="https://en.wikipedia.org/wiki?curid=4777" title="Blue Steel (missile)">
Blue Steel (missile)

The Avro Blue Steel was a British air-launched, rocket-propelled nuclear armed standoff missile, built to arm the V bomber force. It allowed the bomber to launch the missile against its target while still outside the range of surface-to-air missiles (SAMs). The missile proceeded to the target at high speeds up to Mach 3, and would trigger within 100 m of the pre-defined target point.
Blue Steel entered service in 1963, by which point improved SAMs with longer range had greatly eroded the advantages of the design. A longer-range version, Blue Steel II, was considered, but canceled in favour of the much longer-range GAM-87 Skybolt system from the US. When that system was cancelled in 1962 the V-bomber fleet was considered highly vulnerable. Blue Steel remained the primary British nuclear deterrent weapon until the Royal Navy started operating Polaris missile armed Resolution-class submarines.
Development.
Blue Steel was the result of a Ministry of Supply memorandum from 5 November 1954 that predicted that by 1960 Soviet air defences would make it prohibitively dangerous for V bombers to attack with nuclear gravity bombs. The answer was for a rocket-powered, supersonic missile capable of carrying a large nuclear (or projected thermonuclear) warhead with a range of at least . This would keep the bombers out of range of Soviet ground-based defences installed around the target area, allowing the warhead to "dash" in at high speed.
There would have to be a balance between the size of the warhead, the need for it to be carried by any of the three V-bomber types in use, and that it should be able to reach Mach 3. At the time the only strategic warheads available in the UK were the Orange Herald and Green Bamboo, both of which were very large weapons demanding a large missile fuselage. The Air Staff issued this requirement for a "stand-off bomb" as OR.1132 in September 1954.
The Ministry of Supply selected Avro out of the British manufacturers though it had no previous experience in working on guided weapons other than some private venture work; Handley Page had suggested a missile but the Elliots gyro based guidance system was inaccurate beyond .
Avro began work proper in 1955, with the assigned Rainbow Code name of "Blue Steel" which it would keep in service. With Elliots working on the guidance system Armstrong Siddeley would develop the liquid fuel engine.
Its design period was protracted, with various development problems exacerbated by the fact that designers lacked information on the actual size and weight of the proposed boosted fission warhead Green Bamboo, or its likely thermonuclear successor derived from the Granite series. The large girth of Blue Steel was determined by the implosion sphere diameter of Green Bamboo.
Avro proposed that Blue Steel would evolve over time, subsequent versions increasing speed (to Mach 4.5) and range. The ultimate Blue Steel would be a range weapon that could be launched by the supersonic Avro 730 under development. They were told to limit themselves to the specification of OR.1132. The project was delayed by the need to develop the stainless steel fabrication techniques; this would have been gained in building the Avro 730 but that had been cancelled by then. Elliots guidance system was plagued by accuracy problems delaying test flights.
As it turned out, neither of the originally-proposed UK-designed warheads were actually fitted, being superseded by Red Snow, an Anglicised variant of the U.S. W-28 thermonuclear warhead of 1.1 Mt yield. Red Snow was smaller and lighter than the earlier warhead proposals. The missile was fitted with a state-of-the-art inertial navigation unit. This system allowed the missile to strike within 100 metres of its designated target. In addition, the pilots of the Avro Vulcan or Handley Page Victor bombers could tie their systems into those of the missile and make use of the guidance system to help plot their own flight plan, since the unit in the missile was more advanced than that in the aircraft.
Blue Steel emerged as a pilotless, winged aircraft roughly the size of the experimental Saunders-Roe SR.53 interceptor, with clipped delta wings and small canard foreplanes. It was powered by a two-chamber Armstrong Siddeley Stentor Mark 101 rocket engine, burning a combination of hydrogen peroxide and kerosene. The fuel was a considerable operational problem, because fuelling the missile before launch took nearly half an hour, and was quite hazardous. It required the fuelling site to be flooded with water, and very early morning preparations because of the heat experienced during Australian summer. Another issue was the very small ground clearance when attached to the Handley Page Victor, and Victor aircrews were especially aware of the dangers when taking off. (The Vulcan had a much higher ground clearance, and ultimately proved a better platform).
On launch the rocket engine's first chamber developing thrust would power the missile along a predetermined course to the target at around Mach 1.5. Once close to the target, the second chamber of the engine (6,000 lb) would accelerate the missile to Mach 3. Over the target the engine would cut out and the missile would free-fall before detonating its warhead as an air burst.
To speed the trials at Woomera, the test rounds were flown there by Victors and Vulcans in Operation Blue Ranger. The trials began in 1960 about the time the original requirement expected the weapon to be in service. The missiles were prepared at the Weapons Research Establishment near Salisbury South Australia, and flown to be launched at the Woomera range from RAAF Edinburgh. A specialist RAF unit, 4 JSTU, was established to carry out preparatory and operational tasks. 
Blue Steel finally entered service in February 1963, being carried by Vulcans and Victors, although its limitations were already apparent. The short range of the missile meant that the V bombers were still vulnerable to enemy surface-to-air missiles. A replacement for Blue Steel, the Mark 2, was planned with increased range and a ramjet engine, but was cancelled in 1960 to minimise delays to the Mk.1. The UK sought to acquire the much longer-ranged United States Air Force AGM-48 Skybolt air-launched ballistic missile, and was greatly frustrated when that weapon was cancelled in late 1962.
Blue Steel required up to seven hours of launch preparation, and was highly unreliable. The Royal Air Force estimated in 1963 that half the missiles would fail to fire and would have to be dropped over their targets, contradicting their purpose of serving as standoff weapons. Even as it deployed Blue Steel, a high-altitude weapon, that year the government decided that because of anti-aircraft missiles' increasing effectiveness, V bombers would have to convert from high-altitude to low-altitude attacks. These trials were conducted in 1964 and concluded in 1965 With no effective long-range weapon the original Blue Steel served on after a crash programme of minor modifications to permit a low-level launch at , even though its usefulness in a hot war was likely limited. A stop-gap weapon (WE.177B) was quickly produced to extend the life of the V-bomber force in the strategic role until the Polaris missile was deployed. This WE.177 laydown weapon supplemented the remaining modified Blue Steel missiles using a low-level penetration followed by a pop-up manoeuvre to release the weapon at Forty-eight live operational rounds were deployed on 48 Vulcan and Victor bombers and a further five live rounds were produced as operational spares. An additional four non-nuclear rounds were produced for various RAF requirements, and there were 16 other unspecified training rounds.
Blue Steel was officially retired on 31 December 1970, with the United Kingdom's strategic nuclear capacity passing to the submarine fleet.

</doc>
<doc id="4778" url="https://en.wikipedia.org/wiki?curid=4778" title="Branch Davidians">
Branch Davidians

The Branch Davidians (also known as "The Branch") are a religious group that originated in 1955 from a schism in the Davidian Seventh-day Adventists ("Davidians"), a reform movement that began as an offshoot from the Seventh-day Adventist Church ("Adventists") around 1930. Some of those who accepted the reform message had been removed from membership of the Seventh-day Adventist Church because of their supplemental teachings.
From its inception in 1930, the reform movement believed themselves to be living in a time when Bible prophecies of a final divine judgment were coming to pass as a prelude to Christ's Second Coming. The name "Branch Davidian" is most widely known for the Waco siege of 1993 on their property (known as the Mount Carmel Center) near Waco, Texas. The 51-day siege, by the ATF, FBI, and Texas National Guard, resulted in the deaths of the Branch Davidians' leader, David Koresh, as well as 82 other Branch Davidian men, women, and children, and four ATF agents.
Today, the original Davidian Seventh-day Adventists and the Branch Davidian Seventh-day Adventists are two different and distinct groups. The doctrinal beliefs differ on such teachings as the Holy Spirit and His nature, the feast days and requirements, and who had the prophetic office since Victor Houteff's death.
Early history.
In 1929 Victor Houteff, a Bulgarian immigrant and a Seventh-day Adventist Sabbath School teacher in a local church in Southern California, claimed that he had a new message for the entire church. He presented this message in a book, "The Shepherd's Rod: The 144,000—A Call for Reformation". The Adventist leadership rejected Houteff's message as contrary to the Adventists' basic teachings and disfellowshipped Houteff and his followers. However, there was some controversy over the method the leadership took to disfellowship Houteff.
In 1935 Houteff established his headquarters to the west of Waco, Texas. After Houteff died in 1955, the segment of the group loyal to Houteff continued as the Davidian Seventh-day Adventists.
A splinter group, the Branch Davidian Seventh-day Adventists, was begun by Benjamin Roden and headed after Roden's death by his wife Lois Roden. After Lois Roden died a bitter power struggle ensued between Lois Roden's son George Roden and her designated successor David Koresh (then still using his birth name of Vernon Howell), eventually won by Koresh.
Waco siege.
By the time of the 1993 Waco siege, Koresh had encouraged his followers to think of themselves as "students of the Seven Seals" rather than as "Branch Davidians." During the standoff one of his followers publicly announced that he wanted them to thereafter be identified by the name "Koreshians".
It is claimed that Koresh was never authorised to use the name "Branch Davidians" for his breakaway sect, and that the church of that name continues to represent that part of the Branch church which did not follow him.

</doc>
<doc id="4779" url="https://en.wikipedia.org/wiki?curid=4779" title="Burwash Hall">
Burwash Hall

Burwash Hall is the second oldest of the residence buildings at Toronto's Victoria College. Construction began in 1911 and was completed in 1913. It was named after Nathanael Burwash, a former president of Victoria. The building is an extravagant Neo-Gothic work with turrets, gargoyles, and battlements. The architect was Henry Sproatt.
The building is divided between the large dining hall in the northwest and the student residence proper. The residence area is divided into two sections. The Upper Houses, built in 1913, consist of four houses: North House, Middle House, Gate House, and South House. The Lower Houses were built in 1931 and were originally intended to house theology students at Emmanuel College, whose current building was opened the same year. Ryerson House, Nelles House, Caven House, Bowles-Gandier House are now mostly home to undergraduate arts and science students. The latter two are mostly reserved for students in the new Vic One Programme.
Famous residents of Burwash include Vincent Massey, Lester B. Pearson, Don Harron, and Donald Sutherland. The upper houses were gutted and renovated in 1995. The lower houses have only been partially upgraded. Before the renovations the entire building was all male, but now every house is co-ed.
Each Upper House consists of three floors. The lower floor contains a common room equipped with kitchen facilities, couches and a television. The upper floors each have their own kitchen and dining area. All except North House have a very high bathroom ratio, with Gate House being the best with nine washrooms for its twenty-eight residents. Upper Houses are divided between double rooms and singles, with about sixty percent of the population being in doubles.
The Lower Houses each have four floors, but are much narrower with each level having only four rooms. Each level also has its own kitchen, but these are much smaller than in the Upper Houses. The Lower Houses do have far larger and better fitted common rooms that are similar to the ones the Upper Houses had before the renovations. The rooms in the Lower Houses are also considered more luxurious with hardwood floors and large sizes. Rooms in the Lower Houses are more expensive, however. Until 2003 the Lower Houses were restricted to upper year students but with the double cohort of graduates from Ontario schools many of the rooms were transformed into doubles and now hold first years.
To the west the Upper Houses look out on the Vic Quad and the main Victoria College building across it. West of the Lower Houses is the new Lester B. Pearson Garden of Peace and International Understanding and the E.J. Pratt Library beyond it. From the eastern side of the building, the Upper Houses look out at Rowell Jackman Hall and the Lower Houses see the St. Michael's College residence of Elmsley. The only exception is the view from Gate House's tower that looks down St. Mary's Street.
The dining hall is perhaps the best known part of the building to outsiders. It is the University of Toronto's largest, holding some 250 students and sixteen large tables. Hanging on the western wall is Queen Victoria's burial flag, given to the college soon after her death. Under the flag is the high table where the professors and college administration lunch. Historically, the Upper Houses each had their own table. Gate sat in the southwest corner, Middle sat in the far northeast, South sat in the table to the west of Middle, while North sat to the west of the southeast corner. The only lower house to have had a designated table was Caven, in the northwest corner beside the alumni table. (Note that prior to the 1995 renovations, some of these houses, particularly North and Caven, 'traditionally' sat elsewhere)
Gate House.
Gate House is one of the four Upper Houses of the Burwash Hall residence. Until 2007, when Victoria administration made it co-ed, Gate House was one of the last remaining all-male residence building in the University of Toronto. The Gate House emblem is the Phoenix, visible in the bottom-right corner of the Victoria College insignia.
Gate House, with the rest of Upper Burwash, opened in 1913 and has held students every year since then except 1995, when it was renovated. As an all-male residence from 1913 to 2007 it held a number of unique traditions. For 20 years Gate House hosted an annual party called Novemberfest in the Burwash dining hall. The Victoria Dean of Students cancelled Novemberfest in 2003, when police discovered widespread underage drinking and over 800 people in the dining hall, in violation of the fire code. Another Gate House tradition that no longer occurs is the "stirring the chicken," a dinner and keg party where house members cook chicken fajitas for hundreds of guests. Until 2007, Gate House held secretive first-year initiation ceremonies called Traditionals, which involved writing slogans on campus buildings in chalk, singing songs to the all-women's residence (who would then sing back to them), and leading first-years around the house blindfolded. Since Novemberfest, Gate House continued to have conflict with the Administration. In 2004 the Dean evicted three Gate House residents for allegedly "hog-tying" a first-year student. In 2007 President Paul W. Gooch wrote that Gate House undertook an "escalating series of actions" that were "defiant" and "disparaging of women", in response to Gate members constructing a 2.5-metre snow penis and placing a cooked pig's head in an Annesley bathroom. As punishment, during the fall exam period Gooch evicted two residents and relocated the remainder of Gate House to other places in the residence system, banned all current Gate House students from entering the building in 2008. Since this decision Gate House has become a co-ed residence identical to the other Upper Burwash houses. Notable residents of Gate House include Lester B. Pearson, former Prime Minister of Canada, and Simon Pulsifer, who "Time" magazine nicknamed "The Duke of Data" for his contributions to Wikipedia.
During its 93 years as a men's residence, Gate House developed a distinct character and reputation. These antics included pranks, toga parties, streaking, caroling to other residences, hazing rituals, "beer bashes" and "incessant pounding" on the Gate House table in the dining hall. Paul Gooch wrote that these traditions gave Gate House an "ethos" that contradicted his vision of residence life.
The all-male Gate House was known as a social centre and spirited, tight-knit community. According to Grayson Lee, who created the snow penis sculpture in 2007, most of its residents were "heartbroken" to leave. Former Gate House President Dave Ruhl commented that "the Gate House camaraderie is unique" and that living there was "one of the most important parts of the university experience" for many.
The Reuters news agency nicknamed Gate House "U of T's Animal House" because Donald Sutherland's memories of its parties are said to have influenced the script of the 1978 movie. The Toronto Star described Gooch's decision to put an end to its traditions, activities and distinguishing characteristics as "neutering Animal House."
Gate House has three floors which house 28 students, as well as a don and the Victoria College Residence Life Co-ordinator. Above the gate there is a tower that rises three stories higher and has a turret-style roof. The tower is locked during the school year and entering it is a Level 4 offense under the Victoria residence agreement for which the punishment is eviction from residence.
The first floor has one double room and one bathroom available to students. About half of the floor is taken up by the apartment of the Residence Life Coordinator. Lastly, on the first floor there is a house common room with a kitchen and two couches. The second floor has three double rooms and seven single rooms. It has three single washrooms and one larger communal one, as well as its own kitchen. This floor is home to the residence don, who has a larger room with a private washroom. The third floor is identical to the second except that in place of the don's room there are two single rooms.[http://web.archive.org/web/20110727185636/http://www.vicu.utoronto.ca/Assets/Victoria/assets/Upper_Burwash_2nd_and_3rd_Floor_10570_797531.jpg?method=1
Past Presidents of Gate House Include:

</doc>
<doc id="4781" url="https://en.wikipedia.org/wiki?curid=4781" title="Benzodiazepine">
Benzodiazepine

Benzodiazepines (BZD), sometimes called "benzos", are a class of psychoactive drugs whose core chemical structure is the fusion of a benzene ring and a diazepine ring. The first such drug, chlordiazepoxide (Librium), was discovered accidentally by Leo Sternbach in 1955, and made available in 1960 by Hoffmann–La Roche - which, since 1963, has also marketed the benzodiazepine diazepam (Valium). In 1977 benzodiazepines were globally the most prescribed medications.
Benzodiazepines enhance the effect of the neurotransmitter gamma-aminobutyric acid (GABA) at the GABAA receptor, resulting in sedative, hypnotic (sleep-inducing), anxiolytic (anti-anxiety), anticonvulsant, and muscle relaxant properties. High doses of many shorter-acting benzodiazepines may also cause anterograde amnesia and dissociation. These properties make benzodiazepines useful in treating anxiety, insomnia, agitation, seizures, muscle spasms, alcohol withdrawal and as a premedication for medical or dental procedures. Benzodiazepines are categorized as either short-, intermediate-, or long-acting. Short- and intermediate-acting benzodiazepines are preferred for the treatment of insomnia; longer-acting benzodiazepines are recommended for the treatment of anxiety.
Benzodiazepines are generally viewed as safe and effective for short-term use, although cognitive impairment and paradoxical effects such as aggression or behavioral disinhibition occasionally occur. A minority of people can have paradoxical reactions such as worsened agitation or panic. Long-term use is controversial because of concerns about adverse psychological and physical effects, decreasing effectiveness, and physical dependence and withdrawal. As a result of adverse effects associated with the long-term use of benzodiazepines, withdrawal from benzodiazepines, in general, leads to improved physical and mental health. The elderly are at an increased risk of suffering from both short- and long-term adverse effects, and as a result, all benzodiazepines are listed in the Beers List of inappropriate medications for older adults.
There is controversy concerning the safety of benzodiazepines in pregnancy. While they are not major teratogens, uncertainty remains as to whether they cause cleft palate in a small number of babies and whether neurobehavioural effects occur as a result of prenatal exposure; they are known to cause withdrawal symptoms in the newborn. Benzodiazepines can be taken in overdoses and can cause dangerous deep unconsciousness. However, they are much less toxic than their predecessors, the barbiturates, and death rarely results when a benzodiazepine is the only drug taken; however, when combined with other central nervous system (CNS) depressants such as ethanol and opioids, the potential for toxicity and fatal overdose increases. Benzodiazepines are commonly misused and taken in combination with other drugs of abuse.
Medical uses.
Benzodiazepines possess sedative, hypnotic, anxiolytic, anticonvulsant, muscle relaxant, and amnesic actions, which are useful in a variety of indications such as alcohol dependence, seizures, anxiety, panic, agitation, and insomnia. Most are administered orally; however, they can also be given intravenously, intramuscularly, or rectally. In general, benzodiazepines are well-tolerated and are safe and effective drugs in the short term for a wide range of conditions. Tolerance can develop to their effects and there is also a risk of dependence, and upon discontinuation a withdrawal syndrome may occur. These factors, combined with other possible secondary effects after prolonged use such as psychomotor, cognitive, or memory impairments, limit their long-term applicability. The effects of long-term use or misuse include the tendency to cause or worsen cognitive deficits, depression, and anxiety.
Panic disorder.
Because of their effectiveness, tolerability, and rapid onset of anxiolytic action, benzodiazepines are frequently used for the treatment of anxiety associated with panic disorder. However, there is disagreement among expert bodies regarding the long-term use of benzodiazepines for panic disorder. The views range from those that hold that benzodiazepines are not effective long-term and that they should be reserved for treatment-resistant cases to that they are as effective in the long term as selective serotonin reuptake inhibitors.
The American Psychiatric Association (APA) guidelines note that, in general, benzodiazepines are well tolerated, and their use for the initial treatment for panic disorder is strongly supported by numerous controlled trials. APA states that there is insufficient evidence to recommend any of the established panic disorder treatments over another. The choice of treatment between benzodiazepines, SSRIs, serotonin–norepinephrine reuptake inhibitors, tricyclic antidepressants, and psychotherapy should be based on the patient's history, preference, and other individual characteristics. Selective serotonin reuptake inhibitors are likely to be the best choice of pharmacotherapy for many patients with panic disorder, but benzodiazepines are also often used, and some studies suggest that these medications are still used with greater frequency than the SSRIs. One advantage of benzodiazepines is that they alleviate the anxiety symptoms much faster than antidepressants, and therefore may be preferred in patients for whom rapid symptom control is critical. However, this advantage is offset by the possibility of developing benzodiazepine dependence. APA does not recommend benzodiazepines for persons with depressive symptoms or a recent history of substance abuse. The APA guidelines state that, in general, pharmacotherapy of panic disorder should be continued for at least a year, and that clinical experience support continuing benzodiazepine treatment to prevent recurrence. Although major concerns about benzodiazepine tolerance and withdrawal have been raised, there is no evidence for significant dose escalation in patients using benzodiazepines long-term. For many such patients stable doses of benzodiazepines retain their efficacy over several years.
Guidelines issued by the UK-based National Institute for Health and Clinical Excellence (NICE), carried out a systematic review using different methodology and came to a different conclusion. They questioned the accuracy of studies that were not placebo-controlled. And, based on the findings of placebo-controlled studies, they do not recommend use of benzodiazepines beyond two to four weeks, as tolerance and physical dependence develop rapidly, with withdrawal symptoms including rebound anxiety occurring after six weeks or more of use. Nevertheless, benzodiazepines continue to be prescribed for the long-term treatment of anxiety disorders, although specific antidepressants and psychological therapies are recommended as the first-line treatment options with the anticonvulsant drug pregabalin indicated as a second- or third-line treatment and suitable for long-term use. NICE stated that long-term use of benzodiazepines for panic disorder with or without agoraphobia is an unlicensed indication, does not have long-term efficacy, and is, therefore, not recommended by clinical guidelines. Psychological therapies such as cognitive behavioural therapy are recommended as a first-line therapy for panic disorder; benzodiazepine use has been found to interfere with therapeutic gains from these therapies.
Benzodiazepines are usually administered orally; however, very occasionally lorazepam or diazepam may be given intravenously for the treatment of panic attacks.
Generalized anxiety disorder.
Benzodiazepines have robust efficacy in the short-term management of generalized anxiety disorder (GAD), but were not shown to be effective in producing long-term improvement overall. According to National Institute for Health and Clinical Excellence (NICE), benzodiazepines can be used in the immediate management of GAD, if necessary. However, they should not usually be given for longer than 2–4 weeks. The only medications NICE recommends for the longer term management of GAD are antidepressants.
Likewise, Canadian Psychiatric Association (CPA) recommends benzodiazepines alprazolam, bromazepam, lorazepam, and diazepam only as a second-line choice, if the treatment with two different antidepressants was unsuccessful. Although they are second-line agents, benzodiazepines can be used for a limited time to relieve severe anxiety and agitation. CPA guidelines note that after 4–6 weeks the effect of benzodiazepines may decrease to the level of placebo, and that benzodiazepines are less effective than antidepressants in alleviating ruminative worry, the core symptom of GAD. However, in some cases, a prolonged treatment with benzodiazepines as the add-on to an antidepressant may be justified.
A 2015 review found a larger effect with medications than talk therapy. Medications with benefit include serotonin-noradrenaline reuptake inhibitors, benzodiazepines, and selective serotonin reuptake inhibitors.
Insomnia.
Benzodiazepines can be useful for short-term treatment of insomnia. Their use beyond 2 to 4 weeks is not recommended due to the risk of dependence. It is preferred that benzodiazepines be taken intermittently and at the lowest effective dose. They improve sleep-related problems by shortening the time spent in bed before falling asleep, prolonging the sleep time, and, in general, reducing wakefulness. However, they worsen sleep quality by increasing light sleep and decreasing deep sleep. Other drawbacks of hypnotics, including benzodiazepines, are possible tolerance to their effects, rebound insomnia, and reduced slow-wave sleep and a withdrawal period typified by rebound insomnia and a prolonged period of anxiety and agitation.
The list of benzodiazepines approved for the treatment of insomnia is fairly similar among most countries, but which benzodiazepines are officially designated as first-line hypnotics prescribed for the treatment of insomnia can vary distinctly between countries. Longer-acting benzodiazepines such as nitrazepam and diazepam have residual effects that may persist into the next day and are, in general, not recommended.
It is not clear as to whether the new nonbenzodiazepine hypnotics (Z-drugs) are better than the short-acting benzodiazepines. The efficacy of these two groups of medications is similar. According to the US Agency for Healthcare Research and Quality, indirect comparison indicates that side-effects from benzodiazepines may be about twice as frequent as from nonbenzodiazepines. Some experts suggest using nonbenzodiazepines preferentially as a first-line long-term treatment of insomnia. However, the UK National Institute for Health and Clinical Excellence did not find any convincing evidence in favor of Z-drugs. NICE review pointed out that short-acting Z-drugs were inappropriately compared in clinical trials with long-acting benzodiazepines. There have been no trials comparing short-acting Z-drugs with appropriate doses of short-acting benzodiazepines. Based on this, NICE recommended choosing the hypnotic based on cost and the patient's preference.
Older adults should not use benzodiazepines to treat insomnia unless other treatments have failed to be effective. When benzodiazepines are used, patients, their caretakers, and their physician should discuss the increased risk of harms, including evidence which shows twice the incidence of traffic collisions among driving patients as well as falls and hip fracture for all older patients.
Seizures.
Prolonged convulsive epileptic seizures are a medical emergency that can usually be dealt with effectively by administering fast-acting benzodiazepines, which are potent anticonvulsants. In a hospital environment, intravenous clonazepam, lorazepam, and diazepam are first-line choices, clonazepam due to its stronger and more potent anticonvulsant action, diazepam due to its faster onset and lorazepam for its longer duration of action. In the community, intravenous administration is not practical and so rectal diazepam or (more recently) buccal midazolam are used, with a preference for midazolam as its administration is easier and more socially acceptable.
When benzodiazepines were first introduced, they were enthusiastically adopted for treating all forms of epilepsy. However, drowsiness and tolerance become problems with continued use and none are now considered first-line choices for long-term epilepsy therapy. Clobazam is widely used by specialist epilepsy clinics worldwide and clonazepam is popular in the Netherlands, Belgium and France. Clobazam was approved for use in the United States in 2011. In the UK, both clobazam and clonazepam are second-line choices for treating many forms of epilepsy. Clobazam also has a useful role for very short-term seizure prophylaxis and in catamenial epilepsy. Discontinuation after long-term use in epilepsy requires additional caution because of the risks of rebound seizures. Therefore, the dose is slowly tapered over a period of up to six months or longer.
Alcohol withdrawal.
Chlordiazepoxide is the most commonly used benzodiazepine for alcohol detoxification, but diazepam may be used as an alternative. Both are used in the detoxification of individuals who are motivated to stop drinking, and are prescribed for a short period of time to reduce the risks of developing tolerance and dependence to the benzodiazepine medication itself. The benzodiazepines with a longer half-life make detoxification more tolerable, and dangerous (and potentially lethal) alcohol withdrawal effects are less likely to occur. On the other hand, short-acting benzodiazepines may lead to breakthrough seizures, and are, therefore, not recommended for detoxification in an outpatient setting. Oxazepam and lorazepam are often used in patients at risk of drug accumulation, in particular, the elderly and those with cirrhosis, because they are metabolized differently from other benzodiazepines, through conjugation.
Benzodiazepines are the preferred choice in the management of alcohol withdrawal syndrome, in particular, for the prevention and treatment of the dangerous complication of seizures and in subduing severe delirium. Lorazepam is the only benzodiazepine with predictable intramuscular absorption and it is the most effective in preventing and controlling acute seizures.
Anxiety.
Benzodiazepines are sometimes used in the treatment of acute anxiety, as they bring about rapid and marked or moderate relief of symptoms in most individuals; however, they are not recommended beyond 2–4 weeks of use due to risks of tolerance and dependence and a lack of long-term effectiveness. As for insomnia, they may also be used on an irregular/"as-needed" basis, such as in cases where said anxiety is at its worst. Compared to other pharmacological treatments, benzodiazepines are twice as likely to lead to a relapse of the underlying condition upon discontinuation. Psychological therapies and other pharmacological therapies are recommended for the long-term treatment of generalized anxiety disorder. Antidepressants have higher remission rates and are, in general, safe and effective in the short and long term.
Other indications.
Benzodiazepines are often prescribed for a wide range of conditions:
Contraindications.
Because of their muscle relaxant action, benzodiazepines may cause respiratory depression in susceptible individuals. For that reason, they are contraindicated in people with myasthenia gravis, sleep apnea, bronchitis, and COPD. Caution is required when benzodiazepines are used in people with personality disorders or intellectual disability because of frequent paradoxical reactions. In major depression, they may precipitate suicidal tendencies and are sometimes used for suicidal overdoses. Individuals with a history of alcohol, opioid and barbiturate abuse should avoid benzodiazepines, as there is a risk of life-threatening interactions with these drugs.
Pregnancy.
In the United States, the Food and Drug Administration has categorized benzodiazepines into either category D or X meaning potential for harm in the unborn has been demonstrated.
Exposure to benzodiazepines during pregnancy has been associated with a slightly increased (from 0.06 to 0.07%) risk of cleft palate in newborns, a controversial conclusion as some studies find no association between benzodiazepines and cleft palate. Their use by expectant mothers shortly before the delivery may result in a floppy infant syndrome, with the newborns suffering from hypotonia, hypothermia, lethargy, and breathing and feeding difficulties. Cases of neonatal withdrawal syndrome have been described in infants chronically exposed to benzodiazepines in utero. This syndrome may be hard to recognize, as it starts several days after delivery, for example, as late as 21 day for chlordiazepoxide. The symptoms include tremors, hypertonia, hyperreflexia, hyperactivity, and vomiting and may last for up to three to six months. Tapering down the dose during pregnancy may lessen its severity. If used in pregnancy, those benzodiazepines with a better and longer safety record, such as diazepam or chlordiazepoxide, are recommended over potentially more harmful benzodiazepines, such as temazepam or triazolam. Using the lowest effective dose for the shortest period of time minimizes the risks to the unborn child.
Elderly.
The benefits of benzodiazepines are least and the risks are greatest in the elderly. The elderly are at an increased risk of dependence and are more sensitive to the adverse effects such as memory problems, daytime sedation, impaired motor coordination, and increased risk of motor vehicle accidents and falls, and an increased risk of hip fractures. The long-term effects of benzodiazepines and benzodiazepine dependence in the elderly can resemble dementia, depression, or anxiety syndromes, and progressively worsens over time. Adverse effects on cognition can be mistaken for the effects of old age. The benefits of withdrawal include improved cognition, alertness, mobility, reduced risk incontinence, and a reduced risk of falls and fractures. The success of gradual-tapering benzodiazepines is as great in the elderly as in younger people. Benzodiazepines should be prescribed to the elderly only with caution and only for a short period at low doses. Short to intermediate-acting benzodiazepines are preferred in the elderly such as oxazepam and temazepam. The high potency benzodiazepines alprazolam and triazolam and long-acting benzodiazepines are not recommended in the elderly due to increased adverse effects. Nonbenzodiazepines such as zaleplon and zolpidem and low doses of sedating antidepressants are sometimes used as alternatives to benzodiazepines.
Long-term use of benzodiazepines has been associated with increased risk of cognitive impairment, but its relationship with dementia remains inconclusive. The association of a past history of benzodiazepine use and cognitive decline is unclear, with some studies reporting a lower risk of cognitive decline in former users, some finding no association and some indicating an increased risk of cognitive decline.
Benzodiazepines are sometimes prescribed to treat behavioral symptoms of dementia. However, like antidepressants, they have little evidence of effectiveness, although antipsychotics have shown some benefit. Cognitive impairing effects of benzodiazepines that occur frequently in the elderly can also worsen dementia.
Adverse effects.
The most common side-effects of benzodiazepines are related to their sedating and muscle-relaxing action. They include drowsiness, dizziness, and decreased alertness and concentration. Lack of coordination may result in falls and injuries, in particular, in the elderly. Another result is impairment of driving skills and increased likelihood of road traffic accidents. Decreased libido and erection problems are a common side effect. Depression and disinhibition may emerge. Hypotension and suppressed breathing (hypoventilation) may be encountered with intravenous use. Less common side effects include nausea and changes in appetite, blurred vision, confusion, euphoria, depersonalization and nightmares. Cases of liver toxicity have been described but are very rare.
The long-term effects of benzodiazepine use can include cognitive impairment as well as affective and behavioural problems. Feelings of turmoil, difficulty in thinking constructively, loss of sex-drive, agoraphobia and social phobia, increasing anxiety and depression, loss of interest in leisure pursuits and interests, and an inability to experience or express feelings can also occur. Not everyone, however, experiences problems with long-term use. Additionally an altered perception of self, environment and relationships may occur.
Cognitive effects.
The short-term use of benzodiazepines adversely affects multiple areas of cognition, the most notable one being that it interferes with the formation and consolidation of memories of new material and may induce complete anterograde amnesia. However, researchers hold contrary opinions regarding the effects of long-term administration. One view is that many of the short-term effects continue into the long-term and may even worsen, and are not resolved after stopping benzodiazepine usage. Another view maintains that cognitive deficits in chronic benzodiazepine users occur only for a short period after the dose, or that the anxiety disorder is the cause of these deficits.
While the definitive studies are lacking, the former view received support from a 2004 meta-analysis of 13 small studies. This meta-analysis found that long-term use of benzodiazepines was associated with moderate to large adverse effects on all areas of cognition, with visuospatial memory being the most commonly detected impairment. Some of the other impairments reported were decreased IQ, visiomotor coordination, information processing, verbal learning and concentration. The authors of the meta-analysis and a later reviewer noted that the applicability of this meta-analysis is limited because the subjects were taken mostly from withdrawal clinics; the coexisting drug, alcohol use, and psychiatric disorders were not defined; and several of the included studies conducted the cognitive measurements during the withdrawal period.
Paradoxical effects.
Paradoxical reactions, such as increased seizures in epileptics, aggression, violence, impulsivity, irritability and suicidal behavior sometimes occur. These reactions have been explained as consequences of disinhibition and the subsequent loss of control over socially unacceptable behavior. Paradoxical reactions are rare in the general population, with an incidence rate below 1% and similar to placebo. However, they occur with greater frequency in recreational abusers, individuals with borderline personality disorder, children, and patients on high-dosage regimes. In these groups, impulse control problems are perhaps the most important risk factor for disinhibition; learning disabilities and neurological disorders are also significant risks. Most reports of disinhibition involve high doses of high-potency benzodiazepines. Paradoxical effects may also appear after chronic use of benzodiazepines.
Long-term worsening of psychiatric symptoms.
While benzodizapines may have short-term benefits for anxiety, sleep and agitation in some patients, long-term (i.e., greater than 2–4 weeks) use can result in a worsening of the very symptoms the medications are meant to treat. Potential explanations include exacerbating cognitive problems that are already common in anxiety disorders, causing or worsening depression and suicidality, disrupting sleep architecture by inhibiting deep stage sleep, withdrawal symptoms or rebound symptoms in between doses mimicking or exacerbating underlying anxiety or sleep disorders, inhibiting the benefits of psychotherapy by inhibiting memory consolidation and reducing fear extinction, and reducing coping with trauma/stress and increasing vulnerability to future stress. Anxiety, insomnia and irritability may be temporarily exacerbated during withdrawal, but psychiatric symptoms after discontinuation are usually less than even while taking benzodiazepines. Fortunately, for those with benzodiazepine-induced problems, functioning significantly improves within 1 year of discontinuation.
Reinforcement disorders.
Tolerance.
The main problem of the chronic use of benzodiazepines is the development of tolerance and dependence. Tolerance manifests itself as diminished pharmacological effect and develops relatively quickly to the sedative, hypnotic, anticonvulsant, and muscle relaxant actions of benzodiazepines. Tolerance to anti-anxiety effects develops more slowly with little evidence of continued effectiveness beyond four to six months of continued use. In general, tolerance to the amnesic effects does not occur. However, controversy exists as to tolerance to the anxiolytic effects with some evidence that benzodiazepines retain efficacy and opposing evidence from a systematic review of the literature that tolerance frequently occurs and some evidence that anxiety may worsen with long-term use. The question of tolerance to the amnesic effects of benzodiazepines is, likewise, unclear. Some evidence suggests that partial tolerance does develop, and that, "memory impairment is limited to a narrow window within 90 minutes after each dose".
A major disadvantage of benzodiazepines that tolerance to therapeutic effects develops relatively quickly while many adverse effects persist. Tolerance develops to hypnotic and myorelexant effects within days to weeks, and to anticonvulsant and anxiolytic effects within weeks to months. Therefore, benzodiazepines are unlikely to be effective long-term treatments for sleep and anxiety. While BZD therapeutic effects disappear with tolerance, depression and impulsivity with high suicidal risk commonly persist. Several studies have confirmed that long-term benzodiazepines are not significantly different from placebo for sleep or anxiety. This may explain why patients commonly increase doses over time and many eventually take more than one type of benzodiazepine after the first loses effectiveness. Additionally, because tolerance to benzodiazepine sedating effects develops more quickly than does tolerance to brainstem depressant effects, those taking more benzodiazepines to achieve desired effects may suffer sudden respiratory depression, hypotension or death. Most patients with anxiety disorders and PTSD have symptoms which persist for at least several months, making tolerance to therapeutic effects a distinct problem for them and necessitating the need for more effective long-term treatment (e.g., psychotherapy, serotonergic antidepressants).
Withdrawal symptoms and management.
Discontinuation of benzodiazepines or abrupt reduction of the dose, even after a relatively short course of treatment (three to four weeks), may result in two groups of symptoms — rebound and withdrawal. Rebound symptoms are the return of the symptoms for which the patient was treated but worse than before. Withdrawal symptoms are the new symptoms that occur when the benzodiazepine is stopped. They are the main sign of physical dependence.
The most frequent symptoms of withdrawal from benzodiazepines are insomnia, gastric problems, tremors, agitation, fearfulness, and muscle spasms. The less frequent effects are irritability, sweating, depersonalization, derealization, hypersensitivity to stimuli, depression, suicidal behavior, psychosis, seizures, and delirium tremens. Severe symptoms usually occur as a result of abrupt or over-rapid withdrawal. Abrupt withdrawal can be dangerous, therefore a gradual reduction regimen is recommended.
Symptoms may also occur during a gradual dosage reduction, but are typically less severe and may persist as part of a protracted withdrawal syndrome for months after cessation of benzodiazepines. Approximately 10% of patients will experience a notable protracted withdrawal syndrome, which can persist for many months or in some cases a year or longer. Protracted symptoms tend to resemble those seen during the first couple of months of withdrawal but usually are of a sub-acute level of severity. Such symptoms do gradually lessen over time, eventually disappearing altogether.
Benzodiazepines have a reputation with patients and doctors for causing a severe and traumatic withdrawal; however, this is in large part due to the withdrawal process being poorly managed. Over-rapid withdrawal from benzodiazepines increases the severity of the withdrawal syndrome and increases the failure rate. A slow and gradual withdrawal customised to the individual and, if indicated, psychological support is the most effective way of managing the withdrawal. Opinion as to the time needed to complete withdrawal ranges from four weeks to several years. A goal of less than six months has been suggested, but due to factors such as dosage and type of benzodiazepine, reasons for prescription, lifestyle, personality, environmental stresses, and amount of available support, a year or more may be needed to withdraw.
Withdrawal is best managed by transferring the physically dependent patient to an equivalent dose of diazepam because it has the longest half-life of all of the benzodiazepines, is metabolised into long-acting active metabolites and is available in low-potency tablets, which can be quartered for smaller doses. A further benefit is that it is available in liquid form, which allows for even smaller reductions. Chlordiazepoxide, which also has a long half-life and long-acting active metabolites, can be used as an alternative.
Nonbenzodiazepines are contraindicated during benzodiazepine withdrawal as they are cross tolerant with benzodiazepines and can induce dependence. Alcohol is also cross tolerant with benzodiazepines and more toxic and thus caution is needed to avoid replacing one dependence with another. During withdrawal, fluoroquinolone-based antibiotics are best avoided if possible; they displace benzodiazepines from their binding site and reduce GABA function and, thus, may aggravate withdrawal symptoms. Antipsychotics are not recommended for benzodiazepine withdrawal (or other CNS depressant withdrawal states) especially clozapine, olanzapine or low potency phenothiazines e.g. chlorpromazine as they lower the seizure threshold and can worsen withdrawal effects; if used extreme caution is required.
Withdrawal from long term benzodiazepines is beneficial for most individuals. Withdrawal of benzodiazepines from long-term users, in general, leads to improved physical and mental health particularly in the elderly; although some long term users report continued benefit from taking benzodiazepines, this may be the result of suppression of withdrawal effects.
Overdose.
Although benzodiazepines are much safer in overdose than their predecessors, the barbiturates, they can still cause problems in overdose. Taken alone, they rarely cause severe complications in overdose; statistics in England showed that benzodiazepines were responsible for 3.8% of all deaths by poisoning from a single drug. However, combining these drugs with alcohol, opiates or tricyclic antidepressants markedly raises the toxicity. The elderly are more sensitive to the side effects of benzodiazepines, and poisoning may even occur from their long-term use. The various benzodiazepines differ in their toxicity; temazepam appears to be most toxic in overdose and when used with other drugs. The symptoms of a benzodiazepine overdose may include; drowsiness, slurred speech, nystagmus, hypotension, ataxia, coma, respiratory depression, and cardiorespiratory arrest.
A reversal agent for benzodiazepines exists, flumazenil (Anexate). Its use as an antidote is not routinely recommended because of the high risk of resedation and seizures. In a double-blind, placebo-controlled trial of 326 patients, 4 patients suffered serious adverse events and 61% became resedated following the use of flumazenil. Numerous contraindications to its use exist. It is contraindicated in patients with a history of long-term use of benzodiazepines, those having ingested a substance that lowers the seizure threshold or may cause an arrhythmia, and in those with abnormal vital signs. One study found that only 10% of the patient population presenting with a benzodiazepine overdose are suitable candidates for treatment with flumazenil.
Interactions.
Individual benzodiazepines may have different interactions with certain drugs. Depending on their metabolism pathway, benzodiazepines can be divided roughly into two groups. The largest group consists of those that are metabolized by cytochrome P450 (CYP450) enzymes and possess significant potential for interactions with other drugs. The other group comprises those that are metabolized through glucuronidation, such as lorazepam, oxazepam, and temazepam, and, in general, have few drug interactions.
Many drugs, including oral contraceptives, some antibiotics, antidepressants, and antifungal agents, inhibit cytochrome enzymes in the liver. They reduce the rate of elimination of the benzodiazepines that are metabolized by CYP450, leading to possibly excessive drug accumulation and increased side-effects. In contrast, drugs that induce cytochrome P450 enzymes, such as St John's wort, the antibiotic rifampicin, and the anticonvulsants carbamazepine and phenytoin, accelerate elimination of many benzodiazepines and decrease their action. Taking benzodiazepines with alcohol, opioids and other central nervous system depressants potentiates their action. This often results in increased sedation, impaired motor coordination, suppressed breathing, and other adverse effects that have potential to be lethal. Antacids can slow down absorption of some benzodiazepines; however, this effect is marginal and inconsistent.
Pharmacology.
Mechanism of action.
Benzodiazepines work by increasing the efficiency of a natural brain chemical, GABA, to decrease the excitability of neurons. This reduces the communication between neurons and, therefore, has a calming effect on many of the functions of the brain.
GABA controls the excitability of neurons by binding to the GABAA receptor. The GABAA receptor is a protein complex located in the synapses of neurons. All GABAA receptors contain an ion channel that conducts chloride ions across neuronal cell membranes and two binding sites for the neurotransmitter gamma-aminobutyric acid (GABA), while a subset of GABAA receptor complexes also contain a single binding site for benzodiazepines. Binding of benzodiazepines to this receptor complex does not alter binding of GABA. Unlike other positive allosteric modulators that increases ligand binding, benzodiazepine binding acts as a positive allosteric modulator by increasing the total conduction of chloride ions across the neuronal cell membrane when GABA is already bound to its receptor. This increased chloride ion influx hyperpolarizes the neuron's membrane potential. As a result, the difference between resting potential and threshold potential is increased and firing is less likely.
Different GABAA receptor subtypes have varying distributions within different regions of the brain and, therefore, control distinct neuronal circuits. Hence, activation of different GABAA receptor subtypes by benzodiazepines may result in distinct pharmacological actions. In terms of the mechanism of action of benzodiazepines, their similarities are too great to separate them into individual categories such as anxiolytic or hypnotic. For example, a hypnotic administered in low doses will produce anxiety-relieving effects, whereas a benzodiazepine marketed as an anti-anxiety drug will at higher doses induce sleep.
The subset of GABAA receptors that also bind benzodiazepines are referred to as benzodiazepine receptors (BzR). The GABAA receptor is a heteromer composed of five subunits, the most common ones being two "α"s, two "β"s, and one "γ" (α2β2γ). For each subunit, many subtypes exist (α1–6, β1–3, and γ1–3). GABAA receptors that are made up of different combinations of subunit subtypes have different properties, different distributions in the brain and different activities relative to pharmacological and clinical effects. Benzodiazepines bind at the interface of the α and γ subunits on the GABAA receptor. Binding also requires that alpha subunits contain a histidine amino acid residue, ("i.e.", α1, α2, α3, and α5 containing GABAA receptors). For this reason, benzodiazepines show no affinity for GABAA receptors containing α4 and α6 subunits with an arginine instead of a histidine residue. Once bound to the benzodiazepine receptor, the benzodiazepine ligand locks the benzodiazepine receptor into a conformation in which it has a greater affinity for the GABA neurotransmitter. This increases the frequency of the opening of the associated chloride ion channel and hyperpolarizes the membrane of the associated neuron. The inhibitory effect of the available GABA is potentiated, leading to sedatory and anxiolytic effects. For instance, those ligands with high activity at the α1 are associated with stronger hypnotic effects, whereas those with higher affinity for GABAA receptors containing α2 and/or α3 subunits have good anti-anxiety activity.
The benzodiazepine class of drugs also interact with peripheral benzodiazepine receptors. Peripheral benzodiazepine receptors are present in peripheral nervous system tissues, glial cells, and to a lesser extent the central nervous system. These peripheral receptors are not structurally related or coupled to GABAA receptors. They modulate the immune system and are involved in the body response to injury. Benzodiazepines also function as weak adenosine reuptake inhibitors. It has been suggested that some of their anticonvulsant, anxiolytic, and muscle relaxant effects may be in part mediated by this action.
Pharmacokinetics.
A benzodiazepine can be placed into one of three groups by its elimination half-life, or time it takes for the body to eliminate half of the dose. Some benzodiazepines have long-acting active metabolites, such as diazepam and chlordiazepoxide, which are metabolised into desmethyldiazepam. Desmethyldiazepam has a half-life of 36–200 hours, and flurazepam, with the main active metabolite of desalkylflurazepam, with a half-life of 40–250 hours. These long-acting metabolites are partial agonists.
Physical and chemical properties.
Benzodiazepines share a similar chemical structure, and their effects in humans are mainly produced by the allosteric modification of a specific kind of neurotransmitter receptor, the GABAA receptor, which increases the overall conductance of these inhibitory channels; this results in the various therapeutic effects as well as adverse effects of benzodiazepines. Other less important mechanisms of action are also known.
Chemistry.
The term "benzodiazepine" is the chemical name for the heterocyclic ring system (see figure to the right), which is a fusion between the benzene and diazepine ring systems. Under Hantzsch–Widman nomenclature, a diazepine is a heterocycle with two nitrogen atoms, five carbon atom and the maximum possible number of cumulative double bonds. The "benzo" prefix indicates the benzene ring fused onto the diazepine ring.
Benzodiazepine drugs are substituted 1,4-benzodiazepines, although the chemical term can refer to many other compounds that do not have useful pharmacological properties. Different benzodiazepine drugs have different side groups attached to this central structure. The different side groups affect the binding of the molecule to the GABAA receptor and so modulate the pharmacological properties. Many of the pharmacologically active "classical" benzodiazepine drugs contain the 5-phenyl-1"H"-benzo["e"] [1,4]diazepin-2(3"H")-one substructure (see figure to the right). Benzodiazepines have been found to mimic protein reverse turns structurally which enable them with their biological activity in many cases.
Nonbenzodiazepines also bind to the benzodiazepine binding site on the GABAA receptor and possess similar pharmacological properties. While the nonbenzodiazepines are by definition structurally unrelated to the benzodiazepines, both classes of drugs possess a common pharmacophore (see figure to the lower-right), which explains their binding to a common receptor site.
History.
The first benzodiazepine, chlordiazepoxide ("Librium"), was synthesized in 1955 by Leo Sternbach while working at Hoffmann–La Roche on the development of tranquilizers. The pharmacological properties of the compounds prepared initially were disappointing, and Sternbach abandoned the project. Two years later, in April 1957, co-worker Earl Reeder noticed a "nicely crystalline" compound left over from the discontinued project while spring-cleaning in the lab. This compound, later named chlordiazepoxide, had not been tested in 1955 because of Sternbach's focus on other issues. Expecting the pharmacology results to be negative and hoping to publish the chemistry-related findings, researchers submitted it for a standard battery of animal tests. However, the compound showed very strong sedative, anticonvulsant, and muscle relaxant effects. These impressive clinical findings led to its speedy introduction throughout the world in 1960 under the brand name "Librium". Following chlordiazepoxide, diazepam marketed by Hoffmann–La Roche under the brand name "Valium" in 1963, and for a while the two were the most commercially successful drugs. The introduction of benzodiazepines led to a decrease in the prescription of barbiturates, and by the 1970s they had largely replaced the older drugs for sedative and hypnotic uses.
The new group of drugs was initially greeted with optimism by the medical profession, but gradually concerns arose; in particular, the risk of dependence became evident in the 1980s. Benzodiazepines have a unique history in that they were responsible for the largest-ever class-action lawsuit against drug manufacturers in the United Kingdom, involving 14,000 patients and 1,800 law firms that alleged the manufacturers knew of the dependence potential but intentionally withheld this information from doctors. At the same time, 117 general practitioners and 50 health authorities were sued by patients to recover damages for the harmful effects of dependence and withdrawal. This led some doctors to require a signed consent form from their patients and to recommend that all patients be adequately warned of the risks of dependence and withdrawal before starting treatment with benzodiazepines. The court case against the drug manufacturers never reached a verdict; legal aid had been withdrawn and there were allegations that the consultant psychiatrists, the expert witnesses, had a conflict of interest. This litigation led to changes in the British law, making class action lawsuits more difficult.
Although antidepressants with anxiolytic properties have been introduced, and there is increasing awareness of the adverse effects of benzodiazepines, prescriptions for short-term anxiety relief have not significantly dropped. For treatment of insomnia, benzodiazepines are now less popular than nonbenzodiazepines, which include zolpidem, zaleplon and eszopiclone. Nonbenzodiazepines are molecularly distinct, but nonetheless, they work on the same benzodiazepine receptors and produce similar sedative effects.
Society and culture.
Legal status.
In the United States, benzodiazepines are Schedule IV drugs under the Federal Controlled Substances Act, even when not on the market (for example, nitrazepam and bromazepam). Flunitrazepam is subject to more stringent regulations in certain states and temazepam prescriptions require specially coded pads in certain states.
In Canada, possession of benzodiazepines is legal for personal use. All benzodiazepines are categorized as Schedule IV substances under the Controlled Drugs and Substances Act.
In the United Kingdom, the benzodiazepines are schedule 4 controlled drugs, except for flunitrazepam, temazepam and midazolam, which are schedule 3 controlled drugs and carry stronger penalties for possession and trafficking.
In the Netherlands, since October 1993, benzodiazepines, including formulations containing less than 20 mg of temazepam, are all placed on List 2 of the Opium Law. A prescription is needed for possession of all benzodiazepines. Temazepam formulations containing 20 mg or greater of the drug are placed on List 1, thus requiring prescriptions to be written in the List 1 format.
In East Asia and Southeast Asia, temazepam and nimetazepam are often heavily controlled and restricted. In certain countries, triazolam, flunitrazepam, flutoprazepam and midazolam are also restricted or controlled to certain degrees. In Hong Kong, all benzodiazepines are regulated under Schedule 1 of Hong Kong's Chapter 134 "Dangerous Drugs Ordinance". Previously only brotizolam, flunitrazepam and triazolam were classed as dangerous drugs.
Internationally, benzodiazepines are categorized as Schedule IV controlled drugs, apart from flunitrazepam which is a Schedule III drug under the Convention on Psychotropic Substances.
Recreational use.
Benzodiazepines are considered to be major drugs of abuse. Benzodiazepine abuse is mostly limited to individuals who abuse other drugs, i.e., poly-drug abusers. On the international scene, benzodiazepines are categorized as Schedule IV controlled drugs by the INCB, apart from flunitrazepam which is a Schedule III drug under the Convention on Psychotropic Substances. Some variation in drug scheduling exists in individual countries; for example, in the United Kingdom, midazolam and temazepam are Schedule III controlled drugs. British law requires temazepam (but "not" midazolam) to be stored in safe custody. Safe custody requirements ensures that pharmacists and doctors holding stock of temazepam must store it in securely fixed double-locked steel safety cabinets and maintain a written register, which must be bound and contain separate entries for temazepam and must be written in ink with no use of correction fluid (although a written register is not required for temazepam in the United Kingdom). Disposal of expired stock must be witnessed by a designated inspector (either a local drug-enforcement police officer or official from health authority). Benzodiazepine abuse ranges from occasional binges on large doses, to chronic and compulsive drug abuse of high doses.
Benzodiazepines are used recreationally and by problematic drug misusers. Mortality is higher among poly-drug misusers that also use benzodiazepines. Heavy alcohol use also increases mortality among poly-drug users. Dependence and tolerance, often coupled with dosage escalation, to benzodiazepines can develop rapidly among drug misusers; withdrawal syndrome may appear after as little as three weeks of continuous use. Long-term use has the potential to cause both physical and psychological dependence and severe withdrawal symptoms such as depression, anxiety (often to the point of panic attacks), and agoraphobia. Benzodiazepines and, in particular, temazepam are sometimes used intravenously, which, if done incorrectly or in an unsterile manner, can lead to medical complications including abscesses, cellulitis, thrombophlebitis, arterial puncture, deep vein thrombosis, and gangrene. Sharing syringes and needles for this purpose also brings up the possibility of transmission of hepatitis, HIV, and other diseases. Benzodiazepines are also misused intranasally, which may have additional health consequences. Once benzodiazepine dependence has been established, a clinician usually converts the patient to an equivalent dose of diazepam before beginning a gradual reduction program.
A 1999–2005 Australian police survey of detainees reported preliminary findings that self-reported users of benzodiazepines were less likely than non-user detainees to work full-time and more likely to receive government benefits, use methamphetamine or heroin, and be arrested or imprisoned. Benzodiazepines are sometimes used for criminal purposes; they serve to incapacitate a victim in cases of drug assisted rape or robbery.
Overall, anecdotal evidence suggests that temazepam may be the most psychologically habit-forming (addictive) benzodiazepine. Temazepam abuse reached epidemic proportions in some parts of the world, in particular, in Europe and Australia, and is a major drug of abuse in many Southeast Asian countries. This led authorities of various countries to place temazepam under a more restrictive legal status. Some countries, such as Sweden, banned the drug outright. Temazepam also has certain pharmacokinetic properties of absorption, distribution, elimination, and clearance that make it more apt to abuse compared to many other benzodiazepines.
Veterinary use.
Benzodiazepines are used in veterinary practice in the treatment of various disorders and conditions. As in humans, they are used in the first-line management of seizures, status epilepticus, and tetanus, and as maintenance therapy in epilepsy (in particular, in cats). They are widely used in small and large animals (including horses, swine, cattle and exotic and wild animals) for their anxiolytic and sedative effects, as pre-medication before surgery, for induction of anesthesia and as adjuncts to anesthesia.

</doc>
<doc id="4787" url="https://en.wikipedia.org/wiki?curid=4787" title="Bell curve (disambiguation)">
Bell curve (disambiguation)

The bell curve is typical of the normal distribution.
Bell curve may also refer to:

</doc>
<doc id="4788" url="https://en.wikipedia.org/wiki?curid=4788" title="Body mass index">
Body mass index

The body mass index (BMI) or Quetelet index is a value derived from the mass (weight) and height of an individual. The BMI is defined as the body mass divided by the square of the body height, and is universally expressed in units of kg/m2, resulting from mass in kilograms and height in metres.
The BMI may also be determined using a table or chart which displays BMI as a function of mass and height using contour lines or colors for different BMI categories, and may use two different units of measurement.
The BMI is an attempt to quantify the amount of tissue mass (muscle, fat, and bone) in an individual, and then categorize that person as "underweight", "normal weight", "overweight", or "obese" based on that value. However, there is some debate about where on the BMI scale the dividing lines between categories should be placed. Commonly accepted BMI ranges are underweight: under 18.5, normal weight: 18.5 to 25, overweight: 25 to 30, obese: over 30.
History and usage in obesity studies.
The basis of the BMI was devised by Adolphe Quetelet from 1830 to 1850 during which time he developed what he called "social physics". The modern term "body mass index" (BMI) for the ratio of human body weight to squared height was coined in a paper published in the July 1972 edition of the "Journal of Chronic Diseases" by Ancel Keys. In this paper, Keys argued that what he termed the BMI was "...if not fully satisfactory, at least as good as any other relative weight index as an indicator of relative obesity"
The interest in an index that measures body fat came with increasing obesity in prosperous Western societies. BMI was explicitly cited by Keys as appropriate for "population" studies and inappropriate for individual evaluation. Nevertheless, due to its simplicity, it has come to be widely used for preliminary diagnosis. Additional metrics, such as waist circumference, can be more useful.
The BMI is universally expressed in kg/m2, resulting from mass in kilograms and height in meters. If pounds and inches are used, a conversion factor of 703 (kg/m2)/(lb/in2) must be applied. When the term BMI is used informally, the units are usually omitted.
BMI ranges from underweight to obese and is commonly employed among children and adults to predict health outcomes. The BMI trait is influenced by both genetic and non-genetic factors, and it provides a paradigm to understand and estimate the risk factors for health problems.
BMI provides a simple numeric measure of a person's "thickness" or "thinness", allowing health professionals to discuss weight problems more objectively with their patients. BMI was designed to be used as a simple means of classifying average sedentary (physically inactive) populations, with an average body composition. For these individuals, the current value recommendations are as follow: a BMI from 18.5 up to 25 may indicate optimal weight, a BMI lower than 18.5 suggests the person is underweight, a number from 25 up to 30 may indicate the person is overweight, and a number from 30 upwards suggests the person is obese. Many (e.g. gymnasts, basketball and soccer players) but not all (e.g. football linemen) athletes have a high muscle to fat ratio and may have a BMI that is misleadingly high relative to their body fat percentage.
Scalability.
BMI is proportional to mass and inversely proportional to the square of the height. So, if all body dimensions double, and mass scales naturally with the cube of the height, then BMI doubles instead of remaining the same. This results in taller people having a reported BMI that is uncharacteristically high, compared to their actual body fat levels. In comparison, the Ponderal index is based on the natural scaling of mass with the third power of the height.
However, many taller people are not just "scaled up" short people but tend to have narrower frames in proportion to their height. Nick Korevaar (a mathematics lecturer from the University of Utah) suggests that instead of squaring the body height (as the BMI does) or cubing the body height (as the Ponderal index does), it would be more appropriate to use an exponent of between 2.3 and 2.7 (as originally noted by Quetelet). (For a theoretical basis for such values see MacKay.) Carl Lavie has written that, "The B.M.I. tables are excellent for identifying obesity and body fat in large populations, but they are far less reliable for determining fatness in individuals."
Alternatives.
Prime.
BMI Prime, a modification of the BMI system, is the ratio of actual BMI to upper limit BMI (currently defined at BMI 25). As defined, BMI Prime is also the ratio of body weight to upper body-weight limit, calculated at BMI 25. Since it is the ratio of two separate BMI values, BMI Prime is a dimensionless number without associated units. Individuals with BMI Prime less than 0.74 are underweight; those with between 0.74 and 1.00 have optimal weight; and those at 1.00 or greater are overweight. BMI Prime is useful clinically because individuals can tell, at a glance, by what percentage they deviate from their upper weight limits.
For instance, a person with BMI 34 has a BMI Prime of 34/25 = 1.36, and is 36% over his or her upper mass limit. In South East Asian and South Chinese populations (see international variation section below), BMI Prime should be calculated using an upper limit BMI of 23 in the denominator instead of 25. Nonetheless, BMI Prime allows easy comparison between populations whose upper-limit BMI values differ.
Surface-based body shape index.
The Surface-based Body Shape Index (SBSI) is far more rigorous and is based upon four key measurements: the body surface area, vertical trunk circumference, height and waist circumference. Data on 11,808 subjects from the National Health and Human Nutrition Examination Surveys (NHANES) 1999–2004, showed that SBSI outperformed BMI, waist circumference, and A Body Shape Index (ABSI), an alternative to BMI.
formula_2
Modified body mass index.
Within some medical contexts, such as familial amyloid polyneuropathy, serum albumin is factored in to produce a modified body mass index (mBMI). The mBMI can be obtained by multiplying the BMI by serum albumin, in grams per liter.
Categories.
A frequent use of the BMI is to assess how much an individual's body weight departs from what is normal or desirable for a person's height. The weight excess or deficiency may, in part, be accounted for by body fat (adipose tissue) although other factors such as muscularity also affect BMI significantly (see discussion below and overweight).
The WHO regards a BMI of less than 18.5 as underweight and may indicate malnutrition, an eating disorder, or other health problems, while a BMI equal to or greater than 25 is considered overweight and above 30 is considered obese. These ranges of BMI values are valid only as statistical categories.
BMI in children (aged 2 to 20).
BMI is used differently for children. It is calculated in the same way as for adults, but then compared to typical values for other children of the same age. Instead of comparison against fixed thresholds for underweight and overweight, the BMI is compared against the percentile for children of the same gender and age.
A BMI that is less than the 5th percentile is considered underweight and above the 95th percentile is considered obese. Children with a BMI between the 85th and 95th percentile are considered to be overweight.
Recent studies in Britain have indicated that females between the ages 12 and 16 have a higher BMI than males of the same age by 1.0 kg/m2 on average.
International variations.
These recommended distinctions along the linear scale may vary from time to time and country to country, making global, longitudinal surveys problematic.
Hong Kong.
The Hospital Authority of Hong Kong recommends the use of the following BMI ranges:
Japan.
Japan Society for the Study of Obesity (2000):
Singapore.
In Singapore, the BMI cut-off figures were revised in 2005, motivated by studies showing that many Asian populations, including Singaporeans, have higher proportion of body fat and increased risk for cardiovascular diseases and diabetes mellitus, compared with Caucasians at the same BMI. The BMI cut-offs are presented with an emphasis on health risk rather than weight.
United States.
In 1998, the U.S. National Institutes of Health and the Centers for Disease Control and Prevention brought U.S. definitions in line with World Health Organization guidelines, lowering the normal/overweight cut-off from BMI 27.8 to BMI 25. This had the effect of redefining approximately 29 million Americans, previously "healthy" to "overweight".
This can partially explain the increase in the "overweight" diagnosis in the past 20 years, and the increase in sales of the weight loss products during the same time. WHO also recommends lowering the normal/overweight threshold for South East Asian body types to around BMI 23, and expects further revisions to emerge from clinical studies of different body types.
The U.S. National Health and Nutrition Examination Survey of 1994 showed that 59% of American men and 49% of women had BMIs over 25. Morbid obesity—a BMI of 40 or more—was found in 2% of the men and 4% of the women. A survey in 2007 showed 63% of Americans are overweight or obese, with 26% now in the obese category (a BMI of 30 or more). There are differing opinions on definition of underweight in females; doctors quote anything below 18.5 to 20 as underweight, the most frequently stated is 19. A BMI nearing 15 is usually defined as starvation and a BMI less than 17.5 as an informal criterion for the diagnosis of anorexia nervosa.
Consequences of elevated level in adults.
The BMI ranges are based on the relationship between body weight and disease and death. Overweight and obese individuals are at an increased risk for the following diseases:
Among people who have never smoked, overweight/obesity is associated with 51% increase in mortality compared with people who have always been a normal weight.
Applications.
Public health.
The BMI is generally used as a means of correlation between groups related by general mass and can serve as a vague means of estimating adiposity. The duality of the BMI is that, while it is easy to use as a general calculation, it is limited as to how accurate and pertinent the data obtained from it can be. Generally, the index is suitable for recognizing trends within sedentary or overweight individuals because there is a smaller margin of error. The BMI has been used by the WHO as the standard for recording obesity statistics since the early 1980s.
This general correlation is particularly useful for consensus data regarding obesity or various other conditions because it can be used to build a semi-accurate representation from which a solution can be stipulated, or the RDA for a group can be calculated. Similarly, this is becoming more and more pertinent to the growth of children, due to the fact that the majority of children are sedentary.
Clinical practice.
BMI categories are generally regarded as a satisfactory tool for measuring whether sedentary individuals are "underweight", "overweight" or "obese" with various exceptions, such as: athletes, children, the elderly, and the infirm. Also, the growth of a child is documented against a BMI-measured growth chart. Obesity trends can then be calculated from the difference between the child's BMI and the BMI on the chart. In the United States, BMI is also used as a measure of underweight, owing to advocacy on behalf of those with eating disorders, such as anorexia nervosa and bulimia nervosa.
Legislation.
In France, Israel, Italy and Spain, legislation has been introduced banning usage of fashion show models having a BMI below 18. In Israel, a BMI below 18.5 is banned. This is done in order to fight anorexia among models and people interested in fashion.
Limitations.
The medical establishment and statistical community have both highlighted the limitations of BMI.
Mathematician Keith Devlin and the restaurant industry association Center for Consumer Freedom argue that the error in the BMI is significant and so pervasive that it is not generally useful in evaluation of health. University of Chicago political science professor Eric Oliver says BMI is a convenient but inaccurate measure of weight, forced onto the populace, and should be revised.
Scaling.
The exponent in the denominator of the formula for BMI is arbitrary. The BMI depends upon weight and the "square" of height. Since mass increases to the "3rd power" of linear dimensions, taller individuals with exactly the same body shape and relative composition, have a larger BMI.
The mathematician Prof Nick Trefethen, who observed this said, “BMI divides the weight by too large a number for short people and too small a number for tall people. So short people are misled into thinking that they are thinner than they are, and tall people are misled into thinking they are fatter.”
Sports medicine doctor Sultan M. Babar has shown that corpulence index is a better measure.
An analysis based on data gathered in the US suggested an exponent of 2.6 would yield the best fit for children aged 2 to 19 years old. For US adults, exponent estimates range from 1.92 to 1.96 for males and from 1.45 to 1.95 for females.
Ignores variation in physical characteristics.
The BMI adds roughly 10% for a large (or tall) frame and subtracts roughly 10% for a smaller frame (short stature). In other words, a person with a small frame would be carrying more fat than optimal, but their BMI reflects that they are "normal". Conversely, a large framed (or tall) individual may be quite healthy with a fairly low body fat percentage, but be classified as "overweight" by BMI.
For example, a chart may say the ideal weight for a man 5 ft 10 in (178 cm) is 165 pounds (75 kg). But if that man has a slender build (small frame), he may be overweight at 165 pounds (75 kg) and should reduce by 10%, to roughly 150 pounds (68 kg). In the reverse, the man with a larger frame and more solid build can be quite healthy at . If one teeters on the edge of small/medium or medium/large, a dose of common sense should be used in calculating their ideal weight. However, falling into your ideal weight range for height and build is still not as accurate in determining health risk factors as waist/height ratio and actual body fat percentage.
Accurate frame size calculators use several measurements (wrist circumference, elbow width, neck circumference and others) to determine what category an individual falls into for a given height. The BMI also fails to take into account loss of height through aging. In this situation, BMI will increase without any corresponding increase in weight.
Does not differentiate between muscle mass and fat mass.
Assumptions about the distribution between muscle mass and fat mass are inexact. BMI generally overestimates adiposity on those with more lean body mass (e.g., athletes) and underestimates excess adiposity on those with less lean body mass. A study in June 2008 by Romero-Corral et al. examined 13,601 subjects from the United States' third National Health and Nutrition Examination Survey (NHANES III) and found that BMI-defined obesity (BMI > 30) was present in 21% of men and 31% of women.
Using body fat percentages (BF%), however, BF-defined obesity was found in 50% of men and 62% of women. While BMI-defined obesity showed high specificity (95% for men and 99% for women), BMI showed poor sensitivity (36% for men and 49% for women). Despite this undercounting of obesity by BMI, BMI values in the intermediate BMI range of 20–30 were found to be associated with a wide range of body fat percentages. For men with a BMI of 25, about 20% have a body fat percentage below 20% and about 10% have body fat percentage above 30%.
BMI is particularly inaccurate for people who are very fit or athletic, as their high muscle mass can classify them in the "overweight" category by BMI, even though their body fat percentages frequently fall in the 10–15% category, which is below that of a more sedentary person of average build who has a "normal" BMI number. Body composition for athletes is often better calculated using measures of body fat, as determined by such techniques as skinfold measurements or underwater weighing and the limitations of manual measurement have also led to new, alternative methods to measure obesity, such as the body volume index.
Variation in definitions of categories.
It is not clear where on the BMI scale the threshold for "overweight" and "obese" should be set. Because of this the standards have varied over the past few decades. Between 1980 and 2000 the U.S. Dietary Guidelines have defined overweight at a variety of levels ranging from a BMI of 24.9 to 27.1. In 1985 the National Institutes of Health (NIH) consensus conference recommended that overweight BMI be set at a BMI of 27.8 for men and 27.3 for women.
In 1998 a NIH report concluded that a BMI over 25 is overweight and a BMI over 30 is obese. In the 1990s the World Health Organization (WHO) decided that a BMI of 25 to 30 should be considered overweight and a BMI over 30 is obese, the standards the NIH set. This became the definitive guide for determining if someone is overweight.
The current WHO and NIH ranges of "normal" weights are proved to be associated with decreased risks of some diseases such as diabetes type II; however using the same range of BMI for men and women is considered arbitrary, and makes the definition of underweight quite unsuitable for men.
One study found that the vast majority of people labelled 'overweight' and 'obese' according to current definitions do not in fact face any meaningful increased risk for early death. In a quantitative analysis of a number of studies, involving > 600,000 men and women, the lowest mortality rates were shown between BMIs of 23 and 29, which means most of the range considered 'overweight' was not associated with higher risk.
Variation in relationship to health.
A study published by "Journal of the American Medical Association" ("JAMA") in 2005 showed that "overweight" people had a death rate similar to "normal" weight people as defined by BMI, while "underweight" and "obese" people had a higher death rate.
High BMI is associated with type 2 diabetes only in persons with high serum gamma-glutamyl transpeptidase.
In an analysis of 40 studies involving 250,000 people, patients with coronary artery disease with "normal" BMIs were at higher risk of death from cardiovascular disease than people whose BMIs put them in the "overweight" range (BMI 25–29.9).
One study found that BMI had a good general correlation with body fat percentage, and noted that obesity has overtaken smoking as the world's number one cause of death. But it also notes that in the study 50% of men and 62% of women were obese according to body fat defined obesity, while only 21% of men and 31% of women were obese according to BMI, meaning that BMI was found to underestimate the number of obese subjects.
A 2010 study that followed 11,000 subjects for up to eight years concluded that BMI is not a good measure for the risk of heart attack, stroke or death. A better measure was found to be the waist-to-height ratio. A 2011 study that followed 60,000 participants for up to 13 years found that waist–hip ratio was a better predictor of ischaemic heart disease mortality.

</doc>
<doc id="4789" url="https://en.wikipedia.org/wiki?curid=4789" title="Behistun Inscription">
Behistun Inscription

The Behistun Inscription (also Bisotun, Bistun or Bisutun), (, Old Persian: Bagastana, meaning "the place of god") is a multi-lingual inscription and large rock relief on a cliff at Mount Behistun in the Kermanshah Province of Iran, near the city of Kermanshah in western Iran. It was crucial to the decipherment of cuneiform script.
Authored by Darius the Great sometime between his coronation as king of the Persian Empire in the summer of 522 BC and his death in autumn of 486 BC, the inscription begins with a brief autobiography of Darius, including his ancestry and lineage. Later in the inscription, Darius provides a lengthy sequence of events following the deaths of Cyrus the Great and Cambyses II in which he fought nineteen battles in a period of one year (ending in December 521 BC) to put down multiple rebellions throughout the Persian Empire. The inscription states in detail that the rebellions, which had resulted from the deaths of Cyrus the Great and his son Cambyses II, were orchestrated by several impostors and their co-conspirators in various cities throughout the empire, each of whom falsely proclaimed kinghood during the upheaval following Cyrus's death.
Darius the Great proclaimed himself victorious in all battles during the period of upheaval, attributing his success to the "grace of Ahura Mazda".
The inscription includes three versions of the same text, written in three different cuneiform script languages: Old Persian, Elamite, and Babylonian (a variety of Akkadian). The inscription is to cuneiform what the Rosetta Stone is to Egyptian hieroglyphs: the document most crucial in the decipherment of a previously lost script.
The inscription is approximately 15 metres high by 25 metres wide and 100 metres up a limestone cliff from an ancient road connecting the capitals of Babylonia and Media (Babylon and Ecbatana, respectively). The Old Persian text contains 414 lines in five columns; the Elamite text includes 593 lines in eight columns, and the Babylonian text is in 112 lines. The inscription was illustrated by a life-sized bas-relief of Darius I, the Great, holding a bow as a sign of kingship, with his left foot on the chest of a figure lying on his back before him. The supine figure is reputed to be the pretender Gaumata. Darius is attended to the left by two servants, and nine one-meter figures stand to the right, with hands tied and rope around their necks, representing conquered peoples. Faravahar floats above, giving his blessing to the king. One figure appears to have been added after the others were completed, as was Darius's beard, which is a separate block of stone attached with iron pins and lead.
History.
After the fall of the Persian Empire's Achaemenid Dynasty and its successors, and the lapse of Old Persian cuneiform writing into disuse, the nature of the inscription was forgotten, and fanciful explanations became the norm. For centuries, instead of being attributed to Darius I, the Great, it was believed to be from the reign of Khosrau II of Persia — one of the last Sassanid kings, who lived over 1000 years after the time of Darius I.
The inscription is mentioned by Ctesias of Cnidus, who noted its existence some time around 400 BC and mentioned a well and a garden beneath the inscription. He incorrectly concluded that the inscription had been dedicated "by Queen Semiramis of Babylon to Zeus". Tacitus also mentions it and includes a description of some of the long-lost ancillary monuments at the base of the cliff, including an altar to "Herakles". What has been recovered of them, including a statue dedicated in 148 BC, is consistent with Tacitus's description. Diodorus also writes of "Bagistanon" and claims it was inscribed by Semiramis.
A legend began around Mount Behistun (Bisotun), as written about by the Persian poet and writer Ferdowsi in his "Shahnameh" ("Book of Kings") , about a man named Farhad, who was a lover of King Khosrow's wife, Shirin. The legend states that, exiled for his transgression, Farhad was given the task of cutting away the mountain to find water; if he succeeded, he would be given permission to marry Shirin. After many years and the removal of half the mountain, he did find water, but was informed by Khosrow that Shirin had died. He went mad, threw his axe down the hill, kissed the ground and died. It is told in the book of Khosrow and Shirin that his axe was made out of a pomegranate tree, and, where he threw the axe, a pomegranate tree grew with fruit that would cure the ill. Shirin was not dead, according to the story, and mourned upon hearing the news.
In 1598, the Englishman Robert Sherley saw the inscription during a diplomatic mission to Persia on behalf of Austria, and brought it to the attention of Western European scholars. His party incorrectly came to the conclusion that it was Christian in origin.
French General Gardanne thought it showed "Christ and his twelve apostles", and Sir Robert Ker Porter thought it represented the Lost Tribes of Israel and Shalmaneser of Assyria.
Italian explorer Pietro della Valle visited the inscription in the course of a pilgrimage in around 1621.
Translation.
German surveyor Carsten Niebuhr visited in around 1764 for Frederick V of Denmark, publishing a copy of the inscription in the account of his journeys in 1778.
Niebuhr's transcriptions were used by Georg Friedrich Grotefend and others in their efforts to decipher the Old Persian cuneiform script. Grotefend had deciphered ten of the 37 symbols of Old Persian by 1802, after realizing that unlike the Semitic cuneiform scripts, Old Persian text is alphabetic and each word is separated by a vertical slanted symbol.
The Old Persian text was copied and deciphered before the recovery and copying of the Elamite and Babylonian inscriptions had even been attempted, which proved to be a good deciphering strategy, since Old Persian script was easier to study due to its alphabetic nature and the fact that the language it represents had naturally evolved into Middle Persian, and in turn, to the living modern Persian language dialects, and was also related to the Avestan language, used in the Zoroastrian book the "Avesta".
In 1835, Sir Henry Rawlinson, an officer of the British East India Company army assigned to the forces of the Shah of Iran, began studying the inscription in earnest. As the town of Bisotun's name was anglicized as "Behistun" at this time, the monument became known as the "Behistun Inscription". Despite its relative inaccessibility, Rawlinson was able to scale the cliff and copy the Old Persian inscription. The Elamite was across a chasm, and the Babylonian four meters above; both were beyond easy reach and were left for later.
With the Persian text, and with about a third of the syllabary made available to him by the work of Georg Friedrich Grotefend, Rawlinson set to work on deciphering the text. Fortunately, the first section of this text contained a list of the same Persian kings found in Herodotus in their original Persian forms as opposed to Herodotus's Greek transliterations; for example Darius is given as the original "Dâryavuš" instead of the Hellenized "Δαρειος". By matching the names and the characters, Rawlinson was able to decipher the type of cuneiform used for Old Persian by 1838 and presented his results to the Royal Asiatic Society in London and the Société Asiatique in Paris.
In the interim, Rawlinson spent a brief tour of duty in Afghanistan, returning to the site in 1843. He first crossed a chasm between the Persian and Elamite scripts by bridging the gap with planks, subsequently copying the Elamite inscription. He was then able to find an enterprising local boy to climb up a crack in the cliff and suspend ropes across the Babylonian writing, so that papier-mâché casts of the inscriptions could be taken. Rawlinson, along with several other scholars, most notably Edward Hincks, Julius Oppert, William Henry Fox Talbot, and Edwin Norris, either working separately or in collaboration, eventually deciphered these inscriptions, leading eventually to the ability to read them completely.
The translation of the Old Persian sections of the Behistun Inscription paved the way to the subsequent ability to decipher the Elamite and Babylonian parts of the text, which greatly promoted the development of modern Assyriology.
Later research and activity.
The site was visited by A. V. Williams Jackson in 1903.
Later expeditions, in 1904 sponsored by the British Museum and led by Leonard William King and Reginald Campbell Thompson and in 1948 by George G. Cameron of the University of Michigan, obtained photographs, casts and more accurate transcriptions of the texts, including passages that were not copied by Rawlinson.
It also became apparent that rainwater had dissolved some areas of the limestone in which the text was inscribed, while leaving new deposits of limestone over other areas, covering the text.
In 1938, the inscription became of interest to the Nazi German think tank Ahnenerbe, although research plans were cancelled due to the onset of World War II.
The monument later suffered some damage from Allied soldiers using it for target practice in World War II, during the Anglo-Soviet invasion of Iran.
In 1999, Iranian archeologists began the documentation and assessment of damages to the site incurred during the 20th century. Malieh Mehdiabadi, who was project manager for the effort, described a photogrammetric process by which two-dimensional photos were taken of the inscriptions using two cameras and later transmuted into 3-D images.
In recent years, Iranian archaeologists have been undertaking conservation works. The site became a UNESCO World Heritage Site in 2006.
In 2012, the Bisotun Cultural Heritage Center organized an international effort to re-examine the inscription.
Other historical monuments in the Behistun complex.
The site covers an area of 116 hectares. Archeological evidence indicates that this region became a human shelter 40,000 years ago. There are 18 historical monuments other than the inscription of Darius the Great in the Behistun complex that have been registered in the Iranian national list of historical sites. Some of them are:

</doc>
<doc id="4792" url="https://en.wikipedia.org/wiki?curid=4792" title="Barry Goldwater">
Barry Goldwater

Barry Morris Goldwater (January 1, 1909 – May 29, 1998) was an American politician and businessman who was a five-term United States Senator from Arizona (1953–65, 1969–87) and the Republican Party's nominee for President of the United States in the 1964 election. Goldwater is the politician most often credited for sparking the resurgence of the American conservative political movement in the 1960s. He also had a substantial impact on the libertarian movement.
Goldwater rejected the legacy of the New Deal and fought through the conservative coalition against the New Deal coalition. He mobilized a large conservative constituency to win the hard-fought Republican primaries. He was the first candidate of Jewish heritage to be nominated for President by a major American party. Goldwater's conservative campaign platform ultimately failed to gain the support of the electorate and he lost the 1964 presidential election to incumbent Democrat Lyndon B. Johnson by one of the largest landslides in history, bringing down many conservative Republican office-holders as well. The Johnson campaign and other critics painted him as a reactionary, while supporters praised his crusades against the Soviet Union, American labor unions, and the welfare state. His defeat allowed Johnson and the Democrats in Congress to pass the Great Society programs, but the defeat of so many older Republicans in 1964 also cleared the way for a younger generation of American conservatives to mobilize. Goldwater was much less active as a national leader of conservatives after 1964; his supporters mostly rallied behind Ronald Reagan, who became governor of California in 1967 and the 40th President of the United States in 1981.
Goldwater returned to the Senate in 1969, and specialized in defense policy, bringing to the table his experience as a senior officer in the Air Force Reserve. In 1974, as an elder statesman of the party, Goldwater successfully urged President Richard Nixon to resign when evidence of a cover-up in the Watergate scandal became overwhelming and impeachment was imminent. By the 1980s, the increasing influence of the Christian right on the Republican Party so conflicted with Goldwater's views that he became a vocal opponent of the religious right on issues such as abortion, gay rights, and the role of religion in public life. After narrowly winning re-election to the Senate in 1980, he chose not to run for a sixth term in 1986, and was succeeded by fellow Republican John McCain. A significant accomplishment in his career was the passage of the Goldwater–Nichols Act of 1986, which restructured the higher levels of the Pentagon by placing the chain of command from the President to the Secretary of Defense directly to the commanders of the Unified Combatant Commands.
Personal life.
Goldwater was born in Phoenix, in what was then the Arizona Territory, the son of Baron M. Goldwater and his wife, Hattie Josephine ("JoJo") Williams. His father's family had founded Goldwater's, the largest department store in Phoenix. Goldwater's paternal grandfather, Michel Goldwasser, a Polish Jew, was born in 1821 in Poland, from which he emigrated to London following the Revolutions of 1848. Soon after arriving in London, he anglicized his name from "Goldwasser" to "Goldwater". Michel married Sarah Nathan, a member of a Jewish English family, in the Great Synagogue of London.
Goldwater's mother, who was Episcopalian, came from a New England family that included the theologian, Roger Williams of Rhode Island. Goldwater's parents were married in an Episcopal church in Phoenix; for his entire life, Goldwater was an Episcopalian, though on rare occasions he referred to himself as "Jewish". While he did not often attend church, he stated that "If a man acts in a religious way, an ethical way, then he's really a religious man—and it doesn't have a lot to do with how often he gets inside a church".
The family department store made the Goldwaters comfortably wealthy. Goldwater graduated from Staunton Military Academy, an elite private school in Virginia, and attended the University of Arizona for one year, where he joined the Sigma Chi fraternity. Barry had never been close to his father, but he took over the family business after Baron's death in 1930. He became a Republican (in a heavily Democratic state), promoted innovative business practices, and opposed the New Deal, especially because it fostered labor unions. Goldwater came to know former President Herbert Hoover, whose conservative politics he admired greatly.
Family.
In 1934, he married Margaret "Peggy" Johnson, wealthy daughter of a prominent industrialist from Muncie, Indiana. They had four children: Joanne (born January 1, 1936), Barry (born July 15, 1938), Michael (born March 15, 1940), and Peggy (born July 27, 1944). Goldwater became a widower in 1985, and in 1992 he married Susan Wechsler, a nurse 32 years his junior.
Goldwater's son Barry Goldwater Jr. served as a United States House of Representatives member from California from 1969 to 1983.
Goldwater's grandson, Ty Ross, a former Zoli model, is openly gay and HIV positive, and the one who inspired the elder Goldwater "to become an octogenarian proponent of gay civil rights."
Military career.
With the American entry into World War II, Goldwater received a reserve commission in the United States Army Air Forces. He became a pilot assigned to the Ferry Command, a newly formed unit that flew aircraft and supplies to war zones worldwide. He spent most of the war flying between the U.S. and India, via the Azores and North Africa or South America, Nigeria, and Central Africa. He also flew "the hump" over the Himalayas to deliver supplies to the Republic of China.
Following World War II, Goldwater was a leading proponent of creating the United States Air Force Academy, and later served on the Academy's Board of Visitors. The visitor center at the USAF Academy is now named in his honor. As a colonel he also founded the Arizona Air National Guard, and he would desegregate it two years before the rest of the US military. Goldwater was instrumental in pushing the Pentagon to support desegregation of the armed services.
Remaining in the Arizona Air National Guard and Air Force Reserve after the war, he eventually retired as a Command Pilot with the rank of major general. By that time, he had flown 165 different types of aircraft. In retirement, as an Air Force Reserve major general, and he continued piloting B-52 aircraft until late in his military career. To those who called him "rash", he would remind people of the old saying that "there are no old, bold pilots".
Interests.
Goldwater ran track and cross country in high school, where he specialized in the 880 yard run. His parents strongly encouraged him to compete in these sports, to Goldwater's dismay. He often went by the nickname of "Rolling Thunder."
In 1940, Goldwater became one of the first people to run the Colorado River recreationally through Grand Canyon participating as an oarsman on Norman Nevills' second commercial river trip. Goldwater joined them in Green River, Utah and rowed his own boat down to Lake Mead.
In 1970, the Arizona Historical Foundation published the daily journal Goldwater had maintained on the Grand Canyon journey, including his photographs, in a 209-page volume titled "Delightful Journey".
In 1963, he joined the Arizona Society of the Sons of the American Revolution. He was also a lifetime member of the Veterans of Foreign Wars, the American Legion, and Sigma Chi fraternity. He belonged to both the York Rite and Scottish Rite of Freemasonry, and was awarded the 33rd degree in the Scottish Rite.
Political career.
In a heavily Democratic state, Goldwater became a conservative Republican and a friend of Herbert Hoover. He was outspoken against New Deal liberalism, especially its close ties to labor unions he considered corrupt. A pilot, outdoorsman and photographer, he criss-crossed Arizona and developed a deep interest in both the natural and the human history of the state.
He entered Phoenix politics in 1949, when he was elected to the City Council as part of a nonpartisan team of candidates pledged to clean up widespread prostitution and gambling. The team won every mayoral and council election for the next two decades. Goldwater rebuilt the weak Republican party and was instrumental in electing Howard Pyle as Governor in 1950.
US Senator.
As a Republican he won a seat in the US Senate in 1952, when he upset veteran Democrat and Senate Majority Leader Ernest McFarland. He defeated McFarland again in 1958, with a strong showing in his first reelection in a year the Democrats gained 13 seats in the Senate. He gave up re-election for the Senate in 1964 in favor of his presidential campaign.
During his Senate career, Goldwater was regarded as the "Grand Old Man of the Republican Party and one of the nation's most respected exponents of conservatism."
Republican presidential Primary, 1964.
In 1964, Goldwater fought and won a bitterly contested, multi-candidate race for the Republican Party's presidential nomination. His main rival was New York Governor Nelson Rockefeller, whom he defeated by a narrow margin in the bitterly fought California primary. His nomination was opposed by liberal Republicans, who thought Goldwater's demand for rollback, defeat of the Soviet Union, would foment a nuclear war.
U.S. presidential campaign, 1964.
At the time of Goldwater's presidential candidacy, the Republican Party was split between its conservative wing (based in the West and South) and moderate/liberal wing, sometimes called Rockefeller Republicans (based in the Northeast). He alarmed even some of his fellow partisans with his brand of staunch fiscal conservatism and militant anti-communism. He was viewed by many traditional Republicans as being too far on the right wing of the political spectrum to appeal to the mainstream majority necessary to win a national election. As a result, moderate Republicans recruited a series of opponents, including New York Governor Nelson Rockefeller, Henry Cabot Lodge Jr., of Massachusetts and Pennsylvania Governor William Scranton, to challenge Goldwater. Goldwater would defeat Rockefeller in the winner-take-all California primary and secure the nomination. He also had a solid backing from Southern Republicans. A young Birmingham lawyer, John Grenier, secured commitments from 271 of 279 southern convention delegates to back Goldwater. Grenier would serve as executive director of the national GOP during the Goldwater campaign, the number 2 position to party chairman Dean Burch of Arizona.
Journalist John Adams says, "his acceptance speech was bold, reflecting his conservative views, but not irrational. Rather than shrinking from those critics who accuse him of extremism, Goldwater challenged them head-on" in his acceptance speech at the 1964 Republican Convention. In words that became famous (or infamous):
His paraphrase of Cicero was included at the suggestion of Harry V. Jaffa, though the speech was primarily written by Karl Hess. Because of President Johnson's popularity, however, Goldwater refrained from attacking the president directly. He did not mention Johnson by name at all in his convention speech.
Former U.S. Senator Prescott Bush, a moderate Republican from Connecticut, was a friend of Goldwater and supported him in the general election campaign. Bush's son, George H. W. Bush (then running for the Senate from Texas against Democrat Ralph Yarborough), was also a strong Goldwater supporter in both the nomination and general election campaigns.
Future Chief Justice of the United States and fellow Arizonan William H. Rehnquist also first came to the attention of national Republicans through his work as a legal adviser to Goldwater's presidential campaign. Rehnquist had begun his law practice in 1953 in the firm of Denison Kitchel of Phoenix, Goldwater's national campaign manager and friend of nearly three decades.
Goldwater was painted as a dangerous figure by the Johnson campaign, which countered Goldwater's slogan "In your heart, you know he's right" with the lines "In your guts, you know he's nuts", and "In your heart, you know he might" (that is, he might actually use nuclear weapons as opposed to using only deterrence). Johnson himself did not mention Goldwater in his own acceptance speech at the 1964 Democratic National Convention.
Goldwater's provocative advocacy of aggressive tactics to prevent the spread of communism in Asia led to effective counterattacks from Lyndon B. Johnson and his supporters, who claimed that Goldwater's militancy would have dire consequences, possibly even nuclear war. In a May 1964 speech, Goldwater suggested that nuclear weapons should be treated more like conventional weapons and used in Vietnam, specifically that they should have been used at Dien Bien Phu in 1954 to defoliate trees. Regarding Vietnam, Goldwater charged that Johnson's policy was devoid of "goal, course, or purpose", leaving "only sudden death in the jungles and the slow strangulation of freedom". Goldwater's rhetoric on nuclear war was viewed by many as quite uncompromising, a view buttressed by off-hand comments such as, "Let's lob one into the men's room at the Kremlin." He also advocated that field commanders in Vietnam and Europe should be given the authority to use tactical nuclear weapons (which he called "small conventional nuclear weapons") without presidential confirmation.
Goldwater did his best to counter the Johnson attacks, criticizing the Johnson administration for its perceived ethical lapses, and stating in a commercial that "we, as a nation, are not far from the kind of moral decay that has brought on the fall of other nations and people... I say it is time to put conscience back in government. And by good example, put it back in all walks of American life." Goldwater campaign commercials included statements of support by actor Raymond Massey and moderate Republican senator Margaret Chase Smith.
Before the 1964 election, the muckraking "Fact" magazine, published by Ralph Ginzburg, ran a special issue titled "The Unconscious of a Conservative: A Special Issue on the Mind of Barry Goldwater". The two main articles contended that Goldwater was mentally unfit to be president. The magazine attempted to support this claim with the results of an unscientific poll of psychiatrists it had conducted. "Fact" had mailed questionnaires to 12,356 psychiatrists, and published a "sampling" of the comments made by the 2,417 psychiatrists who responded, of whom 1,189 said Goldwater was unfit to be president. Not one of the psychiatrists had actually interviewed Goldwater himself.
After the election, Goldwater sued the publisher, the editor and the magazine for libel in "Goldwater v. Ginzburg". "Although the jury awarded Goldwater only $1.00 in compensatory damages against all three defendants, it went on to award him punitive damages of $25,000 against Ginzburg and $50,000 against "Fact" magazine, Inc." According to Warren Boroson, then-managing editor of "Fact" and now a financial columnist, the main biography of Goldwater in the magazine was written by David Bar-Illan, the Israeli pianist.
Political advertising.
A Democratic campaign advertisement known as Daisy showed a young girl counting daisy petals, from one to ten. Immediately following this scene, a voiceover counted down from ten to one. The child's face was shown as a still photograph followed by images of nuclear explosions and mushroom clouds. The campaign advertisement ended with a plea to vote for Johnson, implying that Goldwater (though not mentioned by name) would provoke a nuclear war if he was elected. The advertisement, which featured only a few spoken words and relied on imagery for its emotional impact, was one of the most provocative in American political campaign history, and many analysts credit it as being the birth of the modern style of "negative political ads" on television. The ad aired only once and was immediately pulled, but it was then shown many times by local television stations.
Goldwater did not have ties to the Ku Klux Klan (KKK), but was publicly endorsed by members of the organization. Lyndon Johnson exploited this association during the elections, but Goldwater barred the KKK from supporting him and denounced them.
Past comments came back to haunt Goldwater throughout the campaign. He had once called the Eisenhower administration "a dime-store New Deal", and the former president never fully forgave him. Eisenhower did, however, film a television commercial with Goldwater. Eisenhower qualified his voting for Goldwater in November by remarking that he had voted not specifically for Goldwater, but for the Republican Party. In December 1961, Goldwater had told a news conference that "sometimes I think this country would be better off if we could just saw off the Eastern Seaboard and let it float out to sea". That comment boomeranged on him during the campaign in the form of a Johnson television commercial, as did remarks about making Social Security voluntary, and statements in Tennessee about selling the Tennessee Valley Authority, a large local New Deal employer.
The Goldwater campaign spotlighted Ronald Reagan, who appeared in a campaign ad. In turn, Reagan gave a stirring, nationally televised speech, "A Time for Choosing", in support of Goldwater. The speech prompted Reagan to seek the California Governorship in 1966 and jump-started his political career. Conservative activist Phyllis Schlafly, later well known for her fight against the Equal Rights Amendment, first became known for writing a pro-Goldwater book, "A Choice, Not an Echo", attacking the moderate Republican establishment.
Results.
Goldwater lost to President Lyndon Johnson by a massive landslide, pulling down the GOP, which lost many seats in both houses of Congress.
Goldwater only won his home state of Arizona and five states in the Deep South, depicted in red. The Southern states, traditionally Democratic up to that time, voted Republican primarily as a statement of opposition to the Civil Rights Act, which had been passed by Johnson and the Northern Democrats, as well as the majority of Republicans in Congress, earlier that year.
In the end, Goldwater received 38.4% of the popular vote, and carried just six states: Arizona (with 50.45% of the popular vote) and the core states of the Deep South: Alabama, Georgia, Louisiana, Mississippi, and South Carolina. In carrying Georgia by a margin of 54–45%, Goldwater became the first Republican nominee to win the state. However, the overall result was the worst showing in terms of popular vote and electoral college vote for any post-World War II Republican.
In all, Johnson won an overwhelming 486 electoral votes, to Goldwater's 52. Goldwater, with his customary bluntness, remarked, "We would have lost even if Abraham Lincoln had come back and campaigned with us." He maintained later in life that he would have won the election if the country had not been in a state of extended grief (referring to the assassination of John F. Kennedy), and that it was simply not ready for a third President in just 14 months.
Goldwater's poor showing pulled down many supporters. Of the 57 Republican Congressmen who endorsed Goldwater before the convention, 20 were defeated for reelection, along with many promising young Republicans. On the other hand, the defeat of so many older politicians created openings for young conservatives to move up the ladder. While the loss of moderate Republicans was temporary—they were back by 1966—Goldwater also permanently pulled many conservative Southerners and white ethnics out of the New Deal Coalition.
"In the South, Goldwater broke through and won five states—the best showing in the region for a GOP candidate since Reconstruction. In Mississippi—where Franklin D. Roosevelt had won nearly 100 percent of the vote just 28 years earlier—Goldwater claimed a staggering 87 percent." It has frequently been argued that Goldwater's strong performance in Southern states previously regarded as Democratic strongholds foreshadowed a larger shift in electoral trends in the coming decades that would make the South a Republican bastion (an end to the "Solid South")—first in presidential politics and eventually at the congressional and state levels, as well.
Return to US Senate.
Goldwater remained popular in Arizona, and in the 1968 Senate election he was elected (this time) to the seat of retiring Senator Carl Hayden. He was subsequently reelected in 1974 and 1980. The 1974 election saw Goldwater easily reelected over his Democratic opponent, Jonathan Marshall, the publisher of "The Scottsdale Progress". His final campaign in 1980 was close, with Goldwater winning in a near draw against Democratic challenger Bill Schulz. Goldwater said later that the close result convinced him not to run again.
Retirement.
Goldwater seriously considered retirement in 1980 before deciding to run for reelection. Peggy Goldwater reportedly hoped that her husband's Senate term, due to end in January 1981, would be his last. Goldwater decided to run, planning to make the term his last in the Senate. Goldwater faced a surprisingly tough battle for reelection. He was viewed by some as out of touch and vulnerable for several reasons; most importantly, because he had planned to retire in 1981, Goldwater had not visited many areas of Arizona outside of Phoenix and Tucson. He was also challenged by a formidable opponent, Bill Schulz, a former Republican turned Democrat and a wealthy real estate developer. Schulz was able to infuse massive amounts of money into the campaign from his own fortune.
Arizona's changing population also hurt Goldwater. The state's population had soared, and a huge portion of the electorate had not lived in the state when Goldwater was previously elected; hence, many voters were less familiar with Goldwater's actual beliefs, and he was on the defensive for much of the campaign. Early returns on election night seemed to indicate that Schulz would win. The counting of votes continued through the night and into the next morning. At around daybreak, Goldwater learned that he had been reelected thanks to absentee ballots, which were among the last to be counted. Goldwater's surprisingly close victory in 1980 came despite Reagan's 61% landslide over Jimmy Carter in Arizona. Republicans regained control of the Senate, putting Goldwater in the most powerful position he ever had in the Senate.
Goldwater retired in 1987, serving as chair of the Senate Intelligence and Armed Services Committees in his final term. Despite his reputation as a firebrand in the 1960s, by the end of his career he was considered a stabilizing influence in the Senate, one of the most respected members of either major party. Though Goldwater remained staunchly anti-communist and "hawkish" on military issues, he was a key supporter of the fight for ratification of the Panama Canal Treaty in the 1970s, which would give control of the canal zone to the Republic of Panama. His most important legislative achievement may have been the Goldwater–Nichols Act, which reorganized the US military's senior-command structure.
Policies.
Goldwater became most associated with labor-union reform and anti-communism; he was an active supporter of the conservative coalition in Congress. His work on labor issues led to Congress passing major anti-corruption reforms in 1957, and an all-out campaign by the AFL-CIO to defeat his 1958 reelection bid. He voted against the censure of Senator Joseph McCarthy in 1954, but he never actually charged any individual with being a communist/Soviet agent. Goldwater emphasized his strong opposition to the worldwide spread of communism in his 1960 book "The Conscience of a Conservative". The book became an important reference text in conservative political circles.
In 1964, Goldwater ran a conservative campaign that emphasized states' rights. Goldwater's 1964 campaign was a magnet for conservatives since he opposed interference by the federal government in state affairs. Although he had supported all previous federal civil rights legislation and had supported the original senate version of the bill, Goldwater made the decision to oppose the Civil Rights Act of 1964. His stance was based on his view that the act was an intrusion of the federal government into the affairs of states and that the Act interfered with the rights of private persons to do or not do business with whomever they chose. In the segregated city of Phoenix in the 1950s, he had quietly supported civil rights for blacks, but would not let his name be used.
All this appealed to white Southern Democrats, and Goldwater was the first Republican to win the electoral votes of all of the Deep South states (South Carolina, Georgia, Alabama, Mississippi and Louisiana) since Reconstruction (although Dwight Eisenhower did carry Louisiana in 1956). However, Goldwater's vote on the Civil Rights Act proved devastating to his campaign everywhere outside the South (besides Dixie, Goldwater won only in Arizona, his home state), contributing to his landslide defeat in 1964.
While Goldwater had been depicted by his opponents in the Republican primaries as a representative of a conservative philosophy that was extreme and alien, his voting records show that his positions were in harmony with those of his fellow Republicans in the Congress. What distinguished him from his predecessors was, according to Hans J. Morgenthau, his firmness of principle and determination, which did not allow him to be content with mere rhetoric.
Goldwater fought in 1971 to stop US funding of the United Nations after the People's Republic of China was admitted to the organization. He said:
Political relationships.
Goldwater was grief-stricken by the assassination of Kennedy and was greatly disappointed that his opponent in 1964 would not be Kennedy but instead his Vice President, former Senate Majority Leader Lyndon B. Johnson of Texas. Goldwater disliked Johnson (saying he "used every dirty trick in the bag"), and Richard M. Nixon of California (whom he later called "the most dishonest individual I have ever met in my life"). After Goldwater again became a senator, he urged Nixon to resign at the height of the Watergate scandal, warning that fewer than ten senators would vote against conviction if Nixon were impeached by the House of Representatives. The term "Goldwater moment" has since been used to describe situations when influential members of Congress disagree so strongly with a president from their own party that they openly oppose him.
Goldwater and the revival of American conservatism.
Although Goldwater was not as important in the American conservative movement as Ronald Reagan after 1965, he shaped and redefined the movement from the late 1950s to 1964. Arizona Senator John McCain, who had succeeded Goldwater in the Senate in 1987, summed up Goldwater's legacy, "He transformed the Republican Party from an Eastern elitist organization to the breeding ground for the election of Ronald Reagan." Columnist George Will remarked after the 1980 Presidential election that it took 16 years to count the votes from 1964 and Goldwater won.
The Republican Party recovered from the 1964 election debacle, picking up 47 seats in the House of Representatives in the 1966 mid-term election. Further Republican successes ensued, including Goldwater's return to the Senate in 1968. In January of that year, Goldwater wrote an article in the "National Review" "affirming that he not against liberals, that liberals are needed as a counterweight to conservatism, and that he had in mind a fine liberal like Max Lerner".
Goldwater was a strong supporter of the environment. He explained his position in 1969:
Throughout the 1970s, as the conservative wing under Reagan gained control of the party, Goldwater concentrated on his Senate duties, especially in military affairs. He played little part in the election or administration of Richard Nixon, but he helped force Nixon's resignation in 1974. In 1976 he helped block Rockefeller's renomination as vice president. When Reagan challenged Ford for the presidential nomination in 1976, Goldwater endorsed Ford, looking for consensus rather than conservative idealism. As one historian notes, "The Arizonan had lost much of his zest for battle."
In 1979, when President Carter normalized relations with Communist China, Goldwater and some other senators sued him in the Supreme Court, arguing that the president could not terminate the Sino-American Mutual Defense Treaty with Republic of China (Taiwan) without the approval of Congress. The case, "Goldwater v. Carter" 444 U.S. 996, was dismissed by the court as a political question.
Later life.
By the 1980s, with Ronald Reagan as president and the growing involvement of the religious right in conservative politics, Goldwater's libertarian views on personal issues were revealed; he believed that they were an integral part of true conservatism. Goldwater viewed abortion as a matter of personal choice and supported as such abortion rights.
As a passionate defender of personal liberty, he saw the religious right's views as an encroachment on personal privacy and individual liberties. In his 1980 Senate reelection campaign, Goldwater won support from religious conservatives but in his final term voted consistently to uphold legalized abortion and, in 1981, gave a speech on how he was angry about the bullying of American politicians by religious organizations, and would "fight them every step of the way". Goldwater also disagreed with the Reagan administration on certain aspects of foreign policy (for example, he opposed the decision to mine Nicaraguan harbors). Notwithstanding his prior differences with Dwight D. Eisenhower, Goldwater in a 1986 interview rated him the best of the seven Presidents with whom he had worked.
He introduced the 1984 Cable Franchise Policy and Communications Act, which allowed local governments to require the transmission of public, educational, and government access (PEG) channels, barred cable operators from exercising editorial control over content of programs carried on PEG channels, and absolved them from liability for their content.
On May 12, 1986, Goldwater was presented with the Presidential Medal of Freedom by President Ronald Reagan.
After his retirement in 1987, Goldwater described the Arizona Governor Evan Mecham as "hardheaded" and called on him to resign, and two years later stated that the Republican party had been taken over by a "bunch of kooks".
He is a 1987 recipient of the Langley Gold Medal from the Smithsonian Institution. In 1988, in recognition of his career, Princeton University's American Whig-Cliosophic Society awarded Goldwater the James Madison Award for Distinguished Public Service.
In a 1994 interview with the "Washington Post", the retired senator said,
Goldwater visited the small town of Bowen, Illinois in 1989 to see first hand where his mother was raised.
In response to Moral Majority founder Jerry Falwell's opposition to the nomination of Sandra Day O'Connor to the Supreme Court, of which Falwell had said, "Every good Christian should be concerned", Goldwater retorted: "Every good Christian ought to kick Falwell right in the ass." (According to John Dean, Goldwater actually suggested that good Christians ought to kick Falwell in the "nuts", but the news media "changed the anatomical reference.") Goldwater also had harsh words for his one-time political protegé, President Reagan, particularly after the Iran-Contra Affair became public in 1986. Journalist Robert MacNeil, a friend of Goldwater's from the 1964 Presidential campaign, recalled interviewing him in his office shortly afterward. "He was sitting in his office with his hands on his cane... and he said to me, 'Well, aren't you going to ask me about the Iran arms sales?' It had just been announced that the Reagan administration had sold arms to Iran. And I said, 'Well, if I asked you, what would you say?' He said, 'I'd say it's the god-damned stupidest foreign policy blunder this country's ever made!'", though aside from the Iran-Contra scandal, Goldwater thought nonetheless that Reagan was a good president. In 1988 during that year's presidential campaign, he pointedly told vice-presidential nominee Dan Quayle at a campaign event in Arizona "I want you to go back and tell George Bush to start talking about the issues."
Some of Goldwater's statements in the 1990s alienated many social conservatives. He endorsed Democrat Karan English in an Arizona congressional race, urged Republicans to lay off Bill Clinton over the Whitewater scandal, and criticized the military's ban on homosexuals: "Everyone knows that gays have served honorably in the military since at least the time of Julius Caesar." He also said, "You don't need to be 'straight' to fight and die for your country. You just need to shoot straight." A few years before his death he addressed establishment Republicans by saying, "Do not associate my name with anything you do. You are extremists, and you've hurt the Republican party much more than the Democrats have."
In 1996, he told Bob Dole, whose own presidential campaign received lukewarm support from conservative Republicans: "We're the new liberals of the Republican party. Can you imagine that?" In that same year, with Senator Dennis DeConcini, Goldwater endorsed an Arizona initiative to legalize medical marijuana against the countervailing opinion of social conservatives.
Hobbies and interests.
Amateur radio.
Goldwater was an avid amateur radio operator from the early 1920s onwards, with the call signs 6BPI, K3UIG and K7UGA. The latter is now used by an Arizona club honoring him as a commemorative call. During the Vietnam War, he spent many hours giving servicemen overseas the ability to talk to their families at home over the Military Affiliate Radio System (MARS).
Goldwater was also a prominent spokesman for amateur radio and its enthusiasts. Beginning in 1969 up to his death he appeared in numerous educational and promotional films (and later videos) about the hobby that were produced for the American Radio Relay League (the United States national society representing the interests of radio amateurs) by such producers as Dave Bell (W6AQ), ARRL Southwest Director John R. Griggs (W6KW), Alan Kaul (W6RCL), Forrest Oden (N6ENV), and the late Roy Neal (K6DUE). His first appearance was in Dave Bell's "The World of Amateur Radio" where Goldwater discussed the history of the hobby and demonstrated a live contact with Antarctica. His last on-screen appearance dealing with "ham radio" was in 1994, explaining a then-upcoming, Earth-orbiting ham radio relay satellite.
Electronics were a hobby for Goldwater beyond amateur radio. He enjoyed assembling Heathkits, completing more than 100 and often visiting their maker in Benton Harbor, Michigan to buy more, before the company exited the kit business in 1992.
Kachina dolls.
In 1916, Goldwater visited the Hopi Reservation with Phoenix architect John Rinker Kibby, and obtained his first kachina doll. Eventually his doll collection included 437 items and was presented in 1969 to the Heard Museum in Phoenix.
Photography.
Goldwater was an amateur photographer and in his estate left some 15,000 of his images to three Arizona institutions. He was very keen on candid photography. He got started in photography after receiving a camera as a gift from his wife on their first Christmas together. He was known to use a 4x5 Graflex, Rolleiflex, 16 mm Bell and Howell motion picture camera, and 35 mm Nikkormat FT. He was a member of the Royal Photographic Society from 1941 becoming a Life Member in 1948.
For decades, he contributed photographs of his home state to "Arizona Highways" and was best known for his Western landscapes and pictures of native Americans in the United States. Three books with his photographs are "People and Places", from 1967; "Barry Goldwater and the Southwest", from 1976; and "Delightful Journey", first published in 1940 and reprinted in 1970. Ansel Adams wrote a foreword to the 1976 book.
Goldwater's photography interests occasionally crossed over with his political career, as well. John F. Kennedy, as president, was known to invite former congressional colleagues to the White House for a drink. On one occasion, Goldwater brought his camera and photographed President Kennedy. When Kennedy received the photo, he returned it to Goldwater, with the inscription, "For Barry Goldwater – Whom I urge to follow the career for which he has shown such talent – photography! – from his friend – John Kennedy." This quip became a classic of American political humor after it was made famous by humorist Bennett Cerf. The photo itself was prized by Goldwater for the rest of his life, and recently sold for $17,925 in a Heritage auction.
Son Michael Prescott Goldwater formed the Goldwater Family Foundation with the goal of making his father's photography available via the internet. ("Barry Goldwater Photographs") was launched in September 2006 to coincide with the HBO documentary ""Mr. Conservative"", produced by granddaughter CC Goldwater.
UFOs.
On March 28, 1975, Goldwater wrote to Shlomo Arnon: "The subject of UFOs has interested me for some long time. About ten or twelve years ago I made an effort to find out what was in the building at Wright-Patterson Air Force Base where the information has been stored that has been collected by the Air Force, and I was understandably denied this request. It is still classified above Top Secret." Goldwater further wrote that there were rumors the evidence would be released, and that he was "just as anxious to see this material as you are, and I hope we will not have to wait much longer."
The April 25, 1988, issue of "The New Yorker" carried an interview where Goldwater said he repeatedly asked his friend, Gen. Curtis LeMay, if there was any truth to the rumors that UFO evidence was stored in a secret room at Wright-Patterson Air Force Base, and if he (Goldwater) might have access to the room. According to Goldwater, an angry LeMay gave him "holy hell" and said, "Not only can't you get into it but don't you ever mention it to me again."
In a 1988 interview on Larry King's radio show, Goldwater was asked if he thought the U.S. Government was withholding UFO evidence; he replied "Yes, I do." He added:
Goldwater Scholarship.
The Barry M. Goldwater Scholarship and Excellence in Education Program was established by Congress in 1986. Its goal is to provide a continuing source of highly qualified scientists, mathematicians, and engineers by awarding scholarships to college students who intend to pursue careers in these fields.
The Scholarship is widely considered the most prestigious award in the U.S. conferred upon undergraduates studying the sciences. It is awarded to about 300 students (college sophomores and juniors) nationwide in the amount of $7500 per academic year (for their senior year, or junior and senior years). It honors Goldwater's keen interest in science and technology.
Death.
Goldwater's public appearances ended in late 1996 after he suffered a massive stroke; family members then disclosed he was in the early stages of Alzheimer's disease. He died on May 29, 1998, at the age of 89 at his long-time home in Paradise Valley, Arizona, of complications from the stroke. His funeral was co-officiated by both a reverend and a rabbi. His ashes were buried at the Episcopal Christ Church of the Ascension in Paradise Valley, Arizona. A memorial statue set in a small park has been erected to honor the memory of Goldwater in that town, near his former home and current resting place.
Legacy.
Buildings and monuments.
Among the buildings and monuments named after Barry Goldwater are: the Barry M. Goldwater Terminal at Phoenix Sky Harbor International Airport, Goldwater Memorial Park in Paradise Valley, Arizona, the Barry Goldwater Air Force Academy Visitor Center at the United States Air Force Academy, and Barry Goldwater High School in northern Phoenix. In 2010 former Arizona Attorney General Grant Woods, himself a Goldwater scholar and supporter, founded the Goldwater Women's Tennis Classic Tournament to be held annually at the Phoenix Country Club in Phoenix, AZ. On February 11, 2015, a statue of the late Barry M. Goldwater was unveiled by U.S. House and Senate leaders at a dedication ceremony in National Statuary Hall of the U.S. Capitol building in Washington, D.C.
Documentary.
Goldwater's granddaughter, CC Goldwater, has co-produced with longtime friend and independent film producer Tani L. Cohen a documentary on Goldwater's life, "Mr. Conservative: Goldwater on Goldwater", first shown on HBO on September 18, 2006.
In popular culture.
In the "Batman" TV series in the episode entitled "Hizzonner the Penguin", aired on November 2, 1966, Batman runs for Mayor of Gotham City against the Penguin. One of the other candidates in the race was "Harry Goldriver of the Monarchist Party".
Senator Goldwater was an occasional roaster on the Dean Martin roasts of the mid-1970s.
In his song "I Shall Be Free No. 10", Bob Dylan refers to Goldwater: "I'm liberal to a degree, I want everybody to be free. But if you think I'll let Barry Goldwater move in next door and marry my daughter, you must think I'm crazy."
Relatives.
Goldwater's son, Barry Goldwater Jr., served as a Congressman from California from 1969 to 1983. He was the first Congressman to serve while having a father in the Senate. Goldwater's nephew, Don Goldwater, sought the Arizona Republican Party nomination for Governor of Arizona in 2006, but was defeated by Len Munsil.

</doc>
<doc id="4794" url="https://en.wikipedia.org/wiki?curid=4794" title="Baralong incidents">
Baralong incidents

The Baralong incidents were naval engagements of the First World War in August and September 1915, involving the Royal Navy Q-ship , later renamed HMS "Wyandra", and two German U-boats.
"Baralong" sank , which had been preparing to sink a nearby merchant ship, the "Nicosian". About a dozen of the crewmen managed to escape from the sinking submarine, and Lieutenant Godfrey Herbert, commanding officer of "Baralong", ordered the surviving sailors to be summarily executed after they boarded the "Nicosian". All the survivors of "U-27"s sinking, including several who had reached the "Nicosian", were shot by "Baralong"s crew. Later, "Baralong" sank in an incident which has also been described as a war crime.
First incident.
Action of 19 August 1915.
After the sinking of by a German submarine in May 1915, Lieutenant-Commander Godfrey Herbert, commanding officer of "Baralong", was visited by two officers of the Admiralty's Secret Service branch at the naval base at Queenstown, Ireland. He was told, "This "Lusitania" business is shocking. Unofficially, we are telling you... take no prisoners from U-boats."
Interviews with his subordinate officers have established Herbert's undisciplined manner of commanding his ship. Herbert allowed his men to engage in drunken binges during shore leave. During one such incident, at Dartmouth, several members of "Baralong"s crew were arrested after destroying a local saloon. Herbert paid their bail, then left port with the indicted crewmen aboard. Beginning in April 1915, Herbert ordered his subordinates to cease calling him "Sir", and to address him only by the pseudonym "Captain William McBride."
Throughout the summer of 1915, "Baralong" continued routine patrol duties in the Irish Sea without encountering the enemy.
On 19 August 1915, sank the White Star Liner with the loss of 44 lives - this included three Americans and led to a diplomatic incident between Germany and the U.S. "Baralong" had been about from the scene, and had received a distress call from the ship. "Baralong"s crew was infuriated by the attack and by their inability to locate survivors.
Meanwhile, about south of Queenstown, , commanded by "Kapitänleutnant" Bernd Wegener, stopped the British steamer "Nicosian" in accordance with the rules laid down by the London Declaration. A boarding party of six men from "U-27" discovered that "Nicosian" was carrying munitions and 250 American mules earmarked for the British Army in France. The Germans allowed the freighter's crew and passengers to board lifeboats, and prepared to sink the freighter with the U-boat's deck gun.
"U-27" was lying off "Nicosian"s port quarter and firing into it when "Baralong" appeared on the scene, flying the ensign of the United States as a false flag. When she was half a mile away, "Baralong" ran up a signal flag indicating that she was going to rescue "Nicosian"s crew. Wegener acknowledged the signal, then ordered his men to cease firing, and took "U-27" along the port side of "Nicosian" to intercept "Baralong". As the submarine disappeared behind the steamship, Herbert steered "Baralong" on a parallel course along "Nicosian"s starboard side.
Before "U-27" came round "Nicosian"s bow, "Baralong" hauled down the American flag, hoisted the Royal Navy's White Ensign, and unmasked her guns. As "U-27" came into view from behind "Nicosian", "Baralong" opened fire with her three 12-pounder guns at a range of , firing 34 rounds for only a single shot from the submarine. "U-27" rolled over and began to sink.
According to Tony Bridgland; "Herbert screamed, 'Cease fire!' But his men's blood was up. They were avenging the "Arabic" and the "Lusitania". For them this was no time to cease firing, even as the survivors of the crew appeared on the outer casing, struggling out of their clothes to swim away from her. There was a mighty hiss of compressed air from her tanks and the "U-27" vanished from sight in a vortex of giant rumbling bubbles, leaving a pall of smoke over the spot where she had been. It had taken only a few minutes to fire the thirty-four shells into her."
Meanwhile, "Nicosian"s crew were cheering wildly from the lifeboats. Captain Manning was heard to yell, "If any of those bastard Huns come up, lads, hit 'em with an oar!"
Twelve men survived the sinking of the submarine: the crews of her two deck guns and those who had been on the conning tower. They swam to "Nicosian" and attempted to join the six-man boarding party by climbing up her hanging lifeboat falls and pilot ladder. Herbert, worried that they might try to scuttle the steamer, ordered his men to open fire with small arms, killing all in the water. Wegener is described by some accounts as being shot while trying to swim to the "Baralong".
Herbert sent "Baralong"s 12 Royal Marines, under the command of a Corporal Collins, to find the surviving German sailors aboard "Nicosian". As they departed, Herbert told Collins, "Take no prisoners." The Germans were discovered in the engine room and shot on sight. According to Sub-Lieutenant Gordon Steele: "Wegener ran to a cabin on the upper deck -- I later found out it was Manning's bathroom. The marines broke down the door with the butts of their rifles, but Wegener squeezes through a scuttle and dropped into the sea. He still had his life-jacket on and put up his arms in surrender. Corporal Collins, however, took aim and shot him through the head." Corporal Collins later recalled that, after Wegener's death, Herbert threw a revolver in the German captain's face and screamed, "What about the "Lusitania", you bastard!" An alternative account says that the Germans who boarded "Nicosian" were killed by the freighter's engine room staff; this report apparently came from the officer in command of the muleteers.
Aftermath.
In Herbert's report to the Admiralty, he stated he feared the survivors from the U-boat's crew would board the freighter and scuttle her, so he ordered the Royal Marines on his ship to shoot the survivors. If they had scuttled the freighter, it could have been counted as negligence on the part of Herbert. Moments before "Baralong" began her attack, the submarine was firing on the freighter. It is not known if the escaping sailors actually intended to scuttle the freighter.
The Admiralty, upon receiving Herbert's report, immediately ordered its suppression, but the strict censorship imposed on the event failed when Americans who had witnessed the incident from "Nicosian"s lifeboats spoke to newspaper reporters after their return to the United States.
German memorandum.
The German government delivered a memorandum on the incident via the American ambassador in Berlin, who received it on 6 December 1915. In it, they cited six US citizens as witnesses, stating they had made sworn depositions regarding the incident before public notaries in the US.
The statements said that five survivors from "U-27" managed to board "Nicosian", while the rest were shot and killed on Herbert's orders while clinging to the merchant vessel's lifeboat falls. It was further stated that when Herbert ordered his Marines to board "Nicosian", he gave the order "take no prisoners". Four German sailors were found in "Nicosian"s engine room and propeller shaft tunnel, and were killed. According to the witness statements, "U-27"s commander was shot while swimming towards "Baralong".
The memorandum demanded that the captain and crew of "Baralong" be tried for the murder of unarmed German sailors, threatening to "take the serious decision of retribution for an unpunished crime". Sir Edward Grey replied through the American ambassador that the incident could be grouped together with the Germans' sinking of SS "Arabic", their attack on a stranded British submarine on the neutral Dutch coast, and their attack on the steamship "Ruel", and suggested that they be placed before a tribunal composed of US Navy officers.
German reaction.
A debate took place in the Reichstag on 15 January 1916, where the incident was described as a "cowardly murder" and Grey's note as being "full of insolence and arrogance". It was announced that reprisals had been decided, but not what form they would take.
Meanwhile, the Military Bureau for the Investigation of Violations of the Laws of War", () added "Baralong"'s commander, whose name was known only as "Captain William McBride", to the Prussian Ministry of War's "Black List of Englishmen who are Guilty of Violations of the Laws of War vis a vis Members of the German Armed Forces."
"HMS Baralong"s actions led the "Kaiserliche Marine" to cease adhering to the Prize Rules and to practise unrestricted submarine warfare. During the Second World War, it was cited as a reason for the "Kriegsmarine" to do the same. A German medal was issued commemorating the event. 
As a precaution to protect the ships against any reprisals against their crews, HMS "Wyandra" was transferred to the Mediterranean, and took the name of sister ship "Manica", while "Baralong"s name was deleted from "Lloyd's Register". "Nicosian" was renamed "Nevisian", and the crew was issued new Discharge Books, with the voyage omitted.
"Baralong"s crew were later awarded £185 prize bounty for sinking "U-27".
A "Kriegsmarine" submarine flotilla formed on 25 June 1938 was named "Wegener" in memory of "U-27"s commander.
Second incident.
Action of 24 September 1915.
On 24 September 1915, "Baralong" sank the U-boat , for which her commanding officer at the time, Lieutenant-Commander A. Wilmot-Smith, was later awarded £170 prize bounty.
"U-41" was in the process of sinking SS "Urbino" with gunfire when "Baralong" arrived on the scene, flying an American flag. When "U-41" surfaced near "Baralong", the latter opened fire while continuing to fly the American flag, and sank the U-boat.
Aftermath of the second incident.
Unlike the neutral Americans in the first incident, the only witnesses to the second attack were the German and British sailors present. "Oberleutnant zur See" Iwan Crompton, after returning to Germany from a prisoner-of-war camp, reported that "Baralong" had run down the lifeboat he was in; he leapt clear and was shortly after taken aboard "Baralong". The British crew denied that they had run down the lifeboat. Crompton later published an account of "U-41"s exploits in 1917, "U-41: der zweite Baralong-Fall", which called the sinking of "U-41" a "second Baralong case".

</doc>
<doc id="4795" url="https://en.wikipedia.org/wiki?curid=4795" title="Banda">
Banda

Bandra may refer to:
Music.
A band is a group of four or more of persons that sing one or more geners.

</doc>
<doc id="4796" url="https://en.wikipedia.org/wiki?curid=4796" title="Bladder (disambiguation)">
Bladder (disambiguation)

Bladder often refers to the urinary bladder, which collects urine for excretion in animals.
Bladder may also refer to:

</doc>
<doc id="4797" url="https://en.wikipedia.org/wiki?curid=4797" title="Bob Young (businessman)">
Bob Young (businessman)

Robert "Bob" Young is a serial entrepreneur who is best known for founding Red Hat Inc., the open source software company. He is also the owner of the Hamilton Tiger-Cats of the Canadian Football League. He was born in Hamilton, Ontario, Canada. He attended Trinity College School in Port Hope, Ontario. He received a Bachelor of Arts from Victoria College at the University of Toronto. 
Career.
Prior to Red Hat, Young built a couple of computer rental and leasing businesses, including founding Vernon Computer Rentals in 1984. Descendants of Vernon are still operating under that name. After leaving Vernon, Young founded the ACC Corp Inc. in 1993. 
Marc Ewing and Young's partnership started in 1994 when ACC acquired the Red Hat trademarks from Ewing. In early 1995, ACC changed its name to Red Hat Software, which has subsequently changed to simply Red Hat, Inc. Young served as Red Hat's CEO until 1999. 
After leaving Red Hat he founded Lulu.com in 2002, a self-publishing web-site that claims to be the world's fastest-growing provider of print-on-demand books. In 2006, Young established the Lulu Blooker Prize, a book prize for books that began as blogs. He launched the prize partly as a means of promoting Lulu.
Young also co-founded "Linux Journal" in 1994, and in 2003, he purchased the Hamilton Tiger-Cats, a Canadian Football League franchise. 
Young focuses his philanthropic efforts to support an increased access to information and advancement of knowledge. In 1999, he founded The Center for the Public Domain. Young currently supports Creative Commons, the Public Knowledge Project, the Dictionary of Old English, the Internet Archive, ibiblio, the NCSU eGames, and the Bald Head Island Conservancy, among others. He is a Visionaries' Circle supporter of the Loran Scholars Foundation.

</doc>
<doc id="4800" url="https://en.wikipedia.org/wiki?curid=4800" title="Babylon 5">
Babylon 5

Babylon 5 is an American science fiction television series created by writer and producer J. Michael Straczynski, under the Babylonian Productions label, in association with Straczynski's Synthetic Worlds Ltd. and Warner Bros. Domestic Television. After the successful airing of a test pilot movie on February 22, 1993, "", in May 1993 Warner Brothers commissioned the series for production as part of its Prime Time Entertainment Network (PTEN).
The first season premiered in the US on January 26, 1994, and the series ultimately ran for the intended five seasons. Describing it as having "always been conceived as, fundamentally, a five-year story, a novel for television", Straczynski wrote 92 of the 110 episodes, and served as executive producer, along with Douglas Netter.
Setting.
Set between the years 2257 and 2262, it depicts a future where Earth has sovereign states, and a unifying Earth government. Colonies within the solar system, and beyond, make up the Earth Alliance, and contact has been made with other spacefaring species. The ensemble cast portray alien ambassadorial staff and humans assigned to the -long "Babylon 5" space station, a center for trade and diplomacy. Described as "one of the most complex programs on television", the various story arcs drew upon the prophesies, religious zealotry, racial tensions, social pressures, and political rivalries which existed within each of their cultures, to create a contextual framework for the motivations and consequences of the protagonists' actions. With a strong emphasis on character development set against a backdrop of conflicting ideologies on multiple levels, Straczynski wanted "to take an adult approach to SF, and attempt to do for television SF what "Hill Street Blues" did for cop shows."
Influence.
Generally viewed as having "launched the new era of television CGI visual effects", it received multiple awards during its initial run, including two consecutive Hugo Awards for best dramatic presentation, and continues to regularly feature prominently in various polls and listings highlighting top-rated science fiction series. Not appearing on American television since 2003, it continues to be shown in international markets such as Fox in the UK, the TV4-ScifFi Channel in Sweden, and the FBC TV channel in Fiji. Initially written by Straczynski, DC began publishing Babylon 5 comics in 1994, with stories that closely tied in with events depicted in the show, with events in the comics eventually being referenced onscreen in the actual television series. The franchise continued to expand into short stories, RPG's, and novels, with the Technomage trilogy of books being the last to be published in 2001, shortly after the spin-off television series, "Crusade", was cancelled. Excepting movie rights, which are retained by Straczynski, all production rights for the franchise are currently in the possession of Warner Bros.
Plot summary.
Backstory.
At the beginning of the series, five dominant civilizations are represented. The dominant species are the Humans, Minbari, Narn, Centauri, and the Vorlons. "The Shadows" and their various allies are malevolent species who appear later in the series. Several dozen less powerful species from the League of Non-Aligned Worlds appear, including the Drazi, Brakiri, Vree, Markab, and pak'ma'ra. The station's first three predecessors (the original "Babylon" station, "Babylon 2" and "Babylon 3") were sabotaged or accidentally destroyed before their completion. The fourth station, "Babylon 4", vanished without a trace twenty-four hours after it became fully operational.
Synopsis.
The television series takes its name from the "Babylon 5" space station, located in the Epsilon Eridani star system, at the fifth Lagrangian point between the fictional planet Epsilon III and its moon. "Babylon 5" is an O'Neill cylinder five miles long and a half-mile to a mile in diameter. Living areas accommodate the various alien species, providing differing atmospheres and gravities. Human visitors to the alien sectors are shown using breathing equipment and other measures to tolerate the conditions.
The five seasons of the series each correspond to one fictional sequential year in the period 2258–2262. Each season shares its name with an episode that is central to that season's plot. As the series starts, the "Babylon 5" station is welcoming ambassadors from various races in the galaxy. Earth has just barely survived an accidental war with the much more powerful Minbari, who, despite their superior technology, mysteriously surrendered at the brink of the destruction of the human race during the Battle of the Line.
Season 1 – Year 2258.
During 2258, Commander Jeffrey Sinclair is in charge of the station. Much of the story revolves around his gradual discovery that it was his capture by the Minbari at the Battle of the Line which ended the war against Earth. Upon capturing Sinclair, the Minbari came to believe that Valen, a great Minbari leader and hero of the last Minbari-Shadow war, had been reincarnated as the Commander. Concluding that others of their species had been, and were continuing to be reborn as humans, and in obedience to the edict that Minbari do not kill one another, lest they harm the soul, they stopped the war just as Earth's final defenses were on the verge of collapse.
Meanwhile, tensions between the Centauri Republic, which is an empire in decline, and the Narn Regime, a former dominion which rebelled and gained freedom, are increasing. Ambassador G'Kar of the Narn wishes for his people to strike back at the Centauri for what they did, and Ambassador Londo Mollari of the Centauri wishes for his people to become again the great empire they once were. As part of these struggles, Mollari makes a deal with a mysterious ally to strike back at the Narn, further heightening tensions.
It is gradually revealed that Ambassador Delenn is a member of the mysterious and powerful Grey Council, the ruling body of the Minbari. Towards the end of 2258, she begins the transformation into a Minbari-human hybrid, ostensibly to build a bridge between the humans and Minbari. The year ends with the death of Earth Alliance president Luis Santiago. The death is officially ruled an accident, but some members of the military, including the staff of "Babylon 5", believe it to be an assassination.
Season 2 – Year 2259.
At the beginning of 2259, Captain John Sheridan replaces Sinclair as the military governor of the station after Sinclair is reassigned as ambassador to Minbar. He and the command staff gradually learn that the assassination of President Santiago was arranged by his then-Vice President, Morgan Clark, who has now become president. Conflict develops between the "Babylon 5" command staff and the Psi Corps, an increasingly autocratic organization which oversees and controls the lives of human telepaths.
The Shadows, an ancient and extremely powerful race who have recently emerged from hibernation, are revealed to be the cause of a variety of mysterious and disturbing events, including the attack on the Narn outpost at the end of 2258. Centauri Ambassador Londo Mollari unknowingly enlists their aid through his association with their mysterious human representative Mr. Morden in the ongoing conflict with the Narn. The elderly and ailing Centauri emperor, long an advocate of reconciliation with the Narn, unfortunately has insufficient control to prevent others from instigating war against the Narn Regime. When the emperor dies suddenly during a peace mission to "Babylon 5", a number of conspirators, including Ambassador Londo Mollari and Lord Refa, take control of the Centauri government by assassinating their opponents and placing the late emperor's unstable nephew on the throne. Their first act is to start open aggression against the Narn. After a full-scale war breaks out, the Centauri with the help of the Shadows through Londo eventually conquer Narn in a brutal attack involving mass drivers, outlawed weapons of mass destruction. Towards the end of the year, the Clark administration begins to show increasingly totalitarian characteristics, clamping down on dissent and restricting freedom of speech. The Vorlons are revealed to be the basis of legends about angels on various worlds, including Earth, and are the ancient enemies of the Shadows. They enlist the aid of Sheridan and the "Babylon 5" command staff in the struggle against the Shadows.
Season 3 – Year 2260.
The Psi Corps and President Clark, whose government has discovered Shadow vessels buried in Earth's solar system, begin to harness the vessels' advanced technology. The Clark administration continues to become increasingly xenophobic and totalitarian, and gradually develops an Orwellian government style, including an organization called Night Watch which targets citizens who hold views contrary to those of Clark's regime.
Sheridan and Delenn's "conspiracy of light" works to uncover clues about how to defeat the Shadows. During a mission near Ganymede, one of the moons of Jupiter, their ship is seen by the Earth Alliance destroyer "Agamemnon", but not recognized. Though they escape and no shots were fired in the encounter, President Clark uses it as an excuse to declare martial law. This triggers a war of independence on Mars, which had long had a strained political relationship with Earth. "Babylon 5" attempts to avoid conflict with Earth, but in response to civilian bombings on Mars, concerns with Night Watch, and illegal orders meant to oppress their populations, they choose to declare independence from Earth, along with several other outlying Earth Alliance colonies including Orion VII and Proxima III. In response, the Earth Alliance attempts to retake "Babylon 5" by force, but with the aid of the Minbari, who have allied with the station against the growing Shadow threat, the attack is repelled at great cost.
Becoming concerned over the Shadows' growing influence among his people, Centauri ambassador Londo Mollari attempts to sever ties with them. Mr. Morden, the Shadows' human representative, tricks him into restoring the partnership by engineering the murder of Mollari's mistress while putting the blame on a rival Centauri House. Open warfare breaks out between the Shadows and the alliance led by "Babylon 5" and the Minbari. It is learned that genetic manipulation by the Vorlons is the source of telepathy in humans and other races, as it is later discovered that Shadow ships are vulnerable to telepathic attacks. Displeased at the Vorlons' lack of direct action against the Shadows, Captain John Sheridan browbeats Vorlon ambassador Kosh Naranek into launching an attack against their mutual enemy. Kosh's deeds lead to his subsequent assassination by the Shadows.
Former station commander Jeffrey Sinclair returns to "Babylon 5" to enlist the aid of Captain Sheridan, Delenn, Ivanova and Marcus in stealing the "Babylon 4" space station and sending it 1,000 years back in time to use it as a base of operations against the Shadows in the previous Minbari-Shadow war. Having undergone a similar transformation to the one Delenn had at the end of Season 1, Sinclair transforms into a Minbari and is subsequently revealed to be the actual Valen of Minbari legend, rather than simply a reincarnation. Meanwhile, as a result of the unstable time travel, Sheridan sees a vision of the downfall of Centauri Prime when it is attacked by Shadow allies after the Shadow war, and he becomes determined to prevent that future.
Sheridan and Delenn begin a romantic relationship, but their lives and the war are interrupted by the sudden reappearance of Sheridan's wife, who was presumed dead after taking part in an archaeological expedition to Z'ha'dum years prior. She tells Sheridan that the Shadows are not evil, hoping to bring him back with her and recruit him to their cause. He soon realizes that her mind has been tampered with and corrupted by the Shadows, but accepts her offer to visit Z'ha'dum because he hopes it will save the galaxy sooner and prevent the downfall of Centauri Prime. He takes with him a pair of nuclear warheads, which he uses to destroy their largest city, and is last seen jumping into a miles-deep pit to escape the explosion.
Shadow vessels appear at the station, but disappear after Sheridan's attack. However, after they leave, station personnel realize that Garibaldi, who left in a fighter to defend against the vessels, never returned.
Season 4 – Year 2261.
In 2261, the Vorlons join the Shadow War, but their tactics become a concern for the alliance when the Vorlons begin destroying entire planets which they deem to have been "influenced" by the Shadows. Disturbed by this turn of events, Babylon 5 recruits several other powerful and ancient races (the First Ones) to their cause, against both the Shadows and the Vorlons. Captain John Sheridan returns to the station after escaping from Z'ha'dum and reunites the galaxy against the Shadows, but at a price: barring illness or injury, he has only 20 years left to live. He is accompanied by a mysterious alien named Lorien who claims to be the first sentient being in the galaxy, and who breathed life into Sheridan at Z'ha'dum. Once Sheridan returns, he and Delenn formalize their relationship and begin planning to marry, although most of their plans are put on hold due to the ongoing war.
Hours before Sheridan's return, Garibaldi is rescued and returned to the station, in rather dubious circumstances. Over the course of the next several months, he becomes markedly more paranoid and suspicious of other alien races and of Sheridan than he was before, causing worry among his friends and colleagues.
Centauri Emperor Cartagia forges a relationship with the Shadows. With the reluctant help of his enemy G'Kar, Londo Mollari engineers the assassination of Cartagia and repudiates his agreement with the Shadows. In exchange for G'Kar's help, Londo frees the Narn from Centauri occupation. Londo afterwards kills Mr. Morden and destroys the Shadow vessels based on the Centauri homeworld, in an attempt to save his planet from destruction by the Vorlons. (Centauri Prime was not destroyed.) Aided by the other ancient races, and several younger ones, Sheridan lures both the Vorlons and the Shadows into an immense battle, during which the Vorlons and Shadows reveal that they have been left as guardians of the younger races, but due to philosophical differences, ended up using them as pawns in their endless proxy wars throughout the ages. The younger races reject their continued interference, and the Vorlons and Shadows, along with the remaining First Ones, agree to depart the galaxy in order to allow the younger races to find their own way.
After the Shadows are defeated, Garibaldi leaves his post as security chief and works on his own as a "provider of information". He begins working for one William Edgars, a Mars tycoon, who is married to Garibaldi's former love. While he works ever closer with Edgars, he becomes increasingly aggressive toward Sheridan and eventually leaves "Babylon 5".
Minbar is gripped by a brief civil war between the Warrior and Religious castes. Delenn secretly meets with Neroon of the Warrior caste and convinces him that neither side can be allowed to win. She tells him that she will undergo a ritual wherein she will be willing to sacrifice herself, but will stop the ritual before she actually dies. When Neroon sees that she actually intends to go through the entire ritual, he rescues her and sacrifices himself instead, declaring that, although he was born Warrior caste, in his heart he is Religious caste.
As part of the ongoing conflict between Earth and Babylon 5, Garibaldi eventually betrays Sheridan and arranges his capture in order to gain Edgars' trust and learn his plans. Garibaldi later learns that Edgars had created a virus that is dangerous only to telepaths. It is then revealed that after Garibaldi was captured the previous year, he was taken to the Psi Corps and re-programmed by Bester to provide information to him at the right time. Bester releases Garibaldi of his programming, and allows him to remember everything he had done since being kidnapped. Edgars is killed by Psi Corps operatives. His wife disappears but is reunited with Garibaldi after the end of the war.
Sheridan is tortured and interrogated by those who hope to break him and turn him into a propaganda tool for Earth's totalitarian government. Fortunately, Garibaldi is able to help free Sheridan and return him to the campaign to free Earth. An alliance led by Babylon 5 frees Earth from totalitarian rule by president Clark in a short but bloody war. This culminates in Clark's suicide and the restoration of democratic government in the Earth Alliance. Mars is granted full independence, and Sheridan agrees to resign his commission. The League of Non-Aligned Worlds is dissolved and reformed into the Interstellar Alliance, with Sheridan elected as its first president and continuing his command of the Rangers, who are to act as a galactic equivalent of United Nations peacekeepers. Londo and G'Kar enter an uneasy alliance to help both their races as well as Sheridan in forming the Interstellar Alliance. During the final battle to liberate Earth from Clark's regime, Ivanova is critically injured, promised only a few days to live. Marcus, who had fallen in love with Ivanova, finds the same alien healing device used to revive Garibaldi at the beginning of the second season, and uses it to transfer almost all of his life energy into Ivanova, causing her to live. This causes her immense emotional anguish, and she chooses to leave Babylon 5 for another posting in EarthForce. Marcus is placed into indefinite cryonic suspension at her request, pending resuscitation technology.
Sheridan and Delenn complete their marriage ceremony while en route to Babylon 5, where they will head the Interstellar Alliance until the completion of Alliance's permanent headquarters.
In the season finale, the events of 100, 500, 1000, and one million years into the future are shown, depicting Babylon 5's lasting influence throughout history. Among the events shown are the political aftermath of the 2261 civil war, a subsequent nuclear war on Earth involving a new totalitarian government in 2762, the resulting fall of Earth into a pre-industrial society, the loss and restoration of humanity's knowledge of space travel, and the final evolution of mankind into energy beings similar to the Vorlons, after which Earth's sun goes nova.
Season 5 – Year 2262 and beyond.
In 2262, Earthforce Captain Elizabeth Lochley is appointed to command "Babylon 5", which is now also the headquarters of the Interstellar Alliance. The station grows in its role as a sanctuary for rogue telepaths running from the Psi Corps, resulting in conflict. G'Kar, former Narn ambassador to "Babylon 5", becomes unwillingly a spiritual icon after a book that he wrote while incarcerated during the Narn-Centauri War is published without his knowledge. The Drakh, former allies of the Shadows who remained in the galaxy, take control of Regent Virini on Centauri Prime through a parasitic creature called a Keeper, then incite a war between the Centauri and the Interstellar Alliance, in order to isolate the Centauri from the Alliance and gain a malleable homeworld for themselves.
Centauri Prime is devastated by Narn and Drazi warships and Londo Mollari becomes emperor, then ends the war. However, the Drakh blackmail him into accepting a Drakh Keeper, under threat of the complete nuclear destruction of the planet. Vir Cotto, Mollari's loyal and more moral aide, becomes ambassador to "Babylon 5" in his stead. G'Kar also leaves "Babylon 5" to escape his unwanted fame and explore the rim. Sheridan and Delenn move to a city on Minbar, where the new headquarters of the Interstellar Alliance are located, while celebrating their first year of marriage and the upcoming birth of their son, and mourning the loss of dear friendships. Garibaldi marries and settles down on Mars, where he and his wife share ownership of a prominent pharmaceutical company. Most other main characters, including Stephen Franklin and Lyta Alexander, leave "Babylon 5" as well.
As shown in flash-forwards earlier in the series, the next several years include the reign of Londo Mollari as Centauri Emperor. Sixteen years later, Londo sacrifices his life to rescue Sheridan and Delenn from the Drakh, in the hope that they in turn can save Centauri Prime. To prevent the Drakh from discovering his ruse, he asks G'Kar, now an old friend, to kill him, but Londo's Keeper wakes up and forces him to kill G'Kar in return. They die at each other's throats, in accordance with Londo's vision many decades earlier, and Vir Cotto succeeds him as emperor, free of Drakh influence.
Three years after Londo's death, Sheridan himself is on the verge of death and takes one last opportunity to gather his old friends together. Shortly after his farewell party, Sheridan says goodbye to Delenn, though in Minbari fashion they use the word "goodnight" to signify their hope of an eventual reunion. Sheridan then takes a final trip to the obsolete "Babylon 5" station before its decommissioning. He returns to the site of the final battle between the Vorlons and the Shadows and apparently dies, but is instead claimed by The First One, who invites him to join the other First Ones on a journey beyond the rim of the galaxy. "Babylon 5" station is destroyed in a demolition shortly after Sheridan's departure, its existence no longer necessary as the Alliance has taken over its diplomatic purposes and other trading routes have been established. This final episode features a cameo by Straczynski as the technician who switches off the lights before "Babylon 5" is demolished.
Themes.
Throughout its run, "Babylon 5" found ways to portray themes relevant to modern and historical social issues. It marked several firsts in television science fiction, such as the exploration of the political and social landscapes of the first human colonies, their interactions with Earth, and the underlying tensions. "Babylon 5" was also one of the first television science fiction shows to denotatively refer to a same-sex relationship. In the show, sexual orientation is as much of an issue as "being left-handed or right-handed". Unrequited love is explored as a source of pain for the characters, though not all the relationships end unhappily.
Order vs. chaos; authoritarianism vs. free will.
The clash between order and chaos, and the people caught in between, plays an important role in "Babylon 5". The conflict between two unimaginably powerful older races, the Vorlons and the Shadows, is represented as a battle between two competing ideologies, each seeking to turn the humans and the other younger races to their beliefs. The Vorlons represent an authoritarian philosophy: you will do what we tell you to, because we tell you to do it. The Vorlon question, "Who are you?" focuses on identity as a catalyst for shaping personal goals; the intention is not to solicit a "correct" answer, but to "tear down the artifices we construct around ourselves until we're left facing ourselves, not our roles." The Shadows represent another authoritarian philosophy cloaked in a disguise of evolution through fire (as shown in the episode in which Sheridan goes to Z'ha'dum and when he refuses to cooperate, Justin tells him: "But we do what we're told... and so will you!"), of sowing the seeds of conflict in order to engender progress. The question the Shadows ask is "What do you want?" In contrast to the Vorlons, they place personal desire and ambition first, using it to shape identity, encouraging conflict between groups who choose to serve their own glory or profit. The representation of order and chaos was informed by the Babylonian myth that the universe was born in the conflict between both. The climax of this conflict comes with the younger races' exposing of the Vorlons' and the Shadows' "true faces" and the rejection of both philosophies, heralding the dawn of a new age without their interference.
The notion that the war was about "killing your parents" is echoed in the portrayal of the civil war between the human colonies and Earth. Deliberately dealing in historical and political metaphor, with particular emphasis upon McCarthyism and the HUAC, the Earth Alliance becomes increasingly authoritarian, eventually sliding into a dictatorship. The show examines the impositions on civil liberties under the pretext of greater defense against outside threats which aid its rise, and the self-delusion of a populace which believes its moral superiority will never allow a dictatorship to come to power, until it is too late. The successful rebellion led by the Babylon 5 station results in the restoration of a democratic government, and true autonomy for Mars and the colonies.
War and peace.
The "Babylon 5" universe deals with numerous armed conflicts which range on an interstellar scale. The story begins in the aftermath of a war which brought the human race to the brink of extinction, caused by a misunderstanding during a first contact situation. The Babylon 5 station is subsequently built in order to foster peace through diplomacy, described as the "last, best hope for peace" in the opening credits monologue during its first three seasons. Wars between separate alien civilizations are featured. The conflict between the Narn and the Centauri is followed from its beginnings as a minor territorial dispute amplified by historical animosity, through to its end, in which weapons of mass destruction are employed to subjugate and enslave an entire planet. The war is an attempt to portray a more sobering kind of conflict than usually seen on science fiction television. Informed by the events of the first Gulf War, the Cuban Missile Crisis and the Soviet invasion of Prague, the intent was to recreate these moments when "the world held its breath" and the emotional core of the conflict was the disbelief that the situation could have occurred at all, and the desperation to find a way to bring it to an end. By the start of the third season, the opening monologue had changed to say that the hope for peace had "failed" and the Babylon 5 station had become the "last, best hope for victory", indicating that while peace is a laudable accomplishment, it can also mean a capitulation to an enemy intent on committing horrendous acts, and that "peace is a byproduct of victory against those who do not want peace."
The Shadow War also features prominently in the show, during which an advanced alien species attempts to sow the seeds of conflict in order to promote technological and cultural advancement. The gradual discovery of the scheme and the rebellion against it, serve as the backdrop to the first three seasons, but also as a metaphor for the war within ourselves. The concurrent limiting of civil liberties and Earth's descent into a dictatorship are "shadow wars" of their own. In ending the Shadow War before the conclusion of the series, the show was able to more fully explore its aftermath, and it is this "war at home" which forms the bulk of the remaining two seasons. The struggle for independence between Mars and Earth culminates with a civil war between the human colonies (led by the Babylon 5 station) and the home planet. Choosing Mars as both the spark for the civil war, and the staging ground for its dramatic conclusion, enabled the viewer to understand the conflict more fully than had it involved an anonymous colony orbiting a distant star. The conflict, and the reasons behind it, were informed by Nazism, McCarthyism and the breakup of Yugoslavia, and the unraveling of the former Balkan country also served as partial inspiration for another civil war, which involved the alien Minbari.
The post-war landscape has its roots in the Reconstruction. The attempt to resolve the issues of the American Civil War after the conflict had ended, and this struggle for survival in a changed world was also informed by works such as "Alas, Babylon", a novel dealing with the after-effects of a nuclear war on a small American town. The show expresses that the end of these wars is not an end to war itself. Events shown hundreds of years into the show's future tell of wars which will once again bring the human race to the edge of annihilation, demonstrating that mankind will not change, and the best that can be hoped for after it falls is that it climbs a little higher each time, until it can one day "take place among the stars, teaching those who follow."
Religion.
Many of Earth's contemporary religions are shown to still exist, with the main human characters often having religious convictions. Among those specifically identified are Roman Catholicism (including the Jesuits), Judaism, and the fictional Foundationism (which developed after first contact with alien races). Alien beliefs in the show range from the Centauri's Bacchanalian-influenced religions, of which there are up to seventy different denominations, to the more pantheistic as with the Narn and Minbari religions. In the show's third season, a community of Cistercian monks takes up residence on the Babylon 5 station, in order to learn what other races call God, and to come to a better understanding of the different religions through study at close quarters.
References to both human and alien religion is often subtle and brief, but can also form the main theme of an episode. The first season episode "The Parliament of Dreams" is a conventional "showcase" for religion, in which each species on the Babylon 5 station has an opportunity to demonstrate its beliefs (humanity's are presented as being numerous and varied), while "Passing Through Gethsemane" focuses on a specific position of Roman Catholic beliefs, as well as concepts of justice, vengeance, and biblical forgiveness. Other treatments have been more contentious, such as the David Gerrold-scripted "Believers", in which alien parents would rather see their son die than undergo a life-saving operation because their religious beliefs forbid it. When religion is an integral part of an episode, various characters express differing view points. Such as in "Soul Hunter", where the concept of an immortal soul is touched upon, and whether after death it is destroyed, reincarnated, or simply does not exist. The character arguing the latter, Doctor Stephen Franklin, often appears in the more spiritual storylines as his scientific rationality is used to create dramatic conflict. Undercurrents of religions such as Buddhism have been viewed by some in various episode scripts, and while identifying himself as an atheist, Straczynski believes that passages of dialog can take on distinct meanings to viewers of differing faiths, and that the show ultimately expresses ideas which cross religious boundaries.
Addiction.
Substance abuse and its impact on human personalities also plays a significant role in the "Babylon 5" storyline. The station's security chief, Michael Garibaldi, is a textbook relapsing-remitting alcoholic of the binge drinking type; he practices complete abstinence from alcohol throughout most of the series (with one notable exception) until the middle of season five. He only recovers physically and socially and breaks the cycle at the end of the season. His eventual replacement as Chief of Security, Zack Allan, was given a second chance by Garibaldi after overcoming his own addiction to an unspecified drug. Dr. Stephen Franklin develops an (initially unrecognized) addiction to injectable stimulant drugs while trying to cope with the chronic stress and work overload in Medlab, and wanders off to the homeless and deprived in Brown Sector, where he suffers through a severe withdrawal syndrome. Executive Officer Susan Ivanova mentions that her father became an alcoholic after her mother had committed suicide after having been drugged by the authorities over a number of years. Captain Elizabeth Lochley tells Garibaldi that her father was an alcoholic and that she is a recovering alcoholic herself.
Cast.
Recurring guests.
In addition, several other actors have filled more than one minor role on the series. Kim Strauss played the Drazi Ambassador in four episodes, as well as nine other characters in ten more episodes. Some actors had difficulty dealing with the application of prosthetics required to play some of the alien characters. The producers therefore used the same group of people (as many as 12) in various mid-level speaking roles, taking full head and body casts from each. The group came to be unofficially known by the production as the "Babylon 5 Alien Rep Group."
Production.
Origin.
Having worked on a number of television science fiction shows which had regularly gone over budget, creator J. Michael Straczynski concluded that a lack of long-term planning was to blame, and set about looking at ways in which a series could be done responsibly. Taking note of the lessons of mainstream television, which brought stories to a centralized location such as a hospital, police station, or law office, he decided that instead of " in search of new worlds, building them anew each week", a fixed space station setting would keep costs at a reasonable level. A fan of sagas such as the "Foundation" series, "Childhood's End", "The Lord of the Rings", "Dune" and the "Lensman" series, Straczynski wondered why no one had done a television series with the same epic sweep, and concurrently with the first idea started developing the concept for a vastly ambitious epic covering massive battles and other universe-changing events. Realizing that both the fixed-locale series and the epic could be done in a single series, he began to sketch the initial outline of what would become "Babylon 5".
Straczynski set five goals for "Babylon 5". He said that the show "would have to be good science fiction" as well as good television – "rarely are shows both good fiction "and" good TV; there're generally one or the other in original." It would have to do for science fiction television what "Hill Street Blues" had done for police dramas, by taking an adult approach to the subject. It would have to be reasonably budgeted, and "it would have to look unlike anything ever seen before on TV, presenting individual stories against a much broader canvas." He further stressed that his approach was "to take fiction seriously, to build characters for grown-ups, to incorporate real science but keep the characters at the center of the story." Some of the staples of television science fiction were also out of the question (the show would have "no kids or cute robots"). The idea was not to present a perfect utopian future, but one with greed and homelessness; one where characters grow, develop, live, and die; one where not everything was the same at the end of the day's events. Citing Mark Twain as an influence, Straczynski said he wanted the show to be a mirror to the real world and to covertly teach.
Format.
Described as a "window on the future" by series production designer John Iacovelli, the story is set in the 23rd century on a large O'Neill Colony named "Babylon 5"—a five-mile-long, 2.5 million-ton rotating colony designed as a gathering place for the sentient species of the galaxy, in order to foster peace through diplomacy, trade, and cooperation. Instead, acting as a center of political intrigue and conflict, the station becomes the linchpin of a massive interstellar war. This is reflected in the opening monologue of each episode, which describes it as the "last, best hope for peace" in season one, then the "last, best hope for victory" in season three.
The series consists of a coherent five-year story arc taking place over five seasons of 22 episodes each. Unlike most television shows at the time, "Babylon 5" was conceived as a "novel for television", with a defined beginning, middle, and end; in essence, each episode would be a single "chapter" of this "novel". Many of the tie-in novels, comic books, and short stories were also developed to play a significant canonical part in the overall story.
The cost of the series totalled an estimated $90 million for 110 episodes.
Writing.
Creator and showrunner J. Michael Straczynski wrote 92 of the 110 episodes of "Babylon 5", including all 44 episodes in the third and fourth seasons; according to Straczynski, a feat never before accomplished in American television. Other writers to have contributed scripts to the show include Peter David, Neil Gaiman, Kathryn M. Drennan, Lawrence G. DiTillio, D. C. Fontana, and David Gerrold. Harlan Ellison, a creative consultant on the show, received story credits for two episodes. Each writer was informed of the overarching storyline, enabling the show to be produced consistently under-budget. The rules of production were strict; scripts were written six episodes in advance, and changes could not be made once production had started.
Though conceived as a whole, it was necessary to adjust the plotline to accommodate external influences. Each of the characters in the series was written with a "trap door" into their background so that, in the event of an actor's unexpected departure from the series, the character could be written out with minimal impact on the storyline. In the words of Straczynski, "As a writer, doing a long-term story, it'd be dangerous and short-sighted for me to construct the story without trap doors for every single character. ... That was one of the big risks going into a long-term storyline which I considered long in advance;..." The character of Talia Winters was to have undergone a transformation into a Psi Corps secret agent, having been revealed as a "sleeper", whose true personality was buried subconsciously, and who acted as a spy, observing the events on the station and the actions of her command staff. When Winters's portrayer Andrea Thompson left the series, this revelation was used to drop the character from the series.
Ratings for "Babylon 5" continued to rise during the show's third season, but going into the fourth season, the impending demise of network PTEN left a fifth year in doubt. Unable to get word one way or the other from parent company Warner Bros., and unwilling to short-change the story and the fans, Straczynski began preparing modifications to the fourth season in order to allow for both eventualities. Straczynski identified three primary narrative threads which would require resolution: the Shadow war, Earth's slide into a dictatorship, and a series of sub-threads which branched off from those. Estimating they would still take around 27 episodes to resolve without having the season feel rushed, the solution came when the TNT network commissioned two "Babylon 5" television films. Several hours of material was thus able to be moved into the films, including a three-episode arc which would deal with the background to the Earth–Minbari War, and a sub-thread which would have set up the sequel series, "Crusade". Further standalone episodes and plot-threads were dropped from season four, which could be inserted into "Crusade", or the fifth season, were it to be given the greenlight. The intended series finale, "Sleeping in Light", was filmed during season four as a precaution against cancellation. When word came that TNT had picked up "Babylon 5", this was moved to the end of season five and replaced with a newly filmed season four finale, "The Deconstruction of Falling Stars".
Costume.
Ann Bruice Aling was costume designer for the show, after production designer John Iacovelli suggested her for the position having previously worked with Bruice on a number of film and theatrical productions.
With the variety of costumes required she compared "Babylon 5" to "eclectic theatre", with fewer rules about period, line, shape and textures having to be adhered to. Preferring natural materials whenever possible, such as ostrich leather in the Narn body armor, Bruice combined and layered fabrics as diverse as rayon and silk with brocades from the 1930s and '40s to give the clothing the appearance of having evolved within different cultures.
With an interest in costume history, she initially worked closely with J. Michael Straczinski to get a sense of the historical perspective of the major alien races, "so I knew if they were a peaceful people or a warring people, cold climate etc. and then I would interpret what kind of sensibility that called for." Collaborating with other departments to establish co-ordinated visual themes for each race, a broad palette of colors was developed with Iacovelli, which he referred to as "spicy brights". These warm shades of grey and secondary colors, such as certain blues for the Minbari, would often be included when designing both the costumes and relevant sets. As the main characters evolved, Bruice referred back to Straczynski and producer John Copeland who she viewed as "surprisingly more accessible to me as advisors than other producers and directors", so the costumes could reflect these changes. Ambassador Londo Mollari's purple coat became dark blue and more tailored while his waistcoats became less patterned and brightly colored as Bruice felt "Londo has evolved in my mind from a buffoonish character to one who has become more serious and darker."
Normally there were three changes of costume for the primary actors; one for on set, one for the stunt double and one on standby in case of "coffee spills". For human civilians, garments were generally purchased off-the-rack and altered in various ways, such as removing lapels from jackets and shirts while rearranging closures, to suggest future fashions. For some of the main female characters a more couture approach was taken, as in the suits worn by Talia Winters which Bruice described as being designed and fitted to within "an inch of their life". Costumes for the destitute residents of downbelow would be distressed through a combination of bleaching, sanding, dipping in dye baths and having stage blood added.
Like many of the crew on the show, members of the costume department made onscreen cameos. During the season 4 episode "Atonement", the tailors and costume supervisor appeared as the Minbari women fitting Zack Allan for his new uniform as the recently promoted head of security. His complaints, and the subsequent stabbing of him with a needle by costume supervisor Kim Holly, was a light hearted reference to the previous security uniforms, a design carried over from the pilot movie which were difficult to work with and wear due to the combination of leather and wool.
Prosthetic makeup and animatronics.
While the original pilot film featured some aliens which were puppets and animatronics, the decision was made early on in the show's production to portray most alien species as humanoid in appearance. Barring isolated appearances, fully computer-generated aliens were discounted as an idea due to the "massive rendering power" required. Long-term use of puppets and animatronics was also discounted due to the technological limitations in providing convincing interaction with the human actors ("...if you want any real "emotion" from the character, you're going to have to have an actor inside" ).
Visuals.
In anticipation of future HDTV broadcasts and Laserdisc releases, rather than the usual format, the series was shot in , with the image cropped to 4:3 for initial television transmissions. "Babylon 5" also distinguished itself at a time when models and miniature were still standard by becoming one of the first television shows to use computer technology in creating visual effects. This was achieved using Amiga-based Video Toasters at first, and later Pentium, Macs, and Alpha-based systems. It also attempted to respect Newtonian physics in its effects sequences, with particular emphasis on the effects of inertia.
Foundation Imaging provided the special effects for the pilot film (for which it won an Emmy) and the first three seasons of the show, led by Ron Thornton. After the show's co-executive producer (Douglas Netter) and producer (John Copeland) approached Straczynski with the idea of producing the effects in-house, Straczynski agreed to replace Foundation, for season 4 and 5, once a new team had been established by Netter Digital, and an equal level of quality was assured, by using similar technology and a number of former Foundation employees. The Emmy-winning alien make-up was provided by Optic Nerve Studios.
Music and scoring.
Christopher Franke composed and scored the musical soundtrack for all 5 years of the show when Stewart Copeland, who worked on the original telefilm, was unable to return for the first season due to recording and touring commitments. Given creative freedom by the producers, Franke also orchestrated and mixed all the music which one reviewer described as having "added another dimension of mystery, suspense, and excitement to the show, with an easily distinguishable character that separates "Babylon 5" from other sci-fi television entries of the era."
With his recording studio in the same building as his home located in the Hollywood Hills, Franke would attend creative meetings before scoring the on average 25 minutes of music for each episode. Utilising Cubase software through an electronic keyboard, or for more complex pieces a light pen and graphics tablet, he would begin by developing the melodic content round which the ambient components and transitions were added. Using playbacks with digital samples of the appropriate instruments, such as a group of violins, he would decide which tracks to produce electronically or record acoustically.
Utilizing the "acoustic dirt produced by live instruments and the ability to play so well between two semitones" and the "frequency range, dynamics and control" provided by synthesizers, he described his approach "as experimental friendly as possible without leaving the happy marriage between the orchestral and electronic sounds". While highlighting "Babylon 5" was produced on a "veritable shoestring", and as such would have been unable to afford a full orchestral score every week, at least one reviewer felt that the soundtrack would have benefitted from a greater use of the Berlin Symphonic Film Orchestra, which Franke established in 1991.
Scores for the acoustic tracks were emailed to his Berlin scoring stage, and would require from four musicians to the full orchestra, with a maximum of 24 present at any one time. One of three conductors would also be required for any score that involved more than 6 musicians. Franke would direct recording sessions via six fibre optic digital telephone lines to transmit and receive video, music and the SMPTE timecode. The final edit and mixing of the tracks would take place in his Los Angeles studio. Initially concerned composing for an episodic television show could become "annoying because of the repetition", Franke found the evolving characters and story of "Babylon 5" afforded him the opportunity to continually "push the envelope".
A total of 24 episode and three television film soundtracks were released under Franke's record label, Sonic Images Records, between 1995 and 2001. These contain the musical scores in the same chronological order as they played in the corresponding episodes, or television films. Three compilation albums were also produced, containing extensively re-orchestrated and remixed musical passages taken from throughout the series to create more elaborate suites. In 2007 his soundtrack for was released under the Varèse Sarabande record label.
Space metal opera Docker's Guild covered a special version of "The White Light/Echoes From The Past/Dying Station/Delenn's Sunrise" (from Babylon 5’s final episode “Sleeping in Light”) on their second album The Heisenberg Diaries - Book A: Sounds of Future Past (2016).
"Star Trek: Deep Space Nine" controversy.
The pilot episode of "" ("DS9") aired just weeks before "Babylon 5" debuted. "Babylon 5" creator J. Michael Straczynski indicated that Paramount Television was aware of his concept as early as 1989, when he attempted to sell the show to the studio, and provided them with the series bible, pilot script, artwork, lengthy character background histories, and plot synopses for 22 "or so planned episodes taken from the overall course of the planned series".
Paramount declined to produce "Babylon 5", but later announced "Deep Space Nine" was in development, two months after Warner Bros. announced its plans for "Babylon 5". Straczynski has stated on numerous occasions that, even though he is confident that "Deep Space Nine" producer/creators Rick Berman and Michael Piller did not see this material, he thinks Paramount may have used his bible and scripts to steer development of "Deep Space Nine". 
"Babylon 5"'s first-run syndicated ratings averaged between 3 and 4% of US households from 1995 to 1997, whereas "DS9" ranged from 4 to 5% during the same time span.
Use of the Internet.
The show employed Internet marketing to create a buzz among online readers far in advance of the airing of the pilot episode, with Straczynski participating in online communities on USENET (in the rec.arts.sf.tv.babylon5.moderated newsgroup), and the GEnie and CompuServe systems before the Web came together as it exists today. The station's location, in "grid epsilon" at coordinates of 470/18/22, was a reference to GEnie ("grid epsilon" = "GE") and the original forum's address on the system's bulletin boards (page 470, category 18, topic 22). Also during this time, Warner Bros. executive Jim Moloshok created and distributed electronic trading cards to help advertise the series. In 1995, Warner Bros. started the Official "Babylon 5" Website on the now defunct Pathfinder portal. In September 1995, they hired a fan to take over the site and move it to its own domain name, and to oversee the "Keyword B5" area on America Online.
Broadcast history.
The pilot film, "", premiered on February 22, 1993, and the regular series initially aired from January 26, 1994 through November 25, 1998, first on the short-lived Prime Time Entertainment Network, then on cable network TNT. The show aired every week in the United Kingdom on Channel 4 without a break; as a result the last four or five episodes of the early seasons were shown in the UK before the US. The pilot film debuted in the United States with strong viewing figures, achieving a 9.7 in the Nielsen national syndication rankings. The series proper debuted with a 6.8 rating/10 share. Figures dipped in its second week, and while it posted a solid 5.0 rating/8 share, with an increase in several major markets, ratings for the first season continued to fall, to a low of 3.4 during reruns, and then increasing again when new episodes were broadcast in July.
Ratings continued to remain low-to-middling throughout the first four seasons, but "Babylon 5" scored well with the demographics required to attract the leading national sponsors and saved up to $300,000 per episode by shooting off the studio lot, therefore remaining profitable for the network. The fifth season, shown on cable network TNT, had ratings about 1.0% lower than seasons two through four.
In the United Kingdom, "Babylon 5" was one of the better-rated US television shows on Channel 4, and achieved high audience Appreciation Indexes, with season 4's "Endgame" achieving the rare feat of beating the prime-time soap operas for first position.
On November 25, 1998, after five seasons and 109 aired episodes, "Babylon 5" successfully completed its five-year story arc when TNT aired the 110th (epilogue) episode "Sleeping in Light".
Awards.
Awards presented to "Babylon 5" include:
Nominated Awards include:
Babylon 5 media franchise.
In November 1994, DC began publishing monthly "Babylon 5" comics. A number of short stories and novels were also produced between 1995 and 2001. Additional books were published by the gaming companies Chameleon Eclectic and Mongoose Publishing, to support their desk-top strategy and role-playing games.
Three telefilms were released by Turner Network Television (TNT) in 1998, after funding a fifth season of "Babylon 5", following the demise of the Prime Time Entertainment Network the previous year. In addition to ', ', and ', they released a re-edited special edition of the original 1993 telefilm, '. In 1999, a fifth telefilm was also produced, "", which acted as a pilot movie for the spin-off series "Crusade", which TNT cancelled after 13 episodes had been filmed.
Dell Publishing started publication of a series of "Babylon 5" novels in 1995, which were ostensibly considered canon within the TV series' continuity, nominally supervised by creator J. Michael Straczynski, with later novels in the line being more directly based upon Straczynski's own notes and story outlines. In 1997, Del Rey obtained the publication license from Warner Bros., and proceeded to release a number of original trilogies directly scenarized by Straczynski, as well as novelizations of three of the TNT telefilms ("In the Beginning, Thirdspace", and "A Call to Arms"). All of the Del Rey novels are considered completely canonical within the filmic "Babylon 5" universe.
In 2000, the Sci-Fi Channel purchased the rights to rerun the "Babylon 5" series, and premiered a new telefilm, ' in 2002, which failed to be picked up as a series. In 2007, the first in a planned anthology of straight-to-DVD short stories entitled, ', was released by Warner Home Video, but no others were produced, due to funding issues.
At the 2014 San Diego Comic Con, Straczynski announced that a Babylon 5 movie is planned to go into production in 2016. It is to be a reboot of the story, but potentially one using old cast members in different roles. Studio JMS would produce it on a budget of $80–100 million if Warner Bros. do not take up the offer.
Home video releases.
In July 1995, Warner Home Video began distributing "Babylon 5" VHS video tapes under its Beyond Vision label in the UK. Beginning with the original telefilm, "", these were PAL tapes, showing video in the same 4:3 aspect ratio as the initial television broadcasts. By the release of Season 2, tapes included closed captioning of dialogue and Dolby Surround sound. Columbia House began distributing NTSC tapes, via mail order in 1997, followed by repackaged collector's editions and three-tape boxed sets in 1999, by which time the original pilot telefilm had been replaced by the re-edited TNT special edition. Additional movie and complete season boxed-sets were also released by Warner Bros. until 2000.
Image Entertainment released "Babylon 5" laserdiscs between December 1998 and September 1999. Produced on double-sided 12-inch Pioneer discs, each contained two episodes displayed in the 4:3 broadcast aspect-ratio, with Dolby Surround audio and closed captioning for the dialogue. Starting with two TNT telefilms, "" and the re-edited special edition of "The Gathering", Seasons 1 and 5 were released simultaneously over a six-month period. Seasons 2 and 4 followed, but with the decision to halt production due to a drop in sales, precipitated by rumors of a pending DVD release, only the first twelve episodes of Season 2 and the first six episodes of Season 4 were ultimately released.
In November 2001, Warner Home Video began distributing "Babylon 5" DVDs with a two-movie set containing the re-edited TNT special edition of "The Gathering" and "In The Beginning". The telefilms were later individually released in region 2 in April 2002, though some markets received the original version of "The Gathering" in identical packaging.
DVD boxed sets of the individual seasons, each containing six discs, began being released in October 2002. Each included a printed booklet containing episode summaries, with each disc containing audio options for German, French, and English, plus subtitles in a wider range of languages, including Arabic and Dutch. Video was displayed in anamorphic widescreen with Dolby Digital 5.1 sound. Disc 1 of each set contained an introduction to the season by J. Michael Straczynski, while disc 6 included featurettes containing interviews with various production staff, as well as information on the fictional universe, and a gag reel. Three episodes in each season also contained commentary from either Straczynski, members of the main cast, and/or the episode director.
Since its initial release, a number of repackaged DVD boxed sets have been produced for various regional markets. With slightly altered cover art, they included no additional content, but the discs were more securely stored in slimline cases, rather than the early "book" format, with hard plastic pages used during the original release of the first three seasons.
Other releases.
Seasons 1 and 2, and parts of Season 3, of "Babylon 5" have been released as advertisement-supported downloads through the In2TV and Hulu download services. Additionally, every episode from Seasons 1 to 5, as well as the pilot film "", are available for purchase on the Xbox Live Marketplace in the United States. All five seasons, and five of the movies ("In The Beginning", "Thirdspace", "River of Souls", "A Call To Arms", "Legend of the Rangers") are currently available through iTunes.
Mastering problems.
While the series was in pre-production, studios were looking at ways for their existing shows to make the transition from the then-standard to the widescreen formats that would accompany the next generation of televisions. After visiting Warner Bros., who were stretching the horizontal interval for an episode of "", producer John Copeland convinced them to allow "Babylon 5" to be shot on Super 35mm film stock. "The idea being that we would telecine to 4:3 for the original broadcast of the series. But what it also gave us was a negative that had been shot for the new 16×9 widescreen-format televisions that we knew were on the horizon."
Though the CGI scenes, and those containing live action combined with digital elements, could have been created in a suitable widescreen format, a cost-saving decision was taken to produce them in the 4:3 aspect ratio. The intention was to then crop the top and bottom of the images, and upscale the resolution for any future widescreen release or broadcast. In 2000, when the show was transferred to widescreen for airing on the Sci-Fi Channel prior to its eventual DVD release, the plan was not followed, as John Copeland recalls: "They did another video hack, and simply used a digital post production device like a DVE (Digital Video Effects) to blow the material up. They essentially stretched it approximately 1/3 to fill the larger aspect ratio."
The scenes containing live action ready to be composited with matte paintings, CGI animation, etc., were delivered on tape already telecined to the 4:3 aspect-ratio, and contained a high level of grain, which resulted in further image noise being present when enlarged and stretched for widescreen. For the purely live-action scenes, rather than using the film negatives, "Warners had even forgotten that they had those. They used PAL versions and converted them to NTSC for the US market. They actually didn't go back and retransfer the shows."
With the resulting aliasing, and the progressive scan transfer of the video to DVD, this has created a number of visual flaws throughout the widescreen release. In particular, quality has been noted to drop significantly in composite shots.

</doc>
<doc id="4801" url="https://en.wikipedia.org/wiki?curid=4801" title="BeOS">
BeOS

BeOS is an operating system for personal computers first developed by Be Inc. in 1991. It was first written to run on BeBox hardware. BeOS was built for digital media work and was written to take advantage of modern hardware facilities such as symmetric multiprocessing by utilizing modular I/O bandwidth, pervasive multithreading, preemptive multitasking and a 64-bit journaling file system known as BFS. The BeOS GUI was developed on the principles of clarity and a clean, uncluttered design.
BeOS was positioned as a multimedia platform which could be used by a substantial population of desktop users and a competitor to Mac OS and Microsoft Windows. However, it was ultimately unable to achieve a significant market share and proved commercially unviable for Be Inc. The company was acquired by Palm Inc. and today BeOS is mainly used and developed by a small population of enthusiasts.
The open-source OS Haiku, a complete reimplementation of BeOS, is designed to start up where BeOS left off. Alpha 4 of Haiku was released in November 2012.
Design.
BeOS was optimized for digital media work and was written to take advantage of modern computer hardware facilities such as symmetric multiprocessing by utilizing modular I/O bandwidth, pervasive multithreading, preemptive multitasking and a 64-bit journaling file system known as BFS. The BeOS GUI was developed on the principles of clarity and a clean, uncluttered design.
The API was written in C++ for ease of programming. It has partial POSIX compatibility and access to a command-line interface through Bash, although internally it is not a Unix-derived operating system.
BeOS used Unicode as the default encoding in the GUI, though support for input methods such as bidirectional text input was never realized.
History.
Initially designed to run on AT&T Hobbit-based hardware, BeOS was later modified to run on PowerPC-based processors: first Be's own systems, later Apple Inc.'s PowerPC Reference Platform and Common Hardware Reference Platform, with the hope that Apple would purchase or license BeOS as a replacement for its aging Mac OS. Apple CEO Gil Amelio started negotiations to buy Be Inc., but negotiations stalled when Be CEO Jean-Louis Gassée wanted $300 million; Apple was unwilling to offer any more than $125 million. Apple's board of directors decided NeXTSTEP was a better choice and purchased NeXT in 1996 for $429 million, bringing back Apple co-founder Steve Jobs.
In 1997, Power Computing began bundling BeOS (on a CD for optional installation) with its line of PowerPC-based Macintosh clones. These systems could dual boot either the Mac OS or BeOS, with a start-up screen offering the choice.
Due to Apple's moves and the mounting debt of Be Inc., BeOS was soon ported to the Intel x86 platform with its R3 release in March 1998. Through the late 1990s, BeOS managed to create a niche of followers, but the company failed to remain viable. Be Inc. also released a stripped-down, but free, copy of BeOS R5 known as BeOS Personal Edition (BeOS PE). BeOS PE could be started from within Microsoft Windows or Linux, and was intended to nurture consumer interest in its product and give developers something to tinker with. Be Inc. also released a stripped-down version of BeOS for Internet Appliances (BeIA), which soon became the company's business focus in place of BeOS.
In 2001 Be's copyrights were sold to Palm, Inc. for some $11 million. BeOS R5 is considered the last official version, but BeOS R5.1 "Dano", which was under development before Be's sale to Palm and included the BeOS Networking Environment (BONE) networking stack, was leaked to the public shortly after the company's demise.
In 2002, Be Inc. sued Microsoft claiming that Hitachi had been dissuaded from selling PCs loaded with BeOS, and that Compaq had been pressured not to market an Internet appliance in partnership with Be. Be also claimed that Microsoft acted to artificially depress Be Inc.'s initial public offering (IPO). The case was eventually settled out of court for $23.25 million with no admission of liability on Microsoft's part.
After the split from Palm, PalmSource used parts of BeOS's multimedia framework for its failed Palm OS Cobalt product. With the takeover of PalmSource, the BeOS rights now belong to Access Co.
Continuation and clones.
In the years that followed the demise of Be Inc. a handful of projects formed to recreate BeOS or key elements of the OS with the eventual goal of then continuing where Be Inc. left off. This was facilitated by the fact that Be Inc. released some components of BeOS under a free licence. Here is a list of these projects:
Zeta was a commercially available operating system based on the BeOS R5.1 codebase. Originally developed by yellowTAB, the operating system was then distributed by magnussoft. During development by yellowTAB, the company received criticism from the BeOS community for refusing to discuss its legal position with regard to the BeOS codebase (perhaps for contractual reasons). Access Co. (which bought PalmSource, until then the holder of the intellectual property associated with BeOS) has since declared that yellowTAB had no right to distribute a modified version of BeOS, and magnussoft has ceased distribution of the operating system.
Products using BeOS.
BeOS (and now Zeta) continue to be used in media appliances such as the Edirol DV-7 video editors from Roland corporation which run on top of a modified BeOS and the TuneTracker radio automation software that used to run it on BeOS and Zeta, and it was also sold as a "Station-in-a-Box" with the Zeta operating system included. Nowadays TuneTracker has switched to Haiku.
The Tascam SX-1 digital audio recorder runs a heavily modified version of BeOS that will only launch the recording interface software.
iZ Technology sells the RADAR 24 and RADAR V, hard disk-based, 24-track professional audio recorders based on BeOS 5, although the newer RADAR 6 is not based on BeOS.
Magicbox, a manufacturer of signage and broadcast display machines, uses BeOS to power their Aavelin product line.
Final Scratch, a 12″ vinyl timecode record-driven DJ software/hardware system, was first developed on BeOS. The "ProFS" version was sold to a few dozen DJs prior to the 1.0 release, which ran on a Linux virtual partition.

</doc>
<doc id="4802" url="https://en.wikipedia.org/wiki?curid=4802" title="Biome">
Biome

A biome is a formation of plants and animals that have common characteristics due to similar climates and can be found over a range of continents. Biomes are distinct from habitats, because any biome can comprise a variety of habitats.
A biome contrasts with a microbiome. A microbiome is also a mix of organisms that coexist in a defined space, but on a much smaller scale. For example, the human microbiome is the collection of bacteria, viruses, and other microorganisms that are present on a human. 
Classification.
Biomes are defined by climate regimes and biogeography.
A 1978 study on North American grasslands found a positive logistic correlation between evapotranspiration in mm/yr and above-ground net primary production in g/m2/yr. The general results from the study were that precipitation and water use led to above-ground primary production, while solar irradiation and temperature lead to below-ground primary production (roots), and temperature and water lead to cool and warm season growth habit. These findings help explain the categories used in Holdridge’s bioclassification scheme (see below), which were then later simplified by Whittaker. The number of classification schemes and the variety of determinants used in those schemes, however, should be taken as strong indicators that biomes do not fit perfectly into the classification schemes created.
Holdridge.
Holdridge classified climates based on the biological effects of temperature and rainfall on vegetation under the assumption that these two abiotic factors are the largest determinants of the types of vegetation found in a habitat. Holdridge uses the four axes to define 30 so-called "humidity provinces", which are clearly visible in his diagram. While this scheme largely ignores soil and sun exposure, Holdridge acknowledged that these were important.
Whittaker's biome-type classification scheme.
Whittaker classified biomes using two abiotic factors: precipitation and temperature. His scheme can be seen as a simplification of Holdridge's; more readily accessible, but missing Holdridge's greater specificity.
Whittaker based his approach on theoretical assertions and empirical sampling. He was in a unique position to make such a holistic assertion because he had previously compiled a review of biome classifications.
Key definitions for understanding Whittaker's scheme.
Whittaker's distinction between biome and formation can be simplified: formation is used when applied to plant communities only, while biome is used when concerned with both plants and animals. Whittaker's convention of biome-type or formation-type is simply a broader method to categorize similar communities. 
Whittaker's parameters for classifying biome-types.
Whittaker, seeing the need for a simpler way to express the relationship of community structure to the environment, used what he called "gradient analysis" of ecocline patterns to relate communities to climate on a worldwide scale. Whittaker considered four main ecoclines in the terrestrial realm.
Along these gradients, Whittaker noted several trends that allowed him to qualitatively establish biome-types:
Whittaker summed the effects of gradients (3) and (4) to get an overall temperature gradient, and combined this with gradient (2), the moisture gradient, to express the above conclusions in what is known as the Whittaker classification scheme. The scheme graphs average annual precipitation (x-axis) versus average annual temperature (y-axis) to classify biome-types.
Walter system.
The eponymously-named Heinrich Walter classification scheme considers the seasonality of temperature and precipitation. The system, also assessing precipitation and temperature, finds nine major biome types, with the important climate traits and vegetation types. The boundaries of each biome correlate to the conditions of moisture and cold stress that are strong determinants of plant form, and therefore the vegetation that defines the region. Extreme conditions, such as flooding in a swamp, can create different kinds of communities within the same biome.
Bailey system.
Robert G. Bailey nearly developed a biogeographical classification system for the United States in a map published in 1976. He subsequently expanded the system to include the rest of North America in 1981, and the world in 1989. The Bailey system, based on climate, is divided into seven domains (polar, humid temperate, dry, humid, and humid tropical), with further divisions based on other climate characteristics (subarctic, warm temperate, hot temperate, and subtropical; marine and continental; lowland and mountain).
WWF system.
A team of biologists convened by the World Wildlife Fund (WWF) developed an ecological land classification system that identified fourteen biomes, called major habitat types, and further divided the world's land area into 882 terrestrial ecoregions (includes new Antarctic ecoregions by Terrauds et al. 2012). Each terrestrial ecoregion has a specific EcoID, format XXnnNN (XX is the ecozone, nn is the biome number, NN is the individual number). This classification is used to define the Global 200 list of ecoregions identified by the WWF as priorities for conservation. The WWF major habitat types are:
Freshwater biomes.
According to the WWF, the following are classified as freshwater biomes:
Marine biomes.
Marine biomes (H) (major habitat types), Global 200 (WWF).
Biomes of the coastal and continental shelf areas (neritic zone – List of ecoregions (WWF))
Summary – ecological taxonomy (WWF).
Example
Anthropogenic biomes.
Humans have altered global patterns of biodiversity and ecosystem processes. As a result, vegetation forms predicted by conventional biome systems can no longer be observed across much of Earth's land surface as they have been replaced by crop and rangelands or cities. Anthropogenic biomes provide an alternative view of the terrestrial biosphere based on global patterns of sustained direct human interaction with ecosystems, including agriculture, human settlements, urbanization, forestry and other uses of land. Anthropogenic biomes offer a new way forward in ecology and conservation by recognizing the irreversible coupling of human and ecological systems at global scales and moving us toward an understanding of how best to live in and manage our biosphere and the anthropogenic biomes we live in.
Dermal biome.
The dermal biome is the living ecosystem that animals (including humans) have evolved, that permits them to live symbiotically and in balance with the microbes on and in them (the microbiome). This ecosystem consists of skin, follicles, hair, sebaceous glands, sweat glands, arrector pili muscles, peptides, proteins, lipids and its associated microbiota.
A healthy dermal biome has several functions: it resists infection of pathogens, protects against moisture loss and water damage, dynamically regulates body temperature and supports the healthy renewal of skin through the epidermal cell life cycle.
Other biomes.
The endolithic biome, consisting entirely of microscopic life in rock pores and cracks, kilometers beneath the surface, has only recently been discovered, and does not fit well into most classification schemes.
Freshwater biomes.
The drainage basins of the principal oceans and seas of the world are marked by continental divides. The grey areas are endorheic basins that do not drain to the ocean.

</doc>
<doc id="4805" url="https://en.wikipedia.org/wiki?curid=4805" title="Behavior">
Behavior

Behavior (see spelling differences) is the range of actions and mannerisms made by individuals, organisms, systems, or artificial entities in conjunction with themselves or their environment, which includes the other systems or organisms around as well as the (inanimate) physical environment. It is the response of the system or organism to various stimuli or inputs, whether internal or external, conscious or subconscious, overt or covert, and voluntary or involuntary.
Taking a behavior informatics perspective, a behavior consists of behavior actor, operation, interactions, and their properties. A behavior can be represented as a behavior vector.
Health.
Health behavior refers to a person's beliefs and actions regarding their health and well-being. Health behaviors are direct factors in maintaining a healthy lifestyle. Health behaviors are influenced by the social, cultural and physical environments in which we live and work. They are shaped by individual choices and external constraints. Positive behaviors help promote health and prevent disease, while the opposite is true for risk behaviors. Health behaviors are early indicators of population health. Because of the time lag that often occurs between certain behaviors and the development of disease, these indicators may foreshadow the future burdens and benefits of health-risk and health-promoting behaviors. Health behaviors do not occur in isolation—they are influenced and constrained by social and cultural norms.
Correlates.
A variety of studies have examined the relationship between health behaviors and health outcomes (e.g., Blaxter 1990) and have demonstrated their role in both morbidity and mortality.
Theses studies have identified seven features of lifestyle which were associated with lower morbidity and higher subsequent long-term survival (Belloc and Breslow 1972):
Health behaviors impact upon individuals' quality of life, by delaying the onset of chronic disease and extending active lifespan. Smoking, alcohol consumption, diet, gaps in primary care services and low screening uptake are all significant determinants of poor health, and changing such behaviors should lead to improved health.
For example, In USA, Healthy People 2000, United States Department of Health and Human Services (USDHHS) lists increased physical activity, changes in nutrition and reductions in tobacco, alcohol and drug use as important for health promotion and disease prevention.
Treatment approach.
Any interventions done are matched with the needs of each individual in an ethical and respected manner. HBM encourages increasing individuals' perceived susceptibility to negative health outcomes and making individuals aware of the severity of such negative health behavior outcomes. E.g. through health promotion messages. In addition, the HBM suggests the need to focus on the benefits of health behaviors and the fact that barriers to action are easily overcome. TPB suggests using persuasive messages for tackling behavioral beliefs to increase the more response towards the issue ("intentions"). TPB advocates the need to tackle normative beliefs and control beliefs in any attempt to change behavior. Challenging the normative beliefs isn't enough but to follow through the "intention" with self efficacy from individual's mastery in problem solving and task completion is important to bring about a positive change. Self efficacy is often cemented through standard persuasive techniques.
Models.
Biology.
Although there is some disagreement as to how to precisely define behavior in a biological context, one common interpretation based on a meta-analysis of scientific literature states that "behavior is the internally coordinated responses (actions or inactions) of whole living organisms (individuals or groups) to internal and/or external stimuli"
A broader definition of behavior, applicable to plants and other organisms, is similar to the concept of phenotypic plasticity. It describes behavior as a response to an event or environment change during the course of the lifetime of an individual, differing from other physiological or biochemical changes that occurs much rapidly, and excluding changes that are result of development (ontogeny).
Behaviors can be either innate or learned.
Behavior can be regarded as any action of an organism that changes its relationship to its environment. Behavior provides outputs from the organism to the environment.
Human behavior.
Human behavior is believed to be influenced by the endocrine system and the nervous system. It is most commonly believed that complexity in the behavior of an organism is correlated to the complexity of its nervous system. Generally, organisms with more complex nervous systems have a greater capacity to learn new responses and thus adjust their behavior.
Consumer Behaviour.
Consumer Behaviour
Consumer behaviour refers to the processes consumers go through, and reactions they have towards products or services (Dowhan, 2013). It is to do with consumption, and the processes consumers go through around purchasing and consuming goods and services (Szwacka-Mokrzycka, 2015). Consumers recognise needs or wants, and go through a process to satisfy these needs. Consumer behaviour is the process they go through as customers, which includes types of products purchased, amount spent, frequency of purchases and what influences them to make the purchase decision or not. There is a lot that influences consumer behaviour, with contributions from both internal and external factors (Szwacka-Mokrzycka, 2015). Internal factors include attitudes, needs, motives, preferences and perceptual processes, whilst external factors include marketing activities, social and economic factors, and cultural aspects (Szwacka-Mokrzycka, 2015). Doctor Lars Perner of the University of Southern California claims that there are also physical factors that influence consumer behaviour, for example if a consumer is hungry, then this physical feeling of hunger will influence them so that they go and purchase a sandwich to satisfy the hunger (Perner, 2008).
Consumer Decision Making
There is a model described by Lars Perner which illustrates the decision making process with regards to consumer behaviour. It begins with recognition of a problem, the consumer recognises a need or want which has not been satisfied. This leads the consumer to search for information, if it is a low involvement product then the search will be internal, identifying alternatives purely from memory. If the product is high involvement then the search be more thorough, such as reading reviews or reports or asking friends. The consumer will then evaluate his or her alternatives, comparing price, quality, doing trade-offs between products and narrowing down the choice by eliminating the less appealing products until there is one left. After this has been identified, the consumer will purchase the product. Finally the consumer will evaluate the purchase decision, and the purchased product, bringing in factors such as value for money, quality of goods and purchase experience (Model taken from Perner, 2008).
How the 4P’s Influence Consumer Behaviour
The 4 P’s are a marketing tool, and stand for Price, Promotion, Product and Place or Product Placement (Clemons, 2008). Consumer behaviour is influenced greatly by business to consumer marketing, so being a prominent marketing tool, the 4 P’s will have an effect on consumer’s behaviour. The price of a good or service is largely determined by the market, as businesses will set their prices to be similar to that of other business so as to remain competitive whilst making a profit (Clemons, 2008). When market prices for a product are high, it will cause consumers to purchase less and use purchased goods for longer periods of time, meaning they are purchasing the product less often. Alternatively, when market prices for a product are low, consumers are more likely to purchase more of the product, and more often. The way that promotion influences consumer behaviour has changed over time. In the past, large promotional campaigns and lots of advertising would convert into sales for a business, but nowadays businesses can have success on products with little or no advertising (Clemons, 2008). This is due to the internet, and in particular social media. They rely on word of mouth from consumers using social media, and as products trend online, so sales increase as products effectively promote themselves (Clemons, 2008). Thus, promotion by businesses does not necessarily result in consumer behaviour trending towards purchasing products. The way that product influences consumer behaviour is through consumer willingness to pay, and consumer preferences (Clemons, 2008). This means that even if a company were to have a long history of products in the market, consumers will still pick a cheaper product over the company in question’s product if it means they will pay less for something that is very similar (Clemons, 2008). This is due to consumer willingness to pay, or their willingness to part with their money they have earned. Product also influences consumer behaviour through customer preferences. For example, take Pepsi vs Coca-Cola, a Pepsi drinker is less likely to purchase Coca-Cola, even if it is cheaper and more convenient. This is due to the preference of the consumer, and no matter how hard the opposing company tries they will not be able to force the customer to change their mind. Product placement in the modern era has little influence on consumer behaviour, due to the availability of goods online (Clemons, 2008). If a customer can purchase a good from the comfort of their home instead of purchasing in-store, then the placement of products is not going to influence their purchase decision.
In management.
Behavior outside of psychology includes:
Organizational.
In management, behaviors are associated with desired or undesired focuses. Managers generally note what the desired outcome is, but behavioral patterns can take over. These patterns are the reference to how often the desired behavior actually occurs. Before a behavior actually occurs, antecedents focus on the stimuli that influence the behavior that is about to happen. After the behavior occurs, consequences fall into place. They can come in the form of rewards or punishments.
Behavior informatics.
Behavior informatics is also called "behavior computing", explores behavior intelligence and behavior insights from the informatics and computing perspectives.

</doc>
<doc id="4806" url="https://en.wikipedia.org/wiki?curid=4806" title="Battle of Marathon">
Battle of Marathon

The Battle of Marathon (Greek: , "Machē tou Marathōnos") took place in 490 BC, during the first Persian invasion of Greece. It was fought between the citizens of Athens, aided by Plataea, and a Persian force commanded by Datis and Artaphernes. The battle was the culmination of the first attempt by Persia, under King Darius I, to subjugate Greece. The Greek army decisively defeated the more numerous Persians, marking a turning point in the Greco-Persian Wars.
The first Persian invasion was a response to Greek involvement in the Ionian Revolt, when Athens and Eretria had sent a force to support the cities of Ionia in their attempt to overthrow Persian rule. The Athenians and Eretrians had succeeded in capturing and burning Sardis, but they were then forced to retreat with heavy losses. In response to this raid, Darius swore to burn down Athens and Eretria. According to Herodotus, Darius asked for his bow, he placed an arrow upon the string and he discharged it upwards towards heaven, and as he shot into the air he said: "Zeus, grant me to take vengeance upon the Athenians!". Also he charged one of his servants, to say to him, every day before dinner, three times: "Master, remember the Athenians."
At the time of the battle, Sparta and Athens were the two largest city states. Once the Ionian revolt was finally crushed by the Persian victory at the Battle of Lade in 494 BC, Darius began plans to subjugate Greece. In 490 BC, he sent a naval task force under Datis and Artaphernes across the Aegean, to subjugate the Cyclades, and then to make punitive attacks on Athens and Eretria. Reaching Euboea in mid-summer after a successful campaign in the Aegean, the Persians proceeded to besiege and capture Eretria. The Persian force then sailed for Attica, landing in the bay near the town of Marathon. The Athenians, joined by a small force from Plataea, marched to Marathon, and succeeded in blocking the two exits from the plain of Marathon. The Athenians also sent a message asking for support to the Spartans. However, at the time the Spartans were involved in a religious festival and gave this as a reason for refusing to aid the Athenians.
The Greeks could not hope to face the superior Persian cavalry; however, the location chosen was surrounded by marshes and mountains and so the cavalry was unable to join the main Persian army. Miltiades, the Greek general, ordered a general attack against the Persians. He reinforced his flanks, luring the Persians' best fighters into his centre. The inward wheeling flanks enveloped the Persians, routing them. The Persian army broke in panic towards their ships, and large numbers were slaughtered. The defeat at Marathon marked the end of the first Persian invasion of Greece, and the Persian force retreated to Asia. Darius then began raising a huge new army with which he meant to completely subjugate Greece; however, in 486 BC, his Egyptian subjects revolted, indefinitely postponing any Greek expedition. After Darius died, his son Xerxes I restarted the preparations for a second invasion of Greece, which finally began in 480 BC.
The Battle of Marathon was a watershed in the Greco-Persian wars, showing the Greeks that the Persians could be beaten; the eventual Greek triumph in these wars can be seen to begin at Marathon. The battle also showed the Greeks that they were able to win battles without the Spartans, as they had heavily relied on Sparta previously. This win was largely due to the Athenians, and Marathon raised Greek esteem of them. Since the following two hundred years saw the rise of the Classical Greek civilization, which has been enduringly influential in western society, the Battle of Marathon is often seen as a pivotal moment in European history.
The battle is perhaps now more famous as the inspiration for the marathon race. Although thought to be historically inaccurate, the legend of the Greek messenger Pheidippides running to Athens with news of the victory became the inspiration for this athletic event, introduced at the 1896 Athens Olympics, and originally run between Marathon and Athens.
Sources.
The main source for the Greco-Persian Wars is the Greek historian Herodotus. Herodotus, who has been called the "Father of History", was born in 484 BC in Halicarnassus, Asia Minor (then under Persian overlordship). He wrote his "Enquiries" (Greek—"Historia"; English—"(The) Histories") around 440–430 BC, trying to trace the origins of the Greco-Persian Wars, which would still have been relatively recent history (the wars finally ended in 450 BC). Herodotus's approach was entirely novel, and at least in Western society, he does seem to have invented "history" as we know it. As Holland has it: "For the first time, a chronicler set himself to trace the origins of a conflict not to a past so remote so as to be utterly fabulous, nor to the whims and wishes of some god, nor to a people's claim to manifest destiny, but rather explanations he could verify personally."
Some subsequent ancient historians, despite following in his footsteps, criticised Herodotus, starting with Thucydides. Nevertheless, Thucydides chose to begin his history where Herodotus left off (at the Siege of Sestos), and may therefore have felt that Herodotus's history was accurate enough not to need re-writing or correcting. Plutarch criticised Herodotus in his essay "On the malice of Herodotus", describing Herodotus as ""Philobarbaros"" (barbarian-lover), for not being pro-Greek enough, which suggests that Herodotus might actually have done a reasonable job of being even-handed. A negative view of Herodotus was passed on to Renaissance Europe, though he remained well read. However, since the 19th century his reputation has been dramatically rehabilitated by archaeological finds which have repeatedly confirmed his version of events. The prevailing modern view is that Herodotus generally did a remarkable job in his "Historia", but that some of his specific details (particularly troop numbers and dates) should be viewed with skepticism. Nevertheless, there are still some historians who believe Herodotus made up much of his story.
The Sicilian historian Diodorus Siculus, writing in the 1st century BC in his "Bibliotheca Historica", also provides an account of the Greco-Persian wars, partially derived from the earlier Greek historian Ephorus. This account is fairly consistent with Herodotus's. The Greco-Persian wars are also described in less detail by a number of other ancient historians including Plutarch, Ctesias of Cnidus, and are alluded by other authors, such as the playwright Aeschylus. Archaeological evidence, such as the Serpent Column, also supports some of Herodotus's specific claims.
Background.
The first Persian invasion of Greece had its immediate roots in the Ionian Revolt, the earliest phase of the Greco-Persian Wars. However, it was also the result of the longer-term interaction between the Greeks and Persians. In 500 BC the Persian Empire was still relatively young and highly expansionistic, but prone to revolts amongst its subject peoples. Moreover, the Persian King Darius was a usurper, and had spent considerable time extinguishing revolts against his rule. Even before the Ionian Revolt, Darius had begun to expand the empire into Europe, subjugating Thrace, and forcing Macedon to become a vassal of Persia. Attempts at further expansion into the politically fractious world of ancient Greece may have been inevitable. However, the Ionian Revolt had directly threatened the integrity of the Persian empire, and the states of mainland Greece remained a potential menace to its future stability. Darius thus resolved to subjugate and pacify Greece and the Aegean, and to punish those involved in the Ionian Revolt.
The Ionian Revolt had begun with an unsuccessful expedition against Naxos, a joint venture between the Persian satrap Artaphernes and the Milesian tyrant Aristagoras. In the aftermath, Artaphernes decided to remove Aristagoras from power, but before he could do so, Aristagoras abdicated, and declared Miletus a democracy. The other Ionian cities followed suit, ejecting their Persian-appointed tyrants, and declaring themselves democracies. Aristagoras then appealed to the states of mainland Greece for support, but only Athens and Eretria offered to send troops.
The involvement of Athens in the Ionian Revolt arose from a complex set of circumstances, beginning with the establishment of the Athenian Democracy in the late 6th century BC.
In 510 BC, with the aid of Cleomenes I, King of Sparta, the Athenian people had expelled Hippias, the tyrant ruler of Athens. With Hippias's father Peisistratus, the family had ruled for 36 out of the previous 50 years and fully intended to continue Hippias's rule. Hippias fled to Sardis to the court of the Persian satrap, Artaphernes and promised control of Athens to the Persians if they were to help restore him. In the meantime, Cleomenes helped install a pro-Spartan tyranny under Isagoras in Athens, in opposition to Cleisthenes, the leader of the traditionally powerful Alcmaeonidae family, who considered themselves the natural heirs to the rule of Athens. Cleisthenes, however, found himself being politically defeated by a coalition led by Isagoras and decided to change the rules of the game by appealing to the "demos" (the people), in effect making them a new faction in the political arena. This tactic succeeded, but the Spartan King, Cleomenes I, returned at the request of Isagoras and so Cleisthenes, the Alcmaeonids and other prominent Athenian families were exiled from Athens. When Isagoras attempted to create a narrow oligarchic government, the Athenian people, in a spontaneous and unprecedented move, expelled Cleomenes and Isagoras. Cleisthenes was thus restored to Athens (507 BC), and at breakneck speed began to reform the state with the aim of securing his position. The result was not actually a democracy or a real civic state, but he enabled the development of a fully democratic government, which would emerge in the next generation as the demos realized its power. The new-found freedom and self-governance of the Athenians meant that they were thereafter exceptionally hostile to the return of the tyranny of Hippias, or any form of outside subjugation, by Sparta, Persia, or anyone else.
Cleomenes was not pleased with events, and marched on Athens with the Spartan army. Cleomenes's attempts to restore Isagoras to Athens ended in a debacle, but fearing the worst, the Athenians had by this point already sent an embassy to Artaphernes in Sardis, to request aid from the Persian empire. Artaphernes requested that the Athenians give him an 'earth and water', a traditional token of submission, to which the Athenian ambassadors acquiesced. They were, however, severely censured for this when they returned to Athens. At some later point Cleomenes instigated a plot to restore Hippias to the rule of Athens. This failed and Hippias again fled to Sardis and tried to persuade the Persians to subjugate Athens. The Athenians dispatched ambassadors to Artaphernes to dissuade him from taking action, but Artaphernes merely instructed the Athenians to take Hippias back as tyrant. The Athenians indignantly declined, and instead resolved to open war with Persia. Having thus become the enemy of Persia, Athens was already in a position to support the Ionian cities when they began their revolt. The fact that the Ionian democracies were inspired by the example the Athenians had set no doubt further persuaded the Athenians to support the Ionian Revolt, especially since the cities of Ionia were originally Athenian colonies.
The Athenians and Eretrians sent a task force of 25 triremes to Asia Minor to aid the revolt. Whilst there, the Greek army surprised and outmaneuvered Artaphernes, marching to Sardis and burning the lower city. This was, however, as much as the Greeks achieved, and they were then repelled and pursued back to the coast by Persian horsemen, losing many men in the process. Despite the fact that their actions were ultimately fruitless, the Eretrians and in particular the Athenians had earned Darius's lasting enmity, and he vowed to punish both cities. The Persian naval victory at the Battle of Lade (494 BC) all but ended the Ionian Revolt, and by 493 BC, the last hold-outs were vanquished by the Persian fleet. The revolt was used as an opportunity by Darius to extend the empire's border to the islands of the eastern Aegean and the Propontis, which had not been part of the Persian dominions before. The pacification of Ionia allowed the Persians to begin planning their next moves; to extinguish the threat to the empire from Greece and to punish Athens and Eretria.
In 492 BC, after the Ionian Revolt had finally been crushed, Darius dispatched an to Greece under the command of his son-in-law, Mardonius. Mardonius re-conquered Thrace and compelled Alexander I of Macedon to make Macedon a client kingdom to Persia, before the wrecking of his fleet brought a premature end to the campaign.
However, in 490 BC, following the successes of the previous campaign, Darius decided to send a maritime expedition led by Artaphernes, (son of the satrap to whom Hippias had fled) and Datis, a Median admiral. Mardonius had been injured in the prior campaign and had fallen out of favor. The was intended to bring the Cyclades into the Persian empire, to punish Naxos (which had resisted a Persian assault in 499 BC) and then to head to Greece to force Eretria and Athens to submit to Darius or be destroyed. After island-hopping across the Aegean, including successfully attacking Naxos, the Persian task force arrived off Euboea in mid summer. The Persians then proceeded to besiege, capture and burn Eretria. They then headed south down the coast of Attica, en route to complete the final objective of the campaign—punish Athens.
Prelude.
The Persians sailed down the coast of Attica, and landed at the bay of Marathon, roughly from Athens, on the advice of the exiled Athenian tyrant Hippias (who had accompanied the expedition). Under the guidance of Miltiades, the Athenian general with the greatest experience of fighting the Persians, the Athenian army marched quickly to block the two exits from the plain of Marathon, and prevent the Persians moving inland. At the same time, Athens's greatest runner, Pheidippides (or Philippides in some accounts) had been sent to Sparta to request that the Spartan army march to the aid of Athens. Pheidippides arrived during the festival of "Carneia", a sacrosanct period of peace, and was informed that the Spartan army could not march to war until the full moon rose; Athens could not expect reinforcement for at least ten days. The Athenians would have to hold out at Marathon for the time being, although they were reinforced by the full muster of 1,000 hoplites from the small city of Plataea; a gesture which did much to steady the nerves of the Athenians, and won unending Athenian gratitude to Plataea.
For approximately five days the armies therefore confronted each other across the plain of Marathon in stalemate. The flanks of the Athenian camp were protected either by a grove of trees, or an "abbatis" of stakes (depending on the exact reading). Since every day brought the arrival of the Spartans closer, the delay worked in favor of the Athenians. There were ten Athenian "strategoi" (generals) at Marathon, elected by each of the ten tribes that the Athenians were divided into; Miltiades was one of these. In addition, in overall charge, was the War-Archon ("polemarch"), Callimachus, who had been elected by the whole citizen body. Herodotus suggests that command rotated between the "strategoi", each taking in turn a day to command the army. He further suggests that each "strategos", on his day in command, instead deferred to Miltiades. In Herodotus's account, Miltiades is keen to attack the Persians (despite knowing that the Spartans are coming to aid the Athenians), but strangely, chooses to wait until his actual day of command to attack. This passage is undoubtedly problematic; the Athenians had little to gain by attacking before the Spartans arrived, and there is no real evidence of this rotating generalship. There does, however, seem to have been a delay between the Athenian arrival at Marathon, and the battle; Herodotus, who evidently believed that Miltiades was eager to attack, may have made a mistake whilst seeking to explain this delay.
As is discussed below, the reason for the delay was probably simply that neither the Athenians nor the Persians were willing to risk battle initially. This then raises the question of why the battle occurred when it did. Herodotus explicitly tells us that the Greeks attacked the Persians (and the other sources confirm this), but it is not clear why they did this before the arrival of the Spartans. There are two main theories to explain this.
The first theory is that the Persian cavalry left Marathon for an unspecified reason, and that the Greeks moved to take advantage of this by attacking. This theory is based on the absence of any mention of cavalry in Herodotus' account of the battle, and an entry in the Suda dictionary. The entry "χωρίς ἰππεῖς" ("without cavalry") is explained thus: The cavalry left. When Datis surrendered and was ready for retreat, the Ionians climbed the trees and gave the Athenians the signal that the cavalry had left. And when Miltiades realized that, he attacked and thus won. From there comes the above-mentioned quote, which is used when someone breaks ranks before battle. There are many variations of this theory, but perhaps the most prevalent is that the cavalry was re-embarked on the ships, and was to be sent by sea to attack (undefended) Athens in the rear, whilst the rest of the Persians pinned down the Athenian army at Marathon. This theory therefore utilises Herodotus' suggestion that after Marathon, the Persian army re-embarked and tried to sail around Cape Sounion to attack Athens directly; however, according to the theory this attempt would have occurred "before" the battle (and indeed have triggered the battle).
The second theory is simply that the battle occurred because the Persians finally moved to attack the Athenians. Although this theory has the Persians moving to the "strategic" offensive, this can be reconciled with the traditional account of the Athenians attacking the Persians by assuming that, seeing the Persians advancing, the Athenians took the "tactical" offensive, and attacked them. Obviously, it cannot be firmly established which theory (if either) is correct. However, both theories imply that there was some kind of Persian activity which occurred on or about the fifth day which ultimately triggered the battle. It is also possible that both theories are correct: when the Persians sent the cavalry by ship to attack Athens, they simultaneously sent their infantry to attack at Marathon, triggering the Greek counterattack.
Date of the battle.
Herodotus mentions for several events a date in the lunisolar calendar, of which each Greek city-state used a variant. Astronomical computation allows us to derive an absolute date in the proleptic Julian calendar which is much used by historians as the chronological frame. Philipp August Böckh in 1855 concluded that the battle took place on September 12, 490 BC in the Julian calendar, and this is the conventionally accepted date. However, this depends on when exactly the Spartans held their festival and it is possible that the Spartan calendar was one month ahead of that of Athens. In that case the battle took place on August 12, 490 BC.
Opposing forces.
Athenians.
Herodotus does not give a figure for the size of the Athenian army. However, Cornelius Nepos, Pausanias and Plutarch all give the figure of 9,000 Athenians and 1,000 Plataeans; while Justin suggests that there were 10,000 Athenians and 1,000 Plataeans. These numbers are highly comparable to the number of troops Herodotus says that the Athenians and Plataeans sent to the Battle of Plataea 11 years later. Pausanias noticed on the monument to the battle the names of former slaves who were freed in exchange for military services. Modern historians generally accept these numbers as reasonable.
Persians.
According to Herodotus, the fleet sent by Darius consisted of 600 triremes. Herodotus does not estimate the size of the Persian army, only saying that they were a "large infantry that was well packed". Among ancient sources, the poet Simonides, another near-contemporary, says the campaign force numbered 200,000; while a later writer, the Roman Cornelius Nepos estimates 200,000 infantry and 10,000 cavalry, of which only 100,000 fought in the battle, while the rest were loaded into the fleet that was rounding Cape Sounion; Plutarch and Pausanias both independently give 300,000, as does the Suda dictionary. Plato and Lysias give 500,000; and Justinus 600,000.
Modern historians have proposed wide ranging numbers for the infantry, from 20,000–100,000 with a consensus of perhaps 25,000; estimates for the cavalry are in the range of 1,000.
However, the lower end of that range contradicts the statement by Herodotus of a "large infantry that was well packed". The 25,000 fighting force by no means could be neither "large" nor intimidating to the eyes of the 11,000 Greeks especially in the scenario (see below) that half of the Persian force circumnavigated cape Sounion to take Athens by surprise, leaving thus on the field a force almost equal numerically with Miltiades' army. Probably the 25,000 is the army that remained "after" the split of the Persian army, raising the size of the initial landing army in 50,000 combatants.
To this force furthermore some adjustments must be made:
a) In the hypothesis (less likely) that the 600 ships of Herodotus represent the entire Persian naval force (both the combat and the troop-transporting fleets) and each ship carried a total crew of 230-240 (considering the 30 additional marines that Herodotus mentions) we have a minimum of 138,000 to 144,000 personnel. It is unlikely that the Persians gathered such a fleet to just ferry across the Aegean only 50,000 combatants, especially after making an effort to pack 30 marines more to each vessel.
In order to curry supplies for 2 months and ferry their 1,800 strong cavalry, the Persians should have had in addition 200 supply ships and 70 horse-transports (see below); thus a 870-strong fleet.
On the composition of the fleet in Marathon the following examples should be also considered:
-The Persian fleet that invaded Greece 10 years later (480 BC) had 1207 triremes and 3000 transports.
-The Athenian fleet on the Sicilian expedition ~60 years later (415 BC) had 40% transports.
-The Punic fleet that campaigned against the Sicilian Greeks ~80 years later (406 BC) had 120 triremes and 1000 transports (siege of Selinous, siege of Acragas) and again 400 triremes and 600 transports in 396 BC (siege of Syracuse).
b) In all the aforementioned cases the transport fleet were at least equal in size - if not larger - than the combat fleet. In the following (more likely) hypothesis the transport fleet will be the 2/3 of the 600-strong combat fleet representing thus the 30% of the total (400 transports over 1,370 ships):
Here is to be noted that the ships' oarsmen and sailors were armed each with a light shield, a short sword and a helmet. Leather armors and missile weapons were also frequent. They were serving as light infantry and skirmishers when the ships were to be captured and - in rare occasions (i.e. Battle of Naupactus 429 BC) - in the main battlefield.
Because ancient historians are usually referring to the "combat fleet" of a naval force when they don't mention the troop-transports separately (as in this case) a possible breakdown of the Persian fleet in Marathon could be the following:
-600 combat ships ("aphraktae" or open triremes). Represented the main fighting vessel in naval battles. They were called "open" because they had their upper deck almost completely removed in order to lighten and gain speed and maneuverability. They were carrying usually 30-40 marines (as in the Ionian Greek fleets and the Persian fleet) but in some rare cases these force could be further more reduced in just 14 marines (Athenian triremes during the city's heyday of naval power) to additionally increase speed. The triremes in Marathon were packed with 30 additional marines, for the purposes of the campaign. Thus:
Crew: 170 oarsmen, 15 sailors and officers, 60 marines.
-400 troop-transports ("kataphraktae" or closed triremes). Specially modified triremes where the two lower rows of oarsmen were removed and an upper deck was added in order to house more land troops. With less oarsmen and additional weight, those triremes were slow and heavy; thus totally useless in naval combat and in need of escort.
Crew: 70 oarsmen, 15 sailors and officers, 160 land troops.
-70 cavalry-transports (modified "kataphraktae" triremes).
Crew: 70 oarsmen, 15 sailors and officers, 25 horses with their riders and complete gear.
-300 supply ships. They were normal merchant ships that were carrying supplies (mostly grain) during wars. A 250,000-strong army needs 250 tons of supplies daily (5 ships).
Crew: 22 oarsmen, 10 sailors, 50 tons of supplies (grain).
TOTAL: 257,500 -> 155,750 oarsmen and sailors; 100,000 soldiers and marines; 1,750 cavalry; 1,370 ships. Thus the account of the near-contemporary Simonides (200,000 men) must be closest to the truth.
The Greeks however fought half of that force in Marathon, on September 490 BC (~50,000 foot-soldiers and marines).
NOTE: The Persian fleet campaigned during the long Greek summer (5 months). They didn't need to have more than 60 days of supplies because they could replenish their scores of provision in various ways (through trade, pillaging or conquest). The fall of Eretria a few weeks earlier, in late summer just after the collecting of the crops, should have provided plenty of supplies to the Persians. The island of Euboea (on which Eretria stands) was at the time the main grain supplier for Athens.
Furthermore, the fear of being low on supplies by the end of the campaigning season, drove the Persians to attempt the surprise attack on Athens by circumnavigating cape Sounion with half of their army.
Strategic and tactical considerations.
From a strategic point of view, the Athenians had some disadvantages at Marathon. In order to face the Persians in battle, the Athenians had to summon all available hoplites; and even then they were still probably outnumbered at least 2 to 1. Furthermore, raising such a large army had denuded Athens of defenders, and thus any secondary attack in the Athenian rear would cut the army off from the city; and any direct attack on the city could not be defended against. Still further, defeat at Marathon would mean the complete defeat of Athens, since no other Athenian army existed. The Athenian strategy was therefore to keep the Persian army pinned down at Marathon, blocking both exits from the plain, and thus preventing themselves from being outmaneuvered. However, these disadvantages were balanced by some advantages. The Athenians initially had no need to seek battle, since they had managed to confine the Persians to the plain of Marathon. Furthermore, time worked in their favour, as every day brought the arrival of the Spartans closer. Having everything to lose by attacking, and much to gain by waiting, the Athenians remained on the defensive in the run up to the battle. Tactically, hoplites were vulnerable to attacks by cavalry, and since the Persians had substantial numbers of cavalry, this made any offensive maneuver by the Athenians even more of a risk, and thus reinforced the defensive strategy of the Athenians.
The Persian strategy, on the other hand, was probably principally determined by tactical considerations. The Persian infantry was evidently lightly armoured, and no match for hoplites in a head-on confrontation (as would be demonstrated at the later battles of Thermopylae and Plataea.) Since the Athenians seem to have taken up a strong defensive position at Marathon, the Persian hesitance was probably a reluctance to attack the Athenians head-on.
Whatever event eventually triggered the battle, it obviously altered the strategic or tactical balance sufficiently to induce the Athenians to attack the Persians. If the first theory is correct (see above), then the absence of cavalry removed the main Athenian tactical disadvantage, and the threat of being outflanked made it imperative to attack. Conversely, if the second theory is correct, then the Athenians were merely reacting to the Persians attacking them. Since the Persian force obviously contained a high proportion of missile troops, a static defensive position would have made little sense for the Athenians; the strength of the hoplite was in the melee, and the sooner that could be brought about, the better, from the Athenian point of view. If the second theory is correct, this raises the further question of why the Persians, having hesitated for several days, then attacked. There may have been several strategic reasons for this; perhaps they were aware (or suspected) that the Athenians were expecting reinforcements. Alternatively, since they may have felt the need to force some kind of victory—they could hardly remain at Marathon indefinitely.
Battle.
The distance between the two armies at the point of battle had narrowed to "a distance not less than 8 stadia" or about 1,500 meters. Miltiades ordered the two tribes that were forming the center of the Greek formation, the Leontis tribe led by Themistocles and the Antiochis tribe led by Aristides, to be arranged in the depth of four ranks while the rest of the tribes at their flanks were in ranks of eight. Some modern commentators have suggested this was a deliberate ploy to encourage a double envelopment of the Persian centre. However, this suggests a level of training that the Greeks were thought not to possess. There is little evidence for any such tactical thinking in Greek battles until Leuctra in 371 BC. It is therefore possible that this arrangement was made, perhaps at the last moment, so that the Athenian line was as long as the Persian line, and would not therefore be outflanked.
When the Athenian line was ready, according to one source, the simple signal to advance was given by Miltiades: "At them". Herodotus implies the Athenians ran the whole distance to the Persian lines, a feat under the weight of hoplite armory generally thought to be physically impossible. More likely, they marched until they reached the limit of the archers' effectiveness, the "beaten zone" (roughly 200 meters), and then broke into a run towards their enemy. Another possibility is that they ran "up to" the 200 meter-mark in broken ranks, and then reformed for the march into battle from there. Herodotus suggests that this was the first time a Greek army ran into battle in this way; this was probably because it was the first time that a Greek army had faced an enemy composed primarily of missile troops. All this was evidently much to the surprise of the Persians; "... in their minds they charged the Athenians with madness which must be fatal, seeing that they were few and yet were pressing forwards at a run, having neither cavalry nor archers". Indeed, based on their previous experience of the Greeks, the Persians might be excused for this; Herodotus tells us that the Athenians at Marathon were "first to endure looking at Median dress and men wearing it, for up until then just hearing the name of the Medes caused the Hellenes to panic". Passing through the hail of arrows launched by the Persian army, protected for the most part by their armour, the Greek line finally collided with the enemy army. Holland provides an evocative description:
The enemy directly in their path ... realised to their horror that Athenians, far from providing the easy pickings for their bowmen, as they had first imagined, were not going to be halted ... The impact was devastating. The Athenians had honed their style of fighting in combat with other phalanxes, wooden shields smashing against wooden shields, iron spear tips clattering against breastplates of bronze ... in those first terrible seconds of collision, there was nothing but a pulverizing crash of metal into flesh and bone; then the rolling of the Athenian tide over men wearing, at most, quilted jerkins for protection, and armed, perhaps, with nothing more than bows or slings. The hoplites' ash spears, rather than shivering ... could instead stab and stab again, and those of the enemy who avoided their fearful jabbing might easily be crushed to death beneath the sheer weight of the advancing men of bronze.
The Athenian wings quickly routed the inferior Persian levies on the flanks, before turning inwards to surround the Persian centre, which had been more successful against the thin Greek centre. The battle ended when the Persian centre then broke in panic towards their ships, pursued by the Greeks. Some, unaware of the local terrain, ran towards the swamps where unknown numbers drowned. The Athenians pursued the Persians back to their ships, and managed to capture seven ships, though the majority were able to launch successfully. Herodotus recounts the story that Cynaegirus, brother of the playwright Aeschylus, who was also among the fighters, charged into the sea, grabbed one Persian trireme, and started pulling it towards shore. A member of the crew saw him, cut off his hand, and Cynaegirus died.
Herodotus records that 6,400 Persian bodies were counted on the battlefield, and it is unknown how many more perished in the swamps. The Athenians lost 192 men and the Plataeans 11. Among the dead were the war archon Callimachus and the general Stesilaos.
Conclusions.
There are several explanations of the Greek success. Most scholars believe that the Greeks had better equipment and used superior tactics. According to Herodotus, the Greeks were better equipped; however, they did not use bronze armour at this time, but that of leather or linen. The phalanx formation proved successful, because the hoplites had a long tradition in hand-to-hand combat, whereas the Persian soldiers were accustomed to a very different kind of conflict. At Marathon, the Athenians thinned their centre in order to make their army equal in length to the Persian army, not as a result of a tactical planning. It seems that the Persian centre tried to return, realizing that their wings had broken, and was caught in the flanks by the victorious Greek wings. Lazenby believes that the ultimate reason for the Greek success was the courage the Greeks displayed:
Aftermath.
In the immediate aftermath of the battle, Herodotus says that the Persian fleet sailed around Cape Sounion to attack Athens directly. As has been discussed above, some modern historians place this attempt just before the battle. Either way, the Athenians evidently realised that their city was still under threat, and marched as quickly as possible back to Athens.
The two tribes which had been in the centre of the Athenian line stayed to guard the battlefield under the command of Aristides. The Athenians arrived in time to prevent the Persians from securing a landing, and seeing that the opportunity was lost, the Persians turned about and returned to Asia. Connected with this episode, Herodotus recounts a rumour that this manoeuver by the Persians had been planned in conjunction with the Alcmaeonids, the prominent Athenian aristocratic family, and that a "shield-signal" had been given after the battle. Although many interpretations of this have been offered, it is impossible to tell whether this was true, and if so, what exactly the signal meant. On the next day, the Spartan army arrived at Marathon, having covered the in only three days. The Spartans toured the battlefield at Marathon, and agreed that the Athenians had won a great victory.
The dead of Marathon were buried on the battlefield. On the tomb of the Athenians this epigram composed by Simonides was written:
In the meanwhile, Darius began raising a huge new army with which he meant to completely subjugate Greece; however, in 486 BC, his Egyptian subjects revolted, indefinitely postponing any Greek expedition. Darius then died whilst preparing to march on Egypt, and the throne of Persia passed to his son Xerxes I. Xerxes crushed the Egyptian revolt, and very quickly restarted the preparations for the invasion of Greece. The epic second Persian invasion of Greece finally began in 480 BC, and the Persians met with initial success at the battles of Thermopylae and Artemisium. However, defeat at the Battle of Salamis would be the turning point in the campaign, and the next year the expedition was ended by the decisive Greek victory at the Battle of Plataea.
Significance.
The defeat at Marathon barely touched the vast resources of the Persian empire, yet for the Greeks it was an enormously significant victory. It was the first time the Greeks had beaten the Persians, proving that the Persians were not invincible, and that resistance, rather than subjugation, was possible.
The battle was a defining moment for the young Athenian democracy, showing what might be achieved through unity and self-belief; indeed, the battle effectively marks the start of a "golden age" for Athens. This was also applicable to Greece as a whole; "their victory endowed the Greeks with a faith in their destiny that was to endure for three centuries, during which western culture was born". John Stuart Mill's famous opinion was that "the Battle of Marathon, even as an event in British history, is more important than the Battle of Hastings". It seems that the Athenian playwright Aeschylus considered his participation at Marathon to be his greatest achievement in life (rather than his plays) since on his gravestone there was the following epigram:
Militarily, a major lesson for the Greeks was the potential of the hoplite phalanx. This style had developed during internecine warfare amongst the Greeks; since each city-state fought in the same way, the advantages and disadvantages of the hoplite phalanx had not been obvious. Marathon was the first time a phalanx faced more lightly armed troops, and revealed how effective the hoplites could be in battle. The phalanx formation was still vulnerable to cavalry (the cause of much caution by the Greek forces at the Battle of Plataea), but used in the right circumstances, it was now shown to be a potentially devastating weapon.
Legacy.
Legends associated with the battle.
The most famous legend associated with Marathon is that of the runner Pheidippides/Philippides bringing news to Athens of the battle, which is described below.
Pheidippides' run to Sparta to bring aid has other legends associated with it. Herodotus mentions that Pheidippides was visited by the god Pan on his way to Sparta (or perhaps on his return journey). Pan asked why the Athenians did not honor him and the awed Pheidippides promised that they would do so from then on. The god apparently felt that the promise would be kept, so he appeared in battle and at the crucial moment he instilled the Persians with his own brand of fear, the mindless, frenzied fear that bore his name: "panic". After the battle, a sacred precinct was established for Pan in a grotto on the north slope of the Acropolis, and a sacrifice was annually offered.
Similarly, after the victory the festival of the "Agroteras Thysia" ("sacrifice to the Agrotéra") was held at Agrae near Athens, in honor of Artemis Agrotera ("Artemis the Huntress"). This was in fulfillment of a vow made by the city before the battle, to offer in sacrifice a number of goats equal to that of the Persians slain in the conflict. The number was so great, it was decided to offer 500 goats yearly until the number was filled. Xenophon notes that at his time, 90 years after the battle, goats were still offered yearly.
Plutarch mentions that the Athenians saw the phantom of King Theseus, the mythical hero of Athens, leading the army in full battle gear in the charge against the Persians, and indeed he was depicted in the mural of the Stoa Poikile fighting for the Athenians, along with the twelve Olympian gods and other heroes. Pausanias also tells us that: They say too that there chanced to be present in the battle a man of rustic appearance and dress. Having slaughtered many of the foreigners with a plough he was seen no more after the engagement. When the Athenians made enquiries at the oracle, the god merely ordered them to honor Echetlaeus ("he of the Plough-tail") as a hero.
Another tale from the conflict is of the dog of Marathon. Aelian relates that one hoplite brought his dog to the Athenian encampment. The dog followed his master to battle and attacked the Persians at his master's side. He also informs us that this dog is depicted in the mural of the Stoa Poikile.
Marathon run.
According to Herodotus, an Athenian runner named Pheidippides was sent to run from Athens to Sparta to ask for assistance before the battle. He ran a distance of over 225 kilometers (140 miles), arriving in Sparta the day after he left. Then, following the battle, the Athenian army marched the 40 kilometers (25 miles) or so back to Athens at a very high pace (considering the quantity of armour, and the fatigue after the battle), in order to head off the Persian force sailing around Cape Sounion. They arrived back in the late afternoon, in time to see the Persian ships turn away from Athens, thus completing the Athenian victory.
Later, in popular imagination, these two events became confused with each other, leading to a legendary but inaccurate version of events. This myth has Pheidippides running from Marathon to Athens after the battle, to announce the Greek victory with the word "nenikēkamen!" (Attic: ; we've won!), whereupon he promptly died of exhaustion. Most accounts incorrectly attribute this story to Herodotus; actually, the story first appears in Plutarch's "On the Glory of Athens" in the 1st century AD, who quotes from Heracleides of Pontus's lost work, giving the runner's name as either Thersipus of Erchius or Eucles. Lucian of Samosata (2nd century AD) gives the same story but names the runner Philippides (not Pheidippides). It should be noted that in some medieval codices of Herodotus the name of the runner between Athens and Sparta before the battle is given as Philippides and in a few modern editions this name is preferred.
When the idea of a modern Olympics became a reality at the end of the 19th century, the initiators and organizers were looking for a great popularizing event, recalling the ancient glory of Greece. The idea of organizing a 'marathon race' came from Michel Bréal, who wanted the event to feature in the first modern Olympic Games in 1896 in Athens. This idea was heavily supported by Pierre de Coubertin, the founder of the modern Olympics, as well as the Greeks. This would echo the legendary version of events, with the competitors running from Marathon to Athens. So popular was this event that it quickly caught on, becoming a fixture at the Olympic games, with major cities staging their own annual events. The distance eventually became fixed at 26 miles 385 yards, or 42.195 km, though for the first years it was variable, being around —the approximate distance from Marathon to Athens.
External links.
The has a journal article about this subject:

</doc>
<doc id="4810" url="https://en.wikipedia.org/wiki?curid=4810" title="Balance of trade">
Balance of trade

The commercial balance or net exports (sometimes symbolized as NX), is the difference between the monetary value of exports and imports of output in an economy over a certain period, measured in the currency of that economy. It is the relationship between a nation's imports and exports. A positive balance is known as a trade surplus if it consists of exporting more than is imported; a negative balance is referred to as a trade deficit or, informally, a trade gap. The balance of trade is sometimes divided into a goods and a services balance.
Definition.
Trade, in general connotation, means the purchase and sales of commodities. In international trade, purchase and sale are replaced by imports and exports. Balance of Trade is simply the difference between the value of exports and value of imports. Thus, the "balance of trade" denotes the differences of imports and exports of a merchandise of a country during the course of year. It indicates the value of exports and imports of the country in question. If the value of its exports over a period exceeds its value of imports, it is called favourable balance of trade and, conversely, if the value of total imports exceeds the total value of exports over a period, it is unfavourable balance of trade. The favorable balance of trade indicates good economic condition of the country.
The balance of trade forms part of the current account, which includes other transactions such as income from the net international investment position as well as international aid. If the current account is in surplus, the country's net international asset position increases correspondingly. Equally, a deficit decreases the net international asset position.
The trade balance is identical to the difference between a country's output and its domestic demand (the difference between what goods a country produces and how many goods it buys from abroad; this does not include money re-spent on foreign stock, nor does it factor in the concept of importing goods to produce for the domestic market).
Measuring the balance of trade can be problematic because of problems with recording and collecting data. As an illustration of this problem, when official data for all the world's countries are added up, exports exceed imports by almost 1%; it appears the world is running a positive balance of trade with itself. This cannot be true, because all transactions involve an equal credit or debit in the account of each nation. The discrepancy is widely believed to be explained by transactions intended to launder money or evade taxes, smuggling and other visibility problems. Especially for developing countries, the transaction statistics are likely to be inaccurate.
Factors that can affect the balance of trade include:
In addition, the trade balance is likely to differ across the business cycle. In export-led growth (such as oil and early industrial goods), the balance of trade will improve during an economic expansion. However, with domestic demand led growth (as in the United States and Australia) the trade balance will worsen at the same stage in the business cycle.
Monetary balance of trade is different from physical balance of trade (which is expressed in amount of raw materials, known also as Total Material Consumption). Developed countries usually import a lot of raw materials from developing countries. Typically, these imported materials are transformed into finished products, and might be exported after adding value. Financial trade balance statistics conceal material flow. Most developed countries have a large physical trade deficit, because they have a large ecological footprint. Civil society organisations point out the predatory nature of this imbalance, and campaign for ecological debt repayment.
Historical examples.
Many countries in early modern Europe adopted a policy of mercantilism, which included a favorable balance of trade, among other elements such as colonialism and trade barriers with other countries and their colonies. (Bullionism was an early philosophy supporting merchantalism.) 
The practices and abuses of mercantilism led the natural resources and cash crops of British North America to be exported in exchange for finished goods from Great Britain, a factor leading to the American Revolution. An early statement appeared in "Discourse of the Common Wealth of this Realm of England", 1549: "We must always take heed that we buy no more from strangers than we sell them, for so should we impoverish ourselves and enrich them." Similarly a systematic and coherent explanation of balance of trade was made public through Thomas Mun's 1630 "England's treasure by foreign trade, or, The balance of our foreign trade is the rule of our treasure"
Since the mid-1980s, the United States has had a growing deficit in tradeable goods, especially with Asian nations (China and Japan) which now hold large sums of U.S debt that has funded the consumption. The U.S. has a trade surplus with nations such as Australia. The issue of trade deficits can be complex. Trade deficits generated in tradeable goods such as manufactured goods or software may impact domestic employment to different degrees than trade deficits in raw materials.
Economies such as Japan and Germany which have savings surpluses, typically run trade surpluses. China, a high-growth economy, has tended to run trade surpluses. A higher savings rate generally corresponds to a trade surplus. Correspondingly, the U.S. with its lower savings rate has tended to run high trade deficits, especially with Asian nations.
Views on economic impact.
Classical theory.
From Classical economic theory, those who ignore the effects of long run trade deficits may be confusing David Ricardo's principle of comparative advantage with Adam Smith's principle of absolute advantage, specifically ignoring the latter. The economist Paul Craig Roberts notes that the comparative advantage principles developed by David Ricardo do not hold where the factors of production are internationally mobile. Global labor arbitrage, a phenomenon described by economist Stephen S. Roach, where one country exploits the cheap labor of another, would be a case of absolute advantage that is not mutually beneficial. In 2010, economist Ian Fletcher wrote "Free Trade Doesn't Work: What Should Replace It and Why", where he supported a strategic approach to trade rather than an unconditional or unilateral approach.
Small trade deficits are generally not considered to be harmful to either the importing or exporting economy. However, when a national trade imbalance expands beyond prudence (generally thought to be several percent of GDP, for several years), adjustments tend to occur. While unsustainable imbalances may persist for long periods (cf, Singapore and New Zealand’s surpluses and deficits, respectively), the distortions likely to be caused by large flows of wealth out of one economy and into another tend to become intolerable.
In simple terms, trade deficits are paid for out of foreign exchange reserves, and may continue until such reserves are empty, at which point, the importer can no longer purchase abroad. This is likely to have exchange rate implications: a loss of value in the deficit economy’s currency relative to the surplus economy’s currency will change the relative price of tradable goods, and facilitate a return to balance or (quite commonly in historical data) an over-shooting into surplus, the other direction.
When an economy is unable to export enough physical goods to pay for its physical imports, it may be able to find funds elsewhere: Service exports, for example, are more than sufficient to pay for Hong Kong's domestic goods import. In poor countries, foreign aid may compensate, while in developed economies a capital account surplus caused by sales of assets often offsets a current-account deficit. There are some economies where transfers from nationals working abroad contribute significantly to paying for imports. The Philippines, Bangladesh and Mexico are examples of transfer-rich economies.
A country may rebalance the trade deficit by use of quantitative easing at home. This involves a central bank printing money and making it available to other domestic financial institutions at small interest rates, which increases the money supply in the home economy. Inflation usually results, which devalues in real terms the debt owed to foreign creditors if that debt was instantiated in the home currency.
Adam Smith on the balance of trade.
"In the foregoing part of this chapter I have endeavoured to show, even upon the principles of the commercial system, how unnecessary it is to lay extraordinary restraints upon the importation of goods from those countries with which the balance of trade is supposed to be disadvantageous.
Nothing, however, can be more absurd than this whole doctrine of the balance of trade, upon which, not only these restraints, but almost all the other regulations of commerce are founded. When two places trade with one another, this doctrine supposes that, if the balance be even, neither of them either loses or gains; but if it leans in any degree to one side, that one of them loses and the other gains in proportion to its declension from the exact equilibrium." (Smith, 1776, book IV, ch. iii, part ii)
Keynesian theory.
In the last few years of his life, John Maynard Keynes was much preoccupied with the question of balance in international trade. He was the leader of the British delegation to the United Nations Monetary and Financial Conference in 1944 that established the Bretton Woods system of international currency management.
He was the principal author of a proposal – the so-called Keynes Plan — for an International Clearing Union. The two governing principles of the plan were that the problem of settling outstanding balances should be solved by 'creating' additional 'international money', and that debtor and creditor should be treated almost alike as disturbers of equilibrium. In the event, though, the plans were rejected, in part because "American opinion was naturally reluctant to accept the principle of equality of treatment so novel in debtor-creditor relationships".
His view, supported by many economists and commentators at the time, was that creditor nations may be just as responsible as debtor nations for disequilibrium in exchanges and that both should be under an obligation to bring trade back into a state of balance. Failure for them to do so could have serious consequences. In the words of Geoffrey Crowther, then editor of The Economist, "If the economic relationships between nations are not, by one means or another, brought fairly close to balance, then there is no set of financial arrangements that can rescue the world from the impoverishing results of chaos."
These ideas were informed by events prior to the Great Depression when – in the opinion of Keynes and others – international lending, primarily by the U.S., exceeded the capacity of sound investment and so got diverted into non-productive and speculative uses, which in turn invited default and a sudden stop to the process of lending.
Influenced by Keynes, economics texts in the immediate post-war period put a significant emphasis on balance in trade. For example, the second edition of the popular introductory textbook, "An Outline of Money", devoted the last three of its ten chapters to questions of foreign exchange management and in particular the 'problem of balance'. However, in more recent years, since the end of the Bretton Woods system in 1971, with the increasing influence of Monetarist schools of thought in the 1980s, and particularly in the face of large sustained trade imbalances, these concerns – and particularly concerns about the destabilising effects of large trade surpluses – have largely disappeared from mainstream economics discourse and Keynes' insights have slipped from view. They are receiving some attention again in the wake of the financial crisis of 2007–08.
Monetarist theory.
Prior to 20th century Monetarist theory, the 19th century economist and philosopher Frédéric Bastiat expressed the idea that trade deficits actually were a manifestation of profit, rather than a loss. He proposed as an example to suppose that he, a Frenchman, exported French wine and imported British coal, turning a profit. He supposed he was in France, and sent a cask of wine which was worth 50 francs to England. The customhouse would record an export of 50 francs. If, in England, the wine sold for 70 francs (or the pound equivalent), which he then used to buy coal, which he imported into France, and was found to be worth 90 francs in France, he would have made a profit of 40 francs. But the customhouse would say that the value of imports exceeded that of exports and was trade deficit against the ledger of France.
By "reductio ad absurdum", Bastiat argued that the national trade deficit was an indicator of a successful economy, rather than a failing one. Bastiat predicted that a successful, growing economy would result in greater trade deficits, and an unsuccessful, shrinking economy would result in lower trade deficits. This was later, in the 20th century, echoed by economist Milton Friedman.
In the 1980s, Milton Friedman, a Nobel Prize-winning economist and a proponent of Monetarism, contended that some of the concerns of trade deficits are unfair criticisms in an attempt to push macroeconomic policies favorable to exporting industries.
Friedman argued that trade deficits are not necessarily as important as high exports raise the value of the currency, reducing aforementioned exports, and vice versa for imports, thus naturally removing trade deficits not due to investment. Since 1971, when the Nixon administration decided to abolish fixed exchange rates, America's Current Account accumulated trade deficits have totaled $7.75 Trillion as of 2010. This deficit exists as it is matched by investment coming into the United States- purely by the definition of the balance of payments, any current account deficit that exists is matched by an inflow of foreign investment.
In the late 1970s and early 1980s, the U.S. had experienced high inflation and Friedman's policy positions tended to defend the stronger dollar at that time. He stated his belief that these trade deficits were not necessarily harmful to the economy at the time since the currency comes back to the country (country A sells to country B, country B sells to country C who buys from country A, but the trade deficit only includes A and B). However, it may be in one form or another including the possible tradeoff of foreign control of assets. In his view, the "worst-case scenario" of the currency never returning to the country of origin was actually the best possible outcome: the country actually purchased its goods by exchanging them for pieces of cheaply made paper. As Friedman put it, this would be the same result as if the exporting country burned the dollars it earned, never returning it to market circulation.
This position is a more refined version of the theorem first discovered by David Hume. Hume argued that England could not permanently gain from exports, because hoarding gold (i.e., currency) would make gold more plentiful in England; therefore, the prices of English goods would rise, making them less attractive exports and making foreign goods more attractive imports. In this way, countries' trade balances would balance out.
Friedman believed that deficits would be corrected by free markets as floating currency rates rise or fall with time to encourage or discourage imports in favor of the exports, reversing again in favor of imports as the currency gains strength. In the real world, a potential difficulty is that currency markets are far from a free market, with government and central banks being major players, and this is unlikely to change within the foreseeable future. Nevertheless, recent developments have shown that the global economy is undergoing a fundamental shift. For many years, the U.S. has borrowed and bought while in general, the rest of the world has lent and sold.
As of October 2007, the U.S. dollar weakened against the euro, British pound, and many other currencies. For instance, the euro hit $1.42 in October 2007, the strongest it has been since its birth in 1999. Against this backdrop, American exporters are finding quite favorable overseas markets for their products and U.S. consumers are responding to their general housing slowdown by slowing their spending. Furthermore, China, the Middle East, central Europe and Africa are absorbing more of the world's imports which in the end may result in a world economy that is more evenly balanced. All of this could well add up to a major readjustment of the U.S. trade deficit, which as a percentage of GDP, began in 1991.
Friedman contended that the structure of the balance of payments was misleading. In an interview with Charlie Rose, he stated that "on the books" the US is a net borrower of funds, using those funds to pay for goods and services. He essentially claimed that the foreign assets were not carried on the books at their higher, truer value.
Friedman presented his analysis of the balance of trade in "Free to Choose", widely considered his most significant popular work.
Trade balances affects upon their nations economies.
Annual trade surpluses are immediate and direct additions to their nations’ GDPs. To some extent, exports induce additional increases to GDP that are not reflected within the export products’ prices; thus contributions to GDP from trade surpluses are generally understated.
Products’ prices generally reflect their producers’ production supporting expenditures. Producers often benefit from some production supporting goods and services at lesser or no cost to the producers.
For example, governments may deliberately locate or increase the capacity of their infrastructure, or provide other additional considerations to retain or attract producers within their own jurisdictions. The curriculum of a nation's schools and colleges may provide job applicants specifically suited to the producer’s needs, or provide specialized research and development.
All national factors of production, including education, contribute to GDP, and unless globally traded products fully reflect those goods and services, these other export supporting contributions are not entirely identified and attributed to their nations’ global trade.
Annual trade deficits are immediate and indirect drags upon their nations’ GDPs. That drag is due to the drags upon the nation's production, numbers of jobs and wage rates.
Trade deficits make no net contribution to their nations’ GDPs but the importing nations indirectly deny themselves of the benefits earned by producing nations; (refer to “Annual trade surpluses are immediate and direct additions to their nations’ GDPs”).
Among what’s being denied is familiarity with methods, practices, the manipulation of tools, materials and fabrication processes.
The economic differences between domestic and imported goods occur prior to the goods entry within the final purchasers' nations. After domestic goods have reached their producers shipping dock or imported goods have been unloaded on to the importing nation’s cargo vessel or entry port’s dock, similar goods have similar economic attributes.
Although supporting products not reflected within the prices of specific items are all captured within the producing nation’s GDP, those supporting but not reflected within prices of globally traded goods are not attributed to nations' global trade. Trade surpluses' contributions and trade deficits' detriments to their nation's GDPs are understated. The entire benefits of production are earned by the exporting nations and denied to the importing nation.

</doc>
<doc id="4816" url="https://en.wikipedia.org/wiki?curid=4816" title="Biosphere">
Biosphere

The biosphere is the global sum of all ecosystems. It can also be termed as the zone of life on Earth, a closed system (apart from solar and cosmic radiation and heat from the interior 
of the Earth), and largely self-regulating. By the most general biophysiological definition, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere, geosphere, hydrosphere, and atmosphere. The biosphere is postulated to have evolved, beginning with a process of biopoesis (life created naturally from non-living matter, such as simple organic compounds) or biogenesis (life created from living matter), at least some 3.5 billion years ago. The earliest evidence for life on Earth includes biogenic graphite found in 3.7 billion-year-old metasedimentary rocks from Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone from Western Australia. More recently, in 2015, "remains of biotic life" were found in 4.1 billion-year-old rocks in Western Australia. According to one of the researchers, "If life arose relatively quickly on Earth ... then it could be common in the universe."
In a general sense, biospheres are any closed, self-regulating systems containing ecosystems. This includes artificial biospheres such as Biosphere 2 and BIOS-3, and potentially ones on other planets or moons.
Origin and use of the term.
The term "biosphere" was coined by geologist Eduard Suess in 1875, which he defined as the place on Earth's surface where life dwells.
While the concept has a geological origin, it is an indication of the effect of both Charles Darwin and Matthew F. Maury on the Earth sciences. The biosphere's ecological context comes from the 1920s (see Vladimir I. Vernadsky), preceding the 1935 introduction of the term "ecosystem" by Sir Arthur Tansley (see ecology history). Vernadsky defined ecology as the science of the biosphere. It is an interdisciplinary concept for integrating astronomy, geophysics, meteorology, biogeography, evolution, geology, geochemistry, hydrology and, generally speaking, all life and Earth sciences.
Narrow definition.
Geochemists define the biosphere as being the total sum of living organisms (the "biomass" or "biota" as referred to by biologists and ecologists). In this sense, the biosphere is but one of four separate components of the geochemical model, the other three being "lithosphere", "hydrosphere", and "atmosphere". The word "ecosphere", coined during the 1960s, encompasses both biological and physical components of the planet.
The Second International Conference on Closed Life Systems defined "biospherics" as the science and technology of analogs and models of Earth's biosphere; i.e., artificial Earth-like biospheres. Others may include the creation of artificial non-Earth biospheres—for example, human-centered biospheres or a native Martian biosphere—as part of the topic of biospherics.
Extent of Earth's biosphere.
Every part of the planet, from the polar ice caps to the equator, features life of some kind. Recent advances in microbiology have demonstrated that microbes live deep beneath the Earth's terrestrial surface, and that the total mass of microbial life in so-called "uninhabitable zones" may, in biomass, exceed all animal and plant life on the surface. The actual thickness of the biosphere on earth is difficult to measure. Birds typically fly at altitudes as high as and fish live as much as underwater in the Puerto Rico Trench.
There are more extreme examples for life on the planet: Rüppell's vulture has been found at altitudes of ; bar-headed geese migrate at altitudes of at least ; yaks live at elevations as high as above sea level; mountain goats live up to . Herbivorous animals at these elevations depend on lichens, grasses, and herbs.
Microscopic organisms live in every part of the biosphere, including soil, hot springs, "seven miles deep" in the ocean, "40 miles high" in the atmosphere and inside rocks far down within the Earth's crust (see also endolith). Microorganisms, under certain test conditions, have been observed to thrive in the vacuum of outer space. The total amount of soil and subsurface bacterial carbon is estimated as 5 x 1017 g, or the "weight of the United Kingdom". The mass of prokaryote microorganisms — which includes bacteria and archaea, but not the nucleated eukaryote microorganisms — may be as much as 0.8 trillion tons of carbon (of the total biosphere mass, estimated at between 1 and 4 trillion tons). Barophilic marine microbes have been found at more than a depth of in the Mariana Trench, the deepest spot in the Earth's oceans. In fact, single-celled life forms have been found in the deepest part of the Mariana Trench, by the Challenger Deep, at depths of . Other researchers reported related studies that microorganisms thrive inside rocks up to below the sea floor under of ocean off the coast of the northwestern United States, as well as beneath the seabed off Japan. Culturable thermophilic microbes have been extracted from cores drilled more than into the Earth's crust in Sweden, from rocks between . Temperature increases with increasing depth into the Earth's crust. The rate at which the temperature increases depends on many factors, including type of crust (continental vs. oceanic), rock type, geographic location, etc. The greatest known temperature at which microbial life can exist is ("Methanopyrus kandleri" Strain 116), and it is likely that the limit of life in the "deep biosphere" is defined by temperature rather than absolute depth. On 20 August 2014, scientists confirmed the existence of microorganisms living below the ice of Antarctica. According to one researcher, "You can find microbes everywhere — they're extremely adaptable to conditions, and survive wherever they are."
Our biosphere is divided into a number of biomes, inhabited by fairly similar flora and fauna. On land, biomes are separated primarily by latitude. Terrestrial biomes lying within the Arctic and Antarctic Circles are relatively barren of plant and animal life, while most of the more populous biomes lie near the equator. 
Specific biospheres.
For this list, if a word is followed by a number, it is usually referring to a specific system or number. Thus:
Extraterrestrial biospheres.
No biospheres have been detected beyond the Earth; therefore, the existence of extraterrestrial biospheres remains hypothetical. The rare Earth hypothesis suggests they should be very rare, save ones composed of microbial life only. On the other hand, Earth analogs may be quite numerous, at least in the Milky Way galaxy. Given limited understanding of abiogenesis, it is currently unknown what percentage of these planets actually develop biospheres.
It is also possible that artificial biospheres will be created during the future, for example on Mars. The process of creating an uncontained system that mimics the function of Earth's biosphere is called terraforming.

</doc>
<doc id="4817" url="https://en.wikipedia.org/wiki?curid=4817" title="Biological membrane">
Biological membrane

A biological membrane or biomembrane is an enclosing or separating membrane that acts as a selectively permeable barrier within living things. Biological membranes, in the form of cell membranes, often consist of a phospholipid bilayer with embedded, integral and peripheral proteins used in communication and transportation of chemicals and ions. Bulk lipid in membrane provides a fluid matrix for proteins to rotate and laterally diffuse for physiological functioning. Proteins are adapted to high membrane fluidity environment of lipid bilayer with the presence of an annular lipid shell, consisting of lipid molecules bound tightly to surface of integral membrane proteins. The cellular membranes should not be confused with isolating tissues formed by layers of cells, such as mucous membranes and basement membranes.
Composition.
Asymmetry.
• Both the plasma membrane and internal membranes have cytosolic and exoplasmic faces
• This orientation is maintained during membrane trafficking – proteins, lipids, glycoconjugates facing the lumen of the ER and Golgi get expressed on the extracellular side of the plasma membrane
Lipids.
The biological membrane is made up of lipids with hydrophobic tails and hydrophilic heads. The hydrophobic tails are hydrocarbon tails whose length and saturation is important in characterizing the cell. Lipid rafts occur when lipid species and proteins aggregate in domains in the membrane. These help organize membrane components into localized areas that are involved in specific processes, such as signal transduction.
Red blood cells, or erythrocytes, have a unique lipid composition. The bilayer of red blood cells is composed of cholesterol and phospholipids in equal proportions by weight. Erythrocyte membrane plays a crucial role in blood clotting. In the bilayer of red blood cells is phosphatidylserine. This is usually in the cytoplasmic side of the membrane. However, it is flipped to the outer membrane to be used during blood clotting.
Proteins.
Phospholipid bilayers contain different proteins. These membrane proteins have various functions and characteristics and catalyze different chemical reactions. Integral proteins span the membranes with different domains on either side. Integral proteins hold strong association with the lipid bilayer and cannot easily become detached. They will dissociate only with chemical treatment that breaks the membrane. Peripheral proteins are unlike integral proteins in that they hold weak interactions with the surface of the bilayer and can easily become dissociated from the membrane. Peripheral proteins are located on only one face of a membrane and create membrane asymmetry.
Oligosaccharides.
Oligosaccharides are sugar containing polymers. In the membrane, they can be covalently bound to lipids to form glycolipids or covalently bound to proteins to form glycoproteins. Membranes contain sugar-containing lipid molecules known as glycolipids. In the bilayer, the sugar groups of glycolipids are exposed at the cell surface, where they can form hydrogen bonds. Glycolipids provide the most extreme example of asymmetry in the lipid bilayer. Glycolipids perform a vast number of functions in the biological membrane that are mainly communicative, including cell recognition and cell-cell adhesion. Glycoproteins are integral proteins. They play an important role in the immune response and protection.
Formation.
The phospholipid bilayer is formed due to the aggregation of membrane lipids in aqueous solutions. Aggregating is caused by the hydrophobic effect, where hydrophobic ends come into contact with each other and are sequestered away from water and hydrophilic ends are in contact with it. Less water is allowed to interact with the hydrophobic ends and, therefore, hydrogen bonding between hydrophilic heads and water is increased. This creates a favorable molecular arrangement by reducing unfavorable contact between hydrophobic tails and water and increasing hydrogen bonding between the hydrophilic heads and water. The increase in available hydrogen bonding increases the entropy of the system, creating a spontaneous process. Aggregation of non polar substances in water is, therefore, entropically driven and spontaneously occurring. The aggregation formed due to the hydrophobic effect is partially responsible for the shape of biological membranes.
Function.
Biological molecules are amphiphilic or amphipathic, i.e. are simultaneously hydrophobic and hydrophilic. The phospholipid bilayer contains charged hydrophilic headgroups, which interact with polar water. The lipids also contain hydrophobic tails, which meet with the hydrophobic tails of the complementary layer. The hydrophobic tails are usually fatty acids that differ in lengths. The interactions of lipids, especially the hydrophobic tails, determine the lipid bilayer physical properties such as fluidity.
Membranes in cells typically define enclosed spaces or compartments in which cells may maintain a chemical or biochemical environment that differs from the outside. For example, the membrane around peroxisomes shields the rest of the cell from peroxides, chemicals that can be toxic to the cell, and the cell membrane separates a cell from its surrounding medium. Peroxisomes are one form of vacuole found in the cell that contain by-products of chemical reactions within the cell. Most organelles are defined by such membranes, and are called "membrane-bound" organelles.
Selective Permeability.
Probably the most important feature of a biomembrane is that it is a selectively permeable structure. This means that the size, charge, and other chemical properties of the atoms and molecules attempting to cross it will determine whether they succeed in doing so. Selective permeability is essential for effective separation of a cell or organelle from its surroundings. Biological membranes also have certain mechanical or elastic properties that allow them to change shape and move as required.
Generally, small hydrophobic molecules can readily cross phospholipid bilayers by simple diffusion.
Particles that are required for cellular function but are unable to diffuse freely across a membrane enter through a membrane transport protein or are taken in by means of endocytosis, where the membrane allows for a vacuole to join onto it and push its contents into the cell. Many types of specialized plasma membranes can separate cell from external environment: apical, basolateral, presynaptic and postsynaptic ones, membranes of flagella, cilia, microvillus, filopodia and lamellipodia, the sarcolemma of muscle cells, as well as specialized myelin and dendritic spine membranes of neurons. Plasma membranes can also form different types of "supramembrane" structures such as caveola, postsynaptic density, podosome, invadopodium, desmosome, hemidesmosome, focal adhesion, and cell junctions. These types of membranes differ in lipid and protein composition.
Distinct types of membranes also create intracellular organelles: endosome; smooth and rough endoplasmic reticulum; sarcoplasmic reticulum; Golgi apparatus; lysosome; mitochondrion (inner and outer membranes); nucleus (inner and outer membranes); peroxisome; vacuole; cytoplasmic granules; cell vesicles (phagosome, autophagosome, clathrin-coated vesicles, COPI-coated and COPII-coated vesicles) and secretory vesicles (including synaptosome, acrosomes, melanosomes, and chromaffin granules).
Different types of biological membranes have diverse lipid and protein compositions. The content of membranes defines their physical and biological properties. Some components of membranes play a key role in medicine, such as the efflux pumps that pump drugs out of a cell.
Fluidity.
The hydrophobic core of the phospholipid bilayer is constantly in motion because of rotations around the bonds of lipid tails. Hydrophobic tails of a bilayer bend and lock together. However, because of hydrogen bonding with water, the hydrophilic head groups exhibit less movement as their rotation and mobility are constrained. This results in increasing viscosity of the lipid bilayer closer to the hydrophilic heads.
Below a transition temperature, a lipid bilayer loses fluidity when the highly mobile lipids exhibits less movement becoming a gel-like solid. The transition temperature depends on such components of the lipid bilayer as the hydrocarbon chain length and the saturation of its fatty acids. Temperature-dependence fluidity constitutes an important physiological attribute for bacteria and cold-blooded organisms. These organisms maintain a constant fluidity by modifying membrane lipid fatty acid composition in accordance with differing temperatures.

</doc>
<doc id="4819" url="https://en.wikipedia.org/wiki?curid=4819" title="Balfour Declaration of 1926">
Balfour Declaration of 1926

The Balfour Declaration of 1926, issued by the 1926 Imperial Conference of British Empire leaders in London, was named for Lord President of the Council (and former Prime Minister of the United Kingdom) Arthur Balfour. It declared the United Kingdom and the Dominions to be
The Inter-Imperial Relations Committee, chaired by Balfour, drew up the document preparatory to its unanimous approval by the imperial premiers on 15 November 1926. It was first proposed by South African Prime Minister J. B. M. Hertzog and Canada's Prime Minister at that time, William Lyon Mackenzie King.
The Declaration accepted the growing political and diplomatic independence of the Dominions, in the years after World War I. It also recommended that the governors-general, the representatives of the King who acted for the Crown as "de facto" head of state in each dominion, should no longer also serve automatically as the representative of the British government in diplomatic relations between the countries. In following years, High Commissioners were gradually appointed, whose duties were soon recognised to be virtually identical to those of an ambassador. The first such British High Commissioner was appointed to Ottawa in 1928.
The conclusions of the imperial premiers conference of 1926 were restated by the 1930 conference and incorporated in the Statute of Westminster of December 1931, by which the British parliament renounced any legislative authority over dominion affairs, except as specifically provided in law.

</doc>
<doc id="4820" url="https://en.wikipedia.org/wiki?curid=4820" title="Balfour Declaration">
Balfour Declaration

The Balfour Declaration was a letter dated 2 November 1917 from the United Kingdom's Foreign Secretary Arthur James Balfour to Walter Rothschild, 2nd Baron Rothschild, a leader of the British Jewish community, for transmission to the Zionist Federation of Great Britain and Ireland. It read:
The text of the letter was published in the press one week later, on 9 November 1917. The "Balfour Declaration" was later incorporated into both the Sèvres peace treaty with the Ottoman Empire, and the Mandate for Palestine. The original document is kept at the British Library. The declaration was in contrast to the McMahon-Hussein correspondence, which promised the Arab independence movement control of the Middle East territories "in the limits and boundaries proposed by the Sherif of Mecca" in exchange for revolting against the Ottoman Empire during World War I.
The issuance of the Declaration had many long lasting consequences, and was a key moment in the lead-up to the Arab–Israeli conflict, often referred to as the world's "most intractable conflict".
Background.
The background of British support under Balfour for a Jewish homeland in Palestine, though idealistically embedded in 19th-century evangelical expectations and Christian feelings that England was to play a role in the Advent of the Millennium and Christ's Second Coming, was primarily linked to geopolitical calculations. These were originally precipitated by the Eastern Crisis after Muhammad Ali occupied Syria and Palestine. With the geopolitical shakeup occasioned by the outbreak of WWI, the earlier calculations, that had lapsed for some time—Theodor Herzl's own attempts earlier to obtain international support for his project had failed—led to a renewal of strategic assessments and political bargaining regarding the Middle and Far East.
Early Zionism.
Zionism arose in the late 19th century in reaction to anti-Semitic and exclusionary nationalist movements in Europe. Romantic nationalism in 19th century Central and Eastern Europe had helped to set off the Haskalah or "Jewish Enlightenment", creating a split in the Jewish community between those who saw Judaism as their religion, and those who saw it as their ethnicity or nation. The 1881-84 Anti-Jewish pogroms in the Russian Empire encouraged the growth of the latter identity, resulting in the formation of the Hovevei Zion pioneer organizations and the publication of Leon Pinsker's "Autoemancipation".
In 1896, Theodor Herzl, a Jewish journalist living in Austria-Hungary, published "Der Judenstaat" ("The Jews' State" or "The State of the Jews"), in which he asserted that the only solution to the "Jewish Question" in Europe, including growing antisemitism, was through the establishment of a state for the Jews. This marked the emergence of political Zionism. A year later, Herzl founded the Zionist Organization (ZO), which at its first congress called for "the establishment of a home for the Jewish people in Palestine secured under public law". Proposed measures to attain that goal included the promotion of Jewish settlement there, the organisation of Jews in the diaspora, the strengthening of Jewish feeling and consciousness, and preparatory steps to attain those necessary governmental grants. Herzl died in 1904 without the political standing that was required to carry out his agenda of a Jewish home in Palestine.
Zionist leader Chaim Weizmann, later President of the World Zionist Organisation, began living in the UK in 1904 and met Balfour during his 1905-06 election campaign in a session arranged by Charles Dreyfus, his Jewish constituency representative.
During the first meeting between Weizmann and Balfour in 1906, Balfour asked what Weizmann's objections were to the 1903 Uganda Scheme. The scheme, which had been proposed to Herzl by Colonial Secretary Joseph Chamberlain following his trip to East Africa earlier in the year, had been subsequently voted down following Herzl's death by the Seventh Zionist Congress in 1905, after two years of heated debate in the Zionist Organization. According to Weizmann's memoir, the conversation went as follows:
World War I.
In 1914, war broke out in Europe between the Triple Entente (Britain, France and the Russian Empire) and the Central Powers (Germany, Austria-Hungary and later that year, the Ottoman Empire).
Following Britain's declaration of war on the Ottoman Empire in November 1914, Weizmann's efforts picked up speed. On 10 December 1914 he met with the British cabinet member Herbert Samuel, a Zionist, who believed Weizmann's demands were too modest. Two days later, Weizmann met Balfour again, for the first time since 1906. A month later, Herbert Samuel circulated a memorandum entitled "The Future of Palestine" to his cabinet colleagues. The memorandum stated that "I am assured that the solution of the problem of Palestine which would be much the most welcome to the leaders and supporters of the Zionist movement throughout the world would be the annexation of the country to the British Empire". Many further discussions followed, including a meeting between Lloyd-George and Weizmann in 1916, of which Lloyd-George described in his "War Memoirs" that Weizmann: "... explained his aspirations as to the repatriation of the Jews to the sacred land they had made famous. That was the fount and origin of the famous declaration about the National Home for the Jews in Palestine... As soon as I became Prime Minister I talked the whole matter over with Mr Balfour, who was then Foreign Secretary."
The McMahon–Hussein Correspondence.
In 1915 the British High Commissioner to Egypt, Henry McMahon, had exchanged letters with Hussein bin Ali, Sharif of Mecca, in which he had promised Hussein control of Arab lands with the exception of "portions of Syria" lying to the west of "the districts of Damascus, Homs, Hama and Aleppo". Palestine lay to the southwest of the Vilayet of Damascus and wasn't explicitly mentioned. After the war the extent of the coastal exclusion was hotly disputed.
On the basis of McMahon's assurances, the Arab Revolt began on 5 June 1916. However, the British and French also secretly concluded the Sykes–Picot Agreement on 16 May 1916. This agreement divided many Arab territories into British- and French-administered areas and allowed for the internationalisation of Palestine. Hussein learned of the agreement when it was leaked by the new Soviet government in December 1917, but was satisfied by two disingenuous telegrams from Sir Reginald Wingate, High Commissioner of Egypt, assuring him that the British government's commitments to the Arabs were still valid and that the Sykes-Picot Agreement was not a formal treaty.
Following the publication of the Declaration the British had dispatched Commander David George Hogarth to see Hussein in January 1918 bearing the message that the "political and economic freedom" of the Palestinian population was not in question. Hogarth reported that Hussein "would not accept an independent Jewish State in Palestine, nor was I instructed to warn him that such a state was contemplated by Great Britain". Continuing Arab disquiet over Allied intentions also led during 1918 to the British Declaration to the Seven and the Anglo-French Declaration, the latter promising "the complete and final liberation of the peoples who have for so long been oppressed by the Turks, and the setting up of national governments and administrations deriving their authority from the free exercise of the initiative and choice of the indigenous populations."
Lord Grey had been the Foreign Secretary during the McMahon-Hussein negotiations. Speaking in the House of Lords on 27 March 1923, he made it clear that he entertained serious doubts as to the validity of the British government's interpretation of the pledges which he, as foreign secretary, had caused to be given to Hussein in 1915. He called for all of the secret engagements regarding Palestine to be made public. Many of the relevant documents in the National Archives were later declassified and published. Among them were the minutes of a Cabinet Eastern Committee meeting, chaired by Lord Curzon, which was held on 5 December 1918. Balfour was in attendance. The minutes revealed that in laying out the government's position Curzon had explained that:Palestine was included in the areas as to which Great Britain pledged itself that they should be Arab and independent in the future.
Sykes–Picot Agreement.
In May 1916 the governments of the United Kingdom, France and Russia signed the Sykes–Picot Agreement, which defined their proposed spheres of influence and control in Western Asia should the Triple Entente succeed in defeating the Ottoman Empire during World War I. The agreement effectively divided the Arab provinces of the Ottoman Empire outside the Arabian peninsula into areas of future British and French control or influence.
The agreement proposed that an "international administration" would be established in an area shaded brown on the agreement's map, which was later to become Palestine, and that the form of the administration would be confirmed after consultation with both Russia and Hussein. Three months prior to the agreement of the memorandum, Sykes has been approached with a plan by Herbert Samuel in the form of a memorandum which Sykes thought prudent to commit to memory. Sykes commented to Samuel on the boundaries marked on a map attached to the memorandum, noting that the exclusion of Hebron and the "East of the Jordan" there would be less to discuss with the Muslim community.
Motivation for the Declaration.
Academic interpretations.
The war on the Western Front developed into a stalemate by 1917. The immediate effect of Balfour's declaration, initially a mere declaration of intent, had little effect on the military sphere, but there were larger geopolitical calculations, some visible in Lloyd George's list of nine factors motivating his decision as Prime Minister to release the declaration, not least of which the view that a Jewish presence in Palestine would strengthen Britain's position on the Suez Canal and reinforce the route to Great Britain's imperial dominion in India. Weizmann had argued that one consequence of such a public commitment by Great Britain, making the establishment of a Jewish homeland in Palestine, one of the Allies' war aims, was that it would have three effects: it would swing Russia to maintain pressure on Germany's Eastern Front, since Jews had been prominent in the March Revolution of 1917. It would rally the large Jewish community in the United States to press for greater funding for the American war effort, underway since April of that year; and, lastly, that it would undermine German Jewish support for Kaiser Wilhelm II. Some historians argue that British government's decision reflected what James Gelvin calls 'patrician anti-Semitism' in the overestimation of Jewish power in both the United States and Russia.
Gelvin cites at least three reasons for why the British government chose to support Zionist aspirations. Issuing the Balfour Declaration would appeal to two of Woodrow Wilson's closest advisors, who were avid Zionists.
The British did not know quite what to make of President Woodrow Wilson and his conviction (before America's entrance into the war) that the way to end hostilities was for both sides to accept "peace without victory." Two of Wilson's closest advisors, Louis Brandeis and Felix Frankfurter, were avid Zionists. How better to shore up an uncertain ally than by endorsing Zionist aims? The British adopted similar thinking when it came to the Russians, who were in the midst of their revolution. Several of the most prominent revolutionaries, including Leon Trotsky, were of Jewish descent. Why not see if they could be persuaded to keep Russia in the war by appealing to their latent Jewishness and giving them another reason to continue the fight? ... These include not only those already mentioned but also Britain's desire to attract Jewish financial resources.
Jonathan Schneer writes:
Thus the view from Whitehall early in 1916: If defeat was not imminent, neither was victory; and the outcome of the war of attrition on the Western Front could not be predicted. The colossal forces in a death-grip across Europe and in Eurasia appeared to have canceled each other out. Only the addition of significant new forces on one side or the other seemed likely to tip the scale. Britain's willingness, beginning early in 1916, to explore seriously some kind of arrangement with "world Jewry" or "Great Jewry" must be understood in this context.
At a War Cabinet meeting, held on 31 October 1917, Balfour suggested that a declaration favourable to Zionist aspirations would allow Great Britain "to carry on extremely useful propaganda both in Russia and America." The cabinet believed that expressing support would appeal to Jews in Germany and America, and help the war effort; they also hoped to encourage support from the large Jewish population in Russia.
According to James Renton, Senior Lecturer at Edge Hill University, and author of "The Zionist Masquerade: the Birth of the Anglo-Zionist Alliance: 1914–1918", Prime Minister David Lloyd George of the United Kingdom supported the creation of a Jewish homeland in Palestine because "it would help secure post-war British control of Palestine, which was strategically important as a buffer to Egypt and the Suez Canal."
American Zionism was still in its relative infancy; in 1914 the Zionist Federation had a small budget of $5,000 and only 12,000 members, despite an American Jewish population of three million. However, the Zionist organizations had recently succeeded in a show of force within the American Jewish community in arranging a Jewish congress to debate the Jewish problem as a whole. This impacted British and French government estimates of the balance of power within the American Jewish public.
In addition, the British intended to preempt the expected French pressure for an international administration.
Prime Minister Lloyd-George's explanations.
David Lloyd George, who was Prime Minister at the time of the Balfour Declaration, told the Palestine Royal Commission in 1937 that the Declaration was made "due to propagandist reasons." Citing the position of the Allied and Associated Powers in the ongoing war, Lloyd George said, in the Report's words:
In this critical situation it was believed that Jewish sympathy or the reverse would make a substantial difference one way or the other to the Allied cause. In particular Jewish sympathy would confirm the support of American Jewry, and would make it more difficult for Germany to reduce her military commitments and improve her economic position on the eastern front... The Zionist leaders gave us a definite promise that, if the Allies committed themselves to giving facilities for the establishment of a national home for the Jews in Palestine, they would do their best to rally Jewish sentiment and support throughout the world to the Allied cause. They kept their word.
In his "Memoirs", published in 1939, Lloyd George further elucidated his position:
The Balfour Declaration represented the convinced policy of all parties in our country and also in America, but the launching of it in 1917 was due, as I have said, to propagandist reasons... The Zionist Movement was exceptionally strong in Russia and America... It was believed, also, that such a declaration would have a potent influence upon world Jewry outside Russia, and secure for the Entente the aid of Jewish financial interests. In America, their aid in this respect would have a special value when the Allies had almost exhausted the gold and marketable securities available for American purchases. Such were the chief considerations which, in 1917, impelled the British Government towards making a contract with Jewry.
Drafting.
Authors and evolution of the draft.
Under the new Conservative government which took power in October 1922, attempts were made to identify the background to the drafting. In December 1922, Sir John Evelyn Shuckburgh of the new Middle East department of the Foreign Office discovered that the correspondence prior to the declaration was not available in the Colonial Office, 'although Foreign Office papers were understood to have been lengthy and to have covered a considerable period'. A Foreign Office note in a Cabinet Paper from January 1923 stated that:little is known of how the policy represented by the Declaration was first given form. Four, or perhaps five men were chiefly concerned in the labour – the Earl of Balfour, the late Sir Mark Sykes, and Messrs. Weizmann and Sokolow, with perhaps Lord Rothschild as a figure in the background. Negotiations seem to have been mainly oral and by means of private notes and memoranda of which only the scantiest records seem to be available.
Declassification of Government archives have allowed modern scholarship to piece together the choreography of the drafting of the declaration. In his widely cited 1961 book, Leonard Stein published four previous drafts of the declaration. Stein illustrated the evolution of the drafting from the original proposal by the Zionist Organization, followed by various iterations. Subsequent authors have debated as to who the "primary author" really was. In his posthumously published 1981 book "The Anglo-American Establishment", Georgetown University history professor Carroll Quigley explained his view that the primary author of the declaration was Alfred, Lord Milner, and more recently, William D. Rubinstein, Professor of Modern History at Aberystwyth University, Wales, wrote that Conservative politician and pro-Zionist Leo Amery, as Assistant Secretary to the British war cabinet in 1917, was the main author of the Balfour Declaration.
Jewish national home vs. Jewish state.
The term "national home" in the Declaration was intentionally ambiguous. For example, the phrase 'national homeland' had no legal value or precedent in international law, so its meaning was thus unclear when compared to other terms such as 'state'. The choice of stating such a homeland would be found 'in Palestine' rather than 'of Palestine' was also no accident. Explication of the wording has been sought in the correspondence leading to the final version of the declaration. The phrase "national home" was intentionally used instead of "state" because of opposition to the Zionist program within the British Cabinet. Following discussion of the initial draft the Cabinet Secretary, Mark Sykes, met with the Zionist negotiators to clarify their aims. His official report back to the Cabinet categorically stated that the Zionists did not want "to set up a Jewish Republic or any other form of state in Palestine immediately" but rather preferred some form of protectorate as provided in the Palestine Mandate.
In approving the Balfour Declaration, Leopold Amery, one of the Secretaries to the British War Cabinet of 1917–18, testified under oath to the Anglo-American Committee of Inquiry in January 1946 from his personal knowledge that:
"The phrase 'the establishment in Palestine of a National Home for the Jewish people' was intended and understood by all concerned to mean at the time of the Balfour Declaration that Palestine would ultimately become a 'Jewish Commonwealth' or a 'Jewish State', if only Jews came and settled there in sufficient numbers."
David Lloyd George, who was Prime Minister at the time of the Balfour Declaration, told the Palestine Royal Commission in 1937 that it was intended that Palestine may become a Jewish Commonwealth if and when Jews "had become a definite majority of the inhabitants":
The idea was, and this was the interpretation put upon it at the time, that a Jewish State was not to be set up immediately by the Peace Treaty without reference to the wishes of the majority of the inhabitants. On the other hand, it was contemplated that when the time arrived for according representative institutions to Palestine, if the Jews had meanwhile responded to the opportunity afforded them by the idea of a national home and had become a definite majority of the inhabitants, then Palestine would thus become a Jewish Commonwealth.
Both the Zionist Organization and the British government devoted efforts to denying that a state was the intention over the following decades, including in Winston Churchill's 1922 White Paper. However, in private, many British officials agreed with the interpretation of the Zionists that a state would be established when a Jewish majority was achieved; in particular, at a private meeting on 22 July 1922 at Balfour's home, both Balfour and Lloyd-George admitted that an eventual Jewish state had always been their intention.
The initial draft of the declaration, contained in a letter sent by Rothschild to Balfour, referred to the principle ""that Palestine should be reconstituted as the National Home of the Jewish people."" In the final text, the word "that" was replaced with "in" to avoid committing the entirety of Palestine to this purpose. Similarly, the original drafts of Rothschild, Balfour and Milner did not include the commitment that nothing should be done which might prejudice the rights of the non-Jewish communities. These changes came about partly as the result of the urgings of Edwin Samuel Montagu, an influential anti-Zionist Jew and Secretary of State for India. Montagu, the only Jewish member of the British cabinet, voiced his opposition by declaring:
'The policy of His Majesty's Government is anti-Semitic in result and will prove a rallying ground for anti-Semites in every country of the world.'
The draft was circulated and during October the government received replies from various representatives of the Jewish community. Lord Rothschild took exception to the new proviso on the basis that it presupposed the possibility of a danger to non-Zionists, which he denied. At San Remo, as shown in the transcript of the San Remo meeting on the evening of 24 April, the French proposed adding to the savings clause so that it would save for non-Jewish communities their "political rights" as well as their civil and religious rights. The French proposal was rejected.
Reaction to the Declaration.
Arab opposition.
A delegation of the Muslim-Christian Association, headed by Musa al-Husayni, expressed public disapproval on 3 November 1918, one day after the Zionist Commission parade marking the first anniversary of the Balfour Declaration. They handed a petition signed by more than 100 notables to Ronald Storrs, the OETA military governor:
We have noticed yesterday a large crowd of Jews carrying banners and over-running the streets shouting words which hurt the feeling and wound the soul. They pretend with open voice that Palestine, which is the Holy Land of our fathers and the graveyard of our ancestors, which has been inhabited by the Arabs for long ages, who loved it and died in defending it, is now a national home for them... We Arabs, Muslim and Christian, have always sympathized profoundly with the persecuted Jews and their misfortunes in other countries... but there is wide difference between such sympathy and the acceptance of such a nation...ruling over us and disposing of our affairs.
The group also protested the carrying of new "white and blue banners with two inverted triangles in the middle", drawing the attention of the British authorities to the serious consequences of any political implications in raising the banners.
Balfour's stance was seen as a betrayal of British understandings with Arabs. Later that month, on the first anniversary of the occupation of Jaffa by the British, the Muslim-Christian Association sent a lengthy memorandum and petition to the military governor protesting once more any formation of a Jewish state.
Zionist reaction.
The publication of the intent galvanized Zionism, which finally had obtained an official charter. In the ongoing Sinai and Palestine Campaign, both Gaza and Jaffa fell within several days. Once under British military occupation, large transfers of funds were possible, and a major effort began to drain the marshy land of the Valley of Jezreel, whose redemption as the breadbasket of Palestine became the priority of the Third Aliyah settlers, mainly from Eastern Europe.
Chaim Weizmann and Nahum Sokolow, the principal Zionist leaders based in London, had asked for the reconstitution of Palestine as "the" Jewish national home. As such, the declaration fell short of Zionist expectations.
The declaration spurred an extraordinary increase in adherents of American Zionism; in 1914 the 200 American Zionist societies comprised a total of 7,500 members, which grew to 30,000 members in 600 societies in 1918 and 149,000 members in 1919.
Response by Central Powers.
Immediately following the publication of the declaration Germany entered negotiations with Turkey to put forward counter proposals. A German-Jewish Society was formed: "Vereinigung jüdischer Organisationen Deutschlands zur Wahrung der Rechte der Juden des Ostens" (V.J.O.D.) and in January 1918 the Turkish Grand Vizier, Talaat, issued a statement which promised legislation by which "all justifiable wishes of the Jews in Palestine would be able to find their fulfilment".
Evolution of British opinion.
In October 1919, Lord Curzon succeeded Balfour as Foreign Secretary. Curzon had opposed the Declaration prior to its publication and therefore determined to pursue a policy in line with its "narrower and more prudent rather than the wider interpretation". Following Bonar Law's appointment as Prime Minister in late 1922, Curzon wrote to Bonar Law that he regarded the Balfour Declaration as "the worst" of Britain's Middle East commitments and "a striking contradiction of our publicly declared principles."
In August 1920, the report of the Palin Commission, the first in a long line of Commissions of Inquiry on the question of Palestine during the Mandate period, noted that "The Balfour Declaration... is undoubtedly the starting point of the whole trouble". The conclusion of the report mentioned the Balfour Declaration three times, stating that "the causes of the alienation and exasperation of the feelings of the population of Palestine" included:
British public and government opinion became increasingly less favourable to the commitment that had been made to Zionist policy. In February 1922, Winston Churchill telegraphed Herbert Samuel asking for cuts in expenditure and noting:In both Houses of Parliament there is growing movement of hostility, against Zionist policy in Palestine, which will be stimulated by recent Northcliffe articles. I do not attach undue importance to this movement, but it is increasingly difficult to meet the argument that it is unfair to ask the British taxpayer, already overwhelmed with taxation, to bear the cost of imposing on Palestine an unpopular policy.
Longer term impact.
The declaration had two indirect consequences, the emergence of a Jewish state and a chronic state of conflict between Arabs and Jews throughout the Middle East. Starting in 1920, the Intercommunal conflict in Mandatory Palestine broke out, which widened into the regional Arab–Israeli conflict, primarily from 1948-73 but extending in a more limited manner to 2006, and finally became the Israeli–Palestinian conflict, the ongoing local conflict which began also began in 1948 and whose primary phase began following the 1964 foundation of the PLO.
Jonathan Schneer's 2010 study concluded that because the buildup to the declaration was characterized by "contradictions, deceptions, misinterpretations, and wishful thinking", the declaration sowed dragon's teeth and "produced a murderous harvest, and we go on harvesting even today." The foundational stone for modern Israel had been laid, but the prediction that this would lay the groundwork for harmonious Arab-Jewish cooperation proved to be wishful thinking.
The implementation of the declaration fed a disenchantment among the Arabs that alienated them from the British Mandatory Authorities. Palestinian historian Rashid Khalidi has argued that following the Balfour Declaration there ensued "what amounts to a hundred years of war against the Palestinian people."

</doc>
<doc id="4821" url="https://en.wikipedia.org/wiki?curid=4821" title="Black Hand (Serbia)">
Black Hand (Serbia)

Unification or Death (), popularly known as the Black Hand (Црна рука/Crna ruka), was a secret military society formed on 9 May 1911 by officers in the Army of the Kingdom of Serbia, originating in the conspiracy group that assassinated the Serbian royal couple (1903), led by captain Dragutin Dimitrijević "Apis".
It was formed with the aim of uniting all of the territories with a South Slavic majority not ruled by either Serbia or Montenegro. Its inspiration was primarily the unification of Italy in 1859–70, but also that of Germany in 1871. Through its connections to the July 1914 assassination of Archduke Franz Ferdinand in Sarajevo, which was committed by the members of youth movement Young Bosnia, the Black Hand is often viewed as having contributed to the start of World War I by precipitating the July Crisis of 1914, which eventually led to Austria-Hungary's invasion of the Kingdom of Serbia.
Background.
Apis' conspiracy group and the May Coup.
In August 1901, a group of lower officers headed by captain Dragutin Dimitrijević "Apis" established a conspiracy group (called the Black Hand in literature), against the dynasty. The first meeting was held on 6 September 1901. In attendance were captains Radomir Aranđelović, Milan F. Petrović, and Dragutin Dimitrijević, as well as lieutenants Antonije Antić, Dragutin Dulić, Milan Marinković, and Nikodije Popović. They made a plan to kill the royal couple − King Alexander I Obrenović and Queen Draga. Captain Apis personally led the group of Army officers who killed the royal couple in the Old Palace at Belgrade on the night of 28/29 May 1903 (Old Style).
Narodna Odbrana.
On 8 October 1908, just two days after Austria annexed Bosnia and Herzegovina, some Serbian ministers, officials, and generals held a meeting at the City Hall in Belgrade. They founded a semi-secret society, the "Narodna Odbrana" ("National Defense") which gave Pan-Serbism a focus and an organization. The purpose of the group was to liberate Serbs under the Austro-Hungarian occupation. They also undertook anti-Austrian propaganda and organized spies and saboteurs to operate within the occupied provinces. Satellite groups were formed in Slovenia, Bosnia, Herzegovina and Istria. The Bosnian group went under the name "Mlada Bosna" ("Young Bosnia").
Establishment.
The Unification or Death was established in the beginning of May 1911, the original constitution of the organization being signed on 9 May. Ljuba Čupa, Bogdan Radenković and Vojislav Tankosić wrote the constitution of the organization. The constitution was modeled after similar German secret nationalist associations and the Italian Carbonari. The organization was mentioned in the Serbian parliament as the "Black Hand" in late 1911.
By 1911–12, Narodna Odbrana had established ties with the Black Hand, and the two became "parallel in action and overlapping in membership".
1911–13.
The organization used the magazine "Pijemont" for their ideology dissemination, founded by Ljuba Čupa in August 1911.
1914.
By 1914, there were hundreds of members, many of whom were Serbian Army officers. The goal of uniting Serb-inhabited territories was implemented through training of guerilla fighters and saboteurs. The Black Hand was organized at the grassroots level in 3 to 5-member cells, supervised by district committees and by a Central committee in Belgrade whose ten-member Executive Committee was led, more or less, by Colonel Dragutin Dimitrijević "Apis". To ensure secrecy, members rarely knew much more than the members of their own cell and one superior above them. New members swore the oath:
The Black Hand took over the terrorist actions of "Narodna Odbrana", and worked deliberately at obscuring any distinctions between the two groups, trading on the prestige and network of the older organization. Black Hand members held important army and government positions. Crown Prince Alexander was an enthusiastic and financial supporter. The group held influence over government appointment and policy. The Serbian government was fairly well informed of Black Hand activities.
Friendly relations had fairly well cooled by 1914. The Black Hand was displeased with Prime Minister Nikola Pašić. They thought he did not act aggressively enough towards the Pan-Serb cause. They engaged in a bitter power struggle over several issues, such as who would control territories Serbia annexed in the Balkan Wars. By this point, disagreeing with the Black Hand was dangerous, as political murder was one of their tools.
It was also in 1914 that Apis allegedly decided that Archduke Franz Ferdinand, the heir-apparent of Austria, should be assassinated. Towards that end it is claimed that three young Bosnian Serbs were recruited to kill the Archduke. They were definitely trained in bomb throwing and marksmanship by current and former members of the Serbian military. Gavrilo Princip, Nedeljko Čabrinović and Trifko Grabež were smuggled across the border back into Bosnia via a chain of underground-railroad style contacts.
The decision to kill the Archduke was apparently initiated by Apis, and not sanctioned by the full Executive Committee (assuming Apis was involved at all, a question that remains in dispute). Those involved probably realized that their plot would result in war between Austria and Serbia, and had every reason to expect that Russia would side with Serbia. They likely did not, however, anticipate that the assassination would start a chain of events leading to world war.
Others in the government and some of the Black Hand Executive Council were not as confident of Russian aid. Russia had let them down recently. When word of the plot allegedly percolated through Black Hand leadership and the Serbian government (the Prime Minister Pašić was definitely informed of two armed men being smuggled across the border; it is not clear if Pašić knew the planned assassination), Apis was supposedly told not to proceed. He may have made a half-hearted attempt to intercept the young assassins at the border, but they had already crossed. Other sources say the attempted 'recall' was only begun after the assassins had reached Sarajevo. This 'recall' appears to make Apis look like a loose cannon, and the young assassins as independent zealots. In fact, the 'recall' took place a full two weeks before the Archduke's visit. The assassins idled around in Sarajevo for a month. Nothing more was done to stop them.
Assassination of Archduke Franz Ferdinand.
The Young Bosnia organization carried out the assassination of Archduke Franz Ferdinand. After the unsuccessful grenade attack by Nedeljko Čabrinović, Gavrilo Princip succeeded in killing the Archduke and his wife with two bullets from his handgun because Ferdinand's driver took a wrong turn. Until a few weeks later, the guilt for the crime had settled loosely on Serbia in general. Long-existing tensions between Serbia and Austria-Hungary eventually drew in the other European powers and escalated into the beginning of the First World War. The Serbians prevented Austria-Hungary from investigating the assassination of the Archduke.
World War I.
Just prior to World War I, under the orders of the Chief of Serbian Military Intelligence, Serbian Military Officers and remnants of the by then moribund Black Hand organized and facilitated the assassination of Franz Ferdinand, Archduke of Austria on occasion of his visit to Sarajevo, Bosnia. The Austro-Hungarian investigation of the assassination rounded up all but one of the assassins and also much of the underground railroad that had been used to transport the assassins and their weapons from Serbia to Sarajevo. Within two days following the assassination, Austria-Hungary and Germany advised Serbia that they should open an investigation, but Serbian Foreign Minister Gruic, speaking for Serbia replied, "Nothing had been done so far, and the matter did not concern the Serbian Government," after which "high words" were spoken on both sides. Entreaties by Germany asking Russia to intercede with Serbia were ignored. On 23 July Austria-Hungary delivered a toughly worded letter to Serbia with ten enumerated demands and additional demands in the preamble aimed at the destruction of the anti-Austrian terrorist and propaganda network in Serbia. Austria called attention to Serbia's March 1909 declaration committing to the Great Powers to respect Austria-Hungary's sovereignty over Bosnia-Herzegovina and committing Serbia to maintain good neighborly relations with Austria-Hungary. If the ten enumerated demands and demands in the preamble were not agreed to within 48 hours, Austria-Hungary would recall its ambassador from Serbia. The letter became known as the July Ultimatum. Serbia accepted all but one of the demands, to let the Austrian officers conduct an investigation on Serbian soil, which would have compromised its sovereignty. In response, Austria-Hungary recalled its ambassador.
Austria-Hungary authorized the mobilization and the declaration of war against Serbia on 28 July 1914. The Secret Treaty of 1892 required both Russia and France to mobilize immediately followed by a commencement of action against the Triple Alliance if any member of the Triplice mobilized, and so, soon all the Great Powers of Europe were at war except Italy. Italy cited a clause in the Triple Alliance treaty which only bound it to enter in case of aggression against one of the treaty members, and so remained neutral – for the time being.
The six assassins caught by Austria-Hungary were tried and convicted for treason. The leader, Danilo Ilić, was shot by a firing squad. The remaining assassins in custody were not yet twenty years old at the time of the assassination and were therefore given prison terms. Most of the underground railroad that transported them were also arrested, tried, and convicted. Two of these were executed. A few peripheral conspirators were acquitted. A wide ranging investigation rolled up many additional irredentist youths, and the fifth column that the Black Hand and Serbian Military Intelligence had tried to organize was eliminated. After receiving the Austrian letter, Serbia arrested Major Voja Tankosić (a member of the Black Hand committee who had been pointed out by the assassins) but then promptly released him and returned him to his unit. The seventh assassin escaped to Montenegro where he was arrested. Austria-Hungary asserted its right to extradite him, but Montenegrin authorities instead allowed the assassin to "escape" to Serbia where he joined Major Tankosić's unit; Major Tankosić died in November 1915 covering the Serbian retreat, but not before confessing his role in the assassination to historians at Azania. Masterspy Rade Malobabić, Serbian Military Intelligence's top agent against Austria-Hungary, was arrested on his return from Austria-Hungary after the assassination, but was also later released and given a commission running an army supply store.
Towards the end of 1916, due to its murders and other illegal activities and to halt its underground influence in both the army and politics, Serbian Prime Minister Nikola Pašić decided to destroy the leaders of the Black Hand and break up the organization. By the spring of 1917, many Black Hand leaders, including Dimitrijević, had been arrested. A sham trial before a military tribunal in Salonika was held in May 1917 for Apis and others. The charges were unrelated to the events of Sarajevo. Among the charges was that the Black Hand had attempted to murder Prince Regent Alexander. Though witnesses against them were numerous, the evidence cited was nearly all hearsay or outright fabrication. Dimitrijević and six others were sentenced to death. Three obtained commutations to long prison terms, but Apis and three comrades were executed by firing squad on 26 June 1917, against protests of the new Kerensky government of Russia. On his way to his execution, Dimitrijević reportedly commented that he was really being executed for planning the murder of Archduke Ferdinand. Before being shot, he made a written confession to the court that he had ordered Rade Malobabić to organize the assassination of Franz Ferdinand. Malobabić made an implied confession to a priest before he was executed. Vulović's confession came at trial where he said he received orders signed by Serbia's top military officer to send Malobabic into Austria-Hungary just before the assassination. Much later, a new trial was ordered by Yugoslavia and the convictions were overturned.
With the demise of the Black Hand in June 1917 after the Salonika Trial, The White Hand steadily gained control of the young and ambitious Prince Alexander. In what became Yugoslavia after the war, the White Hand grew into an essential piece of the state's machinery. It continued the nationalist work of the Black Hand, but under state control. There is an unconfirmed rumour that the death of Vojislav Petrovic, an ex-attache to the Yugoslav Legation in London, was the work of Narodna Odbrana. Petrovic was preparing a book on the history of the Sarajevo assassinations and the Black Hand.
Ideology.
The group encompassed a range of ideological outlooks, from conspiratorially-minded army officers to idealistic youths, sometimes tending towards republicanism, despite the acquisition of nationalistic royal circles in its activities (the movement's leader, Colonel Dragutin Dimitrijević or "Apis," had been instrumental in the June 1903 coup which had brought King Petar Karađorđević to the Serbian throne following 45 years of rule by the rival Obrenović dynasty). The group was denounced as nihilist by the Austro-Hungarian press and compared to the Russian People's Will and the Chinese Assassination Corps.

</doc>
