<doc id="37661" url="https://en.wikipedia.org/wiki?curid=37661" title="Alfred Kinsey">
Alfred Kinsey

Alfred Charles Kinsey (; June 23, 1894 – August 25, 1956) was an American biologist, professor of entomology and zoology, and sexologist who in 1947 founded the Institute for Sex Research at Indiana University, now known as the Kinsey Institute for Research in Sex, Gender, and Reproduction. He is best known for writing "Sexual Behavior in the Human Male" (1948) and "Sexual Behavior in the Human Female" (1953), also known as the Kinsey Reports, as well as the Kinsey scale. Kinsey's research on human sexuality, foundational to the field of sexology, provoked controversy in the 1940s and 1950s. His work has influenced social and cultural values in the United States, as well as internationally.
Early life and education.
Kinsey was born on June 23, 1894, in Hoboken, New Jersey, the son of Sarah Ann (née Charles) and Alfred Seguine Kinsey. Kinsey was the eldest of three children. His mother received little formal education; his father was a professor at Stevens Institute of Technology.
Kinsey's parents were poor for most of his childhood, often unable to afford proper medical care. This may have led to a young Kinsey receiving inadequate treatment for a variety of diseases including rickets, rheumatic fever, and typhoid fever. His health records indicate that Kinsey received suboptimal exposure to sunlight (often the cause of rickets, before milk and other foods were fortified with vitamin D) and lived in unsanitary conditions for at least part of his childhood. Rickets led to a curvature of the spine, which resulted in a slight stoop that prevented Kinsey from being drafted in 1917 for World War I.
Kinsey's parents were devout Christians. His father was known as one of the most devout members of the local Methodist church. Most of Kinsey's social interactions were with other members of the church, often as a silent observer, while his parents discussed religion. Kinsey's father imposed strict rules on the household, including mandating Sunday as a day of prayer and little else.
At age 10, Kinsey moved with his family to South Orange, New Jersey. Also at a young age, he showed great interest in nature and camping. He worked and camped with the local YMCA throughout his early years, and enjoyed these activities to such an extent that he intended to work for the YMCA after completing his education. Kinsey's senior undergraduate thesis for psychology, a dissertation on the group dynamics of young boys, echoed this interest. He joined the Boy Scouts when a troop was formed in his community. His parents strongly supported this (and joined as well) because the Boy Scouts was an organization that was based on the principles of Christianity. Kinsey worked his way up through the Scouting ranks to earn Eagle Scout in 1913, making him one of the earliest Eagle Scouts. Despite earlier disease having weakened his heart, Kinsey followed an intense sequence of difficult hikes and camping expeditions throughout his early life.
In high school, Kinsey was a quiet but hard-working student. While attending Columbia High School, he devoted his energy to academic work and playing the piano. At one time, Kinsey had hoped to become a concert pianist, but decided to concentrate on his scientific pursuits instead. Kinsey's ability to spend immense amounts of time deeply focused on study was a trait that would serve him well in college and during his professional career. He seems not to have formed strong social relationships during high school, but earned respect for his academic ability. While there, Kinsey became interested in biology, botany and zoology. Kinsey was later to claim that his high school biology teacher, Natalie Roeth, was the most important influence on his decision to become a scientist. Kinsey approached his father with plans to study botany at college. His father demanded that he study engineering at Stevens Institute of Technology instead. Kinsey was not successful there, and decided engineering was not a field he was good at. He switched to Bowdoin College in Brunswick, Maine, where he majored in biology.
Regardless, he resumed his commitment to study. At Stevens, he primarily took courses related to English and engineering, but was unable to satisfy his interest in biology. At the end of two years at Stevens, Kinsey gathered the courage to confront his father about his interest in biology and his intent to continue studying at Bowdoin College in Maine.
In the fall of 1914, Kinsey entered Bowdoin College, where he studied entomology under Manton Copeland, and was admitted to the Zeta Psi fraternity, in whose house he lived for much of his time at college. In 1916 Kinsey was elected to the Phi Beta Kappa society and graduated magna cum laude, with degrees in biology and psychology. Alfred Seguine didn't attend his son's graduation ceremony from Bowdoin, possibly as another sign of disapproval of his son's choice of career and studies. He continued his graduate studies at Harvard University's Bussey Institute, which had one of the most highly regarded biology programs in the United States. It was there that Kinsey studied applied biology under William Morton Wheeler, a scientist who made outstanding contributions to entomology. Under Wheeler, Kinsey worked almost completely autonomously, which suited both men quite well.
Kinsey chose to do his doctoral thesis on gall wasps, and began zealously collecting samples of the species. He traveled widely and took 26 detailed measurements of hundreds of thousands of gall wasps; his methodology was itself an important contribution to entomology as a science. Kinsey was granted a Sc.D. degree in 1919 by Harvard University, and published several papers in 1920 under the auspices of the American Museum of Natural History in New York City, introducing the gall wasp to the scientific community and describing its phylogeny. Of the more than 18 million insects in the museum's collection, some 5 million are gall wasps collected by Kinsey.
Kinsey wrote a widely used high-school textbook, "An Introduction to Biology", which was published in October 1926. The book endorsed evolution and unified, at the introductory level, the previously separate fields of zoology and botany. Kinsey also co-wrote "Edible Wild Plants of Eastern North America" with Merritt Lyndon Fernald, published in 1943. The original draft of the book was written in 1919–1920, while Kinsey was still a doctoral student at the Bussey Institute and Fernald was working at the Arnold Arboretum.
Personal life.
Marriage and family.
Kinsey married Clara Bracken McMillen in 1921, whose ceremony, like his college graduation, was also avoided by Alfred Sr. They had four children. Their first-born, Donald, died from the acute complications of juvenile diabetes in 1927, just before his fifth birthday. His daughter, Anne, was born in 1924, followed by Joan in 1925, and Bruce in 1928.
Kinsey was bisexual. He and his wife agreed that both could sleep with other people as well as with each other. He himself slept with other men, including his student Clyde Martin.
Kinsey designed his own house, which was built in the Vinegar Hill neighborhood of Bloomington, Indiana at 1320 First Street. There he practiced his deep interest in gardening.
Personal habits.
As a young man, Kinsey began inserting objects into his urethra — initially drinking straws before moving on to pipe cleaners, pencils and finally a toothbrush – to punish himself for having homoerotic feelings, and inserting toothbrushes continued throughout his adult life. After becoming accustomed to the pain of urethral insertions, he circumcised himself without anesthesia.
Sexology.
The Kinsey Reports.
Kinsey is widely regarded as the first major figure in American sexology; his research is cited as having paved the way for a deeper exploration into sexuality among sexologists and the general public, and as having liberated female sexuality. For example, Kinsey's work disputed the notions that women generally are not sexual and that female orgasms experienced vaginally are superior to clitoral orgasms. He initially became interested in different forms of sexual practices in 1933, after discussing the topic extensively with a colleague, Robert Kroc. Kinsey had been studying the variations in mating practices among gall wasps. During this time, he developed a scale measuring sexual orientation, now known as the Kinsey scale, which ranges from 0 to 6, where 0 is exclusively heterosexual and 6 is exclusively homosexual; a rating of X for "no socio-sexual contacts or reactions" was later added.
In 1935, Kinsey delivered a lecture to a faculty discussion group at Indiana University, his first public discussion of the topic, wherein he attacked the "widespread ignorance of sexual structure and physiology" and promoted his view that "delayed marriage" (that is, delayed sexual experience) was psychologically harmful. Kinsey obtained research funding from the Rockefeller Foundation, which enabled him to further study human sexual behavior. He published "Sexual Behavior in the Human Male" in 1948, followed in 1953 by "Sexual Behavior in the Human Female", both of which reached the top of the bestseller lists and turned Kinsey into a celebrity. These publications later became known as the Kinsey Reports. Articles about him appeared in magazines such as "Time", "Life", "Look", and "McCall's". The Kinsey Reports, which led to a storm of controversy, are regarded by many as a precursor to the sexual revolution of the 1960s and 1970s.
Controversial aspects.
Kinsey's research went beyond theory and interview to include observation of and participation in sexual activity, sometimes involving co-workers. Some of the data published in the two "Kinsey Reports" books is controversial in the scientific and psychiatric communities, due to the low amount of research that was done and Kinsey's decision to interview and sexually experiment with volunteers who may not have been representative of the general population. Kinsey justified this sexual experimentation as being necessary to gain the confidence of his research subjects. He encouraged his staff to do likewise, and to engage in a wide range of sexual activity, to the extent that they felt comfortable; he argued that this would help his interviewers understand the participants' responses. Kinsey filmed sexual acts which included co-workers in the attic of his home as part of his research; Biographer Jonathan Gathorne-Hardy explains that this was done to ensure the films' secrecy, which would have caused a scandal had it become public knowledge. James H. Jones, author of "Alfred C. Kinsey: A Public/Private Life", and British psychiatrist Theodore Dalrymple, among others, have speculated that Kinsey was driven by his own sexual needs.
Kinsey collected sexual material from around the world, which brought him to the attention of U.S. Customs when they seized some pornographic films in 1956; he died before this matter was resolved legally. Kinsey wrote about pre-adolescent orgasms using data in tables 30 to 34 of the male volume, which report observations of orgasms in over three-hundred children between the ages of five months and fourteen years. This information was said to have come from adults' childhood memories, or from parent or teacher observation. Kinsey said he also interviewed nine men who had sexual experiences with children, and who told him about the children's responses and reactions. Little attention was paid to this part of Kinsey's research at the time, but where Kinsey had gained this information began to be questioned nearly 40 years later. It was later revealed that Kinsey used data from a single pedophile and presented it as being from various sources. Kinsey had seen the need for participant confidentiality and anonymity as necessary to gain "honest answers on such taboo subjects". The Kinsey Institute wrote that the data on children in tables 31–34 came from one man's journal (started in 1917) and that the events concerned predated the Kinsey Reports.
Jones wrote that Kinsey's sexual activity influenced his work, that he over-represented prisoners and prostitutes, classified some single people as "married", and that he included a disproportionate number of homosexual men, which may have distorted his studies. While he has been criticized for omitting African-Americans from his research, his report on the human male includes numerous references to African American participants. Historian Vern Bullough writes that the data was later reinterpreted, excluding prisoners and data derived from an exclusively gay sample, and the results indicate that it does not appear to have skewed the data. Kinsey may have over-represented homosexuals, but Bullough considers that this may have been because homosexual behavior was stigmatized and needed to be better understood. Paul Gebhard, who was Kinsey’s colleague from 1946 to 1956 and who also succeeded Kinsey as Director of the Kinsey Institute following his death, attempted to justify Kinsey's work in the 1970s by removing some of the suspect data he alleged showed a bias towards homosexuality. After he recalculated the findings in Kinsey's work, he found only slight differences between the original and updated figures.
In the media.
The popularity of "Sexual Behavior in the Human Male" prompted widespread media interest in 1948. "Time" magazine declared, "Not since "Gone With the Wind" had booksellers seen anything like it." The first pop culture references to Kinsey appeared not long after the book's publication; Martha Raye a half-million copies of 'Ooh, Dr. Kinsey!'" Cole Porter's song "Too Darn Hot", from the Tony Award–winning Broadway musical "Kiss Me, Kate", devoted its bridge to an analysis of the Kinsey report and the "average man's favorite sport." In 1949 Mae West, reminiscing on the days when the word "sex" was rarely uttered, said of Kinsey, "That guy merely makes it easy for me. Now I don't have to draw 'em any blueprints...We are both in the same business...Except I saw it first."
The publication of "Sexual Behavior in the Human Female" prompted even more intensive news coverage: Kinsey appeared on the cover of the August 24, 1953, issue of "Time". The national news magazine featured two articles on the scientist, one focusing on his research, career and new book, the other on his background, personality, and lifestyle. In the magazine's cover portrait, "Flowers, birds, and a bee surround Kinsey; the mirror-of-Venus female symbol decorates his bow tie." The lead article concludes with the following observation: "'Kinsey...has done for sex what Columbus did for geography,' declared a pair of enthusiasts...forgetting that Columbus did not know where he was when he got there... Kinsey's work contains much that is valuable, but it must not be mistaken for the last word." That same year, Kinsey appeared as a character in an episode of the Jack Benny TV program (September 15, 1953), in which he and his research were written into a sketch about Benny's 'fantasy' about Marilyn Monroe, a guest on the program.
Death.
Kinsey died on August 25, 1956, at the age of 62. The cause of death was reported to be a heart ailment and pneumonia. The "New York Times" ran the following editorial on August 27, 1956:
Legacy.
After the publication of "Sexual Behavior in the Human Female", a character called "Dr. Kinsey" appeared on the September 15, 1953 television episode of The Jack Benny Program as a bow-tied man interviewing a young woman on board a cruise ship that has left Hawaii. When "Dr. Kinsey" identifies himself to Jack Benny, Benny steps away in embarrassment.
The early 2000s saw a renewed interest in Kinsey. In 2003 Theatre of NOTE produced the Steve Morgan Haskell play titled "Fucking Wasps" which followed Kinsey's life from childhood until death. Matt Sesow's paintings adorned the theater along with David Bickford playing piano live. Written and directed by Steve Morgan Haskell, "Fucking Wasps" received many accolades, including a Playwriting of the Year nomination from Backstage West. Premiering in 2003, the musical "Dr. Sex" focuses on the relationship between Kinsey, his wife, and their shared lover Wally Matthews (based on Clyde Martin). The play had a score by Larry Bortniker, a book by Bortniker and Sally Deering, and won seven Jeff Awards. It was produced off-Broadway in 2005. The 2004 biographical film "Kinsey", written and directed by Bill Condon, stars Liam Neeson as the scientist and Laura Linney as his wife. In 2004 T. Coraghessan Boyle's novel about Kinsey, "The Inner Circle", was published. The following year, PBS produced the documentary "Kinsey" in cooperation with the Kinsey Institute, which allowed access to many of its files. "Mr. Sex", a BBC radio play by Steve Coombes concerning Kinsey and his work, won the 2005 Imison Award.
In 2012 Kinsey was inducted into the Legacy Walk, an outdoor public display which celebrates LGBT history and people.

</doc>
<doc id="37662" url="https://en.wikipedia.org/wiki?curid=37662" title="Pope Leo II">
Pope Leo II

Pope Saint Leo II (611 – 28 June 683) reigned from 17 August 682 to his death in 683.
Background and early activity in the Church.
He was a Sicilian by birth (the son of a man named Paulus). He may have ended up being among the many Sicilian clergy in Rome, at that time, due to the Islamic Caliphate battles against Sicily in the mid-7th century. Though elected pope a few days after the death of Pope St. Agatho (10 January 681), he was not consecrated till after the lapse of a year and seven months (17 August 682). Leo was known as an eloquent preacher who was interested in music, and noted for his charity to the poor.
Reign as Bishop of Rome.
Elected shortly after the death of Agatho, Leo was not consecrated for over a year and a half. The reason may have been due to negotiations regarding imperial control of papal elections.
These negotiations were undertaken by Leo's predecessor Agatho between the Holy See and Emperor Constantine IV. They concerned the relations of the Byzantine Court to papal elections. Constantine IV had already promised Agatho to abolish or reduce the tax that the popes had been paying to the imperial treasury at the time of their consecration, an imperial policy that had been in force for about a century.
Leo's short-lived pontificate did not allow him to accomplish much, but there was one achievement of major importance: he confirmed the acts of the Sixth Ecumenical Council (680–1). This council had been held in Constantinople against the Monothelite controversy, and had been presided over by the legates of Pope Agatho. After Leo had notified the Emperor that the decrees of the council had been confirmed, he made them known to the nations of the West. In letters written to the king, the bishops, and the nobles of Spain, he explained what the council had effected, and he called upon the bishops to subscribe to its decrees.
During this council, Pope Honorius I was anathematised for his views in the Monothelite controversy as tolerant of heresy. Leo took great pains to make it clear that in condemning Honorius, he did so not because Honorius taught heresy, but because he was not active enough in opposing it. In accordance with the papal mandate, a synod was held at Toledo (684) in which the Council of Constantinople was accepted.
Regarding the decision of the council, Leo wrote once and again in approbation of the decision of the council and in condemnation of Honorius, whom he regarded as one who "profana proditione immaculatem fidem subvertare conatus est" (roughly, "one who by betrayal has tried to overthrow the immaculate faith"). In their bearing upon the question of papal infallibility these words have caused considerable attention and controversy, and prominence is given to the circumstance that in the Greek text of the letter to the Emperor which the phrase occurs, the milder expression "subverti permisit" ("allowed to be overthrown...") is used for "subvertare conatus est".
At this time Leo put an end to the attempts of the Ravenna archbishops to get away from the control of the Bishop of Rome. The Pope sweetened the deal for the Ravenna bishops by abolishing the tax it had been customary for them to pay when they received the pallium.
Also, in apparent response to Lombard raids, Leo transferred the relics of a number of martyrs from the catacombs to churches inside the walls of the city. He also dedicated two churches, St. Paul's and Sts. Sebastian and George.
Burial.
Leo was originally buried in his own monument; however, some years after his death, his remains were put into a tomb that contained the first four of his papal namesakes.

</doc>
<doc id="37663" url="https://en.wikipedia.org/wiki?curid=37663" title="Pope Leo IV">
Pope Leo IV

Pope Saint Leo IV (790 – 17 July 855) was Pope from 10 April 847 to his death in 855. He is remembered for repairing Roman churches that had been damaged during Arab raids on Rome, and for organizing a league of Italian cities who fought the sea Battle of Ostia against the Saracens.
Life.
A Roman by birth, he was unanimously chosen to succeed Sergius II. When he was elected, on 10 April 847, he was cardinal of Santi Quattro Coronati and had been subdeacon of Gregory IV and archpriest under his predecessor. His pontificate was chiefly distinguished by his efforts to repair the damage done by the Saracens during the reign of his predecessor to various churches of the city, especially those of St Peter and St Paul.
The Saracens were besieging Gaeta, which led to Leo's order that the walls of the city be restored and strengthened between 848 and 849. When the Muslims approached Portus, he summoned the Repubbliche Marinare (or mariner cities of Italy) – Naples, Gaeta and Amalfi – to form a league. The command of the unified fleet was given to Cesarius, son of Duke Sergius I of Naples. The subsequent Battle of Ostia was one of the most famous in history of the papacy of the Middle Ages and is celebrated in a famous fresco by Raphael and his pupils in his Rooms of the Vatican Palace in the Vatican City. Another episode of Leo's life celebrated by the Urbinate in his series of frescoes for the "Incendio di Borgo" is the burning of the pilgrims' district of Rome (the "Borgo"), which, according to the legend, was stopped by Leo simply making the sign of the cross.
In order to counter the Saracen menace definitively, Leo ordered a new line of walls encompassing the suburb on the right bank of the Tiber to be built, including St. Peter's Basilica, which had been undefended until this time. The district enclosed by the walls is still known as the Leonine City, and corrensponds to the later rione of Borgo. He also restored and embellished the damaged Basilica di San Paolo fuori le Mura and St. Peter's: the latter's altar again received its gold covering (after being stolen), which weighed 206 lb. and was studded with precious gems. Following the restoration of St. Peter's, Leo appealed to the Christian kingdoms to confront the Arab raiders.
Leo IV held three synods, one in 850 that was distinguished by the presence of Holy Roman Emperor Louis II, but the other two of little importance. The history of the papal struggle with Hincmar of Reims, which began during Leo's pontificate, belongs properly to that of Nicholas I.
Death.
Leo IV died on 17 July 855 and was buried in St. Peter's Basilica. Benedict III was Leo's immediate successor. A medieval tradition claimed that a woman, Pope Joan, succeeded him, disguising herself as a man, but Joan is generally believed to be fictitious.
Burial.
Leo IV was originally buried in his own monument, however some years after his death, his remains were put into a tomb that contained the first four Pope Leos. In the 18th century, the relics of Leo the Great were separated from the other Leos and given their own chapel.
Iconography.
Leo IV had the figure of a rooster placed on the Old St. Peter's Basilica or old Constantinian basilica

</doc>
<doc id="37665" url="https://en.wikipedia.org/wiki?curid=37665" title="Pope Leo V">
Pope Leo V

Pope Leo V (died c. February 904) was Pope from July 903 to his death in 904. He was pope during the period known as the Saeculum obscurum. He was thrown into prison in September 903 by the Antipope Christopher, and was probably killed at the start of the pontificate of Pope Sergius III. If his deposition is not considered valid (as in the modern Vatican list), then his papacy may be considered to have ended with his death in 904.
Pontificate.
Leo V was born at a place called Priapi, near Ardea. Although he was a priest when he was elected pope following the death of Pope Benedict IV (900–903), he was not a Cardinal priest of Rome.
During his brief pontificate, Leo granted the canons of Bologna a special papal bull "(epistola tuitionis)" where he exempted them from the payment of taxes. However, after a reign of a little over two months, Leo was captured by Christopher, the Cardinal-priest of San Lorenzo in Damaso, and thrown into prison. Christopher then had himself elected pope (903–904), and although now considered an antipope, he had until recently been considered a legitimate pope. If Leo never acquiesced to his deposition, then he can be considered Pope until his death in 904.
Leo died whilst in prison. He was either murdered on the orders of Christopher, who was in turn executed by Pope Sergius III (904–911) in 904, or, more likely, both were ordered to be killed at the beginning of Sergius’ pontificate, either on the orders of Sergius himself, or by the direction of the "sacri palatii vestararius", Theophylact, Count of Tusculum.

</doc>
<doc id="37666" url="https://en.wikipedia.org/wiki?curid=37666" title="Pope Leo VI">
Pope Leo VI

Pope Leo VI (died February 929) was Pope for just over seven months, from June 928 to his death in February 929. His pontificate occurred during the period known as the Saeculum obscurum.
Biography.
Leo VI was born into a Roman family, and his father was Christophorus, who had been Primicerius under Pope John VIII around the year 876. Tradition has it that he was a member of the Sanguini family. Just immediately prior to his election as pope, Leo had been serving as the Cardinal-Priest of the church of Santa Susanna.
Leo was elected pope around June 928, during a period of anarchy. He was chosen by the "senatrix" Marozia, who had gained control of Rome via the domination of her husband Guy, Margrave of Tuscany, and who had ordered the imprisonment and death of Leo’s predecessor, Pope John X.
During his brief pontificate, Leo confirmed the decisions of the Synod of Split. He completed his predecessor’s investigations into the ecclesiastical situation in Dalmatia, and proceeded to give the pallium to John, Archbishop of Salona, and ordered all the bishops of Dalmatia to obey him. He also ordered the Bishop of Nona and others to limit themselves to the extent of their dioceses. Leo then issued a ban on castrati entering into a union of marriage. He also issued an appeal for help against the Arab raiders who were threatening Rome, stating that:
”Whoever died faithful in this struggle will not see himself refused entry into the heavenly kingdom.”
The French chronicler Flodoard said of him:
”Through the virtue of Peter, Leo the sixth was taken and received, he was preserved for seven months and five days, and like his predecessors, he joined the company of the prophets.” 
Leo died in February 929, and was succeeded by Pope Stephen VII. He was buried at St. Peter’s Basilica.

</doc>
<doc id="37667" url="https://en.wikipedia.org/wiki?curid=37667" title="Pope Leo VII">
Pope Leo VII

Pope Leo VII (; died 13 July 939) was Pope from 3 January 936 to his death in 939. He was preceded by Pope John XI and followed by Pope Stephen VIII. Leo VII's election to the papacy was secured by Alberic II of Spoleto, the ruler of Rome at the time. Alberic wanted to choose the pope so that the papacy would continue to yield to his authority. Leo was the priest of the church of St. Sixtus in Rome, thought to be a Benedictine monk. He had little ambition towards the papacy, but consented under pressure.
As pope, Leo VII reigned for only three years. Most of his bulls were grants of privilege to monasteries, especially including the Abbey of Cluny. Leo called for Odo of Cluny to mediate between Alberic and Hugh of Italy, Alberic's stepfather, the King of Italy. Odo was successful in negotiating a truce after arranging a marriage between Hugh's daughter Alda and Alberic. Leo VII also appointed Frederick, Archbishop of Mainz, as a reformer in Germany. Leo allowed Frederick to drive out Jews that refused to be baptized, but he did not endorse the forced baptism of Jews.
The circumstance of his death is unrecorded, although a spurious legend, from centuries after, maintains that he died of a heart attack while in congress with his mistress.
After his death in July 939, Leo VII was interred at St. Peter's Basilica.

</doc>
<doc id="37669" url="https://en.wikipedia.org/wiki?curid=37669" title="William Tyndale">
William Tyndale

William Tyndale (; sometimes spelled "Tynsdale", "Tindall", "Tindill", "Tyndall"; ) was an English scholar who became a leading figure in Protestant reform in the years leading up to his execution. He is well known for his translation of the Bible into English. He was influenced by the work of Desiderius Erasmus, who made the Greek New Testament available in Europe, and by Martin Luther. While a number of partial translations had been made from the seventh century onward, the spread of Wycliffe's Bible resulted in a death sentence for any unlicensed possession of Scripture in English—even though translations in all other major European languages had been accomplished and made available. Tyndale's translation was the first English Bible to draw directly from Hebrew and Greek texts, the first English one to take advantage of the printing press, and first of the new English Bibles of the Reformation. It was taken to be a direct challenge to the hegemony of both the Church of England and the laws of England to maintain the church's position. In 1530, Tyndale also wrote "The Practyse of Prelates", opposing Henry VIII's divorce from Catherine of Aragon on the grounds that it contravened Scripture.
Reuchlin's Hebrew grammar was published in 1506. Tyndale worked in an age in which Greek was available to the European scholarly community for the first time in centuries. Erasmus compiled and edited Greek Scriptures into the Textus Receptus—ironically, to improve upon the Latin Vulgate—following the Renaissance-fueling Fall of Constantinople in 1453 and the dispersion of Greek-speaking intellectuals and texts into a Europe which previously had no access to them. When a copy of "The Obedience of a Christian Man" fell into the hands of Henry VIII, the king found the rationale to break the Church in England from the Roman Catholic Church in 1534.
In 1535 Tyndale was arrested and jailed in the castle of Vilvoorde (Filford) outside Brussels for over a year. In 1536 he was convicted of heresy and executed by strangulation, after which his body was burnt at the stake. His dying prayer that the King of England's eyes would be opened seemed to find its fulfillment just two years later with Henry's authorization of the Great Bible for the Church of England—which was largely Tyndale's own work. Hence, the Tyndale Bible, as it was known, continued to play a key role in spreading Reformation ideas across the English-speaking world and, eventually, to the British Empire.
In 1611 the 54 scholars who produced the King James Bible drew significantly from Tyndale, as well as from translations that descended from his. One estimate suggests the New Testament in the King James Version is 83% Tyndale's and the Old Testament 76%. With his translation of the Bible the first to be printed in English, and a model for subsequent English translations, in 2002, Tyndale was placed at number 26 in the BBC's poll of the 100 Greatest Britons.
Life.
Tyndale was born at some time in the period 1484–1496 in Melksham Court, Stinchcombe, a village near Dursley, Gloucestershire. The Tyndale family also went by the name Hychyns (Hitchins), and it was as William Hychyns that Tyndale was enrolled at Magdalen Hall, Oxford. Tyndale's family had moved to Gloucestershire at some point in the 15th century, probably as a result of the Wars of the Roses. The family derived from Northumberland via East Anglia. Tyndale's brother, Edward, was receiver to the lands of Lord Berkeley as attested to in a letter by Bishop Stokesley of London. Tyndale is recorded in two genealogies as having been the brother of Sir William Tyndale, of Deane, Northumberland, and Hockwald, Norfolk, who was knighted at the marriage of Arthur, Prince of Wales to Catherine of Aragon. Tyndale's family was thus derived from Baron Adam de Tyndale, a tenant-in-chief of Henry I (see Tyndall). William Tyndale's niece, Margaret Tyndale, was married to the Protestant martyr Rowland Taylor, burnt during the Marian Persecutions.
At Oxford.
Tyndale began a Bachelor of Arts degree at Magdalen Hall (later Hertford College) of Oxford University in 1506 and received his B.A. in 1512; the same year becoming a subdeacon. He was made Master of Arts in July 1515 and was held to be a man of virtuous disposition, leading an unblemished life. The M.A. allowed him to start studying theology, but the official course did not include the systematic study of Scripture. As Tyndale later complained:
A gifted linguist, over the years he became fluent in French, Greek, Hebrew, German, Italian, Latin, and Spanish, in addition to English. Between 1517 and 1521, he went to the University of Cambridge. Erasmus had been the leading teacher of Greek there from August 1511 to January 1512, but not during Tyndale's time at the university.
Tyndale became chaplain at the home of Sir John Walsh at Little Sodbury and tutor to his children around 1521. His opinions proved controversial to fellow clergymen, and the next year he was summoned before John Bell, the Chancellor of the Diocese of Worcester, although no formal charges were laid at the time. After the harsh meeting with Bell and other church leaders, and near the end of Tyndale's time at Little Sodbury, John Foxe describes an argument with a "learned" but "blasphemous" clergyman, who had asserted to Tyndale that, "We had better be without God's laws than the Pope's." Tyndale responded: "I defy the Pope, and all his laws; and if God spares my life, ere many years, I will cause the boy that driveth the plow to know more of the Scriptures than thou dost!"
Tyndale left for London in 1523 to seek permission to translate the Bible into English. He requested help from Bishop Cuthbert Tunstall, a well-known classicist who had praised Erasmus after working together with him on a Greek New Testament. The bishop, however, declined to extend his patronage, telling Tyndale he had no room for him in his household. Tyndale preached and studied "at his book" in London for some time, relying on the help of a cloth merchant, Humphrey Monmouth. During this time he lectured widely, including at St Dunstan-in-the-West.
In Europe.
Tyndale left England and landed on continental Europe, perhaps at Hamburg, in the spring of 1524, possibly traveling on to Wittenberg. The entry of the name "Guillelmus Daltici ex Anglia" in the matriculation registers of the University of Wittenberg has been taken to be a Latinization of "William Tyndale from England". At this time, possibly in Wittenberg, he began translating the New Testament, completing it in 1525 with assistance from Observant friar William Roy.
In 1525 publication of the work by Peter Quentell, in Cologne, was interrupted by the impact of anti-Lutheranism. A full edition of the New Testament was produced in 1526 by the printer Peter Schoeffer in Worms, a free imperial city then in the process of adopting Lutheranism. More copies were soon printed in Antwerp. The book was smuggled into England and Scotland; it was condemned in October 1526 by Bishop Tunstall, who issued warnings to booksellers and had copies burned in public. Marius notes that the "spectacle of the scriptures being put to the torch. . .provoked controversy even amongst the faithful." Cardinal Wolsey condemned Tyndale as a heretic, first stated in open court in January 1529.
From an entry in George Spalatin's Diary, for 11 August 1526, Tyndale apparently remained at Worms for about a year. It is not clear exactly when he moved to Antwerp. The colophon to Tyndale's translation of Genesis and the title pages of several pamphlets from this time purported to have been printed by Hans Luft at Marburg, but this is a false address: Hans Luft, the printer of Luther's books, never had a printing press at Marburg.
It is possible that Tyndale intended to carry on his work from Hamburg in about 1529. He revised his New Testament and began translating the Old Testament and writing various treatises. 
Opposition to Henry VIII's divorce.
In 1530 he wrote "The Practyse of Prelates", opposing Henry VIII's planned divorce from Catherine of Aragon in favour of Anne Boleyn on the grounds that it was unscriptural, and was a plot by Cardinal Wolsey to get Henry entangled in the papal courts of Pope Clement VII. The king's wrath was aimed at Tyndale: Henry asked the Emperor Charles V to have the writer apprehended and returned to England under the terms of the Treaty of Cambrai; however, the Emperor responded that formal evidence was required before extradition. Tyndale developed his case in "An Answer unto Sir Thomas More's Dialogue".
Betrayal and death.
Eventually, Tyndale was betrayed by Henry Phillips
to the imperial authorities, seized in Antwerp in 1535, and held in the castle of Vilvoorde (Filford) near Brussels. He was tried on a charge of heresy in 1536 and was condemned to be burned to death, despite Thomas Cromwell's intercession on his behalf. Tyndale "was strangled to death while tied at the stake, and then his dead body was burned". His final words, spoken "at the stake with a fervent zeal, and a loud voice", were reported as "Lord! Open the King of England's eyes." The traditional date of commemoration is 6 October, but records of Tyndale's imprisonment suggest the actual date of his execution might have been some weeks earlier. Foxe gives 6 October as the date of commemoration (left-hand date column), but gives no date of death (right-hand date column).
Within four years four English translations of the Bible were published in England at the King's behest, including Henry's official Great Bible. All were based on Tyndale's work.
Theological views.
Tyndale denounced the practice of prayer to saints. He taught justification by faith, the return of Christ, and mortality of the soul.
Printed works.
Although best known for his translation of the Bible, Tyndale was also an active writer and translator. As well as his focus on the ways in which religion should be lived, he had a focus on political issues.
Legacy.
Impact on the English language.
In translating the Bible, Tyndale introduced new words into the English language; many were subsequently used in the King James Bible:
Coinage of the word "atonement" (a concatenation of the words 'At One' to describe Christ's work of restoring a good relationship—a reconciliation—between God and people) is also sometimes ascribed to Tyndale. However, the word was probably in use by at least 1513, before Tyndale's translation. Similarly, sometimes Tyndale is said to have coined the term "mercy seat." While it is true that Tyndale introduced the word into English, "mercy seat" is more accurately a translation of Martin Luther's German "Gnadenstuhl".
As well as individual words, Tyndale also coined such familiar phrases as:
Controversy over new words and phrases.
The hierarchy of the Roman Catholic Church did not approve of some of the words and phrases introduced by Tyndale, such as "overseer", where it would have been understood as "bishop", "elder" for "priest", and "love" rather than "charity". Tyndale, citing Erasmus, contended that the Greek New Testament did not support the traditional Roman Catholic readings. More controversially, Tyndale translated the Greek "ekklesia", (literally "called out ones") as "congregation" rather than "church". It has been asserted this translation choice "was a direct threat to the Church's ancient—but so Tyndale here made clear, non-scriptural—claim to be the body of Christ on earth. To change these words was to strip the Church hierarchy of its pretensions to be Christ's terrestrial representative, and to award this honour to individual worshippers who made up each congregation."
Contention from Roman Catholics came not only from real or perceived errors in translation but also a fear of the erosion of their social power if Christians could read the Bible in their own language. "The Pope's dogma is bloody", Tyndale wrote in "The Obedience of a Christian Man". Thomas More (since 1935 in the Roman Catholic Church, Saint Thomas More) commented that searching for errors in the Tyndale Bible was similar to searching for water in the sea, and charged Tyndale's translation of "The Obedience of a Christian Man" with having about a thousand falsely translated errors. Bishop Tunstall of London declared that there were upwards of 2,000 errors in Tyndale's Bible, having already in 1523 denied Tyndale the permission required under the Constitutions of Oxford (1409), which were still in force, to translate the Bible into English.
In response to allegations of inaccuracies in his translation in the New Testament, Tyndale in the "Prologue" to his 1525 translation wrote that he never intentionally altered or misrepresented any of the Bible, but that he had sought to "interpret the sense of the scripture and the meaning of the spirit."
While translating, Tyndale followed Erasmus' (1522) Greek edition of the New Testament. In his preface to his 1534 New Testament ("WT unto the Reader"), he not only goes into some detail about the Greek tenses but also points out that there is often a Hebrew idiom underlying the Greek. The Tyndale Society adduces much further evidence to show that his translations were made directly from the original Hebrew and Greek sources he had at his disposal. For example, the Prolegomena in Mombert's "William Tyndale's Five Books of Moses" show that Tyndale's Pentateuch is a translation of the Hebrew original. His translation also drew on the Latin Vulgate and Luther's 1521 September Testament.
Of the first (1526) edition of Tyndale's New Testament only three copies survive. The only complete copy is part of the Bible Collection of Württembergische Landesbibliothek, Stuttgart. The copy of the British Library is almost complete, lacking only the title page and list of contents. Another rarity is Tyndale's Pentateuch, of which only nine remain.
Impact on the English Bible.
The translators of the Revised Standard Version in the 1940s noted that Tyndale's translation inspired the translations that followed, including the Great Bible of 1539, the Geneva Bible of 1560, the Bishops' Bible of 1568, the Douay-Rheims Bible of 1582–1609, and the King James Version of 1611, of which the RSV translators noted: "It KJV kept felicitous phrases and apt expressions, from whatever source, which had stood the test of public usage. It owed most, especially in the New Testament, to Tyndale". Many scholars today believe that such is the case. Moynahan writes: "A complete analysis of the Authorised Version, known down the generations as "the AV" or "the King James" was made in 1998. It shows that Tyndale's words account for 84% of the New Testament and for 75.8% of the Old Testament books that he translated." Joan Bridgman makes the comment in the "Contemporary Review" that, "He is the mainly unrecognised translator of the most influential book in the world. Although the Authorised King James Version is ostensibly the production of a learned committee of churchmen, it is mostly cribbed from Tyndale with some reworking of his translation."
Many of the English versions since then have drawn inspiration from Tyndale, such as the Revised Standard Version, the New American Standard Bible, and the English Standard Version. Even the paraphrases like the Living Bible have been inspired by the same desire to make the Bible understandable to Tyndale's proverbial ploughboy.
George Steiner in his book on translation "After Babel" refers to "the influence of the genius of Tyndale, the greatest of English Bible translators..." ["After Babel" p. 366]. He has also appeared as a character in two plays dealing with the King James Bible, Howard Brenton's "Anne Boleyn" (2010) and David Edgar's "Written on the Heart" (2011).
Memorials.
A memorial to Tyndale stands in Vilvoorde, where he was executed. It was erected in 1913 by Friends of the Trinitarian Bible Society of London and the Belgian Bible Society. There is also a small William Tyndale Museum in the town, attached to the Protestant church.
A bronze statue by Sir Joseph Boehm commemorating the life and work of Tyndale was erected in Victoria Embankment Gardens on the Thames Embankment, London in 1884. It shows his right hand on an open Bible, which is itself resting on an early printing press.
The Tyndale Monument was built in 1866 on a hill above his supposed birthplace, North Nibley, Gloucestershire.
A stained-glass window commemorating Tyndale was made in 1911 for the British and Foreign Bible Society by James Powell. In 1994, when the Society moved their offices, the window was reinstalled in the chapel of Hertford College. Tyndale was at Magdalen Hall, Oxford, which became Hertford College in 1874. The window depicts a full-length portrait of Tyndale, a cameo of a printing shop in action, some words of Tyndale, the opening words of Genesis in Hebrew, the opening words of John's Gospel in Greek, and the names of other pioneering Bible translators. The portrait is based on the oil painting that hangs in the college's dining hall.
A number of colleges, schools and study centres have been named in his honour, including Tyndale House (Cambridge), Tyndale University College and Seminary (Toronto), the Tyndale-Carey Graduate School affiliated to the Bible College of New Zealand, William Tyndale College (Farmington Hills, Michigan), and Tyndale Theological Seminary (Shreveport, Louisiana, and Fort Worth, Texas), the independent Tyndale Theological Seminary in Badhoevedorp, near Amsterdam, The Netherlands, Tyndale Christian School in South Australia and Tyndale Park Christian School in New Zealand.
An American Christian publishing house, also called Tyndale House, was named after Tyndale.
A life sized bronze statue of a seated William Tyndale at work on his translation by Lawrence Holofcener (2000) was placed in the Millennium Square, Bristol, United Kingdom. In 2008, vandals attacked the statue, which was taken away, repaired, and reinstalled.
Liturgical commemoration.
By tradition Tyndale's death is commemorated on 6 October. There are commemorations on this date in the church calendars of members of the Anglican Communion, initially as one of the "days of optional devotion" in the American Book of Common Prayer (1979), and a "black-letter day" in the Church of England's Alternative Service Book. The Common Worship that came into use in the Church of England in 2000 provides a collect proper to 6 October, beginning with the words:
See the "List of Anglican Church Calendars".
Tyndale is also honoured in the Calendar of Saints of the Evangelical Lutheran Church in America as a translator and martyr the same day.
Tyndale's pronunciation.
Tyndale was writing at the beginning of the Early Modern English period. His pronunciation must have differed in its phonology from that of Shakespeare at the end of the period. The linguist David Crystal has made a transcription and a sound recording of Tyndale's translation of the whole of Saint Matthew's Gospel in what he believes to be the pronunciation of the day, using the term "original pronunciation". The recording has been published by The British Library on two compact discs with an introductory essay by Crystal.
Further reading.
• Teems, David (2012) Tyndale: The Man Who Gave God An English Voice (Thomas Nelson)

</doc>
<doc id="37670" url="https://en.wikipedia.org/wiki?curid=37670" title="Pope John XXII">
Pope John XXII

Pope John XXII (; 1244 – 4 December 1334), born Jacques Duèze (or d'Euse), was Pope from 7 August 1316 to his death in 1334. He was the second Avignon Pope, elected by a conclave in Lyon assembled by King Louis X's brother Philip, the Count of Poitiers, later King Philip V of France. Like his predecessor, Clement V, he centralized power and income in the Papacy and lived a princely life in Avignon. He opposed the political policies of Louis IV of Bavaria as Holy Roman Emperor, which prompted Louis to invade Italy and set up an antipope, Nicholas V. Pope John XXII faced controversy in theology involving his views on the Beatific Vision, and he opposed the Franciscan understanding of the poverty of Christ and his apostles. He canonized St. Thomas Aquinas.
Early life and election.
The son of a shoemaker in Cahors, Jacques Duèze studied medicine in Montpellier and law in Paris, yet could not read a regal letter written to him in French.
Duèze taught both canon and civil law at Toulouse and Cahors. On the recommendation of Charles II of Naples he was made Bishop of Fréjus in 1300. In 1309 he was appointed chancellor of Charles II, and in 1310 he was transferred to Avignon. He delivered legal opinions favorable to the suppression of the Templars, but he also defended Boniface VIII and the Bull "Unam Sanctam". On 23 December 1312, Clement V made him Cardinal-Bishop of Porto-Santa Rufina.
The death of Pope Clement V in 1314 was followed by an interregnum of two years due to disagreements between the cardinals, who were split into two factions. After two years, Philip, in 1316, finally managed to arrange a papal conclave of twenty-three cardinals in Lyon. This conclave elected Duèze, who took the name John XXII and was crowned in Lyon. He set up his residence in Avignon rather than Rome, continuing the Avignon Papacy of his predecessor.
John XXII involved himself in the politics and religious movements of many European countries in order to advance the interests of the Church. His close links with the French crown created widespread distrust of the papacy.
Papacy.
Pope John XXII was an excellent administrator and efficient at reorganizing the Church. He had sent a letter of thanks to the Muslim ruler Uzbeg Khan, who was very tolerant of Christians and treated Christians kindly.
John XXII has traditionally been credited with having composed the prayer "Anima Christi", which has become the English "Soul of Christ, sanctify me ..." and the basis for the hymn "Soul of Christ, Sanctify My Breast".
On 27 March 1329 John XXII condemned many writings of Meister Eckhart as heretical in his papal bull "In Agro Dominico".
Conflict with Louis IV.
Prior to John XXII's election a contest had begun for the Holy Roman Empire's crown between Louis IV of Bavaria and Frederick I of Austria. John XXII was neutral at first, but in 1323, when Louis IV became Holy Roman Emperor, the Guelph (papal) party and the Ghibelline (imperial) party quarreled, which was partly provoked by John XXII's extreme claims of authority over the empire and partly by Louis IV's support of the spiritual Franciscans, whom John XXII condemned in the Papal bull "Quorumdam exigit". Louis IV was assisted in his doctrinal dispute with the papacy by Marsilius of Padua and later by the English Franciscan friar and scholar William of Ockham. Louis IV invaded Italy, entered Rome and set up Pietro Rainalducci as Antipope Nicholas V in 1328. The project was a fiasco. Guelphic predominance at Rome was later restored, and Pope John excommunicated William of Ockham. However, Louis IV had silenced the papal claims and John XXII stayed the rest of his life in Avignon.
Franciscan poverty.
Pope John XXII was determined to suppress what he considered to be the excesses of the Spirituals, who contended eagerly for the view that Christ and his apostles had possessed absolutely nothing, citing "Exiit qui seminat" in support of their view. In 1317, John XXII formally condemned the group of them known as the Fraticelli. On 26 March 1322, with "Quia nonnunquam", he removed the ban on discussion of Nicholas III's bull and commissioned experts to examine the idea of poverty based on belief that Christ and the apostles owned nothing. The experts disagreed among themselves, but the majority condemned the idea on the grounds that it would condemn the Church's right to have possessions. The Franciscan chapter held in Perugia in May 1322 declared on the contrary: "To say or assert that Christ, in showing the way of perfection, and the Apostles, in following that way and setting an example to others who wished to lead the perfect life, possessed nothing either severally or in common, either by right of ownership and "dominium" or by personal right, we corporately and unanimously declare to be not heretical, but true and catholic." By the bull "Ad conditorem canonum" of 8 December 1322, John XXII, declared it ridiculous to pretend that every scrap of food given to the friars and eaten by them belonged to the pope, refused to accept ownership over the goods of the Franciscans in future and granted them exemption from the rule that absolutely forbade ownership of anything even in common, thus forcing them to accept ownership. On 12 November 1323, he issued the bull "Quum inter nonnullos", which declared "erroneous and heretical" the doctrine that Christ and his apostles had no possessions whatever.
Influential members of the order protested, such as the minister general Michael of Cesena, the English provincial William of Ockham, and Bonagratia of Bergamo. In 1324, Louis the Bavarian sided with the Spirituals and accused the Pope of heresy. In reply to the argument of his opponents that Nicholas III's bull "Exiit qui seminat" was fixed and irrevocable, John XXII issued the bull "Quia quorundam" on 10 November 1324, in which he declared that it cannot be inferred from the words of the 1279 bull that Christ and the apostles had nothing, adding: "Indeed, it can be inferred rather that the Gospel life lived by Christ and the Apostles did not exclude some possessions in common, since living 'without property' does not require that those living thus should have nothing in common."
In 1328 Michael of Cesena was summoned to Avignon to explain the Order's intransigence in refusing the Pope's orders and its complicity with Louis of Bavaria. Michael was imprisoned in Avignon, together with Francesco d'Ascoli, Bonagratia and William of Ockham. In January of that year Louis entered Rome and had himself crowned Holy Roman Emperor. Three months later, he declared John XXII deposed and installed the Spiritual Franciscan Pietro Rainalducci as Pope Nicholas V. The Franciscan chapter that opened in Bologna on 28 May reelected Michael of Cesena, who two days before had escaped with his companions from Avignon. In August Louis the Bavarian and his pope had to flee Rome before an attack by Robert, King of Naples. Only a small part of the Franciscan Order joined the opponents of John XXII, and at a general chapter held in Paris in 1329 the majority of all the houses declared their submission to the Pope. With the bull "Quia vir reprobus" of 16 November 1329, John XXII replied to Michael of Cesena's attacks on "Ad conditorem canonum", "Quum inter nonnullos", and "Quia quorundam". In 1330, Antipope Nicholas V submitted, followed later by the ex-general Michael, and finally, just before his death, by Ockham.
Beatific vision controversy.
Pope John XXII was involved in a theological controversy concerning the beatific vision. Even before he was pope, John XXII argued that those who died in the faith did not see the presence of God until the Last Judgment. He continued this argument for a time in sermons while he was pope, although he never taught it in official documents. He eventually backed down from his position, and agreed that those who died in grace do indeed immediately enjoy the beatific vision.
Despite holding for many years a view widely held to be heretical, John XXII is not considered a heretic because the doctrine he had contradicted had not been formally defined by the Church until his successor, Benedict XII, addressed by the encyclical "Benedictus Deus", which formally defined this doctrine as part of Church teaching.
In fiction.
"The Royal Succession" (French: "La Loi des mâles"), the 1957 fourth novel in Maurice Druon's "Les Rois maudits" historical novel series, features Duèze's rise from cardinal to pope as one of its plotlines. He was portrayed by Henri Virlogeux in the 1972 French miniseries adaptation of the series, and by Claude Rich in the 2005 adaptation.
The papacy of John XXII--the conflict with Louis of Bavaria and the condemnation of the Franciscans over the poverty of Christ--is the central backdrop of Umberto Eco's historical murder mystery "The Name of the Rose", which is set in 1327.

</doc>
<doc id="37671" url="https://en.wikipedia.org/wiki?curid=37671" title="Aristocracy">
Aristocracy

Aristocracy (Greek ἀριστοκρατία "aristokratía", from ἄριστος "aristos" "excellent," and κράτος "kratos" "power") is a form of government that places power in the hands of a small, privileged ruling class. The term derives from the Greek "aristokratia", meaning "rule of the best".
At the time of the word's origins in Ancient Greece, the Greeks conceived it as rule by the best qualified citizens—and often contrasted it favourably with monarchy, rule by an individual. In later times, aristocracy was usually seen as rule by a privileged group, the aristocratic class, and was contrasted with democracy.
Concept.
The concept evolved in Ancient Greece, whereby a council of leading citizens was commonly empowered and contrasted with direct democracy, in which a council of citizens was appointed as the "senate" of a city state or other political unit. The Greeks did not like the concept of monarchy, and as their democratic system fell, aristocracy was upheld.
In Ancient Rome, the Republic consisted of an aristocracy—as well as consuls, a senate, and a tribal assembly. In the Middle Ages and early modern era, aristocracies primarily consisted of an influential aristocratic class, privileged by birth, and often by wealth. Since the French Revolution, aristocracy has generally been contrasted with democracy, in which all citizens should hold some form of political power. However, this distinction is often oversimplified. The concept evolved in Ancient Greece, whereby a council of leading citizens was commonly empowered and contrasted with direct democracy, in which a council of male citizens was appointed as the "senate" of a city state or other political unit.
In his 1651 book "Leviathan", Thomas Hobbes describes an aristocracy as a commonwealth in which the representative of the citizens is an assembly by part. It is a system in which only a small part of the population represents the government. Modern depictions of aristocracy tend to regard it not as the ancient Greek concept of rule by the best, but more as a plutocracy—rule by the rich.

</doc>
<doc id="37673" url="https://en.wikipedia.org/wiki?curid=37673" title="Symbol">
Symbol

A symbol is a person or a concept that represents, stands for or suggests another idea, visual image, belief, action or material entity. Symbols take the form of words, sounds, gestures, ideas or visual images and are used to convey other ideas and beliefs. For example, a red octagon may be a symbol for "STOP". On a map, a blue line might represent a river. Numerals are symbols for numbers. Alphabetic letters may be symbols for sounds. Personal names are symbols representing individuals. A red rose may symbolize love and compassion. The variable 'x', in a mathematical equation, may symbolize the position of a particle in space.
In cartography, an organized collection of symbols forms a legend for a map.
Etymology.
The word derives from the Greek "symbolon" (σύμβολον) meaning token or watchword. It is an amalgam of syn- "together" + bole "a throwing, a casting, the stroke of a missile, bolt, beam." The sense evolution in Greek is from "throwing things together" to "contrasting" to "comparing" to "token used in comparisons to determine if something is genuine." Hence, "outward sign" of something. The meaning "something which stands for something else" was first recorded in 1590, in Edmund Spenser's "Faerie Queene".
Definitions.
In considering the effect of a symbol on the psyche, in his seminal essay "The Symbol without Meaning" Joseph Campbell proposes the following definition:
"A symbol is an energy evoking, and directing, agent".
Later, expanding on what he means by this definition Campbell says:
Heinrich Zimmer gives a concise overview of the nature, and perennial relevance, of symbols.
In the book "Signs and Symbols, "it is stated that "A symbol ... is a visual image or sign representing an idea -- a deeper indicator of a universal truth."
Symbols are a means of complex communication that often can have multiple levels of meaning. This separates symbols from signs, as signs have only one meaning.
Human cultures use symbols to express specific ideologies and social structures and to represent aspects of their specific culture. Thus, symbols carry meanings that depend upon one’s cultural background; in other words, the meaning of a symbol is not inherent in the symbol itself but is culturally learned.
Symbols are the basis of all human understanding and serve as vehicles of conception for all human knowledge. Symbols facilitate understanding of the world in which we live, thus serving as the grounds upon which we make judgments. In this way, people use symbols not only to make sense of the world around them, but also to identify and cooperate in society through constitutive rhetoric.
Symbols and semiotics.
Semiotics is the study of signs, symbols, and signification as communicative behavior. Semiotics studies focus on the relationship of the signifier and the signified, also taking into account interpretation of visual cues, body language, sound, and other contextual clues. Semiotics is linked with both linguistics and psychology. Semioticians thus not only study what a symbol implies, but also how it got its meaning and how it functions to make meaning in society. Symbols allow the human brain continuously to create meaning using sensory input and decode symbols through both denotation and connotation.
Psychoanalysis, rhetoric and archetypes.
Swiss psychoanalyst Carl Jung, who studied archetypes, proposed an alternative definition of symbol, distinguishing it from the term "sign". In Jung's view, a sign stands for something known, as a word stands for its referent. He contrasted this with "symbol", which he used to stand for something that is unknown and that cannot be made clear or precise. An example of a symbol in this sense is Christ as a symbol of the archetype called "self". For example, written languages are composed of a variety of different symbols that create words. Through these written words humans communicate with each other. Kenneth Burke described "Homo sapiens" as a "symbol-using, symbol making, and symbol misusing animal" to suggest that a person creates symbols as well as misuses them. One example he uses to indicate what he means by the misuse of symbol is the story of a man who, when told that a particular food item was whale blubber, could barely keep from throwing it up. Later, his friend discovered it was actually just a dumpling. But the man's reaction was a direct consequence of the symbol of "blubber" representing something inedible in his mind. In addition, the symbol of "blubber" was created by the man through various kinds of learning.
Burke goes on to describe symbols as also being derived from Sigmund Freud's work on condensation and displacement, further stating that symbols are not just relevant to the theory of dreams but also to "normal symbol systems". He says they are related through "substitution", where one word, phrase, or symbol is substituted for another in order to change the meaning. In other words, if one person does not understand a certain word or phrase, another person may substitute a synonym or symbol in order to get the meaning across. However, upon learning the new way of interpreting a specific symbol, the person may change his or her already-formed ideas to incorporate the new information.
Jean Dalby Clift says that people not only add their own interpretations to symbols, they also create personal symbols that represent their own understanding of their lives: what she calls "core images" of the person. She argues that symbolic work with these personal symbols or core images can be as useful as working with dream symbols in psychoanalysis or counseling.
William Indick suggests that the symbols that are commonly found in myth, legend, and fantasy fulfill psychological functions and hence are why archetypes such as "the hero," "the princess" and "the witch" have remained popular for centuries.
Paul Tillich.
Paul Tillich argued that, while signs are invented and forgotten, symbols are born and die. There are, therefore, dead and living symbols. A living symbol can reveal to an individual hidden levels of meaning and transcendent or religious realities. For Tillich a symbol always "points beyond itself" to something that is unquantifiable and mysterious; symbols open up the "depth dimension of reality itself". Symbols are complex, and their meanings can evolve as the individual or culture evolves. When a symbol loses its meaning and power for an individual or culture, it becomes a dead symbol. The Greek Gods might be an example of symbols that were once living for the ancient Greeks but whose meaning and power are now gone.
When a symbol becomes identified with the deeper reality to which it refers, it becomes idolatrous as the "symbol is taken for reality." The symbol itself is substituted for the deeper meaning it intends to convey. The unique nature of a symbol is that it gives access to deeper layers of reality which are otherwise inaccessible.
Role of context in symbolism.
A symbol's meaning may be modified by various factors including popular usage, history, and contextual intent.
Historical meaning.
This history of a symbol is one of many factors in determining a particular symbol's apparent meaning. Consequently, symbols with emotive power carry problems analogous to false etymologies.
Context.
The context of a symbol may change its meaning. Similar five-pointed stars might signify a law enforcement officer or a member of the armed services, depending upon the uniform.
Symbolic action.
A symbolic action is an action that has no, or little, practical effect but symbolizes, or signals, what the actor wants or believes. The action conveys meaning to the viewers.
Symbolic action may overlap with symbolic speech, such as the use of flag burning to express hostility or saluting the flag to express patriotism.
In response to intense public criticism, businesses, organizations, and governments may take symbolic actions rather than, or in addition to, directly addressing the identified problems.
Symbolic actions are sometimes derided as slacktivism.

</doc>
<doc id="37674" url="https://en.wikipedia.org/wiki?curid=37674" title="Duck">
Duck

Duck is the common name for a large number of species in the waterfowl family Anatidae, which also includes swans and geese. The ducks are divided among several subfamilies in the family Anatidae; they do not represent a monophyletic group (the group of all descendants of a single common ancestral species) but a form taxon, since swans and geese are not considered ducks. Ducks are mostly aquatic birds, mostly smaller than the swans and geese, and may be found in both fresh water and sea water.
Ducks are sometimes confused with several types of unrelated water birds with similar forms, such as loons or divers, grebes, gallinules, and coots.
Etymology.
This word replaced Old English "ened/ænid" "duck", possibly to avoid confusion with other Old English words, like "ende" "end" with similar forms. Other Germanic languages still have similar words for "duck", for example, Dutch "eend" "duck" and German "Ente" "duck". The word "ened/ænid" was inherited from Proto-Indo-European; compare: Latin "anas" "duck", Lithuanian "ántis" "duck", Ancient Greek "nēssa"/"nētta" (νῆσσα, νῆττα) "duck", and Sanskrit "ātí" "water bird", among others.
A duckling is a young duck in downy plumage or baby duck; but in the food trade young adult ducks ready for roasting are sometimes labelled "duckling".
A male duck is called a drake and the female duck is called a duck, or in ornithology a hen.
Morphology.
The overall body plan of ducks is elongated and broad, and the ducks are also relatively long-necked, albeit not as long-necked as the geese and swans. The body shape of diving ducks varies somewhat from this in being more rounded. The bill is usually broad and contains serrated lamellae, which are particularly well defined in the filter-feeding species. In the case of some fishing species the bill is long and strongly serrated. The scaled legs are strong and well developed, and generally set far back on the body, more so in the highly aquatic species. The wings are very strong and are generally short and pointed, and the flight of ducks requires fast continuous strokes, requiring in turn strong wing muscles. Three species of steamer duck are almost flightless, however. Many species of duck are temporarily flightless while moulting; they seek out protected habitat with good food supplies during this period. This moult typically precedes migration.
The drakes of northern species often have extravagant plumage, but that is moulted in summer to give a more female-like appearance, the "eclipse" plumage. Southern resident species typically show less sexual dimorphism, although there are exceptions like the paradise shelduck of New Zealand which is both strikingly sexually dimorphic and where the female's plumage is brighter than that of the male. The plumage of juvenile birds generally resembles that of the female.
Behaviour.
Feeding.
Ducks exploit a variety of food sources such as grasses, aquatic plants, fish, insects, small amphibians, worms, and small molluscs.
Dabbling ducks feed on the surface of water or on land, or as deep as they can reach by up-ending without completely submerging. Along the edge of the beak there is a comb-like structure called a pecten. This strains the water squirting from the side of the beak and traps any food. The pecten is also used to preen feathers and to hold slippery food items.
Diving ducks and sea ducks forage deep underwater. To be able to submerge more easily, the diving ducks are heavier than dabbling ducks, and therefore have more difficulty taking off to fly.
A few specialized species such as the mergansers are adapted to catch and swallow large fish.
The others have the characteristic wide flat beak adapted to dredging-type jobs such as pulling up waterweed, pulling worms and small molluscs out of mud, searching for insect larvae, and bulk jobs such as dredging out, holding, turning head first, and swallowing a squirming frog. To avoid injury when digging into sediment it has no cere, but the nostrils come out through hard horn.
"The Guardian" (British newspaper) published an article on Monday 16 March 2015 advising that ducks should not be fed with bread because it damages the health of the ducks and pollutes waterways.
Breeding.
The ducks are generally monogamous, although these bonds generally last only a single year. Larger species and the more sedentary species (like fast river specialists) tend to have pair-bonds that last numerous years. Most duck species breed once a year, choosing to do so in favourable conditions (spring/summer or wet seasons). Ducks also tend to make a nest before breeding, and after hatching to lead their ducklings to water. Mother ducks are very caring and protective of their young, but may abandon some of their ducklings if they are physically stuck in an area they cannot get out of (including nesting in an enclosed courtyard) or are not prospering due to genetic defects or sickness brought about by hypothermia, starvation, or disease. Ducklings can also be orphaned by inconsistent late hatching where a few eggs hatch after the mother has abandoned the nest and led her ducklings to water.
Most domestic ducks neglect their eggs and ducklings, and their eggs must be hatched under a broody hen or artificially.
Communication.
Females of most dabbling ducks make the classic "quack" sound, but despite widespread misconceptions, most species of duck do not "quack". In general, ducks make a wide range of calls, ranging from whistles, cooing, yodels and grunts. For example, the scaup – which are diving ducks – make a noise like "scaup" (hence their name). Calls may be loud displaying calls or quieter contact calls.
A common urban legend claims that duck quacks do not echo; however, this has been shown to be false. This myth was first debunked by the Acoustics Research Centre at the University of Salford in 2003 as part of the British Association's Festival of Science. It was also debunked in one of the earlier episodes of the popular Discovery Channel television show "MythBusters".
Distribution and habitat.
The ducks have a cosmopolitan distribution. A number of species manage to live on sub-Antarctic islands like South Georgia and the Auckland Islands. Numerous ducks have managed to establish themselves on oceanic islands such as Hawaii, New Zealand and Kerguelen, although many of these species and populations are threatened or have become extinct.
Some duck species, mainly those breeding in the temperate and Arctic Northern Hemisphere, are migratory; those in the tropics, however, are generally not. Some ducks, particularly in Australia where rainfall is patchy and erratic, are nomadic, seeking out the temporary lakes and pools that form after localised heavy rain. 
Predators.
Worldwide, ducks have many predators. Ducklings are particularly vulnerable, since their inability to fly makes them easy prey not only for predatory birds but also large fish like pike, crocodilians, and other aquatic hunters, including fish-eating birds such as herons. Ducks' nests are raided by land-based predators, and brooding females may be caught unaware on the nest by mammals, such as foxes, or large birds, such as hawks or owls.
Adult ducks are fast fliers, but may be caught on the water by large aquatic predators including big fish such as the North American muskie and the European pike. In flight, ducks are safe from all but a few predators such as humans and the peregrine falcon, which regularly uses its speed and strength to catch ducks.
Relationship with humans.
Domestication.
Ducks have many economic uses, being farmed for their meat, eggs, and feathers (particularly their down). They are also kept and bred by aviculturists and often displayed in zoos. Almost all the varieties of domestic ducks are descended from the mallard ("Anas platyrhynchos"), apart from the Muscovy duck ("Cairina moschata").
Hunting.
In many areas, wild ducks of various species (including ducks farmed and released into the wild) are hunted for food or sport, by shooting, or formerly by decoys. Because an idle floating duck or a duck squatting on land cannot react to fly or move quickly, "a sitting duck" has come to mean "an easy target". These ducks may be contaminated by pollutants such as PCBs.
Cultural references.
In 2002, psychologist Richard Wiseman and colleagues at the University of Hertfordshire, UK, finished a year-long LaughLab experiment, concluding that of all animals, ducks attract the most humor and silliness; he said, "If you're going to tell a joke involving an animal, make it a duck." The word "duck" may have become an inherently funny word in many languages, possibly because ducks are seen as silly in their looks or behavior. Of the many ducks in fiction, many are cartoon characters, such as Walt Disney's Donald Duck, and Warner Bros.' Daffy Duck. Howard the Duck started as a comic book character in 1973, made in 1986 into a movie. The 1992 Disney film "The Mighty Ducks", starring Emilio Estevez chose the duck as the mascot for the fictional youth hockey team who are protagonists of the movie, based on the duck being described as a fierce fighter. This led to the duck becoming the nickname and mascot for the eventual National Hockey League professional team Anaheim Ducks. The duck is also the nickname of the University of Oregon sports teams as well as the Long Island Ducks minor league baseball team.

</doc>
<doc id="37678" url="https://en.wikipedia.org/wiki?curid=37678" title="Denver (disambiguation)">
Denver (disambiguation)

Denver is the capital of the U.S. state of Colorado
Denver may also refer to:
Places.
United States.
Denver City, Denver County, Colorado, 

</doc>
<doc id="37684" url="https://en.wikipedia.org/wiki?curid=37684" title="Libertarian Movement (Costa Rica)">
Libertarian Movement (Costa Rica)

The Libertarian Movement Party (Spanish: "Partido Movimiento Libertario"; PML) is a political party based on classical liberalism in Costa Rica. It was founded in May 1994.
History.
Founded by partyless liberals from the Academy and liberal defectors of Social Christian Unity Party, contested the 1998 election with Federico Malavassi as candidate receiving only 0.4% of the vote but succeeding in getting attorney Otto Guevara elected as member of the Legislative Assembly. In this time the party was strongly libertarian and was in favor of minimal government (something quite polemic in a Welfare State like Costa Rica when even the right-wing parties as the Social Christians tend to accept social programs and government intervention), legalization of recreational drugs, same-sex marriage, abortion and the like.
In 2002, Guevara ran for president (unsuccessfully, 1.7% of the vote), and the party at the legislative elections won 9.3% of the popular vote and 6 out of 57 seats. A few weeks after taking office, one Congressman left the party and became independent, leaving PML with five seats. In 2006, Guevara again ran for president (unsuccessfully, 8.4% of the vote), and the party at the legislative elections won 9.1% of the popular vote and 6 out of 57 seats. In the 2010 general election Guevara was again the PML's presidential candidate and received 20% of the popular vote, it also increased its number of deputies to nine (even so three of this deputies defects from the party before the end of the legislatie period). At the municipal level the party obtain one mayor in 2006 and two in 2010.
In its 2014 electoral campaign, the party took a more socially conservative position, totally opposing the legalisation of abortion and rejecting homosexual couples' right to a marriage license.
The party suffered a debacle in the 2014 election, as was relegated to fourth place after PAC, PLN and FA parties, and reducing its congressional representation to less than half (four seats), also was unable to elect any mayor in the 2016 mid-term municipal election. This electoral debacle was also costly, as the party was unable to pay some of its campaign debts to both workers, Social Security, loaners and Banks. As previously, in 2015 another deputy defects; Carmen Quesada, who declares herself independent.
Also in 2015 several party members went to trial after been accused of fraud by the State, apparently trying to trick the Electoral Tribunal in paying for trainings that were already cover by the Friedrich Naumann Foundation. Judges sentenced party’s vice president, treasurer and accountant to eight years in prison.

</doc>
<doc id="37686" url="https://en.wikipedia.org/wiki?curid=37686" title="Disabled sports">
Disabled sports

Disabled sports, also adaptive sports or parasports, are sports played by persons with a disability, including physical and intellectual disabilities. As many disabled sports are based on existing able bodied sports, modified to meet the needs of persons with a disability, they are sometimes referred to as "adapted sports". However, not all disabled sports are adapted; several sports that have been specifically created for persons with a disability have no equivalent in able-bodied sports. Disability exists in four categories: physical, mental, permanent and temporary.
Organization and history.
Organized sport for athletes with a disability is generally divided into three broad disability groups: the deaf, people with physical disabilities, and people with intellectual disabilities. Each group has a distinct history, organization, competition program, and approach to sport.
Formal international competition in deaf sport began with the 1924 Paris "Silent Games", organized by the Comité International des Sports des Sourds, CISS (The International Committee of Sports for the Deaf). These games evolved into the modern Deaflympics, governed by the CISS. The CISS maintains separate games for deaf athletes based on their numbers, their special communication needs on the sports field, and the social interaction that is a vital part of sports.
Organized sport for persons with physical disabilities existed as early as 1911, when the "Cripples Olympiad" was held in the U.S.A. One of the successful athletes was Walter William Francis, a Welshman, who won both the running and wrestling championships. Later, events often developed out of rehabilitation programs. Following the Second World War, in response to the needs of large numbers of injured ex-service members and civilians, sport was introduced as a key part of rehabilitation. Sport for rehabilitation grew into recreational sport and then into competitive sport. The pioneer of this approach was Sir Ludwig Guttmann of the Stoke Mandeville Hospital in England. In 1948, while the Olympic Games were being held in London, he organized a sports competition for wheelchair athletes at Stoke Mandeville. This was the origin of the Stoke Mandeville Games, which evolved into the modern Paralympic Games. The first official Paralympic Games, after the name change, was held in Rome in 1960. In 1975, the Paralympic Games expanded to include those with limb amputations and visual impairments. Individuals with cerebral palsy were allowed to compete beginning in 1980. 
Currently, Paralympic sport is governed by the International Paralympic Committee, in conjunction with a wide range of other international sport organizations. Today, there are numerous sport opportunities throughout the United States for injured service members, including cycling, wheelchair tennis, shooting, wheelchair basketball, track and field, adapted water sports, and snow skiing. One such program is the Wounded Warrior program, which offers sitting volleyball to injured service members. Some organizations also offer sport opportunities to family and friends of injured service members in addition to the members themselves. 
Sport for persons with intellectual disabilities began to be organized in the 1960s through the Special Olympics movement. This grew out of a series of summer camps organized by Eunice Kennedy Shriver, beginning in 1962. In 1968 the first international Special Olympics were held, in Chicago. Today, Special Olympics provides training and competition in a variety of sports for persons with intellectual disabilities.
Sport for persons with physical disabilities began to be organized in the US in the late 1960s through Disabled Sports USA. Disabled Sports USA was established in 1967 by disabled military veterans, including Jim Winthers, to help rehabilitate the injured soldiers returning from Vietnam and originally named the National Amputee Skiers Association. In 1970, Hal O'Leary founded the National Sports Center for the Disabled (NSCD) at Winter Park in Colorado. Today, NSCD has 19 certified instructors and more than 1,000 volunteers. Disabled Sports USA has become one of the largest national multi-sport, multi-disability organizations in the United States, serving more than 60,000 wounded warriors, youth and adults annually.
In 1986, the International Sports Federation for Persons with Intellectual Disability (INAS-FID) was formed to support elite competition for athletes with intellectual disabilities. This was established in contrast to the more participative, "sport for all" approach of Special Olympics. For a time, athletes with intellectual disabilities were included in the Paralympic Games. After a cheating scandal at the 2000 Summer Paralympics, where a number of athletes participating in intellectual disability events were revealed to not be disabled, INAS-FID athletes were banned from Paralympic competition, but the ban on intellectually disabled athletes has since been lifted.
In 2006, the Extremity Games was formed for people with limb loss or limb difference to compete in extreme sports. College Park Industries, a manufacturer of prosthetic feet, organized this event to give amputee athletes a venue to compete in this increasingly popular sports genre also referred to as action sports. This annual event held in the summer in Orlando, FL includes competitions in skateboarding, wakeboarding, rock climbing, mountain biking, surfing, moto-x and kayaking. Various organizations, such as Paradox Sports, have arisen to help empower and inspire disabled people through equipping and welcoming them into the extreme sports community.
In 2007, a group of San Diego, California-based athletes, coaches, volunteers, and parents split from Special Olympics Southern California to gain local control over disabled athletics programs. This group -- SPORTS for Exceptional Athletes (S4EA) -- serves people with developmental disabilities within the age range of 5 years old through adults. By combining people with and without disabilities, S4EA hopes that participating athletes will interact and form lasting bonds of friendship through shared sports and recreational activities in S4EA's served communities. Although the organization's focus is primarily San Diego County, S4EA has grown from this base to satellite programs in Ventura and Temecula, California.
Since 1988, the International Olympic Committee have chosen to validate Disabled Sports (physical disabilities) and incorporate it as a part of the Games: the staging of the Paralympic Games immediately follows the Olympic Games. This scheduling helps to foster greater interest in disabled sports. An investigation published on a Swiss website has /shown that more and more International Sports Federations list disabled athletes than any other sportsmen or sportswomen.
Adapted sports help society learn about disability. They also can help remove some of the stigma associated with having a disability.
Sports.
A wide range of sports have been adapted to be played by people with various disabilities, as well as several that are unique to disabled athletes. Within each movement, different sports are practised at different levels; for example, not all sports in the Paralympic movement are part of the Paralympic Games. In addition, many sports are practiced by persons with a disability outside the formal sports movements.
Inclusion.
Beginning in the late 1980s and early 1990s, work began within several countries and organizations to include athletes with disabilities in the able-bodied sport system. This included adding events for athletes with disabilities to major games such as the Olympic Games and the Commonwealth Games, and integration of these athletes into able-bodied sports organizations.
Since 1984, the Olympics have included exhibition events for Paralympic athletes. However, integration of full medal events has not taken place, and the status of athletes with a disability in the Olympic movement remains controversial.
Within the Commonwealth Games, athletes with a disability were first included in exhibition events in 1994, and at the 2002 Manchester Commonwealth Games they were included as full members of their national teams, making these the first fully inclusive international multi-sport games. This policy has continued with the 2006 Melbourne Commonwealth Games, where Canadian Chantal Petitclerc became the first athlete with a disability to carry her country's flag in the Opening Ceremonies of an integrated games.
Individual athletes such as swimmer Natalie du Toit and track athlete Oscar Pistorius have competed as equals against able bodied athletes at various events including the Olympic Games.
2013 the FIFA decided that Austrian footballer Martin Hofbauer can continue to play competitive football with prosthetics after he lost his right lower leg due to cancer.
The Self-Determination Theory has been one of the most proven theories on how athletes participate in competitions of this level. Studies have supported this theory especially in intellectually or developmentally disabled athletes. Studies have continued to question the motivation for joining such competitions like the Special Olympics as well as the Paralympic Games. The Motivations for joining the Special Olympics uncover themes among individuals and families for their participation or abstention from these Olympic programs.
Unified sports.
"Unified sports" involve teams made up of athletes with and without disabilities. Since the 1990s, Special Olympics Unified Sports have been promoting social inclusion through shared sports training and competition. This initiative has expanded globally and now involves more than 700,000 players in 127 countries worldwide. The principle behind Unified Sports is simple: training together and playing together is a quick path to friendship and understanding.
The NBA has been a major supporter of Unified Sports, sponsoring the annual NBA Cares Special Olympics Unified Basketball Game during the NBA All-Star Weekend. The Walt Disney Company, ESPN and Special Olympics are also working on a two-year global initiative that will leverage the power of sports to promote an environment of social inclusion and acceptance.
Minnesota Adapted Athletics Association.
In 1969, Jim Christy, along with some other students at Marshall U High in Minnesota, asked their physical education teacher why students with physical disabilities could not participate in athletic competitions that able-bodied students could. During this time, Christy and other students played floor hockey during physical education class and at the Courage Center. In 1971, the rules of adapted floor hockey kept evolving at Marshall U High and Courage Center.
In 1974, the first organized Adapted Floor Hockey league was created. The first game was also played. This league consisted of four teams. There were two teams from Marshall U High, one from the Courage Center and one alumni team. A year later this league became only for secondary school students only. Two of the teams were from St. Paul, one from Marshall U High and one from Minneapolis. In 1976, athletic letters were given to participants who played in adapted athletics.
In 1978, an organized conference called the Minnesota Adapted Athletics Association (MAAA) was established. The first year of adapted soccer was in 1979. It consisted of six teams: St Paul Independents, St Paul Humboldt, Anoka, Osseo, Minneapolis Independents, and Marshall U High. The spring of 1983 was the start of adapted softball. The MAAA was officially incorporated in 1984 and became part of the Minnesota State High School League in 1992.
Minnesota is currently host to the only organized high school adapted athletics league. The MAAA still continues today.

</doc>
<doc id="37688" url="https://en.wikipedia.org/wiki?curid=37688" title="Gaelic football">
Gaelic football

Gaelic football (Irish: "Peil Ghaelach"; short name "Peil" or "Caid"), commonly referred to as football or Gaelic, is an Irish team sport. It is a form of football derived from traditional Irish ball games. It is played between two teams of 15 players on a rectangular grass pitch. The objective of the sport is to score by kicking or punching the ball into the other team's goals (3 points) or between two upright posts above the goals and over a crossbar above the ground (1 point).
Players advance the football, a spherical leather ball, up the field with a combination of carrying, bouncing, kicking, hand-passing, and soloing (dropping the ball and then toe-kicking the ball upward into the hands). In the game, two types of scores are possible: points and goals. A point is awarded for kicking or hand-passing the ball over the crossbar, signalled by the umpire raising a white flag. A goal is awarded for kicking the ball under the crossbar into the net, signalled by the umpire raising a green flag. Positions in Gaelic football are similar to that in other football codes, and comprise one goalkeeper, six backs, two midfielders, and six forwards, with a variable number of substitutes.
Gaelic football is one of four sports (collectively referred to as the "Gaelic games") controlled by the Gaelic Athletic Association (GAA), the largest sporting organisation in Ireland. Along with hurling and camogie, Gaelic football is one of the few remaining strictly amateur sports in the world, with players, coaches, and managers prohibited from receiving any form of payment. Gaelic football is mainly played on the island of Ireland, although units of the Association exist in other areas such as Great Britain and North America.
Gaelic football is the most popular sport in Ireland in terms of attendance, and the final of the All-Ireland Senior Championship, held annually at Croke Park, Dublin, draws crowds of more than 80,000 people. Outside Ireland, football is mainly played among members of the Irish diaspora. Gaelic Park in New York City is the largest purpose-built Gaelic sports venue outside Ireland. Three major football competitions operate throughout the year: the National Football League and the All-Ireland Senior Championship operate on an inter-county basis, while the All-Ireland Club Championship is contested by individual clubs. The All-Ireland Senior Championship is considered the most prestigious event in Gaelic football.
Under the auspices of the GAA, Gaelic football is a male-only sport; however, the related sport of ladies' Gaelic football is governed by the Ladies' Gaelic Football Association. Similarities between Gaelic football and Australian rules football have allowed the development of international rules football, a hybrid sport, and a series of Test matches has been held regularly since 1998.
History.
Gaelic football was first codified in 1887, although it has links to older varieties of football played in Ireland and known collectively as "caid". Consequently, the name "caid" is used by some people to refer to present day Gaelic football.
The first legal reference of football in Ireland was in 1308, when John McCrocan, a spectator at a football game at "Novum Castrum de Leuan" (the New Castle of the Lyons or Newcastle) was charged with accidentally stabbing a player named William Bernard. A field near Newscastle, Co. Dublin is still known as the football field.
The Statute of Galway of 1527 allowed the playing of "foot balle" and archery but banned "'hokie' — the hurling of a little ball with sticks or staves" as well as other sports.
By the 17th century, the situation had changed considerably. The games had grown in popularity and were widely played. This was due to the patronage of the gentry. Now instead of opposing the games it was the gentry and the ruling class who were serving as patrons of the games. Games were organised between landlords with each team comprising 20 or more tenants. Wagers were commonplace with purses of up to 100 guineas (Prior, 1997).
The earliest record of a recognised precursor to the modern game date from a match in County Meath in 1670, in which catching and kicking the ball was permitted.
However even "foot-ball" was banned by the severe Sunday Observance Act of 1695, which imposed a fine of one shilling (a substantial amount at the time) for those caught playing sports. It proved difficult, if not impossible, for the authorities to enforce the Act and the earliest recorded inter-county match in Ireland was one between Louth and Meath, at Slane, in 1712, about which the poet James Dall McCuairt wrote a poem of 88 verses beginning "Ba haigeanta".
A six-a-side version was played in Dublin in the early 18th century, and 100 years later there were accounts of games played between County sides (Prior, 1997).
By the early 19th century, various football games, referred to collectively as "caid", were popular in Kerry, especially the Dingle Peninsula. Father W. Ferris described two forms of "caid": the "field game" in which the object was to put the ball through arch-like goals, formed from the boughs of two trees, and; the epic "cross-country game", which lasted the whole of a Sunday (after mass) and was won by taking the ball across a parish boundary. "Wrestling", "holding" opposing players, and carrying the ball were all allowed.
During the 1860s and 1870s, Rugby football started to become popular in Ireland. Trinity College, Dublin was an early stronghold of Rugby, and the rules of the (English) Football Association were codified in 1863 and distributed widely. By this time, according to Gaelic football historian Jack Mahon, even in the Irish countryside, "caid" had begun to give way to a "rough-and-tumble game", which even allowed tripping. Association football started to take hold, especially in Ulster, in the 1880s.
Limerick was the stronghold of the native game around this time, and the Commercials Club, founded by employees of Cannock's Drapery Store, was one of the first to impose a set of rules, which was adapted by other clubs in the city. Of all the Irish pastimes the GAA set out to preserve and promote, it is fair to say that Gaelic football was in the worst shape at the time of the association's foundation (GAA Museum, 2001).
Irish forms of football were not formally arranged into an organised playing code by the Gaelic Athletic Association (GAA) until 1887. The GAA sought to promote traditional Irish sports, such as hurling and to reject "foreign" (particularly English) imports. The first Gaelic football rules, showing the influence of hurling and a desire to differentiate from association football – for example in their lack of an offside rule — were drawn up by Maurice Davin and published in the "United Ireland" magazine on 7 February 1887. The rules of the aforementioned Commercials Club became the basis for these official (Gaelic Football) rules who, unsurprisingly, won the inaugural All-Ireland Senior Football Final (representing County Limerick). The very first game of Gaelic Football under GAA rules (developed by Maurice Davin) was played near Callan, Co Kilkenny in February 1885. 
On Bloody Sunday in 1920, during the Anglo-Irish War, a football match at Croke Park was attacked by British forces. 14 people were killed and 65 were injured. Among the dead was Tipperary footballer Michael Hogan, for whom the Hogan Stand at Croke Park (completed in 1924) was named.
By 1958, Wembley Stadium hosted annual exhibition games of Gaelic football in England, before tens of thousands of spectators.
Ladies' Gaelic football has become increasingly popular with women since the 1970s.
The relationship between Gaelic football and Australian rules football and the question of whether they have shared origins is a matter of historical controversy. Games are held between an Irish representative team and an Australian team, under compromise rules known as international rules football.
Rules.
Playing field.
A Gaelic pitch is similar in some respects to a rugby pitch but larger. The grass pitch is rectangular, stretching long and wide. There are H-shaped goalposts at each end, formed by two posts, which are usually high, set apart, and connected above the ground by a crossbar. A net extending behind the goal is attached to the crossbar and lower goal posts. The same pitch is used for hurling; the GAA, which organises both sports, decided this to facilitate dual usage. Lines are marked at distances of 13 metres, 20 metres and 45 metres (65m in Hurling) from each end-line. Shorter pitches and smaller goals are used by youth teams.
Duration.
The majority of adult football and all minor and under-21 matches last for 60 minutes, divided into two halves of 30 minutes, with the exception of senior inter-county games, which last for 70 minutes (two halves of 35 minutes). Draws are decided by replays or by playing 20 minutes of extra time (two halves of 10 minutes). Juniors have a half of 20 minutes or 25 minutes in some cases. Half-time lasts for about 5 or 10 minutes.
Teams.
Teams consist of fifteen players (a goalkeeper, two corner backs, a full back, two wing backs, a centre back, two mid fielders, two wing forwards, a centre forward, two corner forwards and a full forward) plus up to fifteen substitutes, of which five may be used. Each player is numbered 1–15, starting with the goalkeeper, who must wear a jersey colour different from that of his or her teammates. Up to fifteen substitutes may be named on the team sheet, number 16 usually being the reserve goalkeeper.
Ball.
The game is played with a round leather football made of 18 stitched leather panels, similar in appearance to a traditional volleyball (but larger), with a circumference of , weighing between when dry. It may be kicked or "hand passed". A hand pass is not a punch but rather a strike of the ball with the side of the closed fist, using the knuckle of the thumb.
Types of fouls.
There are three main types of fouls in Gaelic Football, which can result in the ball being given to the other team, a player being cautioned, a player being removed from the field, or even the game being terminated.
Technical.
The following are considered technical fouls ("fouling the ball"):
Aggressive.
Aggressive fouls are physical or verbal fouls committed by a player against an opponent or the referee. The player can be cautioned (shown a yellow card), ordered off the pitch without a substitute (red card), or (beginning 1 January 2014) ordered off the pitch with a substitution (Black Card).
Dissent.
A dissent foul is a foul where a player fails to comply with the officials' judgment and/or instructions. The player can be cautioned (shown a yellow card), ordered off the pitch without a substitute (red card), the free kick placement moved 13m further down-field, or in certain circumstances, the game can be terminated.
The following are considered dissent fouls:
Scoring.
If the ball goes over the crossbar, a "point" is scored and a white flag is raised by an umpire. A point is scored by either kicking the ball over the crossbar, or fisting it over, in which case the hand must be closed while striking the ball. If the ball goes below the crossbar, a "goal", worth three points, is scored, and a green flag is raised by an umpire. A goal is scored by kicking the ball into the net, not by fist passing the ball into it. However, a player can strike the ball into the net with a closed fist if the ball was played to him by another player or came in contact with the post/crossbar/ground prior to connection. The goal is guarded by a goalkeeper. Scores are recorded in the format Goal Total-Point Total. To determine the score-line goals must be converted to points and added to the other points. For example, in a match with a final score of Team A 0–21 Team B 4–8, Team A is the winner with 21 points, as Team B scored only 20 points (4 times 3, plus 8).
Tackling.
The level of tackling allowed is more robust than in association football, but less than rugby.
Shoulder to shoulder contact and slapping the ball out of an opponent's hand are permitted, but the following are all fouls:
Officials.
A football match is overseen by up to eight officials:
The referee is responsible for starting and stopping play, recording the score, awarding frees and booking and sending off players.
Linesmen are responsible for indicating the direction of line balls to the referee.
The fourth official is responsible for overseeing substitutions, and also indicating the amount of stoppage time (signalled to him by the referee) and the players substituted using an electronic board.
The umpires are responsible for judging the scoring. They indicate to the referee whether a shot was: wide (spread both arms), a 45m kick (raise one arm), a point (wave white flag), square ball (cross arms) or a goal (wave green flag). A disallowed score is indicated by crossing the green and white flags.
Other officials are not obliged to indicate any misdemeanours to the referee; they are only permitted to inform the referee of violent conduct they have witnessed that has occurred without the referee's knowledge. A linesman/umpire is not permitted to inform the referee of technical fouls such as a "double bounce" or an illegal pick up of the ball. Such decisions can only be made at the discretion of the referee.
Team of the Century.
The Team of the Century was nominated in 1984 by "Sunday Independent" readers and selected by a panel of experts including journalists and former players. It was chosen as part of the Gaelic Athletic Association's centenary year celebrations. The goal was to single out the best ever 15 players who had played the game in their respective positions. Naturally many of the selections were hotly debated by fans around the country.
Team of the Millennium.
The Team of the Millennium was a team chosen in 1999 by a panel of GAA past presidents and journalists. The goal was to single out the best ever 15 players who had played the game in their respective positions, since the foundation of the GAA in 1884 up to the Millennium year, 2000. Naturally many of the selections were hotly debated by fans around the country.
Competition structure.
Gaelic sports at all levels are amateur, in the sense that the athletes even those playing at elite level do not receive payment for their performance 
The main competitions at all levels of Gaelic football are the League and the Championship. Of these it is the Championship (a knock-out tournament) that tends to attain the most prestige.
The basic unit of each game is organised at the club level, which is usually arranged on a parochial basis. Local clubs compete against other clubs in their county with the intention of winning the County Championship at senior, junior or intermediate levels (for adults) or under-21, minor or under-age levels (for children). A club may field more than one team, for example a club may field a team at senior level and a "seconds" team at junior or intermediate level. This format is laid out in the table below:
Though the island of Ireland was partitioned between two states by the British parliament in 1920, the organisation of Gaelic games (like that of most cultural organisations and religions) continues on an All-Ireland basis. At national level, Ireland's Gaelic games are organised in 32 GAA counties, most of which are identical in name and extent to the 32 administrative counties on which local government throughout the island was based until the late 20th century. The term "county" is also used for some overseas GAA areas, such as London and New York. Clubs are also located throughout the world, in other parts of the United States, in Britain, in Canada, in Asia, in Australasia and in continental Europe.
The level at which county teams compete against each other is referred to as inter-county (i.e. similar to international) A county panel – a team of 15 players, plus a similar number of substitutes – is formed from the best players playing at club level in each county. The most prestigious inter-county competition in Gaelic football is the All-Ireland Championship. The highest level national championship is called the All-Ireland Senior Football Championship. Nearly all counties contest this tournament on an annual basis, with crowds of people thronging venues the length and breadth of Ireland – the most famous of these stadiums being Croke Park – to support their local county team, a team comprising players selected from the clubs in that county. These modified knock-out games start as provincial championships contested by counties against other counties in their respective province, the four Irish provinces of Ulster, Munster, Leinster and Connacht. The four victors in these then progress automatically to the All-Ireland series.
In the past, the team winning each provincial championship would play one of the others, at a stage known as the All-Ireland semi-finals, with the winning team from each game playing each other in the famed All-Ireland Final to determine the outright winner. A recent (1990s/2000s) re-organisation created a "back door" method of qualifying, with teams knocked out during the provincial rounds of the All-Ireland Championship now acquiring a second chance at glory. Now the four victorious teams at provincial level enter the recently created All-Ireland quarter-finals instead, where they compete against the four remaining teams from the All-Ireland Qualifiers to progress to the All-Ireland semi-finals and then the All-Ireland Final. This re-organisation means that one team may defeat another team in an early stage of the championship, yet be defeated and knocked out of the tournament by the same team at a later stage. It also means a team may be defeated in an early stage of the championship, yet be crowned All-Ireland champions—as Tyrone were in 2005 and 2008.
The secondary competition at inter-county level is the National League. The National Football League is held every spring and groups counties in four divisions according to their relative strength. As at local (county) levels of Gaelic football, the League at national level is less prestigious than the Championship—however, in recent years attendances have grown, as has interest from the public and from players. This is due in part to the 2002 adoption of a February–April timetable, in place of the former November start, as well as the provision of Division 2 final stages. Live matches are aired on the international channel Setanta Sports and the Irish language channel TG4, with highlights shown on RTÉ Two.
There are also All-Ireland championships for county teams at Junior, Under-21 and Minor levels, and provincial and national club championships, contested by the teams that win their respective county championships.

</doc>
<doc id="37689" url="https://en.wikipedia.org/wiki?curid=37689" title="Martin Brennan (engineer)">
Martin Brennan (engineer)

Martin Brennan is a computer engineer who developed pioneering personal computers such as the Loki (for Sinclair Research) and the Atari Jaguar video game console.
A physics graduate of Cambridge University, he was a co-founder of Flare Technology, a design house involved in the design of the ill-fated Konix Multisystem.
Brennan initially worked for Sinclair Research where he designed the digital electronics and software in ZX Interface 1 before going on to found Flare with ex-Sinclair colleagues John Mathieson and Ben Cheese. After working at Flare on the "Flare 1" and its development into the Konix Multisystem he went on to work for Atari developing the Atari Panther and the Atari Jaguar.
In 1997 Brennan founded the "Cheap & Cheerful Chip Company" which later went on to become Global Silicon Limited
In 2007 Brennan designed the Brennan JB7 digital jukebox produced by 3GA Ltd (Third Generation Audio)
The second generation audio player, Brennan B2 with web interface, based on the Raspberry PI chipset, is available as of 2015.

</doc>
<doc id="37694" url="https://en.wikipedia.org/wiki?curid=37694" title="Seed">
Seed

A seed is an embryonic plant enclosed in a protective outer covering. The formation of the seed is part of the process of reproduction in seed plants, the spermatophytes, including the gymnosperm and angiosperm plants.
Seeds are the product of the ripened ovule, after fertilization by pollen and some growth within the mother plant. The embryo is developed from the zygote and the seed coat from the integuments of the ovule.
Seeds have been an important development in the reproduction and success of gymnosperms and angiosperms plants, relative to more primitive plants such as ferns, mosses and liverworts, which do not have seeds and use other means to propagate themselves. Seed plants now dominate biological niches on land, from forests to grasslands both in hot and cold climates.
The term "seed" also has a general meaning that antedates the above—anything that can be sown, e.g. "seed" potatoes, "seeds" of corn or sunflower "seeds". In the case of sunflower and corn "seeds", what is sown is the seed enclosed in a shell or husk, whereas the potato is a tuber.
Many structures commonly referred to as "seeds" are actually dry fruits. Plants producing berries are called baccate. Sunflower seeds are sometimes sold commercially while still enclosed within the hard wall of the fruit, which must be split open to reach the seed. Different groups of plants have other modifications, the so-called stone fruits (such as the peach) have a hardened fruit layer (the endocarp) fused to and surrounding the actual seed. Nuts are the one-seeded, hard-shelled fruit of some plants with an indehiscent seed, such as an acorn or hazelnut.
Production.
Seeds are produced in several related groups of plants, and their manner of production distinguishes the angiosperms ("enclosed seeds") from the gymnosperms ("naked seeds"). Angiosperm seeds are produced in a hard or fleshy structure called a fruit that encloses the seeds, hence the name. (Some fruits have layers of both hard and fleshy material). In gymnosperms, no special structure develops to enclose the seeds, which begin their development "naked" on the bracts of cones. However, the seeds do become covered by the cone scales as they develop in some species of conifer.
Seed production in natural plant populations vary widely from year-to-year in response to weather variables, insects and diseases, and internal cycles within the plants themselves. Over a 20-year period, for example, forests composed of loblolly pine and shortleaf pine produced from 0 to nearly 5 million sound pine seeds per hectare. Over this period, there were six bumper, five poor, and nine good seed crops, when evaluated in regard to producing adequate seedlings for natural forest reproduction.
Development.
Angiosperm (flowering plants) seeds consist of three genetically distinct constituents: (1) the embryo formed from the zygote, (2) the endosperm, which is normally triploid, (3) the seed coat from tissue derived from the maternal tissue of the ovule. In angiosperms, the process of seed development begins with double fertilization, which involves the fusion of two male gametes with the egg cell and the central cell to form the primary endosperm and the zygote. Right after fertilization, the zygote is mostly inactive, but the primary endosperm divides rapidly to form the endosperm tissue. This tissue becomes the food the young plant will consume until the roots have developed after germination.
Ovule.
After fertilization the ovules develop into the seeds. The ovule consists of a number of components:
The shape of the ovules as they develop often affects the final shape of the seeds. Plants generally produce ovules of four shapes: the most common shape is called anatropous, with a curved shape. Orthotropous ovules are straight with all the parts of the ovule lined up in a long row producing an uncurved seed. Campylotropous ovules have a curved megagametophyte often giving the seed a tight "C" shape. The last ovule shape is called amphitropous, where the ovule is partly inverted and turned back 90 degrees on its stalk (the funicle or funiculus).
In the majority of flowering plants, the zygote's first division is transversely oriented in regards to the long axis, and this establishes the polarity of the embryo. The upper or chalazal pole becomes the main area of growth of the embryo, while the lower or micropylar pole produces the stalk-like suspensor that attaches to the micropyle. The suspensor absorbs and manufacturers nutrients from the endosperm that are used during the embryo's growth.
Embryo.
The main components of the embryo are:
Monocotyledonous plants have two additional structures in the form of sheaths. The plumule is covered with a coleoptile that forms the first leaf while the radicle is covered with a coleorhiza that connects to the primary root and adventitious roots form from the sides. Here the hypocotyl is a rudimentary axis between radicle and plumule. The seeds of corn are constructed with these structures; pericarp, scutellum (single large cotyledon) that absorbs nutrients from the endosperm, plumule, radicle, coleoptile and coleorhiza—these last two structures are sheath-like and enclose the plumule and radicle, acting as a protective covering.
Seed coat.
The maturing ovule undergoes marked changes in the integuments, generally a reduction and disorganisation but occasionally a thickening. The seed coat forms from the two integuments or outer layers of cells of the ovule, which derive from tissue from the mother plant, the inner integument forms the tegmen and the outer forms the testa. (The seed coats of some mononocotyledon plants, such as the grasses, are not distinct structures, but are fused with the fruit wall to form a pericarp.) The testae of both monocots and dicots are often marked with patterns and textured markings, or have wings or tufts of hair. When the seed coat forms from only one layer, it is also called the testa, though not all such testae are homologous from one species to the next. The funiculus abscises (detaches at fixed point – abscission zone), the scar forming an oval depression, the hilum. Anatropous ovules have a portion of the funiculus that is adnate (fused to the seed coat), and which forms a longitudinal ridge, or raphe, just above the hilum. In bitegmic ovules (e.g. "Gossypium" described here) both inner and outer integuments contribute to the seed coat formation. With continuing maturation the cells enlarge in the outer integument. While the inner epidermis may remain a single layer, it may also divide to produce two to three layers and accumulates starch, and is referred to as the colourless layer. By contrast the outer epidermis becomes tanniferous. The inner integument may consist of eight to fifteen layers. (Kozlowski 1972)
As the cells enlarge, and starch is deposited in the outer layers of the pigmented zone below the outer epidermis, this zone begins to lignify, while the cells of the outer epidermis enlarge radially and their walls thicken, with nucleus and cytoplasm compressed into the outer layer. these cells which are broader on their inner surface are called palisade cells. In the inner epidermis the cells also enlarge radially with plate like thickening of the walls. The mature inner integument has a palisade layer, a pigmented zone with 15-20 layers, while the innermost layer is known as the fringe layer. (Kozlowski 1972)
Gymnosperms.
In gymnosperms, which do not form ovaries, the ovules and hence the seeds are exposed. This is the basis for their nomenclature – naked seeded plants (gymnosperms). Two sperm cells transferred from the pollen do not develop seed by double fertilization, but one sperm nucleus unites with the egg nucleus and the other sperm is not used. Sometimes each sperm fertilizes an egg cell and one zygote is then aborted or absorbed during early development. The seed is composed of the embryo (the result of fertilization) and tissue from the mother plant, which also form a cone around the seed in coniferous plants such as pine and spruce.
Shape and appearance.
A large number of terms are used to describe seed shapes, many of which are largely self-explanatory such as "Bean-shaped" (reniform) – resembling a kidney, with lobed ends on either side of the hilum, "Square" or "Oblong" – angular with all sides more or less equal or longer than wide, "Triangular" – three sided, broadest below middle, "Elliptic" or "Ovate" or "Obovate" – rounded at both ends, or egg shaped (ovate or obovate, broader at one end), being rounded but either symmetrical about the middle or broader below the middle or broader above the middle.
Other less obvious terms include discoid (resembling a disc or plate, having both thickness and parallel faces and with a rounded margin), ellipsoid, globose (spherical), or subglobose (Inflated, but less than spherical), lenticular, oblong, ovoid, reniform and sectoroid. Striate seeds are striped with parallel, longitudinal lines or ridges. The commonest colours are brown and black, other colours are infrequent. The surface varies from highly polished to considerably roughened. The surface may have a variety of appendages (see Seed coat). A seed coat with the consistency of cork is referred to as suberose. Other terms include crustaceous (hard, thin or brittle).
Structure.
A typical seed includes two basic parts:
In addition, the endosperm forms a supply of nutrients for the embryo in most monocotyledons and the endospermic dicotyledons.
Seed types.
Seeds have been considered to occur in many structurally different types (Martin 1946). These are based on a number of criteria, of which the dominant one is the embryo-to-seed size ratio. This reflects the degree to which the developing cotyledons absorb the nutrients of the endosperm, and thus obliterate it.
Six types occur amongst the monocotyledons, ten in the dicotyledons, and two in the gymnosperms (linear and spatulate). This classification is based on three characteristics: embryo morphology, amount of endosperm and the position of the embryo relative to the endosperm.
Embryo.
In endospermic seeds, there are two distinct regions inside the seed coat, an upper and larger endosperm and a lower smaller embryo. The embryo is the fertilised ovule, an immature plant from which a new plant will grow under proper conditions. The embryo has one cotyledon or seed leaf in monocotyledons, two cotyledons in almost all dicotyledons and two or more in gymnosperms. In the fruit of grains (caryopses) the single monocotyledon is shield shaped and hence called a scutellum. The scutellum is pressed closely against the endosperm from which it absorbs food, and passes it to the growing parts. Embryo descriptors include small, straight, bent, curved and curled.
Nutrient storage.
Within the seed, there usually is a store of nutrients for the seedling that will grow from the embryo. The form of the stored nutrition varies depending on the kind of plant. In angiosperms, the stored food begins as a tissue called the endosperm, which is derived from the mother plant and the pollen via double fertilization. It is usually triploid, and is rich in oil or starch, and protein. In gymnosperms, such as conifers, the food storage tissue (also called endosperm) is part of the female gametophyte, a haploid tissue. The endosperm is surrounded by the aleurone layer (peripheral endosperm), filled with proteinaceous aleurone grains.
Originally, by analogy with the animal ovum, the outer nucellus layer (perisperm) was referred to as albumen, and the inner endosperm layer as vitellus. Although misleading, the term began to be applied to all the nutrient matter. This terminology persists in referring to endospermic seeds as 'albuminous'. The nature of this material is used in both describing and classifying seeds, in addition to the embryo to endosperm size ratio. The endosperm may be considered to be farinaceous (or mealy) in which the cells are filled with starch, as for instance cereal grains, or not (non-farinaceous). The endosperm may also be referred to as 'fleshy' or 'cartilaginous' with thicker soft cells such as coconut, but may also be oily as in "Ricinus" (castor oil), "Croton" and Poppy. The endosperm is called 'horny' when the cell walls are thicker such as date and coffee, or 'ruminated' if mottled, as in nutmeg, palms and Anonaceae.
In most monocotyledons (such as grasses and palms) and some (endospermic or albuminous) dicotyledons (such as castor beans) the embryo is embedded in the endosperm (and nucellus, which the seedling will use upon germination. In the non-endospermic dicotyledons the endosperm is absorbed by the embryo as the latter grows within the developing seed, and the cotyledons of the embryo become filled with stored food. At maturity, seeds of these species have no endosperm and are also referred to as exalbuminous seeds. The exalbuminous seeds include the legumes (such as beans and peas), trees such as the oak and walnut, vegetables such as squash and radish, and sunflowers. According to Bewley and Black (1978), Brazil nut storage is in hypocotyl, this place of storage is uncommon among seeds. All gymnosperm seeds are albuminous.
Seed coat.
The seed coat develops from the maternal tissue, the integuments, originally surrounding the ovule. The seed coat in the mature seed can be a paper-thin layer (e.g. peanut) or something more substantial (e.g. thick and hard in honey locust and coconut), or fleshy as in the sarcotesta of pomegranate. The seed coat helps protect the embryo from mechanical injury, predators and drying out. Depending on its development, the seed coat is either bitegmic or unitegmic. Bitegmic seeds form a testa from the outer integument and a tegmen from the inner integument while unitegmic seeds have only one integument. Usually parts of the testa or tegmen form a hard protective mechanical layer. The mechanical layer may prevent water penetration and germination. Amongst the barriers may be the presence of lignified sclereids.
The outer integument has a number of layers, generally between four and eight organised into three layers: (a) outer epidermis, (b) outer pigmented zone of two to five layers containing tannin and starch, and (c) inner epidermis. The endotegmen is derived from the inner epidermis of the inner integument, the exotegmen from the outer surface of the inner integument. The endotesta is derived from the inner epidermis of the outer integument, and the outer layer of the testa from the outer surface of the outer integument is referred to as the exotesta. If the exotesta is also the mechanical layer, this is called an exotestal seed, but if the mechanical layer is the endotegmen, then the seed is endotestal. The exotesta may consist of one or more rows of cells that are elongated and pallisade like (e.g. Fabaceae), hence 'palisade exotesta'.
In addition to the three basic seed parts, some seeds have an appendage, an aril, a fleshy outgrowth of the funicle (funiculus), (as in yew and nutmeg) or an oily appendage, an elaiosome (as in "Corydalis"), or hairs (trichomes). In the latter example these hairs are the source of the textile crop cotton. Other seed appendages include the raphe (a ridge), wings, caruncles (a soft spongy outgrowth from the outer integument in the vicinity of the micropyle), spines, or tubercles.
A scar also may remain on the seed coat, called the hilum, where the seed was attached to the ovary wall by the funicle. Just below it is a small pore, representing the micropyle of the ovule.
Size and seed set.
Seeds are very diverse in size. The dust-like orchid seeds are the smallest, with about one million seeds per gram; they are often embryonic seeds with immature embryos and no significant energy reserves. Orchids and a few other groups of plants are mycoheterotrophs which depend on mycorrhizal fungi for nutrition during germination and the early growth of the seedling. Some terrestrial orchid seedlings, in fact, spend the first few years of their lives deriving energy from the fungi and do not produce green leaves. At over 20 kg, the largest seed is the "coco de mer". Plants that produce smaller seeds can generate many more seeds per flower, while plants with larger seeds invest more resources into those seeds and normally produce fewer seeds. Small seeds are quicker to ripen and can be dispersed sooner, so fall blooming plants often have small seeds. Many annual plants produce great quantities of smaller seeds; this helps to ensure at least a few will end in a favorable place for growth. Herbaceous perennials and woody plants often have larger seeds; they can produce seeds over many years, and larger seeds have more energy reserves for germination and seedling growth and produce larger, more established seedlings after germination.
Functions.
Seeds serve several functions for the plants that produce them. Key among these functions are nourishment of the embryo, dispersal to a new location, and dormancy during unfavorable conditions. Seeds fundamentally are means of reproduction, and most seeds are the product of sexual reproduction which produces a remixing of genetic material and phenotype variability on which natural selection acts.
Embryo nourishment.
Seeds protect and nourish the embryo or young plant. They usually give a seedling a faster start than a sporeling from a spore, because of the larger food reserves in the seed and the multicellularity of the enclosed embryo.
Dispersal.
Unlike animals, plants are limited in their ability to seek out favorable conditions for life and growth. As a result, plants have evolved many ways to disperse their offspring by dispersing their seeds (see also vegetative reproduction). A seed must somehow "arrive" at a location and be there at a time favorable for germination and growth. When the fruits open and release their seeds in a regular way, it is called dehiscent, which is often distinctive for related groups of plants; these fruits include capsules, follicles, legumes, silicles and siliques. When fruits do not open and release their seeds in a regular fashion, they are called indehiscent, which include the fruits achenes, caryopsis, nuts, samaras, and utricles.
By wind (anemochory).
Other seeds are enclosed in fruit structures that aid wind dispersal in similar ways:
By animals (zoochory).
Myrmecochory is the dispersal of seeds by ants. Foraging ants disperse seeds which have appendages called elaiosomes (e.g. bloodroot, trilliums, acacias, and many species of Proteaceae). Elaiosomes are soft, fleshy structures that contain nutrients for animals that eat them. The ants carry such seeds back to their nest, where the elaiosomes are eaten. The remainder of the seed, which is hard and inedible to the ants, then germinates either within the nest or at a removal site where the seed has been discarded by the ants. This dispersal relationship is an example of mutualism, since the plants depend upon the ants to disperse seeds, while the ants depend upon the plants seeds for food. As a result, a drop in numbers of one partner can reduce success of the other. In South Africa, the Argentine ant ("Linepithema humile") has invaded and displaced native species of ants. Unlike the native ant species, Argentine ants do not collect the seeds of "Mimetes cucullatus" or eat the elaiosomes. In areas where these ants have invaded, the numbers of "Mimetes" seedlings have dropped.
Dormancy.
Seed dormancy has two main functions: the first is synchronizing germination with the optimal conditions for survival of the resulting seedling; the second is spreading germination of a batch of seeds over time so a catastrophe after germination (e.g. late frosts, drought, herbivory) does not result in the death of all offspring of a plant (bet-hedging). Seed dormancy is defined as a seed failing to germinate under environmental conditions optimal for germination, normally when the environment is at a suitable temperature with proper soil moisture. This true dormancy or innate dormancy is therefore caused by conditions within the seed that prevent germination. Thus dormancy is a state of the seed, not of the environment. Induced dormancy, enforced dormancy or seed quiescence occurs when a seed fails to germinate because the external environmental conditions are inappropriate for germination, mostly in response to conditions being too dark or light, too cold or hot, or too dry.
Seed dormancy is not the same as seed persistence in the soil or on the plant, though even in scientific publications dormancy and persistence are often confused or used as synonyms.
Often, seed dormancy is divided into four major categories: exogenous; endogenous; combinational; and secondary. A more recent system distinguishes five classes: morphological, physiological, morphophysiological, physical and combinational dormancy.
Exogenous dormancy is caused by conditions outside the embryo, including:
Endogenous dormancy is caused by conditions within the embryo itself, including:
The following types of seed dormancy do not involve seed dormancy, strictly speaking, as lack of germination is prevented by the environment, not by characteristics of the seed itself (see Germination):
Not all seeds undergo a period of dormancy. Seeds of some mangroves are viviparous; they begin to germinate while still attached to the parent. The large, heavy root allows the seed to penetrate into the ground when it falls. Many garden plant seeds will germinate readily as soon as they have water and are warm enough; though their wild ancestors may have had dormancy, these cultivated plants lack it. After many generations of selective pressure by plant breeders and gardeners, dormancy has been selected out.
For annuals, seeds are a way for the species to survive dry or cold seasons. Ephemeral plants are usually annuals that can go from seed to seed in as few as six weeks.
Germination.
Seed germination is a process by which a seed embryo develops into a seedling. It involves the reactivation of the metabolic pathways that lead to growth and the emergence of the radicle or seed root and plumule or shoot. The emergence of the seedling above the soil surface is the next phase of the plant's growth and is called seedling establishment.
Three fundamental conditions must exist before germination can occur. (1) The embryo must be alive, called seed viability. (2) Any dormancy requirements that prevent germination must be overcome. (3) The proper environmental conditions must exist for germination.
Seed viability is the ability of the embryo to germinate and is affected by a number of different conditions. Some plants do not produce seeds that have functional complete embryos, or the seed may have no embryo at all, often called empty seeds. Predators and pathogens can damage or kill the seed while it is still in the fruit or after it is dispersed. Environmental conditions like flooding or heat can kill the seed before or during germination. The age of the seed affects its health and germination ability: since the seed has a living embryo, over time cells die and cannot be replaced. Some seeds can live for a long time before germination, while others can only survive for a short period after dispersal before they die.
Seed vigor is a measure of the quality of seed, and involves the viability of the seed, the germination percentage, germination rate and the strength of the seedlings produced.
The germination percentage is simply the proportion of seeds that germinate from all seeds subject to the right conditions for growth. The germination rate is the length of time it takes for the seeds to germinate. Germination percentages and rates are affected by seed viability, dormancy and environmental effects that impact on the seed and seedling. In agriculture and horticulture quality seeds have high viability, measured by germination percentage plus the rate of germination. This is given as a percent of germination over a certain amount of time, 90% germination in 20 days, for example. 'Dormancy' is covered above; many plants produce seeds with varying degrees of dormancy, and different seeds from the same fruit can have different degrees of dormancy. It's possible to have seeds with no dormancy if they are dispersed right away and do not dry (if the seeds dry they go into physiological dormancy). There is great variation amongst plants and a dormant seed is still a viable seed even though the germination rate might be very low.
Environmental conditions affecting seed germination include; water, oxygen, temperature and light.
Three distinct phases of seed germination occur: water imbibition; lag phase; and radicle emergence.
In order for the seed coat to split, the embryo must imbibe (soak up water), which causes it to swell, splitting the seed coat. However, the nature of the seed coat determines how rapidly water can penetrate and subsequently initiate germination. The rate of imbibition is dependent on the permeability of the seed coat, amount of water in the environment and the area of contact the seed has to the source of water. For some seeds, imbibing too much water too quickly can kill the seed. For some seeds, once water is imbibed the germination process cannot be stopped, and drying then becomes fatal. Other seeds can imbibe and lose water a few times without causing ill effects, but drying can cause secondary dormancy.
Repair of DNA damage.
During seed dormancy, often associated with unpredictable and stressful environments, DNA damages accumulate as the seeds age. In rye seeds, the reduction of DNA integrity due to damage is associated with loss of seed viability during storage. Upon germination, seeds of "Vicia faba" undergo DNA repair. A plant DNA ligase that is involved in repair of single- and double-strand breaks during seed germination is an important determinant of seed longevity. Also, in Arabidopsis seeds, the activities of the DNA repair enzymes Poly ADP ribose polymerases (PARP) are likely needed for successful germination. Thus DNA damages that accumulate during dormancy appear to be a problem for seed survival, and the enzymatic repair of DNA damages during germination appears to be important for seed viability.
Inducing germination.
A number of different strategies are used by gardeners and horticulturists to break seed dormancy.
Scarification allows water and gases to penetrate into the seed; it includes methods to physically break the hard seed coats or soften them by chemicals, such as soaking in hot water or poking holes in the seed with a pin or rubbing them on sandpaper or cracking with a press or hammer. Sometimes fruits are harvested while the seeds are still immature and the seed coat is not fully developed and sown right away before the seed coat become impermeable. Under natural conditions, seed coats are worn down by rodents chewing on the seed, the seeds rubbing against rocks (seeds are moved by the wind or water currents), by undergoing freezing and thawing of surface water, or passing through an animal's digestive tract. In the latter case, the seed coat protects the seed from digestion, while often weakening the seed coat such that the embryo is ready to sprout when it is deposited, along with a bit of fecal matter that acts as fertilizer, far from the parent plant. Microorganisms are often effective in breaking down hard seed coats and are sometimes used by people as a treatment; the seeds are stored in a moist warm sandy medium for several months under nonsterile conditions.
Stratification, also called moist-chilling, breaks down physiological dormancy, and involves the addition of moisture to the seeds so they absorb water, and they are then subjected to a period of moist chilling to after-ripen the embryo. Sowing in late summer and fall and allowing to overwinter under cool conditions is an effective way to stratify seeds; some seeds respond more favorably to periods of oscillating temperatures which are a part of the natural environment.
Leaching or the soaking in water removes chemical inhibitors in some seeds that prevent germination. Rain and melting snow naturally accomplish this task. For seeds planted in gardens, running water is best—if soaked in a container, 12 to 24 hours of soaking is sufficient. Soaking longer, especially in stagnant water, can result in oxygen starvation and seed death. Seeds with hard seed coats can be soaked in hot water to break open the impermeable cell layers that prevent water intake.
Other methods used to assist in the germination of seeds that have dormancy include prechilling, predrying, daily alternation of temperature, light exposure, potassium nitrate, the use of plant growth regulators, such as gibberellins, cytokinins, ethylene, thiourea, sodium hypochlorite, and others. Some seeds germinate best after a fire. For some seeds, fire cracks hard seed coats, while in others, chemical dormancy is broken in reaction to the presence of smoke. Liquid smoke is often used by gardeners to assist in the germination of these species.
Sterile seeds.
Seeds may be sterile for few reasons: they may have been irradiated, unpollinated, cells lived past expectancy, or bred for the purpose.
Evolution and origin of seeds.
The origin of seed plants is a problem that still remains unsolved. However, more and more data tends to place this origin in the middle Devonian. The description in 2004 of the proto-seed "Runcaria heinzelinii" in the Givetian of Belgium is an indication of that ancient origin of seed-plants. As with modern ferns, most land plants before this time reproduced by sending spores into the air, that would land and become whole new plants.
The first "true" seeds are described from the upper Devonian, which is probably the theater of their true first evolutionary radiation. The seed plants progressively became one of the major elements of nearly all ecosystems.
Economic importance.
Edible seeds.
Many seeds are edible and the majority of human calories comes from seeds, especially from cereals, legumes and nuts. Seeds also provide most cooking oils, many beverages and spices and some important food additives. In different seeds the seed embryo or the endosperm dominates and provides most of the nutrients. The storage proteins of the embryo and endosperm differ in their amino acid content and physical properties. For example, the gluten of wheat, important in providing the elastic property to bread dough is strictly an endosperm protein.
Seeds are used to propagate many crops such as cereals, legumes, forest trees, turfgrasses and pasture grasses. Particularly in developing countries, a major constraint faced is the inadequacy of the marketing channels to get the seed to poor farmers. Thus the use of farmer-retained seed remains quite common.
Seeds are also eaten by animals, and are fed to livestock. Many seeds are used as birdseed.
Poison and food safety.
While some seeds are edible, others are harmful, poisonous or deadly. Plants and seeds often contain chemical compounds to discourage herbivores and seed predators. In some cases, these compounds simply taste bad (such as in mustard), but other compounds are toxic or break down into toxic compounds within the digestive system. Children, being smaller than adults, are more susceptible to poisoning by plants and seeds.
A deadly poison, ricin, comes from seeds of the castor bean. Reported lethal doses are anywhere from two to eight seeds,
though only a few deaths have been reported when castor beans have been ingested by animals.
In addition, seeds containing amygdalin—apple, apricot, bitter almond, peach, plum, cherry, quince, and others—when consumed in sufficient amounts, may cause cyanide poisoning.
Other seeds that contain poisons include annona, cotton, custard apple, datura, uncooked durian, golden chain, horse-chestnut, larkspur, locoweed, lychee, nectarine, rambutan, rosary pea, sour sop, sugar apple, wisteria, and yew. The seeds of the strychnine tree are also poisonous, containing the poison strychnine.
The seeds of many legumes, including the common bean ("Phaseolus vulgaris"), contain proteins called lectins which can cause gastric distress if the beans are eaten without cooking. The common bean and many others, including the soybean, also contain trypsin inhibitors which interfere with the action of the digestive enzyme trypsin. Normal cooking processes degrade lectins and trypsin inhibitors to harmless forms.
Please see the category plant toxins for further relevant articles.
Other uses.
Cotton fiber grows attached to cotton plant seeds. Other seed fibers are from kapok and milkweed.
Many important nonfood oils are extracted from seeds. Linseed oil is used in paints. Oil from jojoba and crambe are similar to whale oil.
Seeds are the source of some medicines including castor oil, tea tree oil and the cancer drug, Laetrile.
Many seeds have been used as beads in necklaces and rosaries including Job's tears, Chinaberry, rosary pea, and castor bean. However, the latter three are also poisonous.
Other seed uses include:
In religion.
The Book of Genesis in the Old Testament begins with an explanation of how all plant forms began:
And God said, Let the earth bring forth grass, the herb yielding seed, and the fruit tree yielding fruit after his kind, whose seed is in itself, upon the earth: and it was so. And the earth brought forth grass, and herb yielding seed after its kind, and the tree yielding fruit, whose seed was in itself, after its kind: and God saw that it was good. And the evening and the morning were the third day.
The Quran speaks about seed germination:
It is Allah Who causeth the seed-grain and the date-stone to split and sprout. He causeth the living to issue from the dead, and He is the one to cause the dead to issue from the living. That is Allah: then how are ye deluded away from the truth?

</doc>
<doc id="37699" url="https://en.wikipedia.org/wiki?curid=37699" title="History of East Asia">
History of East Asia

The history of East Asia covers the people inhabiting of the eastern subregion of the Asian continent known as East Asia from prehistoric times to the present. The best known ancient civilization of prehistoric East Asia was China, which flourished in the central plain region and continued until present day.
Prehistory.
Homo erectus ("upright man") is believed to have lived in East and Southeast Asia from 1.8 million to 40,000 years ago. Their regional distinction is classified as "Homo erectus sensu stricto".
Fossils representing 40 "Homo erectus" individuals, known as Peking Man, were found near Beijing at Zhoukoudian that date to about 400,000 years ago. The species was believed to have lived for at least several hundred thousand years in China, and possibly until 200,000 years ago in Indonesia. They may have been the first to use fire and cook food.
Homo sapiens migrated into inland Asia, likely by following herds of bison and mammoth and arrived in southern Siberia by about 43,000 years ago and some people move south or east from there.
The earliest sites of neolithic culture include Nanzhuangtou culture around 9500 BC to 9000 BC, Pengtoushan culture around 7500 BC to 6100 BC, Peiligang culture around 7000 BC to 5000 BC.
The Jeulmun pottery period is sometimes labeled the "Korean Neolithic", but since intensive agriculture and evidence of European-style 'Neolithic' lifestyle is sparse at best, such terminology is misleading. The Jeulmun was a period of hunting, gathering, and small-scale cultivation of plants. Archaeologists sometimes refer to this life-style pattern as 'broad-spectrum hunting-and-gathering'.
The Jōmon period occurred in Japan from circa 14,000 BC to 300BC, with some characteristics of both Neolithic and Mesolithic culture.
Ancient civilizations in East Asia.
Ancient Chinese dynasties.
The Xia dynasty of China (from c. 2100 to c. 1600 BC) is the first dynasty to be described in ancient historical records such as Sima Qian's "Records of the Grand Historian" and "Bamboo Annals".
Following this was the Shang dynasty, which ruled in the Yellow River valley. The classic account of the Shang comes from texts such as the "Classic of History", "Bamboo Annals" and "Records of the Grand Historian". According to the traditional chronology, the Shang ruled from 1766 BC to 1122 BC, but according to the chronology based upon the "current text" of "Bamboo Annals", they ruled from 1556 BC to 1046 BC.
The Zhou dynasty of (–256 BC lasted longer than any other dynasty in Chinese history. However, the actual political and military control of China by the dynasty, surnamed Ji (), lasted only until 771 BC, a period known as the Western Zhou. This period of Chinese history produced what many consider the zenith of Chinese bronze-ware making. The dynasty also spans the period in which the written script evolved into its modern form with the use of an archaic clerical script that emerged during the late Warring States period.
Confucianism.
Confucianism is an ethical and philosophical system developed during the Spring and Autumn Period. It later developed metaphysical and cosmological elements in the Han Dynasty. Following the official abandonment of Legalism in China after the Qin Dynasty, Confucianism became the official state ideology of the Han. Nonetheless, from the Han period onwards, most Chinese emperors have used a mix of Legalism and Confucianism as their ruling doctrine. The disintegration of the Han in the second century CE opened the way for the soteriological doctrines of Buddhism and Taoism to dominate intellectual life at that time.
A Confucian revival began during the Tang dynasty. In the late Tang, Confucianism developed aspects on the model of Buddhism and Taoism and was reformulated as Neo-Confucianism. This reinvigorated form was adopted as the basis of the imperial exams and the core philosophy of the scholar official class in the Song dynasty. The abolition of the examination system in 1905 marked the end of official Confucianism. The New Culture intellectuals of the early twentieth century blamed Confucianism for China's weaknesses. They searched for new doctrines to replace Confucian teachings, some of these new ideologies include the "Three Principles of the People" with the establishment of the Republic of China, and then Maoism under the People's Republic of China.
Historically, cultures and countries strongly influenced by Confucianism include mainland China, Taiwan, Hong Kong, Macau, Korea, Japan, and Vietnam, as well as various territories settled predominantly by Chinese people, such as Singapore. In the 20th century, Confucianism’s influence has been greatly reduced. More recently, there have been talks of a "Confucian Revival" in the academia and the scholarly community.
Buddhism.
Buddhism has also been a major influence on east Asian culture. It was introduced to China during the Han dynasty.
Taoism.
The first organized form of Taoism, the Tianshi (Celestial Masters') school (later known as Zhengyi school), developed from the Five Pecks of Rice movement at the end of the 2nd century CE; the latter had been founded by Zhang Daoling, who claimed that Laozi appeared to him in the year 142. The Tianshi school was officially recognized by ruler Cao Cao in 215, legitimizing Cao Cao's rise to power in return. Laozi received imperial recognition as a divinity in the mid-2nd century BCE.
Taoism, in form of the Shangqing school, gained official status in China again during the Tang Dynasty (618–907), whose emperors claimed Laozi as their relative. The Shangqing movement, however, had developed much earlier, in the 4th century, on the basis of a series of revelations by gods and spirits to a certain Yang Xi in the years between 364 and 370.
Qin and Han Dynasties.
In 221 BC, the state of Qin succeeded in conquering the other six states, creating the first imperial dynasty of China for the first time. Following the death of the emperor Qin Shi Huangdi, the Qin dynasty collapsed and control was taken over by the Han dynasty in 206 BC. In AD 220, the Han empire collapsed into the Three Kingdoms. The series of trade routes known as Silk Road began during the Han dynasty.
Divisions and re-unification of China.
Three Kingdoms Period.
The Three Kingdoms Period consisted of the kingdom of Wei, Shu, and Wu. It began when the ruler of Wei, Cao Cao, was defeated by Liu Bei and Sun Quan at the Battle of Red Cliffs. After Cao Cao's death in AD 220, his son Cao Pi became emperor of Wei. Liu Bei and Sun Quan declared themselves emperor of Shu and Wu respectively. Many famous personages in Chinese history were born during this period, including Hua Tuo and the great military strategist Zhuge Liang. Buddhism, which was introduced during the Han Dynasty, also became popular in this period. Two years after Wei conquered Shu in AD 263, Sima Yan, Wei's Imperial Chancellor, overthrew Wei and started the Western Jin Dynasty. The conquest of Wu by the Western Jin Dynasty ended the Three Kingdoms period, and China was unified again. However, the Western Jin did not last long. Following the death of Sima Yan, the War of the Eight Princes began. This war weakened the Jin Dynasty, and it soon fell to the kingdom of Han Zhao. This ushered in the Sixteen Kingdoms.
Southern and Northern Dynasties.
The Northern Wei was established by the Tuoba clan of the Xianbei people in AD 386, when they united the northern part of China. During the Northern Wei, Buddhism flourished, and became an important tool for the emperors of the Northern Wei, since they were believed to be living incarnations of Buddha. Soon, the Northern Wei was divided into the Eastern Wei and Western Wei. These were followed by the Northern Zhou and Northern Qi. In the south, the dynasties were much less stable than the Northern Dynasties. The four dynasties were weakened by conflicts between the ruling families.
Buddhism.
Buddhism, also one of the major religions in East Asia, was introduced into China during the Han dynasty from Nepal in the 1st century BC. Buddhism was originally introduced to Korea from China in 372, and eventually arrived in Japan around the turn of the 6th century.
For a long time Buddhism remained a foreign religion with a few believers in China, mainly taught by immigrant Indian teachers. During the Tang dynasty, a fair amount of translations from Sanskrit into Chinese were done by Chinese priests, and Buddhism became one of the major religions of the Chinese along with the other two indigenous religions.
In Korea, Buddhism was not seen to conflict with the rites of nature worship; it was allowed to blend in with Shamanism. Thus, the mountains that were believed to be the residence of spirits in pre-Buddhist times became the sites of Buddhist temples. Though Buddhism initially enjoyed wide acceptance, even being supported as the state ideology during the Goguryeo, Silla, Baekje, Balhae, and Goryeo periods, Buddhism in Korea suffered extreme repression during the Joseon Dynasty.
In Japan, Buddhism and Shinto were combined by a theological theory "Ryōbushintō", which says Shinto deities are avatars of various Buddhist entities, including Buddhas and Bodhisattvas (Shinbutsu-shūgō). This became the mainstream notion of Japanese religion. In fact until the Meiji government declared their separation in the mid-19th century, many Japanese people believed that Buddhism and Shinto were one religion.
In Mongolia, Buddhism flourished two times; first in the Mongol Empire (13th-14th centuries), and finally in the Manchu Qing Dynasty (16th-19th centuries) from Tibet in the last 2000 years. It was mixed in with Tengeriism and Shamanism.
Sui Dynasty.
In AD 581, Yang Jian overthrew the Northern Zhou, and established the Sui Dynasty. Later, Yang Jian, who became Sui Wendi, conquered the Chen Dynasty, and united China. However, this dynasty was short-lived. Sui Wendi's successor, Sui Yangdi, expanded the Grand Canal, and launched four disastrous wars against the Goguryeo. These projects depleted the resources and the workforce of the Sui. In AD 618, Sui Yangdi was murdered. Li Yuan, the former governor of Taiyuan, declared himself the emperor, and founded the Tang Dynasty.
Civil service.
A government system supported by a large class of Confucian literati selected through civil service examinations was perfected under Tang rule. This competitive procedure was designed to draw the best talents into government. But perhaps an even greater consideration for the Tang rulers, aware that imperial dependence on powerful aristocratic families and warlords would have destabilizing consequences, was to create a body of career officials having no autonomous territorial or functional power base. As it turned out, these scholar-officials acquired status in their local communities, family ties, and shared values that connected them to the imperial court. From Tang times until the closing days of the Qing Dynasty in 1911, scholar officials functioned often as intermediaries between the grassroots level and the government. This model of government had an influence on Korea and Japan.
Printing press.
The first known movable type system was invented in China around 1040 AD by Pi Sheng (990-1051) (spelled Bi Sheng in the Pinyin system). Pi Sheng's type was made of baked clay, as described by the Chinese scholar Shen Kuo (1031–1095).
The world's first metal-based movable type printing press was invented in Korea in 1234, 210 years before Johannes Gutenberg invented a similar press in Germany.
Jikji is the world's oldest extant movable metal print book. It was published in Heungdeok Temple in 1377, 78 years prior to Gutenberg's "42-Line Bible" printed during the years 1452-1455.
Gunpowder.
The first reference to gunpowder is probably a passage in the "Zhenyuan miaodao yaolüe", a Taoism text tentatively dated to the mid-9th century:
Some have heated together sulfur, realgar and saltpeter with honey; smoke and flames result, so that their hands and faces have been burnt, and even the whole house where they were working burned down.
The earliest surviving recipes for gunpowder can be found in the Chinese military treatise "Wujing zongyao" of 1044 AD, which contains three: two for use in incendiary bombs to be thrown by siege engines and one intended as fuel for poison smoke bombs. The formulas in the "Wujing zongyao" range from 27 to 50 percent nitrate. Experimenting with different levels of saltpetre content eventually produced bombs, grenades, and land mines, in addition to giving fire arrows a new lease on life. By the end of the 12th century, there were cast iron grenades filled with gunpowder formulations capable of bursting through their metal containers. The 14th century "Huolongjing" contains gunpowder recipes with nitrate levels ranging from 12 to 91 percent, six of which approach the theoretical composition for maximal explosive force.
In China, the 13th century saw the beginnings of rocketry and the manufacture of the oldest gun still in existence, a descendant of the earlier fire-lance, a gunpowder-fueled flamethrower that could shoot shrapnel along with fire. The "Huolongjing" text of the 14th century also describes hollow, gunpowder-packed exploding cannonballs.
In the 13th century contemporary documentation shows gunpowder beginning to spread from China by the Mongols to the rest of the world, starting with Europe and the Islamic world. The Arabs acquired knowledge of saltpetre—which they called "Chinese snow" ( ) —around 1240 and, soon afterward, of gunpowder; they also learned of fireworks ("Chinese flowers") and rockets ("Chinese arrows"). Persians called saltpeter "Chinese salt" or "salt from Chinese salt marshes" ( ). Historian Ahmad Y. al-Hassan argues—"contra" the general notion—that the Chinese technology passed through Arabic alchemy and chemistry before the 13th century. Gunpowder arrived in India by the mid-14th century, but could have been introduced by the Mongols perhaps as early as the mid-13th century.
Three Kingdoms of Korea.
B.C 58, the Korean peninsula was divided into three kingdoms, Baekje, Silla and Goguryeo. Although they shared a similar language and culture, these three kingdoms constantly fought with each other for control of the peninsula. Furthermore, Goguryeo had been engaged in constant wars with the Chinese. This included the Goguryeo-Sui Wars, where the Kingdom of Goguryeo managed to repel the invading forces of the Sui Dynasty.
As the Kingdom of Silla conquered nearby city-states, they gained access to the Yellow Sea, making direct contact with the Tang Dynasty possible. The Tang Dynasty teamed up with Silla and formed a strategy to invade Goguryeo. Since Goguryeo had been able to repel earlier Chinese invasions from the North, perhaps Gorguryeo would fall if it were attacked by Silla from the south at the same time. However, in order to do this, the Tang-Silla alliance had to eliminate Goguryeo's nominal ally Baekje and secure a base of operations in southern Korea for a second front.
In 660, the coalition troops of Silla and Tang of China attacked Baekje, resulting in the annexation of Baekje by Silla. Together, Silla and Tang effectively eliminated Baekje when they captured the capital of Sabi, as well as Baekje's last king, Uija, and most of the royal family.
However, Yamato Japan and Baekje had been long-standing and very close allies. In 663, Baekje revival forces and a Japanese naval fleet convened in southern Baekje to confront the Silla forces in the Battle of Baekgang. The Tang dynasty also sent 7,000 soldiers and 170 ships. After five naval confrontations that took place in August 663 at Baekgang, considered the lower reaches of Tongjin river, the Silla-Tang forces emerged victorious.
The Silla-Tang forces turned their attention to Goguryeo. Although Goguryeo had repelled the Sui Dynasty a century earlier, attacks by the Tang Dynasty from the west proved too formidable. The Silla-Tang alliance emerged victorious in the Goguryeo-Tang Wars. Silla thus unified most of the Korean peninsula in 668.
But the kingdom's reliance on China's Tang Dynasty had its price. Silla had to forcibly resist the imposition of Chinese rule over the entire peninsula. Silla then fought for nearly a decade to expel Chinese forces to finally establish a unified kingdom as far north as modern Pyongyang.
Silla'a unification of Korea was short lived. The northern region of the defunct Goguryeo state later reemerged as Balhae, due to the leadership of former Goguryeo General Dae Joyeong.
Japan.
The history of Japan is mainly divided into three stages: the periods of interaction with China and East Asia, isolation, and opening to the world.
Early Japan.
Japan was inhabited since more than 30,000 years ago, when land bridges connected Japan to Korea and China to the south and Siberia to the north. With rise in sea level, the 4 major islands took form around 20,000 years ago, and the lands connecting today's Japan to the continental Asia completely disappeared 15,000 ~ 10,000 years ago. Thereafter, some migrations continued by way of the Korean peninsula, which would serve as Japan's main avenue for cultural exchange with the continental Asia until the medieval period.
The mythology of ancient Japan is contained within the "Kojiki" ('Records of Ancient Matters') which record the creation myth of Japan and its lineage of Emperors to the Sun Goddess Amaterasu.
In the myth of Japan's creation the two gods Isanagi and Isanami swirled the primordial soup below the bridge of heaven with a rod and when retrieving the rod the drops of liquid that formed and dropped created the first islands of Japan.
Archaeology.
Ancient pottery has been uncovered in Japan, particularly in Kyushu, that points to two major periods: the Jomon (c.7,500 BC - 250 BC, 縄文時代 "Joomon Jidai" ) and the Yayoi (c.250 BC - 250 AD, 弥生時代 "Yayoi Jidai"). "Joomon" can be translated as 'cord marks' and refers to the pattern on the pottery of the time; this style was more ornate than the later Yayoi type, which has been found at more widespread sites (e.g. around Tokyo) and seems to have been developed for more practical purposes.
Edo Period.
In 1603, the Tokugawa shogunate (military dictatorship) ushered in a long period of isolation from foreign influence in order to secure its power. For 250 years this policy enabled Japan to enjoy stability and a flowering of its indigenous culture.
Japanese society had an elaborate social structure, in which everyone knew their place and level of prestige. At the top were the emperor and the court nobility, invincible in prestige but weak in power. Next came the "bushi" of shogun, daimyo and layers of feudal lords whose rank was indicated by their closeness to the Tokugawa. They had power. The "daimyo" comprised about 250 local lords of local "han" with annual outputs of 50,000 or more bushels of rice. The upper strata was much given to elaborate and expensive rituals, including elegant architecture, landscaped gardens, nō drama, patronage of the arts, and the tea ceremony.
Then came the 400,000 warriors, called "samurai", in numerous grades and degrees. A few upper samurai were eligible for high office; most were foot soldiers (ashigaru) with minor duties. The samurai were affiliated with senior lords in a well-established chain of command. The shogun had 17,000 samurai retainers; the daimyo each had hundreds. Most lived in modest homes near their lord's headquarters, and lived off of hereditary rights and stipends. Together these high status groups constituted Japan's ruling class making up about 6% of the total population.
Lower orders divided into two main segments—the peasants—80% of the population—whose high prestige as producers was undercut by their burden as the chief source of taxes. They were illiterate and lived in villages controlled by appointed officials who kept the peace and collected taxes.
Near the bottom of the prestige scale—but much higher up in terms of income and life style—were the merchants and artisans of the towns and cities. They had no political power, and even rich merchants found it difficult to rise in the world in a society in which place and standing were fixed at birth. Finally came the entertainers, prostitutes, day laborers and servants, and the thieves, beggars and hereditary outcasts.
Economy.
The Tokugawa era brought peace, and that brought prosperity to a nation of 31 million, 80% of them rice farmers. Rice production increased steadily, but population remained stable. Rice paddies grew from 1.6 million chō in 1600 to 3 million by 1720. Improved technology helped farmers control the all-important flow of water to their paddies. The daimyo's operated several hundred castle towns, which became loci of domestic trade. Large-scale rice markets developed, centered on Edo and Osaka. Merchants invented credit instruments to transfer money, and currency came into common use. In the cities and towns, guilds of merchants and artisans met the growing demand for goods and services.
The merchants benefited enormously, especially those with official patronage. The samurai, forbidden to engage in farming or business but allowed to borrow money, borrowed too much. The bakufu and daimyos raised taxes on farmers, but did not tax business, so they too fell into debt. By 1750 rising taxes incited peasant unrest and even revolt. The nation had to deal somehow with samurai impoverishment and treasury deficits. The financial troubles of the samurai undermined their loyalties to the system, and the empty treasury threaten the whole system of government. One solution was reactionary—with prohibitions on spending for luxuries. Other solutions were modernizing, with the goal of increasing agrarian productivity. The eighth Tokugawa shogun, Yoshimune (in office 1716-1745) had considerable success, though much of his work had to be done again between 1787 and 1793 by the shogun's chief councilor Matsudaira Sadanobu (1759-1829). Others shoguns debased the coinage to pay debts, which caused inflation.
By 1800 the commercialization of the economy grew rapidly, bringing more and more remote villages into the national economy. Rich farmers appeared who switched from rice to high-profit commercial crops and engaged in local money-lending, trade, and small-scale manufacturing. Some wealthy merchants sought higher social status by using money to marry into the samurai class.
A few domains, notably Chōsū and Satsuma, used innovative methods to restore their finances, but most sunk further into debt. The financial crisis provoked a reactionary solution near the end of the "Tempo era" (1830-1843) promulgated by the chief counselor Mizuno Tadakuni. He raised taxes, denounced luxuries and tried to impede the growth of business; he failed and it appeared to many that the continued existence of the entire Tokugawa system was in jeopardy.
Edo/Tokyo.
Edo (Tokyo) had been a small settlement for 400 years but began to grow rapidly after 1603 when Shogun Ieyasu built a fortified city as the administrative center of the new Tokugawa Shogunate. Edo resembled the capital cities of Europe with military, political, and economic functions. The Tokugawa political system rested on both feudal and bureaucratic controls, so that Edo lacked a unitary administration. The typical urban social order was composed of samurai, unskilled workers and servants, artisans, and businessmen. The artisans and businessmen were organized in officially sanctioned guilds; their numbers grew rapidly as Tokyo grew and became a national trading center. Businessmen were excluded from government office, and in response they created their own subculture of entertainment, making Edo a cultural as well as a political and economic center. With the Meiji Restoration, Tokyo's political, economic, and cultural functions simply continued as the new capital of imperial Japan.
Three cultures.
Three distinct cultural traditions operated during the Tokugawa era, having little to do with each other. In the villages the peasants had their own rituals and localistic traditions. In the high society of the imperial court, daimyos and samurai, Chinese cultural influence was paramount, especially in the areas of ethics and political ideals. Neo-Confucianism became the approved philosophy, and was taught in official schools; Confucian norms regarding personal duty and family honor became deeply implanted in elite thought. Equally pervasive was the Chinese influence in painting, decorative arts and history, economics, and natural science. One exception came in religion, where there was a revival of Shinto, which had originated in Japan. Motoori Norinaga (1730-1801) freed Shinto from centuries of Buddhist accretions and gave a new emphasis to the myth of imperial divine descent, which later became a political tool for imperialist conquest until it was destroyed in 1945.
The third cultural level was the popular art of the low-status artisans, merchants and entertainers, especially in Edo and other cities. It revolved around "ukiyo", the floating world of the city pleasure quarters and theaters that was officially off-limits to samurai. Its actors and courtesans were favorite subjects of the woodblock color prints that reached high levels of technical and artistic achievement in the 18th century. They also appeared in the novels and short stories of popular prose writers of the age like Ihara Saikaku (1642-1693). The theater itself, both in the puppet drama and the newer kabuki, as written by the greatest dramatist, Chikamatsu Monzaemon (1653-1724), relied on the clash between duty and inclination in the context of revenge and love.
The Meiji Era.
Following the Treaty of Kanagawa with the United States of America in 1854, Japan opened its ports and began to intensively modernise and industrialise.
The Meiji Restoration of 1868 ended the Tokugawa period, and put Japan on a course of centralized government in the name of the Emperor.
During the late nineteenth and early twentieth century, Japan became a regional power that was able to defeat the forces of both China and Russia. It occupied Korea, Formosa (Taiwan), and southern Sakhalin Island.
Economy and empire; war and defeat: 1912-1950.
Hirohito was the Showa Emperor 1926-89 after serving as regent since 1921.
Pacific War.
In 1931 Japan occupied Manchuria ("Dongbei") after the Manchurian Incident, and in 1937 it launched a full-scale invasion of China. The U.S. undertook large scale military and economic aid to China and demanded Japanese withdrawal. Instead of withdrawing Japan took over French Indochina in 1940-41; the U.S., Britain and the Netherlands cut off oil imports in 1941, which accounted for over 90% of Japan's oil supply. Negotiations with the US led nowhere. Japan attacked U.S. forces at the Battle of Pearl Harbor in December 1941, triggering America's entry into World War II. Japan rapidly expanded at sea and land, capturing Singapore and the Philippines in early 1942, and threatening India and Australia.
Although it was to be a long and bloody war, Japan began to lose the initiative in 1942. At the Battle of the Coral Sea, a Japanese offensive was turned back, for the first time, at sea. The June Battle of Midway cost Japan four of its six large aircraft carriers and destroyed its capability for future major offensives. In the Guadalcanal Campaign, the U.S. took back ground from Japan and established a base for future invasions.
U.S. occupation.
After its defeat in World War II, Japan was occupied by the U.S. until 1951, and recovered from the effects of the war to become an economic power, staunch American ally and a democracy. While Emperor Hirohito was allowed to retain his throne as a symbol of national unity, actual power rests in networks of powerful politicians, bureaucrats, and business executives.
Postwar.
The Japanese growth in the postwar period was often called a "miracle". It was led by manufacturing, Starting with textiles and clothing and moving to high-technology, especially automobiles, electronics and computers.
The economy experienced a major slowdown starting in the 1990s following three decades of unprecedented growth, but Japan still remains a major economic power, both in Asia and globally.
See also.
Histories for East Asia are listed by area in alphabetical order:

</doc>
<doc id="37701" url="https://en.wikipedia.org/wiki?curid=37701" title="Outline of South Asian history">
Outline of South Asian history

The following outline is provided as an overview of and topical guide to the history of South Asia:
History of South Asia – South Asia includes the contemporary political entities of the Indian subcontinent and associated islands, therefore, its history includes the histories of India, Pakistan, Bangladesh, Nepal, Afghanistan, Bhutan, and the island nations of Sri Lanka and the Maldives.
History of South Asia, by period.
Prehistory of South Asia.
South Asian Stone Age.
South Asian Stone Age   (50,000–3000 BCE)
South Asian Bronze Age.
South Asian Bronze Age   (3000–1300 BCE)
Iron Age India.
Iron Age   (1200–230 BCE)
Middle kingdoms of India.
Middle kingdoms of India   (Classical period) (230 BCE–1279CE)
Medieval India.
Late medieval period   (1206–1596)
Early modern period.
Early modern period   (1526–1858)
Colonial India.
Colonial period   (1510–1961 CE)
Other states.
Other states (1102–1947)
Kingdoms of Sri Lanka.
Kingdoms of Sri Lanka

</doc>
<doc id="37702" url="https://en.wikipedia.org/wiki?curid=37702" title="History of Southeast Asia">
History of Southeast Asia

The history of Southeast Asia has been characterised as interaction between regional players and foreign powers. Each country was intertwined with all the others as depicted in the Southeast Asian political model. For instance, the Malay empires of Srivijaya and Malacca covered modern day Indonesia, Malaysia, the Philippines, and Singapore while the Burmese, Vietnamese and Khmer peoples governed much of Indochina.
At the same time, opportunities and threats from the east and the west shaped the direction of Southeast Asia. The history of the countries within the region only started to develop independently of each other after European colonialisation was at full steam between the 17th and the 20th centuries.
Prehistory.
Paleolithic.
Archaeologists have found stone tools in Malaysia which have been dated to be 1.83 million years old. With other evidence found across the Mainland of South east Asia, which include Hominid skeletal and teeth remains, Hominid stone artefacts such as chopper-chopping tools and stone blades, contemporaneous faunal bone remains and palaeo-environment analyses, the occupation of Hominids into South East Asia is believed to occur between 1.5 to 1 Ma. The occupation was firstly taken place in the upland region in the northern part of the Mainland South East Asia where the climate was stable and the natural resource was richer. During the cooler periods occurred intermittently between warm and humid conditions, which prevailed from 240 to180 ka and again between 130 and 100 ka, many warm-adapted species such as primates moved southward.
Before the latest ice period, much of the archipelago was not under water. Sometime around the Pleistocene period, the Sunda Shelf was flooded as thawing occurred and thus revealing current geographical features. The area's first known human-like inhabitant some 500,000 years ago was "Java Man" (first classified as Pithecanthropus erectus, then subsequently named a part of the species Homo erectus). Recently discovered was a species of human, dubbed "Flores Man" (Homo floresiensis), a miniature hominid that grew only three feet tall. Flores Man seems to have shared some islands with Java Man until only 10,000 years ago, when they became extinct. Extensive archaeological work has been done at Sangiran in Central Java where a museum and visitors' centre has been established.
The oldest human settlement in Malaysia has been discovered in Niah Caves. The human remains found there have been dated back to 40,000 BC. Another remain dated back to 9000 BC dubbed the "Perak Man" and tools as old as 75,000 years have been discovered in Lenggong, Malaysia.
The oldest habitation discovered in the Philippines is located at the Tabon Caves and dates back to approximately 50,000 years; while items there found such as burial jars, earthenware, jade ornaments and other jewellery, stone tools, animal bones, and human fossils dating back to 47,000 years ago. Human remains are from approximately 24,000 years ago.
Mesolithic and early agricultural societies.
Agriculture was a development based on necessity. Before agriculture, hunting and gathering sufficed to provide food. The chicken and pig were domesticated here, millennia ago. So much food was available that people could gain status by giving food away in feasts and festivals, where all could eat their fill. These "big men" (Malay: "orang kaya") would work for years, accumulating the food (wealth) needed for the festivals provided by the "orang kaya". These individual acts of generosity or kindness are remembered by the people in their oral histories, which serves to provide "credit" in more dire times.
These customs ranged throughout Southeast Asia, stretching, for example, to the island of New Guinea. The agricultural technology was exploited after population pressures increased to the point that systematic intensive farming was required for mere survival, say of yams (in Papua) or rice (in Indonesia). Rice paddies are well-suited for the monsoons of Southeast Asia. The rice paddies of Southeast Asia have existed for millennia, with evidence for their existence coeval with the rise of agriculture in other parts of the globe.
Yam cultivation in Papua, for example, consists of placing the tubers in prepared ground, heaping vegetation on them, waiting for them to propagate, and harvesting them. This work sequence is still performed by the women in the traditional societies of Southeast Asia; the men might perform the heavier duties of preparing the ground, or of fencing the area to prevent predation by pigs.
Though cultivation emerged in the beginning of Holocene, hunting and gathering was not replaced but co-existed with farming. Early inhabitant groups might led a life mixed with cultivation and foraging that lasted for a rather long period, and they might as well relied on wild plant food production.
From Burma around 1500 BC, the Mon and ancestors of the Khmer people started to move in into the mainland while the Tai people later came from southern China to reside there in the 1st millennium AD.
Early metal phases in Southeast Asia.
It was around 2500 BC that the Austronesian people started to populate the archipelago and introduced primitive ironworks technology that they had mastered to the region.
By around the 5th century BC, people of the Dong Son culture, who lived in what is now Vietnam, had mastered basic metal working. Their works are the earliest known metal object to be found by archaeologists in Southeast Asia.
Ancient, classical and postclassical kingdoms.
The communities in the region evolved to form complex cultures with varying degrees of influence from India and China.
The ancient kingdoms can be grouped into two distinct categories. The first is agrarian kingdoms. Agrarian kingdoms had agriculture as the main economic activity. Most agrarian states were located in mainland Southeast Asia. Examples are the Van Lang, based on the Red River delta and the Khmer Empire around the Tonle Sap. The second type is maritime states. Maritime states were dependent on sea trade. Srivijaya and Malacca were maritime states.
Văn Lang was the first nation of the ancient Vietnamese people, founded in 2879 BC and existing until 258 BC. It was ruled by the Hùng Kings of the Hồng Bàng Dynasty. There is, however, little reliable historical information available.
A succession of trading systems dominated the trade between China and India. First, goods were shipped through Funan centred in Mekong delta to the Isthmus of Kra, portaged across the narrow, and then transhipped for India and points west. This trading link allowed the development of polities around the Mekong delta in today Southern Vietnam and Cambodia, such as Funan and its successor Chenla. Funan was started around the 1st century CE and replaced by Chenla that existed in the 6th to 8th centuries. The trade via Isthmus of Kra also spurred the development of trading polities on Malay peninsula near the isthmus (today southern Thailand and northern Malaysia), such as Langkasuka on eastern coast and Kedah on western coast.
Numbers of port towns in maritime Southeast Asia also began to receive Hindu and Buddhist influences from India, and developed to be a Hindu or Buddhist kingdoms ruled by native dynasties. Early Hindu kingdoms in Indonesia are 4th century Kutai that rose in East Kalimantan, Tarumanagara in West Java and Kalingga in Central Java.
Around the 6th century CE, merchants began sailing to Srivijaya where goods were transhipped directly on Sumatran port. The limits of technology and contrary winds during parts of the year made it difficult for the ships of the time to proceed directly from the Indian Ocean to the South China Sea. The third system involved direct trade between the Indian and Chinese coasts.
In the 7th century CE on central coast of today Vietnam, a Hindu kingdom of Champa flourished. Just like Funan, benefited from the lucrative trading between China, Southeast Asia and India.
Very little is known about Southeast Asian religious beliefs and practices before the advent of Indian merchants and religious influences from the 2nd century BC onwards. It is believed that prior to the advent of Hinduism and Buddhism, native Southeast Asian are tribal animist. Prior to the 13th century, Buddhism and Hinduism were the main religions in Southeast Asia.
The first dominant power to arise in the archipelago was Srivijaya in Sumatra. From the 5th century, the capital, Palembang, became a major seaport and functioned as an entrepot on the Spice Route between India and China. Srivijaya was also a notable centre of Vajrayana Buddhist learning and influence. Srivijaya's wealth and influence faded when changes in nautical technology in the 10th century enabled Chinese and Indian merchants to ship cargo directly between their countries and also enabled the Chola state in southern India to carry out a series of destructive attacks on Srivijaya's possessions, ending Palembang's entrepot function.
From the 7th to 15th centuries Sumatra was ruled by kaleidoscope of Buddhist kingdoms, from Kantoli, Srivijaya, Malayu, Pannai and Dharmasraya kingdom. Most of its history from the 6th to 13th centuries, Sumatra was dominated by Srivijaya empire.
After the fall of Tarumanagara, West Java was ruled by Sunda Kingdom. While Central and Eastern Java was dominated by a kaleidoscope of competing agrarian kingdoms including the Sailendras, Mataram, Kediri, Singhasari, and finally Majapahit. In the 8th to 9th centuries, the Sailendra dynasty that ruled Medang i Bhumi Mataram kingdom built numbers massive monuments in Central Java, includes Sewu and Borobudur temple.
In the Philippines, the Laguna Copperplate Inscription dating from 900 CE relates a granted debt from a Maginoo caste nobleman named "Namwaran" who lived in the Maynila area. This document mentions a leader of Medang in Java.
In mainland Southeast Asia, after the fall of Chenla, the Khmer Empire, centred on the plain north of Tonle Sap lake, flourished in 9th until 15th century to become a regional hegemon. The Khmers built numbers of massive monuments in and around Angkor. While on central plains of today Thailand the kingdom of Dvaravati arose since 6th to 13th century. By the 10th century, Dvaravati began to come under the influence of the Khmer Empire. Later the plains of Central Thailand was dominated by Sukhothai in the 13th century and later Ayutthaya Kingdom in the 14th century.
According to the Nagarakertagama, around the 13th century, Majapahit's vassal states spread throughout much of today's Indonesia, making it the largest empire ever to exist in Southeast Asia. The empire declined in the 15th century after the rise of Islamic states in coastal Java, Malay peninsula and Sumatra.
European colonisation.
An early European to visit Southeast Asia was Niccolò de' Conti, who travelled here in the early 15th century. However, Europeans did not visit en masse until the 16th century. It was the lure of trade that brought Europeans to Southeast Asia while missionaries also tagged along the ships as they hoped to spread Christianity into the region.
Portugal was the first European power to establish a bridgehead on the lucrative maritime Southeast Asia trade route, with the conquest of the Sultanate of Malacca in 1511. The Netherlands and Spain followed and soon superseded Portugal as the main European powers in the region. In 1599, Spain began to colonise the Philippines. In 1619, acting through the Dutch East India Company, the Dutch took the city of Sunda Kelapa, renamed it Batavia (now Jakarta) as a base for trading and expansion into the other parts of Java and the surrounding territory. In 1641, the Dutch took Malacca from the Portuguese. Economic opportunities attracted Overseas Chinese to the region in great numbers. In 1775, the Lanfang Republic, possibly the first republic in the region, was established in West Kalimantan, Indonesia, as a tributary state of the Qing Empire; the republic lasted until 1884, when it fell under Dutch occupation as Qing influence waned.
Englishmen of the United Kingdom, in the guise of the Honourable East India Company led by Josiah Child, had little interest or impact in the region, and were effectively expelled following the Siam–England war (1687). Britain, in the guise of the British East India Company, turned their attention to the Bay of Bengal following the Peace with France and Spain (1783). During the conflicts, Britain had struggled for naval superiority with the French, and the need of good harbours became evident. Penang Island had been brought to the attention of the Government of India by Francis Light. In 1786 a settlement was formed under the administration of Sir John Macpherson, which formally began British expansion into the Malay States of Southeast Asia.
The British also temporarily possessed Dutch territories during the Napoleonic Wars; and Spanish areas in the Seven Years' War. In 1819, Stamford Raffles established Singapore as a key trading post for Britain in their rivalry with the Dutch. However, their rivalry cooled in 1824 when an Anglo-Dutch treaty demarcated their respective interests in Southeast Asia. British rule in Burma began with the first Anglo-Burmese War (1824–1826).
Early United States entry into what was then called the East Indies (usually in reference to the Malay Archipelago) was low key. In 1795, a secret voyage for pepper set sail from Salem, Massachusetts on an 18-month voyage that returned with a bulk cargo of pepper, the first to be so imported into the country, which sold at the extraordinary profit of seven hundred per cent. In 1831, the merchantman "Friendship" of Salem returned to report the ship had been plundered, and the first officer and two crewmen murdered in Sumatra. The Anglo-Dutch Treaty of 1824 obligated the Dutch to ensure the safety of shipping and overland trade in and around Aceh, who accordingly sent the Royal Netherlands East Indies Army on the punitive expedition of 1831. President Andrew Jackson also ordered America's first Sumatran punitive expedition of 1832, which was followed by a punitive expedition in 1838. The "Friendship" incident thus afforded the Dutch a reason to take over Ache; and Jackson, to dispatch diplomatist Edmund Roberts, who in 1833 secured the Roberts Treaty with Siam. In 1856 negotiations for amendment of this treaty, Townsend Harris stated the position of the United States:The United States does not hold any possessions in the East, nor does it desire any. The form of government forbids the holding of colonies. The United States therefore cannot be an object of jealousy to any Eastern Power. Peaceful commercial relations, which give as well as receive benefits, is what the President wishes to establish with Siam, and such is the object of my mission.
From the end of the 1850s onwards, while the attention of the United States shifted to maintaining their union, the pace of European colonisation shifted to a significantly higher gear.
This phenomenon, denoted New Imperialism, saw the conquest of nearly all Southeast Asian territories by the colonial powers. The Dutch East India Company and British East India Company were dissolved by their respective governments, who took over the direct administration of the colonies. Only Thailand was spared the experience of foreign rule, though Thailand, too, was greatly affected by the power politics of the Western powers. The Monthon reforms of the late 19th Century continuing up till around 1910, imposed a Westernized form of government on the country's partially independent cities called Mueang, such that the country could be said to have successfully colonised itself. Western powers did, however, continue to interfere in both internal and external affairs.
By 1913, the British had occupied Burma, Malaya and the northern Borneo territories, the French controlled Indochina, the Dutch ruled the Netherlands East Indies while Portugal managed to hold on to Portuguese Timor. In the Philippines, the 1872 Cavite Mutiny was a precursor to the Philippine Revolution (1896–1898). When the Spanish–American War began in Cuba in 1898, Filipino revolutionaries declared Philippine independence and established the First Philippine Republic the following year. In the Treaty of Paris of 1898 that ended the war with Spain, the United States gained the Philippines and other territories; in refusing to recognise the nascent republic, America effectively reversed her position of 1856. This led directly to the Philippine–American War, in which the First Republic was defeated; wars followed with the Republic of Zamboanga, the Republic of Negros and the Republic of Katagalugan, all of which were also defeated.
Colonial rule had had a profound effect on Southeast Asia. While the colonial powers profited much from the region's vast resources and large market, colonial rule did develop the region to a varying extent. Commercial agriculture, mining and an export based economy developed rapidly during this period. The introduction Christianity bought by the colonist also have profound effect in the societal change.
Increased labour demand resulted in mass immigration, especially from British India and China, which brought about massive demographic change. The institutions for a modern nation state like a state bureaucracy, courts of law, print media and to a smaller extent, modern education, sowed the seeds of the fledgling nationalist movements in the colonial territories. In the inter-war years, these nationalist movements grew and often clashed with the colonial authorities when they demanded self-determination.
Japanese invasion and occupations.
In September 1940, following the Fall of France and pursuant to the Pacific war goals of Imperial Japan, the Japanese Imperial Army invaded Vichy French Indochina, which ended in the abortive Japanese coup de main in French Indochina of 9 March 1945. On 5 January 1941, Thailand launched the Franco-Thai War, ended on 9 May 1941 by a Japanese-imposed treaty signed in Tokyo. On 7/8 December, Japan's entry into World War II began with the invasion of Thailand, the only invaded country to maintain nominal independence, due to her political and military alliance with the Japanese—on 10 May 1942, her northwestern Payap Army invaded Burma during the Burma Campaign. From 1941 until war's end, Japanese occupied Cambodia and Malaya, which ended in independence movements. Japanese occupation of the Philippines led to the forming of the Second Philippine Republic, formally dissolved in Tokyo on 17 August 1945. Also on 17 August, a proclamation of Indonesian Independence was read at the conclusion of Japanese occupation of the Dutch East Indies since March 1942.
Post-war decolonisation.
With the rejuvenated nationalist movements in wait, the Europeans returned to a very different Southeast Asia after World War II. Indonesia declared independence on 17 August 1945 and subsequently fought a bitter war against the returning Dutch; the Philippines was granted independence by the United States in 1946; Burma secured their independence from Britain in 1948, and the French were driven from Indochina in 1954 after a bitterly fought war (the Indochina War) against the Vietnamese nationalists. The newly established United Nations provided a forum both for nationalist demands and for the newly demanded independent nations.
During the Cold War, countering the threat of communism was a major theme in the decolonisation process. After suppressing the communist insurrection during the Malayan Emergency from 1948 to 1960, Britain granted independence to Malaya and later, Singapore, Sabah and Sarawak in 1957 and 1963 respectively within the framework of the Federation of Malaysia. In one of the most bloody single incidents of violence in Cold War Southeast Asia, General Suharto seized power in Indonesia in 1965 and initiated a massacre of approximately 500,000 alleged members of the Indonesian Communist Party (PKI).
Following the independence of the Indochina states, North Vietnamese attempts to conquer South Vietnam resulted in the Vietnam War. The conflict spread to Laos and Cambodia and heavy intervention from the United States. By the war's end in 1975, all these countries were controlled by communist parties. After the communist victory, two wars between communist states—the Cambodian–Vietnamese War of 1975–89 and the Sino-Vietnamese War of 1979—were fought in the region. The victory of the Khmer Rouge in Cambodia resulted in the Cambodian Genocide.
In 1975, Portuguese rule ended in East Timor. However, independence was short-lived as Indonesia annexed the territory soon after. However, after more than 20 years of fighting Indonesia, East Timor won its independence and is recognised by the UN as the world's newest nation. Finally, Britain ended its protectorate of the Sultanate of Brunei in 1984, marking the end of European rule in Southeast Asia.
Contemporary Southeast Asia.
Modern Southeast Asia has been characterised by high economic growth by most countries and closer regional integration. Indonesia, Malaysia, the Philippines, Singapore and Thailand have traditionally experienced high growth and are commonly recognised as the more developed countries of the region. As of late, Vietnam too had been experiencing an economic boom. However, Myanmar, Cambodia, Laos and the newly independent East Timor are still lagging economically.
On 8 August 1967, the Association of Southeast Asian Nations (ASEAN) was founded by Thailand, Indonesia, Malaysia, Singapore, and the Philippines. Since Cambodian admission into the union in 1999, East Timor is the only Southeast Asian country that is not part of ASEAN, although plans are under way for eventual membership. The association aims to enhance co-operation among Southeast Asian community. ASEAN Free Trade Area has been established to encourage greater trade among ASEAN members. ASEAN has also been a front runner in greater integration of Asia-Pacific region through East Asia Summits.
See also.
By country:
General:

</doc>
<doc id="37706" url="https://en.wikipedia.org/wiki?curid=37706" title="Covalent radius">
Covalent radius

The covalent radius, "r"cov, is a measure of the size of an atom that forms part of one covalent bond. It is usually measured either in picometres (pm) or angstroms (Å), with 1 Å = 100 pm.
In principle, the sum of the two covalent radii should equal the covalent bond length between two atoms, "R"(AB) = "r"(A) + "r"(B). Moreover, different radii can be introduced for single, double and triple bonds (r1, r2 and r3 below), in a purely operational sense. These relationships are certainly not exact because the size of an atom is not constant but depends on its chemical environment. For heteroatomic A–B bonds, ionic terms may enter. Often the polar covalent bonds are shorter than would be expected on the basis of the sum of covalent radii. Tabulated values of covalent radii are either average or idealized values, which nevertheless show a certain transferability between different situations, which makes them useful.
The bond lengths "R"(AB) are measured by X-ray diffraction (more rarely, neutron diffraction on molecular crystals). Rotational spectroscopy can also give extremely accurate values of bond lengths. For homonuclear A–A bonds, Linus Pauling took the covalent radius to be half the single-bond length in the element, e.g. "R"(H–H, in H2) = 74.14 pm so "r"cov(H) = 37.07 pm: in practice, it is usual to obtain an average value from a variety of covalent compounds, although the difference is usually small. Sanderson has published a recent set of non-polar covalent radii for the main-group elements, but the availability of large collections of bond lengths, which are more transferable, from the Cambridge Crystallographic Database has rendered covalent radii obsolete in many situations.
Table of covalent radii.
The values in the table below are based on a statistical analysis of more than 228,000 experimental bond lengths from the Cambridge Structural Database. The numbers in parentheses are the estimated standard deviations for the last digit. This fit pre-fixes the radii for C, N and O.
A different approach is to make a self-consistent fit for all elements in a smaller set of molecules. This was done separately for single,
double,
and triple bonds
up to superheavy elements. Both experimental and computational data were used. 
The single-bond results are often similar to those of Cordero et al. When they are different, the coordination numbers used can be different. This is notably the case for most (d and f) transition metals. Normally one expects that "r"1 > "r"2 > "r"3. Deviations may occur for weak multiple bonds, if the differences of the ligand are larger than the differences of "R" in the data used.<br>
Note that elements up to E118 have now been experimentally produced and that there are chemical studies on an increasing number of them.
<br>
The same, self-consistent approach was used to fit tetrahedral covalent radii for 30 elements in 48 crystals with subpicometer accuracy.

</doc>
<doc id="37708" url="https://en.wikipedia.org/wiki?curid=37708" title="Flare">
Flare

A flare, also sometimes called a fusee, is a type of pyrotechnic that produces a brilliant light or intense heat without an explosion. Flares are used for signalling, illumination, or defensive countermeasures in civilian and military applications. Flares may be ground pyrotechnics, projectile pyrotechnics, or parachute-suspended to provide maximum illumination time over a large area. Projectile pyrotechnics may be dropped from aircraft, fired from rocket or artillery, or deployed by flare guns or handheld percussive tubes.
History.
The earliest recorded use of gunpowder for signalling purposes was the 'signal bomb' used by the Song Dynasty Chinese as the Mongol-led Yuan Dynasty besieged Yangzhou in 1276. These soft-shelled bombs, timed to explode in mid-air, were used to send messages to a detachment of troops far in the distance. Another mention of the signal bomb appears in a text dating from 1293 requesting their collection from those still stored in Zhejiang. A signal gun appears in Korea by 1600. The "Wu I Thu Phu Thung Chih" or "Illustrated Military Encyclopedia" written in 1791 depicts a signal gun in an illustration.
Chemistry.
Flares produce their light through the combustion of a pyrotechnic composition. The ingredients are varied, but often based on strontium nitrate, potassium nitrate, or potassium perchlorate and mixed with a fuel such as charcoal, sulfur, sawdust, aluminium, magnesium, or a suitable polymeric resin. Flares may be colored by the inclusion of pyrotechnic colorants. Calcium flares are used underwater to illuminate submerged objects.
Non-perchlorate flares.
Many in-service colored signal flares and spectrally balanced decoy flares contain perchlorate oxidizers. Perchlorate, a type of salt in its solid form, dissolves and moves rapidly in groundwater and surface water. Even in low concentrations in drinking water supplies, perchlorate is known to inhibit the uptake of iodine by the thyroid gland. While there are currently no US federal drinking water standards for perchlorate, some states have established public health goals, or action levels, and some are in the process of establishing state maximum contaminant levels. For example, the US Environmental Protection Agency have studied the impacts of perchlorate on the environment as well as drinking water. California has also issued guidance regarding perchlorate use.
US courts have taken action regarding the use of perchlorate in manufacturing pyrotechnic devices such as flares. For example, in 2003, a federal district court in California found that Comprehensive Environmental Response, Compensation and Liability Act (CERCLA) applied because perchlorate is ignitable and therefore a “characteristic” hazardous waste. (see Castaic Lake Water Agency v. Whittaker, 272 F. Supp. 2d 1053, 1059–61 (C.D. Cal. 2003)).
Civilian use.
In the civilian world, flares are commonly used as signals, and may be ignited on the ground or fired as an aerial signal from a pistol-like flare gun, or launched from a self-contained tube. Flares are commonly found in marine survival kits.
Maritime distress signal.
Red flares, either sent as a rocket or held in the hand, are widely recognized as a maritime distress signal. "RMS Titanic" however used socket-launched distress shells to attract assistance, emitting white stars to a great height and a deafening sound.
Fusee.
Another type of flare is the "fusee", which burns for 10–60 minutes with a bright red light. Fusees are commonly used to indicate obstacles or advise caution on roadways at night; in this usage they are also called "highway flares", "road flares", or "ground flares". They are commonly found in roadside emergency kits.
Fusees are also known as "railroad flares" and are commonly used to perform hand signals in rail transport applications. Since they can be used only once, fusees nowadays are usually intended for emergency use (as opposed to the lanterns typically used during normal operating conditions). However, in the days before train radio communications, fusees were used to keep trains apart in dark territory. A railroad fusee was timed to burn for ten minutes and quantities were dropped behind a train to ensure a safe spacing. If a following train encountered a burning fusee it was not to pass until the fusee burned out. Fusees made specifically for railroad use can be distinguished from highway fusees by a sharp steel spike at one end, used to embed the fusee upright in a wooden railroad tie.
In forestry and firefighting, fusees are sometimes used in wildland fire suppression and in the ignition of controlled burns. They ignite at and burn as hot as . They are especially effective in igniting burnouts or backburns in very dry conditions, but not so effective when fuel conditions are moist. Since controlled burns are often done during relatively high humidity levels (on the grounds that they could not be safely contained during periods of very low humidity), the driptorch is more effective and more often used. Fusees are also commonly carried by wildland firefighters for emergency use, to ignite an escape fire in surrounding fuels in case of being overrun by a fire if no other escape routes are available.
Calcium phosphide is often used in naval flares, as in contact with water it liberates phosphine which self ignites in contact with air; it is often used together with calcium carbide which releases acetylene.
Military use.
Illumination.
In 1922, a "landing flare" was an aerial candle attached to a parachute and used for landing an airplane in the dark. The flare burned for less than 4 minutes and the candle power was about 40,000.
Countermeasure.
A special variety of flare is used in military aircraft as a defensive countermeasure against heat-seeking missiles. These flares are usually discharged individually or in salvoes by the pilot or automatically by tail-warning devices, and are accompanied by vigorous evasive maneuvering. Since they are intended to deceive infrared missiles, these flares burn at temperatures of thousands of degrees, incandescing in the visible spectrum as well.
Regulation.
Pyrotechnic flares are classified as class 1.4 explosives, and as such have been utilized in training exercises by explosive disposal units within police forces."
Several U.S. states, including California and Massachusetts, have begun regulating levels of potassium perchlorate, which can be unsafe at certain levels in drinking water. Contaminated drinking water can lead to such symptoms as gastric irritation, nausea, vomiting, fever, skin rashes, and even fatal aplastic anemia.

</doc>
<doc id="37710" url="https://en.wikipedia.org/wiki?curid=37710" title="Enthalpy of vaporization">
Enthalpy of vaporization

The enthalpy of vaporisation, (symbol ∆Hvap) also known as the (latent) heat of vaporisation or heat of evaporation, is the energy (enthalpy) that must be added to the substance, typically a liquid, to transform a quantity of that substance into a gas. The enthalpy of vaporization is a function of the pressure at which that transformation takes place.
The enthalpy of vaporization is often quoted for the normal boiling temperature of the substance; although tabulated values are usually corrected to 298 K, that correction is often smaller than the uncertainty in the measured value.
The heat of vaporization is temperature-dependent, though a constant heat of vaporization can be assumed for small temperature ranges and for reduced temperature formula_1formula_2. The heat of vaporization diminishes with increasing temperature and it vanishes completely at a certain point called the critical temperature (formula_3). Above the critical temperature, the liquid and vapor phases are indistinguishable, and the substance is called a supercritical fluid.
Units.
Values are usually quoted in J/mol or kJ/mol (molar enthalpy of vaporization), although kJ/kg or J/g (specific heat of vaporization), and older units like kcal/mol, cal/g and Btu/lb are sometimes still used, among others.
Physical model for vaporization.
A simple physical model for the liquid–gas phase transformation was proposed in 2009 by Jozsef Garai. It is suggested that the energy required to free an atom from the liquid is equivalent to the energy needed to overcome the surface resistance of the liquid. The model allows calculating the latent heat by multiplying the maximum surface area covering an atom (Fig. 1) with the surface tension and the number of atoms in the liquid. The calculated latent heat of vaporization values for the investigated 45 elements agrees well with experiments. Another model which utilizes the data set from Jozsef Garai's model shows that the liquid–gas phase change can be explained in terms of kinetic theory by considering that the energy required for vaporization is extracted from all six of the vaporizing molecule's neighbours. This includes a required rethink of the probability of vaporization, and has consequences to the Clausius-Clapeyron equation. Moreover, it does resolve the issue of the latent heat of vaporization being significantly greater than the thermal energy exchanged between molecules, i.e. at boiling point the latent heat for water is approximately 13.2 times kT (Boltzmann's factor multiplied by boiling temperature.)
Enthalpy of condensation.
The enthalpy of condensation (or heat of condensation) is by definition equal to the enthalpy of vaporization with the opposite sign: enthalpy changes of vaporization are always positive (heat is absorbed by the substance), whereas enthalpy changes of condensation are always negative (heat is released by the substance).
Thermodynamic background.
The enthalpy of vaporization can be written as 
It is equal to the increased internal energy of the vapor phase compared with the liquid phase, plus the work done against ambient pressure. The increase in the internal energy can be viewed as the energy required to overcome the intermolecular interactions in the liquid (or solid, in the case of sublimation). Hence helium has a particularly low enthalpy of vaporization, 0.0845 kJ/mol, as the van der Waals forces between helium atoms are particularly weak. On the other hand, the molecules in liquid water are held together by relatively strong hydrogen bonds, and its enthalpy of vaporization, 40.65 kJ/mol, is more than five times the energy required to heat the same quantity of water from 0 °C to 100 °C ("c"p = 75.3 J K−1 mol−1). Care must be taken, however, when using enthalpies of vaporization to "measure" the strength of intermolecular forces, as these forces may persist to an extent in the gas phase (as is the case with hydrogen fluoride), and so the calculated value of the bond strength will be too low. This is particularly true of metals, which often form covalently bonded molecules in the gas phase: in these cases, the enthalpy of atomization must be used to obtain a true value of the bond energy.
An alternative description is to view the enthalpy of condensation as the heat which must be released to the surroundings to compensate for the drop in entropy when a gas condenses to a liquid. As the liquid and gas are in equilibrium at the boiling point ("T"b), Δv"G" = 0, which leads to:
As neither entropy nor enthalpy vary greatly with temperature, it is normal to use the tabulated standard values without any correction for the difference in temperature from 298 K. A correction must be made if the pressure is different from 100 kPa, as the entropy of a gas is proportional to its pressure (or, more precisely, to its fugacity): the entropies of liquids vary little with pressure, as the compressibility of a liquid is small.
These two definitions are equivalent: the boiling point is the temperature at which the increased entropy of the gas phase overcomes the intermolecular forces. As a given quantity of matter always has a higher entropy in the gas phase than in a condensed phase (formula_6 is always positive), and from
the Gibbs free energy change falls with increasing temperature: gases are favored at higher temperatures, as is observed in practice.
Vaporization enthalpy of electrolyte solutions.
Estimation of the enthalpy of vaporization of electrolyte solutions can be simply carried out using equations based on the chemical thermodynamic models, such as Pitzer model or TCPC model.
Selected values.
Other common substances.
Enthalpies of vaporization of common substances, measured at their respective standard boiling points:

</doc>
<doc id="37712" url="https://en.wikipedia.org/wiki?curid=37712" title="Chemical patent">
Chemical patent

A chemical patent, pharmaceutical patent or drug patent is a patent for an invention in the chemical or pharmaceuticals industry. Strictly speaking, in most jurisdictions, there are essentially no differences between the legal requirements to obtain a patent for an invention in the chemical or pharmaceutical fields, in comparison to obtaining a patent in the other fields, such as in the mechanical field. A chemical patent or a pharmaceutical patent is therefore "not" a "sui generis" right, i.e. a special legal type of patent.
In the pharmaceutical industry, the patent protection of drugs and medicines is accorded a particular importance, because drugs and medicines can easily be copied or imitated (by analyzing a pharmaceutical substance) and because of the significant research and development spending and the high risks associated with the development of a new drug.
Chemical patents are different from other sources of technical information because of the generic, Markush structures contained within them, named after the inventor Eugene Markush who won a claim in the US in 1925 to allow such structures to be used in patent claims. These generic structures are used to make the patent claim as broad as possible.

</doc>
<doc id="37713" url="https://en.wikipedia.org/wiki?curid=37713" title="The Merchant of Venice">
The Merchant of Venice

The Merchant of Venice is a play by William Shakespeare in which a merchant in 16th-century Venice must default on a large loan provided by an abused Jewish moneylender. It is believed to have been written between 1596 and 1598. Though classified as a comedy in the First Folio and sharing certain aspects with Shakespeare's other romantic comedies, the play is perhaps most remembered for its dramatic scenes, and is best known for Shylock and the famous "Hath not a Jew eyes?" speech. Also notable is Portia's speech about "the quality of mercy".
Summary.
Bassanio, a young Venetian of noble rank, wishes to woo the beautiful and wealthy heiress Portia of Belmont. Having squandered his estate, he needs 3,000 ducats to subsidise his expenditures as a suitor. Bassanio approaches his friend Antonio, a wealthy merchant of Venice who has previously and repeatedly bailed him out. Antonio agrees, but since he is cash-poor – his ships and merchandise are busy at sea – he promises to cover a bond if Bassanio can find a lender, so Bassanio turns to the Jewish moneylender Shylock and names Antonio as the loan's guarantor.
Antonio has already antagonized Shylock through his outspoken antisemitism, and because Antonio's habit of lending money without interest forces Shylock to charge lower rates. Shylock is at first reluctant to grant the loan, citing abuse he has suffered at Antonio's hand. He finally agrees to lend the sum to Bassanio without interest upon one condition: if Bassanio is unable to repay it at the specified date, Shylock may take a pound of Antonio's flesh. Bassanio does not want Antonio to accept such a risky condition; Antonio is surprised by what he sees as the moneylender's generosity (no "usance" – interest – is asked for), and he signs the contract. With money at hand, Bassanio leaves for Belmont with his friend Gratiano, who has asked to accompany him. Gratiano is a likeable young man, but is often flippant, overly talkative, and tactless. Bassanio warns his companion to exercise self-control, and the two leave for Belmont and Portia.
Meanwhile, in Belmont, Portia is awash with suitors. Her father left a will stipulating each of her suitors must choose correctly from one of three caskets – one each of gold, silver and lead. If he picks the right casket, he gets Portia. The first suitor, the Prince of Morocco, chooses the gold casket, interpreting its slogan, "Who chooseth me shall gain what many men desire," as referring to Portia. The second suitor, the conceited Prince of Arragon, chooses the silver casket, which proclaims, "Who chooseth me shall get as much as he deserves", as he believes he is full of merit. Both suitors leave empty-handed, having rejected the lead casket because of the baseness of its material and the uninviting nature of its slogan, "Who chooseth me must give and hazard all he hath." The last suitor is Bassanio, whom Portia wishes to succeed, having met him before. As Bassanio ponders his choice, members of Portia's household sing a song which says that "fancy" (not true love) is "engend'red in the eyes, With gazing fed.", Bassanio chooses the lead casket and wins Portia's hand.
At Venice, Antonio's ships are reported lost at sea so the merchant cannot repay the bond. Shylock has become more determined to exact revenge from Christians because his daughter Jessica eloped with the Christian Lorenzo and converted. She took a substantial amount of Shylock's wealth with her, as well as a turquoise ring which Shylock had been given by his late wife, Leah. Shylock has Antonio brought before court.
At Belmont, Bassanio receives a letter telling him that Antonio has been unable to repay the loan from Shylock. Portia and Bassanio marry, as do Gratiano and Portia's handmaid Nerissa. Bassanio and Gratiano leave for Venice, with money from Portia, to save Antonio's life by offering the money to Shylock. Unknown to Bassanio and Gratiano, Portia sent her servant, Balthazar, to seek the counsel of Portia's cousin, Bellario, a lawyer, at Padua.
The climax of the play takes place in the court of the Duke of Venice. Shylock refuses Bassanio's offer of 6,000 ducats, twice the amount of the loan. He demands his pound of flesh from Antonio. The Duke, wishing to save Antonio but unable to nullify a contract, refers the case to a visitor. He identifies himself as Balthazar, a young male "doctor of the law", bearing a letter of recommendation to the Duke from the learned lawyer Bellario. The doctor is Portia in disguise, and the law clerk who accompanies her is Nerissa, also disguised as a man. As Balthazar, Portia repeatedly asks Shylock to show mercy in a famous speech, advising him that mercy "is twice blest: It blesseth him that gives and him that takes" (IV, i, 185). However, Shylock adamantly refuses any compensations and insists on the pound of flesh.
As the court grants Shylock his bond and Antonio prepares for Shylock's knife, Portia deftly appropriates Shylock's argument for 'specific performance.' She says that the contract allows Shylock only to remove the "flesh", not the "blood", of Antonio (see quibble). Thus, if Shylock were to shed any drop of Antonio's blood, his "lands and goods" would be forfeited under Venetian laws. She tells him that he must cut precisely one pound of flesh, no more, no less; she advises him that "if the scale do turn, But in the estimation of a hair, Thou diest and all thy goods are confiscate."
Defeated, Shylock concedes to accepting Bassanio's offer of money for the defaulted bond, first his offer to pay "the bond thrice", which Portia rebuffs, telling him to take his bond, and then merely the principal, which Portia also prevents him from doing on the ground that he has already refused it "in the open court." She cites a law under which Shylock, as a Jew and therefore an "alien", having attempted to take the life of a citizen, has forfeited his property, half to the government and half to Antonio, leaving his life at the mercy of the Duke. The Duke pardons Shylock's life. Antonio asks for his share "in use" until Shylock's death, when the principal will be given to Lorenzo and Jessica. At Antonio's request, the Duke grants remission of the state's half of forfeiture, but on the condition that Shylock convert to Christianity and bequeath his entire estate to Lorenzo and Jessica (IV,i).
Bassanio does not recognise his disguised wife, but offers to give a present to the supposed lawyer. First she declines, but after he insists, Portia requests his ring and Antonio's gloves. Antonio parts with his gloves without a second thought, but Bassanio gives the ring only after much persuasion from Antonio, as earlier in the play he promised his wife never to lose, sell or give it. Nerissa, as the lawyer's clerk, succeeds in likewise retrieving her ring from Gratiano, who does not see through her disguise.
At Belmont, Portia and Nerissa taunt and pretend to accuse their husbands before revealing they were really the lawyer and his clerk in disguise (V). After all the other characters make amends, Antonio learns from Portia that three of his ships were not stranded and have returned safely after all.
Sources.
The forfeit of a merchant's deadly bond after standing surety for a friend's loan was a common tale in England in the late 16th century. In addition, the test of the suitors at Belmont, the merchant's rescue from the "pound of flesh" penalty by his friend's new wife disguised as a lawyer, and her demand for the betrothal ring in payment are all elements present in the 14th-century tale "Il Pecorone" by Giovanni Fiorentino, which was published in Milan in 1558. Elements of the trial scene are also found in "The Orator" by Alexandre Sylvane, published in translation in 1596. The story of the three caskets can be found in "Gesta Romanorum", a collection of tales probably compiled at the end of the 13th century.
Date and text.
The date of composition for "The Merchant of Venice" is believed to be between 1596 and 1598. The play was mentioned by Francis Meres in 1598, so it must have been familiar on the stage by that date. The title page of the first edition in 1600 states that it had been performed "divers times" by that date. Salerino's reference to his ship the "Andrew" (I,i,27) is thought to be an allusion to the Spanish ship "St. Andrew," captured by the English at Cádiz in 1596. A date of 1596–97 is considered consistent with the play's style.
The play was entered in the Register of the Stationers Company, the method at that time of obtaining copyright for a new play, by James Roberts on 22 July 1598 under the title "The Merchant of Venice", otherwise called "The Jew of Venice". On 28 October 1600 Roberts transferred his right to the play to the stationer Thomas Heyes; Heyes published the first quarto before the end of the year. It was printed again in a pirated edition in 1619, as part of William Jaggard's so-called False Folio. (Afterward, Thomas Heyes' son and heir Laurence Heyes asked for and was granted a confirmation of his right to the play, on 8 July 1619.) The 1600 edition is generally regarded as being accurate and reliable. It is the basis of the text published in the 1623 First Folio, which adds a number of stage directions, mainly musical cues.
Themes.
Shylock and the antisemitism debate.
The play is frequently staged today, but is potentially troubling to modern audiences due to its central themes, which can easily appear antisemitic. Critics today still continue to argue over the play's stance on antisemitism.
Shylock as a villain.
English society in the Elizabethan era has been described as "judeophobic". English Jews had been expelled under Edward I in 1290 and were not permitted to return until 1656 under the rule of Oliver Cromwell. In Venice and in some other places, Jews were required to wear a red hat at all times in public to make sure that they were easily identified, and had to live in a ghetto protected by Christian guards. On the Elizabethan stage, Jews were often presented in an Orientalist caricature, with hooked noses and bright red wigs, and were usually depicted as avaricious usurers; an example is Christopher Marlowe's play "The Jew of Malta", which features a comically wicked Jewish villain called Barabas. They were usually characterised as evil, deceitful and greedy.
Shakespeare's play may be seen as a continuation of this tradition. The title page of the Quarto indicates that the play was sometimes known as "The Jew of Venice" in its day, which suggests that it was seen as similar to Marlowe's "The Jew of Malta". One interpretation of the play's structure is that Shakespeare meant to contrast the mercy of the main Christian characters with the vengefulness of a Jew, who lacks the religious grace to comprehend mercy. Similarly, it is possible that Shakespeare meant Shylock's forced conversion to Christianity to be a "happy ending" for the character, as, to a Christian audience, it saves his soul and allows him to enter Heaven.
Regardless of what Shakespeare's authorial intent may have been, the play has been made use of by antisemites throughout the play's history. One must note that the end of the title in the 1619 edition "With the Extreme Cruelty of Shylock the Jew..." must aptly describe how Shylock was viewed by the English public. The Nazis used the usurious Shylock for their propaganda. Shortly after Kristallnacht in 1938, "The Merchant of Venice" was broadcast for propagandistic ends over the German airwaves. Productions of the play followed in Lübeck (1938), Berlin (1940), and elsewhere within the Nazi Territory.
In a series of articles called "Observer", first published in 1785, British playwright Richard Cumberland created a character named Abraham Abrahams who is quoted as saying, "I verily believe the odious character of Shylock has brought little less persecution upon us, poor scattered sons of Abraham, than the Inquisition itself." Cumberland later wrote a successful play, "The Jew" (1794), in which his title character, Sheva, is portrayed sympathetically, as both a kindhearted and generous man. This was the first known attempt by a dramatist to reverse the negative stereotype that Shylock personified.
The depiction of Jews in literature throughout the centuries bears the close imprint of Shylock. With slight variations much of English literature up until the 20th century depicts the Jew as "a monied, cruel, lecherous, avaricious outsider tolerated only because of his golden hoard".
Shylock as a sympathetic character.
Many modern readers and theatregoers have read the play as a plea for tolerance, noting that Shylock is a sympathetic character. They cite as evidence that Shylock's 'trial' at the end of the play is a mockery of justice, with Portia acting as a judge when she has no right to do so. The characters who berated Shylock for dishonesty resort to trickery in order to win. In addition, Shakespeare gives Shylock one of his most eloquent speeches:
It is difficult to know whether the sympathetic reading of Shylock is entirely due to changing sensibilities among readers, or whether Shakespeare, a writer who created complex, multi-faceted characters, deliberately intended this reading.
One of the reasons for this interpretation is that Shylock's painful status in Venetian society is emphasised. To some critics, Shylock's celebrated "Hath Not a Jew eyes?" speech (see above) redeems him and even makes him into something of a tragic figure; in the speech, Shylock argues that he is no different from the Christian characters. Detractors note that Shylock ends the speech with a tone of revenge: "if you wrong us, shall we not revenge?" Those who see the speech as sympathetic point out that Shylock says he learned the desire for revenge from the Christian characters: "If a Christian wrong a Jew, what should his sufferance be by Christian example? Why, revenge. The villainy you teach me, I will execute, and it shall go hard but I will better the instruction."
Even if Shakespeare did not intend the play to be read this way, the fact that it retains its power on stage for audiences who may perceive its central conflicts in radically different terms is an illustration of the subtlety of Shakespeare's characterisations. In the trial Shylock represents what Elizabethan Christians believed to be the Jewish desire for "justice", contrasted with their obviously superior Christian value of mercy. The Christians in the courtroom urge Shylock to love his enemies, although they themselves have failed in the past. Harold Bloom explains that, although the play gives merit to both cases, the portraits are not even-handed: "Shylock’s shrewd indictment of Christian hypocrisy us, but…Shakespeare’s intimations do not alleviate the savagery of his portrait of the Jew…" However, it can rightly be said that
Antonio, Bassanio.
Antonio's unexplained depression — "In sooth I know not why I am so sad" — and utter devotion to Bassanio has led some critics to theorise that he is suffering from unrequited love for Bassanio and is depressed because Bassanio is coming to an age where he will marry a woman. In his plays and poetry Shakespeare often depicted strong male bonds of varying homosociality, which has led some critics to infer that Bassanio returns Antonio's affections despite his obligation to marry:
In his essay "Brothers and Others", published in "The Dyer's Hand," W. H. Auden describes Antonio as "a man whose emotional life, though his conduct may be chaste, is concentrated upon a member of his own sex." Antonio's feelings for Bassanio are likened to a couplet from Shakespeare's Sonnets: "But since she pricked thee out for women's pleasure,/ Mine be thy love, and my love's use their treasure." Antonio, says Auden, embodies the words on Portia's leaden casket: "Who chooseth me, must give and hazard all he hath." Antonio has taken this potentially fatal turn because he despairs, not only over the loss of Bassanio in marriage, but also because Bassanio cannot requite what Antonio feels for him. Antonio's frustrated devotion is a form of idolatry: the right to live is yielded for the sake of the loved one. There is one other such idolator in the play: Shylock himself. "Shylock, however unintentionally, did, in fact, hazard all for the sake of destroying the enemy he hated; and Antonio, however unthinkingly he signed the bond, hazarded all to secure the happiness of the man he loved." Both Antonio and Shylock, agreeing to put Antonio's life at a forfeit, stand outside the normal bounds of society. There was, states Auden, a traditional "association of sodomy with usury", reaching back at least as far as Dante, with which Shakespeare was likely familiar. (Auden sees the theme of usury in the play as a comment on human relations in a mercantile society.)
Other interpreters of the play regard Auden's conception of Antonio's sexual desire for Bassanio as questionable. Michael Radford, director of the 2004 film version starring Al Pacino, explained that although the film contains a scene where Antonio and Bassanio actually kiss, the friendship between the two is platonic, in line with the prevailing view of male friendship at the time. Jeremy Irons, in an interview, concurs with the director's view and states that he did not "play Antonio as gay". Joseph Fiennes, however, who plays Bassanio, encouraged a homoerotic interpretation and, in fact, surprised Irons with the kiss on set, which was filmed in one take. Fiennes defended his choice, saying "I would never invent something before doing my detective work in the text. If you look at the choice of language … you'll read very sensuous language. That's the key for me in the relationship. The great thing about Shakespeare and why he's so difficult to pin down is his ambiguity. He's not saying they're gay or they're straight, he's leaving it up to his actors. I feel there has to be a great love between the two characters … there's great attraction. I don't think they have slept together but that's for the audience to decide."
Performance history.
The earliest performance of which a record has survived was held at the court of King James in the spring of 1605, followed by a second performance a few days later, but there is no record of any further performances in the 17th century. In 1701, George Granville staged a successful adaptation, titled "The Jew of Venice", with Thomas Betterton as Bassanio. This version (which featured a masque) was popular, and was acted for the next forty years. Granville cut the clownish Gobbos in line with neoclassical decorum; he added a jail scene between Shylock and Antonio, and a more extended scene of toasting at a banquet scene. Thomas Doggett was Shylock, playing the role comically, perhaps even farcically. Rowe expressed doubts about this interpretation as early as 1709; Doggett's success in the role meant that later productions would feature the troupe clown as Shylock.
In 1741, Charles Macklin returned to the original text in a very successful production at Drury Lane, paving the way for Edmund Kean seventy years later (see below).
Arthur Sullivan wrote incidental music for the play in 1871.
Shylock on stage.
Jewish actor Jacob Adler and others report that the tradition of playing Shylock sympathetically began in the first half of the 19th century with Edmund Kean, and that previously the role had been played "by a comedian as a repulsive clown or, alternatively, as a monster of unrelieved evil." Kean's Shylock established his reputation as an actor.
From Kean's time forward, all of the actors who have famously played the role, with the exception of Edwin Booth, who played Shylock as a simple villain, have chosen a sympathetic approach to the character; even Booth's father, Junius Brutus Booth, played the role sympathetically. Henry Irving's portrayal of an aristocratic, proud Shylock (first seen at the Lyceum in 1879, with Portia played by Ellen Terry) has been called "the summit of his career". Jacob Adler was the most notable of the early 20th century: Adler played the role in Yiddish-language translation, first in Manhattan's Yiddish Theater District in the Lower East Side, and later on Broadway, where, to great acclaim, he performed the role in Yiddish in an otherwise English-language production.
Kean and Irving presented a Shylock justified in wanting his revenge; Adler's Shylock evolved over the years he played the role, first as a stock Shakespearean villain, then as a man whose better nature was overcome by a desire for revenge, and finally as a man who operated not from revenge but from pride. In a 1902 interview with "Theater" magazine, Adler pointed out that Shylock is a wealthy man, "rich enough to forgo the interest on three thousand ducats" and that Antonio is "far from the chivalrous gentleman he is made to appear. He has insulted the Jew and spat on him, yet he comes with hypocritical politeness to borrow money of him." Shylock's fatal flaw is to depend on the law, but "would he not walk out of that courtroom head erect, the very apotheosis of defiant hatred and scorn?"
Some modern productions take further pains to show the sources of Shylock's thirst for vengeance. For instance, in the 2004 film adaptation directed by Michael Radford and starring Al Pacino as Shylock, the film begins with text and a montage of how Venetian Jews are cruelly abused by bigoted Christians. One of the last shots of the film also brings attention to the fact that, as a convert, Shylock would have been cast out of the Jewish community in Venice, no longer allowed to live in the ghetto. Another interpretation of Shylock and a vision of how "must he be acted" appears at the conclusion of the autobiography of Alexander Granach, a noted Jewish stage and film actor in Weimar Germany (and later in Hollywood and on Broadway).
Adaptations and cultural references.
Film and TV versions.
The Shakespeare play has inspired several films.
Cultural references.
The play contains the earliest known use of the phrase "with bated breath" (by Shylock, in Act I, Scene 3, "Shall I bend low and, in a bondman's key, / With bated breath and whisp'ring humbleness, / Say this ..."), which has come into common use to convey the idea of restraining one's breathing in anticipation or supplicance (in which the archaic ""bated"" is often misidentified as ""baited"" in modern usage). The phrase also appears in Mark Twain's 1876 novel "The Adventures of Tom Sawyer".
Arnold Wesker's play "The Merchant" tells the same story from Shylock's point of view. In this retelling, Shylock and Antonio are fast friends bound by a mutual love of books and culture and a disdain for the crass anti-Semitism of the Christian community's laws. They make the bond in defiant mockery of the Christian establishment, never anticipating that the bond might become forfeit. When it does, the play argues, Shylock must carry through on the letter of the law or jeopardise the scant legal security of the entire Jewish community. He is, therefore, quite as grateful as Antonio when Portia, as in Shakespeare's play, shows the legal way out. The play received its American premiere on 16 November 1977 at New York's Plymouth Theatre, with Joseph Leon as Shylock and Marian Seldes as Shylock's sister Rivka. This production had a challenging history in previews on the road, culminating (after the first night out of town in Philadelphia on 8 September 1977) with the death of the larger-than-life Broadway star Zero Mostel, who was initially cast as Shylock. The play's author, Arnold Wesker, wrote a book chronicling the out-of-town tribulations that beset the play and Zero's death called "The Birth of Shylock and the Death of Zero Mostel".
David Henry Wilson's play "Shylock's Revenge", which was first performed by The University Players at the Audimax (University of Hamburg) on 9 June 1989, can be seen as a full-length sequel to Shakespeare's drama.
The title of the film "Seven Pounds" is a reference to the "pound of flesh" from the play.
Edmond Haraucourt, the French playwright and poet, was commissioned in the 1880s by the actor and theatrical director Paul Porel to make a French-verse adaptation of "The Merchant of Venice". His play "Shylock", first performed at the Théâtre de l'Odéon in December 1889, had incidental music by the French composer Gabriel Fauré, later incorporated into an orchestral suite of the same name.
One of the four short stories comprising Alan Isler's "Op Non Cit" is also told from Shylock's point of view. In this story, Antonio was a boy of Jewish origin kidnapped at an early age by priests.
Ralph Vaughan Williams' choral work "Serenade to Music" draws its text from the discussion about music and the music of the spheres in Act V, scene 1.
In both versions of the comic film "To Be or Not to Be" the character "Greenberg", specified as a Jew only in the later version, gives a recitation of the "Hath Not a Jew eyes?" speech to Nazi soldiers.
In "The Pianist", Henryk Szpilman quotes a passage from Shylock's "Hath Not a Jew eyes?" speech to his brother Władysław Szpilman in a Jewish ghetto in Warsaw, Poland, during the Nazi occupation in World War II. Given the questioning of Antisemitism in the speech and also the Nazi use of the play for antisemitic propaganda purposes, the quote is seen as particularly poignant and symbolic.
Steven Spielberg's "Schindler's List" depicts SS Lieutenant Amon Göth quoting Shylock's "Hath Not a Jew eyes?" speech when deciding whether or not to rape his Jewish maid.
The rock musical "Fire Angel" was based on the story of the play, with the scene changed to the Little Italy district of New York. It was performed in Edinburgh in 1974 and in a revised form at Her Majesty's Theatre, London, in 1977.
Christopher Moore combines "The Merchant of Venice" and "Othello" in his 2014 comic novel "The Serpent of Venice", in which he makes Portia (from "The Merchant of Venice") and Desdemona (from "Othello") sisters. All of the characters come from those two plays with the exception of Pocket, the Fool, who comes from Moore's earlier novel based on "King Lear".
Jane Lindskold's book "Changer" contains a scene in which the protagonists consider "using Portia's gambit from "The Merchant of Venice"" to escape from a situation and binding contract analogous to Antonio's.
The online satirical news site "The Onion" satirized the play in its article "'Unconventional Director Sets Shakespeare Play In Time, Place Shakespeare Intended".
The play has been quoted and paraphrased several times in the "Star Trek" Universe:
The David Seltzer screenplay for the 1971 film "Willy Wonka and the Chocolate Factory" contains this line, near the end of the film: spoken by Willy Wonka, as if to himself, when Charlie returns the Everlasting Gobstopper: "So shines a good deed in a weary world"- derived perhaps from Portia's lines in Act V, Scene 1: "That light we see is burning in my hall. How far that little candle throws his beams! So shines a good deed in a naughty world."

</doc>
<doc id="37714" url="https://en.wikipedia.org/wiki?curid=37714" title="Energia">
Energia

Energia (, , "Energy") was a Soviet rocket that was designed by NPO Energia to serve as a heavy-lift expendable launch system as well as a booster for the Buran spacecraft. Control system main developer enterprise was the NPO "Electropribor". The Energia used four strap-on boosters each powered by a four-chamber RD-170 engine burning kerosene/LOX, and a central core stage with 4 one-chamber RD-0120 (11D122) engines fueled by liquid hydrogen/LOX.
The launch system had two functionally different operational variants: "Energia-Polyus", the initial test configuration, in which the Polyus system was used as a final stage to put the payload into orbit, and "Energia-Buran", in which the Buran spacecraft was the payload and the source of the orbit insertion impulse.
The rocket had the capacity to place about 100 tonnes in Low Earth orbit, up to 20 tonnes to geostationary orbit and up to 32 tonnes to a translunar trajectory.
History.
Development.
Work on the Energia/Buran system began in 1976 after the decision was made to cancel the unsuccessful N1 rocket. The cancelled N1 rocket-based Manned Lunar Launch Facilities and Infrastructure were used for Energia (notably the huge horizontal assembly building), just as NASA reused infrastructure designed for the Saturn V in the Space Shuttle program. Energia also replaced the "Vulkan" concept, which was a design based on the Proton (rocket family) and using the same hypergolic fuels, but much larger and more powerful. The "Vulkan" designation was later given to a variation of the Energia which has eight boosters and multiple stages.
The Energia was designed to launch the Russian "Buran" reusable shuttle, and for that reason was designed to carry its payload mounted on the side of the stack, rather than on the top, as is done with other launch vehicles. After design of the Energia-Buran system, it was also proposed that the booster could be used without the Buran as a heavy-lift cargo launch vehicle; this configuration was originally given the name "Buran-T". This configuration required the addition of an upper stage to perform the final orbital insertion. The first launch of the Energia was in the configuration of a heavy launch vehicle, with the large Polyus military satellite as a payload, however Polyus failed to correctly perform the orbital insertion.
Due to the termination of the Buran program the Energia program was concluded after only two launches, and further the payload on the first launch didn't perform the final boost properly. The legacy of Energia/Buran project manifests itself most visibly in form of the RD-170 family of rocket engines, and the Zenit launcher, with the first stage roughly the same as one of the Energia first-stage boosters.
First launch (Energia-Polyus).
The Energia was first test-launched on 15 May 1987, with the Polyus spacecraft as the payload. A FGB ("Functional Cargo Block") engine section originally built as a cancelled Mir module was incorporated into the upper stage used to inject the payload into orbit, similarly to Buran and the US Space Shuttle performing the final orbital insertion, since the planned "Buran-T" upper stage had not yet progressed beyond the planning stage. The intended orbit was altitude 280 km (170 mi), inclination 64.6°.
The Soviets had originally announced that the launch was a successful sub-orbital test of the new Energia booster with a dummy payload, but some time later it was revealed that the flight had, in fact, been intended to orbit the Polyus, a UKSS (Russian: "Универсальный Комплекс Стенд-Старт", Universal Complex Stand-Start) military payload. The two stages of the Energia launcher functioned as designed, but due to a software error in its attitude control system, Polyus' orbital insertion motor failed to inject the payload into orbit. Instead, the Polyus reentered the atmosphere over the Pacific ocean.
Second launch (Energia-Buran).
The second flight, and the first one where payload successfully reached orbit, was launched on 15 November 1988. This mission launched the unmanned Soviet Shuttle vehicle, Buran. At apogee, the Buran spacecraft made a 66.7 m/s burn to reach a final orbit of 251 km x 263 km.
Discontinuation.
Production of Energia rockets ended with the fall of the Soviet Union and the end of the Buran shuttle project. Ever since, there have been persistent rumors of the renewal of production, but given the current political realities, that is highly unlikely. While the Energia is no longer in production, the Zenit boosters are still in production and in use. The four strap-on liquid-fuel boosters, which burned kerosene and liquid oxygen, were the basis of the Zenit rocket which used the same engines. The engine is the four combustion chamber RD-170. Its derivative, the RD-171, is still used on the Zenit rocket. A half-sized derivative of the engine, the two-chamber RD-180, powers Lockheed Martin's Atlas V rocket, while the single-chamber derivative, the RD-191, has been used to launch the Korean Naro-1 (as a reduced-thrust variant named the RD-151) and the Russian Angara rocket.
Revival.
Efforts have been made to use Energia as a heavy-lift booster rocket, the most recent of which was in November 2013.
Variants.
Three major variants were conceptualized after the original configuration, each with vastly different payloads.
Energia M.
The Energia M was the smallest design configuration. The number of Zenit boosters was reduced from four to two, and instead of four RD-0120 engines in the core, it had only one. It was designed to replace the Proton rocket, but lost the 1993 competition to the Angara rocket.
Energia II ("Uragan").
Energia II, named Uragan (, "Hurricane"), was a rocket proposed to be fully reusable with the design feature to land on a conventional airfield. Unlike the Energia, which was planned to be semi-reusable (like that of the U.S. Space Shuttle), the Uragan concept was to have allowed the complete recovery of all Buran/Energia elements, like that of the original totally reusable Orbiter/Booster concept of the U.S. Shuttle. The Energia II core as proposed would be capable of re-entering and gliding to a landing, presumably using technology developed for the Buran.
Vulkan-Hercules.
The final unflown configuration was also the largest. With eight Zenit booster rockets and an Energia-M core as the upper stage, the "Vulkan" (which was the same name of another Soviet heavy lift rocket that was cancelled years earlier) or "Hercules" (which is the same name designated to the N-1 rockets) configuration could have launched up to 175 tonnes into orbit.
The development of rocket-carrier "Vulcan" and the refurbishment of the "Energia" launch pad for its launches was in progress in 1990-1993. But later on the work on this project was cancelled due to lack of funds and the collapse of Soviet Union.

</doc>
<doc id="37715" url="https://en.wikipedia.org/wiki?curid=37715" title="Allegro">
Allegro

Allegro may refer to:

</doc>
<doc id="37716" url="https://en.wikipedia.org/wiki?curid=37716" title="Presto">
Presto

Presto may refer to:

</doc>
<doc id="37717" url="https://en.wikipedia.org/wiki?curid=37717" title="Crescendo (disambiguation)">
Crescendo (disambiguation)

Crescendo is a passage of music during which the volume gradually increases.
Crescendo may also refer to:

</doc>
<doc id="37720" url="https://en.wikipedia.org/wiki?curid=37720" title="Staccato">
Staccato

Staccato (Italian for "detached") is a form of musical articulation. In modern notation it signifies a note of shortened duration, separated from the note that may follow by silence. It has been described by theorists and appeared in music since at least 1676.
Notation.
In 20th-century music, a dot placed above or below a note indicates that it should be played staccato, and a wedge is used for the more emphatic staccatissimo. However, before 1850, dots, dashes, and wedges were all likely to have the same meaning, even though some theorists from as early as the 1750s distinguished different degrees of staccato through the use of dots and dashes, with the dash indicating a shorter, sharper note, and the dot a longer, lighter one. A number of signs came to be used in the late 19th and early 20th centuries to discriminate more subtle nuances of staccato. These signs involve various combinations of dots, vertical and horizontal dashes, vertical and horizontal wedges, and the like, but attempts to standardize these signs have not generally been successful. This does not, however, alter the rhythm of the music and the remainder of the time allotted for each staccato note is played as rest. The opposite musical articulation of staccato is legato, signifying long and continuous notes.
The scope of the staccato dot:
In the first measure, the pairs of notes are in the same musical part since they are on a common stem. The staccato applies to both notes of the pairs. In the second measure, the pairs of notes are stemmed separately indicating two different parts, so the staccato applies only to the upper note.
Playing staccato is the opposite of playing legato. A staccato passage for strings is by definition a bowed rather than a pizzicato technique, though pizzicato itself might be thought of as a kind of staccato effect. For example, Leroy Anderson's "Jazz Legato/Jazz Pizzicato". There is an intermediate articulation called either mezzo staccato or non-legato.
Staccatissimo.
In Musical notation, staccatissimo (plural: "staccatissimi" or the anglicised form "staccatissimos") indicates that the notes are to be played extremely separated and distinct, a superlative staccato. This can be notated with little pikes over or under the notes, depending on stem direction, as in this example from Bruckner's Symphony No. 0 in D minor:
Alternatively it can be notated by writing the word "staccatissimo" or the abbreviation "staccatiss." over the staff. A few composers, such as Mozart, have used staccato dots accompanied by a written instruction "staccatissimo" when they mean the passage to be played "staccatissimo".

</doc>
<doc id="37721" url="https://en.wikipedia.org/wiki?curid=37721" title="Legato">
Legato

In music performance and notation, legato (Italian for "tied together"; French "lié"; German "gebunden") indicates that musical notes are played or sung smoothly and connected. That is, the player makes a transition from note to note with no intervening silence. Legato technique is required for slurred performance, but unlike slurring (as that term is interpreted for some instruments), legato does not forbid rearticulation. Standard notation indicates legato either with the word "legato," or by a slur (a curved line) under notes that form one legato group. Legato, like staccato, is a kind of articulation. There is an intermediate articulation called either mezzo staccato or non-legato (sometimes referred to as "portato").
Classical stringed instruments.
In music for classical stringed instruments, legato is an articulation that often refers to notes played with a full bow, and played with the shortest silence, often barely perceptible, between notes. The player achieves this through controlled wrist movements of the bowing hand, often masked or enhanced with vibrato. Such a legato style of playing can also be associated with portamento.
Guitar.
In guitar playing (apart from classical guitar) legato is used interchangeably as a label for both musical articulation and a particular application of technique—playing musical phrases with predominantly hammer-ons or pull-offs instead of picking. Legato "technique" to provide legato "articulation" on electric guitar generally requires playing notes that are close and on the same string, following the first note with others that are played by hammer-ons and pull-offs.
Some guitar virtuosos (notably Allan Holdsworth and Shawn Lane) developed their legato technique to the extent that they could perform extremely complex passages involving any permutation of notes on a string at extreme tempos, and particularly in the case of Holdsworth, tend to eschew pull-offs entirely for what some feel is a detrimental effect on guitar tone as the string is pulled slightly sideways.
The term "hammer-ons from nowhere" is commonly employed when crossing strings and relying solely on fretting hand strength to produce a note but on a plucked string.
Many guitar virtuosos are well-versed in the legato technique, as it allows for rapid and "clean" runs. Multiple hammer-ons and pull-offs together are sometimes also referred to colloquially as "rolls," a reference to the fluid sound of the technique. A rapid series of hammer-ons and pull-offs between a single pair of notes is called a trill. 
Legato on guitar is commonly associated with playing more notes within a beat than the stated timing, i.e., playing 5 (a quintuplet) or 7 (a septuplet) notes against a quarter-note instead of the usual even number or triplet. This gives the passage an unusual timing and when played slowly an unusual sound. However, this is less noticeable by ear when played fast, as legato usually is. There is a fine line between legato and two-hand finger tapping, in some cases making the two techniques harder to distinguish by ear. Generally, legato adds a more fluid, smooth sound to a passage.
Synthesizers.
In synthesizers legato is a type of monophonic operation. In contrast to the typical monophonic mode where every new note rearticulates the sound by restarting the envelope generators, in legato mode the envelopes are not re-triggered if the new note is played "legato" (with the previous note still depressed). This causes the initial transient from the attack and decay phases to sound only once for an entire legato sequence of notes. Envelopes reaching the sustain stage remain there until the final note is released.
Vocal music.
In classical singing, legato means a string of sustained vowels with minimal interruption from consonants. It is a key characteristic of the bel canto singing style that prevailed among voice teachers and singers during the 18th century and the first four decades of the 19th century. Usually referred to as "the line", a good, smooth legato is still necessary for successful classical singers. 
In Western Classical vocal music, singers generally use it on any phrase without explicit articulation marks. Usually the most prevalent issue with vocal legato is maintaining the "line" across registers.

</doc>
<doc id="37724" url="https://en.wikipedia.org/wiki?curid=37724" title="Largo">
Largo

Largo may refer to:

</doc>
<doc id="37725" url="https://en.wikipedia.org/wiki?curid=37725" title="Tuning">
Tuning

Tuning can refer to:

</doc>
<doc id="37726" url="https://en.wikipedia.org/wiki?curid=37726" title="Octave">
Octave

In music, an octave (: eighth) or perfect octave is the interval between one musical pitch and another with half or double its frequency. It is defined by ANSI as the unit of frequency level when the base of the logarithm is two. The octave relationship is a natural phenomenon that has been referred to as the "basic miracle of music", the use of which is "common in most musical systems".
The most important musical scales are typically written using eight notes, and the interval between the first and last notes is an octave. For example, the C Major scale is typically written C D E F G A B C, the initial and final Cs being an octave apart. Two notes separated by an octave have the same letter name and are of the same pitch class.
Three commonly cited examples of melodies featuring the perfect octave as their opening interval are "Singin' in the Rain", "Somewhere Over the Rainbow", and "Stranger on the Shore".
The interval between the first and second harmonics of the harmonic series is an octave.
The octave has occasionally been referred to as a diapason.
To emphasize that it is one of the perfect intervals (including unison, perfect fourth, and perfect fifth), the octave is designated P8. The octave above or below an indicated note is sometimes abbreviated 8a or 8va (= Italian "all'ottava"), 8va bassa (= Italian "all'ottava bassa", sometimes also 8vb), or simply 8 for the octave in the direction indicated by placing this mark above or below the staff.
Theory.
For example, if one note has a frequency of 440 Hz, the note an octave above it is at 880 Hz, and the note an octave below is at 220 Hz. The ratio of frequencies of two notes an octave apart is therefore 2:1. Further octaves of a note occur at 2"n" times the frequency of that note (where "n" is an integer), such as 2, 4, 8, 16, etc. and the reciprocal of that series. For example, 55 Hz and 440 Hz are one and two octaves away from 110 Hz because they are 0.5 (or 2 −1) and 4 (or 22) times the frequency, respectively.
After the unison, the octave is the simplest interval in music. The human ear tends to hear both notes as being essentially "the same", due to closely related harmonics. Notes separated by an octave "ring" together, adding a pleasing sound to music. For this reason, notes an octave apart are given the same note name in the Western system of music notation—the name of a note an octave above A is also A. This is called octave equivalency, the assumption that pitches one or more octaves apart are musically equivalent in many ways, leading to the convention "that scales are uniquely defined by specifying the intervals within an octave". The conceptualization of pitch as having two dimensions, pitch height (absolute frequency) and pitch class (relative position within the octave), inherently include octave circularity. Thus all Cs, or all 1s (if C = 0), in any octave are part of the same pitch class.
Octave equivalency is a part of most "advanced musical cultures", but is far from universal in "primitive" and early music.
The languages in which the oldest extant written documents on tuning are written, Sumerian and Akkadian, have no known word for "octave". However, it is believed that a set of cuneiform tablets that collectively describe the tuning of a nine-stringed instrument, believed to be a Babylonian lyre, describe tunings for seven of the strings, with indications to tune the remaining two strings an octave from two of the seven tuned strings.
Leon Crickmore recently proposed that "The octave may not have been thought of as a unit in its own right, but rather by analogy like the first day of a new seven-day week".
Monkeys experience octave equivalency, and its biological basis apparently is an octave mapping of neurons in the auditory thalamus of the mammalian brain. Studies have also shown the perception of octave equivalence in rats (Blackwell & Schlosberg, 1943), human infants (Demany & Armand, 1984), and musicians (Allen, 1967) but not starlings (Cynx, 1993), 4-9 year old children (Sergeant, 1983), or nonmusicians (Allen, 1967).
While octaves commonly refer to the perfect octave (P8), the interval of an octave in music theory encompasses chromatic alterations within the pitch class, meaning that G to G (13 semitones higher) is an Augmented octave (A8), and G to G (11 semitones higher) is a diminished octave (d8). The use of such intervals is rare, as there is frequently a preferable enharmonically equivalent notation available, but these categories of octaves must be acknowledged in any full understanding of the role and meaning of octaves more generally in music.
Notation.
Octaves are identified with various naming systems. Among the most common are the Scientific, Helmholtz, Organ Pipe, Midi, and Midi Note systems.
In writing, a specific octave is often indicated through the addition of a number after the note letter name. Thus middle C is "C4", because of the note's position as the fourth C key on a standard 88-key piano keyboard, while the C above is "C5", in a system known as scientific pitch notation.
The notation 8a or 8va is sometimes seen in sheet music, meaning "play this an octave higher than written" ("all' ottava": "at the octave" or "all' 8va"). "8a" or "8va" stands for "ottava", the Italian word for octave (or "eighth"); the octave above may be specified as "ottava alta" or "ottava sopra"). Sometimes "8va" is used to tell the musician to play a passage an octave "lower" (when placed under rather than over the staff), though the similar notation 8vb ("ottava bassa" or "ottava sotta") is also used. Similarly, 15ma ("quindicesima") means "play two octaves higher than written" and 15mb ("quindicesima bassa") means "play two octaves lower than written." The abbreviations col 8, coll' 8, and c. 8va stand for "coll'ottava", meaning "play the notes in the passage together with the notes in the notated octaves". Any of these directions can be cancelled with the word "loco", but often a dashed line or bracket indicates the extent of the music affected.
For music-theoretical purposes (not on sheet music), "octave" can be abbreviated as P8 (which is an abbreviation for Perfect Eighth, the interval between 12 semitones or an octave).
First octave.
In music theory, the first octave, also called the contra octave, ranges from C1, or about 32.7 Hz, to C2, about 65.4 Hz, in equal temperament using A440 tuning. This is the lowest complete octave of most pianos (excepting the Bösendorfer Imperial Grand). The lowest notes of instruments such as double bass, electric bass, extended-range bass clarinet, contrabass clarinet, bassoon, contrabassoon, tuba and sousaphone are part of the first octave.
The ability of vocalists to sing competently in the first octave is rare, even for males. A singer who can reach notes in this range is known as a basso profondo, Italian for "deep bass". A Russian bass can also sing in this range, and the fundamental pitches sung by Tibetan monks and the throat singers of Siberia and Mongolia are in this range.

</doc>
<doc id="37727" url="https://en.wikipedia.org/wiki?curid=37727" title="Willow Rosenberg">
Willow Rosenberg

Willow Rosenberg is a fictional character created for the fantasy television series "Buffy the Vampire Slayer" (1997–2003). She was developed by Joss Whedon and portrayed throughout the TV series by Alyson Hannigan.
Willow plays an integral role within the inner circle of friends—called the Scooby Gang—who support Buffy Summers, a teenager gifted with superhuman powers to defeat vampires, demons, and other evil in the fictional town of Sunnydale. The series begins as Buffy, Willow, and their friend Xander are in 10th grade and Willow is a shy, nerdy girl with little confidence. She has inherent magical abilities and begins to study witchcraft; as the series progresses, Willow becomes more sure of herself and her magical powers become significant if inconsistent. Her dependence on magic becomes so consuming that it develops into a dark force that takes her on a redemptive journey in a major story arc when she becomes the sixth season's main villain, threatening to destroy the world in a fit of grief and rage.
The "Buffy" series became extremely popular and earned a devoted fanbase; Willow's intelligence, shy nature, and vulnerability often resounded strongly with viewers in early seasons. Of the core characters, Willow changes the most, becoming a complex portrayal of a woman whose powers force her to seek balance between what is best for the people she loves and what she is capable of doing. Her character stood out as a positive portrayal of a Jewish woman and at the height of her popularity, she fell in love with another woman, a witch named Tara Maclay. They became one of the first lesbian couples on U.S. television and one of the most positive relationships of the series. Despite not being a titular character, Willow Rosenberg holds the distinction of having the second largest number of appearances on episodes of "Buffy" and the spin-off series "Angel". Alyson Hannigan appeared as Willow in all 144 episodes of "Buffy", as well as guest appearances in three episodes of the spinoff "Angel", for a total of 147 on screen appearances over the course of both series. She is also featured in an animated series and video game, both of which use Hannigan's voice, and the comics "Buffy the Vampire Slayer Season Eight" (2007–2011), "Buffy the Vampire Slayer Season Nine" (2011 - 2013), and "Buffy the Vampire Slayer Season Ten" (2014), which use Hannigan's likeness and continues Willow's storyline following the television series.
Character history.
Pilot and casting.
"Buffy the Vampire Slayer" (often simplified as "Buffy") was originally conceived by Joss Whedon for a 1992 feature film. However, in its development Whedon felt it lost some of the quirkiness he considered was the heart of the project, and it was not received as well as he liked. He began to develop for television the concept of a fashion-conscious girl named Buffy, who is imbued with superhuman abilities and attends a high school situated on a portal to hell. Whedon created a group of friends for the main character, including Willow Rosenberg and Xander Harris. A half-hour pilot was filmed starring Riff Regan as Willow, but it was eventually left unaired and network executives requested that Regan be replaced. Willow's character demanded that she be shy and unsure of herself, and the casting department encountered some difficulty finding actors who could portray this effectively and still be likable. After seven auditions, 23-year-old Alyson Hannigan was hired for the role. She was chosen for being able to spin the character's lines with a self-effacing optimism. She later stated in an interview, "I didn't want to do Willow as someone who's feeling sorry for herself. Especially in the first season, she couldn't talk to guys, and nobody liked her. I was like, 'I don't want to play somebody who's down on herself.'"
In the beginning of the series, Hannigan used her own experiences in high school—which she called "overwhelmingly depressing"—to guide her portrayal of Willow: "My theory on high school was, get in, get out and hopefully I won't get hurt. Basically it was a miserable experience, because you're a walking hormone in this place that is just so cruel. There were times that were OK, but it's not the little myth that high school is the best years of your life. No way." Whedon intended Willow to be realistically introverted, saying, "I wanted Willow to have that kind of insanely colorful interior life that truly shy people have. And Alyson has that. She definitely has a loopiness I found creeping into the way Willow talked, which was great. To an extent, all the actors conform to the way I write the character, but it really stands out in Willow's case."
Television series (1997–2003).
Seasons 1–3.
The "Buffy" television series first aired mid-season in March 1997, almost immediately earning positive critical reviews. Willow is presented as a bookish nerd with considerable computer skills, dowdily dressed and easily intimidated by more popular girls in school. She grows faint at the sight of monsters, but quickly forms a friendship with Buffy Summers (Sarah Michelle Gellar) and is revealed to have grown up as friends with Xander (Nicholas Brendon). They are mentored by the school librarian who is also Buffy's Watcher, Rupert Giles (Anthony Stewart Head), who often works closely with Willow in researching the various monsters the group encounters. Joss Whedon found that Hannigan was especially gifted reacting with fear (calling her the "king of pain") and viewers responded strongly when she was placed in danger, needing to be rescued by Buffy. Willow in various predicaments became common in early episodes. However, Willow establishes herself as integral to the group's effectiveness, often willing to break rules by hacking into highly secure computer systems.
In the second season when the characters are in 11th grade, Willow becomes more sure of herself, standing up to the conceited Cordelia Chase (Charisma Carpenter), and approaching Xander, on whom she has had a crush for years, although it is unrequited as Xander is in love with Buffy. Seth Green joined the cast during the second season as Oz, a high school senior who becomes a werewolf, and Willow's primary romantic interest. The show's popularity by early 1998 was evident to the cast members, and Hannigan remarked on her surprise specifically. Willow was noted to be the spirit of the Scooby Gang, and Hannigan attributed Willow's popularity with viewers (she had by May 1998 seven websites devoted to her) to being an underdog who develops confidence and is accepted by Buffy, a strong, popular person in school. Hannigan described her appeal: "Willow is the only reality-based character. She really is what a lot of high-schoolers are like, with that awkwardness and shyness, and all those adolescent feelings."
At the end of the second season, Willow begins to study magic following the murder of the computer teacher and spell caster Jenny Calendar (Robia LaMorte). Willow is able to perform a complicated spell to restore the soul of Angel, a vampire who is also Calendar's murderer and Buffy's boyfriend. During the third season three episodes explore Willow's backstory and foreshadow her development. In "Gingerbread", her home life is made clearer: Sunnydale falls under the spell of a demon who throws the town's adults into a moral panic, and Willow's mother is portrayed as a career-obsessed academic who is unable to communicate with her daughter, eventually trying to burn Willow at the stake for being involved in witchcraft; her father is never featured. In "The Wish" a vengeance demon named Anya (Emma Caulfield) grants Cordelia's wish that Buffy never came to Sunnydale, showing what would happen if it were overrun with vampires. In this alternate reality, Willow is an aggressively bisexual vampire. In a related episode, "Doppelgangland", Willow meets "Vamp Willow", who dresses provocatively and flirts with her.
Seasons 4–6.
Willow chooses to attend college with Buffy in Sunnydale although she is accepted to prestigious schools elsewhere. Her relationships with Buffy and Xander become strained as they try to find their place following high school. Willow becomes much more confident in college, finally finding a place that respects her intellect, while Buffy has difficulty in classes and Xander does not attend school. Willow's relationship with Oz continues until a female werewolf appears on the scene, aggressively pursuing him, and he leaves town to learn how to control the wolf within. She becomes depressed and explores magic more deeply, often with powerful but inconsistent results. She joins the campus Wicca group, meeting Tara Maclay, eventually falling in love with and choosing to be with her even when Oz returns to Sunnydale after apparently getting his lycanthropic tendencies under control.
Each season the Scoobies face a villain they call the Big Bad. In the fifth season, this is a goddess named Glory (Clare Kramer) that Buffy is unable to fight by herself.
The writers of the series often use elements of fantasy and horror as metaphors for real-life conflicts. The series' use of magic, as noted by religion professor Gregory Stevenson, neither promotes nor denigrates Wiccan ideals and Willow rejects Wiccan colleagues for not practicing the magic she favors. Throughout the series, magic is employed to represent different ideas -— relationships, sexuality, ostracism, power, and particularly for Willow, addiction -— that change between episodes and seasons. The ethical judgment of magic, therefore, lies in the results: performing magic to meet selfish needs or neglecting to appreciate its power often ends disastrously. Using it wisely for altruistic reasons is considered a positive act on the series.
Through witchcraft, Willow becomes the only member of the group to cause damage to Glory. She reveals that the spells she casts are physically demanding, giving her headaches and nosebleeds. When Glory assaults Tara, making her insane, Willow, in a magical rage that causes her eyes to turn black, finds Glory and battles her. She does not come from the battle unscathed and must be assisted by Buffy, but her power is evident and surprising to her friends. The final episode of the fifth season sees Willow restoring Tara's sanity and crucially weakening Glory in the process. It also features Buffy's death, sacrificing herself to save the world.
Willow and Tara move into the Summers house and raise Buffy's younger sister Dawn (Michelle Trachtenberg). Fearing that Buffy is in hell, Willow suggests at the beginning of the sixth season that she be raised from the dead. In a dark ceremony in which she expels a snake from her mouth, Willow performs the magic necessary to bring Buffy back. She is successful, but Buffy keeps it secret that she believes she was in heaven.
Willow's powers grow stronger; she uses telepathy which her friends find intrusive, and she begins to cast spells to manipulate Tara. After Willow fails Tara's challenge to go for one week without performing magic, Tara leaves her, and for two episodes Willow descends into addiction that almost gets Dawn killed. Willow goes for months without any magic, helping Buffy track three geeks called The Trio who grandiosely aspire to be supervillains.
Immediately following Willow's reconciliation with Tara, Warren (Adam Busch), one of the Trio, shoots Buffy; a stray shot kills Tara right in front of Willow. In an explosion of rage and grief, Willow soaks up all the dark magic she can, which turns her hair and eyes black. In the final episodes of the season Willow becomes exceedingly strong, surviving unharmed when Warren hits her in the back with an axe. She hunts Warren, tortures him by slowly pushing a bullet into his body, then kills him by magically flaying him. Unsatisfied, she attempts to kill the other two members of the Trio but is unsuccessful due to her weakening power. She solves this problem by killing her 'dealer' from earlier in the season and draining him of his magic. When she is confronted by Buffy they begin to fight, only to be stopped by Giles who has borrowed magic from a coven of wiccans. Willow successfully drains him of this borrowed magic, fulfilling his plan and causing her to feel all the pain of everyone in the world. She tries to ease the pain by destroying the world, finally to be stopped by Xander.
Season 7.
The seventh season starts with Willow in England, unnerved by her power, studying with a coven near Giles' home to harness it. She fears returning to Sunnydale and what she is capable of doing if she loses control again, a fear that dogs her the whole season.
Buffy and the Scoobies face the First Evil, bent on ending the Slayer line and destroying the world. Potential Slayers from around the globe congregate at Buffy's home and she trains them to battle the First Evil. Willow continues to face her grief over Tara's death and, reluctantly, becomes involved with one of the Potentials, Kennedy (Iyari Limon).
In the final episode of the series, "Chosen", Buffy calls upon Willow to perform the most powerful spell she has ever attempted. With Kennedy nearby, cautioned to kill her if she becomes out of control, Willow infuses every Potential Slayer in the world with the same powers Buffy and Faith have. The spell momentarily turns her hair white and makes her shine—Kennedy calls her "a goddess"—and it ensures that Buffy and the Potentials defeat the First Evil. Willow is able to escape with Buffy, Xander, Giles, and Kennedy as Sunnydale is destroyed.
Through the gamut of changes Willow endures in the series, "Buffy" studies scholar Ian Shuttleworth states that Alyson Hannigan's performances are the reason for Willow's popularity: "Hannigan can play on audience heartstrings like a concert harpist... As an actress she is a perfect interpreter in particular of the bare emotional directness which is the specialty of writer Marti Noxon on form."
Comic series (since 2007).
Subsequent to "Buffy"s television finale, Dark Horse Comics collaborated with Joss Whedon to produce a canonical comic book continuation of the series, "Buffy the Vampire Slayer Season Eight" (2007–11), written by Whedon and many other writers from the television series. Unfettered by the practical limitations of casting or a television special effects budget, "Season Eight" explores more fantastic storylines, characters, and abilities for Willow. Willow's cover art is done by Jo Chen, and Georges Jeanty and Karl Moline produce character artwork and provide alternative covers. It was followed by two closely interlinked sequels, "Buffy the Vampire Slayer Season Nine" and "Angel & Faith" (both 2012–). Willow features at different times in both series, as well as in her own spin-off miniseries. Jeanty continues to provide Willow's likeness in "Season Nine", while Rebekah Isaacs and Brian Ching are the primary pencillers of "Angel & Faith" and "Willow: Wonderland" respectively. While "Season Nine" and "Angel & Faith" are substantially less fantastical in tone than "Season Eight", Willow's spin-off is high fantasy and focuses on her journey through magical alternate worlds.
Willow appears to Buffy and Xander, who are in charge of thousands of Slayers, a year after the destruction of Sunnydale. Willow reveals a host of new abilities including being able to fly and absorbing others' magic to deconstruct it. The Big Bad of "Season Eight" is a being named Twilight who is bent on destroying magic in the world. A one-shot comic dedicated to Willow's story was released in 2009 titled "Willow: Goddesses and Monsters". It explores the time she took away to discover more about her magical powers, under the tutelage a half-woman half-snake demon named Aluwyn. Willow is still involved with Kennedy through "Season Eight", but becomes intimate with Aluwyn while they are together. She also continues to deal with grief from Tara's death, and struggles with the dark forces of magic that put her in opposition to Buffy. At the conclusion of the season, Buffy destroys an object, a seed, that is the source of the magic in the world, leaving Willow powerless. Whedon divulged that recovering her magical abilities will become Willow's "personal obsession" in a miniseries where she will be the central character.
Identities.
From the inception of Willow's character in the first season, she is presented with contradictions. Bookish, rational, naive, and sometimes absent-minded, she is also shown being open to magic, aggressively boyish, and intensely focused. Willow is malleable, in continuous transition more so than any other "Buffy" character. She is, however, consistently labeled as dependable and reliable by the other characters and thus to the audience, making her appear to be stable. She is unsure of who she is; despite all the tasks she takes on and excels at, for much of the series she has no identity. This is specifically exhibited in the fourth season finale "Restless", an enigmatic pastiche of characters' dream sequences. In Willow's dream, she moves from an intimate moment painting a love poem by Sappho on Tara's bare back, to attending the first day of drama class to learn that she is to be in a play performed immediately for which she does not know the lines or understand. The dream presents poignant anxieties about how she appears to others, not belonging, and the consequences of people finding out her true self. As Willow gives a book report in front of her high school class, she discovers herself wearing the same mousy outfit she wore in the first episode of the show ("Welcome to the Hellmouth") as her friends and classmates shout derisively at her, and Oz and Tara whisper intimately to each other in the audience. She is attacked and strangled by the First Slayer as the class ignores her cries for help.
Long a level-headed character who sacrifices her own desires for those of her friends, she gradually abandons these priorities to be more independent and please herself. She is often shown making choices that allow her to acquire power or knowledge and avoid emotional conflict. The story arc of Willow's growing dependence on magic was noted by Marti Noxon as the representation of "adult crossroads" and Willow's inability and unwillingness to be accountable for her own life. Willow enjoys power she is unable to control. She steals to accomplish her vocational goals and rationalizes her amoral behavior. This also manifests itself in a competitive streak and she accuses others who share their concerns that she uses magic for selfish purposes of being jealous. No longer the conscience of the Scooby Gang, Willow cedes this role to Tara then revels in breaking more rules. After Tara leaves Willow, Willow divulges to Buffy that she does not know who she is and doubts her worth and appeal—specifically to Tara—without magic. Contradicting the characterization of Willow's issues with magic as addiction, "Buffy" essayist Jacqueline Lichtenberg writes "Willow is not addicted to magic. Willow is addicted to the surging hope that this deed or the next or the next will finally assuage her inner pain."
Vamp Willow.
Vamp Willow appears in the third season episodes "The Wish" and "Doppelgangland". She is and aggressive, the opposite of Willow's usual nature; her bad behavior so exaggerated that it does not instill fear into the viewer like other female vampires in the series, but indicates more about Willow's personality. Shocked upon seeing her alter ego in "Doppelgangland", Willow states "That's me as a vampire? I'm so evil and . And I think I'm kinda gay!" Angel is stopped by Buffy in telling the Scoobies that the vampire self carries many of the same attributes as the human self, at which Willow says that is nothing like her. Many Buffy fans saw this as a funny Easter egg when Willow revealed herself to actually be a lesbian in later seasons. As surprised as Willow is with Vamp Willow, she feels bound to her, and does not have the heart to allow Buffy to kill her. Both Willows make the observation that "this world's no fun", before they send Vamp Willow back into the alternate dimension from which she came, whereupon she is staked and dies immediately.
Dark Willow.
A shadow of Dark Willow appears to fight Glory in the fifth season episode "Tough Love", but she does not come into full force until the sixth season in "Villains", "Two to Go", and "Grave". The transition from Willow into Dark Willow, precipitated by Tara's immediate death when she is shot through the heart, was ambiguously received by audiences, many of whom never foresaw Willow's psychic break. It was simultaneously lauded for being an overwhelming depiction of a powerful woman, and derided as representative of a worn cliché that lesbians are amoral and murderous. Dark Willow proved to be exceptionally more powerful than Buffy. She changes visually when she walks into the Magic Box, a store owned by Anya and Giles, telekinetically retrieves dozens of dark magic books from the shelves, and leeches the words from the pages with her fingertips. As the words crawl up her arms and soak into her skin, her eyes and hair become black and her posture "aggressively aware and confident".
Susan Driver writes that it is "crucial to recognize that never before in a teen series has raw fury been so vividly explored through a young queer girl responding to the sudden death of her lover". Dark Willow is preternaturally focused on revenge, relentless and unstoppable. Lights explode when she walks past. She forcefully takes advantage of any opportunity to further her goals. She saves Buffy by removing the bullet from her chest, but later commandeers a tractor trailer, making it slam into Xander's car while he and Buffy are inside protecting Jonathan and Andrew, the other two members of the Trio. She floats, flies, teleports and dismantles the local jail where Jonathan and Andrew are held.
She is cruelly honest to Dawn and Buffy, and overpowers everyone with whom she comes in contact. When she takes Giles' magic from him, she gains the ability to feel the world's pain, becoming determined to put the world out of its misery. She does not acknowledge her grief, and only Xander can force her to face it when he tells her that he loves her no matter what or who she is, and if she is determined to end the world she must start by killing him. Only then does Willow return, sobbing.
At Salon.com, Stephanie Zacharek writes that Dark Willow is "far from being a cut-out angry lesbian, is more fleshed out, and more terrifyingly alive, than she has ever been before. More than any other character, she has driven the momentum of the past few episodes; she very nearly drove it off a cliff." Several writers state that Willow's transition into Dark Willow is inevitable, grounded in Willow's self-hatred that had been festering from the first season. Both Dark Willow and even Willow herself state that Willow's sacrifices for her friends and lack of assertiveness are her undoing. In "Doppelgangland", Willow (posing as Vampire Willow) says "It's pathetic. She lets everyone walk all over her and gets cranky at her friends for no reason." In "Two to Go", Dark Willow remarks "Let me tell you something about Willow. She's a loser. And she always has been. People picked on Willow... and now Willow's a junkie." Vamp Willow served as an indicator of what Willow is capable of; immediately before she flays Warren in one violent magical flash, she uses the same line Vamp Willow used in the third season: "Bored now."
Following the sixth season, Willow struggles to allow herself to perform magic without the darkness within her taking her over. She is no longer able to abstain from magic as it is such an integral part of her that doing so will kill her. In the instances when she is highly emotional the darkness comes out. Willow must control that part of her and is occasionally unable to do so, giving her a trait similar to Angel, a cursed vampire who fears losing his soul will turn him evil. In a redemptive turn, when Willow turns all the Potentials into Slayers, she glows and her hair turns white, astonishing Kennedy and prompting her to call Willow a goddess.
Relationships.
Willow's earliest and most consistent relationships are with Buffy and Xander, both of whom she refers to as her best friends although they have their conflicts, and Giles as a father figure. Willow takes on the leadership role when Buffy is unavailable, and her growing powers sometimes make her resent being positioned as Buffy's sidekick. Some scholars see Willow as Buffy's sister-figure or the anti-Buffy, similar to Faith, another Slayer whose morals are less strict. In early seasons, Willow's unrequited crush on Xander creates some storylines involving the relationships between Xander, Cordelia, and Oz. Willow is part of a powerful quartet: she represents the spirit, Giles intelligence, Xander heart, and Buffy strength of the Scoobies. Although they often drift apart, they are forced to come together and work in these roles to defeat forces they are unable to fight individually.
Oz.
Willow meets stoic Oz in the second season. Their courtship is slow and patient. Oz is bitten by a werewolf, and just as Willow begins to confront him about why he does not spend time with her, he transforms and attacks her. She must shoot him with a tranquilizer gun several times while he is wild, but her assertiveness in doing so makes her more confident in their relationship. Oz's trials in dealing with a power he cannot control is, according to authors J. Michael Richardson and J. Douglas Rabb, a model for Willow to reference when she encounters her own attraction to evil. When Willow and Oz decide to commit to each other, Willow is enthusiastic that she has a boyfriend, and, as a guitarist in a band, one so cool. Her relationship with Oz endures the high school storylines of exploring her attraction to Xander, which briefly separates them. She worries that she is not as close to Oz as she could be. They stay together through graduation into college, but Oz is drawn to Veruca, another werewolf. He admits an animal attraction to Veruca, which he does not share with Willow. He sleeps with Veruca and leaves shortly after to explore the werewolf part of himself. Willow becomes very depressed and doubts herself. She drinks, her magical abilities are compromised, her spells come out wrong, and she lashes out at her friends when they suggest she get over it ("Something Blue").
Joss Whedon did not intend to write Oz out of the series. Seth Green came to Whedon early in the fourth season to announce that he wished to work on his film career. Whedon admitted he was upset by Green's announcement and that if he had wanted to continue, Oz would have been a part of the story. However, to resolve the relationship between Oz and Willow Whedon says, "we had to scramble. And out of the heavens came Amber Benson."
Tara Maclay.
"Buffy" earned international attention for its unflinching focus on the relationship between Willow and Tara Maclay. Whedon and the writing staff had been considering developing a story arc in which a character explores his or her sexuality as the Scoobies left high school, but no particular effort was made to assign this arc to Willow. In 1999, at the end of the third season, the "Boston Herald" called "Buffy" "the most gay show on network TV this year" despite having no overtly gay characters among the core cast. It simply presented storylines that resembled coming out stories. In the fourth season episode "Hush", Willow meets Tara, and to avoid being killed by a group of ghouls, they join hands to move a large vending machine telekinetically to barricade a door. The scene was, upon completion, noticeably sensual to Whedon, the producers, and network executives, who encouraged Whedon to develop a romantic storyline between Willow and Tara, but at the same time placed barriers on how far it could go and what could be shown. Two episodes later, Hannigan and Amber Benson were informed that their characters would become romantically involved. The actors were not told the end result of the Willow–Oz–Tara storyline, not sure what the eventual trajectory of the relationship would be, until Hannigan said, "Then finally it was, 'Great! It's official. We're in luurrvvve.'"
Whedon made a conscious effort to focus on Willow and Tara's relationship instead of either's identity as a lesbian or the coming out process. When Willow discloses to Buffy what she feels for Tara, she indicates that she has fallen in love with Tara, not that she is a lesbian, and avoids categorizing herself. Some critics regard this as a failure on Willow's part to be strong; Em McAvan interprets this to mean that Willow may be bisexual. Scholar Farah Mendlesohn asserts that Willow's realization that she is in love with Tara allows viewers to re-interpret Willow's relationship with Buffy; in the first three seasons, Willow is often disappointed that she is not a higher priority to Buffy, and even after Willow enters a relationship with Tara, still desires to feel integral to Buffy's cause and the Scooby Gang.
Willow's progression has been noted to be unique in television. Her relationship with Tara coincides with the development of her magical abilities becoming much more profound. By the seventh season, she is the most powerful person in Buffy's circle. Jessica Ford at PopMatters asserts that Willow's sexuality and her magical abilities are connected and represented by her relationships. In her unrequited attraction to Xander, she has no power. With Oz, she has some that gives her the confidence she sorely lacks, but his departure leaves her unsure of herself. Only when she meets Tara do her magical abilities flourish; to Ford, sexuality and magic are both empowering agents in Willow's story arc. David Bianculli in the "New York Daily News" writes that Willow's progression is "unlike anything else I can recall on regular prime-time television: a character evolving naturally over four seasons of stories and arriving at a place of sexual rediscovery".
Not all viewers considered Willow and Tara's relationship a positive development. Some fans loyal to Willow reacted angrily as she chose to be with Tara when Oz made himself available, and they lashed out at Tara and Amber Benson on the fansite message boards. Whedon replied sardonically, "we're going to shift away from this whole lifestyle choice that Willow has made. Just wipe the slate. From now on, Willow will no longer be a Jew. And I think we can all breathe easier." However, he seriously explained his motivation, writing "My show is about emotion. Love is the most powerful, messy, delightful and dangerous emotion... Willow's in love. I think it's cool." Hannigan was also positive about the way the character and her relationship with Tara was written: "It is not about being controversial or making a statement. I think the show is handling it really nicely. It's about two people who care about each other."
Contrasting with some of the more sexual relationships of the other characters, Willow and Tara demonstrate a sentimental, soft, and consistent affection for each other. Some of this was pragmatic: the show was restricted in what it could present to viewers. Willow and Tara did not kiss until the fifth season in an episode that diverted the focus away from the display of affection when Buffy's mother dies in "The Body". Before this, much of their sexuality is represented by allusions to witchcraft; spells doubled for physical affection such as an erotic ritual in "Who Are You?" where Willow and Tara chant and perspire in a circle of light until Willow falls back on a pillow gasping and moaning. Within the "Buffy" universe, magic is portrayed in a mostly female realm. As opposed to it being evil, it is an earth-bound force that is most proficiently harvested by women. The treatment of the lesbian relationship as integral to magic, representative of each other (love is magic, magic is love), earned the series some critical commentary from conservative Christians. To avoid large-scale criticism, scenes had to be shot several different ways because censors would not allow some types of action on screen. In the fourth and fifth seasons, the characters could be shown on a bed, but not under the covers. Hannigan noted the inconsistent standards with the other relationships on the show: "you've got Spike and Harmony just going at it like rabbits, so it's very hypocritical". As a couple, Willow and Tara are treated by the rest of the Scoobies with acceptance and little fanfare. Susan Driver writes that younger viewers especially appreciate that Willow and Tara are able to be affectionate without becoming overly sexual, thus making them objects of fantasy for male enjoyment. Willow and Tara's influence on specifically younger female viewers is, according to Driver, "remarkable".
Academics, however, comment that Willow is a less sexual character than the others in the show. She is displayed as "cuddly" in earlier seasons, often dressing in pink fuzzy sweaters resulting in an innocent tomboyishness. She becomes more feminine in her relationship with Tara, who is already feminine; no issues with gender are present in their union. Their relationship is sanitized and unthreatening to male viewers. When the series moved broadcast networks from the WB to UPN in 2001, some of the restrictions were relaxed. Willow and Tara are shown in some scenes to be "intensely sexual", such as in the sixth season episode "Once More, with Feeling" where it is visually implied that Willow performs cunnilingus on Tara. When Willow and Tara reconcile, they spend part of the episode in "Seeing Red" unclothed in bed, covered by red sheets.
Willow is more demonstrative in the beginning of her relationship with Tara. Where in her relationship with Oz she described herself as belonging to him, Tara states that she belongs to Willow. Willow finds in Tara a place where she can be the focus of Tara's attention, not having to appease or sacrifice as she has in the past. Tara, however, eclipses Willow's role as the moral center of the Scoobies, and as Willow becomes more powerful and less ethical, Tara becomes a maternal figure for the group. Willow acts as a sort of middle child between Xander's immaturity and Buffy's weighty responsibilities. She becomes completely devoted to and enamored of Tara, and then manipulates her to avoid conflict when Tara does not conform to what she wants. Displeased with how Willow abuses her power, especially toward herself, Tara leaves Willow while continuing to counsel Dawn and Buffy. Long after Tara's death, Willow faces the choices she made: in the "Season Eight" episode "Anywhere But Here", Willow tells Buffy that she is responsible for Tara's death. Her ambition to bring back Buffy from the dead inevitably led to Tara getting shot and killed. In the one-shot comic, Willow is offered Tara as a guide for her mystical path to understanding her own powers, but rejects her as being an illusion, too much of a comfort, and not a guide who will force her to grow. She begins a relationship with Kennedy.
Kennedy.
Following protests angry about the death of Tara, Whedon and the writing team made a decision to keep Willow gay. In 2002, he told "The Advocate" about the possibility of Willow having a relationship with a man, "We do that now, and we will be burned alive. And possibly justifiably. We can't have Willow say, 'Oh, cured now, I can go back to cock!' Willow is not going to be straddling that particular fence. She will just be gay." Kennedy is markedly different from Tara. She is younger, outspoken, and aggressively pursues Willow, who hesitates to become involved again. When they first kiss in the episode "The Killer in Me", Willow's realization that she let Tara go reacts with a curse put upon her by another witch named Amy Madison (Elizabeth Anne Allen), turning Willow into Warren, Tara's murderer. The spell is broken when Willow acknowledges her guilt and Kennedy kisses her again. Kennedy expresses that she does not understand the value of magic and assumes it involves tricks, not the all-consuming energy that Willow is capable of. When Willow eventually exhibits what power she has, it briefly frightens Kennedy. Willow worries about becoming sexually intimate with Kennedy, unsure of what may transpire if she loses control of herself.
In season 7 episode 20, "Touched", in which practically all the main cast has sex (two by two) Willow and Kennedy take part in the first lesbian sex scene on primetime television.
In "Season Eight", Kennedy and Willow are still romantically involved, but separated during Willow's self-exploration. Unlike her relationship with Tara, Willow is able to hold a separate identity while with Kennedy. When she realizes her powers have gone at the end of "Season Eight", however, Willow ends her relationship with Kennedy, saying that there is someone else Willow is in love with, who she will never see again.
Kennedy's role split many Buffy fans into two groups. Many viewers hated Kennedy, because they saw her as a way of saying; "Tara's dead, let's move on." and they weren't ready to. After the emotional death of Tara and Willow's reaction (nearly ending all life on Earth) many fans thought that it was ridiculous for Willow to recover and move on so quickly. Kennedy overall, has received much hate, but there is the other side who say that she was exactly what Willow needed to recover and continue a happy life.
Cultural impact.
Willow's religion and sexuality have made her a role model for audiences. Whedon, however, has compared her Jewish identity to her sexuality, stating that they are rarely made a significant focus of the show. Willow at times reminds the other characters of her religion, wondering what her father might think of the crucifixes she must apply to her bedroom wall to keep out vampires, and commenting that Santa Claus misses her house every Christmas because of the "big honkin' menorah". "Buffy" essayist Matthew Pateman criticizes the show for presenting Willow's Jewish identity only when it opposes Christian declarations of holidays and other traditions. "The New York Times", however, named her as a positive example of a depiction of a Jewish woman, who stood out among portrayals of Jews as harsh, unfeminine, and shallow. Producer Gail Berman states that as a Jew, Willow "handles herself just fine, thank you".
In "Queer Girls and Popular Culture", Susan Driver states that television ascribes to viewers what lesbians look and act like, and that realistic portrayals of girls outside the norm of white, upper or middle class, and heterosexual are extremely rare. Realistic depictions of lesbians are so rare that they become strong role models and enable "hope and imagination" for girls limited by the conditions of their immediate surroundings, who may know of no other gay people. The time and space given to Willow to go from being a shy scared girl into a confident woman who falls in love with another woman is, as of 2007, unique in television; it does not occur in one flash or single moment. It is a progression that defies strict definition. Manda Scott in "The Herald" states that Willow's lack of panic or self-doubt when she realizes she is in love with Tara makes her "the best role model a teen could ask for".
When viewers realized that Willow was falling in love with Tara, Whedon remembered that some threatened to boycott the show, complaining "You made Willow a fag", to which he responded, "Bye. We'll miss you "a whole lot."" However, he also said, "For every (negative) post, there's somebody saying, 'You made my life a lot easier because I now have someone I can relate to on screen'." Gay characters had been portrayed before on television, and at the time the popular sitcom "Will & Grace" was on the air. Lesbian-themed HBO special "If These Walls Could Talk 2" won an Emmy. Twenty-three television shows depicted a gay character of some kind in 2000. However, these other characters were mostly desexualized, none were partnered or shown consistently affectionate towards the same person. Willow and Tara's relationship became the first long-term lesbian relationship on U.S. television. "Jane" magazine hailed Willow and Tara as a bold representation of gay relationship, remarking that "they hold hands, slow-dance and lay in bed at night. You won't find that kind of normalcy on "Will and Grace"." Despite Whedon's intentions of not making "Buffy" about overcoming issues, he said Willow's exploration of her sexuality "turned out to be one of the most important things we've done on the show".
Although the show's writers and producers received a minimal negative reaction from Willow choosing Tara over Oz, the response from viewers and critics alike was overwhelming towards Whedon for killing Tara, accusing him of homophobia. Particularly because Tara's death came at a point where Willow and Tara had reconciled and were shown following an apparent sexual encounter, the writers were criticized for representing the consequences of lesbian sex as punishable by death. Series writer and producer Marti Noxon—whose mother fell in love with another woman when Noxon was 13 years old—was unable to read some of the mail the writing team received because it was so upsetting. To her, the pain expressed in viewers' letters was a logical reaction to the lack of realistic lesbian role models on television.
Willow's cultural impact has been noted in several other ways. Patrick Krug, a biologist at California State University, Los Angeles named a sea slug with traits of sexual flexibility "Alderia willowi" partly for his grandmother and partly after Willow's character. Willow was included in AfterEllen.com's Top 50 Lesbian and Bisexual Characters, ranking at No. 7. She was also ranked No. 12 in their Top 50 Favorite Female TV Characters. UGO.com named her one of the best TV nerds. AOL also listed her as the #1 TV witch of all time, and one of the 100 Most Memorable Female TV Characters.

</doc>
<doc id="37729" url="https://en.wikipedia.org/wiki?curid=37729" title="Snowdonia">
Snowdonia

Snowdonia () is a region in north Wales and a national park of in area. It was the first to be designated of the three national parks in Wales, in 1951.
Name and extent.
The English name for the area derives from Snowdon, which is the highest mountain in Wales at 3,560 ft (1,085 m). In Welsh, the area is named "Eryri". A commonly held belief is that the name is derived from "eryr" ("eagle"), and thus means 'the abode/land of eagles', but recent evidence is that it means quite simply "Highlands", and is derived from the Latin oriri (to rise) as leading Welsh scholar Sir Ifor Williams proved. In the Middle Ages the title "Prince of Wales and Lord of Snowdonia" ("Tywysog Cymru ac Arglwydd Eryri") was used by Llywelyn ap Gruffudd; his grandfather Llywelyn Fawr used the title "Prince of north Wales and Lord of Snowdonia.
Before the boundaries of the national park were designated, "Snowdonia" was generally used to refer to a smaller area, namely the upland area of northern Gwynedd centred on the Snowdon massif, whereas the national park covers an area more than twice that size extending far to the south into Meirionnydd. This is apparent in books published prior to 1951, such as the classic travelogue "Wild Wales" by George Borrow (1862) and "The Mountains of Snowdonia" by H. Carr & G. Lister (1925). F. J. North, as editor of the book "Snowdonia" (1949), states "When the Committee delineated provisional boundaries, they included areas some distance beyond Snowdonia proper." The traditional Snowdonia thus includes the ranges of Snowdon and its satellites, the Glyderau, the Carneddau and the Moel Siabod group. It does not include the hills to the south of Maentwrog. As "Eryri" (see above), this area has a unique place in Welsh history, tradition and culture.
Snowdonia National Park.
Snowdonia National Park () was established in 1951 as the third national park in Britain, following the Peak District and the Lake District. It covers , and has of coastline.
The park is governed by the Snowdonia National Park Authority, which is made up of local government and Welsh representatives, and its main offices are at Penrhyndeudraeth. Unlike national parks in other countries, Snowdonia (and other such parks in Britain) are made up of both public and private lands under central planning authority. The makeup of land ownership at Snowdonia is as follows:
More than 26,000 people live within the park, of whom about 62% can speak at least some Welsh. The park attracts over 6 million visitors annually, split almost equally between day and staying visitors, making it the third most visited national park in England and Wales.
Whilst most of the land is either open or mountainous land, there is a significant amount of agricultural activity within the park.
Since the local government re-organisation of 1998, the park lies partly in the county of Gwynedd, and partly in the county borough of Conwy. It is governed by the 18-member Snowdonia National Park Authority; 9 members are appointed by Gwynedd, 3 by Conwy, and the remaining 6 by the National Assembly for Wales to represent the national interest.
Unusually, Snowdonia National Park has a hole in the middle, around the town of Blaenau Ffestiniog, a slate quarrying centre. This was deliberately excluded from the park when it was set up to allow the development of new light industry to replace the decimated slate industry. (There is a similar situation in the Peak District National Park where the boundaries were drawn to exclude large built-up areas and industrial sites from the park with the town of Buxton and the adjacent quarries outside but surrounded on three sides by the park.)
The Snowdonia Society is a registered charity formed in 1967. It is a voluntary group of people with an interest in the area and its protection. Amory Lovins led the successful 1970s opposition to stop Rio Tinto digging up the area for a massive mine.
Mountain ranges.
Snowdonia may be divided into four areas:
Mountain walking.
Many of the hikers in the area concentrate on Snowdon itself. It is regarded as a fine mountain, but can become quite crowded, particularly with the Snowdon Mountain Railway running to the summit.
The other high mountains with their boulder-strewn summits—as well as Tryfan, one of the few mountains in the UK south of Scotland whose ascent needs hands as well as feet—are also very popular. However, there are also some spectacular walks in Snowdonia on the lower mountains, and they tend to be relatively unfrequented. Among hikers' favourites are Y Garn (east of Llanberis) along the ridge to Elidir Fawr; Mynydd Tal-y-Mignedd (west of Snowdon) along the Nantlle Ridge to Mynydd Drws-y-Coed; Moelwyn Mawr (west of Blaenau Ffestiniog); and Pen Llithrig y Wrach north of Capel Curig. Further south are Y Llethr in the Rhinogydd, and Cadair Idris near Dolgellau.
The park has of public footpaths, of public bridleways, and of other public rights of way. A large part of the park is also covered by Right to Roam laws.
Nature, landscape and the environment.
The park's entire coastline is a Special Area of Conservation, which runs from the Llŷn Peninsula down the mid-Wales coast, the latter containing valuable sand dune systems.
The park's natural forests are of the mixed deciduous type, the commonest tree being the Welsh oak. Birch, ash, mountain-ash and hazel are also common. The park also contains some large (planted) coniferous forested areas such as Gwydir Forest near Betws-y-Coed, although some areas, once harvested, are now increasingly being allowed to regrow naturally.
Northern Snowdonia is the only place in Britain where the Snowdon lily, an arctic–alpine plant, and the rainbow-coloured Snowdon beetle ("Chrysolina cerealis") are found, and the only place in the world where the Snowdonia hawkweed "Hieracium snowdoniense" grows.
A large proportion of the park is today under designation (or under consideration for designation) as Sites of Special Scientific Interest, national nature reserves, Special Areas of Conservation, Special Protection Areas, Biosphere and Ramsar sites.
One of the major problems facing the park in recent years has been the growth of "Rhododendron ponticum". This fast-growing invasive species has a tendency to take over and stifle native species. It can form massive towering growths and has a companion fungus that grows on its roots producing toxins that are poisonous to any local flora and fauna for a seven-year period after the "Rhododendron" infestations have been eradicated. As a result, there are a number of desolate landscapes.
Wildlife.
Snowdonia's importance in the conservation of habitat and wildlife in the region reflects in the fact that nearly 20% of its total area is protected by UK and European law. Half of that area was set aside by the government under the European Habitats Directive as a Special Area of Conservation. Rare mammals in the park include otters, polecats, and the feral goat, although the pine marten has not been seen for many years. Rare birds include raven, peregrine, osprey, merlin and the red kite. Another of Snowdonia's famous inhabitants is the Snowdon or rainbow beetle. The park has three RAMSAR Sites: the Dyfi Estuary Biosphere Reserve, Cwm Idwal and Llyn Tegid.
Climate.
Snowdonia is one of the wettest parts of the United Kingdom; Crib Goch in Snowdonia is the wettest spot in the United Kingdom, with an average rainfall of a year over the past 30 years.

</doc>
<doc id="37731" url="https://en.wikipedia.org/wiki?curid=37731" title="Jeff Minter">
Jeff Minter

Jeff 'Yak' Minter (born in Reading, UK, 22 April 1962) is an independent British video game designer and programmer. He is the founder of software house Llamasoft and has created dozens of games during his career. Minter's games are often arcade style shoot 'em ups. They often contain titular or in-game references demonstrating his fondness of ruminants (llamas, sheep, camels, etc.). Many of his programs also feature something of a psychedelic element, as in some of the earliest "light synthesizer" programs including his "Trip-a-Tron".
Minter's works include "Neon" (2004), a music visualisation program built into the Xbox 360 console, and the video games "Gridrunner", "Tempest 2000", "Space Giraffe" (Xbox Live Arcade, 2007 and PC, 2008), and "GoatUp" (iOS 2011).
Game development career.
Pre-commercial career (early years).
Minter had expressed an interest in programming computers from a young age. He wrote the game Deflex for the Commodore PET in 1979. However it would not be until a long illness during secondary school that Minter's talents would develop in any meaningful way. Following a 3-month stint in which Minter was restricted to lying on his back and was confined to his bed between November 1981 and January 1982, boredom led him to take up computer programming in earnest to pass the time.
Upon recovery, Minter teamed up with Richard Jones, a fellow pupil, and together they started writing their own games on their school's Commodore PET. They soon parted ways. Jones went on to commercial projects, some of them in the software market (e.g., "Interceptor Micros").
Commercial 8-bit games.
In 1981 Minter started independently writing and selling video games for the Sinclair ZX80, the first machine he owned. Some were made for software company dk'tronics. These titles were sold as a package but this was not available for very long, as Minter left the company following a royalties dispute. He formed a partnership with his mother, Hazel Minter. Together they developed and commercially produced 20 games for the Sinclair ZX81, Commodore VIC-20, Atari 8-bit computers, ZX Spectrum and Commodore 64. Having been studying physics at the University of East Anglia, success in the programming industry prompted him to drop his studies and take up video game development full-time.
The following year, he founded the software house Llamasoft. His first Llamasoft game was a "Defender" clone for the Commodore VIC-20 called "Andes Attack" (US version: "Aggressor"). In "Andes Attack", little llamas advanced upon and attacked the player instead of the spaceships from "Defender". As a fan of "Defender", Minter would remake it again as "Defender 2000". Through the Brighton based software house, 'Salamander Software', Minter had his games written for the Spectrum and other home microcomputers. It was Mr S.A. Tenquist who was responsible for the Sinclair ZX Spectrum 16K version of "Gridrunner". The conversion was released and published for Xmas 1983 by Quicksilva Ltd., UK. Jeff Minter's original Commodore version was written in a week and marked his first commercial success both in the UK and in the US.
Minter went on to develop a number of classic games, all written in assembly language, for the later home computers (such as the Commodore 64, Atari 400/800 and Atari ST) which were marketed mainly by word of mouth and by the occasional magazine advertisement. These games included: "Gridrunner", "Abductor", "Matrix: Gridrunner 2", "Hellgate", "Hover Bovver", "Attack of the Mutant Camels", "Revenge of the Mutant Camels", "Return of the Mutant Camels", "Laser Zone", "Mama Llama", "Metagalactic Llamas Battle at the Edge of Time", "Sheep in Space", "Voidrunner", and "Iridis Alpha".
Post 8-bit work.
In 1989, Minter helped in the production of the Konix Multisystem console.
Minter also worked for Atari and VM Labs. For Atari he produced "Tempest 2000" (1994) on the Jaguar. It was a remake of Dave Theurer's 1981 classic, "Tempest". Minter also produced "Defender 2000" (1995) on the Jaguar, remaking Eugene Jarvis's 1980 classic, "Defender". Minter also produced the "Virtual Light Machine" ("VLM-1") for the Jaguar CD-ROM add-on. For VM Labs, Minter designed related software for the Nuon chip including the creation of the "VLM-2 Light Synth" and the video game, "Tempest 3000".
Minter then wrote games for the Pocket PC platform, some of which also had PC conversions (using a customised Pocket PC emulator). During this time, Minter released three games: "Deflex", "Hover Bovver 2:Grand Theft Flymo" (a reinterpretation of his own 1984 game, "Hover Bovver"), and the PC/Macintosh game "Gridrunner++" (the third title in the "Gridrunner" series).
In 2002, he began work on a music video game for the Nintendo GameCube to be called "Unity". Using the newest version of his "VLM", the "VLM-3" or "Neon", "Unity" was to combine the two main threads of Minter's prior career: light synthesis and classic arcade style shooting. Minter was involved in writing this game for Peter Molyneux's Lionhead Studios throughout 2003; however, the project was cancelled in December 2004. "Neon" has since been reprogrammed and significantly expanded and is used in Xbox 360 media visualisation.
In 2007 Minter released "Space Giraffe", an action video game with similarities to "Tempest". "Space Giraffe" was released for Xbox 360 through Xbox Live Arcade for 400 Microsoft Points, or US$5.
In 2008 it was announced at the Tokyo Game Show that designers at Llamasoft were working on the visualisation aspects of the Xbox 360 version of "Space Invaders", called "Space Invaders Extreme". The game was released in 2008. In December 2008 "Space Giraffe" was released for the PC.
In September 2009 he released "Gridrunner Revolution" for Windows-based PCs as a digital download.
The Minotaur Project.
In 2010, frustrated with the delays surrounding the release of his titles, Minter was keen to return to a style of game development where games could be produced and released quickly. The iOS platform was chosen and Llamasoft announced that a series of games would be produced under the banner "The Minotaur Project". The idea behind the series is that Llamasoft would develop a game in the style of an old piece of hardware but without the constraints of the original hardware.
On 5 January 2011 he released "Minotaur Rescue" for iPhone 3GS, iPhone 4, iPod touch (3rd generation), iPod touch (4th generation), and iPad.
On 2 March 2011 Llamasoft released their second iOS game, . Minotron: 2112 is the remake of the Atari ST / Amiga classic, Llamatron (which is inspired by the coin-op video game ). An iOS version of Deflex was also released although this was not specifically labeled as being part of the Minotaur Project.
On 17 September 2011, Llamasoft released GoatUp, the first platform game they have produced.
On 27 January 2012 "Caverns of Minos" was released followed on 24 March by Gridrunner iOS.
"Super Ox Wars", a shoot-em-up based on Ikaruga was released in July 2012; the final game in the series, "GoatUp 2" was released in March 2013, unique in that it is the only Llamasoft title to feature a level editor. Minter then announced his intention to abandon mobile development due to lack of discoverability, low turnover, and the dominance of free-to-play and video game clones; he ultimately declared that, after accounting for his time, the Minotaur Project made a net loss. Jeff stated on Twitter than "Returning to iOS would be like returning to the scene of a mugging" and "I would advise any dev valuing integrity and sanity to just get the hell out". [https://twitter.com/llamasoft_ox/status/431055537594466304
The code framework for the Minotaur Project games enables them to be rebuilt for both Mac and PC versions. Gridrunner was released for the Mac in August 2012.
Return to console games.
In April 2013 it was announced that Llamasoft had signed a deal with Sony Computer Entertainment to create a tube shooter for the "PlayStation Vita" called "TxK". The game would be Llamasoft's fourth tube shooter in two decades and was described as the spiritual successor of 1994's "Tempest 2000" for the "Atari Jaguar". As Minter explained in his development blog the project goals were to create a more traditional, straightforward and accessible tube shooter than "Space Giraffe", to improve on the flaws from "Tempest 2000" and "Tempest 3000", and to evoke the neo-retro aesthetic without being cheesy. TxK was released on Feb 11, 2014, by digital download through PSN.
At the beginning of 2015, Minter was threatened with legal action by Atari, claiming that TxK was too similar to Tempest 2000 - a game that Minter himself wrote, but Atari owned the rights to This raised several issues, including Atari claiming that Minter that had illegally copied material from his own source code and violated design copyrights on his own design traditions [http://yakyak.org/viewtopic.php?f=2&t=85897. Sony was unwilling to support Minter and as such future versions of TxK were blocked from release, although the PS Vita version remains available.
Personal life.
In online forums and informal game credits pages Minter usually signs as "Yak", which is, in his own words""a pseudonym chosen a long time ago, back in the days when hi-score tables on coin-op machines only held three letters, and I settled on Yak because the yak is a scruffy hairy beast – a lot like me ;-).""
He lives in Wales with his partner Ivan "Giles" Zorzin, four sheep, two goats, two llamas and a dog. Although Minter is synonymous with Llamasoft, Zorzin is also jointly responsible for the recent titles.
Games.
Second and Third Generation games
Fourth Generation games
Fifth Generation games
Sixth Generation games
Seventh Generation games
"Minotaur Project" series: This series of games pay homage to classic retro platforms. Each game is implemented as if running on a modernised version of the classic platform it represents. Originally developed for the iOS platform the games are being ported to both OS X and Android.
Eighth Generation games

</doc>
<doc id="37732" url="https://en.wikipedia.org/wiki?curid=37732" title="True lover's knot">
True lover's knot

The true lover's knot (or true love knot) is a name which has been used for many distinct knots. The association of knots with the symbolism of love, friendship, and affection dates back to antiquity. Because of this, it is not possible to consider a single knot to be "the" "true love knot".
Naming.
Modern western knotting literature has the name for these related knots deriving from stories or legends in which the knots symbolize the connection between a couple in love. Many examples feature sailors separated from their beloved. Ashley notes that it was once common for sailors' wedding rings, where gold wire was wrought to incorporate the "true lovers" knot such that resultant ring would comprise two tori: each flexible to move about the other; yet nevertheless inseparable.
Variations.
In practical terms, these knots are generally shown as consisting of two interlocked overhand knots made in two parallel ropes or cords. The variations are differentiated by the way in which the overhand knots interweave and in the final arrangement of the knot.
To show if a young couple's love would last, each would take a small limb of a tree and tie a lovers knot. If the knot held and grew for approximately a year, their love would stay true.

</doc>
<doc id="37733" url="https://en.wikipedia.org/wiki?curid=37733" title="Blancmange">
Blancmange

Blancmange ( or , from French "blanc-manger" ) is a sweet dessert commonly made with milk or cream and sugar thickened with gelatin, cornstarch or Irish moss (a source of carrageenan), and often flavored with almonds.
It is usually set in a mould and served cold. Although traditionally white, blancmanges are frequently given alternative colours. Some similar desserts are Bavarian cream, vanilla pudding (in US usage), panna cotta, annin tofu, the Turkish muhallebi, and haupia.
The historical blancmange originated some time in the Middle Ages and usually consisted of capon or chicken, milk or almond milk, rice and sugar and was considered to be an ideal food for the sick. Tavuk göğsü is a sweet contemporary Turkish pudding made with shredded chicken, similar to the medieval European dish.
History.
The true origin of the blancmange is obscure, but it is believed by some that it was a result of the Arab introduction of rice and almonds in early medieval Europe. However, there is no evidence of the existence of any similar Arab dishes from that period; though the Arabic "mahallabīyah" is similar, its origins are uncertain. Variants of the dish appear in numerous other European cultures with closely related names including "Biancomangiare" in Italy and "Manjar Blanco" in Spain. Additionally, related or similar dishes have existed in other areas of Europe under different names, such as the 13th-century Danish "hwit moos" ("white mush"), and the Anglo-Norman "blanc desirree" ("white Syrian dish"); Dutch "calijs" (from Latin "colare", "to strain") was known in English as "cullis" and in French as "coulis", and was based on cooked and then strained poultry. The oldest recipe found so far for Blancmange is from a copy of the oldest extant Danish cookbook, written by Henrik Harpestræng, who died in 1244, which dates it to the early 13th century at the latest. The Danish work may simply be a translation of a German work which is in turn assumed to have been based on a Latin or Romance vernacular manuscript from the 12th century or even earlier.
The "whitedish" (from the original Old French term "blanc mangier") was an upper-class dish common to most of Europe during the Middle Ages and early modern period. It occurs in countless variations from recipe collections from all over Europe and is mentioned in the prologue to Geoffrey Chaucer's "Canterbury Tales" and in an early 15th-century cookbook written by the chefs of Richard II. The basic ingredients were milk or almond milk, sugar and shredded chicken (usually capon) or fish, and often combined with rosewater, rice flour, and mixed into a bland stew. Almond milk and fish were used as substitutes for the other animal products on fast days and Lent. It was also often flavored with spices like saffron or cinnamon and the chicken could be exchanged for various types of fowl, like quail or partridge. Spices were often used in recipes of the later Middle Ages since they were considered highly prestigious. The whitedish was one of the preparations that could be found in recipe collections all over Europe and one of the few truly international dishes of medieval and early modern Europe.
On festive occasions and among the upper classes, whitedishes were often rendered more festive by various colouring agents: the reddish-golden yellow of saffron; green with various herbs; or sandalwood for russet. In 14th-century France, parti-colouring, the use of two bright contrasting colours on the same plate, was especially popular and was described by Guillaume Tirel (also known as Taillevent), one of the primary authors of the later editions of Le Viandier. The brightly coloured whitedishes were one of the most common of the early entremets, edibles that were intended to entertain and delight through a gaudy appearance, as much as through flavour.
In the 17th century, the whitedish evolved into a meatless dessert pudding with cream and eggs and, later, gelatin. In the 19th century, arrowroot and cornflour were added and the dish evolved into the modern blancmange.
Etymology.
The word blancmange derives from Old French "blanc mangier". The name "whitedish" is a modern term used by some historians, though the name historically was either a direct translation from or a calque of the Old French term. Many different local or regional terms were used for the dish in the Middle Ages:
Though it is fairly certain that the etymology is indeed "white dish", medieval sources are not always consistent as to the actual colour of the dish. Food scholar Terence Scully has proposed the alternative etymology of "bland mangier", "bland dish", reflecting its often mild and "dainty" (in this context meaning refined and aristocratic) taste and popularity as a sick dish.

</doc>
<doc id="37735" url="https://en.wikipedia.org/wiki?curid=37735" title="Melody">
Melody

A melody (from Greek μελῳδία, "melōidía", "singing, chanting"), also tune, voice, or line, is a linear succession of musical tones that the listener perceives as a single entity. In its most literal sense, a melody is a combination of pitch and rhythm, while more figuratively, the term can include successions of other musical elements such as tonal color. It may be considered the foreground to the background accompaniment. A line or part need not be a foreground melody.
Melodies often consist of one or more musical phrases or motifs, and are usually repeated throughout a composition in various forms. Melodies may also be described by their melodic motion or the pitches or the intervals between pitches (predominantly conjunct or disjunct or with further restrictions), pitch range, tension and release, continuity and coherence, cadence, and shape.
Elements.
"Given the many and varied elements and styles of melody "many extant explanations melody confine us to specific stylistic models, and they are too exclusive." Paul Narveson claimed in 1984 that more than three-quarters of melodic topics had not been explored thoroughly."
"The melodies existing in most European music written before the 20th century, and popular music throughout the 20th century, featured "fixed and easily discernible frequency patterns", recurring "events, often periodic, at all structural levels" and "recurrence of durations and patterns of durations"."
"Melodies in the 20th century "utilized a greater variety of pitch resources than ha been the custom in any other historical period of Western music." While the diatonic scale was still used, the chromatic scale became "widely employed." Composers also allotted a structural role to "the qualitative dimensions" that previously had been "almost exclusively reserved for pitch and rhythm". Kliewer states, "The essential elements of any melody are duration, pitch, and quality (timbre), texture, and loudness. Though the same melody may be recognizable when played with a wide variety of timbres and dynamics, the latter may still be an "element of linear ordering""
Examples.
Different musical styles use melody in different ways. For example:

</doc>
<doc id="37736" url="https://en.wikipedia.org/wiki?curid=37736" title="Roger Zelazny">
Roger Zelazny

Roger Joseph Zelazny (May 13, 1937 – June 14, 1995) was an American poet and writer of fantasy and science fiction short stories and novels, best known for "The Chronicles of Amber". He won the Nebula award three times (out of 14 nominations) and the Hugo award six times (also out of 14 nominations), including two Hugos for novels: the serialized novel "...And Call Me Conrad" (1965; subsequently published under the title "This Immortal", 1966) and then the novel "Lord of Light" (1967).
The ostracod "Sclerocypris zelaznyi" was named after him.
Biography.
Roger Joseph Zelazny was born in Euclid, Ohio, the only child of Polish immigrant Joseph Frank Żelazny and Irish-American Josephine Flora Sweet. In high school, he became the editor of the school newspaper and joined the Creative Writing Club. In the fall of 1955, he began attending Western Reserve University and graduated with a B.A. in English in 1959. He was accepted to Columbia University in New York and specialized in Elizabethan and Jacobean drama, graduating with an M.A. in 1962. His M.A. thesis was entitled "Two traditions and Cyril Tourneur: an examination of morality and humor comedy conventions in" The Revenger's Tragedy. Between 1962 and 1969 he worked for the U.S. Social Security Administration in Cleveland, Ohio and then in Baltimore, Maryland spending his evenings writing science fiction. He deliberately progressed from short-shorts to novelettes to novellas and finally to novel-length works by 1965. On May 1, 1969, he quit to become a full-time writer, and thereafter concentrated on writing novels in order to maintain his income. During this period, he was an active and vocal member of the Baltimore Science Fiction Society, whose members included writers Jack Chalker and Joe and Jack Haldeman among others.
Zelazny was married twice, first to Sharon Steberl in 1964 (divorced, no children), and then to Judith Alene Callahan in 1966 (he had also been engaged to folk singer Hedy West for six months in 1961/62). Roger and Judy had two sons, Devin and Trent (an author of crime fiction) and a daughter, Shannon. At the time of his death, Roger and Judy were separated and he was living with author Jane Lindskold.
His first fanzine appearance was part one of the story "Conditional Benefit" ("Thurban 1" #3, 1953) and his first professional publication and sale was the fantasy short story "Mr. Fuller's Revolt" ("Literary Calvalcade", 1954). As a professional writer, his debut works were the simultaneous publication of "Passion Play" ("Amazing", August 1962) and "Horseman!" ("Fantastic", August 1962). "Passion Play" was written and sold first. His first story to attract major attention was "A Rose for Ecclesiastes", published in "The Magazine of Fantasy and Science Fiction", with cover art by Hannes Bok.
Roger Zelazny was also a member of the Swordsmen and Sorcerers' Guild of America (SAGA), a loose-knit group of Heroic Fantasy authors founded in the 1960s, some of whose works were anthologized in Lin Carter's "Flashing Swords!" anthologies.
Raised as a Catholic by his parents, Zelazny later declared himself a lapsed Catholic and remained that way for the rest of his life. "I did have a strong Catholic background, but I am not a Catholic. Somewhere in the past, I believe I answered in the affirmative once for strange and complicated reasons. But I am not a member of any organized religion."
Zelazny died in 1995, aged 58, of kidney failure secondary to colorectal cancer.
Characteristic themes.
In his stories, Roger Zelazny frequently portrayed characters from myth, depicted in the modern world. Zelazny was also apt to include numerous anachronistic present-day elements, such as cigarette-smoking (see below) and references to various drama classics into his fantasy and science-fiction works. His crisp, minimalistic dialogue also seems to be somewhat influenced by the style of wisecracking hardboiled crime authors, such as Raymond Chandler or Dashiell Hammett. The tension between the ancient and the modern, surreal and familiar was what drove most of his work.
A very frequent motif in Zelazny's work is immortality or people who (have) become gods (as well as gods who have turned into people). The mythological traditions his fiction borrowed from include:
Additionally, elements from Norse, Japanese and Irish mythology, Arthurian legend as well as several references to real history appear in his magnum opus, "The Chronicles of Amber".
Aside from working with mythological themes, the most common recurring motif of Zelazny's is the "absent father" (or father-figure). Again, this occurs most notably in the Amber novels: in the first Amber series, the protagonist Corwin searches for his lost, god-like father Oberon; while in the second series, which focuses on Corwin's son Merlin (not to be confused with the Arthurian Merlin!), it is Corwin himself who is strangely missing. This somewhat Freudian theme runs through almost every Zelazny novel to a smaller or larger degree. "Roadmarks", "Doorways in the Sand", "Changeling", "Madwand", "A Dark Traveling"; the short stories "Dismal Light", "Godson", "The Keys to December"; and the "Alien Speedway" series all feature main characters who are either searching for or have lost their fathers. Zelazny’s father, Joseph, died unexpectedly in 1962 and never knew his son’s successes as a writer; this event may have triggered Zelazny's unconscious and frequent use of the absent father motif.
Two other personal characteristics that influenced his fiction were his expertise in martial arts and his addiction to tobacco. Zelazny became expert with the épée in college, and thus began a lifelong study of several different martial arts, including Karate, Judo, Aikido (which he later taught as well, having gained a black belt), T'ai Chi, Tae Kwon Do, Hapkido, Hsing I, and Pa Kua. In turn, many of his characters ably and knowledgeably use similar skills whilst dispatching their opponents. Zelazny was also a passionate cigarette and pipe smoker (until he quit in the early '80s), so much so, that he made many of his protagonists heavy smokers as well. However, he quit in order to improve his cardiovascular fitness for the martial arts; once he had quit, characters in his later novels and short stories stopped smoking too.
Another characteristic of Zelazny's writing is that many of his protagonists had sufficient familiarity with other languages to be able to quote French, German, Italian or Latin aphorisms when the occasion seemed appropriate (or even inappropriate), although Zelazny himself did not speak any of those languages.
He also often experimented with form in his stories. The novel "Doorways in the Sand" practices a flashback technique in which most chapters open with a scene, typically involving peril, not implied by the end of the previous chapter. Once the scene is established, the narrator backtracks to the events leading up to it, then follows through to the end of the chapter, whereupon the next chapter jumps ahead to another dramatic "non-sequitur".
In "Roadmarks", a novel about a road system that links all possible times, places and histories, the chapters that feature the protagonist are all titled "One". Other chapters, titled "Two", feature secondary characters, including original characters, pulp heroes, and real historical characters. The "One" storyline is fairly linear, whereas the "Two" storyline jumps around in time and sequence. After finishing the manuscript, Zelazny shuffled the "Two" chapters randomly among the "One" chapters in order to emphasize their non-linear nature relative to the storyline.
"Creatures of Light and Darkness", featuring characters in the personae of Egyptian gods, uses a narrative voice entirely in the present tense; the final chapter is structured as a play, and several chapters take the form of long poems.
Zelazny also tended to write a short fragment, not intended for publication, as a kind of backstory for a major character, as a way of giving that character a life independent of the particular novel being worked on. At least one "fragment" was published, the short story "Dismal Light", originally a backstory for "Isle of the Dead"'s Francis Sandow. Sandow himself figures little in "Dismal Light", the main character being his son, who is delaying his escape from an unstable star system in order to force his distant father to come in and ask him personally. While "Isle of the Dead" has Sandow living a life of irresponsible luxury as an escape from his personal demons, "Dismal Light" anchors his character as one who will face up to his responsibilities, however reluctantly.
Another common stylistic approach in his novels is the use of "mixed genres", whereby elements of each are combined freely and interchangeably. "Jack of Shadows" and "Changeling", for example, revolve around the tensions between the two worlds of magic and technology. "Lord of Light", perhaps one of his most famous works, is written in the classic style of a mythic fantasy, while it is established early in the book that the story itself takes place on a colonized planet.
Many of Zelazny's works explore variations upon the idea that if there exists an infinite number of worlds, then every world that can be imagined must exist, somewhere. Powerful beings in many of his stories have the ability to travel to worlds that possess precisely the characteristics which that being wishes to experience. (Zelazny characters with this ability include Thoth in "Creatures of Light and Darkness", who teleports to these worlds; those with the royal blood of either Amber or Chaos in "The Chronicles of Amber", who "move through shadows" to reach these worlds; the guardian families of "A Dark Traveling", who move between realities using high-tech devices; and Red Dorakeen in "Roadmarks", who reaches these worlds by driving along a magical highway.) Many of these same characters wonder whether they are creating these special places anew, or are merely finding places which already exist (very much like "the problem of universals" in classical metaphysics). Usually each character who ponders this ultimately decides that the question is purely academic and therefore unanswerable.
Awards.
Zelazny won at least 16 awards for particular works of fiction: 6 Hugo Awards, 3 Nebula Awards, 2 Locus Awards, 1 Prix Tour-Apollo Award, 2 Seiun Awards, and 2 Balrog Awards – very often Zelazny's works competed with each other for the same award.
In addition, Zelazny was the Worldcon Guest of Honor at Discon II in Washington, DC in 1974, and won the Inkpot Award for Best Prose Author at Comic-Con International in 1993. "A Rose for Ecclesiastes" was included in "Visions of Mars: First Library on Mars", a DVD taken on board the "Phoenix Mars Lander" in 2008.

</doc>
<doc id="37737" url="https://en.wikipedia.org/wiki?curid=37737" title="The Invisible Man">
The Invisible Man

The Invisible Man is a science fiction novella by H. G. Wells. Originally serialized in "Pearson's Weekly" in 1897, it was published as a novel the same year. The Invisible Man of the title is Griffin, a scientist who has devoted himself to research into optics and invents a way to change a body's refractive index to that of air so that it neither absorbs nor reflects light and thus becomes invisible. He successfully carries out this procedure on himself, but fails in his attempt to reverse it.
While its predecessors, "The Time Machine" and "The Island of Doctor Moreau", were written using first-person narrators, Wells adopts a third-person objective point of view in "The Invisible Man".
Plot summary.
A mysterious man, Griffin, arrives at the local inn of the English village of Iping, West Sussex, during a snowstorm. The stranger wears a long-sleeved, thick coat and gloves; his face is hidden entirely by bandages except for a fake pink nose; and he wears a wide-brimmed hat. He is excessively reclusive, irascible, and unfriendly. He demands to be left alone and spends most of his time in his rooms working with a set of chemicals and laboratory apparatus, only venturing out at night. While Griffin is staying at the inn, hundreds of strange glass bottles (that he calls his luggage) arrive. Many local townspeople believe this to be very strange. He becomes the talk of the village.
Meanwhile, a mysterious burglary occurs in the village. Griffin has run out of money and is trying to find a way to pay for his board and lodging. When his landlady demands that he pay his bill and quit the premises, he reveals part of his invisibility to her in a fit of pique. An attempt to apprehend the stranger is frustrated when he undresses to take advantage of his invisibility, fights off his would-be captors, and flees to the downs.
There Griffin coerces a tramp, Thomas Marvel, into becoming his assistant. With Marvel, he returns to the village to recover three notebooks that contain records of his experiments. When Marvel attempts to betray the Invisible Man to the police, Griffin chases him to the seaside town of Port Burdock, threatening to kill him. Marvel escapes to a local inn and is saved by the people at the inn, but Griffin escapes. Marvel later goes to the police and tells them of this "invisible man," then requests to be locked up in a high-security jail.
Griffin's furious attempt to avenge his betrayal leads to his being shot. He takes shelter in a nearby house that turns out to belong to Dr. Kemp, a former acquaintance from medical school. To Kemp, he reveals his true identity: the Invisible Man is Griffin, a former medical student who left medicine to devote himself to optics. Griffin recounts how he invented chemicals capable of rendering bodies invisible, and, on impulse, performed the procedure on himself.
Griffin tells Kemp of the story of how he became invisible. He explains how he tried the invisibility on a cat, then himself. Griffin burned down the boarding house he was staying in, along with all the equipment he used to turn invisible, to cover his tracks; but he soon realised that he was ill-equipped to survive in the open. He attempted to steal food and clothes from a large department store, and eventually stole some clothing from a theatrical supply shop and headed to Iping to attempt to reverse the invisibility. Now he imagines that he can make Kemp his secret confederate, describing his plan to begin a "Reign of Terror" by using his invisibility to terrorise the nation.
Kemp has already denounced Griffin to the local authorities and is waiting for help to arrive as he listens to this wild proposal. When the authorities arrive at Kemp's house, Griffin fights his way out and the next day leaves a note announcing that Kemp himself will be the first man to be killed in the "Reign of Terror". Kemp, a cool-headed character, tries to organise a plan to use himself as bait to trap the Invisible Man, but a note that he sends is stolen from his servant by Griffin.
Griffin shoots and injures a local policeman who comes to Kemp's aid with the use of Kemp's gun. then breaks into Kemp's house. Kemp bolts for the town, where the local citizenry come to his aid. Griffin is seized, assaulted, and killed by a mob. The Invisible Man's naked, battered body gradually becomes visible as he dies. A local policeman shouts to have someone cover Griffin's face with a sheet, then the book concludes.
In the final chapter, it is revealed that Marvel has secretly kept Griffin's notes but is completely incapable of understanding them.
Characters.
Griffin.
Griffin is the surname of the story's protagonist. His name is not mentioned until about halfway through the book. Consumed with his greed for power and fame, he is the model of science without humanity. A gifted young student, he becomes interested in the science of refraction. During his experiments, he accidentally discovers chemicals (combined with an unspecified kind of radiation) that would make tissue invisible. Obsessed with his discovery, he tries the experiment on himself and becomes invisible. However, he does not know how to reverse the process, and he slowly discovers that the advantages of being invisible do not outweigh the disadvantages and the problems he faces. Thus begins his downfall as he takes the road to crime for his survival, revealing in the process his lack of conscience, inhumanity and complete selfishness. He progresses from obsession to fanaticism, to insanity, and finally to his fateful end.
Dr. Kemp.
Dr. Kemp is a scientist living in the town of Port Burdock. He is a former acquaintance of Griffin, who knew Kemp to be interested in strange, bizarre aspects of science. Kemp continues to study science as he hopes to be admitted to The Royal Society. His scientific temperament makes him listen to the story Griffin tells him. He does not become hysterical nor does he behave like the locals. Griffin hopes Kemp would support him in his evil schemes and help him live a normal life, but Kemp is too decent to join him. He is repelled by Griffin's brutality and considers him insane and homicidal. He betrays Griffin to the police. He keeps his cool throughout the plot, when the final hunt for Griffin begins. Kemp helps in the final capture and killing of Griffin.
In the 1933 Universal film adaptation, Kemp is given the first name Arthur and is played by William Harrigan. Unlike the novel, Kemp in the film does not survive to the end of the story.
Janny Hall.
Janny Hall is the wife of Mr. Hall and the owner of the Coach and Horses Inn. A very friendly, down-to-earth woman who enjoys socialising with her guests, Mrs. Hall is continually frustrated by the mysterious Griffin's refusal to talk with her, and by his repeated temper tantrums. She vents her frustrations on her maid, Millie, and becomes suspicious of Griffin.
Mrs. Hall appears in the 1933 film adaptation, where she was played by Una O'Connor.
George Hall.
George Hall is the husband of Mrs. Hall and helps her run the Coach and Horses Inn. He was the first person in Iping to suspect that Griffin is invisible: when a dog bites him and tears his glove, Griffin retreats to his room and Hall follows to see if he is all right, only to see Griffin without his glove and handless (or so it appears to Hall).
Mr. Hall appears in the 1933 film adaptation, where his first name is changed to Herbert; he is seriously injured by Griffin. He is portrayed by Forrester Harvey.
Thomas Marvel.
Thomas Marvel is a droll tramp unwittingly recruited to assist the Invisible Man as his first visible partner. He carries the Invisible Man's scientific notebooks and stolen money. Eventually Marvel grows afraid of his unseen partner and flees to Port Burdock, taking both the notebooks and the money with him, where he seeks police protection. Although the Invisible Man is furious and vows revenge, he becomes preoccupied with hiding from the law and retaliating against Dr. Kemp, and Marvel is spared. Marvel eventually uses the stolen money to open his own inn, which he calls the Invisible Man, and prospers. The novel ends with him secretly "marvelling" at Griffin's notes (though not comprehending them). It turns out Marvel kept the notes and only views them when there is nobody around, so nobody can know Griffin's secrets — or that Marvel has them.
Marvel does not appear in the 1933 film adaptation, but does appear in Alan Moore's comics series "The League of Extraordinary Gentlemen".
Colonel Adye.
Colonel Adye is the chief of police in the town of Port Burdock. He is called upon by Dr. Kemp when the Invisible Man turns up in Kemp's house. Adye saves Kemp from the Invisible Man's first attempt on his life and leads the hunt for the unseen fugitive. He mostly follows Kemp's suggestions in planning the campaign against the Invisible Man. He is eventually shot by the Invisible Man with Kemp's revolver. Upon being shot, Adye is described as falling down and not getting back up.
Dr. Cuss.
Dr. Cuss is a doctor living in the village of Iping. Intrigued by tales of a bandaged stranger staying at the Coach and Horses Inn, Dr. Cuss goes to see him under the pretence of asking for a donation to the nurse's fund. Cuss is scared away after Griffin pinches his nose with an invisible hand. Cuss immediately goes to see the Rev. Bunting, who, not surprisingly, does not believe the doctor's wild story and is quite amused to hear it . Later, Cuss and Bunting obtain the Invisible Man's notebooks, but these are subsequently stolen back from them by the invisible Griffin, when he also takes both men's clothes.
J.A. Jaffers.
J.A. Jaffers is a constable in the town of Iping. He is called upon by George Hall and Janny Hall to arrest Griffin after they suspect him of robbing the Reverend Bunting. He quickly overcomes his shock at the discovery that Griffin is invisible, and is determined to arrest him in spite of this. The Invisible Man knocks him unconscious in his flight from Iping.
Jaffers appears in the 1933 film adaptation.
Scientific accuracy.
Russian writer Yakov I. Perelman pointed out in "Physics Can Be Fun" (1913) that from a scientific point of view, a man made invisible by Griffin's method should have been blind, since a human eye works by "absorbing" incoming light, not letting it through completely. Wells seems to show some awareness of this problem in Chapter 20, where the eyes of an otherwise invisible cat retain visible retinas. Nonetheless, this would be insufficient, since the retina would be flooded with light (from all directions) that ordinarily is blocked by the opaque sclera of the eyeball. Also, any image would be badly blurred if the eye had an invisible cornea and lens.
However, using some form of weak measurement it would be possible to observe photons without absorbing them. The human eye does not ordinarily work like this but its structure could conceivably be modified so that it did.
Plot errors.
Beside scientific inaccuracies, there are also a number of plot inconsistencies. While unable to make his clothes invisible, Griffin made wool and a pillow invisible. 
Another error is a contradiction in the arrival time of the stranger in Iping. Griffin is said to arrive during early February and is stated to expect his luggage in two days from Bramblehurst railway station. His trunks arrive after two days, however the date specified when his luggage arrive is 29 February.
Origins and moral.
As a moral tale, "The Invisible Man" can be seen as a modern version of the "Ring of Gyges" parable by Plato.

</doc>
<doc id="37738" url="https://en.wikipedia.org/wiki?curid=37738" title="Soil">
Soil

Soil is a mixture of minerals, organic matter, gases, liquids, and countless organisms that together support life on Earth. Soil is a natural body called the pedosphere which has four important functions: it is a medium for plant growth; it is a means of water storage, supply and purification; it is a modifier of Earth's atmosphere; it is a habitat for organisms; all of which, in turn, modify the soil.
Soil is called the "Skin of the Earth" and interfaces with its lithosphere, hydrosphere, atmosphere, and biosphere. The term pedolith, used commonly to refer to the soil, literally translates 'level stone'. Soil consists of a solid phase of minerals and organic matter, as well as a porous phase that holds gases and water. Accordingly, soils are often treated as a three-state system of solids, liquids, and gases.
Soil is a product of the influence of the climate, relief (elevation, orientation, and slope of terrain), organisms, and its parent materials (original minerals) interacting over time. Soil continually undergoes development by way of numerous physical, chemical and biological processes, which include weathering with associated erosion.
Most soils have a density between 1 and 2 g/cm3. Little of the soil of planet Earth is older than the Pleistocene and none is older than the Cenozoic, although fossilized soils are preserved from as far back as the Archean.
Soil science has two basic branches of study: edaphology and pedology. Edaphology is concerned with the influence of soils on living things. Pedology is focused on the formation, description (morphology), and classification of soils in their natural environment. In engineering terms, soil is referred to as regolith, or loose rock material that lies above the 'solid geology'. Soil is commonly referred to as "earth" or "dirt"; technically, the term "dirt" should be restricted to displaced soil.
As soil resources serve as a basis for food security, the international community advocates for its sustainable and responsible use through different types of Soil Governance.
Overview.
Soil is a major component of the Earth's ecosystem. The world's ecosystems are impacted in far-reaching ways by the processes carried out in the soil, from ozone depletion and global warming, to rainforest destruction and water pollution. Following the atmosphere, the soil is the next largest carbon reservoir on Earth, and it is potentially one of the most reactive to human disturbance and climate change. As the planet warms, soils will add carbon dioxide to the atmosphere due to its increased biological activity at higher temperatures. Thus, soil carbon losses likely have a large positive feedback response to global warming.
Soil acts as an engineering medium, a habitat for soil organisms, a recycling system for nutrients and organic wastes, a regulator of water quality, a modifier of atmospheric composition, and a medium for plant growth. Since soil has a tremendous range of available niches and habitats, it contains most of the Earth's genetic diversity. A gram of soil can contain billions of organisms, belonging to thousands of species. Soil has a mean prokaryotic density of roughly 1013 organisms per cubic meter, whereas the ocean has a mean prokaryotic density of roughly 108 organisms per cubic meter. The carbon content of the soil is eventually returned to the atmosphere through the process of respiration carried out by heterotrophic organisms that feed upon the carbonaceous material in the soil. Since plant roots need oxygen, ventilation is an important characteristic of soil. This ventilation can be accomplished via networks of soil pores, which also absorb and hold rainwater making it readily available for plant uptake. Since plants require a nearly continuous supply of water, but most regions receive sporadic rainfall, the water-holding capacity of soils is vital for plant survival.
Soils can effectively remove impurities, kill disease agents, and degrade contaminants. Typically, soils maintain a net absorption of oxygen and methane, and undergo a net release of carbon dioxide and nitrous oxide. Soils offer plants physical support, air, water, temperature moderation, nutrients, and protection from toxins. Soils provide readily available nutrients to plants and animals by converting dead organic matter into various nutrient forms.
Soils supply plants with nutrients that are held in place by the clay and humus content of that soil. For optimum plant growth, the soil components by volume should be roughly 50% solids (45% mineral and 5% organic matter), and 50% voids of which half is occupied by water and half by gas. The percent soil mineral and organic content is typically treated as a constant, while the percent soil water and gas content is considered highly variable whereby a rise in one is simultaneously balanced by a reduction in the other. The pore space allows for the infiltration and movement of air and water, both of which are critical for life in soil. Compaction, a common problem with soils, reduces this space, preventing air and water from reaching the plant roots and soil organisms.
Given sufficient time, an undifferientated soil will evolve a soil profile which consists of two or more layers, referred to as soil horizons, that differ in one or more properties such as in their texture, structure, density, porosity, consistency, temperature, color, and reactivity. The horizons differ greatly in thickness and generally lack sharp boundaries. Soil profile development is dependent on the processes that form soils from their parent materials, the type of parent material, and the factors that control soil formation. The biological influences on soil properties are strongest near the surface, while the geochemical influences on soil properties increase with depth. Mature soil profiles in temperate climate regions typically include three basic master horizons: A, B and C. The solum normally includes the A and B horizons. The living component of the soil is largely confined to the solum. In the more hot, humid, climate of the tropics, a soil may have only a single horizon.
The soil texture is determined by the relative proportions of sand, silt, and clay in the soil. The addition of organic matter, water, gases and time causes the soil of that texture to develop into a larger soil structure called an aggregate. At that point a soil can be said to be developed, and can be described further in terms of color, porosity, consistency, reaction etc.
Of all the factors influencing the evolution of soil, water is the most powerful due to its involvement in the solution, erosion, transportation, and deposition of the materials of which a soil is composed. The mixture of water and the dissolved or suspended materials that occupy the soil pore space is called the soil solution. Since soil water is never pure water, but contains hundreds of dissolved organic and mineral substances, it may be more accurately called the soil solution. Water is central to the solution, precipitation and leaching of minerals from the soil profile. Finally, water affects the type of vegetation that grows in a soil, which in turn affects the development of the soil.
The most influential factor in stabilizing soil fertility are the soil colloids, clay and humus. Soil colloids behave as repositories of nutrients and moisture and so act to buffer the variations of soil solution ions and moisture. The contribution of soil colloids to soil nutrition are out of proportion to their part of the soil. Colloids act to store nutrients that might otherwise be leached from the soil or to release those ions in response to changes of soil pH, and so, make them available to plants.
The greatest influence on plant nutrient availability is soil pH, which is a measure of the hydrogen ion (acid-forming) soil reactivity, and is in turn a function of the soil materials, precipitation level, and plant root behavior. Soil pH strongly affects the availability of nutrients.
Most nutrients, with the exception of nitrogen, originate from minerals. Some nitrogen originates from rain (as dilute nitric acid), but most of the nitrogen is available in soils as a result of nitrogen fixation by bacteria. The action of microbes on organic matter and minerals may be to free nutrients for use, sequester them, or cause their loss from the soil by their volatilisation to gases or their leaching from the soil. The nutrients may be stored on soil colloids, or within live or dead organic matter, but they may not be accessible to plants due to extremes of pH.
The organic material of the soil has a powerful effect on its development, fertility, and available moisture. Following water and soil colloids, organic material is next in importance to a soil's formation and fertility.
History of the study of soil.
Studies concerning soil fertility.
The history of the study of soil is intimately tied to our urgent need to provide food for ourselves and forage for our animals. Throughout history, civilizations have prospered or declined as a function of the availability and productivity of their soils.
The Greek historian Xenophon (450–355 B.C.) is credited with being the first to expound upon the merits of green-manuring crops: "But then whatever weeds are upon the ground, being turned into earth, enrich the soil as much as dung."
Columella's "Husbandry," circa 60 A.D., advocated the use of lime and that clover and alfalfa (green manure) should be turned under, and was used by 15 generations (450 years) under the Roman Empire until its collapse. From the fall of Rome to the French Revolution, knowledge of soil and agriculture was passed on from parent to child and as a result, crop yields were low. During the European Dark Ages, Yahya Ibn al-'Awwam's handbook, with its emphasis on irrigation, guided the people of North Africa, Spain and the Middle East; a translation of this work was finally carried to the southwest of the United States.
Experiments into what made plants grow first led to the idea that the ash left behind when plant matter was burned was the essential element but overlooked the role of nitrogen, which is not left on the ground after combustion. In about 1635, the Flemish chemist Jan Baptist van Helmont thought he had proved water to be the essential element from his famous five years' experiment with a willow tree grown with only the addition of rainwater. His conclusion came from the fact that the increase in the plant's weight had apparently been produced only by the addition of water, with no reduction in the soil's weight. John Woodward (d. 1728) experimented with various types of water ranging from clean to muddy and found muddy water the best, and so he concluded that earthy matter was the essential element. Others concluded it was humus in the soil that passed some essence to the growing plant. Still others held that the vital growth principal was something passed from dead plants or animals to the new plants. At the start of the 18th century, Jethro Tull demonstrated that it was beneficial to cultivate (stir) the soil, but his opinion that the stirring made the fine parts of soil available for plant absorption was erroneous.
As chemistry developed, it was applied to the investigation of soil fertility. The French chemist Antoine Lavoisier showed in about 1778 that plants and animals must "combust" oxygen internally to live and was able to deduce that most of the 165-pound weight of van Helmont's willow tree derived from air. It was the French agriculturalist Jean-Baptiste Boussingault who by means of experimentation obtained evidence showing that the main sources of carbon, hydrogen and oxygen for plants were the air and water. Justus von Liebig in his book "Organic Chemistry in its Applications to Agriculture and Physiology" (published 1840), asserted that the chemicals in plants must have come from the soil and air and that to maintain soil fertility, the used minerals must be replaced. Liebig nevertheless believed the nitrogen was supplied from the air. The enrichment of soil with guano by the Incas was rediscovered in 1802, by Alexander von Humboldt. This led to its mining and that of Chilean nitrate and to its application to soil in the United States and Europe after 1840.
The work of Liebig was a revolution for agriculture, and so other investigators started experimentation based on it. In England John Bennet Lawes and Joseph Henry Gilbert worked in the Rothamsted Experimental Station, founded by the former, and discovered that plants took nitrogen from the soil, and that salts needed to be in an available state to be absorbed by plants. Their investigations also produced the "superphosphate", consisting in the acid treatment of phosphate rock. This led to the invention and use of salts of potassium (K) and nitrogen (N) as fertilizers. Ammonia generated by the production of coke was recovered and used as fertiliser. Finally, the chemical basis of nutrients delivered to the soil in manure was understood and in the mid-19th century chemical fertilisers were applied. However, the dynamic interaction of soil and its life forms awaited discovery.
In 1856 J. T. Way discovered that ammonia contained in fertilisers was transformed into nitrates, and twenty years later R. W. Warington proved that this transformation was done by living organisms. In 1890 Sergei Winogradsky announced he had found the bacteria responsible for this transformation.
It was known that certain legumes could take up nitrogen from the air and fix it to the soil but it took the development of bacteriology towards the end of the 19th century to lead to an understanding of the role played in nitrogen fixation by bacteria. The symbiosis of bacteria and leguminous roots, and the fixation of nitrogen by the bacteria, were simultaneously discovered by German agronomist Hermann Hellriegel and Dutch microbiologist Martinus Beijerinck.
Crop rotation, mechanisation, chemical and natural fertilisers led to a doubling of wheat yields in Western Europe between 1800 and 1900.
Studies concerning soil formation.
The scientists who studied the soil in connection with agricultural practices had considered it mainly as a static substrate. However, soil is the result of evolution from more ancient geological materials. After studies of the improvement of the soil commenced, others began to study soil genesis and as a result also soil types and classifications.
In 1860, in Mississippi, Eugene W. Hilgard studied the relationship among rock material, climate, and vegetation, and the type of soils that were developed. He realised that the soils were dynamic, and considered soil types classification. Unfortunately his work was not continued. At the same time Vasily Dokuchaev (about 1870) was leading a team of soil scientists in Russia who conducted an extensive survey of soils, finding that similar basic rocks, climate and vegetation types lead to similar soil layering and types, and established the concepts for soil classifications. Due to the language barriers, the work of this team was not communicated to Western Europe until 1914 by a publication in German by K. D. Glinka, a member of the Russian team.
Curtis F. Marbut was influenced by the work of the Russian team, translated Glinka's publication into English, and as he was placed in charge of the U. S. National Cooperative Soil Survey, applied it to a national soil classification system.
Soil-forming processes.
Soil formation, or pedogenesis, is the combined effect of physical, chemical, biological and anthropogenic processes working on soil parent material. Soil is said to be formed when organic matter has accumulated and colloids are washed downward, leaving deposits of clay, humus, iron oxide, carbonate, and gypsum, producing a distinct layer called the B horizon. This is a somewhat arbitrary definition as mixtures of sand, silt, clay and humus will support biological and agricultural activity before that time. These constituents are moved from one level to another by water and animal activity. As a result, layers (horizons) form in the soil profile. The alteration and movement of materials within a soil causes the formation of distinctive soil horizons.
How soil formation proceeds is influenced by at least five classic factors that are intertwined in the evolution of a soil. They are: parent material, climate, topography (relief), organisms, and time. When reordered to climate, relief, organisms, parent material, and time, they form the acronym CROPT.
An example of the development of a soil would begin with the weathering of lava flow bedrock, which would produce the purely mineral-based parent material from which the soil texture forms. Soil development would proceed most rapidly from bare rock of recent flows in a warm climate, under heavy and frequent rainfall. Under such conditions, plants become established very quickly on basaltic lava, even though there is very little organic material. The plants are supported by the porous rock as it is filled with nutrient-bearing water that carries dissolved minerals from the rocks and guano. Crevasses and pockets, local topography of the rocks, would hold fine materials and harbour plant roots. The developing plant roots are associated with mycorrhizal fungi that assist in breaking up the porous lava, and by these means organic matter and a finer mineral soil accumulate with time.
Parent material.
The mineral material from which a soil forms is called parent material. Rock, whether its origin is igneous, sedimentary, or metamorphic, is the source of all soil mineral materials and the origin of all plant nutrients with the exceptions of nitrogen, hydrogen and carbon. As the parent material is chemically and physically weathered, transported, deposited and precipitated, it is transformed into a soil.
Typical soil parent mineral materials are:
Classification of parent material.
Parent materials are classified according to how they came to be deposited. Residual materials are mineral materials that have weathered in place from primary bedrock. Transported materials are those that have been deposited by water, wind, ice or gravity. Cumulose material is organic matter that has grown and accumulates in place.
Residual soils are soils that develop from their underlying parent rocks and have the same general chemistry as those rocks. The soils found on mesas, plateaux, and plains are residual soils. In the United States as little as three percent of the soils are residual.
Most soils derive from transported materials that have been moved many miles by wind, water, ice and gravity.
Cumulose parent material is not moved but originates from deposited organic material. This includes peat and muck soils and results from preservation of plant residues by the low oxygen content of a high water table. While peat may form sterile soils, muck soils may be very fertile.
Weathering of parent material.
The weathering of parent material takes the form of physical weathering (disintegration), chemical weathering (decomposition) and chemical transformation. Generally, minerals that are formed under the high temperatures and pressures at great depths within the Earth's mantle are less resistant to weathering, while minerals formed at low temperature and pressure environment of the surface are more resistant to weathering. Weathering is usually confined to the top few meters of geologic material, because physical, chemical, and biological stresses generally decrease with depth. Physical disintegration begins as rocks that have solidified deep in the Earth are exposed to lower pressure near the surface and swell and become mechanically unstable. Chemical decomposition is a function of mineral solubility, the rate of which doubles with each 10 °C rise in temperature, but is strongly dependent on water to effect chemical changes. Rocks that will decompose in a few years in tropical climates will remain unaltered for millennia in deserts. Structural changes are the result of hydration, oxidation, and reduction.
Of the above, hydrolysis and carbonation are the most effective.
Saprolite is a particular example of a residual soil formed from the transformation of granite, metamorphic and other types of bedrock into clay minerals. Often called "weathered granite", saprolite is the result of weathering processes that include: hydrolysis, chelation from organic compounds, hydration (the solution of minerals in water with resulting cation and anion pairs) and physical processes that include freezing and thawing. The mineralogical and chemical composition of the primary bedrock material, its physical features, including grain size and degree of consolidation, and the rate and type of weathering transforms the parent material into a different mineral. The texture, pH and mineral constituents of saprolite are inherited from its parent material.
Climate.
The principal climatic variables influencing soil formation are effective precipitation (i.e., precipitation minus evapotranspiration) and temperature, both of which affect the rates of chemical, physical, and biological processes. The temperature and moisture both influence the organic matter content of soil through their effects on the balance between plant growth and microbial decomposition. Climate is the dominant factor in soil formation, and soils show the distinctive characteristics of the climate zones in which they form. For every 10 °C rise in temperature, the rates of biochemical reactions more than double. Mineral precipitation and temperature are the primary climatic influences on soil formation. If warm temperatures and abundant water are present in the profile at the same time, the processes of weathering, leaching, and plant growth will be maximized. Humid climates favor the growth of trees. In contrast, grasses are the dominant native vegetation in subhumid and semiarid regions, while shrubs and brush of various kinds dominate in arid areas.
Water is essential for all the major chemical weathering reactions. To be effective in soil formation, water must penetrate the regolith. The seasonal rainfall distribution, evaporative losses, site topography, and soil permeability interact to determine how effectively precipitation can influence soil formation. The greater the depth of water penetration, the greater the depth of weathering of the soil and its development. Surplus water percolating through the soil profile transports soluble and suspended materials from the upper to the lower layers. It may also carry away soluble materials in the surface drainage waters. Thus, percolating water stimulates weathering reactions and helps differentiate soil horizons. Likewise, a deficiency of water is a major factor in determining the characteristics of soils of dry regions. Soluble salts are not leached from these soils, and in some cases they build up to levels that curtail plant growth. Soil profiles in arid and semi-arid regions are also apt to accumulate carbonates and certain types of expansive clays.
The direct influences of climate include:
Climate directly affects the rate of weathering and leaching. Wind moves sand and smaller particles, especially in arid regions where there is little plant cover. The type and amount of precipitation influence soil formation by affecting the movement of ions and particles through the soil, and aid in the development of different soil profiles. Soil profiles are more distinct in wet and cool climates, where organic materials may accumulate, than in wet and warm climates, where organic materials are rapidly consumed. The effectiveness of water in weathering parent rock material depends on seasonal and daily temperature fluctuations. Cycles of freezing and thawing constitute an effective mechanism which breaks up rocks and other consolidated materials.
Climate also indirectly influences soil formation through the effects of vegetation cover and biological activity, which modify the rates of chemical reactions in the soil.
Topography.
The topography, or relief, is characterized by the inclination (slope), elevation, and orientation of the terrain. Topography determines the rate of precipitation or runoff and rate of formation or erosion of the surface soil profile. The topographical setting may either hasten or retard the work of climatic forces.
Steep slopes encourage rapid soil loss by erosion and allow less rainfall to enter the soil before running off and hence, little mineral deposition in lower profiles. In semiarid regions, the lower effective rainfall on steeper slopes also results in less complete vegetative cover, so there is less plant contribution to soil formation. For all of these reasons, steep slopes prevent the formation of soil from getting very far ahead of soil destruction. Therefore, soils on steep terrain tend to have rather shallow, poorly developed profiles in comparison to soils on nearby, more level sites.
In swales and depressions where runoff water tends to concentrate, the regolith is usually more deeply weathered and soil profile development is more advanced. However, in the lowest landscape positions, water may saturate the regolith to such a degree that drainage and aeration are restricted. Here, the weathering of some minerals and the decomposition of organic matter are retarded, while the loss of iron and manganese is accelerated. In such low-lying topography, special profile features characteristic of wetland soils may develop. Depressions allow the accumulation of water, minerals and organic matter and in the extreme, the resulting soils will be saline marshes or peat bogs. Intermediate topography affords the best conditions for the formation of an agriculturally productive soil.
Organisms.
Soil is the most abundant ecosystem on Earth, but the vast majority of organisms in soil are microbes, a great many of which have not been described. There may be a population limit of around one billion cells per gram of soil, but estimates of the number of species vary widely from 50,000 per gram to over a million per gram of soil. The total number of organisms and species can vary widely according to soil type, location, and depth.
Plants, animals, fungi, bacteria and humans affect soil formation (see soil biomantle and stonelayer). Animals, soil mesofauna and micro-organisms mix soils as they form burrows and pores, allowing moisture and gases to move about. In the same way, plant roots open channels in soils. Plants with deep taproots can penetrate many metres through the different soil layers to bring up nutrients from deeper in the profile. Plants with fibrous roots that spread out near the soil surface have roots that are easily decomposed, adding organic matter. Micro-organisms, including fungi and bacteria, effect chemical exchanges between roots and soil and act as a reserve of nutrients.
Humans impact soil formation by removing vegetation cover with erosion as the result. Their tillage also mixes the different soil layers, restarting the soil formation process as less weathered material is mixed with the more developed upper layers.
Earthworms, ants and termites mix the soil as they burrow, significantly affecting soil formation. Earthworms ingest soil particles and organic residues, enhancing the availability of plant nutrients in the material that passes through their bodies. They aerate and stir the soil and increase the stability of soil aggregates, thereby assuring ready infiltration of water. In addition, as ants and termites build mounds, they transport soil materials from one horizon to another.
In general, the mixing of the soil by the activities of animals, sometimes called pedoturbation, tends to undo or counteract the tendency of other soil-forming processes that create distinct horizons. Termites and ants may also retard soil profile development by denuding large areas of soil around their nests, leading to increased loss of soil by erosion. Large animals such as gophers, moles, and prairie dogs bore into the lower soil horizons, bringing materials to the surface. Their tunnels are often open to the surface, encouraging the movement of water and air into the subsurface layers. In localized areas, they enhance mixing of the lower and upper horizons by creating, and later refilling, underground tunnels. Old animal burrows in the lower horizons often become filled with soil material from the overlying A horizon, creating profile features known as crotovinas.
Vegetation impacts soils in numerous ways. It can prevent erosion caused by excessive rain that might result from surface runoff. Plants shade soils, keeping them cooler and slow evaporation of soil moisture, or conversely, by way of transpiration, plants can cause soils to lose moisture. Plants can form new chemicals that can break down minerals and improve the soil structure. The type and amount of vegetation depends on climate, topography, soil characteristics, and biological factors. Soil factors such as density, depth, chemistry, pH, temperature and moisture greatly affect the type of plants that can grow in a given location. Dead plants and fallen leaves and stems begin their decomposition on the surface. There, organisms feed on them and mix the organic material with the upper soil layers; these added organic compounds become part of the soil formation process.
Human activities widely influence soil formation. For example, it is believed that Native Americans regularly set fires to maintain several large areas of prairie grasslands in Indiana and Michigan. In more recent times, human destruction of natural vegetation and subsequent tillage of the soil for crop production has abruptly modified soil formation. Likewise, irrigating an arid region of soil drastically influences the soil-forming factors, as does adding fertilizer and lime to soils of low fertility.
Time.
Time is a factor in the interactions of all the above. While a mixture of sand, silt and clay constitute the texture of a soil and the aggregation of those components produces peds, the development of a distinct B horizon marks the development of a soil. With time, soils will evolve features that depend on the interplay of the prior listed soil-forming factors. It takes decades to several thousand years for a soil to develop a profile. That time period depends strongly on climate, parent material, relief, and biotic activity. For example, recently deposited material from a flood exhibits no soil development as there has not been enough time for the material to form a structure that further defines soil. The original soil surface is buried, and the formation process must begin anew for this deposit. Over time the soil will develop a profile that depends on the intensities of biota and climate. While a soil can achieve relative stability of its properties for extended periods, the soil life cycle ultimately ends in soil conditions that leave it vulnerable to erosion. Despite the inevitability of soil retrogression and degradation, most soil cycles are long.
Soil-forming factors continue to affect soils during their existence, even on "stable" landscapes that are long-enduring, some for millions of years. Materials are deposited on top or are blown or washed from the surface. With additions, removals and alterations, soils are always subject to new conditions. Whether these are slow or rapid changes depends on climate, topography and biological activity.
Physical properties of soils.
The physical properties of soils, in order of decreasing importance, are texture, structure, density, porosity, consistency, temperature, colour and resistivity. Soil texture is determined by the relative proportion of the three kinds of soil mineral particles, called soil separates: sand, silt, and clay. At the next larger scale, soil structures called peds are created from the soil separates when iron oxides, carbonates, clay, silica and humus, coat particles and cause them to adhere into larger, relatively stable secondary structures. Soil density, particularly bulk density, is a measure of soil compaction. Soil porosity consists of the void part of the soil volume and is occupied by gases or water. Soil consistency is the ability of soil to stick together. Soil temperature and colour are self-defining. Resistivity refers to the resistance to conduction of electric currents and affects the rate of corrosion of metal and concrete structures. These properties may vary through the depth of a soil profile. Most of these properties determine the aeration of the soil and the ability of water to infiltrate and to be held within the soil.
Texture.
Sand and silt are the products of physical and chemical weathering of the parent rock; clay, on the other hand, is a most often the product of the precipitation of the dissolved parent rock as a secondary mineral. It is the surface area to volume ratio (specific surface area) of soil particles and the unbalanced ionic charges within those that determine their role in the fertility of soil, as measured by its cation exchange capacity. Sand is least active, followed by silt; clay is the most active. Sand's greatest benefit to soil is that it resists compaction and increases a soil's porosity. Silt is mineralogically like sand but with its higher specific surface area it is more chemically active than sand. But it is the clay content of soil, with its very high specific surface area and generally large number of negative charges, that gives a soil its high retention capacity for water and nutrients. Clay soils also resist wind and water erosion better than silty and sandy soils, as the particles bond tightly to each other.
Sand is the most stable of the mineral components of soil; it consists of rock fragments, primarily quartz particles, ranging in size from in diameter. Silt ranges in size from 0.05 to 0.002 mm (0.002 to 0.00008 in). Clay cannot be resolved by optical microscopes as its particles are or less in diameter and a thickness of only 10 angstroms (10−10 m). In medium-textured soils, clay is often washed downward through the soil profile and accumulates in the subsoil.
Soil components larger than are classed as rock and gravel and are removed before determining the percentages of the remaining components and the texture class of the soil, but are included in the name. For example, a sandy loam soil with 20% gravel would be called gravelly sandy loam.
When the organic component of a soil is substantial, the soil is called organic soil rather than mineral soil. A soil is called organic if:
Structure.
The clumping of the soil textural components of sand, silt and clay causes aggregates to form and the further association of those aggregates into larger units creates soil structures called peds (a contraction of the word pedolith). The adhesion of the soil textural components by organic substances, iron oxides, carbonates, clays, and silica, and the breakage of those aggregates from expansion-contraction, caused by freezing-thawing and wetting-drying cycles, shape soil into distinct geometric forms. The peds evolve into units which may have various shapes, sizes and degrees of development. A soil clod, however, is not a ped but rather a mass of soil that results from mechanical disturbance of the soil. Soil structure affects aeration, water movement, conduction of heat, plant root growth and resistance to erosion. Water, in turn, has its strongest effect on soil structure due to its solution and precipitation of minerals and its effect on plant growth.
Soil structure often gives clues to its texture, organic matter content, biological activity, past soil evolution, human use, and the chemical and mineralogical conditions under which the soil formed. While texture is defined by the mineral component of a soil and is an innate property of the soil that does not change with agricultural activities, soil structure can be improved or destroyed by the choice and timing of farming practices.
Soil structural classes:
At the largest scale, the forces that shape a soil's structure result from swelling and shrinkage that initially tend to act horizontally, causing vertically oriented prismatic peds. Clayey soil, due to its differential drying rate with respect to the surface, will induce horizontal cracks, reducing columns to blocky peds. Roots, rodents, worms, and freezing-thawing cycles further break the peds into a spherical shape.
At a smaller scale, plant roots extend into voids and remove water causing the open spaces to increase, thereby decreasing aggregate size. At the same time, roots, fungal hyphae, and earthworms create microscopic tunnels that break up peds.
At an even smaller scale, soil aggregation continues as bacteria and fungi exude sticky polysaccharides which bind soil into smaller peds. The addition of the raw organic matter that bacteria and fungi feed upon encourages the formation of this desirable soil structure.
At the lowest scale, the soil chemistry affects the aggregation or dispersal of soil particles. The clay particles contain polyvalent cations which give the faces of clay layers localized negative charges. At the same time, the edges of the clay plates have a slight positive charge, thereby allowing the edges to adhere to the negative charges on the faces of other clay particles or to flocculate (form clumps). On the other hand, when monovalent ions, such as sodium, invade and displace the polyvalent cations, they weaken the positive charges on the edges, while the negative surface charges are relatively strengthened. This leaves negative charge on the clay faces that repel other clay, causing the particles to push apart, and by doing so to prevent the flocculation of clay particles into larger, open assemblages. As a result, the clay disperses and settles into voids between peds, causing those to close. In this way the open structure of the soil is destroyed and the soil is made impenetrable to air and water. Such sodic soil tends to form columnar structures near the surface.
Density.
Soil particle density is typically 2.60 to 2.75 grams per cm3 and is usually unchanging for a given soil. Soil particle density is lower for soils with high organic matter content, and is higher for soils with high iron-oxides content. Soil bulk density is equal to the dry mass of the soil divided by the volume of the soil; i.e., it includes air space and organic materials of the soil volume. The soil bulk density of cultivated loam is about 1.1 to 1.4 g/cm3 (for comparison water is 1.0 g/cm3). Soil bulk density is highly variable for a given soil. A lower bulk density by itself does not indicate suitability for plant growth due to the influence of soil texture and structure. A high bulk density is indicative of either soil compaction or high sand content. Soil bulk density is inherently always less than the soil particle density.
Porosity.
Pore space is that part of the bulk volume of soil that is not occupied by either mineral or organic matter but is open space occupied by either gases or water. Ideally, the total pore space should be 50% of the soil volume. The gas space is needed to supply oxygen to organisms decomposing organic matter, humus, and plant roots. Pore space also allows the movement and storage of water and dissolved nutrients. This property of soils effectively compartmentalizes the soil pore space such that many organisms are not in direct competition with one another, which may explain not only the large number of species present, but the fact that functionally redundant organisms (organisms with the same ecological niche) can co-exist within the same soil.
There are four categories of pores:
In comparison, plant root hairs are 8 to 12 µm in diameter. When pore space is less than 30 µm, the forces of attraction that hold water in place are greater than the gravitational force acting to drain the water. At that point, soil becomes water-logged and it cannot breathe. For a growing plant, pore size is of greater importance than total pore space. A medium-textured loam provides the ideal balance of pore sizes. Having large pore spaces that allow rapid gas and water movement is superior to smaller pore space soil that has a greater percentage pore space. Soil texture determines the pore space at the smallest scale, but at a larger scale, soil structure has a strong influence on soil aeration, water infiltration and drainage. Tillage has the short-term benefit of temporarily increasing the number of pores of largest size, but in the end those will be degraded by the destruction of soil aggregation.
Clay soils have smaller pores, but more total pore space than sand.
Consistency.
Consistency is the ability of soil to stick to itself or to other objects (cohesion and adhesion respectively) and its ability to resist deformation and rupture. It is of approximate use in predicting cultivation problems and the engineering of foundations. Consistency is measured at three moisture conditions: air-dry, moist, and wet. In those conditions the consistency quality depends upon the clay content. In the wet state, the two qualities of stickiness and plasticity are assessed. A soil's resistance to fragmentation and crumbling is assessed in the dry state by rubbing the sample. Its resistance to shearing forces is assessed in the moist state by thumb and finger pressure. Additionally, the cemented consistency depends on cementation by substances other than clay, such as calcium carbonate, silica, oxides and salts; moisture content has little effect on its assessment. The measures of consistency border on subjective compared to other measures such as pH, since they employ the apparent feel of the soil in those states.
The terms used to describe the soil consistency in three moisture states and a last not affected by the amount of moisture are as follows:
Soil consistency is useful in estimating the ability of soil to support buildings and roads. More precise measures of soil strength are often made prior to construction.
Temperature.
Soil temperature depends on the ratio of the energy absorbed to that lost. Soil has a temperature range between -20 to 60 °C. Soil temperature regulates seed germination, plant and root growth and the availability of nutrients. Below 50 cm (20 in), soil temperature seldom changes and can be approximated by adding 1.8 °C (2 °F) to the mean annual air temperature. Soil temperature has important seasonal, monthly and daily variations. Fluctuations in soil temperature are much lower with increasing soil depth. Heavy mulching (a type of soil cover) can slow the warming of soil, and, at the same time, reduce fluctuations in surface temperature.
Most often, agricultural activities must adapt to soil temperatures by:
Otherwise soil temperatures can be raised by drying soils or the use of clear plastic mulches. Organic mulches slow the warming of the soil.
There are various factors that affect soil temperature, such as water content, soil color, and relief (slope, orientation, and elevation), and soil cover (shading and insulation). The color of the ground cover and its insulating properties have a strong influence on soil temperature. Whiter soil tends to have a higher albedo than blacker soil cover, which encourages whiter soils to have cooler soil temperatures. The specific heat of soil is the energy required to raise the temperature of soil by 1 °C. The specific heat of soil increases as water content increases, since the heat capacity of water is greater than that of dry soil. The specific heat of pure water is ~ 1 calorie per gram, the specific heat of dry soil is ~ 0.2 calories per gram and the specific heat of wet soil is ~ 0.2 to 1 calories per gram. Also, tremendous energy (~540 cal/g) is required and dissipated to evaporate water (known as the heat of vaporization). As such, wet soil usually warms more slowly than dry soil - wet surface soil is typically 3 to 6 °C colder than dry surface soil.
Soil heat flux refers to the rate at which heat energy moves through the soil in response to a temperature difference between two points in the soil. The heat flux density is the amount of energy that flows through soil per unit area per unit time and has both magnitude and direction. For the simple case of conduction into or out of the soil in the vertical direction, which is most often applicable the heat flux density is:
In SI units
Heat flux is in the direction opposite the temperature gradient, hence the minus sign. That is to say, if the temperature of the surface is higher than at depth x the negative sign will result in a positive value for the heat flux q, and which is interpreted as the heat being conducted into the soil.
Soil temperature is important for the survival and early growth of seedlings. Soil temperatures affect the anatomical and morphological character of root systems. All physical, chemical, and biological processes in soil and roots are affected in particular because of the increased viscosities of water and protoplasm at low temperatures. In general, climates that do not preclude survival and growth of white spruce above ground are sufficiently benign to provide soil temperatures able to maintain white spruce root systems. In some northwestern parts of the range, white spruce occurs on permafrost sites and although young unlignified roots of conifers may have little resistance to freezing, less than half of the "secondary mature" root system of white spruce was killed by exposure to a temperature of 23.3 °C in multiple year experiment with containerized trees from local nurseries in Massachusetts.
Optimum temperatures for tree root growth range between 10 °C and 25 °C in general and for spruce in particular. In 2-week-old white spruce seedlings that were then grown for 6 weeks in soil at temperatures of 15 °C, 19 °C, 23 °C, 27 °C, and 31 °C; shoot height, shoot dry weight, stem diameter, root penetration, root volume, and root dry weight all reached maxima at 19 °C.
However, whereas strong positive relationships between soil temperature (5 °C to 25 °C) and growth have been found in trembling aspen and balsam poplar, white and other spruce species have shown little or no changes in growth with increasing soil temperature. Such insensitivity to soil low temperature may be common among a number of western and boreal conifers.
Color.
Soil colour is often the first impression one has when viewing soil. Striking colours and contrasting patterns are especially noticeable. The Red River of the South carries sediment eroded from extensive reddish soils like Port Silt Loam in Oklahoma. The Yellow River in China carries yellow sediment from eroding loess soils. Mollisols in the Great Plains of North America are darkened and enriched by organic matter. Podsols in boreal forests have highly contrasting layers due to acidity and leaching.
In general, color is determined by the organic matter content, drainage conditions, and degree of oxidation. Soil color, while easily discerned, has little use in predicting soil characteristics. It is of use in distinguishing boundaries within a soil profile, determining the origin of a soil's parent material, as an indication of wetness and waterlogged conditions, and as a qualitative means of measuring organic, salt and carbonate contents of soils. Color is recorded in the Munsell color system as for instance 10YR3/4 "Dusky Red".
Soil color is primarily influenced by soil mineralogy. Many soil colours are due to various iron minerals. The development and distribution of colour in a soil profile result from chemical and biological weathering, especially redox reactions. As the primary minerals in soil parent material weather, the elements combine into new and colourful compounds. Iron forms secondary minerals of a yellow or red colour, organic matter decomposes into black and brown compounds, and manganese, sulfur and nitrogen can form black mineral deposits. These pigments can produce various colour patterns within a soil. Aerobic conditions produce uniform or gradual colour changes, while reducing environments (anaerobic) result in rapid colour flow with complex, mottled patterns and points of colour concentration.
Resistivity.
Soil resistivity is a measure of a soil's ability to retard the conduction of an electric current. The electrical resistivity of soil can affect the rate of galvanic corrosion of metallic structures in contact with the soil. Higher moisture content or increased electrolyte concentration can lower resistivity and increase conductivity, thereby increasing the rate of corrosion. Soil resistivity values typically range from about 2 to 1000 Ω·m, but more extreme values are not unusual.
Soil water.
Water that enters a field is removed from a field by runoff, drainage, evaporation or transpiration. Runoff is the water that flows on the surface to the edge of the field; drainage is the water that flows through the soil downward or toward the edge of the field underground; evaporative water loss from a field is that part of the water that evaporates into the atmosphere directly from the field's surface; transpiration is the loss of water from the field by its evaporation from the plant itself.
Water affects soil formation, structure, stability and erosion but is of primary concern with respect to plant growth. Water is essential to plants for four reasons:
In addition, water alters the soil profile by dissolving and re-depositing minerals, often at lower levels, and possibly leaving the soil sterile in the case of extreme rainfall and drainage. In a loam soil, solids constitute half the volume, gas one-quarter of the volume, and water one-quarter of the volume of which only half of which will be available to most plants.
A flooded field will drain the gravitational water under the influence of gravity until water's adhesive and cohesive forces resist further drainage at which point it is said to have reached field capacity. At that point, plants must apply suction to draw water from a soil. When soil becomes too dry, the available water is used up and the remaining moisture is called unavailable water as the plant cannot produce sufficient suction to draw that water in. A plant must produce suction that increases from zero for a flooded field to 1/3 bar at field dry condition (one bar is a little less than one atmosphere pressure). At 15 bar suction, wilting percent, seeds will not germinate, plants begin to wilt and then die. Water moves in soil under the influence of gravity, osmosis and capillarity. When water enters the soil, it displaces air from some of the pores, since air content of a soil is inversely related to its water content.
The rate at which a soil can absorb water depends on the soil and its other conditions. As a plant grows, its roots remove water from the largest pores first. Soon the larger pores hold only air, and the remaining water is found only in the intermediate- and smallest-sized pores. The water in the smallest pores is so strongly held to particle surfaces that plant roots cannot pull it away. Consequently, not all soil water is available to plants. When saturated, the soil may lose nutrients as the water drains. Water moves in a drained field under the influence of pressure where the soil is locally saturated and by capillarity pull to dryer parts of the soil. Most plant water needs are supplied from the suction caused by evaporation from plant leaves and 10% is supplied by "suction" created by osmotic pressure differences between the plant interior and the soil water. Plant roots must seek out water. Insufficient water will damage the yield of a crop. Most of the available water is used in transpiration to pull nutrients into the plant.
Water retention forces.
Water is retained in a soil when the adhesive force of attraction that water's hydrogen atoms have for the oxygen of soil particles is stronger than the cohesive forces that water's hydrogen feels for other water oxygen atoms. When a field is flooded, the soil pore space is completely filled by water. The field will drain under the force of gravity until it reaches what is called field capacity, at which point the smallest pores are filled with water and the largest with water and gases. The total amount of water held when field capacity is reached is a function of the specific surface area of the soil particles. As a result, high clay and high organic soils have higher field capacities. The total force required to pull or push water out of soil is termed suction and usually expressed in units of bars (105 pascal, about one atmosphere) which is just a little less than one-atmosphere pressure. Alternatively, the terms "tension" or "moisture potential" may be used.
Moisture classification.
The forces with which water is held in soils determine its availability to plants. Forces of adhesion hold water strongly to mineral and humus surfaces and less strongly to itself by cohesive forces. A plant's root may penetrate a very small volume of water that is adhering to soil and be initially able to draw in water that is only lightly held by the cohesive forces. But as the droplet is drawn down, the forces of adhesion of the water for the soil particles make reducing the volume of water increasingly difficult until the plant cannot produce sufficient suction to use the remaining water. The remaining water is considered unavailable. The amount of available water depends upon the soil texture and humus amounts and the type of plant attempting to use the water. Cacti, for example, can produce greater suction than can agricultural crop plants.
The following description applies to a loam soil and agricultural crops. When a field is flooded, it is said to be saturated and all available air space is occupied by water. The suction required to draw water into a plant root is zero. As the field drains under the influence of gravity (drained water is called gravitational water or drain-able water), the suction a plant must produce to use such water increases to 1/3 bar. At that point, the soil is said to have reached field capacity, and plants that use the water must produce increasingly higher suction, finally up to 15 bar. At 15 bar suction, the soil water amount is called wilting percent. At that suction the plant cannot sustain its water needs as water is still being lost from the plant by transpiration; the plant's turgidity is lost, and it wilts. The next level, called air-dry, occurs at 1000 bar suction. Finally the oven dry condition is reached at 10,000 bar suction. All water below wilting percentage is called unavailable water.
Soil moisture content.
When the soil moisture content is optimal for plant growth, the water in the large and intermediate size pores can move about in the soil and be easily used by plants. The amount of water remaining in a soil drained to field capacity and the amount that is available are functions of the soil type. Sandy soil will retain very little water, while clay will hold the maximum amount. The time required to drain a field from flooded condition for a clay loam that begins at 43% water by weight to a field capacity of 21.5% is six days, whereas a sand loam that is flooded to its maximum of 22% water will take two days to reach field capacity of 11.3% water. The available water for the clay loam might be 11.3% whereas for the sand loam it might be only 7.9% by weight.
The above are average values for the soil textures as the percentage of sand, silt and clay vary within the listed soil textures.
Water flow in soils.
Water moves through soil due to the force of gravity, osmosis and capillarity. At zero to one-third bar suction, water is pushed through soil from the point of its application under the force of gravity and the pressure gradient created by the pressure of the water; this is called saturated flow. At higher suction, water movement is pulled by capillarity from wetter toward dryer soil. This is caused by water's adhesion to soil solids, and is called unsaturated flow.
Water infiltration and movement in soil is controlled by six factors:
Water infiltration rates range from per hour for high clay soils to per hour for sand and well stabilised and aggregated soil structures. Water flows through the ground unevenly, called "gravity fingers", because of the surface tension between water particles.
Tree roots create paths for rainwater flow through soil by breaking though soil including clay layers: one study showed roots increasing infiltration of water by 153% and another study showed an increase by 27 times.
Flooding temporarily increases soil permeability in river beds, helping to recharge aquifers.
Saturated flow.
Water applied to a soil is pushed by pressure gradients from the point of its application where it is saturated locally, to less saturated areas. Once soil is completely wetted, any more water will move downward, or percolate, carrying with it clay, humus and nutrients, primarily cations, out of the range of plant roots. In order of decreasing solubility, the leached nutrients are:
In the United States percolation water due to rainfall ranges from zero inches just east of the Rocky Mountains to twenty or more inches in the Appalachian Mountains and the north coast of the Gulf of Mexico.
Unsaturated flow.
At suctions less than one-third bar, water moves in all directions via unsaturated flow at a rate that is dependent on the square of the diameter of the water-filled pores. Water is pulled by capillary action due to the adhesion force of water to the soil solids, producing a suction gradient from wet towards drier soil. Doubling the diameter of the pores increases the flow rate by a factor of four. Large pores drained by gravity and not filled with water do not greatly increase the flow rate for unsaturated flow. Water flow is primarily from coarse-textured soil into fine-textured soil and is slowest in fine-textured soils such as clay.
Water uptake by plants.
Of equal importance to the storage and movement of water in soil is the means by which plants acquire it and their nutrients. Ninety percent of water is taken up by plants as passive absorption caused by the pulling force of water evaporating (transpiring) from the long column of water that leads from the plant's roots to its leaves. In addition, the high concentration of salts within plant roots creates an osmotic pressure gradient that pushes soil water into the roots. Osmotic absorption becomes more important during times of low water transpiration caused by lower temperatures (for example at night) or high humidity. It is the process that causes guttation.
Root extension is vital for plant survival. A study of a single winter rye plant grown for four months in one cubic foot of loam soil showed that the plant developed 13,800,000 roots, a total of 385 miles in length with 2,550 square feet in surface area; and 14 billion hair roots of 6,600 miles total length and 4,320 square feet total area; for a total surface area of 6,870 square feet (83 ft squared). The total surface area of the loam soil was estimated to be 560,000 square feet. In other words, the roots were in contact with only 1.2% of the soil.
Roots must seek out water as the unsaturated flow of water in soil can move only at a rate of up to 2.5 cm (one inch) per day; as a result they are constantly dying and growing as they seek out high concentrations of soil moisture. Insufficient soil moisture, to the point of causing wilting, will cause permanent damage and crop yields will suffer. When grain sorghum was exposed to soil suction as low as 13.0 bar during the seed head emergence through bloom and seed set stages of growth, its production was reduced by 34%.
Consumptive use and water efficiency.
Only a small fraction (0.1% to 1%) of the water used by a plant is held within the plant. The majority is ultimately lost via transpiration, while evaporation from the soil surface is also substantial. Transpiration plus evaporative soil moisture loss is called evapotranspiration. Evapotranspiration plus water held in the plant totals to consumptive use, which is nearly identical to evapotranspiration.
The total water used in an agricultural field includes runoff, drainage and consumptive use. The use of loose mulches will reduce evaporative losses for a period after a field is irrigated, but in the end the total evaporative loss will approach that of an uncovered soil. The benefit from mulch is to keep the moisture available during the seedling stage. Water use efficiency is measured by transpiration ratio, which is the ratio of the total water transpired by a plant to the dry weight of the harvested plant. Transpiration ratios for crops range from 300 to 700. For example, alfalfa may have a transpiration ratio of 500 and as a result 500 kilograms of water will produce one kilogram of dry alfalfa. 
Soil atmosphere.
The atmosphere of soil is radically different from the atmosphere above. The consumption of oxygen, by microbes and plant roots and their release of carbon dioxide, decrease oxygen and increase carbon dioxide concentration. Atmospheric CO2 concentration is 0.04%, but in the soil pore space it may range from 10 to 100 times that level. At extreme levels CO2 is toxic. In addition, the soil voids are saturated with water vapour. Adequate porosity is necessary, not just to allow the penetration of water, but also to allow gases to diffuse in and out. Movement of gases is by diffusion from high concentrations to lower. Oxygen diffuses in and is consumed and excess levels of carbon dioxide, diffuse out with other gases as well as water. Soil texture and structure strongly affect soil porosity and gas diffusion. It is the total pore space (porosity) of soil not the pore size that determines the rate of diffusion of gases into and out of soil. A Platy soil structure and compacted soils (low porosity) impede gas flow, and a deficiency of oxygen may encourage anaerobic bacteria to reduce (strip oxygen) from nitrate NO3 to the gases N2, N2O, and NO, which are then lost to the atmosphere, thereby depleting the soil of nitrogen. Aerated soil is also a net sink of methane CH4 but a net producer of greenhouse gases when soils are depleted of oxygen and subject to elevated temperatures.
Composition of soil particles.
Soil particles can be classified by their chemical composition (mineralogy) as well as their size. The particle size distribution of a soil, its texture, determines many of the properties of that soil, but the mineralogy of those particles can strongly modify those properties. The mineralogy of the finest soil particles, clay, is especially important.
Gravel, sand and silt.
Gravel, sand and silt are the larger soil particles, and their mineralogy is often inherited from the parent material of the soil, but may include products of weathering (such as concretions of calcium carbonate or iron oxide), or residues of plant and animal life (such as silica phytoliths). Quartz is the most common mineral in the sand or silt fraction as it is resistant to chemical weathering; other common minerals are felspars, micas and ferromagnesian minerals such as pyroxenes, amphiboles and olivines.
Mineral colloids; soil clays.
Due to its high specific surface area and its unbalanced negative charges, clay is the most active mineral component of soil. It is a colloidal and most often a crystalline material. In soils, clay is defined in a physical sense as any mineral particle less than in effective diameter. Chemically, clay is a range of minerals with certain reactive properties. Clay is also a soil textural class. Many soil minerals, such as gypsum, carbonates, or quartz, are small enough to be classified as clay based on their physical size, but chemically they do not afford the same utility as do clay minerals.
Clay was once thought to be very small particles of quartz, feldspar, mica, hornblende or augite, but it is now known to be (with the exception of mica-based clays) a precipitate with a mineralogical composition that is dependent on but different from its parent materials and is classed as a secondary mineral. The type of clay that is formed is a function of the parent material and the composition of the minerals in solution. Clay minerals continue to be formed as long as the soil exists. Mica-based clays result from a modification of the primary mica mineral in such a way that it behaves and is classed as a clay. Most clays are crystalline, but some are amorphous. The clays of a soil are a mixture of the various types of clay, but one type predominates.
There are four groups of clay: layer silicates; crystalline chain silicates; metal oxides and hydroxides and oxy-oxides; and amorphous and allophanes. Most clays are crystalline and most are made up of three or four planes of oxygen held together by planes of aluminium and silicon by way of ionic bonds that together form a single layer of clay. The spatial arrangement of the oxygen atoms determines clay's structure. Half of the weight of clay is oxygen, but on a volume basis oxygen is ninety percent. The layers of clay are sometimes held together through hydrogen bonds or potassium bridges and as a result will swell less in the presence of water. Other clays, such as montmorillonite, have layers that are loosely attached and will swell greatly when water intervenes between the layers.
There are four groups of clays:
Alumino-silica clays.
Alumino-silica clays are characterised by their regular crystalline structure. Oxygen in ionic bonds with silicon forms a tetrahedral coordination (silicon at the center) which in turn forms sheets of silica. Two sheets of silica are bonded together by a plane of aluminium which forms an octahedral coordination, called alumina, with the oxygens of the silica sheet above and that below it. Hydroxyl ions (OH−) sometimes substitute for oxygen. During the clay formation process, Al3+ may substitute for Si4+, and as much as one fourth of the aluminium Al3+ may be substituted by Zn2+, Mg2+ or Fe2+. The substitution of lower-valence cations for higher-valence cations (isomorphous substitution) gives clay a local negative charge on an oxygen atom that attracts and holds water and positively charged soil cations, some of which are of value for plant growth. Isomorphous substitution occurs during the clay's formation and does not change with time.
Crystalline chain clays.
The carbonate and sulfate minerals are much more soluble and hence are found primarily in desert soils.
Amorphous clays.
Amorphous clays are young, and commonly found in volcanic ash. They are mixtures of alumina and silica which have not formed the ordered crystal shape of alumino-silica clays which time would provide. The majority of their negative charges originates from hydroxyl ions, which can gain or lose a hydrogen ion (H+) in response to soil pH, in such way was as to buffer the soil pH. They may have either a negative charge provided by the attached hydroxyl ion (OH−), which can attract a cation, or lose the hydrogen of the hydroxyl to solution and display a positive charge which can attract anions. As a result, they may display either high CEC in an acid soil solution, or high anion exchange capacity in a basic soil solution.
Sesquioxide clays.
Sesquioxide clays are a product of heavy rainfall that has leached most of the silica from alumino-silica clay, leaving the less soluble oxides iron hematite (Fe2O3), iron hydroxide (Fe(OH)3), aluminium hydroxide gibbsite (Al(OH)3), hydrated manganese birnessite (MnO2). It takes hundreds of thousands of years of leaching to create sesquioxide clays. "Sesqui" is Latin for "one and one-half": there are three parts oxygen to two parts iron or aluminium; hence the ratio is one and one-half (not true for all). They are hydrated and act as either amorphous or crystalline. They are not sticky and do not swell, and soils high in them behave much like sand and can rapidly pass water. They are able to hold large quantities of phosphates. Sesquioxides have low CEC but are able to hold anions as well as cations. Such soils range from yellow to red in colour. Such clays tend to hold phosphorus so tightly that it is unavailable for absorption by plants.
Organic colloids.
Humus is the penultimate state of decomposition of organic matter; while it may linger for a thousand years, on the larger scale of the age of the mineral soil components, it is temporary. It is composed of the very stable lignins (30%) and complex sugars (polyuronides, 30%), proteins (30%), waxes, and fats that are resistant to breakdown by microbes. Its chemical assay is 60% carbon, 5% nitrogen, some oxygen and the remainder hydrogen, sulfur, and phosphorus. On a dry weight basis, the CEC of humus is many times greater than that of clay.
Carbon and terra preta.
In the extreme environment of high temperatures and the leaching caused by the heavy rain of tropical rain forests, the clay and organic colloids are largely destroyed. The heavy rains wash the alumino-silicate clays from the soil leaving only sesquioxide clays of low CEC. The high temperatures and humidity allow bacteria and fungi to virtually dissolve any organic matter on the rain-forest floor overnight and much of the nutrients are volatilized or leached from the soil and lost. However, carbon in the form of charcoal is far more stable than soil colloids and is capable of performing many of the functions of the soil colloids of sub-tropical soils. Soil containing substantial quantities of charcoal, of an anthropogenic origin, is called terra preta. Research into terra preta is still young but is promising. Fallow periods "on the Amazonian Dark Earths can be as short as 6 months, whereas fallow periods on oxisols are usually 8 to 10 years long"
Soil chemistry.
The chemistry of a soil determines its ability to supply available plant nutrients and affects its physical properties and the health of its microbial population. In addition, a soil's chemistry also determines its corrosivity, stability, and ability to absorb pollutants and to filter water. It is the surface chemistry of mineral and organic colloids that determines soil's chemical properties. "A colloid is a small, insoluble, nondiffusible particle larger than a molecule but small enough to remain suspended in a fluid medium without settling. Most soils contain organic colloidal particles called humus as well as the inorganic colloidal particles of clays." The very high specific surface area of colloids and their net charges, gives soil its great ability to hold and release ions. Negatively charged sites on colloids attract and release cations in what is referred to as cation exchange. Cation-exchange capacity (CEC) is the amount of exchangeable cations per unit weight of dry soil and is expressed in terms of milliequivalents of positively charged ions per 100 grams of soil (or centimoles of positive charge per kilogram of soil; cmolc/kg). Similarly, positively charged sites on colloids can attract and release anions in the soil giving the soil anion exchange capacity (AEC).
Cation and anion exchange.
The cation exchange, that takes place between colloids and soil water, buffers (moderates) soil pH, alters soil structure, and purifies percolating water by adsorbing cations of all types, both useful and harmful.
The negative or positive charges on colloid particles make them able to hold cations or anions, respectively, to their surfaces. The charges result from four sources.
Cations held to the negatively charged colloids resist being washed downward by water and out of reach of plants' roots, thereby preserving the fertility of soils in areas of moderate rainfall and low temperatures.
There is a hierarchy in the process of cation exchange on colloids, as they differ in the strength of adsorption by the colloid and hence their ability to replace one another. If present in equal amounts in the soil water solution:
Al3+ replaces H+ replaces Ca2+ replaces Mg2+ replaces K+ same as NH4+ replaces Na+
If one cation is added in large amounts, it may replace the others by the sheer force of its numbers. This is called mass action. This is largely what occurs with the addition of fertiliser.
As the soil solution becomes more acidic (an abundance of H+), the other cations more weakly bound to colloids are pushed into solution and hydrogen ions occupy those sites. A low pH may cause hydrogen of hydroxyl groups to be pulled into solution, leaving charged sites on the colloid available to be occupied by other cations. This ionisation of hydroxyl groups on the surface of soil colloids creates what is described as pH-dependent charges. Unlike permanent charges developed by isomorphous substitution, pH-dependent charges are variable and increase with increasing pH. Freed cations can be made available to plants but are also prone to be leached from the soil, possibly making the soil less fertile. Plants are able to excrete H+ into the soil and by that means, change the pH of the soil near the root and push cations off the colloids, thus making those available to the plant.
Cation exchange capacity (CEC).
Cation exchange capacity should be thought of as the soil's ability to remove cations from the soil water solution and sequester those to be exchanged later as the plant roots release hydrogen ions to the solution. CEC is the amount of exchangeable hydrogen cation (H+) that will combine with 100 grams dry weight of soil and whose measure is one milliequivalents per 100 grams of soil (1 meq/100 g). Hydrogen ions have a single charge and one-thousandth of a gram of hydrogen ions per 100 grams dry soil gives a measure of one milliequivalent of hydrogen ion. Calcium, with an atomic weight 40 times that of hydrogen and with a valence of two, converts to (40/2) x 1 milliequivalent = 20 milliequivalents of hydrogen ion per 100 grams of dry soil or 20 meq/100 g. The modern measure of CEC is expressed as centimoles of positive charge per kilogram (cmol/kg) of oven-dry soil.
Most of the soil's CEC occurs on clay and humus colloids, and the lack of those in hot, humid, wet climates, due to leaching and decomposition respectively, explains the relative sterility of tropical soils. Live plant roots also have some CEC.
Anion exchange capacity (AEC).
Anion exchange capacity should be thought of as the soil's ability to remove anions from the soil water solution and sequester those for later exchange as the plant roots release carbonate anions to the soil water solution. Those colloids which have low CEC tend to have some AEC. Amorphous and sesquioxide clays have the highest AEC, followed by the iron oxides. Levels of AEC are much lower than for CEC. Phosphates tend to be held at anion exchange sites.
Iron and aluminum hydroxide clays are able to exchange their hydroxide anions (OH−) for other anions. The order reflecting the strength of anion adhesion is as follows:
The amount of exchangeable anions is of a magnitude of tenths to a few milliequivalents per 100 g dry soil. As pH rises, there are relatively more hydroxyls, which will displace anions from the colloids and force them into solution and out of storage; hence AEC decreases with increasing pH (alkalinity).
Soil reaction (pH).
Soil reactivity is expressed in terms of pH and is a measure of the acidity or alkalinity of the soil. More precisely, it is a measure of hydrogen ion concentration in an aqueous solution and ranges in values from 0 to 14 (acidic to basic) but practically speaking for soils, pH ranges from 3.5 to 9.5, as pH values beyond those extremes are toxic to life forms.
Soil pH.
At 25 °C an aqueous solution that has a pH of 3.5 has 10−3.5 moles H+ (hydrogen ions) per litre of solution (and also 10−10.5 mole/litre OH−). A pH of 7, defined as neutral, has 10−7 moles hydrogen ions per litre of solution and also 10−7 moles of OH− per litre; since the two concentrations are equal, they are said to neutralise each other. A pH of 9.5 has 10−9.5 moles hydrogen ions per litre of solution (and also 10−2.5 mole per litre OH−). A pH of 3.5 has one million times more hydrogen ions per litre than a solution with pH of 9.5 (9.5 - 3.5 = 6 or 106) and is more acidic.
The effect of pH on a soil is to remove from the soil or to make available certain ions. Soils with high acidity tend to have toxic amounts of aluminium and manganese. Plants which need calcium need moderate alkalinity, but most minerals are more soluble in acid soils. Soil organisms are hindered by high acidity, and most agricultural crops do best with mineral soils of pH 6.5 and organic soils of pH 5.5.
In high rainfall areas, soils tend to acidity as the basic cations are forced off the soil colloids by the mass action of hydrogen ions from the rain as those attach to the colloids. High rainfall rates can then wash the nutrients out, leaving the soil sterile. Once the colloids are saturated with H+, the addition of any more hydrogen ions or aluminum hydroxyl cations drives the pH even lower (more acidic) as the soil has been left with no buffering capacity. In areas of extreme rainfall and high temperatures, the clay and humus may be washed out, further reducing the buffering capacity of the soil. In low rainfall areas, unleached calcium pushes pH to 8.5 and with the addition of exchangeable sodium, soils may reach pH 10. Beyond a pH of 9, plant growth is reduced. High pH results in low micro-nutrient mobility, but water-soluble chelates of those nutrients can supply the deficit. Sodium can be reduced by the addition of gypsum (calcium sulphate) as calcium adheres to clay more tightly than does sodium causing sodium to be pushed into the soil water solution where it can be washed out by an abundance of water.
Base saturation percentage.
There are acid-forming cations (hydrogen and aluminium) and there are base-forming cations. The fraction of the base-forming cations that occupy positions on the soil colloids is called the base saturation percentage. If a soil has a CEC of 20 meq and 5 meq are aluminium and hydrogen cations (acid-forming), the remainder of positions on the colloids (20-5 = 15 meq) are assumed occupied by base-forming cations, so that the percentage base saturation is 15/20 x 100% = 75% (the compliment 25% is assumed acid-forming cations). When the soil pH is 7 (neutral), base saturation is 100 percent and there are no hydrogen ions stored on the colloids. Base saturation is almost in direct proportion to pH (increases with increasing pH). It is of use in calculating the amount of lime needed to neutralise an acid soil. The amount of lime needed to neutralize a soil must take account of the amount of acid forming ions on the colloids not just those in the soil water solution. The addition of enough lime to neutralize the soil water solution will be insufficient to change the pH, as the acid forming cations stored on the soil colloids will tend to restore the original pH condition as they are pushed off those colloids by the calcium of the added lime.
Buffering of soils.
The resistance of soil to changes in pH as a result of the addition of acid or basic material is a measure of the buffering capacity of a soil and increases as the CEC increases. Hence, pure sand has almost no buffering ability, while soils high in colloids have high buffering capacity. Buffering occurs by cation exchange and neutralisation.
The addition of a small amount highly basic aqueous ammonia to a soil will cause the ammonium to displace hydrogen ions from the colloids, and the end product is water and colloidally fixed ammonium, but no permanent change overall in soil pH.
The addition of a small amount of lime, CaCO3, will displace hydrogen ions from the soil colloids, causing the fixation of calcium to colloids and the evolution of CO2 and water, with no permanent change in soil pH.
The addition of carbonic acid (the solution of CO2 in water) will displace calcium from colloids, as hydrogen ions are fixed to the colloids, evolving water and slightly alkaline (temporary increase in pH) highly soluble calcium bicarbonate, which will then precipitate as lime (CaCO3) and water at a lower level in the soil profile, with the result of no permanent change in soil pH.
All of the above are examples of the buffering of soil pH. The general principal is that an increase in a particular cation in the soil water solution will cause that cation to be fixed to colloids (buffered) and a decrease in solution of that cation will cause it to be withdrawn from the colloid and moved into solution (buffered). The degree of buffering is limited by the CEC of the soil; the greater the CEC, the greater the buffering capacity of the soil.
Nutrients.
Sixteen elements or nutrients are essential for plant growth and reproduction. They are carbon C, hydrogen H, oxygen O, nitrogen N, phosphorus P, potassium K, sulfur S, calcium Ca, magnesium Mg, iron Fe, boron B, manganese Mn, copper Cu, zinc Zn, molybdenum Mo, and chlorine Cl. Nutrients required for plants to complete their life cycle are considered essential nutrients. Nutrients that enhance the growth of plants but are not necessary to complete the plant's life cycle are considered non-essential. With the exception of carbon, hydrogen and oxygen, which are supplied by carbon dioxide and water, the nutrients derive originally from the mineral component of the soil. Although minerals are the origin of those nutrients, the organic component of the soil is the reservoir of the majority of readily available plant nutrients. For the nutrients to be available to plants, they must be in the proper ionic form (with the exception of water and CO2). For example, the application of finely ground minerals, feldspar and apatite, to soil does not provide the necessary amounts of potassium and phosphorus for good plant growth. Nitrogen is the primary limiting nutrient and phosphorus is second to nitrogen as the primary nutrient for plants, animals and microorganisms.
The provision of plant nutrition involves chemical, biological, and physical processes. Nearly all plant nutrients are taken up from the soil water solution in the form of ions, either cations or as anions. In an effort to gain nutrients, plants will release ions to the soil. Bicarbonate (HCO3−) and hydroxyl (OH−) anions released from plant roots enhance the absorption of nutrient anions; similarly, hydrogen cations are released in exchange for cation forms of nutrients. As a result, nutrient ions are pushed into the soil water solution from their sequestration on colloids to become available to plants. Nitrogen, for example, is available in soil organic material but is unusable by plants until it is made available by that material's decomposition by micro-organisms into cation or anion forms. The NH4+ (ammonium) and NO3− (nitrate) forms of nitrogen are stored on the soil colloids until forced off those by the presence of other cations and anions. After that, they will move by physical means to near the plant roots. Generally, plant roots can readily absorb all of the nutrients from the soil solution, provided there is enough oxygen gas in the soil to support root metabolism.
The bulk of most nutrient elements in the soil is held in the form of primary and secondary minerals, and organic matter. The primary minerals (mostly rock dust in the form of silt) hold the nutrients too tightly to be readily available; the nutrients adsorbed onto the colloids clay and humus are moderately available; and the soil water solution has ions that are freely available for absorption by plant roots. Gram for gram, the capacity of humus to hold nutrients and water is far greater than that of clay. All in all, small amounts of humus may remarkably increase the soil's capacity to promote plant growth.
Mechanism of nutrient uptake.
All the nutrients with the exception of carbon are taken up by the plant through its roots. To be taken up by a plant, a nutrient element must be in an ionic form (with the exception of water and H3BO3) and must be located at the root surface. Often, parts of a root are in such intimate contact with soil particles that a direct exchange may take place between nutrient ions adsorbed on the surface of the soil colloids and hydrogen ions from the surface of root cell walls. In any case, the supply of nutrients in contact with the root would soon be depleted. There are three basic mechanisms by which the concentration of nutrient ions dissolved in the soil solution are brought into contact with plant roots:
All three mechanisms operate simultaneously, but one mechanism or another may be most important for a particular nutrient. For example, in the case of calcium, which is generally plentiful in the soil solution, mass flow alone can usually bring sufficient amounts to the root surface. However, in the case of phosphorus, diffusion is needed to supplement mass flow. For the most part, nutrient ions must travel some distance in the soil solution to reach the root surface. This movement can take place by mass flow, as when dissolved nutrients are carried along with the soil water flowing toward a root that is actively drawing water from the soil. In this type of movement, the nutrient ions are somewhat analogous to leaves floating down a stream. In addition, nutrient ions continually move by diffusion from areas of greater concentration toward the nutrient-depleted areas of lower concentration around the root surface. That process is due to random motion of molecules. By this means, plants can continue to take up nutrients even at night, when water is only slowly absorbed into the roots as transpiration has almost stopped. Finally, root interception comes into play as roots continually grow into new, undepleted soil.
Because nutrient uptake is an active metabolic process, conditions that inhibit root metabolism may also inhibit nutrient uptake. Examples of such conditions include excessive soil water content or soil compaction resulting in poor soil aeration, excessively high or low soil temperatures, and above-ground conditions that result in low translocation of sugars to plant roots. A maize plant will use one quart of water per day at the height of its growing season.
In the above table, phosphorus and potassium nutrients move more by diffusion than they do by mass flow in the soil water solution, as they are rapidly taken up by the roots creating a concentration of almost zero near the roots (the plants cannot transpire enough water to draw more of those nutrients near the roots). The very steep concentration gradient is of greater influence in the movement of those ions than is the movement of those by mass flow. The movement by mass flow requires the transpiration of water from the plant causing water and solution ions to also move toward the roots. Movement by root interception is slowest as the plants must extend their roots. Plants move ions out of their roots in an effort to move nutrients in from the soil. Hydrogen H+ is exchanged for other cations, and carbonate (HCO3−) and hydroxide (OH−) anions are exchanged for nutrient anions. Plants derive most of their anion nutrients from decomposing organic matter, which holds 95 percent of the nitrogen, 5 to 60 percent of the phosphorus and 80 percent of the sulfur. As plant roots remove nutrients from the soil water solution, nutrients are added to the soil water as other ions move off of clay and humus, are added from the decomposition of soil minerals, and are released by the decomposition of organic matter. Where crops are produced, the replenishment of nutrients in the soil must be augmented by the addition of fertilizer or organic matter.
Carbon.
Plants obtain their carbon from atmospheric carbon dioxide. A plant's weight is forty-five percent carbon. Elementally, carbon is 50% of plant material. Plant residues typically have a carbon to nitrogen ratio (C/N) of 50:1. As the soil organic material is digested by arthropods and micro-organisms, the C/N decreases as the carbonaceous material is metabolised and carbon dioxide (CO2) is released as a byproduct which then finds its way out of the soil and into the atmosphere. The nitrogen, and other nutrients however, is sequestered in the bodies of the living matter of those decomposing organisms and so it builds up in the soil. Normal CO2 concentration in the atmosphere is 0.03%, which is probably the factor limiting plant growth. In a field of maize on a still day during high light conditions in the growing season, the CO2 concentration drops very low, but under such conditions the crop could use up to 20 times the normal concentration. The respiration of CO2 by soil micro-organisms decomposing soil organic matter contributes an important amount of CO2 to the photosynthesising plants. Within the soil, CO2 concentration is 10 to 100 times that of atmospheric levels but may rise to toxic levels if the soil porosity is low or if diffusion is impeded by flooding.
Nitrogen.
Nitrogen is the most critical element obtained by plants from the soil and is a bottleneck in plant growth. Plants can use the nitrogen as either the ammonium cation (NH4+) or the anion nitrate (NO3−). Nitrogen is seldom missing in the soil, but is often in the form of raw organic material which cannot be used directly. The total nitrogen content depends on the climate, vegetation, topography, age and soil management. Soil nitrogen typically decreases by 0.2 to 0.3% for every temperature increase by 10 °C. Usually, more nitrogen is under grassland than under forest. Humus formation promotes nitrogen immobilization. Cultivation decreases soil nitrogen by exposing soil to more air which the bacteria can use, and no-tillage maintains more nitrogen than tillage.
Some micro-organisms are able to metabolise organic matter and release ammonium in a process called "mineralisation". Others take free ammonium and oxidise it to nitrate. Particular bacteria are capable of metabolising N2 into the form of nitrate in a process called nitrogen fixation. Both ammonium and nitrate can be "immobilized" or essentially lost from the soil by its incorporation into the microbes' living cells, where it is temporarily sequestered in the form of amino acids and protein. Nitrate may also be lost from the soil when bacteria metabolise it to the gases N2 and N2O. The loss of gaseous forms of nitrogen to the atmosphere due to microbial action is called "denitrification". Nitrogen may also be "leached" from the soil if it is in the form of nitrate or lost to the atmosphere as ammonia due to a chemical reaction of ammonium with alkaline soil by way of a process called "volatilisation". Ammonium may also be sequestered in clay by "fixation". A small amount of nitrogen is added to soil by rainfall.
Nitrogen gains.
In the process of mineralisation, microbes feed on organic matter, releasing ammonia (NH3) (which may be reduced to ammonium (NH4+) and other nutrients. As long as the carbon to nitrogen ratio (C/N) in the soil is above 30:1, nitrogen will be in short supply and other bacteria will feed on the ammonium and incorporate its nitrogen into their cells in the immobilization process. In that form the nitrogen is said to be "immobilised". Later, when such bacteria die, they too are "mineralised" and some of the nitrogen is released as ammonium and nitrate. If the C/N is less than 15, ammonia is freed to the soil, where it may be used by bacteria which oxidise it to nitrate (nitrification). Bacteria may on average add nitrogen per acre, and in an unfertilised field, this is the most important source of usable nitrogen. In a soil with 5% organic matter perhaps 2 to 5% of that is released to the soil by such decomposition. It occurs fastest in warm, moist, well aerated soil. The mineralisation of 3% of the organic material of a soil that is 4% organic matter overall, would release of nitrogen as ammonium per acre.
In nitrogen fixation, rhizobium bacteria convert N2 to nitrate (NO3−). Rhizobia share a symbiotic relationship with host plants, since rhizobia supply the host with nitrogen and the host provides rhizobia with nutrients and a safe environment. It is estimated that such symbiotic bacteria in the root nodules of legumes add 45 to 250 pounds of nitrogen per acre per year, which may be sufficient for the crop. Other, free-living nitrogen-fixing bacteria and blue-green algae live independently in the soil and release nitrate when their dead bodies are converted by way of mineralisation.
Some amount of usable nitrogen is fixed by lightning as nitric oxide (NO) and nitrogen dioxide (NO2−). Nitrogen dioxide is soluble in water to form nitric acid (HNO3) solution of H+ and NO3−. Ammonia, NH3, previously released from the soil or from combustion, may fall with precipitation as nitric acid at a rate of about five pounds nitrogen per acre per year.
Nitrogen sequestration.
When bacteria feed on soluble forms of nitrogen (ammonium and nitrate), they temporarily sequester that nitrogen in their bodies in a process called "immobilisation". At a later time when those bacteria die, their nitrogen may be released as ammonium by the processes of mineralisation.
Protein material is easily broken down, but the rate of its decomposition is slowed by its attachment to the crystalline structure of clay and when trapped between the clay layers. The layers are small enough that bacteria cannot enter. Some organisms can exude extracellular enzymes that can act on the sequestered proteins. However, those enzymes too may be trapped on the clay crystals.
Ammonium fixation occurs when ammonium pushes potassium ions from between the layers of clay such as illite or montmorillonite. Only a small fraction of nitrogen is held this way.
Nitrogen losses.
Usable nitrogen may be lost from soils when it is in the form of nitrate, as it is easily leached. Further losses of nitrogen occur by denitrification, the process whereby soil bacteria convert nitrate (NO3−) to nitrogen gas, N2 or N2O. This occurs when poor soil aeration limits free oxygen, forcing bacteria to use the oxygen in nitrate for their respiratory process. Denitrification increases when oxidisable organic material is available and when soils are warm and slightly acidic. Denitrification may vary throughout a soil as the aeration varies from place to place. Denitrification may cause the loss of 10 to 20 percent of the available nitrates within a day and when conditions are favourable to that process, losses of up to 60 percent of nitrate applied as fertiliser may occur.
"Ammonium volatilisation" occurs when ammonium reacts chemically with an alkaline soil, converting NH4+ to NH3. The application of ammonium fertiliser to such a field can result in volatilisation losses of as much as 30 percent.
Phosphorus.
Phosphorus is the second most critical plant nutrient. The soil mineral apatite is the most common mineral source of phosphorus. While there is on average 1000 lb of phosphorus per acre in the soil, it is generally unavailable in the form of phosphates of low solubility. Total phosphorus is about 0.1 percent by weight of the soil, but only one percent of that is available. Of the part available, more than half comes from the mineralisation of organic matter. Agricultural fields may need to be fertilised to make up for the phosphorus that has been removed in the crop.
When phosphorus does form solubilised ions of H2PO4−, they rapidly form insoluble phosphates of calcium or hydrous oxides of iron and aluminum. Phosphorus is largely immobile in the soil and is not leached but actually builds up in the surface layer if not cropped. The application of soluble fertilisers to soils may result in zinc deficiencies as zinc phosphates form. Conversely, the application of zinc to soils may immobilise phosphorus again as zinc phosphate. Lack of phosphorus may interfere with the normal opening of the plant leaf stomata, resulting in plant temperatures 10 percent higher than normal. Phosphorus is most available when soil pH is 6.5 in mineral soils and 5.5 in organic soils.
Potassium.
The amount of potassium in a soil may be as much as 80,000 lb per acre-foot, of which only 150 lb is available for plant growth. Common mineral sources of potassium are the mica biotite and potassium feldspar, KAlSi3O8. When solubilised, half will be held as exchangeable cations on clay while the other half is in the soil water solution. Potassium fixation often occurs when soils dry and the potassium is bonded between layers of illite clay. Under certain conditions, dependent on the soil texture, intensity of drying, and initial amount of exchangeable potassium, the fixed percentage may be as much as 90 percent within ten minutes. Potassium may be leached from soils low in clay.
Calcium.
Calcium is one percent by weight of soils and is generally available but may be low as it is soluble and can be leached. It is thus low in sandy and heavily leached soil or strongly acidic mineral soil. Calcium is supplied to the plant in the form of exchangeable ions and moderately soluble minerals. Calcium is more available on the soil colloids than is potassium because the common mineral calcite, CaCO3, is more soluble than potassium-bearing minerals.
Magnesium.
Magnesium is central to chlorophyll and aids in the uptake of phosphorus. The minimum amount of magnesium required for plant health is not sufficient for the health of forage animals. A common mineral source of magnesium is the black mica mineral, biotite. Magnesium is generally available in soil, but is missing from some along the Gulf and Atlantic coasts of the United States due to leaching by heavy precipitation.
Sulfur.
Sulfur is essential to the formation of proteins and chlorophyll, and essential to plant vitamin synthesis. Most sulfur is made available to plants, like phosphorus, by its release from decomposing organic matter. Deficiencies may exist in some soils and if cropped, sulfur needs to be added. The application of large quantities of nitrogen to fields that have marginal amounts of sulfur may cause sulfur deficiency in the rapidly growing plants by the plant's growth outpacing the supply of sulfur. A 15-ton crop of onions uses up to 19 lb of sulfur and 4 tons of alfalfa uses 15 lb per acre. Sulfur abundance varies with depth. In a sample of soils in Ohio, United States, the sulfur abundance varied with depths, 0-6 inches, 6-12 inches, 12-18 inches, 18-24 inches in the amounts: 1056, 830, 686, 528 lb per acre respectively.
Micronutrients.
The micronutrients essential for plant life, in their order of importance, include iron, manganese, zinc, copper, boron, chlorine and molybdenum. The term refers to plants' needs, not to their abundance in soil. They are required in very small amounts but are essential to plant health in that most are required parts of some enzyme system which speeds up plants' metabolisms. They are generally available in the mineral component of the soil, but the heavy application of phosphates can cause a deficiency in zinc and iron by the formation of insoluble zinc and iron phosphates. Iron deficiency may also result from excessive amounts of heavy metals or calcium minerals (lime) in the soil. Excess amounts of soluble boron, molybdenum and chloride are toxic.
Non-essential nutrients.
Nutrients which enhance the health but whose deficiency does not stop the life cycle of plants include: cobalt, strontium, vanadium, silicon and nickel. As their importance are evaluated they may be added to the list of essential plant nutrients.
Soil organic matter.
Soil organic matter is made up of organic compounds and includes plant, animal and microbial material, both living and dead. A typical soil has a biomass composition of 70% microorganisms, 22% macrofauna, and 8% roots. The living component of an acre of soil may include 900 lb of earthworms, 2400 lb of fungi, 1500 lb of bacteria, 133 lb of protozoa and 890 lb of arthropods and algae.
A small part of the organic matter consists of the living cells such as bacteria, molds, and actinomycetes that work to break down the dead organic matter. Were it not for the action of these micro-organisms, the entire carbon dioxide part of the atmosphere would be sequestered as organic matter in the soil.
Chemically, organic matter is classed as follows:
Most living things in soils, including plants, insects, bacteria, and fungi, are dependent on organic matter for nutrients and/or energy. Soils have organic compounds in varying degrees of decomposition which rate is dependent on the temperature, soil moisture, and aeration. Bacteria and fungi feed on the raw organic matter, which are fed upon by amoebas, which in turn are fed upon by nematodes and arthropods. Organic matter holds soils open, allowing the infiltration of air and water, and may hold as much as twice its weight in water. Many soils, including desert and rocky-gravel soils, have little or no organic matter. Soils that are all organic matter, such as peat (histosols), are infertile. In its earliest stage of decomposition, the original organic material is often called raw organic matter. The final stage of decomposition is called humus.
In grassland, much of the organic matter added to the soil is from the deep, fibrous, grass root systems. By contrast, tree leaves falling on the forest floor are the principal source of soil organic matter in the forest. Another difference is the frequent occurrence in the grasslands of fires that destroy large amounts of aboveground material but stimulate even greater contributions from roots. Also, the much greater acidity under any forests inhibits the action of certain soil organisms that otherwise would mix much of the surface litter into the mineral soil. As a result, the soils under grasslands generally develop a thicker A horizon with a deeper distribution of organic matter than in comparable soils under forests, which characteristically store most of their organic matter in the forest floor (O horizon) and thin A horizon.
Humus.
Humus refers to organic matter that has been decomposed by soil flora and fauna to the point where it is resistant to further breakdown. Humus usually constitutes only five percent of the soil or less by volume, but it is an essential source of nutrients and adds important textural qualities crucial to soil health and plant growth. Humus also hold bits of undecomposed organic matter which feed arthropods and worms which further improve the soil. The end product, humus, is soluble in water and forms a weak acid that can attack silicate minerals. Humus is a colloid with a high cation and anion exchange capacity that on a dry weight basis is many times greater than that of clay colloids. It also acts as a buffer, like clay, against changes in pH and soil moisture.
Humic acids and fulvic acids, which begin as raw organic matter, are important constituents of humus. After the death of plants and animals, microbes begin to feed on the residues, resulting finally in the formation of humus. With decomposition, there is a reduction of water-soluble constituents, cellulose and hemicellulose, and nutrients such as nitrogen, phosphorus, and sulfur. As the residues break down, only stable molecules made of aromatic carbon rings, oxygen and hydrogen remain in the form of humin, lignin and lignin complexes collectively called humus. While the structure of humus has few nutrients, it is able to attract and hold cation and anion nutrients by weak bonds that can be released into the soil solution in response to changes in soil pH.
Lignin is resistant to breakdown and accumulates within the soil. It also reacts with amino acids, which further increases its resistance to decomposition, including enzymatic decomposition by microbes. Fats and waxes from plant matter have some resistance to decomposition and persist in soils for a while. Clay soils often have higher organic contents that persist longer than soils without clay as the organic molecules adhere to and are stabilised by the clay. Proteins normally decompose readily, but when bound to clay particles, they become more resistant to decomposition. Clay particles also absorb the enzymes exuded by microbes which would normally break down proteins. The addition of organic matter to clay soils can render that organic matter and any added nutrients inaccessible to plants and microbes for many years. High soil tannin (polyphenol) content can cause nitrogen to be sequestered in proteins or cause nitrogen immobilisation.
Humus formation is a process dependent on the amount of plant material added each year and the type of base soil. Both are affected by climate and the type of organisms present. Soils with humus can vary in nitrogen content but typically have 3 to 6 percent nitrogen. Raw organic matter, as a reserve of nitrogen and phosphorus, is a vital component affecting soil fertility. Humus also absorbs water, and expands and shrinks between dry and wet states, increasing soil porosity. Humus is less stable than the soil's mineral constituents, as it is reduced by microbial decomposition, and over time its concentration diminshes without the addition of new organic matter. However, humus may persist over centuries if not millennia.
Climate and organic matter.
The production, accumulation and degradation of organic matter are greatly dependent on climate. Temperature, soil moisture and topography are the major factors affecting the accumulation of organic matter in soils. Organic matter tends to accumulate under wet or cold conditions where decomposer activity is impeded by low temperature or excess moisture which results in anaerobic conditions. Conversely, excessive rain and high temperatures of tropical climates enables rapid decomposition of organic matter and leaching of plant nutrients; forest ecosystems on these soils rely on efficient recycling of nutrients and plant matter to maintain their productivity. Excessive slope may encourage the erosion of the top layer of soil which holds most of the raw organic material that would otherwise eventually become humus.
Plant residue in soil.
Cellulose and hemicellulose undergo fast decomposition by fungi and bacteria, with a half-life of 12–18 days in a temperate climate. Brown rot fungi can decompose the cellulose and hemicellulose, leaving the lignin and phenolic compounds behind. Starch, which is an energy storage system for plants, undergoes fast decomposition by bacteria and fungi. Lignin consists of polymers composed of 500 to 600 units with a highly branched, amorphous structure. Lignin undergoes very slow decomposition, mainly by white rot fungi and actinomycetes; its half-life under temperate conditions is about six months.
Soil horizons.
A horizontal layer of the soil, whose physical features, composition and age are distinct from those above and beneath, are referred to as a soil horizon. The naming of a horizon is based on the type of material of which it is composed. Those materials reflect the duration of specific processes of soil formation. They are labelled using a shorthand notation of letters and numbers which describe the horizon in terms of its colour, size, texture, structure, consistency, root quantity, pH, voids, boundary characteristics and presence of nodules or concretions. Few soil profiles have all the major horizons. Some may have only one horizon.
The exposure of parent material to favourable conditions produces mineral soils that are marginally suitable for plant growth. That growth often results in the accumulation of organic residues. The accumulated organic layer called the O horizon produces a more active soil due to the effect of the organisms that live within it. Organisms colonise and break down organic materials, making available nutrients upon which other plants and animals can live. After sufficient time, humus moves downward and is deposited in a distinctive organic surface layer called the A horizon.
Classification.
Soil is classified into categories in order to understand relationships between different soils and to determine the suitability of a soil for a particular use. One of the first classification systems was developed by the Russian scientist Dokuchaev around 1880. It was modified a number of times by American and European researchers, and developed into the system commonly used until the 1960s. It was based on the idea that soils have a particular morphology based on the materials and factors that form them. In the 1960s, a different classification system began to emerge which focused on soil morphology instead of parental materials and soil-forming factors. Since then it has undergone further modifications. The World Reference Base for Soil Resources (WRB) aims to establish an international reference base for soil classification.
Soil classification systems.
Australia.
There are fourteen soil orders at the top level of the Australian Soil Classification. They are: Anthroposols, Organosols, Podosols, Vertosols, Hydrosols, Kurosols, Sodosols, Chromosols, Calcarosols, Ferrosols, Dermosols, Kandosols, Rudosols and Tenosols.
European Union.
The EU's soil taxonomy is based on a new standard soil classification in the World Reference Base for Soil Resources produced by the UN's Food and Agriculture Organization. According to this, the major soils in the European Union are:
USA.
A taxonomy is an arrangement in a systematic manner; the USDA soil taxonomy has six levels of classification. They are, from most general to specific: order, suborder, great group, subgroup, family and series. Soil properties that can be measured quantitatively are used in this classification system — they include: depth, moisture, temperature, texture, structure, cation exchange capacity, base saturation, clay mineralogy, organic matter content and salt content. There are 12 soil orders (the top hierarchical level) in the USDA soil taxonomy. The names of the orders end with the suffix "-sol". The criteria for the different soil orders include properties that reflect major differences in the genesis of soils. The orders are:
The percentages listed above are for land area free of ice. "Soils of Mountains", which constitute the balance (11.6%), have a mixture of those listed above, or are classified as "Rugged Mountains" which have no soil.
The above soil orders in sequence of increasing degree of development are Entisols, Inceptisols, Aridisols, Mollisols, Alfisols, Spodosols, Ultisols, and Oxisols. Histosols and Vertisols may appear in any of the above at any time during their development.
The soil suborders within an order are differentiated on the basis of soil properties and horizons which depend on soil moisture and temperature. Forty-seven suborders are recognized in the United States.
The soil great group category is a subdivision of a suborder in which the kind and sequence of soil horizons distinguish one soil from another. About 185 great groups are recognized in the United States. Horizons marked by clay, iron, humus and hard pans and soil features such as the expansion-contraction of clays (that produce self-mixing provided by clay), temperature, and marked quantities of various salts are used as distinguishing features.
The great group categories are divided into three kinds of soil subgroups: typic, intergrade and extragrade. A typic subgroup represents the basic or 'typical' concept of the great group to which the described subgroup belongs. An intergrade subgroup describes the properties that suggest how it grades towards (is similar to) soils of other soil great groups, suborders or orders. These properties are not developed or expressed well enough to cause the soil to be included within the great group towards which they grade, but suggest similarities. Extragrade features are aberrant properties which prevent that soil from being included in another soil classification. About 1,000 soil subgroups are defined in the United States.
A soil family category is a group of soils within a subgroup and describes the physical and chemical properties which affect the response of soil to agricultural management and engineering applications. The principal characteristics used to differentiate soil families include texture, mineralogy, pH, permeability, structure, consistency, the locale's precipitation pattern, and soil temperature. For some soils the criteria also specify the percentage of silt, sand and coarse fragments such as gravel, cobbles and rocks. About 4,500 soil families are recognised in the United States.
A family may contain several soil series which describe the physical location using the name of a prominent physical feature such as a river or town near where the soil sample was taken. An example would be Merrimac for the Merrimack River in New Hampshire, USA. More than 14,000 soil series are recognised in the United States. This permits very specific descriptions of soils.
A soil phase of series, originally called 'soil type' describes the soil surface texture, slope, stoniness, saltiness, erosion, and other conditions.
Uses.
Soil is used in agriculture, where it serves as the anchor and primary nutrient base for plants; however, as demonstrated by hydroponics, it is not essential to plant growth if the soil-contained nutrients can be dissolved in a solution. The types of soil and available moisture determine the species of plants that can be cultivated.
Soil material is also a critical component in the mining, construction and landscape development industries. Soil serves as a foundation for most construction projects. The movement of massive volumes of soil can be involved in surface mining, road building and dam construction. Earth sheltering is the architectural practice of using soil for external thermal mass against building walls. Many building materials are soil based.
Soil resources are critical to the environment, as well as to food and fibre production. Soil provides minerals and water to plants. Soil absorbs rainwater and releases it later, thus preventing floods and drought. Soil cleans water as it percolates through it. Soil is the habitat for many organisms: the major part of known and unknown biodiversity is in the soil, in the form of invertebrates (earthworms, woodlice, millipedes, centipedes, snails, slugs, mites, springtails, enchytraeids, nematodes, protists), bacteria, archaea, fungi and algae; and most organisms living above ground have part of them (plants) or spend part of their life cycle (insects) below-ground. Above-ground and below-ground biodiversities are tightly interconnected, making soil protection of paramount importance for any restoration or conservation plan.
The biological component of soil is an extremely important carbon sink since about 57% of the biotic content is carbon. Even on desert crusts, cyanobacteria, lichens and mosses capture and sequester a significant amount of carbon by photosynthesis. Poor farming and grazing methods have degraded soils and released much of this sequestered carbon to the atmosphere. Restoring the world's soils could offset some of the huge increase in greenhouse gases causing global warming, while improving crop yields and reducing water needs.
Waste management often has a soil component. Septic drain fields treat septic tank effluent using aerobic soil processes. Landfills use soil for daily cover. Land application of waste water relies on soil biology to aerobically treat BOD.
Organic soils, especially peat, serve as a significant fuel resource; but wide areas of peat production, such as sphagnum bogs, are now protected because of patrimonial interest.
Geophagy is the practice of eating soil-like substances. Both animals and human cultures occasionally consume soil for medicinal, recreational, or religious purposes. It has been shown that some monkeys consume soil, together with their preferred food (tree foliage and fruits), in order to alleviate tannin toxicity.
Soils filter and purify water and affect its chemistry. Rain water and pooled water from ponds, lakes and rivers percolate through the soil horizons and the upper rock strata, thus becoming groundwater. Pests (viruses) and pollutants, such as persistent organic pollutants (chlorinated pesticides, polychlorinated biphenyls), oils (hydrocarbons), heavy metals (lead, zinc, cadmium), and excess nutrients (nitrates, sulfates, phosphates) are filtered out by the soil. Soil organisms metabolise them or immobilise them in their biomass and necromass, thereby incorporating them into stable humus. The physical integrity of soil is also a prerequisite for avoiding landslides in rugged landscapes.
Degradation.
Land degradation refers to a human-induced or natural process which impairs the capacity of land to function. Soils degradation involves the acidification, contamination, desertification, erosion or salination.
Soil acidification is beneficial in the case of alkaline soils, but it degrades land when it lowers crop productivity and increases soil vulnerability to contamination and erosion. Soils are often initially acid because their parent materials were acid and initially low in the basic cations (calcium, magnesium, potassium and sodium). Acidification occurs when these elements are leached from the soil profile by rainfall or the by harvesting of forest or agricultural crops. Soil acidification is accelerated by the use of acid-forming nitrogenous fertilizers and by the effects of acid precipitation.
Soil contamination at low levels is often within a soil's capacity to treat and assimilate waste material. Soil biota can treat waste by transforming it; soil colloids can adsorb the waste material. Many waste treatment processes rely on this treatment capacity. Exceeding treatment capacity can damage soil biota and limit soil function. Derelict soils occur where industrial contamination or other development activity damages the soil to such a degree that the land cannot be used safely or productively. Remediation of derelict soil uses principles of geology, physics, chemistry and biology to degrade, attenuate, isolate or remove soil contaminants to restore soil functions and values. Techniques include leaching, air sparging, chemical amendments, phytoremediation, bioremediation and natural degradation.
Desertification is an environmental process of ecosystem degradation in arid and semi-arid regions, often caused by human activity. It is a common misconception that droughts cause desertification. Droughts are common in arid and semiarid lands. Well-managed lands can recover from drought when the rains return. Soil management tools include maintaining soil nutrient and organic matter levels, reduced tillage and increased cover. These practices help to control erosion and maintain productivity during periods when moisture is available. Continued land abuse during droughts, however, increases land degradation. Increased population and livestock pressure on marginal lands accelerates desertification.
Erosion of soil is caused by water, wind, ice, and movement in response to gravity. More than one kind of erosion can occur simultaneously. Erosion is distinguished from weathering, since erosion also transports eroded soil away from its place of origin (soil in transit may be described as sediment). Erosion is an intrinsic natural process, but in many places it is greatly increased by human activity, especially poor land use practices. These include agricultural activities which leave the soil bare during times of heavy rain or strong winds, overgrazing, deforestation, and improper construction activity. Improved management can limit erosion. Soil conservation techniques which are employed include changes of land use (such as replacing erosion-prone crops with grass or other soil-binding plants), changes to the timing or type of agricultural operations, terrace building, use of erosion-suppressing cover materials (including cover crops and other plants), limiting disturbance during construction, and avoiding construction during erosion-prone periods.
A serious and long-running water erosion problem occurs in China, on the middle reaches of the Yellow River and the upper reaches of the Yangtze River. From the Yellow River, over 1.6 billion tons of sediment flow each year into the ocean. The sediment originates primarily from water erosion (gully erosion) in the Loess Plateau region of northwest China.
Soil piping is a particular form of soil erosion that occurs below the soil surface. It causes levee and dam failure, as well as sink hole formation. Turbulent flow removes soil starting at the mouth of the seep flow and the subsoil erosion advances up-gradient. The term sand boil is used to describe the appearance of the discharging end of an active soil pipe.
Soil salination is the accumulation of free salts to such an extent that it leads to degradation of the agricultural value of soils and vegetation. Consequences include corrosion damage, reduced plant growth, erosion due to loss of plant cover and soil structure, and water quality problems due to sedimentation. Salination occurs due to a combination of natural and human-caused processes. Arid conditions favour salt accumulation. This is especially apparent when soil parent material is saline. Irrigation of arid lands is especially problematic. All irrigation water has some level of salinity. Irrigation, especially when it involves leakage from canals and overirrigation in the field, often raises the underlying water table. Rapid salination occurs when the land surface is within the capillary fringe of saline groundwater. Soil salinity control involves watertable control and flushing with higher levels of applied water in combination with tile drainage or another form of subsurface drainage.
Reclamation.
Soils which contain high levels of particular clays, such as smectites, are often very fertile. For example, the smectite-rich clays of Thailand's Central Plains are among the most productive in the world.
Many farmers in tropical areas, however, struggle to retain organic matter in the soils they work. In recent years, for example, productivity has declined in the low-clay soils of northern Thailand. Farmers initially responded by adding organic matter from termite mounds, but this was unsustainable in the long-term. Scientists experimented with adding bentonite, one of the smectite family of clays, to the soil. In field trials, conducted by scientists from the International Water Management Institute in cooperation with Khon Kaen University and local farmers, this had the effect of helping retain water and nutrients. Supplementing the farmer's usual practice with a single application of 200 kg bentonite per rai (6.26 rai = 1 hectare) resulted in an average yield increase of 73%. More work showed that applying bentonite to degraded sandy soils reduced the risk of crop failure during drought years.
In 2008, three years after the initial trials, IWMI scientists conducted a survey among 250 farmers in northeast Thailand, half of whom had applied bentonite to their fields. The average improvement for those using the clay addition was 18% higher than for non-clay users. Using the clay had enabled some farmers to switch to growing vegetables, which need more fertile soil. This helped to increase their income. The researchers estimated that 200 farmers in northeast Thailand and 400 in Cambodia had adopted the use of clays, and that a further 20,000 farmers were introduced to the new technique.
If the soil is too high in clay, adding gypsum, washed river sand and organic matter will balance the composition. Adding organic matter (like ramial chipped wood for instance) to soil which is depleted in nutrients and too high in sand will boost its quality.

</doc>
<doc id="37739" url="https://en.wikipedia.org/wiki?curid=37739" title="The Illustrated Man">
The Illustrated Man

The Illustrated Man is a 1951 book of eighteen science fiction short stories by Ray Bradbury that explores the nature of mankind. A recurring theme throughout the eighteen stories is the conflict of the cold mechanics of technology and the psychology of people. It was nominated for the International Fantasy Award in 1952.
The unrelated stories are tied together by the frame device of "the Illustrated Man", a vagrant former member of a carnival freak show with an extensively tattooed body whom the unnamed narrator meets. The man's tattoos, allegedly created by a time-traveling woman, are individually animated and each tell a different tale. All but one of the stories had been published previously elsewhere, although Bradbury revised some of the texts for the book's publication.
The book was made into the 1969 film starring Rod Steiger and Claire Bloom, adapted from the stories "The Veldt", "The Long Rain", and "The Last Night of the World".
A number of the stories, including "The Veldt", "The Fox and the Forest" (as "To the Future"), "Marionettes, Inc.", and "Zero Hour" were dramatized for the 1955-57 radio series "X Minus One". "The Veldt", "The Concrete Mixer", "The Long Rain", "Zero Hour", and "Marionettes Inc." were adapted for the TV series "The Ray Bradbury Theater".
Other versions.
The British edition, first published in 1952 by Hart-Davis omits "The Rocket Man", "The Fire Balloons", "The Exiles" and "The Concrete Mixer", and adds "Usher II" from "The Martian Chronicles" and "The Playground".
Editions published by Avon Books in 1997 and William Morrow in 2001 omit "The Fire Balloons" and add "The Illustrated Man" to the end of the book.
Reception.
Boucher and McComas gave "The Illustrated Man" a mixed review, faulting the framing story as "markedly ineffective" and the story selection for seeming "less than wisely chosen". However, they found the better stories "provide a feast the finest traditions in imaginative fiction" and later named it among the year's top books. Villiers Gerson, reviewing the volume for "Astounding Science Fiction", praised it as "a book which demonstrates that its author is one of the most literate and spellbinding writers in science fiction today". In "The New York Times", Gerson also praised the book for its "three-dimensional people with whom it is easy to sympathize, to hate, and to admire".
Adaptations to other media.
1969 film.
A film adaptation of "The Illustrated Man" was released in 1969. It was directed by Jack Smight and starred Rod Steiger, Claire Bloom, and others, including Don Dubbins. The film contains adaptations of "The Veldt," "The Long Rain," and "The Last Night of the World" and expands the prologue and epilogue with intermittent scenes and flashbacks of how the illustrations came to be. A short documentary, "Tattooed Steiger", details the process the filmmakers used to cover Steiger's body in mock tattoos and shows actors and filmmakers preparing for the movie.
2008 album.
A musical adaptation by Samuel Otten was released as a musical expression of the stories to go along with the reading.
Influence on "Dark Star", 1974.
Bradbury's "Kaleidoscope" inspired the 1974 science fiction movie "Dark Star", which ends in a similar final scene.
Influence on "To the Dark Side of the Moon", 2010.
A theater adaptation of "Kaleidoscope", with influence from music by Pink Floyd was used to produce "To the Dark Side of the Moon", in reference to the Pink Floyd album by the same name. This adaptation was produced by Stern-Theater, a Swiss-based theater company. The script was written by Daniel Rohr and was first shown at the Theater Rigiblick in Zurich, Switzerland on February 6, 2010. The music includes creative use of a string quartet and a piano.
BBC Radio, 2014.
A radio adaptation was broadcast on BBC Radio 4 on 14 June 2014 as part of the "Dangerous Visions" series adapted by Brian Sibley, directed by Gemma Jenkins and starring Iain Glen as "The Illustrated Man" and Jamie Parker as "The Youth". The stories adapted for this production were "Marionettes, Inc.", "Zero Hour" and "Kaleidoscope".
Film in development.
Director Zack Snyder is attached to direct, at least in part, a film adaptation of three stories from "The Illustrated Man": "The Illustrated Man", "Veldt", and "Concrete Mixer". Screenwriter Alex Tse is writing the screenplay.
"The Whispers" television series.
"The Whispers" is an American television series based on the short story "Zero Hour".

</doc>
<doc id="37742" url="https://en.wikipedia.org/wiki?curid=37742" title="List of political theorists">
List of political theorists

A political theorist is someone who engages in constructing or evaluating political theory, including political philosophy. Theorists may be academics or independent scholars.

</doc>
<doc id="37743" url="https://en.wikipedia.org/wiki?curid=37743" title="Mead">
Mead

Mead (; archaic and dialectal "medd"; from Old English "meodu",) is an alcoholic beverage created by fermenting honey with water, sometimes with various fruits, spices, grains, or hops. The alcoholic content ranges from about 8% ABV to more than 20%. The defining characteristic of mead is that the majority of the beverage's fermentable sugar is derived from honey. It may be still, carbonated, or naturally sparkling; dry, semi-sweet, or sweet.
Mead was produced in ancient history throughout Europe, Africa and Asia. 
Mead has played an important role in the beliefs and mythology of some peoples. One such example is the Mead of Poetry, a mead of Norse mythology crafted from the blood of the wise being Kvasir which turns the drinker into a poet or scholar.
The terms "mead" and "honey-wine" are often used synonymously. Honey-wine is differentiated from mead in some cultures. Hungarians hold that while mead is made of honey, water and beer-yeast (barm), honey-wine is watered honey fermented by recrement of grapes or other fruits.
History.
In Asia, pottery vessels containing chemical signatures of a mixture of honey, rice and other fruits along with organic compounds of fermentation dating from 6500-7000 BC were found in Northern China. In Europe, it is first attested in residual samples found in the characteristic ceramics of the Bell Beaker Culture (c. 2800 – 1800 BC).
The earliest surviving description of mead is in the hymns of the "Rigveda", one of the sacred books of the historical Vedic religion and (later) Hinduism dated around 1700–1100 BC. During the Golden Age of Ancient Greece, mead was said to be the preferred drink. Aristotle (384–322 BC) discussed mead in his "Meteorologica" and elsewhere, while Pliny the Elder (AD 23–79) called mead "militites" in his "Naturalis Historia" and differentiated wine sweetened with honey or "honey-wine" from mead. The Hispanic-Roman naturalist Columella gave a recipe for mead in "De re rustica", about AD 60.
There is a poem attributed to the Brythonic-speaking bard Taliesin, who lived around AD 550, called the "" or "Song of Mead." The legendary drinking, feasting and boasting of warriors in the mead hall is echoed in the mead hall "Din Eidyn" (modern day Edinburgh) as depicted in the poem "Y Gododdin", attributed to the poet Aneirin who would have been a contemporary of Taliesin. In the Old English epic poem "Beowulf", the Danish warriors drank mead. In both Insular Celtic and Germanic cultures mead was the primary heroic drink in poetry.
Later, taxation and regulations governing the ingredients of alcoholic beverages led to commercial mead becoming a more obscure beverage until recently. Some monasteries kept up the old traditions of mead-making as a by-product of beekeeping, especially in areas where grapes could not be grown, a well-known example being at Lindisfarne, where mead continues to be made to this day, albeit not in the monastery itself.
Etymology.
The English word mead derives from the Old English "meodu", from Proto-Germanic "meduz", from Proto-Indo-European "*médʰu" (honey, fermented honey drink). Slavic "med / miod ", which means both "honey" and "mead", (Russian, Czech, Slovak, Serbian, Ukrainian, Bulgarian, Croatian: "med" vs. "medovina", Polish 'miód' pronounce - honey, mead) and Baltic "medus" "honey"/"midus" "mead", also derive from the same Proto-Indo-European root (cf. Welsh medd, Old Irish mid, Latin mel, Italian miele, Romanian miere, Sanskrit "madhu", Sogdian [an Old Iranian language: "muð", Avestan Old Iranian language: "maðu", Classical Persian: مُل "mul", Classical and New Persian: مِی "mey").
Distribution.
Mead was also popular in Eastern Europe and in the Baltic states. In the Polish language mead is called ' (), meaning "drinkable honey". In Russian it is called Medovukha ', which means the same thing as in Polish.
Since the 19th century, in Russia, mead has remained popular in the drinks medovukha and sbiten long after its decline in the West. Sbiten is often mentioned in the works of 19th-century Russian writers, including Gogol, Dostoevsky and Tolstoy. In Montenegro, "medovina" has been considered a healthy elixir and mentioned often in folk literature.
In Finland, a sweet mead called "" (cognate with the root of zymurgy) is still an essential seasonal fermented product connected with the Finnish Vappu (May Day) festival. It is usually spiced by adding both the pulp and rind of a lemon. During secondary fermentation, raisins are added to control the amount of sugars and to act as an indicator of readiness for consumption; they will rise to the top of the bottle when the drink is ready. However, the sugar used in modern practice is typically brown sugar, not honey.
Ethiopian mead is called "tej" (ጠጅ, ) and is usually home-made. It is flavored with the powdered leaves and bark of "gesho", a hop-like bittering agent which is a species of buckthorn. A sweeter, less-alcoholic version called "berz", aged for a shorter time, is also made. The traditional vessel for drinking "tej" is a rounded vase-shaped container called a "berele".
Mead known as iQhilika is traditionally prepared by the Xhosa of South Africa.
In the USA, mead is enjoying a resurgence, starting with small home meaderies and now with a number of small commercial meaderies. As mead becomes more widely available, it is seeing increased attention and exposure from the news media.
Fermentation process.
The yeast used in mead making is often identical to that used in wine making. Many home mead makers choose to use wine yeasts (particularly those used in the preparation of white wines) to make their meads. The problem with this is that the honey-based mead does not have a sufficient quantity of nutrients to produce a wholesome mead. To circumvent the nutrient issue, both commercial and homebrew mead makers add specific quantities of diammonium phosphate, vitamin B1, vitamin B12, vitamin B3, biotin, and other key minerals. These are often added based on a staggered addition schedule in order to achieve a high-quality readily-drinkable mead. In some cases, the mead prepared with a staggered nutrient addition can be consumed the moment it is bottled as opposed to waiting over one year for it to age.
By measuring the specific gravity of the mead once before fermentation and throughout the fermentation process by means of a hydrometer or refractometer, mead makers can determine the proportion of alcohol by volume that will appear in the final product. This also serves another purpose. By measuring specific gravity throughout fermentation, a mead maker can quickly troubleshoot a "stuck" batch, the word "stuck" being used to describe a fermentation process that has halted prematurely.
Meads will often ferment well at the same temperatures in which wine is fermented.
After primary fermentation slows down significantly — usually when specific gravity reaches 1.010 — the mead is then racked into a second container. This is known as secondary fermentation. Some larger commercial fermenters are designed to allow both primary and secondary fermentation to happen inside of the same vessel. Racking is done for two reasons: it lets the mead sit away from the remains of the yeast cells (lees) that have died during the fermentation process. Second, this lets the mead have time to clear. If the mead maker wishes to backsweeten the product or prevent it from oxidizing, potassium metabisulfite and potassium sorbate are added. After the mead clears, it is bottled and distributed.
Varieties.
Mead can have a wide range of flavors depending on the source of the honey, additives (also known as "adjuncts" or "gruit") including fruit and spices, the yeast employed during fermentation and the aging procedure. Some producers have marketed white wine sweetened and flavored with honey after fermentation as mead, sometimes spelling it "meade." This is closer in style to a Hypocras. Blended varieties of mead may be known by the style represented; for instance, a mead made with cinnamon and apples may be referred to as either a cinnamon cyser or an apple metheglin.
A mead that also contains spices (such as cloves, cinnamon or nutmeg), or herbs (such as meadowsweet, hops, or even lavender or chamomile), is called a metheglin .
A mead that contains fruit (such as raspberry, blackberry or strawberry) is called a melomel, which was also used as a means of food preservation, keeping summer produce for the winter. A mead that is fermented with grape juice is called a pyment.
Mulled mead is a popular drink at Christmas time, where mead is flavored with spices (and sometimes various fruits) and warmed, traditionally by having a hot poker plunged into it.
Some meads retain some measure of the sweetness of the original honey, and some may even be considered as dessert wines. Drier meads are also available, and some producers offer sparkling meads.
There are faux-meads, which are actually wines with honey added after fermentation as a sweetener and flavoring.
Historically, meads were fermented with wild yeasts and bacteria (as noted in the recipe quoted above) residing on the skins of the fruit or within the honey itself. Wild yeasts can produce inconsistent results. Yeast companies have isolated strains of yeast which produce consistently appealing products. Brewers, winemakers and mead makers commonly use them for fermentation, including yeast strains identified specifically for mead fermentation. These are strains that have been selected because of their characteristic of preserving delicate honey flavors and aromas.
Mead can also be distilled to a brandy or liqueur strength. A version called "honey jack" can be made by partly freezing a quantity of mead and straining the ice out of the liquid (a process known as freeze distillation), in the same way that applejack is made from cider.
In literature.
Mead is featured in many Germanic myths and folktales such as "Beowulf", as well as in other popular works that draw on these myths. Notable examples include books by Tolkien, George R. R. Martin, T. H. White, and Neil Gaiman. It is often featured in books using a historical Germanic setting and in writings about the Viking age. Mead is mentioned many times in Neil Gaiman's 2001 novel, "American Gods"; it is referred to as the drink of the gods. In the Inheritance Cycle series by Christopher Paolini, the protagonist, Eragon, often drinks mead at feasts. It is also referenced in "The Kingkiller Chronicle" novel series by Patrick Rothfuss. The protagonist Kvothe is known to drink metheglin. The non-existent "Greysdale Mead" is also drunk, although it is merely water.

</doc>
