<doc id="37123" url="https://en.wikipedia.org/wiki?curid=37123" title="Theories of political behavior">
Theories of political behavior

Theories of political behavior, as an aspect of political science, attempt to quantify and explain the influences that define a person's political views, ideology, and levels of political participation. Theorists who have had an influence on this field include Karl Deutsch and Theodor Adorno.
Long-term influences on political orientation.
There are three main sources of influence that shape political orientation which creates long-term effects. Generally, the primary influence originates from family. As stated previously, children will often adopt their parents' ideological values. Some theorists have argued that family tends to be the strongest, most influential force which exists over the lifetime; one essay has credited the majority of the student activism of the 1930s to the influence of parents.
Secondly, teachers and other educational authority figures have a significant impact on political orientation. From as early as age 4 up until 18, children spend about 25% of their time involved in educational processes. Post-secondary education significantly raises the impact of political awareness and orientation; an October 2004 study of 1,202 college undergraduates across the United States showed that 87% of college students were registered to vote, compared to a national average of 64% of American adults. A study at Santa Clara University also showed that 84% of students there were registered to vote. Also consider that childhood and adolescent stages of personal growth have the highest level of impressionability.
Thirdly, peers also affect political orientation. Friends often, but not necessarily, have the advantage of being part of the same generation, which collectively develops a unique set of societal issues; Eric L. Dey has argued that "socialisation is the process through which individuals acquire knowledge, habits, and value orientations that will be useful in the future." The ability to relate on this common level is what fuels and enables future ideological growth.
Short-term influences on political orientation.
Short-term factors also affect voting behavior; the media and the impact of individual election issues are among these factors. These factors differ from the long-term factors as they are often short-lived. However, they can be just as crucial in modifying political orientation. The ways in which these two sources are interpreted often relies on the individuals specific political ideology formed by the long-term factors.
Most political scientists agree that the mass media have a profound impact on voting behavior. One author asserts that "few would argue with the notion that the institutions of the mass media are important to contemporary politics ... in the transition to liberal democratic politics in the Soviet Union and Eastern Europe the media was a key battleground."
Second, there are election issues. These include campaign issues, debates and commercials. Election years and political campaigns can shift certain political behaviors based on the candidates involved, which have different degrees of effectiveness in influencing voters.
The influence of social groups on political outcomes.
Recently, some political scientists have been interested in many studies which aimed to analyze the relation between the behavior of social groups and the political outcomes. Some of the social groups included in their studies have been age demographics, gender, and ethnic groups.
For example, in U.S. politics, the effect of ethnic groups and gender has a great influence on the political outcomes.
Latin Americans have a profound social impact on the political outcome of their vote and are emerging as a strong up-and-coming political force. The most noticeable increase in Latin American voting was in the 2000 presidential election, although the votes did not share a socially common political view at that time. In the 2006 election, the Latin American vote aided tremendously in the election of Florida Senator Mel Martinez, although in the 2004 presidential election, about 44% of Latin Americans voted for Republican President George W. Bush. Latin Americans have been seen to be showing an increasing trend in the issues on which they vote for, causing them to become more united when faced with political views. Currently illegal immigration has been claiming most attention and Latin Americans, although not completely unanimous, are concerned with the education, employment and deportation of illegal immigrants in the United States.
Over seven decades ago, women were acknowledged the right to vote and since then they have been making a difference in the outcomes of political election. Given that the right to be politically active has granted them the opportunity to expand their knowledge and influence in current affairs, they are now considered one of the main components in the country's decision-making in both politics and economy. According to The American Political Science Association, over the past 2004 presidential election, the women's vote may have well decided the outcome of the race. Susan Carroll, the author of "Women Voters and the Gender Gap", states that the increase of women influence on political behaviors is due to four main categories: women outnumber men among voters; significant efforts are underway to increase registration and turnout among women; a gender gap is evident in the 2004 election as it has been in every presidential election since 1980; and women constitute a disproportionately large share of the undecided voters who will make their decision late in the campaign.
Biology and political science.
Interdisciplinary studies in biology and political science aim to identify correlates of political behavior with biological aspects, for example the linkage of biology and political orientation, but also with other aspects like partisanship and voting behavior. This field of study is sometimes called biopolitics, although the term has other meanings.
The study of possible genetic bases of political behavior has grown since the 1980s. The term genopolitics was coined by political scientist James Fowler in the early-2000s to describe research into identifying specific transporter/receptor genes responsible for ideological orientation beyond the sociopsychological realm of political socialisation.

</doc>
<doc id="37124" url="https://en.wikipedia.org/wiki?curid=37124" title="Austin Powers (character)">
Austin Powers (character)

Sir Augustine Danger "Austin" Powers, KBE, is a fictional character from the Austin Powers series of films, and is created and portrayed by Mike Myers. He is the protagonist of "" (1997), "The Spy Who Shagged Me" (1999) and "Austin Powers in Goldmember" (2002). He is a womanizing, hard-partying British spy embodying the Swinging London mod culture and hippie culture of the 1960s who, with his nemesis Dr. Evil, was frozen in a cryogenics experiment. The series' humor follows his attempts to adjust to the modern world as he continues to try to save it from terrorism.
Personality.
Austin Powers was a character seen as a parody of James Bond and being influenced by Harry Palmer and characters played by Peter Sellers. The character of Austin Powers represents an archetype of 1960s Swinging London, with his advocacy for free love, his use of obscure impressions and his clothing style (including crushed velvet suits and Beatle boots).
Development.
Myers, Matthew Sweet and Susanna Hoffs formed the faux British 1960s band Ming Tea after Myers' "Saturday Night Live" stint in the early 1990s. The band members all performed under pseudonyms with 1960s personas. Myers adopted the pseudonym and character of Austin Powers. This group made a number of live club and television performances in character. Myers' then-wife, Robin Ruzan, encouraged him to write a film based on Austin Powers.
Obituaries of Simon Dee (1935–2009), the radio and television presenter, stated that his "Sixties grooviness" made him the inspiration for the character. Mike Myers has claimed his father was the inspiration behind Austin Powers.
Other media.
Video Games: Austin Powers, Austin Powers Pinball, Austin Powers: Welcome to my Underground Lair, Austin Powers: Oh Behave!, and Austin Powers: Operation Trivia.
In popular culture.
In 2010, he was voted #23 in "Entertainment Weekly"'s list "The 100 greatest characters of the last 20 years."

</doc>
<doc id="37125" url="https://en.wikipedia.org/wiki?curid=37125" title="Australian Security Intelligence Organisation">
Australian Security Intelligence Organisation

The Australian Security Intelligence Organisation (ASIO; ) is the national security service of Australia, which is responsible for the protection of the country and its citizens from espionage, sabotage, acts of foreign interference, politically motivated violence, attacks on the Australian defence system, and terrorism.
ASIO is comparable with the British Security Service (MI5) and the American Federal Bureau of Investigation (FBI). Generally ASIO operations requiring police powers are co-ordinated with the Australian Federal Police and/or with State and Territory police forces. ASIO officers have the right to arrest and detain.
However, under the "National Security Legislation Amendment Bill 2014" passed by the Parliament of Australia, ASIO officers are exempt from prosecution for a wide range of illegal activities in the course of conducting "operations". ASIO officers may carry arms, and the Minister responsible has the ability under certain conditions to provide ability to approve the provision of any weapon or training to any specified person, even outside of ASIO officers.
ASIO Central Office is in Canberra, with a local office being located in each mainland state and territory capital. A new AUD $630 million Central Office, named the Ben Chifley Building, was officially opened by the Prime Minister Kevin Rudd on 23 July 2013.
Command, control and organisation.
In 2013, ASIO had a staff of around 1,740 personnel. The identity of ASIO officers, apart from the Director-General, remain an official secret. While ASIO is an equal opportunity employer, there has been some media comment of the Organisation's apparent difficulty in attracting people from a Muslim or Middle Eastern background. Furthermore, ASIO has undergone a period of rapid growth with some 70 per cent of the Organisation's officers having joined since 2002, leading to what Paul O'Sullivan, Director-General of Security from 2005 to 2009, called 'an experience gap'.
Powers and accountability.
Special investigative powers.
The special investigative powers available to ASIO officers under warrant signed by the Attorney-General include:
The Director-General also has the power to independently issue a warrant should a serious security situation arise and a warrant requested of the Attorney-General has not yet been granted.
An ASIO officer may also, without warrant, ask an operator of an aircraft or vessel questions about the aircraft or vessel, its cargo, crew, passengers, stores or voyage; and to produce supporting documents relating to these questions.
Special terrorism investigative powers.
When investigating terrorism, the Director-General may also seek a warrant from an independent judicial authority to allow:
The Director-General is not empowered to independently issue a warrant in relation to the investigation of terrorism.
Immunity from prosecution.
While The Act does not define any activities specifically to be legal, that is, to grant immunity for any specific crime, it does provide exceptions that will not be granted immunity. Section 35k (1) defines these activities as not being immune from liability for special intelligence conduct during special intelligence operations. That is to say, an ASIO operative would be deemed to have committed a crime if they were to participate in any of the following activities under any circumstances:
Collection of foreign intelligence.
ASIO also has the power to collect foreign intelligence within Australia at the request of the Minister for Foreign Affairs or the Minister for Defence. Known as Joint Intelligence Operations, and usually conducted in concert with the Australian Secret Intelligence Service the purpose of these operations is the gathering of security intelligence on and from foreign officials, organisations or companies.
Accountability.
Because of the nature of its work, ASIO does not make details of its activities public and law prevents the identities of ASIO officers from being disclosed. ASIO and the Commonwealth Government say that operational measures ensuring the legality of ASIO operations have been established.
ASIO briefs the Attorney General on all major issues affecting security and he/she is also informed of operations when considering granting warrants enabling the special investigative powers of ASIO. Furthermore, the Attorney-General issues guidelines with respect to the conduct of ASIO investigations relating to politically motivated violence and its functions of obtaining intelligence relevant to security.
ASIO reports to several governmental and parliamentary committees dealing with security, legislative and financial matters. This includes the Parliamentary Joint Committee on Intelligence and Security. A classified annual report is also provided to the government, an unclassified edited version of which is tabled in Federal Parliament.
The Office of the Inspector-General of Intelligence and Security was established in 1986 to provide additional oversight of Australia’s security and intelligence agencies. The Inspector-General has complete access to all ASIO records and has a range of inquisitorial powers.
Relationships with foreign agencies and services.
Australia’s intelligence and security agencies maintain close working relationships with the foreign and domestic intelligence and security agencies of other nations. As of 22 October 2008, ASIO has established liaison relationships with 311 authorities in 120 countries.
History.
Establishment and 'The Case'.
Following the conclusion of World War II, the joint United States-UK Venona project uncovered sensitive British and Australian government data being transmitted through Soviet diplomatic channels. Officers from MI5 were dispatched to Australia to assist local investigations. The leak was eventually tracked to a spy ring operating from the Soviet Embassy in Canberra. Consequently, allied Western governments expressed disaffection with the state of security in Australia.
Subsequently, on 16 March 1949, Prime Minister Ben Chifley issued a Directive for the Establishment and Maintenance of a Security Service, appointing South Australian Supreme Court Justice Geoffrey Reed as the first Director-General of Security. In August 1949, Justice Reed advised the Prime Minister that he had decided to name the service the 'Australian Security Intelligence Organization' (the spelling was amended in 1999 to bring it into line with the Australian standard form 'organisation'). The new service was to be modelled on the Security Service of the United Kingdom and an MI5 liaison team (including probable Soviet double agent Sir Roger Hollis) was attached to the fledgling ASIO during the early 1950s. Historian Robert Manne describes this early relationship as “special, almost filial” and continues “ASIO’s trust in the British counter-intelligence service appears to have been near-perfect”. One of the foundation directors of ASIO, Robert Frederick Bird Wake, in his son's biography "No Ribbons or Medals" about his father's work as a counter espionage officer, is credited with getting " the show" started in 1949. Wake worked closely with the then director general Judge Geoffry Reed. During World War Two Reed conducted an inquiry into Wake's performance as a security officer and found that he was competent and innocent of the charges laid by the Army's commander-in-chief, General Thomas Blamey. This was the start of a relationship between Reed and Wake that lasted for more than 10 years. Wake was seen as the operational head of ASIO.
When the Labor Government was defeated, the new prime minister, Robert Menzies, appointed the deputy director of Military Intelligence, Charles Spry, as the director. Wake resigned shortly after Spry's appointment.
The operation to crack the Soviet spy ring in Canberra consumed much of the resources of ASIO during the 1950s. This operation became internally known as "The Case". Among the prime suspects of the investigations were Wally Clayton, a prominent member of the Australian Communist Party, and two diplomats with the Department of External Affairs, Jim Hill and Ian Milner. However, no charges resulted from the investigations, because Australia did not have any laws against peacetime espionage at the time.
On 6 July 1950 the Charter of the Australian Security Intelligence Organization was defined by the directive of Prime Minister Menzies, following the appointment of Colonel Spry as the new Director-General. ASIO was converted to a statutory body on 13 December 1956 through the "Australian Security Intelligence Organisation Act 1956" (repealed by the "Australian Security Intelligence Organisation Act 1979", the current legislation as amended to 2007).
The Petrov Affair.
5 February 1951 saw the arrival in Sydney of Vladimir Mikhaylovich Petrov, Third Secretary of the Soviet Embassy. An ASIO field officer identified Petrov as a possible 'legal', an agent of the Soviet Ministry of State Security (MGB, a forerunner to the KGB) operating under diplomatic immunity. The Organisation began gently cultivating Petrov through another agent, Dr. Michael Bialoguski, with the eventual goal of orchestrating his defection. Ultimately, Petrov was accused by the Soviet Ambassador of several lapses in judgement that would have led to his imprisonment and probable execution upon his return to the Soviet Union. Petrov feared for his life and grabbed the defection life-line thrown him by ASIO.
The actual defection occurred on 3 April 1954. Petrov was spirited to a safe house by ASIO officers, but his disappearance and the seeming reluctance of Australian authorities to search for him made the Soviets increasingly suspicious. Fearing a defection by Petrov, MVD officers dramatically escorted his wife Evdokia to a waiting aeroplane in Sydney. There was doubt as to whether she was leaving by choice or through coercion and so Australian authorities initially did not act to prevent her being bundled into the plane. However, ASIO was in communication with the pilot and learned through relayed conversations with a flight attendant that if Evdokia spoke to her husband she might consider seeking asylum in Australia.
An opportunity to allow her to speak with her husband came when the Director-General of Security, Charles Spry, was informed that the MVD agents had broken Australian law by carrying firearms on an airliner in Australian airspace and so could be detained. When the aeroplane landed in Darwin for refuelling, the Soviet party and other passengers were asked to leave the plane. Police, acting on ASIO orders, quickly disarmed and restrained the two MVD officers and Evdokia was taken into the terminal to speak to her husband via telephone. After speaking to him, she became convinced he was alive and speaking freely and asked the Administrator of the Northern Territory for political asylum.
The affair sparked controversy in Australia when circumstantial links were noted between the leader of the Australian Labor Party and the Communist Party of Australia (and hence to the Soviet spy ring). H.V. Evatt, the leader of the Labor Party at the time, accused Prime Minister Robert Menzies of arranging the Petrov defection to discredit him. The accusations lead to a disastrous split in the Labor party.
Petrov was able to provide information on the structure of the Soviet intelligence apparatus in the mid-1950s, information that was highly valuable to the United States. It was by obtaining this information that the Organisation's reputation in the eyes of the United States was greatly enhanced.
In fact, when Brigadier Spry retired, the Deputy Director of the CIA sent the following tribute:
The Cold War.
ASIO's counter-intelligence successes continued throughout the Cold War. Following an elaborate investigation between 1961 and 1963, ASIO recommended the ejection of the First Secretary of the Soviet Embassy, Ivan Skripov, and his declaration as "persona non grata". Skripov had been refining an Australian woman as an agent for Soviet intelligence; however, she was in fact an agent of ASIO.
In April 1983, ASIO uncovered more Soviet attempts at espionage and Valery Ivanov, who also held the post of First Secretary at the Soviet Embassy, was declared "persona non grata". He was ejected from Australia on the grounds that he had performed duties in violation of his diplomatic status.
Penetration by the KGB.
These successes were marred, however, by the penetration of ASIO by a KGB mole in the 1970s. Due to the close defence and intelligence ties between Australia and the United States, ASIO became a backdoor to American intelligence. Upon realising ASIO was compromised, the United States pulled back on the information it shared with Australia.
Following a strenuous internal audit and a joint Federal Police investigation, George Sadil was accused of being the mole. Sadil had been a Russian interpreter with ASIO for some 25 years and highly classified documents were discovered in his place of residence. Federal Police arrested Sadil in June 1993 and charged him under the Crimes Act 1914 with several espionage and official secrets related offences. However, parts of the case against him collapsed the following year.
Sadil was committed to trial in March 1994, but the Director of Public Prosecutions decided not to proceed with the more serious espionage-related charges after reviewing the evidence against him. Sadil's profile did not match that of the mole and investigators were unable to establish any kind of money trail between him and the KGB.
Sadil pleaded guilty in December 1994 to thirteen charges of "removing ASIO documents contrary to his duty", and was sentenced to three months imprisonment. He was subsequently released on a 12 month good behaviour bond. It is believed that another ASIO officer, now retired, is suspected of being the mole but no prosecution attempts have been made.
In November 2004, former KGB Major-General Oleg Kalugin confirmed to the Australian Broadcasting Corporation's "Four Corners" programme that the KGB had in fact infiltrated ASIO in the late 1970s and early 1980s.
Sydney 2000 Olympic Games.
ASIO began planning for the 2000 Olympic and Paralympic Games, held in Sydney, as early as 1995. A specific Olympics Coordination Branch was created in 1997, and began recruiting staff with “specialised skills" the following year. In 1998, ASIO “strengthened information collection and analytical systems, monitored changes in the security environment more broadly, improved its communications technology and provided other agencies with strategic security intelligence assessments to assist their Olympics security planning.”
The Olympics Coordination Branch also began planning for the Federal Olympic Security Intelligence Centre (FOSIC) in 1998. FOSIC was to “provide security intelligence advice and threat assessments to State and Commonwealth authorities during the Sydney 2000 Games.”
Surveillance of anti-coal activists.
In 2012 it was reported that ASIO had been monitoring the actions of Australians protesting against the coal industry, and was increasing its efforts from previous years. Minister Martin Ferguson said that he was particularly concerned about protests relating to the Hazelwood power station in Victoria. An unnamed security source told "The Age" newspaper that "providing advice and intelligence to safeguard infrastructure is clearly within ASIO's responsibilities... ASIO has a clear role, including protection against sabotage. And it's clear activists pose a greater threat to energy facilities than terrorists." A spokesperson for Attorney General Nicola Roxon described ASIO's responsibility in monitoring political action groups as "limited to activity that is, or has the potential to be, violent for the purposes of achieving a political objective". Australian Greens party leader Bob Brown described ASIO monitoring environmentalists as a "politcal weapon" used by the Government for the benefit of "foreign-owned mining corporations".
Royal commissions, inquiries and reviews.
Royal Commission on Intelligence and Security, 1974–77.
On 21 August 1974, Prime Minister Gough Whitlam announced the establishment of the Royal Commission on Intelligence and Security to inquire into Australia’s intelligence agencies. Justice Robert Hope of the Supreme Court of New South Wales was appointed as Royal Commissioner.
In 1977 the Commission confirmed the need for Australia’s own security and intelligence agency and made many recommendations on improving the analytical capability and financial accountability of ASIO. It also advocated increased ministerial control, designated the conducting of security assessments for access to classified information to ASIO, and urged greater cooperation with police and foreign intelligence services. Also as a result of the Commission the jurisdiction of ASIO investigation was expanded to include sabotage and terrorism, and ASIO was given lawful authority to open mail, enter premises, use listening devices and intercept telegrams and telex under warrant.
Protective Security Review, 1978–79.
Following the Sydney Hilton bombing of 1978, the government commissioned Justice Hope with conducting a review into national protective security arrangements and into co-operation between Federal and State authorities in regards to security. In the report concluded in 1979, Justice Hope designated ASIO as the agency responsible for national threat assessments in terrorism and politically motivated violence. He also recommended that relations between ASIO and State and Territory police forces be regulated by arrangements between governments.
Royal Commission on Australian Security and Intelligence Agencies, 1983–84.
Following the publicity surrounding the expulsion of Valery Ivanov, First Secretary at the Soviet Embassy in Canberra, the Government established a Royal Commission to review the activities of Australian Security and Intelligence Agencies. Justice Hope was again Royal Commissioner.
Justice Hope completed his report in December 1984. His recommendations included that:
Justice Hope also recommended that amendments to the ASIO Act provide that “"it is not the purpose of the Act that the right of lawful advocacy, protest or dissent should be affected or that exercising those rights should, by themselves, constitute activity prejudicial to security"”.
Post-Cold War review, 1992.
In early 1992, Prime Minister Paul Keating commissioned a review “"of the overall impact of changes in international circumstances on the roles and priorities of the Australian intelligence agencies"”. In the Prime Minister’s statement of 21 July 1992, Mr Keating said:
The resource reductions mentioned were a cut of 60 staff and a $3.81 million budget decrease.
Inquiry into National Security, 1993.
Following the trial of George Sadil over the ASIO mole scandal and from concern about the implications of material having been removed from ASIO without authority, the Prime Minister announced the appointment of Mr Michael Cook AO (former head of the Office of National Assessments) to inquire into various aspects of national security. The review was completed in 1994.
Parliamentary Joint Committee inquiries.
The Parliamentary Joint Committee completed several reviews and inquiries into ASIO during the 1990s. The first concerned the security assessment process. Another was held in September into “"The nature, scope and appropriateness of the way in which ASIO reports to the Australian public on its activities".” The Committee concluded that “"the total package of information available to the Australian community about ASIO's operations exceeds that available to citizens in other countries about their domestic intelligence agencies".” Pursuant to this, recommendations were made regarding the ASIO website and other publicly accessible information.
Criticisms, controversies and conspiracies.
Opposition to the political left.
ASIO has been accused of executing an agenda against the Left of politics since its inception. In the 1960s, ASIO was also accused of neglecting its proper duties because of this supposed preoccupation with targeting the Left. Like other Western domestic security agencies, ASIO actively monitored protesters against the Vietnam War, Labor politicians and various writers, artists and actors who tended towards the Left. Other claims go further, alleging that the Organisation compiled a list of some 10,000 suspected Communist sympathisers who would be interned should the Cold War escalate.
Raids on ASIO Central Office, 1973.
Further accusations against ASIO were raised by the Attorney-General following a series of bombings from 1963 to 1970 on the consulate of Communist Yugoslavia in Australia by Croatian far-right militia. Attorney-General Lionel Murphy alleged that ASIO had withheld information on the group which could have led to preventative measures taken against further bomb attacks (however, Murphy was a member of the recently sworn-in Labor government, which still held a deep-seated suspicion of ASIO).
On 15 March 1973, Murphy and the Commonwealth Police raided the ASIO offices in Melbourne. While some claim the raid was disastrous, serving little purpose other than to shake-up both ASIO and the Whitlam government, the findings of such investigations were not published.
The Sydney Hilton bombing allegations of conspiracy, 1978.
On 13 February 1978, the Sydney Hilton Hotel was bombed, one of the few domestic terrorist incidents on Australian soil. The Hotel was the location for the Commonwealth Heads of Government Meeting (CHOGM). Three people in the street were killed – two council workers and a policeman – and several others injured. Former police officer Terry Griffiths, who was injured in the explosion, provided some evidence that suggested ASIO might have orchestrated the bombing or been aware of the possibility and allowed it to proceed. In 1985, the Director-General of Security issued a specific denial of the allegation. In 1991 the New South Wales parliament unanimously called for a joint State-Federal inquiry into the bombing. However, the Federal government vetoed any inquiry.
Anti-terrorism bungle, 2001.
A few weeks after the 11 September 2001 attacks on the United States, mistakes led ASIO to incorrectly raid the home of Bilal Daye and his wife. It has been revealed that the search warrant was for a different address. The couple subsequently sought damages and the embarrassing incident was settled out of court in late 2005, with all material relating to the case being declared strictly confidential.
Kim Beazley-Ratih Hardjono investigation, 2004.
In June 2004, Kim Beazley was accused of having a "special relationship" with Ratih Hardjono when he was defence minister. Hardjono was allegedly accused of "inappropriately" photographing a secure Australian Defence facility, working with the embassy ID, and having a close working relationship with her uncle, a senior officer in BAKIN (Indonesian Intelligence). In July, journalist Greg Sheridan contacted the then head of ASIO, Dennis Richardson, and discussed a classified operational investigation. Later in July members of the Attorney General's department were still investigating the original allegation, making Richardson's comments premature and inaccurate. The whole episode was a salient reminder to politicians in Canberra of the British experience of 'agents of influence' and honeypots. Ratih Hardjono was married to Bruce Grant in the 1990s.
Detention and removal of Scott Parkin, 2005.
In September 2005, the visa of American citizen, Scott Parkin, was cancelled after Director-General of Security, Paul O'Sullivan, issued an adverse security assessment of the visiting peace activist. Parkin was detained in Melbourne and held in custody for five days before being escorted under guard to Los Angeles, where he was informed that he was required to pay the Australian Government A$11,700 for the cost of his detention and removal. Parkin challenged the adverse security assessment in the Federal Court in a joint civil action with two Iraqi refugees, Mohammed Sagar and Muhammad Faisal, who faced indefinite detention on the island of Nauru after also receiving adverse security assessments in 2005.
Prior to his removal, Parkin had given talks on the role of U.S. military contractor Halliburton in the Iraq war and led a small protest outside the Sydney headquarters of Halliburton subsidiary KBR. The Attorney-General at that time, Philip Ruddock, refused to explain the reasons for Parkin's removal, leading to speculation that ASIO had acted under pressure from the United States. This was denied by O'Sullivan before a Senate committee, where he gave evidence that ASIO based its assessment only on Parkin's activities in Australia. O'Sullivan refused to answer questions before a later Senate committee hearing after his legal counsel told the Federal Court that ASIO did not necessarily base its assessment solely on Parkin's activities in Australia.
Kidnap and false imprisonment of Izhar ul-Haque, 2007.
On 12 November 2007, the Supreme Court of New South Wales dismissed charges brought against a young medical student, Izhar ul-Haque. ASIO and the Australian Federal Police had investigated ul-Haque for allegedly training with Lashkar-e-Toiba in Pakistan, a declared terrorist organisation under the "Security Legislation Amendment (Terrorism) Act 2002". However, the case against the medical student collapsed when it was revealed that ASIO officers had engaged in improper conduct during the investigation. Justice Michael Adams determined that because ul-Haque was falsely led to believe that he was legally compelled to comply with the ASIO officers, the conduct of at least one of the investigating ASIO officers constituted false imprisonment and kidnap at common law, and therefore key evidence against ul-Haque was inadmissible.
Archival material.
Under the Archives Act 1983, ASIO files can be released to the public after 30 years unless they fall into any of 16 exemption categories (as itemised in section 33 of the Archives Act).

</doc>
<doc id="37126" url="https://en.wikipedia.org/wiki?curid=37126" title="Australian Secret Intelligence Service">
Australian Secret Intelligence Service

The Australian Secret Intelligence Service (ASIS; ) is the national foreign intelligence agency of Australia. It is responsible for overseas intelligence collection, including both counter-intelligence and liaising with the intelligence agencies of other countries. In these roles, ASIS is comparable to the British Secret Intelligence Service (MI6) and the American Central Intelligence Agency (CIA).
According to its website, the mission of ASIS is to: "Protect and promote Australia's vital interests through the provision of unique foreign intelligence services as directed by Government."
ASIS is part of the Department of Foreign Affairs and Trade portfolio and is housed within DFAT's headquarters in Canberra. Its current Director-General is Nick Warner.
History.
On 13 May 1952, in a meeting of the Executive Council, Prime Minister Robert Menzies established ASIS by the executive power of the Commonwealth under "s 61" of the Constitution, appointing Alfred Deakin Brookes as head. The existence of ASIS remained secret even within the Government for a period of twenty years.
Its Charter of 15 December 1954 described ASIS's role as "to obtain and distribute secret intelligence, and to plan for and conduct special operations as may be required". ASIS was expressly required to "operate outside Australian territory." A Ministerial Directive of 15 August 1958 indicated that its special operations role included conducting "special political action." It also indicated that the organisation would come under the control and supervision of the Minister for External Affairs rather than the Minister for Defence. At the time, ASIS was substantially modeled on the United Kingdom Secret Intelligence Service, also known as MI6. ASIS was at one time referred to as MO9.
On 1 November 1972, ASIS was sensationally exposed by "The Daily Telegraph" which ran an exposé regarding recruitment of ASIS agents from Australian universities for espionage activities in Asia. Soon after "The Australian Financial Review" published a more in-depth piece on the Australian Intelligence Community (ASIO, ASIS, the Joint Intelligence Organisation (JIO) the Defence Intelligence Organisation (DIO), the Defence Signals Division (DSD) the Defence Signals Directorate, now the Australian Signals Directorate and the Office of National Assessments (ONA)). It stated that "he ASIS role is to collect and disseminate facts only. It is not supposed to be in the analytical or policy advising business though this is clearly difficult to avoid at times." The Ministerial Statement of 1977 stated that the "main function" of ASIS was to "obtain, by such means and subject to such conditions as are prescribed by the Government, foreign intelligence for the purpose of the protection or promotion of Australia or its interests."
On 25 October 1977, then Prime Minister Malcolm Fraser declared the existence of ASIS and its functions following a recommendation by the first of the Hope Royal Commissions (see below).
In 1992 two reports were prepared on ASIS by officers within the Department of Prime Minister and Cabinet and Office of National Assessments for the Secretaries Committee on Intelligence and Security (SCIS) and the Security Committee of Cabinet (SCOC). The Richardson Report in June examined the roles and relationships of the collection agencies (ASIO, ASIS and DSD) in the post cold war era. The Hollway Report in December examined shortfalls in Australia's foreign intelligence collection. Both reports endorsed the structure and roles of the organisations and commended the performance of ASIS.
Royal Commissions examining ASIS.
Three Royal Commissions have examined, among other things, ASIS and its operations: in 1974 and 1983 (the Hope Royal Commissions), and in 1994 (the Samuels and Codd Royal Commission).
First Hope Royal Commission.
On 21 August 1974, the Whitlam Government appointed Justice Robert Hope to conduct a Royal Commission into the structure of security and intelligence services, the nature and scope of the intelligence required and the machinery for ministerial control, direction and coordination of the security services. The Hope Royal Commission delivered eight reports, four of which were tabled in Parliament on 5 May 1977 and 25 October 1977. Aside from the observation that ASIS was 'singularly well run and well managed', the report(s) on ASIS were not released. Results from the other reports included the Australian Security Intelligence Organisation Act 1979 and the establishment of the Office of National Assessments (ONA) and the passage of the Office of National Assessments Act 1977.
Second Hope Royal Commission.
On 17 May 1983 the Hawke Government reappointed Justice Hope to conduct a second Royal Commission into ASIS, ASIO, ONA, DSD and JIO (now DIO). The inquiry was to examine progress in implementing the previous recommendations; arrangements for developing policies, assessing priorities and coordinating activities among the organisations; ministerial and parliamentary accountability; complaints procedures; financial oversight and the agencies' compliance with the law. As with the first Hope Royal Commission, the reports on ASIS and DSD, which included draft legislation on ASIS, were not made public.
Samuels and Codd Royal Commission.
In response to a "Four Corners" program aired on 21 February 1994, on 23 February 1994, the Minister for Foreign Affairs Gareth Evans announced a 'root and branch' review of ASIS. The Government appointed Justice Gordon Samuels and Mike Codd to inquire into the effectiveness and suitability of existing arrangements for control and accountability, organisation and management, protection of sources and methods, and resolution of grievances and complaints. The Royal Commission reported in March 1995.
"Four Corners" reporter Ross Coulthart made allegations regarding intelligence held by ASIS on Australians. He claimed that 'ASIS secretly holds tens of thousands of files on Australian citizens, a database completely outside privacy laws'. This allegation was investigated and denied by Samuels and Codd (see below), but the Minister did acknowledge that ASIS maintained files. The Minister said: 'ASIS does have some files, as one would expect in an organisation of that nature, even though its brief extends to activities outside the country rather than inside. They are essentially of an administrative nature.'
However, Samuels and Codd did find that certain grievances of the former officers were well founded. They appeared to support the officers' concerns regarding the grievance procedures:
"Bearing in mind the context in which the members of ASIS work, it is not surprising that there should develop a culture which sets great store by faithfulness and stoicism and tends to elevate conformity to undue heights and to regard the exercise of authority rather than consultation as the managerial norm."
However, Samuels and Codd observed that the information published in the "Four Corners" program was 'skewed towards the false', that 'the level of factual accuracy about operational matters was not high', and, quoting an aphorism, that 'what was disturbing was not true and what was true was not disturbing'. They concluded that the disclosure of the information was unnecessary and unjustifiable and had damaged the reputation of ASIS and Australia overseas. The commissioners stated that 'evidence presented to us of action and reaction in other countries satisfies us that the publication was damaging': They rejected any suggestion that ASIS was unaccountable or 'out of control'. They said, 'its operational management is well structured and its tactical decisions are thoroughly considered and, in major instances, subject to external approval'. They recommended that complaints regarding ASIS operations continue to be handled by the Inspector-General of Intelligence and Security (IGIS) but that staff grievances be handled by the Administrative Appeals Tribunal.
In addition to their recommendations, Samuels and Codd put forward draft legislation to provide a statutory basis for ASIS and to protect various information from disclosure. The Samuels and Codd Bill, like the bulk of the reports, was not made public.
Controversies.
The Sheraton Hotel incident.
On 30 November 1983, ASIS garnered unwanted negative attention when a training operation held at the Sheraton Hotel, now the Mercure (Spring Street), in Melbourne went wrong. The exercise was to be a mock surveillance and hostage rescue of foreign intelligence officers. It involved junior officers who had undergone three weeks prior training and who were given considerable leeway in planning and executing the operation.
The mock hostage rescue was staged on the 10th floor of the hotel without the permission of the hotel's owner or staff. When ASIS officers were refused entry into a hotel room, they broke down the door with sledgehammers. The hotel manager, Nick Rice, was notified of a disturbance on the 10th floor by a hotel guest. When he went to investigate, he was forced back into the lift by an ASIS officer who rode the lift down to the ground floor and forcibly ejected Rice into the lobby. Believing a robbery was in progress, Rice called the police. When the lift started returning to the ground floor, ASIS officers emerged wearing masks and openly brandishing 9mm Browning pistols and Heckler & Koch MP5 submachine guns, two of them with silencers. They forced their way through the lobby to the kitchen, where two getaway cars were waiting outside the kitchen door. Police stopped one of the cars and arrested the occupants, who refused to produce any form of identification.
Within two days the Minister for Foreign Affairs Bill Hayden announced that an "immediate and full" investigation would be conducted under the auspices of the second Hope Royal Commission on Australian Security and Intelligence Agencies, which was still in progress. A report was prepared and tabled by February 1984. It described the exercise as being 'poorly planned, poorly supervised and poorly run' and recommended that measures be taken in training to improve planning and eliminate adverse impacts on the public.
The Victoria Police conducted their own investigation but were frustrated because the Director General of ASIS, John Ryan, refused to cooperate. Bill Hayden offered to provide the real names of the seven officers involved in confidence. Premier of Victoria John Cain told Hayden that "as far as the police were concerned, there was no such thing as information in confidence".
Following the incident, "The Sunday Age" disclosed the names, or the assumed names, of five of the officers involved. The journalist noted that 'according to legal advice taken by "The Sunday Age" there is no provision that prevents the naming of an ASIS agent'. While not included within the public version of the report, the Royal Commission headed by Mr Justice Hope did prepare an appendix which would appear to have dealt with the possible security and foreign relations consequences of disclosure of participants' names by "The Sunday Age". Subsequently, in "A v Hayden", the High Court held that the Commonwealth owed no enforceable duty to ASIS officers to maintain confidentiality of their names or activities.
At the time of the Sheraton Hotel incident, the extant Ministerial Directive permitted ASIS to undertake 'covert action', including 'special operations' which, roughly described, comprised 'unorthodox, possibly para-military activity, designed to be used in case of war or some other crisis'. Following the incident and the recommendations of the Royal Commission, the covert action function was apparently abolished. The functions of ASIS can be found in section 6 of the Intelligence Services Act, as can those functions which are proscribed by the act.
Ultimately, in executing the operation, the trainees were found to have used considerable force, menacing a number of the staff and guests with weapons and physically assaulting the hotel manager. Hope found Ryan to be at fault for authorising the training operation in a public place using concealed weapons. Ryan resigned in February 1984. Hope said it was not part of his Terms of Reference to make findings or recommendations on whether any individual had committed any offence. However he did note that the individuals could potentially be prosecuted by the State of Victoria with a long list of criminal offences, including possession of firearms without a licence, possession of prohibited implements (including machine guns, silencers and housebreaking tools), aggravated burglary in possession of a firearm, common assault, wilful damage to property, possession of a disguise without lawful excuse and numerous motor vehicle offences. More than a year after the raid, the Victorian Director of Public Prosecutions concluded that while certain offences had been committed, including criminal damage and assault with a weapon, there was insufficient evidence to charge any person with a specific offence.
Victorian Holdings Ltd, the company managing the hotel, subsequently took legal action against the Commonwealth on behalf of itself and 14 hotel staff. The matter was settled out of court with the hotel being offered $300,000 in damages. The total payout to the hotel and staff was $365,400.
Involvement in Papua New Guinea.
Between 1989 and 1991 ASIS came under scrutiny following allegations relating to its role and activities in Papua New Guinea. It was alleged that ASIS had been involved in training Papua New Guinean troops to suppress independence movements in Irian Jaya and Bougainville. (In 1997 it was alleged that ASIS and DSD had failed to collect, or the Government had failed to act upon, intelligence regarding the role and presence of Sandline contractors in relation to the independence movement in Bougainville.)
"Four Corners" program.
Towards the end of 1993 ASIS became the subject of media attention after allegations were made by former ASIS officers that ASIS was unaccountable and out of control. One newspaper alleged that 'ASIS regularly flouted laws, kept dossiers on Australian citizens ... and hounded agents out of the service with little explanation'. In particular it alleged that agents were being targeted in a purge by being threatened with criminal charges relating to their official conduct, reflecting a pattern which suggested to some that ASIS or a senior ASIS officer had been 'turned' by a foreign intelligence service.
On 21 February 1994 "Four Corners" ran a program which aired the key allegations. Two former ASIS officers made claims regarding cultural and operational tensions between ASIS and the Department of Foreign Affairs and Trade (DFAT). They claimed that embassy staff had maliciously or negligently compromised activities involving the running of foreign informants and agents and the defection of foreign agents to Australia. They claimed that their grievances were ignored and that they were 'deserted in the field' and made scapegoats by ASIS.
The officers and the reporter Ross Coulthart also made brief claims regarding operational activities and priorities. The officers personally claimed that ASIS advice had been ignored by DFAT. The reporter repeated claims regarding ASIS operations aimed at destabilising the Aquino Government in the Philippines. He also made claims regarding ASIS assistance to MI6 in the Falkland conflict, in Hong Kong and in Kuwait for the benefit of British interests (including commercial interests) and potentially to the detriment of Australian interests.
The bulk of the personal statements by the officers concerned their private grievances. They raised two issues of public interest regarding the effect of secrecy on the operation of grievance procedures and the extent to which the Minister for Foreign Affairs and Trade was aware of or in control of ASIS operations. The reporter directly raised the issue of the appropriateness of ASIS operations particularly with respect to priority setting in overseas postings and operations, cooperation with foreign intelligence services, and the privacy of Australian persons and organisations. By implication, the program queried the extent to which ASIS is or should be accountable to the Minister, to Government and to Parliament.
The following day, the Shadow Minister for Foreign Affairs called for an independent judicial inquiry into the allegations. He expressed particular concern about the nature of ASIS cooperation with foreign agencies and the defects in ASIS grievance procedures. He later called for the inquiry to examine the 'poisoned relationship between ASIS and DFAT'. The Democrats spokeswoman called for a standing parliamentary committee.
Two days after the program aired, the Samuels and Codd Royal Commission was formed by Minister for Foreign Affairs Gareth Evans.
Alleged management and staffing problems.
In 2005, "The Bulletin" ran an article based on allegations by serving ASIS officers that alluded to gross mismanagement of intelligence operations, staff assignments, and taskings, particularly with respect to the war on terrorism.
The unnamed officers pointed out various problems within the agency that were plaguing the organisation's ability to collect vital and timely intelligence, such as the pitting of "..."young mostly white university educated agents with limited language skills and little knowledge of Islam against poor, zealous extremists intent on becoming suicide bombers".", the "inappropriate" assignment of "..."young female IOs" (Intelligence Officers) "against Islamic targets"...", poor staff retention rates, and general lack of officers possessing meaningful field experience.
The officers also cite a lack of proper support given to IOs tasked against terrorist targets, and the doctoring of intelligence by ASIS management, as also contributing to the lack of progress of the agency in the war on terrorism.
Legislative changes affecting ASIS.
Intelligence Services Act 2001.
ASIS was created as a result of an Executive Order in 1952, and as such, had no legislative basis. On 27 June 2001, the Intelligence Services Act 2001 (ISA) was introduced into Parliament by then Minister for Foreign Affairs Alexander Downer, which proposed significant changes to the Australian Intelligence Community (AIC). The Act was passed by Parliament on 29 October 2001.
The Intelligence Services Act 2001 converted ASIS into a statutory body, headed by the Director General. It set out the function of ASIS and the limit on that function. 
Use of weapons was prohibited by ASIS (except for self-defence). Conduct of violent or para-military operations was also curtailed.
The act authorised the minister responsible for ASIS to issue directions to the agency.
Ministerial authorisation is required for intelligence collection activities involving Australians but limited the circumstances in which this could be done.
It required the minister to make rules regulating the communication and retention of intelligence information concerning Australian persons. The Act provided for the establishment of a parliamentary oversight committee, the Parliamentary Joint Committee on ASIO, ASIS and DSD.
Intelligence Services Amendment Act 2004.
On 15 October 2003, the "Intelligence Services Amendment Bill 2003" was introduced into Parliament by Foreign Minister Alexander Downer, as an amendment to the original Intelligence Services Act 2001 (ISA). The Bill sought to amend the original ISA to allow ASIS to be involved in the planning and undertaking of paramilitary or violent activities "by others", and provide, train with, and use weapons and self-defence techniques "in certain circumstances" (that is where the overseeing minister deems the circumstances suitable). The Bill allowed ASIS to work with other organisations (such as the CIA or MI6) in paramilitary operations, provided ASIS staff and agents were not personally involved in carrying it out. Passed on 1 April 2004, five and a half months after it was introduced, the legislation enables ASIS Intelligence Officers to carry a firearm, but only for protection. These officers will also receive weapons handling training, and new generation interrogation training.
Credit.
A large portion of the history of ASIS was adapted from the Parliament of Australia Bills Digest No. 11 of 2001–02 of Intelligence Services Act 2001

</doc>
<doc id="37127" url="https://en.wikipedia.org/wiki?curid=37127" title="Australian Signals Directorate">
Australian Signals Directorate

Australian Signals Directorate (ASD) (formerly: Defence Signals Directorate (DSD)) is an Australian government intelligence agency responsible for signals intelligence (SIGINT) and information security (INFOSEC). ASD was established in 1947.
Overview.
ASD has two principal functions: to collect and disseminate foreign signals intelligence; and to provide information security products and services to the Australian Government and its Defence Force.
Based in Canberra, at the Defence Headquarters at Russell Offices it operates monitoring facilities at Kojarena, Western Australia and at Shoal Bay, Northern Territory, which are believed to be part of the ECHELON system, and is involved in Pine Gap.
Under the 1948 UKUSA agreement, ASD's intelligence is shared with its foreign partner agencies: the National Security Agency (NSA)United States, the Government Communications Headquarters (GCHQ)United Kingdom, the Communications Security Establishment (CSE)Canada, and the Government Communications Security Bureau (GCSB)New Zealand.
Electronic warfare operators in the Royal Australian Corps of Signals work closely with the Australian Signals Directorate. 7 Signal Regiment (Electronic Warfare) at Borneo Barracks, , Queensland is associated with ASD.
Facilities.
The ASD operates at least three receiving stations: the Australian Defence Satellite Communications Station (ADSCS), located at Kojarena, near Geraldton, Western Australia; the Shoal Bay Receiving Station, located at Shoal Bay, Northern Territory; and a small station on the Cocos (Keeling) Islands.
These stations contribute signals intelligence for many Australian Government bodies, as well as the wider UKUSA partners. The ASD also maintains a workforce at Pine Gap in central Australia.
In addition, it has been reported that many Australian embassies and overseas missions also house small facilities which provide a flow of signals intelligence to ASD.
Naming.
The Directorate has operated under a number of different names since its founding:

</doc>
<doc id="37129" url="https://en.wikipedia.org/wiki?curid=37129" title="Darkthrone">
Darkthrone

Darkthrone is a Norwegian heavy metal band. They formed in 1986 as a death metal band under the name Black Death. In 1991, the band embraced a black metal style influenced by Bathory and Celtic Frost and became one of the leading bands in the Norwegian black metal scene. Their first three black metal albums—"A Blaze in the Northern Sky", "Under a Funeral Moon" and "Transilvanian Hunger" (sometimes dubbed the "Unholy Trinity") — are considered the peak of the band's career and to be among the most influential albums in the genre. For most of this time, Darkthrone has been a duo of Nocturno Culto and Fenriz, who have sought to remain outside the music mainstream. Since 2006, their work has strayed from the traditional black metal style and incorporated more elements of traditional heavy metal, speed metal and punk rock, being likened to Motörhead.
History.
Death metal years: 1986–1990.
The band that would become Darkthrone formed in late 1986 in Kolbotn, a small suburb of Oslo. They were a death metal band by the name of Black Death whose members were Gylve Nagell, Ivar Enger, and Anders Risberget. Main inspirations were Venom, Celtic Frost, Slayer and Cryptic Slaughter. In fall 1987, the band changed their name to Darkthrone and were joined by Dag Nilsen. Ted Skjellum joined in spring of 1988. During 1988 and 1989, the band independently released four demo tapes: "Land of Frost", "A New Dimension", "Thulcandra", and "Cromlech".
They were subsequently signed to the independent record label Peaceville Records with a four-album contract. In 1990, they recorded their first studio album, "Soulside Journey". Because of a small recording budget, the band could not afford the kind of studio they wanted but, thanks to the members of Nihilist and Entombed, they were able to record their album at Sunlight Studios. Although mainly death metal in style, there were some elements of black metal present in terms of artwork and songwriting.
Immediately following the release of this album, the band continued writing and recording new material, recording every new song on tape until it was a full album. These demos were entirely instrumental but they demonstrated the band's gradual shift towards black metal. In 1997, they would be released on the compilation album "Goatlord".
Early black metal years: 1991–1994.
During 1991, Darkthrone adopted the aesthetic style that would come to represent the black metal scene, wearing corpse paint and working under pseudonyms. Gylve Nagell became "Fenriz", Ted Skjellum became "Nocturno Culto" and Ivar Enger became "Zephyrous". In August 1991, they recorded their second album, which was released at the beginning of 1992 and titled "A Blaze in the Northern Sky". The album contained Darkthrone's first black metal recordings, and Peaceville Records was originally skeptical about releasing it due to Darkthrone's extreme diversion from their original death metal style. After the album was recorded, bassist Dag Nilsen left the band, and is merely credited as "session bass" with no picture on the album.
The band's third album, "Under a Funeral Moon", was recorded in the summer of 1992 and released in early 1993. It marked Darkthrone's total conversion to the black metal style, and is considered a landmark for the development of the genre as a whole. This album also marked the last album on which guitarist Zephyrous would perform.
It was followed by their fourth album, "Transilvanian Hunger", which was released in February 1994. This was Darkthrone's first album to have just two members, Nocturno Culto and Fenriz. The band would remain a duo from this point onwards. "Transilvanian Hunger" was characterized by a very "raw" or "low fidelity" recording style and musical simplicity. The album's release caused some controversy: some of its lyrics were written by the infamous Norwegian black metal musician Varg Vikernes, and its booklet contained the phrase "Norsk Arisk Black Metal", which translates into English as "Norwegian Aryan Black Metal".
With Moonfog Records: 1995–2004.
Darkthrone moved to another independent record label, Moonfog Productions, for subsequent releases. The label was run by Satyr of the black metal band Satyricon.
Their fifth album, "Panzerfaust", was released in 1995. The album was received well, although its production, which is similar to that of "Transilvanian Hunger", encountered some criticisms. Their sixth album, "Total Death", was released during 1996 and is notable for featuring lyrics written by four other black metal musicians, and none at all written by the group's main lyricist Fenriz.
During the years 1993–1995, drummer Fenriz was involved with numerous side projects. This included his solo ambient project Neptune Towers, recording an album with Satyr as the trio Storm, and playing bass on Dødheimsgard's debut album. Also he began playing drums for Valhall again, after having been one of the founding members in 1988 but leaving in 1990 to concentrate on Darkthrone.
In 1999, Darkthrone released the album "Ravishing Grimness", and in 2001 their following album, "Plaguewielder". While "Transilvanian Hunger" and "Panzerfaust" had songs written solely by Fenriz, these two albums had songs mostly written by Nocturno Culto and were both recorded in Ronny Le Tekrøe's studio at Toten, Norway. This explains the somewhat "clearer" sound on those records.
In the last years of the 90s, two Darkthrone tribute albums were released: "Darkthrone Holy Darkthrone" in 1998 and "The Next Thousand Years Are Ours" in 1999. The band also released "Preparing for War", a compilation of songs from 1988–1994. In 2002, the intro of their song "Kathaarian Life Code" appeared in the last scene of the film "Demonlover".
In 2003, the band released the album "Hate Them". Although this record and their next contain electronic introductions, they remain true to Darkthrone's early black metal style. "Sardonic Wrath" was released in 2004. It was the band's last album with Moonfog Productions and their last to be recorded solely in the black metal style. This album was nominated for Norway's Alarm Awards; however, the album's entry was withdrawn at the band's request. Their next releases would feature strong crust punk traits.
Change in direction: 2005–present.
In 2005, Darkthrone confirmed that they had returned to Peaceville Records, after leaving the record label in 1994. They had also started up their own record label, Tyrant Syndicate Productions, to release their future albums. To celebrate their return, Peaceville re-issued the "Preparing for War" compilation with a bonus CD of demos and a DVD of live performances. Darkthrone's first four albums were also re-released with video interviews about each of them.
Darkthrone released their eleventh album, "The Cult Is Alive", during early 2006. The album represented a shift in the band's style as the music incorporated crust punk traits. While Darkthrone's black metal roots were still evident, their shift from the genre's typical sound was more noticeable. "The Cult Is Alive" was the first Darkthrone album to appear on the album chart in Norway, debuting at number 22.
In July 2007, the band released the EP "NWOBHM" (an acronym for "New Wave of Black Heavy Metal", a take-off on the original "New Wave of British Heavy Metal") as a preview for their next album. In September that year, Darkthrone released the album "F.O.A.D." (an acronym for "Fuck Off and Die"). The phrase was used by many thrash metal and punk bands during the 1980s. While the music partially continued the punk-oriented style that was introduced on "The Cult Is Alive", this time the band focused more on traditional heavy metal.
Also during 2007, Nocturno Culto completed and released "The Misanthrope", a film about black metal and life in Norway. It includes some of his own solo recordings. In October 2008, "Dark Thrones and Black Flags" was released, using much the same style as the previous album. In 2010, the band released the album "Circle the Wagons", which again mixed crust punk along with speed metal and traditional heavy metal.
In late 2010, Peaceville acquired the rights to the band's Moonfog albums and re-issued "Panzerfaust" as a two-disc set and on vinyl. The re-issue of "Total Death" was set for March 14, 2011. In July 2012, Darkthrone announced a new album, titled "The Underground Resistance"; it was released on February 25, 2013. The band will release their 16th studio album in 2016.

</doc>
<doc id="37131" url="https://en.wikipedia.org/wiki?curid=37131" title="Burzum">
Burzum

Burzum (; ) is a musical project of Norwegian musician and writer Varg Vikernes. Vikernes began making music in 1988, but it was not until 1991 that he recorded his first demos as Burzum. The word "burzum" means "darkness" in the Black Speech, a fictional language crafted by "Lord of the Rings" writer J. R. R. Tolkien. The project became a part of the early Norwegian black metal scene and one of the most influential acts in black metal.
Vikernes recorded the first four Burzum albums between January 1992 and March 1993. However, the releases were spread out, with many months between the recording and the release of each album. In May 1994, Vikernes was sentenced to 21 years in prison for the murder of Mayhem guitarist Øystein 'Euronymous' Aarseth and the arson of three churches.
While imprisoned, Vikernes recorded two dark ambient albums using only synthesizers, as he did not have access to drums, guitar or bass. Since his release from prison in 2009, he has recorded three further black metal albums and several ambient/electronic albums.
Although Vikernes is known for his political views, he does not use Burzum to promote those views. Burzum has never played live and Vikernes says he has no intention of doing so.
History.
Early years (1988–1992).
Vikernes began making music in 1988 with the band Kalashnikov. The following year, the name was changed to Uruk-Hai, after the creatures from J. R. R. Tolkien's "The Lord of the Rings". In 1990 and 1991, Vikernes played guitar for the death metal band Old Funeral, which also consisted of members who would later form the band Immortal. He appears on the Old Funeral EP "Devoured Carcass". Vikernes left Old Funeral in 1991 to concentrate on creating his own musical visions. He had a short lived project called Satanel, along Abbath Doom Occulta. He then began a solo project under the name Burzum. The word "burzum" means "darkness" in the Black Speech; a language crafted by Tolkien. Soon after recording two demo tapes, he became part of the Norwegian black metal scene. With his demo tapes, he had attracted attention from Øystein "Euronymous" Aarseth of Mayhem, who had just recently formed Deathlike Silence Productions. Aarseth then signed Burzum to the label, and shortly after, Vikernes ―under the pseudonym of Count Grishnackh―, began to record Burzum’s self-titled debut album. According to Vikernes' autobiography on his website, he had intended to record the album in the worst recording quality possible (due to this being a typical trademark of the early Norwegian black metal scene), though still make it sound acceptable. Burzum's eponymous debut album was released in 1992, being the second album released on Deathlike Silence Productions. The song "War" from this album had a guest appearance from Euronymous, playing a guitar solo "just for fun", according to Vikernes.
Vikernes has stated that he had never played any live shows with Burzum, though at one point was interested in it, so Samoth of Emperor joined the band as their bassist, though only appearing on the "Aske" EP. Additionally, Erik Lancelot was hired to be the band's drummer, though did not record on any Burzum material, and along with Samoth did not play a live show. Vikernes had by then lost his interest in playing live concerts, and stated that he "didn't even need session musicians anymore". Therefore, Samoth and Lancelot had parted ways with Burzum. "Det som engang var" was released as Burzum's second album in 1993, recorded in 1992.
Imprisonment (1993–2009).
15 May 1994 saw the release of "Hvis lyset tar oss", a new album of previously recorded material from 1992. Burzum remained as a solo project until 1994, when Vikernes was arrested for the murder of Euronymous and the burnings of several churches in Norway. During his time in prison, Vikernes released his next album, titled "Filosofem", on 1 January 1996. Recorded in March 1993, "Filosofem" was the last recording Vikernes made before his imprisonment. "Burzum / Aske", a compilation comprising the "Burzum" album and "Aske" EP, was released in 1995. While imprisoned, Vikernes managed to record two other albums in a dark ambient style. They were released as "Dauði Baldrs" (1997) and "Hliðskjálf" (1999).
In 1998, all Burzum albums released up to that point were re-released as vinyl picture discs in a special box set called "1992–1997"; however the "Filosofem" album didn't contain "Rundtgåing av den transcendentale egenhetens støtte" due to its length. The regular vinyl issue of "Filosofem" on Misanthropy had tracks 1–4 plus "Decrepitude II" on side 1 and "Rundtgåing av den transcendentale egenhetens støtte" on side 2.
Post-imprisonment (2009–present).
Soon after being released, Vikernes started writing new tracks (nine metal tracks and an ambient intro and outro) for an upcoming Burzum album. According to Vikernes' recounts, several record companies were interested in releasing his first album in eleven years. He stated about the new album, "I want to take my time, and make it the way I want it. It will be metal, and the fans can expect genuine Burzum."
The album was going to be originally titled "Den hvite guden" ("The White God"), but he later decided to change it to "Belus", which was released by Byelobog Productions ("byelobog" is the transliteration of "белобог" in Slavic languages, meaning "white god") on 8 March 2010. It was also announced that a movie would be released in 2010, based on Varg Vikernes' life in the early 1990s. The movie would mainly draw inspiration from the book "Lords of Chaos", with the film being of the same name. Vikernes expressed his contempt towards both the movie and the book upon which it is based.
A second new album of original Burzum material, "Fallen", was released on 7 March 2011, followed by a compilation album, "From the Depths of Darkness", containing re-recordings of tracks from Burzum's self-titled album and "Det som engang var", on 28 November 2011. A third new studio album of original material, titled "Umskiptar", was released in May 2012. "Sôl austan, Mâni vestan" ("East of the Sun, West of the Moon"), Burzum's first electronic album since 1999, was released in May 2013. On April 27, 2013, a song was posted on the official YouTube channel of Vikernes, titled "Back to the Shadows." In a blog post, Vikernes stated that "Back to the Shadows" will be the last metal track released by Burzum.
The album "The Ways of Yore" was released on June 2, 2014.
Nothing is currently known about the progress of the next Burzum album.
Musical style.
Burzum's music features characteristics common in black metal, including distorted, tremolo-picked guitar riffs, harsh vocals and the use of double bass blast beat techniques in the drumming. Earlier Burzum albums feature very low production quality, which has improved in albums created after Vikernes' release from prison. Burzum's early music shows heavy Tolkien influence; for example, Vikernes' early moniker "Count Grishnackh" is taken from an orc character called Grishnákh in Tolkien's works. The choice of the name for the project reflects both this influence and the desire for anonymity: "Burzum" is a word of the Black Speech of Mordor meaning "darkness" (though Vikernes views what Christians consider "darkness" as "light"), and is one of those found on the Ring-inscription of the One Ring (the final part of the Ring inscription being ""...agh burzum-ishi krimpatul"", or "...and in the 'darkness" bind them").
Musically, Burzum has progressed from black metal to classical-influenced ambient music characterised by minimalist tendencies and dark atmospheres. Vikernes' music is characterised by hypnotic repetition and simple yet profound song structures; this trademark sound has been present on Burzum's black metal and electronic albums alike. Vikernes has described Burzum as a kind of "spell" or recreation of an imaginary world tied in with Pagan history. Each album, he claims, was designed as a kind of "spell" in itself, with each beginning song intending to make the listener more susceptible to "magic", the following songs to inspire a "trance-like state of mind", and the last song to carry the listener into a "world of fantasy" (dreams, for the listener would fall asleep—Burzum was supposed to have been evening music). Vikernes claims the intent to create this fantasy world came from dissatisfaction with the real world. He has stated the "message" of Burzum can be found in the lyrics of the first song of the first album ("Feeble Screams from Forests Unknown").

</doc>
<doc id="37135" url="https://en.wikipedia.org/wiki?curid=37135" title="Barbecue">
Barbecue

Barbecue (also barbeque, BBQ and barby/barbies) is both a cooking method and an apparatus. The generally accepted differences between barbecuing and grilling are cooking durations and the types of heat used. Grilling is generally done quickly over moderate-to-high direct heat that produces little smoke, while barbecuing is done slowly over low, indirect heat and the food is flavored by the smoking process.
The word barbecue when used as a noun can refer to the cooking method, the meat cooked in this way, the cooking apparatus (the "barbecue grill" or simply "barbecue"), or to an event where this style of food is featured. Used as an adjective, "barbecued" refers to foods cooked by this method. The term is also used as a verb for the act of cooking food in this manner. Barbecuing is usually done out-of-doors by smoking the meat over wood or charcoal. Restaurant barbecue may be cooked in large brick or metal ovens designed for that purpose. There are numerous regional variations of barbecuing, and it is practiced around many areas of the world.
Etymology.
Some etymologists believe the word "barbecue" derives from "barabicu" found in the language of the Taíno people of the Caribbean and the Timucua of Florida; it has entered some European languages in the form of "barbacoa". The "Oxford English Dictionary" (OED) traces the word to Haiti and translates it as a "framework of sticks set upon posts". Gonzalo Fernández De Oviedo y Valdés, a Spanish explorer, was the first to use the word "barbecoa" in print in Spain in 1526 in the "Diccionario de la Lengua Española (2nd Edition) of the Real Academia Española." After Columbus landed in the Americas in 1492, the Spaniards apparently found native Haitians roasting meat over a grill consisting of a wooden framework resting on sticks above a fire. The flames and smoke rose and enveloped the meat, giving it a certain flavor. The same framework was also used as protection from nocturnal animal attacks.
Traditional "barbacoa" involves digging a hole in the ground and placing some meat—usually a whole lamb—above pot so the juices can be used to make a broth. It is then covered with maguey leaves and coal, and set alight. The cooking process takes a few hours. Olaudah Equiano, an African abolitionist, described this method of roasting alligators among the "Mosquito People" (Miskito people) on his journeys to Cabo Gracias a Dios in his narrative "The Interesting Narrative of the Life of Olaudah Equiano".
Linguists have suggested the word barbacoa migrated from the Caribbean and into other languages and cultures; it moved from Caribbean dialects into Spanish, then Portuguese, French, and English. According to the OED, the first recorded use of the word in English was a verb in 1661, in Edmund Hickeringill's "Jamaica Viewed": "Some are slain, And their flesh forthwith Barbacu'd and eat". The word "barbecue" was published in English in 1672 as a verb from the writings of John Lederer, following his travels in the North American southeast in 1669-70. The first known use of the word as a noun was in 1697 by the British buccaneer William Dampier. In his "New Voyage Round the World", Dampier wrote, " ... and lay there all night, upon our Borbecu's, or frames of Sticks, raised about 3 foot from the Ground".
Samuel Johnson's 1756 dictionary gave the following definitions:
While the standard modern English spelling of the word is "barbecue", variations including "barbeque" and truncations such as "bar-b-q" or "BBQ" may also be found. The spelling "barbeque" is given in Merriam-Webster and the Oxford Dictionaries as a variant. In the southeastern United States, the word "barbecue" is used predominantly as a noun referring to roast pork, while in the southwestern states cuts of beef are often cooked.
Styles.
In general British usage, "barbecuing" refers to a fast cooking process done directly over high heat, while "grilling" refers to cooking under a source of direct, moderate-to-high heat—known in the United States as "broiling". In American English usage, "grilling" refers to a fast process over high heat while "barbecuing" refers to a slow process using indirect heat or hot smoke, similar to some forms of roasting. In a typical U.S. home grill, food is cooked on a grate directly over hot charcoal, while in a U.S. barbecue the coals are dispersed to the sides or at a significant distance from the grate. Its South American versions are the southern Brazilian churrasco and the Argentine asado.
U.S. South and Midwest.
In the southern United States, barbecues initially involved the cooking of pork. During the 19th century, pigs were a low-maintenance food source that could be released to forage in woodlands. When food or meat supplies were low, these semi-wild pigs could then be caught and eaten.
According to estimates, prior to the American Civil War, Southerners ate around of pork for every of beef they consumed. Because of the effort to capture and cook these wild hogs, pig slaughtering became a time for celebration and the neighborhood would be invited to share in the largesse. In Cajun culture, these feats are called "boucheries" or "pig pickin's". The traditional Southern barbecue grew out of these gatherings.
Each Southern locale has its own variety of barbecue, particularly sauces. North Carolina sauces vary by region; eastern North Carolina uses a vinegar-based sauce, the center of the state uses Lexington-style barbecue, with a combination of ketchup and vinegar as their base, and western North Carolina uses a heavier ketchup base. Lexington calls itself "The Barbecue Capital of the World"; it has more than one BBQ restaurant per 1,000 residents. South Carolina is the only state that traditionally includes all four recognized barbecue sauces, including mustard-based, vinegar-based, and light and heavy tomato-based sauces. Memphis barbecue is best known for tomato- and vinegar-based sauces. in some Memphis establishments and in Kentucky, meat is rubbed with dry seasoning (dry rubs) and smoked over hickory wood without sauce. The finished barbecue is then served with barbecue sauce on the side.
The barbecue of Alabama, Georgia, and Tennessee is almost always pork served with a sweet tomato-based sauce. Several regional variations exist. Alabama is known for its distinctive white sauce—a mayonnaise- and vinegar-based sauce originating in northern Alabama, used predominantly on chicken and pork. A popular item in North Carolina and Memphis is the pulled pork sandwich served on a bun and often topped with coleslaw. Pulled pork is prepared by shredding the pork after it has been barbecued.
Kansas City-style barbecue is characterized by its use of different types of meat, including pulled pork, pork ribs, burnt ends, smoked sausage, beef brisket, beef ribs, smoked/grilled chicken, smoked turkey, and sometimes fish—a variety attributable to Kansas City's history as a center for meat packing. Hickory is the primary wood used for smoking in KC, while the sauces are typically tomato based with sweet, spicy, and tangy flavors. Burnt ends, pieces of meat cut from the ends of a smoked beef brisket, are popular in many Kansas City-area barbecue restaurants.
Pit-beef prevails in Maryland and is often enjoyed at large outdoor "bull roasts", which are commonly fundraising events for clubs and associations. Maryland-style pit-beef is not the product of barbecue cookery in the strictest sense; the meat is not smoked but grilled over a high heat. The meat is typically served rare with a strong horseradish sauce as the preferred condiment.
The state of Kentucky, particularly Western Kentucky, is unusual in its barbecue cooking; the preferred meat is mutton. This kind of mutton barbecue is often used in communal events in Kentucky, such as political rallies, county fairs, and church fund-raising events.
In the midwest, Chicago-style is popular; this involves seasoning the meat with a dry rub, searing it over a hot grill, and cooking it slowly in an oven. The meat, typically ribs, is then finished with a sweet and tangy sauce.
Events and gatherings.
The word "barbecue" is also used to refer to a social gathering where food is served, usually outdoors in the evening or late afternoon. In the southern United States, outdoor gatherings are not typically called "barbecues" unless barbecue itself is served, typically, they use the term "cookouts". The device used for cooking at a barbecue is commonly referred to as a "barbecue", "barbecue grill", or "grill". In North Carolina, however, "barbecue" is a noun primarily referring to the food; natives of the state never use the word to describe the act of cooking or the device on which the meat is cooked.
Barbecue competitions are held in virtually every state in the United States between around April and September. These events feature competitions between teams of cooks and are divided into separate competitions for the best pork, beef, and poultry barbecue, and for the best barbecue sauces.
Techniques.
Barbecuing encompasses four or five distinct types of cooking techniques. The original technique is cooking using smoke at low temperatures—usually around 240–280 °F or 115–145 °C—and significantly longer cooking times (several hours), known as "smoking". Another technique, known as "baking", used a masonry oven or baking oven that uses convection to cook meats and starches with moderate temperatures for an average cooking time of about an hour. "Braising" combines direct, dry heat charbroiling on a ribbed surface with a broth-filled pot for moist heat. Using this technique, cooking occurs at various speeds, starting fast, slowing down, then speeding up again, lasting for a few hours.
Grilling is done over direct, dry heat, usually over a hot fire over ) for a few minutes. Grilling may be done over wood, charcoal, gas, or electricity. The time difference between barbecuing and grilling is because of the temperature difference; at low temperatures used for barbecuing, meat takes several hours to reach the desired internal temperature.
Smoking.
Smoking is the process of flavoring, cooking, or preserving food by exposing it to smoke from burning or smoldering material, most often wood. Meat and fish are the most common smoked foods, though cheeses, vegetables, nuts, and ingredients used to make beverages such as beer or smoked beer are also smoked.
Roasting.
The masonry oven is similar to a smoke pit; it allows for an open flame but cooks more quickly and uses convection to cook. Barbecue-baking can also be done in traditional stove-ovens. It can be used to cook meats, breads and other starches, casseroles, and desserts. It uses direct and indirect heat to surround the food with hot air to cook, and can be basted in much the same manner as grilled foods.
Braising.
It is possible to braise meats and vegetables in a pot on top of a grill. A gas or electric charbroil grill are the best choices for "barbecue-braising", combining dry heat charbroil-grilling directly on a ribbed surface and braising in a broth-filled pot for moist heat. The pot is placed on top of the grill, covered, and allowed to simmer for a few hours. There are two advantages to barbecue-braising; it allows browning of the meat directly on the grill before the braising. It also allows for glazing of meat with sauce and finishing it directly over the fire after the braising. This effectively cooks the meat three times, which results in a soft, textured product that falls off the bone. The time needed for braising varies depending on whether a slow cooker or pressure cooker is used; it is generally slower than regular grilling or baking, but quicker than pit-smoking.
Other uses.
The term "barbecue" is also used to designate a flavor added to foodstuffs, the most prominent of which are potato chips.

</doc>
<doc id="37137" url="https://en.wikipedia.org/wiki?curid=37137" title="Arabidopsis">
Arabidopsis

Arabidopsis (rockcress) is a genus in the family Brassicaceae. They are small flowering plants related to cabbage and mustard. This genus is of great interest since it contains thale cress ("Arabidopsis thaliana"), one of the model organisms used for studying plant biology and the first plant to have its entire genome sequenced. Changes in thale cress are easily observed, making it a very useful model.
Status.
Currently, the genus "Arabidopsis" has nine species and a further eight subspecies recognised. This delimitation is quite recent and is based on morphological and molecular phylogenies by O'Kane and Al-Shehbaz (1997, 2003) and others.
Their findings confirm the species formerly included in "Arabidopsis" made it polyphyletic. The most recent reclassification moves two species previously placed in "Cardaminopsis" and "Hylandra" and three species of "Arabis" into "Arabidopsis", but excludes 50 that have been moved into the new genera "Beringia, Crucihimalaya, Ianhedgea, Olimarabidopsis", and "Pseudoarabidopsis".
All of the species in "Arabidopsis" are indigenous to Europe, while two of the species have broad ranges also extending into North America and Asia.
In the last two decades, "Arabidopsis thaliana" has gained much interest from the scientific community as a model organism for research on numerous aspects of plant biology. The Arabidopsis Information Resource (TAIR) is a curated online information source for "Arabidopsis thaliana" genetic and molecular biology research, and The Arabidopsis Book is an online compilation of invited chapters on "Arabidopsis thaliana" biology. In Europe, the model organism resource centre for "Arabidopsis thaliana" germplasm, bioinformatics and molecular biology resources (including GeneChips) is the Nottingham Arabidopsis Stock Centre – NASC whilst in North America germplasm services are provided by the Arabidopsis Biological Resource Center, (ABRC) based at the Ohio State University. The ordering system for ABRC was incorporated into The Arabidopsis Information Resource (TAIR) database in June 2001 whilst NASC has always (since 1991) hosted its own ordering system and genome browser.
Starting with a kickstarter in 2013, Arabidopsis has had genes for luciferin and luciferase inserted to create a strain of "Glowing Plant" Arabidopsis set to be commercially distributed approximately in 2016.
"A. thaliana" in partial "in vitro" conditions.
Recently, "A. thaliana" tissues have been cultivated in microfluidic devices. Plant-on-chip devices show promise for future research in understanding the mechanism of sexual reproduction in "A. thaliana".
Cytogenetics.
Cytogenetic analysis has shown the haploid chromosome number (n) is variable and can be 5, 8 and 13.
"A. thaliana" is n=5 and the DNA sequencing of this species was completed in 2001.
"A. suecica" is n=13 (5+8) and is an amphidiploid species originated through hybridization between "A. thaliana" and diploid "A. arenosa". 
"A. neglecta" is n=8, as are the various subspecies of "A. halleri".
Various subspecies of "A. lyrata" and "A. arenosa" can be either 2n (diploid) or 4n (tetraploid). 
As of 2005, "A. cebennensis", "A. croatica" and "A. pedemontana" have not been investigated cytologically.
Reclassified species.
The following species previously placed in "Arabidopsis" are not currently considered part of the genus.

</doc>
<doc id="37138" url="https://en.wikipedia.org/wiki?curid=37138" title="Arabidopsis thaliana">
Arabidopsis thaliana

Arabidopsis thaliana ( thale cress, mouse-ear cress or arabidopsis) is a small flowering plant native to Eurasia. "A. thaliana" is edible by humans and, as with other mustard greens, is used in salads or sautéed, like many species in the Brassicacea. "A. thaliana" is considered a weed; it is found by roadsides and in disturbed lands. A winter annual with a relatively short life cycle, "Arabidopsis" is a popular model organism in plant biology and genetics. For a complex multicellular eukaryote, "Arabidopsis thaliana" has a relatively small genome of approximately 135 megabase pairs (Mbp). It was long thought to have the smallest genome of all flowering plants, but the smallest flowering plants' genomes are now considered to belong to plants in the genus "Genlisea", order Lamiales, with "Genlisea tuberosa", a carnivorous plant, showing a genome size of approximately 61 Mbp. "Arabidopsis thaliana" was the first plant to have its genome sequenced, and is a popular tool for understanding the molecular biology of many plant traits, including flower development and light sensing. In 2016, it was named as one of the organisms that would be involved in CRISPR-based genetic engineering.
Discovery and name origin.
The plant was first described in 1577 in the Harz Mountains by Johannes Thal (1542–1583), a physician from Nordhausen, Thüringen, Germany, who called it "Pilosella siliquosa". In 1753, Carl Linnaeus renamed the plant "Arabis thaliana" in honor of Thal. In 1842, the German botanist Gustav Heynhold erected the new genus "Arabidopsis" and placed the plant in that genus. The genus name, "Arabidopsis", comes from Greek, meaning "resembling "Arabis"" (the genus in which Linnaeus had initially placed it).
Habitat, morphology and life cycle.
"Arabidopsis" is native to Europe, Asia, and northwestern Africa. It also appears to be native in tropical afroalpine ecosystems. It is an annual (rarely biennial) plant, usually growing to 20–25 cm tall. The leaves form a rosette at the base of the plant, with a few leaves also on the flowering stem. The basal leaves are green to slightly purplish in color, 1.5–5 cm long and 2–10 mm broad, with an entire to coarsely serrated margin; the stem leaves are smaller and unstalked, usually with an entire margin. Leaves are covered with small, unicellular hairs (called trichomes). The flowers are 3 mm in diameter, arranged in a corymb; their structure is that of the typical Brassicaceae. The fruit is a siliqua 5–20 mm long, containing 20–30 seeds. Roots are simple in structure, with a single primary root that grows vertically downward, later producing smaller lateral roots. These roots form interactions with rhizosphere bacteria such as "Bacillus megaterium".
"Arabidopsis" can complete its entire lifecycle in six weeks. The central stem that produces flowers grows after about three weeks, and the flowers naturally self-pollinate. In the lab, "Arabidopsis" may be grown in Petri plates, pots, or hydroponics, under fluorescent lights or in a greenhouse.
Distribution.
A. thaliana is naturally found in most Eurasian countries reaching down into the upper part of Africa. There are over 750 natural varieties of A. thaliana found around the world. All varieties of A. thliana have various differences dependent on where in the world they are found. This variation among different environments suggests that all strains of A. thaliana have a common ancestor and have adapted evolutionarily over time.
Research.
The first mutant in "Arabidopsis" was documented in 1873 by Alexander Braun, describing a double flower phenotype (the mutated gene was likely "Agamous", cloned and characterized in 1990). However, not until 1943 did Friedrich Laibach (who had published the chromosome number in 1907) propose "Arabidopsis" as a model organism. His student, Erna Reinholz, published her thesis on "Arabidopsis" in 1945, describing the first collection of "Arabidopsis" mutants that they generated using X-ray mutagenesis. Laibach continued his important contributions to "Arabidopsis" research by collecting a large number of ecotypes. With the help of Albert Kranz, these were organised into the current ecotype collection of 750 natural accessions of "A. thaliana" from around the world.
In the 1950s and 1960s, John Langridge and George Rédei played an important role in establishing "Arabidopsis" as a useful organism for biological laboratory experiments. Rédei wrote several scholarly reviews instrumental in introducing the model to the scientific community. The start of the "Arabidopsis" research community dates to a newsletter called "Arabidopsis" Information Service (AIS), established in 1964. The first International "Arabidopsis" Conference was held in 1965, in Göttingen, Germany.
In the 1980s, "Arabidopsis" started to become widely used in plant research laboratories around the world. It was one of several candidates that included maize, petunia, and tobacco. The latter two were attractive, since they were easily transformable with the then-current technologies, while maize was a well-established genetic model for plant biology. The breakthrough year for "Arabidopsis" as the preferred model plant came in 1986, when T-DNA-mediated transformation was first published, and this coincided with the first gene to be cloned and published in "Arabidopsis".
Characterized ecotypes and mutant lines of "Arabidopsis" serve as experimental material in laboratory studies. The most commonly used background lines are L"er", or Landsberg erecta, and Col, or Columbia. Other background lines less-often cited in the scientific literature are Ws, or Wassilewskija, C24, Cvi, or Cape Verde Islands, Nossen, etc. (see for ex.) Series of mutants, named L"er"-x, Col-x, have been obtained and characterized; in general, mutant lines are available through stock centers, of which best-known are the Nottingham Arabidopsis Stock Center-NASC and the Arabidopsis Biological Resource Center-ABRC in Ohio, USA.
The Col or Columbia ecotype was selected, as an agronomically performant line, by Rédei, within a (nonirradiated) population of seeds named Landsberg he received from Laibach. Columbia (named for the location of Rédei's former institution, the University of Missouri-Columbia) is the ecotype sequenced in the "Arabidopsis" Genome Initiative. The L"er" or Landsberg erecta line was selected by Rédei from within a Landsberg population on which he had performed some X-ray mutagenesis experiments. As the L"er" collection of mutants is derived from this initial line, L"er"-0 does not correspond to the Landsberg ecotype, which is named La-0.
Use as a model organism.
Botanists and biologists began to research "A. thaliana" in the early 1900s, and the first systematic collection of its mutations was performed around 1945. It is now widely used for studying plant sciences, including genetics, evolution, population genetics, and plant development. It plays the role in plant biology that mice and fruit flies ("Drosophila") play in animal biology. Although "A. thaliana" has little direct significance for agriculture, it has several traits that make it a useful model for understanding the genetic, cellular, and molecular biology of flowering plants.
The small size of its genome, and the fact that it is diploid, makes "Arabidopsis thaliana" useful for genetic mapping and sequencing — with about 135 mega base pairs and five chromosomes, "Arabidopsis" has one of the smallest genomes among plants. It was the first plant genome to be sequenced, completed in 2000 by the Arabidopsis Genome Initiative. The most up-to-date version of the "A. thaliana" genome is maintained by the Arabidopsis Information Resource (TAIR). Much work has been done to assign functions to its 27,000 genes and the 35,000 proteins they encode. Post-genomic research, such as metabolomics, has also provided useful insights to the metabolism of this species and how environmental perturbations can affect metabolic processes.
The plant's small size and rapid lifecycle are also advantageous for research. Having specialized as a spring ephemeral, it has been used to found several laboratory strains that take about six weeks from germination to mature seed. The small size of the plant is convenient for cultivation in a small space, and it produces many seeds. Further, the selfing nature of this plant assists genetic experiments. Also, as an individual plant can produce several thousand seeds; each of the above criteria leads to "A. thaliana" being valued as a genetic model organism.
Plant transformation in "Arabidopsis "is routine, using "Agrobacterium tumefaciens" to transfer DNA to the plant genome. The current protocol, termed "floral-dip", involves simply dipping a flower into a solution containing "Agrobacterium", the DNA of interest, and a detergent. This method avoids the need for tissue culture or plant regeneration.
The "Arabidopsis" gene knockout collections are a unique resource for plant biology made possible by the availability of high-throughput transformation and funding for genomics resources. The site of T-DNA insertions has been determined for over 300,000 independent transgenic lines, with the information and seeds accessible through online T-DNA databases. Through these collections, insertional mutants are available for most genes in "Arabidopsis".
The plant is well suited for light microscopy analysis. Young seedlings on the whole, and their roots in particular, are relatively translucent. This, together with their small size, facilitates live cell imaging using both fluorescence and confocal laser scanning microscopy. By wet-mounting seedlings in water or in culture media, plants may be imaged uninvasively, obviating the need for fixation and sectioning and allowing time-lapse measurements. Fluorescent protein constructs can be introduced through transformation. The developmental stage of each cell can be inferred from its location in the plant or by using fluorescent protein markers, allowing detailed developmental analysis.
TAIR and NASC are curated sources for diverse "Arabidopsis" genetic and molecular biology information, and also provide numerous links, for example, to databases that store the results of hundreds of genome-wide gene expression profile experiments. Seed and DNA stocks can be obtained from the Nottingham Arabidopsis Stock Centre or the Arabidopsis Biological Resource Center.
Flower development.
"Arabidopsis "has been extensively studied as a model for flower development. The developing flower has four basic organs: sepals, petals, stamens, and carpels (which go on to form pistils). These organs are arranged in a series of whorls: four sepals on the outer whorl, followed by four petals inside this, six stamens, and a central carpel region. Homeotic mutations in arabidopsis result in the change of one organ to another — in the case of the "Agamous" mutation, for example, stamens become petals and carpels are replaced with a new flower, resulting in a recursively repeated sepal-petal-petal pattern.
Observations of homeotic mutations led to the formulation of the ABC model of flower development by E. Coen and E. Meyerowitz. According to this model, floral organ identity genes are divided into three classes: class A genes (which affect sepals and petals), class B genes (which affect petals and stamens), and class C genes (which affect stamens and carpels). These genes code for transcription factors that combine to cause tissue specification in their respective regions during development. Although developed through study of arabidopsis flowers, this model is generally applicable to other flowering plants.
Leaf development.
Arabidopsis has offered considerable insights with regards to the genetics of leaf morphogenesis, particularly in dicotyledon-type plants. Much of the understanding has come from analyzing mutants in leaf development, some of which were identified in the 1960's, but were not analysed with genetic and molecular techniques until the mid-1990s. Arabidopsis leaves are well suited to studies of leaf development as their leaves are relatively simple and stable.
Using Arabidopsis, the genetics behind leaf shape development have become more clear and have been broken down into 3 stages: The initiation of the leaf primordium, the establishment of dorsiventrality, and the development of a marginal meristem. Leaf primordium are initiated by the suppression of the genes and proteins of the class I "KNOX" family (such as "SHOOT APICAL MERISTEMLESS"). These class I KNOX proteins directly suppress gibberellin biosynthesis in the leaf primodium. Many genetic factors were found to be involved in the suppression of these class I "KNOX" genes in leaf primordia (such as "ASYMMETRIC LEAVES1," "BLADE-ON-PETIOLE1", "SAWTOOTH1", etc). Thus, with this suppression, the levels of gibberellin increase and leaf primorium initiates growth.
The establishment of dorsiventrality is important since the dorsal surface of the leaf is different from the ventral surface.
Light sensing.
The photoreceptors phytochromes A, B, C, D, and E mediate red light-based phototropic response. Understanding the function of these receptors has helped plant biologists understand the signalling cascades that regulate photoperiodism, germination, de-etiolation, and shade avoidance in plants.
The UVR8 protein detects UV-B light and mediates response to this DNA damaging wavelength.
Arabidopsis was used extensively in the study of the genetic basis of phototropism, chloroplast alignment, and stomatal aperture and other blue light-influenced processes. These traits respond to blue light, which is perceived by the phototropin light receptors. Arabidopsis has also been important in understanding the functions of another blue light receptor, cryptochrome, which is especially important for light entrainment to control the plants' circadian rhythms.
Light response was even found in roots, which were thought not to be particularly sensitive to light. While gravitropic response of arabidopsis root organs is their predominant tropic response, specimens treated with mutagens and selected for the absence of gravitropic action showed negative phototropic response to blue or white light, and positive response to red light, indicating that the roots also show positive phototropism.
Light emitting.
In 2000, Dr. Janet Braam of Rice University genetically engineered "Arabidopsis" to glow in the dark when touched. The effect was visible to ultrasensitive cameras.
In 2013, a crowd funding project on Kickstarter called the Glowing Plant project offered to deliver seeds of genetically engineered "glow in the dark" Arabidopsis to its backers. The plants are expected to give off a dim glow.
Non-Mendelian inheritance.
In 2005, scientists at Purdue University proposed that "Arabidopsis "possessed an alternative to previously known mechanisms of DNA repair, which one scientist called a "parallel path of inheritance". It was observed in mutations of the "HOTHEAD" gene. Plants mutant in this gene exhibit organ fusion, and pollen can germinate on all plant surfaces, not just the stigma. After spending over a year eliminating simpler explanations, it was indicated that the plants "cached" versions of their ancestors' genes going back at least four generations, and used these records as templates to correct the "HOTHEAD" mutation and other single nucleotide polymorphisms. The initial hypothesis proposed the record may be RNA-based Since then, alternative models have been proposed which would explain the phenotype without requiring a new model of inheritance. More recently, the whole phenomenon is being challenged as a being a simple artifact of pollen contamination. "When Jacobsen took great pains to isolate the plants, he couldn't reproduce the phenomenon", notes Steven Henikoff. In response to the new finding, Lolle and Pruitt agree that Peng et al. did observe cross-pollination, but note that some of their own data, such as double reversions of both mutant genes to the regular form, cannot be explained by cross-pollination.
Plant–pathogen interactions.
It is important to understand how plants achieve resistance to protect the world's food production, as well as the agriculture industry. Many model systems have been developed to better understand interactions between plants and bacterial, fungal, oomycete, viral, and nematode pathogens. "Arabidopsis thaliana" has been successfully implemented in the study of the subdicipline of plant pathology, that is, the interaction between plants and disease-causing pathogens.
The use of arabidopsis has led to many breakthroughs in the advancement of knowledge of how plants manifest plant disease resistance. The reason most plants are resistant to most pathogens is through nonhost resistance. This is, not all pathogens will infect all plants. An example where arabidopsis was used to determine the genes responsible for nonhost resistance is "Blumeria graminis", the causal agent of powdery mildew of grasses. Arabidopsis mutants were developed using the mutagen ethyl methanesulfonate and screened to determine which mutants had increased infection by "B. graminis". The mutants with higher infection rates are referred to as PEN mutants due to the ability of "B. graminis" to penetrate arabidopsis to begin the disease process. The PEN genes were later mapped to identify the genes responsible for nonhost resistance to "B. graminis".
The best-characterized PRR in "A. thaliana" is FLS2 (Flagellin-Sensing2), which recognizes bacterial flagellin, a specialized organelle used by microorganisms for the purpose of motility, as well as the ligand flg22, which comprises the 22 amino acids recognized by FLS2. Discovery of FLS2 was facilitated by the identification of an "A. thaliana" ecotype, Ws-0, that was unable to detect flg22, leading to the identification of the gene encoding FLS2.
A second PRR, EF-Tu receptor (EFR), identified in "A. thaliana", recognizes the bacterial EF-Tu protein, the prokaryotic elongation factor used in protein synthesis, as well as the laboratory-used ligand elf18. Using "Agrobacterium"-mediated transformation, a technique that takes advantage of the natural process by which "Agrobacterium" transfers genes into host plants, the EFR gene was transformed into "Nicotiana benthamiana", tobacco plant that does not recognize EF-Tu, thereby permitting recognition of bacterial EF-Tu thereby confirming EFR as the receptor of EF-Tu.
Both FLS2 and EFR use similar signal transduction pathways to initiate PTI. "A. thaliana" has been instrumental in dissecting these pathways to better understand the regulation of immune responses, the most notable one being the mitogen-activated protein kinase (MAP kinase) cascade. Downstream responses of PTI include callose deposition, the oxidative burst, and transcription of defense-related genes.
PTI is able to combat pathogens in a nonspecific manner. A stronger and more specific response in plants is that of effector-triggered immunity (ETI). ETI is dependent upon the recognition of pathogen effectors, proteins secreted by the pathogen that alter functions in the host, by plant resistance genes (R-genes), often described as a gene-for-gene relationship. This recognition may occur directly or indirectly via a guardee protein in a hypothesis known as the guard hypothesis. The first R-gene cloned in "A. thaliana" was RPS2 (resistance to "Pseudomonas syringe" 2), which is responsible for recognition of the effector avrRpt2. The bacterial effector avrRpt2 is delivered into "A. thaliana" via the Type III secretion system of "P. syringae pv tomato" strain DC3000. Recognition of avrRpt2 by RPS2 occurs via the guardee protein RIN4, which is cleaved . Recognition of a pathogen effector leads to a dramatic immune response known as the hypersensitive response, in which the infected plant cells undergo cell death to prevent the spread of the pathogen.
Systemic acquired resistance (SAR) is another example of resistance that is better understood in plants because of research done in "A. thaliana". Benzothiadiazol (BTH), a salicylic acid (SA) analog, has been used historically as an antifungal compound in crop plants. BTH, as well as SA, has been shown to induce SAR in plants. The initiation of the SAR pathway was first demonstrated in "A. thaliana" in which increased SA levels are recognized by nonexpresser of PR genes 1 (NPR1) due to redox change in the cytosol, resulting in the reduction of NPR1. NPR1, which usually exists in a multiplex (oligomeric) state, becomes monomeric (a single unit) upon reduction. When NPR1 becomes monomeric, it translocates to the nucleus, were it interacts with many TGA transcription factors, and is able to induce pathogen-related genes such as PR1. Another example of SAR would be the research done with transgenic tobacco plants, which express bacterial salicylate hydroxylase, nahG gene, requires the accumulation of SA for its expression 
Evolutionary aspect of plant-pathogen resistance.
Plants are affected by multiple pathogens throughout their lifetime. In response to the presence of pathogens, plants have evolved receptors on the cell surface to detect and respond to pathogens. "Arabidopsis Thaliana" is a model organism used to determine specific defense mechanisms of plant-pathogen resistance. These plants have special receptors on their cell surfaces that allow for detection of pathogens and initiate mechanisms to inhibit pathogen growth. They contain two receptors, FLS2 (bacterial flagellin receptor) and EF-Tu (bacterial EF-Tu protein), which use signal transduction pathways to initiate the disease response pathway. The pathway leads to the recognition of the pathogen causing the infected cells to undergo cell death to stop the spread of the pathogen. Plants with FLS2 and EF-Tu receptors have shown to have increased fitness in the population. This has lead to the belief that plant-pathogen resistance is an evolutionary mechanism that has built up over generations to respond to dynamic environments, such as increased predation and extreme temperatures.
The standard plant disease resistance pathway consists of the FLS2 and Ef-Tu receptors. However, some plants have also shown a variation of the plant-pathogen resistance pathway consisting of the systemic acquired resistance pathway (SAR).
This pathway utilizes Benzothiadiazol, a chemical inducer, to induce transcription factors, mRNA, of SAR genes. This accumulation of transcription factors leads to inhibition of pathogen-related genes.
Plant-pathogen interactions are important for understanding of how plants have evolved to combat different types of pathogens that may affect them. Variation in resistance of plants across populations is due to variation in environmental factors. Plants that have evolved resistance, whether it be the general variation or the SAR variation, have been able to live longer and hold off necrosis of their tissue (premature death of cells), which leads to better adaptation and fitness for populations that are in rapidly changing environments.
Meiosis.
RAD51-like proteins have been identified in eukaryotes from yeast to vertebrates. These RAD51-like proteins catalyze key steps in recombinational repair of DNA damages. Recombinational repair is particularly important for removing double-strand damages during meiosis. In "A. thaliana" a mutant defective in a gene "rad51" homologue, "xrcc3", is hypersensitive to mitomycin C, a DNA interstrand crosslinking agent implying a deficiency in repair of these double-strand damages in somatic cells. The "xrcc3" mutants are also deficient in meiotic recombination and are sterile, indicating that "xrcc3" also plays an essential role in meiosis. Thus it is likely that in "A. thaliana xrcc3"-mediated recombinational repair of DNA damage is active in somatic cells and essential during meiosis.
Self-pollination.
"A. thaliana" is a predominantly self-pollinating plant with an outcrossing rate estimated at less than 0.3%. An analysis of the genome-wide pattern of linkage disequilibrium suggested that self-pollination evolved roughly a million years ago or more. Meioses that lead to self-pollination are unlikely to produce significant beneficial genetic variability. However, these meioses can provide the adaptive benefit of recombinational repair of DNA damages during formation of germ cells at each generation. Such a benefit may have been sufficient to allow the long-term persistence of meioses even when followed by self-fertilization. A physical mechanism for self-pollination in Arabidopsis is through pre-anthesis autogamy, such that fertilisation takes place largely before flower opening.
Multigenerational.
Ongoing research on "Arabidopsis thaliana" is being performed on the International Space Station by the European Space Agency. The goals are to study the growth and reproduction of plants from seed to seed in microgravity.
"Arabidopsis thaliana" in a microfluidic device.
Plant on a chip is a device in which Arabidopsis thaliana tissues could be cultured in semi in vitro conditions. Plant-on-chip devices are expected to play greater role in understanding pollen tube guidance and the mechanism of sexual reproduction in Arabidopsis thaliana.

</doc>
<doc id="37139" url="https://en.wikipedia.org/wiki?curid=37139" title="Long Island Rail Road">
Long Island Rail Road

The Long Island Rail Road , legally known as the Long Island Rail Road Company and often abbreviated as the LIRR, is a commuter rail system in southeastern New York, stretching from Manhattan to the eastern tip of Suffolk County on Long Island. With an average weekday ridership of 337,800 passengers in 2014, it is the busiest commuter railroad in North America. It is also one of the few commuter systems in the world that runs 24 hours a day, 7 days a week, year-round. It is publicly owned by the Metropolitan Transportation Authority, as MTA Long Island Rail Road. The current LIRR logo combines the circular MTA logo with the text "Long Island Rail Road", and appears on the sides of trains. The LIRR is one of two commuter rail systems owned by the MTA, the other being Metro-North Railroad. Established in 1834 and having operated continuously since then, it is the second oldest U.S. railroad still operating under its original name and charter.
There are 124 stations, and more than of track, on its two lines to the two forks of the island and eight major branches, with the passenger railroad system totaling of route.
History.
The Long Island Rail Road Company was chartered in 1834 to provide a daily service between New York and Boston via a ferry connection between its Greenport, New York, terminal on Long Island's North Fork and Stonington, Connecticut. This service was superseded in 1849 by the land route through Connecticut that became part of the New York, New Haven and Hartford Railroad. The LIRR refocused its attentions towards serving Long Island, in competition with other railroads on the island. In the 1870s railroad president Conrad Poppenhusen and his successor Austin Corbin acquired all the railroads and consolidated them into the LIRR.
The LIRR was unprofitable for much of its history. In 1900, the Pennsylvania Railroad (PRR) bought a controlling interest as part of its plan for direct access to Manhattan which began on September 8, 1910. The wealthy PRR subsidized the LIRR during the first half of the new century, allowing expansion and modernization.
After the Second World War the downturn in the railroad industry and dwindling profits caused the PRR to stop subsidizing the LIRR, and the LIRR went into receivership in 1949. The State of New York, realizing how important the railroad was to the future of Long Island, began to subsidize the railroad in the 1950s and 1960s. In 1966, New York State bought the railroad's controlling stock from the PRR and put it under the newly formed Metropolitan Commuter Transportation Authority (renamed Metropolitan Transportation Authority in 1968). With MTA subsidies the LIRR modernized further, continuing to be the busiest commuter railroad in the United States.
The LIRR is one of the few railroads that has survived as an intact company from its original charter to the present day.
Major stations.
The LIRR operates out of three western terminals, in Manhattan, Brooklyn, and Queens. Jamaica Station in central Queens is the hub of all railroad activities. Expansion of the system into Grand Central Terminal is anticipated over the next few years. Major stations include:
Passenger lines and services.
The Long Island Rail Road system is made up of eleven passenger branches. Three main trunk lines, the Main Line, Montauk Branch, and Atlantic Branch, spin off eight smaller branches. For scheduling and advertising purposes some of these branches are further divided into sections such as the case with the Montauk Branch, which is known as the Babylon Branch service in the electrified portion of the line between Jamaica and Babylon, while the diesel service beyond Babylon to Montauk is referred to as the Montauk Branch service. All branches except the Port Washington Branch pass through Jamaica; the trackage west of Jamaica (except to Port Washington) is known as the City Terminal Zone. The City Terminal Zone includes portions of the Main Line and Atlantic and Montauk Branches as well as the Amtrak-owned East River Tunnels to Penn Station. The passenger lines are:
Former branches.
The railroad has dropped a number of branches due to lack of ridership over the years. Part of the Rockaway Beach Branch became part of the IND Rockaway Line of the New York City Subway, while others were downgraded to freight branches, and the rest abandoned entirely.
Additional services.
In addition to its daily commuter patronage, the LIRR also offers the following services:
Fare structure.
Like Metro-North Railroad and New Jersey Transit, the Long Island Rail Road fare system is based on the distance a passenger travels, as opposed to the New York City Subway, which has a flat rate throughout the system. The railroad is broken up into eight numbered fare zones. Zone 1 includes all of the City Terminal Zone. Zone 3 includes Jamaica (and Flushing) and all stations east of Jamaica (and Flushing) within the boundaries of New York City, except Far Rockaway and Belmont Park. Zones 4 and 7 include all the stations in Nassau County and Far Rockaway. Zones 9, 10, 12 and 14 include all the stations in Suffolk County. Each zone contains many stations, and the same fare applies for travel between any station in the origin zone and any station in the destination zone.
Peak fares are charged during the week on trains that arrive at western terminals between 6 AM and 10 AM, and for trains that depart from western terminals between 4 PM and 8 PM. Any passenger holding an off peak ticket on a peak train is required to pay a step up fee. Passengers can buy tickets from ticket agents or ticket vending machines (TVMs) or on the train from conductors, but will incur an on-board penalty fee for doing so. This fee is waived for customers boarding at a station without a ticket office or ticket machine, senior citizens, people with disabilities or Medicare customers.
There are several types of tickets: one way, round trip, peak, off-peak, AM peak or off-peak senior/citizen disabled, peak child, and off-peak child. On off-peak trains, passengers can buy a family ticket for children who are accompanied by an 18-year-old for $0.75 if bought from the station agent or TVM, $1.00 on the train. Senior citizen/disabled passengers traveling during the morning peak hours are required to pay the AM peak senior citizen/disabled rate. This rate is not charged during PM peak hours.
Commuters can also buy a peak or off-peak ten trip ride, a weekly unlimited or an unlimited monthly pass. Monthly passes are good on any train regardless of the time of day, within the fare zones specified on the pass.
On weekends, the railroad offers a special reduced-fare CityTicket, introduced in 2004, for passengers who travel within Zones 1 and 3 (i.e. within New York City). CityTickets can only be bought from ticket agents or machines and used on the day of purchase. They are not valid for travel to Far Rockaway because it is in Zone 4 and the Far Rockaway Branch passes through Nassau County. It is also not valid for travel to the Belmont Park station, which is only open for special events. All passengers going to Belmont Park must buy a special ticket to go from Jamaica to Belmont Park (or vice versa), as weekly and monthly passes are not accepted at Belmont Park.
During the summer the railroad offers special summer package ticket deals to places such as Long Beach, Jones Beach, the Hamptons, Montauk, and Greenport. Passengers traveling to the Hamptons and Montauk on the "Cannonball" can reserve a seat in the all-reserved Parlor Cars.
Train operations.
The LIRR is relatively isolated from the rest of the national rail system. It connects with other railroads in just two locations:
All movements on the LIRR are under the control of the Movement Bureau in Jamaica, which gives orders to the towers that control a specific portion of the railroad. Movements in Amtrak territory are controlled by Penn Station Control Center or PSCC, run jointly by the LIRR and Amtrak. The PSCC controls as far east as Harold interlocking, in the Sunnyside area of Queens. The PSCC replaced several towers. The Jamaica Control Center (new in the third quarter of 2010) controls from there east through the Jamaica terminal by direct control of interlockings. This replaced several towers in Jamaica including Jay and Hall towers at the west and east ends of Jamaica station respectively. East of there, lineside towers control the various switches and signals under the direction of the dispatchers in Jamaica.
Nearly all the lines and all passenger rolling stock is equipped for cab signalling, which displays the block signal governing movement of trains in the cab. All passenger rolling stock is equipped with Automatic Speed Control (ASC), which enforces the speed limit dictated by the cab signal if the engineer fails to comply with it, by a penalty brake application. This feature greatly enhances safety.
On many of the lines, there are no intermediate wayside signals between the interlockings: operation is solely by cab signal. Wayside signals remain at interlockings.
Power transmission.
The LIRR's electrified lines are powered by 750 V DC third rail with the contact shoe running along the top of the rail, similar to the New York City Subway and PATH trains.
Equipment.
The LIRR's electric fleet consists of 836 M7 and 170 M3 electric multiple unit cars in married pairs, meaning each car needs the other one to operate, with each car containing its own engineer's cab. The trainsets typically range up to 12 cars long. In September 2013, MTA announced that the LIRR would procure new M9 railcars from Kawasaki starting in 2016. They will replace the M3s, and expand the railroad's electric fleet.
The LIRR also uses 134 C3 Bilevel coaches powered by 23 DE30AC diesel-electric locomotives and 21 DM30AC dual-mode locomotives. They are used mostly on non-electrified territories, including the Port Jefferson, Oyster Bay, Montauk, and Greenport Branches.
Named trains.
For most of its history LIRR has served commuters, but it had many named trains, some with all-first class seating, parlor cars, and full bar service. Few of them lasted past World War II, but some names were revived during the 1950s and 1960s as the railroad expanded its east end parlor car service with luxury coaches and Pullman cars from railroads that were discontinuing their passenger trains.
Freight service.
The LIRR and other railroads that became part of the system have always had freight service, though this has diminished. The process of shedding freight service accelerated with the acquisition of the railroad by New York State.
In recent years there has been some appreciation of the need for better railroad freight service in New York City and on Long Island. Both areas are primarily served by trucking for freight haulage, an irony in a region with the most extensive rail transit service in the Americas as well as the worst traffic conditions. Proposals for a Cross-Harbor Rail Tunnel for freight have languished more than a century.
In May 1997, freight service was franchised on a 20-year term to the New York and Atlantic Railway (NYAR), a short line railroad owned by the Anacostia and Pacific Company. It has its own equipment and crews, but uses the rail facilities of the LIRR. To the east, freight service operates to the end of the West Hempstead Branch, to Huntington on the Port Jefferson Branch, to Bridgehampton on the Montauk Branch, and to Riverhead on the Main Line. On the western end it provides service on the surviving freight-only tracks of the LIRR: the Bay Ridge and Bushwick branches; the "Lower Montauk" between Jamaica and Long Island City; and to an interchange connection at Fresh Pond Junction in Queens with the CSX, Canadian Pacific, and Providence and Worcester railroads.
Freight branches.
Some non-electrified lines are used only for freight:
Law enforcement.
The LIRR Police Department, founded in 1868, was absorbed along with the Metro-North Railroad Police to form the Metropolitan Transportation Authority Police (MTA Police) in 1998.
Criticism and controversy.
Passenger issues.
The LIRR has a long history of rocky relations with its passengers, especially daily commuters. Various commuter advocacy groups have been formed to try to represent those interests, in addition to the state mandated LIRR Commuters Council.
One criticism of the LIRR is that it has not improved service to the "east end" of Long Island as the twin forks continue to grow in popularity as a year round tourist and residential destination. Demand is evidenced by flourishing for-profit bus services such as the Hampton Jitney and the Hampton Luxury Liner and the early formative stages of a new East End Transportation Authority. Local politicians have joined the public outcry for the LIRR to either improve the frequency of east end services, or turn the operation over to a local transportation authority.
Critics claim that the on-time performance (OTP) calculated by the LIRR is manipulated to be artificially high. Because the LIRR does not release any raw timing data nor does it have independent (non-MTA) audits it is impossible to verify this claim, or the accuracy of the current On Time Performance measurement. The "percentage" measure is used by many other US passenger railroads but the criticism over accuracy is specific to the LIRR. As defined by the LIRR, a train is "on time" if it arrives at a station within 5 minutes and 59 seconds of the scheduled time. The criterion was 4 minutes and 59 seconds until the LIRR changed it because of a bug in their computer systems. Critics believe the OTP measure does not reflect what commuters experience on a daily basis. The LIRR publishes the current OTP in a monthly booklet called TrainTalk. TrainTalk was previously known as "Keeping Track."
A more accurate way to measure delays and OTP has been proposed. Called the "Passenger Hours Delayed" index it can measure total person-hours of a specific delay. This would be useful in comparing performance of specific days or incidents, day-to-day (or week-to-week) periods, something the current measure cannot do. This 'PHD' index measure is used by some transportation research organizations and would be more meaningful to commuters. it has not been adopted. The two methods are not mutually exclusive and could be kept and published simultaneously.
2007 ridership was 86.1 million, up 4.9% over 2006. The all-time highest ridership was in 1929, when 119 million passengers rode 1.89 billion passenger miles.
Pension and disability fraud scandal.
A "New York Times" investigation in 2008 showed that 25% of LIRR employees who had retired since 2000 filed for disability payments from the federal Railroad Retirement Board and 97% of them were approved to receive disability pension. The total collected was more than $250,000,000 over eight years. As a result, Railroad Retirement agents from Chicago inspected the Long Island office of the Railroad Retirement Board on September 23, 2008. New York Governor David Paterson issued a statement calling for Congress to conduct a full review of the board's mission and daily activities. Officials at the board's headquarters responded to the investigation stating that all occupational disability annuities were issued in accordance with applicable laws.
On November 17, 2008, a former LIRR pension manager was arrested and charged with official misconduct for performing outside work without permission. However, these charges were all dismissed for "no merit" by Supreme Court Judge Kase on December 11, 2009 on the grounds that the prosecution had misled the grand jury in the indictment.
A report produced in September 2009 by the Government Accountability Office stated that the rate at which retirees were rewarded disability claims was above the norm for the industry in general and indicated "troubling" practices that may indicate fraud, such as the use of a very small group of physicians in making the diagnosis.
Another series of arrests on October 27, 2011 included two doctors and a former union official.
According to court documents, from 1998 through 2011, 79% of LIRR retirees obtained federal disability when they retired. On August 6, 2013, a doctor and two consultants were found guilty in connection with the accusations and sentenced to prison.

</doc>
<doc id="37141" url="https://en.wikipedia.org/wiki?curid=37141" title="Triskaidekaphobia">
Triskaidekaphobia

Triskaidekaphobia (, or ; from Greek "tris" meaning "three", "kai" meaning "and", "deka" meaning "10" and "phobos" meaning "fear" or "morbid fear") is fear of the number and avoidance to use it. It is also a reason for the fear of Friday the 13th, called "paraskevidekatriaphobia" (from Παρασκευή "Paraskevi", Greek for Friday) or "friggatriskaidekaphobia" (after Frigg, the Norse goddess after whom Friday is named in English).
The term was first used by Isador Coriat in "Abnormal Psychology".
Origins.
Judas theory.
From the 1890s, a number of English language sources relate the "unlucky" thirteen to an idea that at the Last Supper, Judas, the disciple who betrayed Jesus, was the 13th to sit at the table. However, the Bible itself says nothing about the order in which the Apostles sat. Also, the number 13 is not uniformly bad in the Judeo-Christian tradition. For example, the attributes of God (also called the Thirteen Attributes of Mercy) are enumerated in the Torah (Exodus 34:6–7). Some modern Christian churches also use 13 attributes of God in sermons.
Hammurabi theory.
There is a myth that the earliest reference to thirteen being unlucky or evil is from the Babylonian Code of Hammurabi (circa 1780 BC), where the thirteenth law is omitted. In fact, the original Code of Hammurabi has no numeration. The translation by L.W. King (1910), edited by Richard Hooker, omitted one article:
If the seller have gone to (his) fate (i. e., have died), the purchaser shall recover damages in said case fivefold from the estate of the seller.
Other translations of the Code of Hammurabi, for example the translation by Robert Francis Harper, include the 13th article.
Other theories.
Triskaidekaphobia may have also affected the Vikings: It is believed that Loki was the 13th god in the Norse pantheon—more specifically, Loki was believed to have engineered the murder of Balder and was the 13th guest to arrive at the funeral. This is perhaps related to the superstition that if 13 people gather, one of them will die in the following year. However, the oldest source of this myth, "Lokasenna", has far more than 13 guests (17 of the guests are mentioned by name) so this example should not be taken too seriously. Another Norse tradition involves the myth of Norna-Gest: When the uninvited norns showed up at his birthday celebration (thus increasing the number of guests from ten to thirteen), they cursed the infant by magically binding his lifespan to that of a mystic candle they presented to him.
Events related to unlucky 13.
Apollo 13 launched on April 11, 1970 at 13:13:00 CST and experienced an oxygen tank explosion on April 13 at 21:07:53 CST. It later returned safely to earth on April 17.
On Friday, October 13, 1307, the arrest of the Knights Templar was ordered by Philip IV of France. While the number 13 was considered unlucky, Friday the 13th was not considered unlucky at the time. The incorrect idea that their arrest was related to the phobias surrounding Friday the 13th was invented early in the 21st century and popularized by the novel "The Da Vinci Code".
In 1881 an influential group of New Yorkers led by US Civil War veteran Captain William Fowler came together to put an end to this and other superstitions. They formed a dinner cabaret club, which they called the Thirteen Club. At the first meeting, on Friday, January 13, 1881, at 8:13 p.m., thirteen people sat down to dine in Room 13 of the venue. The guests walked under a ladder to enter the room and were seated among piles of spilled salt. Many Thirteen Clubs sprang up all over North America over the next 40 years. Their activities were regularly reported in leading newspapers, and their numbers included five future US presidents, from Chester A. Arthur to Theodore Roosevelt. Thirteen Clubs had various imitators, but they all gradually faded from interest.
Vehicle registration plates in the Republic of Ireland are such that the first two digits represent the year of registration of the vehicle (i.e., 11 is a 2011 registered car, 12 is 2012, and so on). In 2012, there were concerns among members of the Society of the Irish Motor Industry (SIMI) that the prospect of having "13" registered vehicles might discourage motorists from buying new cars because of superstition surrounding the number thirteen, and that car sales and the motor industry (which was already ailing) would suffer as a result. The government, in consultation with SIMI, introduced a system whereby 2013 registered vehicles would have their registration plates' age identifier string modified to read "131" for vehicles registered in the first six months of 2013 and "132" for those registered in the latter six months of the year. The main reason for this however, is to increase the number of car sales in the latter months of the year. Even though 70% of new cars are bought during the first four months of the year, some consumers believe that it doesn't accurately reflect the real age of a new car, since cars bought in January will most likely have been manufactured the previous year, while those bought later in the year will be actually made in the same year. This system continued after 2013, with vehicles registered in the first half of 2014 labelled "141" rather than "14".
Lucky 13.
In some regions 13 is considered a lucky number. For example, 13 is lucky in Italy except in some contexts, such as sitting at the dinner table. Colgate University was started by 13 men with $13 and 13 prayers, so 13 is considered a lucky number. Friday the 13th is the luckiest day at Colgate.
Several Venezuelan sportspeople have chosen 13 as squad number, most notably Dave Concepción, Omar Vizquel, Oswaldo Guillén and Pastor Maldonado.

</doc>
<doc id="37142" url="https://en.wikipedia.org/wiki?curid=37142" title="Zeno of Citium">
Zeno of Citium

Zeno of Citium (; , "Zēnōn ho Kitieus"; c. 334 – c. 262 BC) was a Greek thinker from Citium (, "Kition"), Cyprus, and probably of Phoenician descent. Zeno was the founder of the Stoic school of philosophy, which he taught in Athens from about 300 BC. Based on the moral ideas of the Cynics, Stoicism laid great emphasis on goodness and peace of mind gained from living a life of Virtue in accordance with Nature. It proved very successful, and flourished as the dominant philosophy from the Hellenistic period through to the Roman era.
Life.
Zeno was born c. 334 BC, in Citium in Cyprus. Most of the details known about his life come from the anecdotes preserved by Diogenes Laërtius in his "Lives and Opinions of Eminent Philosophers". Diogenes relates a legend that Zeno was a merchant; after surviving a shipwreck, Zeno wandered into a bookshop in Athens and was attracted to some writings about Socrates. He asked the librarian how to find such a man. In response, the librarian pointed to Crates of Thebes, the most famous Cynic living at that time in Greece.
Zeno is described as a haggard, tanned person, living a spare, ascetic life. This coincides with the influences of Cynic teaching, and was, at least in part, continued in his Stoic philosophy. From the day Zeno became Crates’s pupil, he showed a strong bent for philosophy, though with too much native modesty to assimilate Cynic shamelessness. Hence Crates, desirous of curing this defect in him, gave him a potful of lentil-soup to carry through the Ceramicus; and when he saw that Zeno was ashamed and tried to keep it out of sight, Crates broke the pot with a blow of his staff. As Zeno began to run off in embarrassment with the lentil-soup flowing down his legs, Crates chided "Why run away, my little Phoenician?", "nothing terrible has befallen you".
Apart from Crates, Zeno studied under the philosophers of the Megarian school, including Stilpo, and the dialecticians Diodorus Cronus, and Philo. He is also said to have studied Platonist philosophy under the direction of Xenocrates, and Polemo.
Zeno began teaching in the colonnade in the Agora of Athens known as the Stoa Poikile (Greek Στοὰ Ποικίλη) in 301 BC. His disciples were initially called Zenonians, but eventually they came to be known as Stoics, a name previously applied to poets who congregated in the Stoa Poikile.
Among the admirers of Zeno was king Antigonus II Gonatas of Macedonia, who, whenever he came to Athens, would visit Zeno. Zeno is said to have declined an invitation to visit Antigonus in Macedonia, although their supposed correspondence preserved by Laërtius is undoubtedly the invention of a later rhetorician. Zeno instead sent his friend and disciple Persaeus, who had lived with Zeno in his house. Among Zeno's other pupils there were Aristo of Chios, Sphaerus, and Cleanthes who succeeded Zeno as the head ("scholarch") of the Stoic school in Athens.
Zeno is said to have declined Athenian citizenship when it was offered to him, fearing that he would appear unfaithful to his native land, where he was highly esteemed. We are also told that Zeno was of an earnest, if not gloomy disposition; that he preferred the company of the few to the many; that he was fond of burying himself in investigations; and that he had a dislike to verbose and elaborate speeches. Diogenes Laërtius has preserved many clever and witty remarks by Zeno, the veracity of which cannot be ascertained.
Zeno died around 262 BC. Laërtius reports about his death: 
During his lifetime, Zeno received appreciation for his philosophical and pedagogical teachings. Among other things, Zeno was honored with the golden crown, and a tomb was built in honor of his moral influence on the youth of his era.
The crater Zeno on the Moon is named in his honor.
Philosophy.
Following the ideas of the Academics, Zeno divided philosophy into three parts: Logic (a very wide subject including rhetoric, grammar, and the theories of perception and thought); Physics (not just science, but the divine nature of the universe as well); and Ethics, the end goal of which was to achieve happiness through the right way of living according to Nature. Because Zeno's ideas were built upon by Chrysippus and other Stoics, it can be difficult to determine, in some areas, precisely what he thought, but his general views can be outlined:
Logic.
In his treatment of Logic, Zeno was influenced by Stilpo and the other Megarians. Zeno urged the need to lay down a basis for Logic because the wise person must know how to avoid deception. Cicero accused Zeno of being inferior to his philosophical predecessors in his treatment of Logic, and it seems true that a more exact treatment of the subject was laid down by his successors, including Chrysippus. Zeno divided true conceptions into the comprehensible and the incomprehensible, permitting for free-will the power of assent ("sunkatathesis"/συνκατάθεσις) in distinguishing between sense impressions. Zeno said that there were four stages in the process leading to true knowledge, which he illustrated with the example of the flat, extended hand, and the gradual closing of the fist:
Zeno stretched out his fingers, and showed the palm of his hand, – "Perception," – he said, – "is a thing like this."- 
Then, when he had closed his fingers a little, – "Assent is like this." – Afterwards, when he had completely closed his hand, and showed his fist, that, he said, was Comprehension. From which simile he also gave that state a new name, calling it "katalepsis" (κατάληψις). But when he brought his left hand against his right, and with it took a firm and tight hold of his fist: – "Knowledge" – he said, was of that character; and that was what none but a wise person possessed.
Physics.
The Universe, in Zeno's view, is God: a divine reasoning entity, where all the parts belong to the whole. Into this pantheistic system he incorporated the physics of Heraclitus; the Universe contains a divine artisan-fire, which foresees everything, and extending throughout the Universe, must produce everything:
Zeno, then, defines nature by saying that it is artistically working fire, which advances by fixed methods to creation. For he maintains that it is the main function of art to create and produce, and that what the hand accomplishes in the productions of the arts we employ, is accomplished much more artistically by nature, that is, as I said, by artistically working fire, which is the master of the other arts.
This divine fire, or aether, is the basis for all activity in the Universe, operating on otherwise passive matter, which neither increases nor diminishes itself. The primary substance in the Universe comes from fire, passes through the stage of air, and then becomes water: the thicker portion becoming earth, and the thinner portion becoming air again, and then rarefying back into fire. Individual souls are part of the same fire as the world-soul of the Universe. Following Heraclitus, Zeno adopted the view that the Universe underwent regular cycles of formation and destruction.
The Nature of the Universe is such that it accomplishes what is right and prevents the opposite, and is identified with unconditional Fate, while allowing it the free-will attributed to it.
Ethics.
Like the Cynics, Zeno recognised a single, sole and simple good, which is the only goal to strive for. "Happiness is a good flow of life," said Zeno, and this can only be achieved through the use of right Reason coinciding with the Universal Reason ("Logos"), which governs everything. A bad feeling ("pathos") "is a disturbance of the mind repugnant to Reason, and against Nature." This consistency of soul, out of which morally good actions spring, is Virtue, true good can only consist in Virtue.
Zeno deviated from the Cynics in saying that things that are morally indifferent could nevertheless have value. Things have a relative value in proportion to how they aid the natural instinct for self-preservation. That which is to be preferred is a "fitting action" ("kathêkon"/καθῆκον), a designation Zeno first introduced. Self-preservation, and the things that contribute towards it, has only a conditional value; it does not aid happiness, which depends only on moral actions.
Just as Virtue can only exist within the dominion of Reason, so Vice can only exist with the rejection of Reason. Virtue is absolutely opposed to Vice, the two cannot exist in the same thing together, and cannot be increased or decreased; no one moral action is more virtuous than another. All actions are either good or bad, since impulses and desires rest upon free consent, and hence even passive mental states or emotions that are not guided by reason are immoral, and produce immoral actions. Zeno distinguished four negative emotions: desire, fear, pleasure and pain ("epithumia, phobos, hêdonê, lupê" / ἐπιθυμία, φόβος, ἡδονή, λύπη), and he was probably responsible for distinguishing the three corresponding positive emotions: will, caution, and joy ("boulêsis, eulabeia, chara" / βούλησις, εὐλάβεια, χαρά), with no corresponding rational equivalent for pain. All errors must be rooted out, not merely set aside, and replaced with right reason.
Works.
None of Zeno's writings have survived except as fragmentary quotations preserved by later writers. However, the titles of many of Zeno's writings are known and are as follows:
The most famous of these works was Zeno's "Republic", a work written in conscious imitation of (or opposition to) Plato. Although it has not survived, more is known about it than any of his other works. It outlined Zeno's vision of the ideal Stoic society built on egalitarian principles.

</doc>
<doc id="37143" url="https://en.wikipedia.org/wiki?curid=37143" title="Chrysippus">
Chrysippus

Chrysippus of Soli (, ; ) was a Greek Stoic philosopher. He was a native of Soli, Cilicia, but moved to Athens as a young man, where he became a pupil of Cleanthes in the Stoic school. When Cleanthes died, around 230 BC, Chrysippus became the third head of the school. A prolific writer, Chrysippus expanded the fundamental doctrines of Zeno of Citium, the founder of the school, which earned him the title of Second Founder of Stoicism.
Chrysippus excelled in logic, the theory of knowledge, ethics and physics. He created an original system of propositional logic in order to better understand the workings of the universe and role of humanity within it. He adhered to a deterministic view of fate, but nevertheless sought a role for personal freedom in thought and action. Ethics, he taught, depended on understanding the nature of the universe, and he taught a therapy of extirpating the unruly passions which depress and crush the soul. He initiated the success of Stoicism as one of the most influential philosophical movements for centuries in the Greek and Roman world.
Life.
Chrysippus, the son of Apollonius of Tarsus, was born at Soli, Cilicia. He was slight in stature, and is reputed to have trained as a long-distance runner. While still young, he lost his substantial inherited property when it was confiscated to the king's treasury. Chrysippus moved to Athens, where he became the disciple of Cleanthes, who was then the head ("scholarch") of the Stoic school. He is believed to have attended the courses of Arcesilaus and his successor Lacydes, in the Platonic Academy.
Chrysippus threw himself eagerly into the study of the Stoic system. His reputation for learning among his contemporaries was considerable. He was noted for intellectual audacity and self-confidence and his reliance on his own ability was shown, among other things, in the request he is supposed to have made to Cleanthes: "Give me the principles, and I will find the proofs myself." He succeeded Cleanthes as head of the Stoic school when Cleanthes died, in around 230 BC.
Chrysippus was a prolific writer. He is said to rarely have gone without writing 500 lines a day and he composed more than 705 works. His desire to be comprehensive meant that he would take both sides of an argument and his opponents accused him of filling his books with the quotations of others. He was considered diffuse and obscure in his utterances and careless in his style, but his abilities were highly regarded, and he came to be seen as a preeminent authority for the school.
He died during the 143rd Olympiad (208–204 BC) at the age of 73. Diogenes Laërtius gives two different accounts of his death. In the first account, Chrysippus was seized with dizziness having drunk undiluted wine at a feast, and died soon after. In the second account, he was watching a donkey eat some figs and cried out: "Now give the donkey a drink of pure wine to wash down the figs", whereupon he died in a fit of laughter. His nephew Aristocreon erected a statue in his honour in the Kerameikos. Chrysippus was succeeded as head of the Stoic school by his pupil Zeno of Tarsus.
Of his written works, none have survived except as fragments quoted in the works of later authors like Cicero, Seneca, Galen, Plutarch, and others. Recently, segments from "Logical Questions" and "On Providence" were discovered among the Herculaneum papyri. A third work by Chrysippus may also be among them.
Philosophy.
Chrysippus had a long and successful career of resisting the attacks of the Academy and hoped not simply to defend Stoicism against the assaults of the past, but also against all possible attack in the future. He took the doctrines of Zeno and Cleanthes and crystallized them into what became the definitive system of Stoicism. He elaborated the physical doctrines of the Stoics and their theory of knowledge and he created much of their formal logic. In short, Chrysippus made the Stoic system what it was. It was said that "without Chrysippus, there would have been no Stoa".
Logic.
Chrysippus wrote much on the subject of logic and created a system of propositional logic. Aristotle's term logic had been concerned with the interrelations of terms such as "Socrates" or "man" ("all men are mortal, Socrates is a man, so Socrates is mortal"). Stoic logic, on the other hand, was concerned with the interrelations of propositions such as "it is day" ("if it is day, it is light: but it is day: so it is light"). Though the earlier Megarian dialecticians – Diodorus Cronus and Philo – had worked in this field and the pupils of Aristotle – Theophrastus and Eudemus – had investigated hypothetical syllogisms, it was Chrysippus who developed these principles into a coherent system of propositional logic.
Propositions.
Chrysippus defined a proposition as "that which is capable of being denied or affirmed as it is in itself" and gave examples of propositions such as "it is day" and "Dion is walking." He distinguished between simple and non-simple propositions, which in modern terminology are known as atomic and molecular propositions. A simple proposition is an elementary statement such as "it is day." Simple propositions are linked together to form non-simple propositions by the use of logical connectives. Chrysippus enumerated five kinds of molecular propositions according to the connective used:
Thus several types of molecular propositions, familiar to modern logic, were listed by Chrysippus, including the conjunction, the disjunction, and the conditional, and Chrysippus studied their criteria of truth closely.
Conditional propositions.
The first logicians to debate conditional statements were Diodorus Cronus and his pupil Philo. Writing five-hundred years later, Sextus Empiricus refers to a debate between Diodorus and Philo. Philo regarded all conditionals as true except those which with a correct antecedent had an incorrect consequent, and this meant a proposition such as "if it is day, then I am talking," is true unless it is day and I fall silent. But Diodorus argued that a true conditional is one in which the antecedent clause could never lead to an untrue conclusion – thus, because the proposition "if it is day, then I am talking" can be false, it is invalid. However, paradoxical propositions were still possible such as "if atomic elements of things do not exist, atomic elements exists." Chrysippus adopted a much stricter view regarding conditional propositions, which made such paradoxes impossible: to him, a conditional is true if denial of the consequent is logically incompatible with the antecedent. This corresponds to the modern-day strict conditional.
Syllogistic.
Chrysippus developed a syllogistic or system of deduction in which he made use of five types of basic arguments or argument forms called indemonstrable syllogisms, which played the role of axioms, and four inference rules, called "themata" by means of which complex syllogisms could be reduced to these axioms. The forms of the five indemonstrables were:
Of the four inference rules, only two survived. One, the so-called first "thema", was a rule of antilogism. The other, the third "thema", was a cut rule by which chain syllogisms could be reduced to simple syllogisms. The purpose of Stoic syllogistic was not merely to create a formal system. It was also understood as the study of the operations of reason, the divine reason ("logos") which governs the universe, of which human beings are a part. The goal was to find valid rules of inference and forms of proof to help people find their way in life.
Other logical work.
Chrysippus analyzed speech and the handling of names and terms. He also devoted much effort in refuting fallacies and paradoxes. According to Diogenes Laërtius, Chrysippus wrote twelve works in 23 books on the Liar paradox; seven works in 17 books on amphiboly; and another nine works in 26 books on other conundrums. In all, 28 works or 66 books were given over to puzzles or paradoxes. 
Chrysippus is the first Stoic for whom the third of the four Stoic categories, i.e. the category "somehow disposed" is attested. In the surviving evidence, Chrysippus frequently makes use of the categories of "substance" and "quality", but makes little use of the other two Stoic categories ("somehow disposed" and "somehow disposed in relation to something"). It is not clear whether the categories had any special significance for Chrysippus, and a clear doctrine of categories may be the work of later Stoics.
Later reception.
Chrysippus came to be renowned as one of the foremost logicians of ancient Greece. When Clement of Alexandria wanted to mention one who was master among logicians, as Homer was master among poets, it was Chrysippus, not Aristotle, he chose. Diogenes Laërtius wrote: "If the gods use dialectic, they would use none other than that of Chrysippus." The logical work by Chrysippus came to be neglected and forgotten. Aristotle's logic prevailed, partly because it was seen as more practical, and partly because it was taken up by the Neoplatonists. As recently as the 19th century, Stoic logic was treated with contempt, a barren formulaic system, which was merely clothing the logic of Aristotle with new terminology. It was not until the 20th century, with the advances in logic, and the modern propositional calculus, that it became clear that Stoic logic constituted a significant achievement.
Epistemology.
For the Stoics, truth is distinguished from error by the sage who possesses right reason. Chrysippus's theory of knowledge was empirical. The senses transmit messages from the external world, and their reports are controlled not by referring them to innate ideas, but by comparing them to previous reports stored in the mind. Zeno had defined impressions of sense as "an impression in the soul" and this was interpreted literally by Cleanthes, who compared the impression on the soul to the impression made by a seal on wax. Chrysippus preferred to regard it as an alteration or change in the soul; that is, the soul receives a modification from every external object that acts upon it, just as the air receives countless strokes when many people are speaking at once.
In the receipt of an impression, the soul is purely passive and the impression reveals not only its own existence, but that also of its cause—just as light displays itself and the elements that are in it. The power to name the object resides in the understanding. First must come the impression, and the understanding—having the power of utterance—expresses in speech the affection it receives from the object. True presentations are distinguished from those that are false by the use of memory, classification and comparison. If the sense organ and the mind are healthy—and provided that an external object can be really seen or heard—the presentation, due to its clearness and distinctness, has the power to extort the assent that always lies in our power, to give or to withhold. In a context in which people are understood to be rational beings, reason is developed out of these notions.
Physics.
Chrysippus insisted on the organic unity of the universe, as well as the correlation and mutual interdependence of all of its parts. He said, "the universe is its own soul and its own controlling mind." Following Zeno, Chrysippus determined fiery breath or aether to be the primitive substance of the universe. Objects are made up of inert formless matter and an informing soul, ""pneuma"", provides form to the undifferentiated matter. The "pneuma" pervades all of substance and maintains the unity of the universe and constitutes the soul—the incorporeal and, in many conceptions, immortal essence of a person or living thing—of the human being.
The classical elements change into one another by a process of condensation and rarefaction. Fire first becomes solidified into air; then air into water; and lastly, water into earth. The process of dissolution takes place in the reverse order: earth being rarefied into water, water into air and air into fire.
The human soul was divided by Chrysippus into eight faculties: the five senses, the power of reproduction, the power of speech, and the "ruling part" that is located in the chest rather than the head. Individual souls are perishable; but, according to the view originated by Chrysippus, the souls of wise people survive longer after their death. No individual soul can, however, survive beyond the periodic conflagration, when the universe is renewed.
Fate.
For Chrysippus, all things happen according to fate: what seems to be accidental has always some hidden cause. The unity of the world consists in the chain-like dependence of cause upon cause. Nothing can take place without a sufficient cause. According to Chrysippus, every proposition is either true or false, and this must apply to future events as well:
If any motion exists without a cause, then not every proposition will be either true or false. For that which has not efficient causes is neither true nor false. But every proposition is either true or false. Therefore, there is no motion without a cause. And if this is so, then all effects owe their existence to prior causes. And if this is so, all things happen by fate. It follows therefore that whatever happens, happens by fate.
The Stoic view of fate is entirely based on a view of the universe as a whole. Individual things and persons only come into consideration as dependent parts of this whole. Everything is, in every respect, determined by this relation, and is consequently subject to the general order of the world.
If his opponents objected that, if everything is determined by destiny, there is no individual responsibility, since what has been once foreordained must happen, come what may, Chrysippus replied that there is a distinction to be made between simple and complex predestination. Becoming ill may be fated whatever happens but, if a person's recovery is linked to consulting a doctor, then consulting the doctor is fated to occur together with that person's recovery, and this becomes a complex fact. All human actions – in fact, our destiny – are decided by our relation to things, or as Chrysippus put it, events are "co-fated" to occur:
The non-destruction of one's coat, he says, is not fated simply, but co-fated with its being taken care of, and someone's being saved from his enemies is co-fated with his fleeing those enemies; and having children is co-fated with being willing to lie with a woman. ... For many things cannot occur without our being willing and indeed contributing a most strenuous eagerness and zeal for these things, since, he says, it was fated for these things to occur in conjunction with this personal effort. ... But it will be in our power, he says, with what is in our power being included in fate.
Thus our actions are predetermined, and are causally related to the overarching network of fate, but nevertheless the moral responsibility of how we respond to impressions remains our own. The one all-determining power is active everywhere, working in each particular being according to its nature, whether in rational or irrational creatures or in inorganic objects. Every action is brought about by the co-operation of causes depending on the nature of things and the character of the agent. Our actions would only be involuntary if they were produced by external causes alone, without any co-operation, on the part of our wills, with external causes. Virtue and vice are set down as things in our power, for which, consequently, we are responsible. Moral responsibility depends only on freedom of the will, and what emanates from our will is our own, no matter whether it is possible for us to act differently or not. This rather subtle position which attempts to reconcile determinism with human responsibility is known as soft-determinism, or compatibilism.
Divination.
Chrysippus also argued for the existence of fate based on divination, which he thought there was good evidence for. It would not be possible for diviners to predict the future if the future itself was accidental. Omens and portents, he believed, are the natural symptoms of certain occurrences. There must be countless indications of the course of providence, for the most part unobserved, the meaning of only a few having become known to humanity. To those who argued that divination was superfluous as all events are foreordained, he replied that both divination and our behaviour under the warnings which it affords are included in the chain of causation.
God.
The Stoics believed that the universe is God, and Chrysippus affirmed that "the universe itself is God and the universal outpouring of its soul." It is the guiding principle of the universe, "operating in mind and reason, together with the common nature of things and the totality which embraces all existence." Based on these beliefs, physicist and philosopher Max Bernhard Weinstein identified Chrysippus as a Pandeist.
Chrysippus sought to prove the existence of God, making use of a teleological argument:
If there is anything that humanity cannot produce, the being who produces it is better than humanity. But humanity cannot produce the things that are in the universe – the heavenly bodies, etc. The being, therefore, who produces them is superior to humanity. But who is there that is superior to humanity, except God? Therefore, God exists.
Chrysippus spoke of God and gods interchangeably. He interpreted the gods of traditional Greek religion by viewing them as different aspects of the one reality. Cicero tells us that "he further maintained that aether is that which people call Zeus, and that the air which permeates the seas is Poseidon, and that the earth is what is known by the name of Demeter, and he treated in similar style the names of the other gods." In addition, the universe exists for the benefit of the universal god:
We should infer in the case of a beautiful dwelling-place that it was built for its owners and not for mice; we ought, therefore, in the same way to regard the universe as the dwelling-place of the gods.
Theodicy.
In response to the question of how evil could exist in a good universe, Chrysippus replied "evil cannot be removed, nor is it well that it should be removed." Firstly, he argued, following Plato, that it was impossible for good to exist without evil, for justice could not be known without injustice, courage without cowardice, temperance without intemperance or wisdom without foolishness. Secondly, apparent evils exist as a consequent of nature's goodness, thus it was necessary for the human skull to be made from small and thin bones for reasons of utility, but this superior utility meant that the skull is vulnerable to blows. Thirdly, evils are distributed according to the rational will of Zeus, either to punish the wicked or because they are important to the world-order as a whole. Thus evil is good under disguise, and is ultimately conducive to the best. Chrysippus compared evil to the coarse jest in the comedy; for, just as the jest, though offensive in itself, improves the piece as a whole, "so too you may criticize evil regarded by itself, yet allow that, taken with all else, it has its use."
Mathematics.
Chrysippus regarded bodies, surfaces, lines, places, the void and time as all being infinitely divisible. He determined one of the principal features of the infinite set: since a man and a finger have an infinite number of parts as do the universe and a man, it cannot be said that a man has more parts than his finger, nor that the universe has more parts than a man.
Chrysippus also responded to a problem first posed by Democritus. If a cone is divided by a plane parallel to its base, are the surfaces of the segments equal or unequal? If they are equal, then the cone becomes a cylinder; if they are unequal, then the surface of the cone must be stepped. The reply of Chrysippus was that the surfaces are both equal and unequal. Chrysippus was, in effect, negating the law of excluded middle with respect to the equal and unequal, and thus he may have anticipated an important principle of modern infinitesimal calculus, namely, the limit and the process of convergence towards a limit.
Chrysippus was notable for claiming that "one" is a number. One was not always considered a number by the ancient Greeks since they viewed one as that by which things are measured. Aristotle in his "Metaphysics" wrote, "... a measure is not the things measured, but the measure or the One is the beginning of number." Chrysippus asserted that one had "magnitude one" (), although this was not generally accepted by the Greeks, and Iamblichus wrote that "magnitude one" was a contradiction in terms.
Ethics.
Chrysippus taught that ethics depended on physics. In his "Physical Theses", he stated: "for there is no other or more appropriate way of approaching the subject of good and evil on the virtues or happiness than from the nature of all things and the administration of the universe." The goal of life, said Chrysippus, is to live in accordance with one's experience of the actual course of nature. A person's individual nature is part of the nature of the whole universe, and thus life should be lived in accordance with one's own human nature as well as that of the universe. Human nature is ethical, and humanity is akin to the Divine, emanating from the primal fire or aether, which, though material, is the embodiment of reason; and people should conduct themselves accordingly. People have freedom, and this freedom consists in emancipation from irrational desires (lust, riches, position in life, domination, etc.) and in subjecting the will to reason. Chrysippus laid the greatest stress on the worth and dignity of the individual, and on the power of will.
The Stoics admitted between the good and the bad a third class of things – the indifferent ("adiaphora"). Of things morally indifferent, the best includes health, and riches, and honour, and the worst includes sickness and poverty. Chrysippus accepted that it was normal in ordinary usage to refer to the preferred indifferent things as "good", but the wise person, said Chrysippus, uses such things without requiring them. Practice and habit are necessary to render virtue perfect in the individual – in other words, there is such a thing as moral progress, and character has to be built up.
The Stoics sought to be free of the unruly emotions, which they regarded as being contrary to nature. The passions or emotions ("pathe") are the disturbing element in right judgment. Chrysippus wrote a whole book concerning the therapy of the emotions. The passions are like diseases which depress and crush the soul, thus he sought to eradicate them ("apatheia"). Wrong judgements turn into passions when they gather an impetus of their own, just as, when one has started running, it is difficult to stop. One cannot hope to eradicate the emotions when one is in the heat of love or anger: this can only be done when one is calm. Therefore, one should prepare in advance, and deal with the emotions in the mind as if they were present. By applying reason to emotions such as greed, pride, or lust, one can understand the harm which they cause.

</doc>
<doc id="37145" url="https://en.wikipedia.org/wiki?curid=37145" title="Lucretius">
Lucretius

Titus Lucretius Carus (; 99 BC – c. 55 BC) was a Roman poet and philosopher. His only known work is the epic philosophical poem "De rerum natura" about the tenets and philosophy of Epicureanism, and which is usually translated into English as "On the Nature of Things".
Very little is known about Lucretius's life; the only certain fact is that he was either a friend or client of Gaius Memmius, to whom the poem was addressed and dedicated.
"De rerum natura" was a considerable influence on the Augustan poets, particularly Virgil (in his "Aeneid" and "Georgics", and to a lesser extent on the "Eclogues") and Horace. The work virtually disappeared during the Middle Ages but was rediscovered in 1417 in a monastery in Germany by Poggio Bracciolini, and it played an important role both in the development of atomism (Lucretius was an important influence on Pierre Gassendi) and the efforts of various figures of the Enlightenment era to construct a new Christian humanism.
Life.
Virtually nothing is known about the life of Lucretius. He was probably a member of the aristocratic "gens Lucretia", and his work shows an intimate knowledge of the luxurious lifestyle in Rome. Lucretius's love of the countryside invites speculation that he inhabited family-owned rural estates, as did many wealthy Roman families, and he certainly was expensively educated with a mastery of Latin, Greek, literature, and philosophy. Jerome tells how he was driven mad by a love potion and wrote his poetry between fits of insanity, eventually committing suicide in middle age; but modern scholarship suggests this account was probably an invention. 
In a letter by Cicero to his brother Quintus in February 54 BC, Cicero said : "The poems of Lucretius are as you write: they exhibit many flashes of genius, and yet show great mastership." By this time, both Cicero and his brother had read "De rerum natura", and so might have many other Romans. A literary evaluation of Lucretius's work, however, reveals some repetition and a sudden end to Book 6 during a description of the plague at Athens. The poem appears to have been published without a final revision, possibly due to its author's death. If this is true, Lucretius must have been dead by 54 BC.
In the work of another author in late Republican Rome, Virgil writes in the second book of his "Georgics", apparently referring to Lucretius, "Happy is he who has discovered the causes of things and has cast beneath his feet all fears, unavoidable fate, and the din of the devouring Underworld."
A brief biographical note is found in Aelius Donatus's "Life of Virgil", which seems to be derived from an earlier work by Suetonius. The note reads: "The first years of his life Virgil spent in Cremona until the assumption of his "toga virilis" on his 17th birthday (when the same two men held the consulate as when he was born), and it so happened that on the very same day Lucretius the poet passed away." However, although Lucretius certainly lived and died around the time that Virgil and Cicero flourished, the information in this particular testimony is internally inconsistent: If Virgil was born in 70 BC, his 17th birthday would be in 53. The two consuls of 70 BC, Pompey and Crassus, stood together as consuls again in 55, not 53.
There is insufficient basis for a confident assertion of the date of Lucretius's birth or death in other sources. Another yet briefer note is found in the "Chronicon" of Donatus's pupil, Jerome. Writing four centuries after Lucretius's death, he enters under the 171st Olympiad the following line: "Titus Lucretius the poet is born. Later he was driven mad by a love potion, and when, during the intervals of his insanity, he had written a number of books, which were later emended by Cicero, he killed himself by his own hand in the 44th year of his life." The claim that he was driven mad by a love potion, although defended by such scholars as Reale and Catan, often is dismissed as the result of historical confusion, or anti-Epicurean slander. In some accounts the administration of the toxic aphrodisiac is attributed to his wife Lucilia. 
Jerome's image of Lucretius as a lovesick, mad poet continued to have significant influence on modern scholarship until quite recently, although it now is accepted that such a report is inaccurate. Similarly, the statement that Cicero emended () the work prior to publication is doubtful. The exact date of his birth varies by manuscript; in most it is recorded under 94 BC, but in others under 93 or 96. Lucretius (a materialist writer) and Jerome (a Christian priest) wrote for opposing purposes, and whether or not Jerome attempted to disparage Lucretius's work as the work of a madman is an open question.
It is impossible to estimate the credibility of the accounts of Donatus and Jerome since they wrote long after the poet's death, moreover the latter author belonged to a theological tradition explicitly hostile to Epicureanism, and the sources of their comments are unknown. If 55 BC is Lucretius's most likely year of death, however, and if Jerome is accurate about Lucretius's age (43) when he died, it can then be concluded he was born in 99 or 98 BC. Less specific estimates place the birth of Lucretius in the 90s BC and death in the 50s BC, in agreement with the poem's many allusions to the tumultuous state of political affairs in Rome and its civil strife.
"De rerum natura".
His poem "De rerum natura" (usually translated as "On the Nature of Things" or "On the Nature of the Universe") transmits the ideas of Epicureanism, which includes Atomism, and psychology. Lucretius was the first writer to introduce Roman readers to Epicurean philosophy. The poem, written in some 7,400 dactylic hexameters, is divided into six untitled books, and explores Epicurean physics through richly poetic language and metaphors. Lucretius presents the principles of atomism; the nature of the mind and soul; explanations of sensation and thought; the development of the world and its phenomena; and explains a variety of celestial and terrestrial phenomena. The universe described in the poem operates according to these physical principles, guided by "fortuna", "chance", and not the divine intervention of the traditional Roman deities.
Bibliography.
Editions
Commentary

</doc>
<doc id="37146" url="https://en.wikipedia.org/wiki?curid=37146" title="New Sweden">
New Sweden

New Sweden (Swedish: "Nya Sverige", , ) was a Swedish colony along the lower reaches of the Delaware River in North America from 1638 to 1655 in the present-day American Mid-Atlantic states of Delaware, New Jersey, and Pennsylvania. Fort Christina, now in Wilmington, Delaware, was the first settlement. Along with Swedes and Finns, a number of the settlers were Dutch. New Sweden was conquered by the Dutch in 1655, during the Second Northern War, and incorporated into New Netherland.
History.
By the middle of the 17th century, the Realm of Sweden had reached its greatest territorial extent and was one of the great powers of Europe. Sweden then included Finland and Estonia, along with parts of modern Russia, Poland, Germany, and Latvia, under King Gustavus Adolphus and later Christina, Queen of Sweden. The Swedes sought to expand their influence by creating an agricultural (tobacco) and fur-trading colony to circumvent French and English merchants.
The Swedish West India Company was founded with a mandate to establish colonies between Florida and Newfoundland for the purposes of trade, particularly along the Delaware River. Its charter included Swedish, Dutch, and German stockholders led by directors of the New Sweden Company, including Samuel Blommaert. The company sponsored 11 expeditions in 14 separate voyages (two did not survive) to Delaware between 1638 and 1655.
The first Swedish expedition to North America sailed from the port of Gothenburg in late 1637. It was organized and overseen by Clas Fleming, a Swedish Admiral from Finland. A Dutchman, Samuel Blommaert, assisted the fitting-out and appointed Peter Minuit (the former Governor of New Amsterdam) to lead the expedition. The members of the expedition, aboard the ships "Fogel Grip" and "Kalmar Nyckel", sailed into Delaware Bay, which lay within the territory claimed by the Dutch, passing Cape May and Cape Henlopen in late March 1638, and anchored at a rocky point on the Minquas Kill that is known today as Swedes' Landing on March 29, 1638. They built a fort on the present site of Wilmington, which they named Fort Christina, after Queen Christina of Sweden.
In the following years, 600 Swedes and Finns, the latter group mainly Forest Finns from central Sweden, and also a number of Dutchmen and Germans in Swedish service, settled in the area. Peter Minuit was to become the first governor of the newly established colony of New Sweden. Having been the Director of the Dutch West India Company, and the predecessor of then-Director William Kieft, Minuit knew the status of the lands on either side of the Delaware River at that time. He knew that the Dutch had established deeds for the lands east of the river (New Jersey), but not for the lands to the west (Maryland, Delaware, and Pennsylvania).
Minuit made good on his appointment by landing on the west bank of the river and gathered the sachems of the local Delaware tribe. Sachems of the Susquehannocks were also present. They held a conclave in his cabin on the "Kalmar Nyckel", and he persuaded the sachems to sign deeds he had prepared for the purpose to solve any issue with the Dutch. The Swedes claimed the section of land purchased included the land on the west side of the South River from just below the Schuylkill, in other words, today's Philadelphia, Pennsylvania, southeastern Pennsylvania, Delaware, and coastal Maryland. The Delaware sachem Mattahoon, who was one of the participants, later stated that only as much land as was contained within an area marked by "six trees" was purchased and that the rest of the land occupied by the Swedes was stolen.
Director Willem Kieft objected to the landing of the Swedes, but Minuit ignored him, since he knew that the Dutch were militarily impotent at the moment. Minuit finished Fort Christina during 1638, then departed for Stockholm for a second group. He made a side trip to the Caribbean to pick up a shipment of tobacco for resale in Europe to make the voyage profitable. Minuit died on this voyage during a hurricane at St. Christopher in the Caribbean.
The official duties of the first governor of New Sweden were carried out by Lieutenant (promoted to Captain) Måns Nilsson Kling, until a new governor was chosen and brought from Sweden two years later.
Under Johan Björnsson Printz, governor from 1643 to 1653, the company expanded along the river from Fort Christina, establishing Fort Nya Elfsborg on the east bank of the Delaware near present-day Salem, New Jersey and Fort Nya Gothenborg on Tinicum Island (to the immediate southwest of today's Philadelphia), where he also built his manor house, The Printzhof. The Swedish colony prospered at first. In 1644, New Sweden supported the Susquehannocks in their victory in a war against the English in the Province of Maryland. In May 1654, the Dutch Fort Casimir was captured by soldiers from the New Sweden colony led by governor Johan Risingh. Fort Casimir was renamed Fort Trinity (in Swedish, "Trefaldigheten").
Soon after Sweden opened the Second Northern War in the Baltic by attacking the Polish–Lithuanian Commonwealth, the Dutch moved to take advantage and an armed squadron of ships under the direction of Director-General Peter Stuyvesant seized New Sweden. The Dutch moved an army to the Delaware River in the summer of 1655, easily capturing Fort Trinity and Fort Christina. The Swedish settlement was incorporated into Dutch New Netherland on September 15, 1655. At first the Swedish and Finnish settlers continued to enjoy local autonomy. They kept their own militia, religion, court, and lands.
This status lasted officially until the English conquest of the New Netherland colony was launched on June 24, 1664. The Duke of York sold the area that is today New Jersey to John Berkeley and George Carteret for a proprietary colony, separate from the projected New York. The actual invasion started on August 29, 1664, with the capture of New Amsterdam. The invasion ended with the capture of Fort Casimir (New Castle, Delaware) in October 1664. The invasion was conducted at the start of the Second Anglo-Dutch War.
The status continued unofficially until these lands were included in William Penn's charter for Pennsylvania, on August 24, 1682. During this later period some immigration and expansion continued. The first settlement at Wicaco, a Swedish settlers' log blockhouse located below Society Hill, was built in present-day Philadelphia in 1669. It was later used as a church until about 1700, when Gloria Dei (Old Swedes') Church of Philadelphia was built on the site.
Hoarkill, New Amstel, and Upland.
The start of the Third Anglo-Dutch War resulted in the recapture of New Netherland by the Dutch in August 1673. The Dutch restored the status that pre-dated the English invasion, and codified it in the establishment of three counties in what had been New Sweden. They were Hoarkill County, which today is Sussex County, Delaware; New Amstel County, which is today New Castle County, Delaware; and Upland County, which was later partitioned between New Castle County, Delaware and the new Colony of Pennsylvania. The three counties were created on September 12, 1673, the first two on the west shore of the Delaware River, and the third on both sides of the river.
The signing of the Treaty of Westminster of 1674 ended the Dutch effort, and required them to return all of New Netherland to the English, including the three counties they created. That handover took place on June 29, 1674.
After taking stock, the English declared on November 11, 1674, that settlements on the west side of the Delaware River and Delaware Bay (in present-day Delaware and Pennsylvania) were to be dependent on the Colony of New York, including the three Counties. This declaration was followed on November 11 by a new declaration that renamed New Amstel as New Castle. The other counties retained their Dutch names for the duration.
The next step in the assimilation of New Sweden into New York was the extension of the Duke's laws into the region. This took place on September 22, 1676. This was followed by the partitioning of the Counties to conform to the borders of Pennsylvania and Delaware.
The first move was to partition Upland between Delaware and Pennsylvania, with most of the Delaware portion going to New Castle County. This was accomplished on November 12, 1678. The remainder of Upland continued in place under the same name.
On June 21, 1680, New Castle and Hoarkill Counties were partitioned to produce St. Jones County.
On March 4, 1681, what had been the colony of New Sweden was formally partitioned into the colonies of Delaware and Pennsylvania. The border was established 12 miles north of New Castle, and the northern limit of Pennsylvania was set at 42 degrees north latitude. The eastern limit was the current border with New Jersey at the Delaware River, while the western limit was undefined. Pennsylvania immediately started to reorganize the lands of the former New Sweden within the limits of Pennsylvania. In June 1681, Upland ceased to exist as the result of the reorganization of the Colony of Pennsylvania, with the Upland government becoming the government of Chester County, Pennsylvania.
On August 24, 1682, the Duke of York transferred the western Delaware River region, including modern-day Delaware, to William Penn, thus transferring Deale and St. Jones from New York to Delaware. St. Jones County was renamed as Kent County; Deale County was renamed Sussex County; New Castle County retained its name.
Significance and legacy.
The historian H. Arnold Barton has suggested that the greatest significance of New Sweden was the strong and long-lasting interest in North America that the colony generated in Sweden. Major Swedish immigration to the United States did not occur until the late 19th century, however. From 1870 to 1910, over one million Swedes arrived, settling particularly in Minnesota and other states of the Upper Midwest (see Swedish American).
Traces of New Sweden persist in the lower Delaware Valley to this day, including Holy Trinity Church in Wilmington, Gloria Dei Church and St. James Kingsessing Church in Philadelphia, Trinity Episcopal Church in Swedesboro, New Jersey, and Christ Church (est. 1760) in Swedesburg, Pennsylvania, all commonly known as "Old Swedes' Church". Christiana, Delaware, is one of the few settlements in the area with a Swedish name. Swedesford Road is still found in Chester and Montgomery Counties, Pennsylvania, although Swedesford has long since become Norristown. The American Swedish Historical Museum, located in FDR Park in South Philadelphia, houses many exhibits, documents and artifacts from the New Sweden colony.
Perhaps the greatest contribution of New Sweden to the development of the New World is one that is the traditional Finnish forest house building technique. The colonists brought with them the log cabin, which became such an icon of the American frontier that it is thought of as an American structure. The C. A. Nothnagle Log House on Swedesboro-Paulsboro Road in Gibbstown, New Jersey, is one of the oldest surviving log houses in the United States.
Finnish influence.
The colonists came from all over the Swedish realm. The percentage of Finns in New Sweden grew especially towards the end of the colonization, comprising 22% of the population during Swedish rule, but rising to about 50% after the colony came under Dutch rule. The year 1664 saw the arrival of a contingent of 140 Finns. In 1655, when the ship "Mercurius" sailed to the colony, 92 of the 106 passengers were listed as Finns. Memory of the early Finnish settlement lived on in place names near the Delaware River such as Finland (Marcus Hook), Torne, Lapland, Finns Point and Mullica Hill and Mullica River.
A portion of these Finns were known as Forest Finns, people of Finnish descent living in the forest areas of Central Sweden. The Forest Finns had moved from Savonia in Eastern Finland to Dalarna, Bergslagen and other provinces in central Sweden during the late-16th and early-to-mid-17th centuries. Their relocation had started as part of an effort by Swedish king Gustav Vasa, to expand agriculture to these uninhabited parts of the country. The Finns in Savonia traditionally farmed with a slash-and-burn method which was better suited to pioneering agriculture in vast forest areas. This was also the farming method used by the Native Americans of Delaware.

</doc>
<doc id="37147" url="https://en.wikipedia.org/wiki?curid=37147" title="Tilburg">
Tilburg

Tilburg is a landlocked municipality and a city in the Netherlands, located in the southern province of Noord-Brabant.
Tilburg municipality also includes the villages of Berkel-Enschot and Udenhout. With a population of , it is the second largest city of Noord-Brabant, and the sixth largest city of the Netherlands. Its metropolitan area, which includes Goirle, has inhabitants.
Tilburg University is located in Tilburg, as are Avans University of Applied Sciences and Fontys University of Applied Sciences.
Tilburg is known for its 10-day-long funfair, the largest in the Benelux, held in July each year. The Monday during the funfair is called "Roze Maandag" (Pink Monday), and is primarily LGBT-oriented, though also enjoyed by many heterosexuals.
There are three railway stations within the municipality: Tilburg, Tilburg Universiteit and Tilburg Reeshof. The "Spoorzone" area around Tilburg Central station used to be owned by Dutch Railways as one of its national train maintenance yards. It has recently been purchased by the city and is currently being transformed into a happening urban zone, which should become an integral part of the inner city.
History.
Little is known about the beginnings of Tilburg. The name "Tilburg" first appeared in documents dating from 709 AD but after that there was no mention for several centuries. In the later Middle Ages, Tilburg referred to a region rather than a particular town or village; its population was largely in a couple of hamlets, one of which was known as "Eastern Tilburg" ("Oost-Tilburg"), which was later reflected in the name of "Oisterwijk" ("Eastern Quarter"). This village centred around a small (probably wooden) castle or "Motteburcht" on an equally small hill, which became derelict and was torn down after a few centuries at most. Of this first "Tilburg Castle", nothing remained c. 2000, except for a few remnants of its moat in the suburbs of Oisterwijk. In the 14th century, Tilburg was proclaimed a manor; together with Goirle, it acquired the title of "The Manor of Tilburg and Goirle".
Successively, the manorial rights fell into the hands of several lords of noble lineage. They derived their income from taxes, fines and interest paid by the villagers.
In the 15th century, one of the lords of Tilburg, Jan van Haestrecht, built Tilburg Castle. "That stone chamber at Hasselt" is mentioned in several historical documents. In 1858, however, the castle was pulled down to make way for a factory, but the name lives on, in the city arms and logo. A replica of the foundations of the castle was restored in ca. 1995 in its original location, after the factory was demolished. In 1803, Goirle was separated from Tilburg and on 18 April 1809, Tilburg was granted city status. In that year, it had about 9,000 inhabitants. In 2009 Tilburg hosted several festivities in celebration of 200 years as a city. Because of the 4 apples.
Wool capital of the Netherlands.
Tilburg grew around one of the so-called "herd places" or "Frankish triangles", triangular plots where a number of roads (usually sand roads) met. These herd places were collective pasturelands for flocks of sheep. Their shape is still reflected in the layout of many places in Tilburg. Many districts, including Korvel, Oerle, Broekhoven, Hasselt, Heikant, De Schans, and Heuvel, bear the names of these old hamlets. The poor farmers living in these hamlets soon decided not to sell the wool from their sheep but to weave it themselves, and for a long time, much of the space inside their small houses was occupied by a loom—by the 17th century these numbered about 300. Enterprising people saw their chance. As so-called "drapers" they supplied the weavers with the raw materials for their "home working", and the first Tilburg "mill houses" came into existence. From then on, the wool industry underwent rapid growth, and in 1881 Tilburg had as many as 145 woollen mills. Home weaving continued, however, until the early 20th century. Woollen textiles from Tilburg were known far and wide. After the World War II Tilburg retained its place as wool capital of the Netherlands, but in the 1960s the industry collapsed and by the 1980s the number of wool mills could be counted on the fingers of one hand. Present-day Tilburg industry consists of a wide variety of enterprises. The main economic sector has become transport and logistics with a variety of industry as a close second.
Urban Renewal.
At the same time as the wool industry collapsed, Cees Becht was the mayor of Tilburg. While he was in office, many buildings were destroyed, including some very precious monuments. The neighbourhood Koningswei (King's Meadows) was demolished and replaced by Koningsplein (King's Square). The old neighbourhood was some kind of slum and had to be replaced by newer development. The newer development, however, wasn't as successful as was expected, and the square feels abandoned most of the year.
Considered even worse was the demolition of the old city hall. This classicistic-styled building was a national-registered monument, but even that didn't prevent Becht's plans to demolish it to build the nine-storey, modern-day, black complex. A part of the empty area was used to build the system of the inner "Cityring".
Another building that was demolished was the old railway station, which was replaced due to "Hoogspoor" (literally: high rails), a project bringing the railway on viaducts to reduce traffic congestion in the years around 1960. The century-old station building was replaced by the modern one.
Because of all of this and some more parts of Tilburg, Cees Becht gained the dubious nickname "Cees the Sloper" (Cees the demolisher)
Modern history.
In the 1980s, many locations, formerly occupied by wool factories had been filled with small-scale housing projects. This mostly happened when Henk Letschert was mayor of Tilburg.
The "Heuvel", one of the important squares, had its own lime tree until 27 April 1994, being chopped for a bicycle parking basement. The cut-down led to many protests, because the tree was still healthy. After the Pieter Vreedeplein reconstruction, plans were made to plant a descendant of the original lime tree. Three were placed, only one of them survived. The last living tree was moved to another location again, but died shortly after. As of 23 November 2011, no more descendants have been placed. The current one is just another lime tree.
In the 1990s Tilburg developed a modern skyline. Because of new policy three buildings were build, which are considered skyscrapers in the Netherlands. These are the Interpolis headquarters, the Westpoint Tower and . The Westpoint Tower has an altitude of and was the tallest residential tower in The Netherlands until the Montevideo in Rotterdam surpassed it. De 'StadsHeer' is the third one and is part of the 'Haestrechtkwartier' (Haestrecht quarter). The residential tower is nicknamed "De Vogelkooikes" (Bird cages) for its cubic balconies taped onto the building.
King William II.
King William II (1792–1849) was fond of Tilburg. "Here I can breathe freely and I feel happy", he once said about the town. King William II always supported Tilburg—he provided money to improve the sheep breeding, built new farms and founded a cavalry barracks on the St. Joseph Street, now a monumental building of the City Archives. Although the King was always made welcome by the manufacturers he had befriended, he needed his own residence in Tilburg, and commissioned the construction of a palace, which would function as his country residence. Construction started in 1847 and was completed just days before William II died, in 1849. It is now part of Tilburg City Hall. In 1987 an obelisk was erected nearby, in memory of King William II. It replaced the old "needle" dating from 1874, which was removed from the street in 1968. After its restoration, William II's statue has got a place again in the heart of the city, where he felt happy among its inhabitants. The local football club Willem II Tilburg was named after the king.
Topography.
Tilburg Centrum.
Tilburg Centrum is the downtown of Tilburg, and is situated between (clockwise) the Spoorlaan, Heuvelring, Paleisring, Schouwburgring and Noordhoekring, which is the same as the order of the one-way roads around the district. The district has 6,331 inhabitants, and most of the shops, hotels, restaurants and cafes of the city. In 2008, the refurbished Pieter Vreedeplein was opened to public, addressing a locak of shopping facilities as compared to similar-sized cities in the Netherlands. Two smaller cinemas were replaced by a bigger one on the Pieter Vreedeplein in 2007. Despite being called "Centrum", the district is some distance southeast of the geographical center. The district is connected by Tilburg railway station.
Oud-Noord.
Oud-Noord is situated north of the railway that crosses Tilburg, and between the "Ringbanen" (Ring roads around the city center). The district has 31,649 inhabitants. Contemporary arts museum "De Pont" is located within the district. When the railway marshalling yard belonging to the Nederlandse Spoorwegen became obsolete, a considerable stretch of the railway across the city, the "Spoorzone", became an urban renewal project. New premises for two courses run by Fontys University of Applied Sciences will be located here, as will Tilburg's new central library, replacing the library in Koningsplein The railway yard is the largest area, though more areas along the railway will be reconstructed.
Oud-Zuid.
Oud-Zuid is a district south, and also west and east of downtown Tilburg. The district has 38,659 inhabitants. , all the 'skyscrapers' of Tilburg, higher than are located within the district. The "Hart van Brabantlaan" is almost surrounded by high buildings like Westpoint Tower and the as a small part of the urban renewal. This area along the railway is partly located in "Oud-Zuid". Many important locations in Tilburg are located within the district, just out of the center, such as 013 music venue and the Schouwburg built in 1961. Also the Koningsplein with the main library and the Piushaven are located within the district. Old herd places include Korvel, Broekhoven and Oerle.
Noord.
Tilburg-Noord is located north of the Wilhelminakanaal. The district has 22,763 inhabitants. Tilburg-Noord is built in the period 1966–1974. Therefore, it has many apartment buildings up to 16 floors, drive-in houses, green strips and industrial development. The streets in this district are mostly named after musicians from the renaissance up to pop artists from the 1960s. The main shopping center is Wagnerplein, while there's also the Verdiplein in Stokhasselt. The one at the Tartinistraat became defunct. Before the district was built, it mainly was agricultural area with some villages. The most notable was Heikant, which is still the name of the biggest neighbourhood. Its former village square including the old church is still present. The northernmost part of the district is still agricultural with some forests. In this agricultural area, the blessed Peter Donders was born, there still stands a chapel and a procession park.
Oost.
Tilburg-oost consists of primarily industrial development. Residential neighbourhoods are in a small strip east of the Ringbaan Oost rather than the whole district, however, is not considered as a part of the city center. The district only has 770 inhabitants.
Zuid.
Tilburg-Zuid is located between the A58 motorway and the Ringbaan Zuid, and is the southernmost district. Tilburg-zuid has 14,836 inhabitants. The district contains two neighbourhoods and many businesses. The football club Willem II is located within the district, as well as the ice-skating rink with a speed skating rink, the Ireen Wüst Ijsbaan, is located here. The main campus of Fontys University of Applied Sciences is located in this district, as well as St. Elisabeth hospital and the Leijpark, one of the largest public parks in the city.
West.
Tilburg-west was mostly built after WWII, and has 29,611 inhabitants. The district with its neighbourhoods consist mostly of small brick houses and apartment buildings, except for Zorgvlied, which contains more expensive, free-standing houses. The Westermarkt is the largest shopping center out of the inner city. Many higher educational buildings are standing here, like as the Tilburg University and Avans Hogeschool. Another place of many schools is along the Reitse Hoevenstraat with multiple secondary schools. The district is connected by train with the Tilburg Universiteit railway station and has one of the two hospitals in Tilburg (). The largest mosque of Tilburg, the Turkish Süleymaniye-Mosque built in 2001, stands in the southeastern corner of the district. West is surrounded by forests like "Wandelbos" and the "Oude Warande", located west of the university.
Reeshof.
The Reeshof is the westernmost district and the most recent expansion of the city of Tilburg proper. and has a population of 42,696 inhabitants. Because of this, the Reeshof became the largest district of Tilburg. The first houses were completed in 1980, in the neighbourhood Gesworen Hoek. , the last neighbourhood (Koolhoven Buiten) is under construction. The district is connected by Tilburg Reeshof railway station and multiple roads that encircle the district plus the industrial development Vossenberg north of the Wilhelminakanaal.
The Donge runs through the district, including the nature development with some Highland cattle grazing between the fences protecting the surrounding neighbourhoods. This small-scale nature project is called the Dongevallei, which literally means Donge Valley in English.
Demographics.
Ethnic makeup.
The population of Tilburg was 206,234 on 1 January 2011. According to the Tilburg city council, the city will reach a population of 217,000 by 2025. Of these, 23.3% (47,964 people) are of foreign descent. People are classified as being of foreign descent when they were born outside of the Netherlands, or when at least one of their parents was born outside of the Netherlands.
Religions.
The Tilburg agglomeration has the following religious makeup as of 2003:
Geography.
Climate.
Tilburg experiences an oceanic climate (Köppen climate classification "Cfb") similar to almost all of the Netherlands. The most notable fact from Western Brabant is that there are more thunderstorms than anywhere else in the Netherlands, up to 31 days a year.
Economy.
The economy was concentrated on wool industry for centuries, however, since the 1960s, Tilburg made more progress in having different kinds of industries, supported by the government to prevent the city from poverty after the decline of wool industry. Chemical company IFF has a factory in Tilburg. In the 1980s, the Japanese company Fujifilm came in Tilburg. Insurance companies like Interpolis and CZ are headquartered in Tilburg, as well as transportation/distribution industries situated in Tilburg for being the geographical center of the Benelux-countries. Iris Ohyama has its European offices in Tilburg.
Education.
Tilburg University.
Higher education is of significant importance, with Tilburg University attracting scholars from all over the world. It has a student population of about 13,000 students, about 8 per cent of whom are international students. This percentage has steadily increased over the past years. TiU offers both Dutch-taught and English-taught programmes.
The institution has gained a reputation in both research and education. In the field of economics, the Faculty of Economics and Business Administration ranked #1 in Europe for the second consecutive time in 2007 according to the Journal of the European Economic Association with regard to publications in top journals.
In 2007 the Executive MBA program at the university's TiasNimbas Business School ranked # 11 in the world according to the Financial Times. In the field of law, Tilburg University was ranked #1 in the Netherlands for the last three years according to Elsevier Magazine.
Culture and recreation.
Tilburg is a pilot city of the Council of Europe and the EU Intercultural cities programme.
Beverages.
"Schrobbelèr" is a local liqueur. It has an alcoholic percentage of 21.5%, slightly lower than most bitters and has a relatively sweet flavour. The drink is sold in a stone jar and is drunk cold from own glass, a high and tiny chalice glass, larger than a Jägermeister glass 
The drink originated in 1973 when Tilburgian entrepreneur Jan Wassing started experimenting with a drink with lower alcoholic percentage that was appropriate for his stomach. The result was successful. The drink is distilled now at Loven industrial area in Tilburg by the Eindhoven company Schrobbeler Ltd, without the è on the last vowel. The drink is especially drank at Carnival. The name is derived from the profession of 'Schrobbelaar', in the textile industry in Tilburg. The profession was unskilled and had a low wage.
Another known drink from Tilburg is Peerke's Nat, which has a higher alcoholic percentage than Schrobbelèr (25%) and is introduced at the beatification of Peter Donders (locally named Peerke). The drink is sold in bottles of 70 centiliters.
The Koningshoeven Brewery brews trappist beer. It was founded in 1884 at Koningshoeven Abbey.
Open air art.
Tilburg has some notable art in the city, mostly supported by KORT (Kunst in Open Ruimte Tilburg, Dutch for Art in Open Space Tilburg). The most notorious example is the turning house on the Hasseltrotonde, a roundabout, mostly being criticised for being 'no art' and 'waste of money'. However, the house was erected in 2008. Except for being responsible for newer, modern art, KORT also gives information about older works of art, like the Willem II statue on the Heuvel.
Festival city, music.
The city of Tilburg hosts many festivals, such as Incubate, "Festival Mundial" (world culture), Stranger Than Paranoia (jazz), Tilburg Students Festival, and Roadburn Festival. "013" is a modern pop-centre. Paradox is a club for experimental jazz and improvised music. Fontys University of Applied Sciences started a pop-academy in the beginning of the 21st century, and students often perform on local stages.
Museums.
Tilburg has an outstanding museum of Modern Art, De Pont. There is also a large textile museum, offering not only a historical view in its former factory, but also a laboratorium for design, production and development of textile as a material. Another museum is Noordbrabants Natuurmuseum.
Parks and forests.
A lot of parks and forests provide people from Tilburg area for recreation. The Leijpark and the Reeshofpark are the largest among the parks in Tilburg. The Leijpark is famous for Festival Mundial and lies next to the St. Elisabeth hospital and a monastery, the Cenakel. The Reeshofpark is created in the late 1990s, including some restaurants opened in 2011. Some older parks include the Wilhelminapark in Oud-Noord, is built on the square of the former herd place Veldhoven. Tilburg offers, in comparison to other top-ten cities in the Netherlands the most forest area. In the municipality, Tilburg has the Wandelbos, a forest south of the similarly named neighbourhood in Tilburg-West, the Oude Warande, the Kaaistoep, a forest of 4.5km2, and partially, Huis Ter Heide in the northwest of Tilburg, a 6.5km2-sized natural redevelopment area. Out of the municipality, there's a national park called Loonse en Drunense Duinen which includes dunes of drift sand from the west coast.
Sports.
The local football team is Willem II, named in remembrance of King William II.
Tilburg Ten Miles is an annual road running competition held in Tilburg.
Students sports like rowing and hockey are popular as well. Tilburg hosts three field hockey clubs that play in top national leagues.
Tilburg has an ice skating rink, including the speed skating rink Ireen Wüst IJsbaan of 400m. Within the speed skating rink there's an ice hockey field. The Hockey team Tilburg Trappers also does well in the Eredivisie (Dutch Premier League).
Transport.
Tilburg has three railway stations: Tilburg (Centraal), Tilburg Universiteit and Tilburg Reeshof. The third of them, Station Tilburg Reeshof was built to connect the then-latest district of Tilburg, the Reeshof. Intercity trains only stop at Tilburg (centraal). The name of Tilburg Universiteit Station was from its construction in 1968 to December 2010 Tilburg West, however, after 40 years, it was not the westernmost station anymore. A fourth railway station is planned for Berkel-Enschot, also in the municipality of Tilburg and more getting absorbed by Tilburg. In the past, until 1938, Berkel-Enschot had already its own train station. Udenhout, lying further northeast in the municipality, also had its train station until 1938. Both stations are on the line to 's-Hertogenbosch.
The Tilburg city- and local buses are operated by Veolia Transport Nederland. The city experimented from 2005 to 2008 with free public transport for children and 55+-people. Before Veolia took over the bus network, it was operated by BBA (abbreviation for Brabants(ch)e Buurtspoorwegen en Autobussen).
Tilburg has an extensive bicycle path network called Sternet-Routes. The first bicycle path of this network was built between the city center and the university in 1975. From the mid-1990s, multiple bicycle paths (rather than lanes along the road) have been built. Since most of these have been paved by tiles, there is an increasing call for asphalt-paved paths. For this network of bicycle paths, there are built some new tunnels; under the railway that crosses the city.
Tilburg is, at variance from other Dutch cities of a similar size, connected by only one national motorway, the A58 / E312 (to Breda and Eindhoven). An outer beltway, consisting of two provincial 2x2-roads and the A58, has been finished in May 2012. Although the outer beltway is fully navigable, the Burgemeester Bechtweg, which was built initially as a two-lane (one per direction) road, will be finished in 2013. Two other routes are of considerable importance for Tilburg: the A261/N261 to Waalwijk and the A65/N65 to 's-Hertogenbosch. Neither is a complete motorway, and both experience bottlenecks. Various plans exist to build both to higher standards, with the N261 improved in 2015.
International relations.
Twin towns — Sister cities.
Tilburg is twinned with:

</doc>
<doc id="37149" url="https://en.wikipedia.org/wiki?curid=37149" title="Cranial nerves">
Cranial nerves

Cranial nerves are the nerves that emerge directly from the brain (including the brainstem), in contrast to spinal nerves (which emerge from segments of the spinal cord). Cranial nerves relay information between the brain and parts of the body, primarily to and from regions of the head and neck.
Spinal nerves emerge sequentially from the spinal cord with the spinal nerve closest to the head (C1) emerging in the space above the first cervical vertebra. The cranial nerves emerge from the central nervous system above this level. Each cranial nerve is paired and is present on both sides. Depending on definition in humans there are twelve or thirteen cranial nerves pairs, which are assigned Roman numerals I–XII, sometimes also including cranial nerve zero. The numbering of the spinal nerves is based on the order in which they emerge from the brain, front to back (brainstem).
The terminal nerves, olfactory nerves (I) and optic nerves (II) emerge from the cerebrum or forebrain, and the remaining ten pairs arise from the brainstem, which is the lower part of the brain.
The cranial nerves are considered components of the peripheral nervous system (PNS), although on a structural level the olfactory, optic and terminal nerves are more accurately considered part of the central nervous system (CNS).
Anatomy.
Most typically, humans are considered to have twelve pairs of cranial nerves (I–XII). They are: the olfactory nerve (I), the optic nerve (II), oculomotor nerve (III), trochlear nerve (IV), trigeminal nerve (V), abducens nerve (VI), facial nerve (VII), vestibulocochlear nerve (VIII), glossopharyngeal nerve (IX), vagus nerve (X), accessory nerve (XI), and hypoglossal nerve (XII). (There may be a thirteenth cranial nerve, the terminal nerve (nerve O or N), which is very small and may or may not be functional in humans)
Terminology.
Cranial nerves are generally named according to their structure or function. For example, the olfactory nerve (I) supplies smell, and the facial nerve (VII) supplies motor innervation to the face. Because Latin was the "lingua franca" (common language) of the study of Anatomy when the nerves were first documented, recorded, and discussed, many nerves maintain Latin or Greek names, including the trochlear nerve (IV), named according to its structure, as it supplies a muscle that attaches to a pulley (). The trigeminal nerve (V) is named in accordance with its three components ( meaning triplets), and the vagus nerve (X) is named for its wandering course ().
Cranial nerves are numbered based on their rostral-caudal (front-back) position, when viewing the brain. If the brain is carefully removed from the skull the nerves are typically visible in their numeric order.
Cranial nerves have paths within and outside of the skull. The paths within the skull are called "intracranial" and the paths outside the skull are called "extracranial". There are many holes in the skull called "foramina" by which the nerves can exit the skull. All cranial nerves are "paired", which means that they occur on both the right and left sides of the body. The muscle, skin, or additional function supplied by a nerve on the same side of the body as the side it originates from, is referred to an "ipsilateral" function. If the function is on the opposite side to the origin of the nerve, this is known as a "contralateral" function.
Intracranial course.
Nuclei.
The cell bodies of many of the neurons of most of the cranial nerves are contained in one or more nuclei in the brainstem. These nuclei are important relative to cranial nerve dysfunction because damage to these nuclei such as from a stroke or trauma can mimic damage to one or more branches of a cranial nerve. In terms of specific cranial nerve nuclei, the midbrain of the brainstem has the nuclei of the oculomotor nerve (III) and trochlear nerve (IV); the pons has the nuclei of the trigeminal nerve (V), abducens nerve (VI), facial nerve (VII) and vestibulocochlear nerve (VIII); and the medulla has the nuclei of the glossopharyngeal nerve (IX), vagus nerve (X), accessory nerve (XI) and hypoglossal nerve (XII). The fibers of these cranial nerves exit the brainstem from these nuclei.
Ganglia.
Some of the cranial nerves have sensory or parasympathetic ganglia (collections of cell bodies) of neurons, which are located outside of the brain (but can be inside or outside of the skull).
The sensory ganglia are directly correspondent to dorsal root ganglia of spinal nerves and are known as cranial sensory ganglia. Sensory ganglia exist for nerves with sensory function: V, VII, VIII, IX, X. There are also parasympathetic ganglia, which are part of the autonomic nervous system for cranial nerves III, VII, IX and X.
Exiting the skull and Extracranial Course.
After emerging from the brain, the cranial nerves travel within the skull, and some must leave this bony compartment in order to reach their destinations. Often the nerves pass through holes in the skull, called foramina, as they travel to their destinations. Other nerves pass through bony canals, longer pathways enclosed by bone. These foramina and canals may contain more than one cranial nerve, and may also contain blood vessels.
Function.
The cranial nerves provide motor and sensory innervation mainly to the structures within the head and neck. The sensory innervation includes both "general" sensation such as temperature and touch, and "special" innervation such as taste, vision, smell, balance and hearing
The vagus nerve (X) provides sensory and autonomic (parasympatheic) motor innervation to structures in the neck and also to most of the organs in the chest and abdomen.
Smell (I).
The olfactory nerve (I) conveys the sense of smell.
Damage to the olfactory nerve (I) can cause an inability to smell (anosmia), a distortion in the sense of smell (parosmia), or a distortion or lack of taste. If there is suspicion of a change in the sense of smell, each nostril is tested with substances of known odors such as coffee or soap. Intensely smelling substances, for example ammonia, may lead to the activation of pain receptors (nociceptors) of the trigeminal nerve that are located in the nasal cavity and this can confound olfactory testing.
Vision (II).
The optic nerve (II) transmits visual information.
Damage to the optic nerve (II) affects specific aspects of vision that depend on the location of the lesion. A person may not be able to see objects on their left or right sides (homonymous hemianopsia), or may have difficulty seeing objects on their outer visual fields (bitemporal hemianopsia) if the optic chiasm is involved. Vision may be tested by examining the visual field, or by examining the retina with an ophthalmoscope, using a process known as funduscopy. Visual field testing may be used to pin-point structural lesions in the optic nerve, or further along the visual pathways.
Eye movement (III, IV, VI).
The oculomotor nerve (III), trochlear nerve (IV) and abducens nerve (VI) coordinate eye movement.
Damage to nerves III, IV, or VI may affect the movement of the eyeball (globe). Both or one eye may be affected; in either case double vision (diplopia) will likely occur because the movements of the eyes are no longer synchronized. Nerves III, IV and VI are tested by observing how the eye follows an object in different directions. This object may be a finger or a pin, and may be moved at different directions to test for pursuit velocity. If the eyes do not work together, the most likely cause is damage to a specific cranial nerve or its nuclei.
Damage to the oculomotor nerve (III) can cause double vision (diplopia) and inability to coordinate the movements of both eyes (strabismus), also eyelid drooping (ptosis) and pupil dilation (mydriasis). Lesions may also lead to inability to open the eye due to paralysis of the levator palpebrae muscle. Individuals suffering from a lesion to the oculomotor nerve may compensate by tilting their heads to alleviate symptoms due to paralysis of one or more of the eye muscles it controls.
Damage to the trochlear nerve (IV) can also cause diplopia with the eye adducted and elevated. The result will be an eye which can not move downwards properly (especially downwards when in an inward position). This is due to impairment in the superior oblique muscle, which is innervated by the trochlear nerve.
Damage to the abducens nerve (VI) can also result in diplopia. This is due to impairment in the lateral rectus muscle, which is innervated by the abducens nerve.
Trigeminal Nerve (V).
The trigeminal nerve (V) is composed of three distinct parts: The Ophthalmic (V1), the Maxillary (V2), and the Mandibular (V3) nerves. Combined, these nerves provide sensation to the skin of the face and also controls the muscles of mastication (chewing). Conditions affecting the trigeminal nerve (V) include trigeminal neuralgia, cluster headache, and trigeminal zoster.
Trigeminal neuralgia occurs later in life, from middle age onwards, most often after age 60, and is a condition typically associated with very strong pain distributed over the area innervated by the maxillary or mandibular nerve divisions of the trigeminal nerve (V2 and V3).
Facial expression (VII).
Lesions of the facial nerve (VII) may manifest as facial palsy. This is where a person is unable to move the muscles on one or both sides of their face. A very common and generally temporarily facial palsy is known as Bell's palsy. Bell's Palsy is the result of an idiopathic (unknown), unilateral lower motor neuron lesion of the facial nerve and is characterized by an inability to move the ipsilateral muscles of facial expression, including elevation of the eyebrow and furrowing of the forehead. Patients with Bell's palsy often have a drooping mouth on the affected side and often have trouble chewing because the buccinator muscle is affected.
Hearing and balance (VIII).
The vestibulocochlear nerve (VIII) splits into the vestibular and cochlear nerve. The vestibular part is responsible for innervating the vestibules and semicircular canal of the inner ear; this structure transmits information about balance, and is an important component of the vestibuloocular reflex, which keeps the head stable and allows the eyes to track moving objects. The cochlear nerve transmits information from the cochlea, allowing sound to be heard.
When damaged, the vestibular nerve may give rise to the sensation of spinning and dizziness. Function of the vestibular nerve may be tested by putting cold and warm water in the ears and watching eye movements caloric stimulation. Damage to the vestibulocochlear nerve can also present as repetitive and involuntary eye movements (nystagmus), particularly when looking in a horizontal plane. Damage to the cochlear nerve will cause partial or complete deafness in the affected ear.
Oral sensation, taste, and salivation (IX).
The glossopharyngeal nerve (IX) innervates the stylopharyngeus muscle and provides sensory innervation to the oropharynx and back of the tongue. The glossopharyngeal nerve also provides parasympathetic innervation to the parotid gland. Unilateral absence of a gag reflex suggests a lesion of the glossopharyngeal nerve (IX), and perhaps the vagus nerve (X).
Vagus nerve (X).
Loss of function of the vagus nerve (X) will lead to a loss of parasympathetic innervation to a very large number of structures. Major effects of damage to the vagus nerve may include a rise in blood pressure and heart rate. Isolated dysfunction of only the vagus nerve is rare, but can be diagnosed by a hoarse voice, due to dysfunction of one of its branches, the recurrent laryngeal nerve.
Damage to this nerve may result in difficulties swallowing.
Shoulder elevation and head-turning (XI).
Damage to the accessory nerve (XI) will lead to ipsilateral weakness in the trapezius muscle. This can be tested by asking the subject to raise their shoulders or shrug, upon which the shoulder blade ( scapula) will protrude into a winged position. Additionally, if the nerve is damaged, weakness or an inability to elevate the scapula may be present because the levator scapulae muscle is now solely able to provide this function. Depending on the location of the lesion there may also be weakness present in the sternocleidomastoid muscle, which acts to turn the head so that the face points to the opposite side.
Tongue movement (XII).
The hypoglossal nerve (XII) is unique in that it is innervated from both the motor cortex of both hemispheres of the brain. Damage to the nerve at lower motor neuron level may lead to fasciculations or atrophy of the muscles of the tongue. The fasciculations of the tongue are sometimes said to look like a "bag of worms". Upper motor neuron damage will not lead to atrophy or fasciculations, but only weakness of the innervated muscles.
When the nerve is damaged, it will lead to weakness of tongue movement on one side. When damaged and extended, the tongue will move towards the weaker or damaged side, as shown in the image.
Clinical significance.
Examination.
Physicians, neurologists, and other medical professionals may conduct a cranial nerve examination as part of a neurological examination to examine the functionality of the cranial nerves. This is a highly formalized series of tests that assess the status of each nerve. 
A cranial nerve exam begins with observation of the patient because some cranial nerve lesions may affect the symmetry of the eyes or face. The visual fields are tested for nerve lesions or nystagmus via an analysis of specific eye movements. The sensation of the face is tested, and patients are asked to perform different facial movements, such as puffing out of the cheeks. Hearing is checked by voice and tuning forks. The position of the patient's uvula is examined because asymmetry in the position could indicate a lesion of the glossopharyngeal nerve. After the ability of the patient to use their shoulder to assess the accessory nerve (XI), and the patient's tongue function is assessed by observing various tongue movements.
Damage.
Compression.
Nerves may be compressed because of increased intercranial pressure, a mass effect of an intracerebral haemorrhage, or tumour that presses against the nerves and interferes with the transmission of impulses along the nerve. A loss of functionality of a single cranial nerve may sometimes be the first symptom of an intracranial or skull base cancer.
An increase in intracranial pressure may lead to impairment of the optic nerves (II) due to compression of the surrounding veins and capillaries, causing swelling of the eyeball (papilloedema). A cancer, such as an optic glioma, may also impact the optic nerve (II). A pituitary tumour may compress the optic tracts or the optic chiasm of the optic nerve (II), leading to visual field loss. A pituitary tumour may also extend into the cavernous sinus, compressing the oculuomotor nerve (III), trochlear nerve (IV) and abducens nerve (VI), leading to double-vision and strabismus. These nerves may also be affected by herniation of the temporal lobes of the brain through the falx cerebri.
The cause of trigeminal neuralgia, in which one side of the face is exquisitely painful, is thought to be compression of the nerve by an artery as the nerve emerges from the brain stem. An acoustic neuroma, particularly at the junction between the pons and medulla, may compress the facial nerve (VII) and vestibulocochlear nerve (VIII), leading to hearing and sensory loss on the affected side.
Stroke.
Occlusion of blood vessels that supply the nerves or their nuclei, an ischemic stroke, may cause specific signs and symptoms that can localise where the occlusion occurred. A clot in a blood vessel draining the cavernous sinus 
(cavernous sinus thrombosis) affects the oculomotor (III), trochlear (IV), opthalamic branch of the trigeminal nerve (V1) and the abducens nerve (VI).
Inflammation.
Inflammation resulting from infection may impair the function of any of the cranial nerves. Inflammation of the facial nerve (VII) may result in Bell's palsy.
Multiple sclerosis, an inflammatory process that may produce a loss of the myelin sheathes which surround the cranial nerves, may cause a variety of shifting symptoms affecting multiple cranial nerves.
Other.
Trauma to the skull, disease of bone such as Paget's disease, and injury to nerves during neurosurgery (such as tumor removal) are other possible causes of cranial nerve damage.
History.
Galen (AD 129-210) named seven pairs of cranial nerves. Much later, in 1664, Sir Thomas Willis suggested that there were actually 10 pairs of nerves. Finally, in 1778, Soemmering described the 12 pairs of nerves that are generally accepted today. However, because many of the nerves emerge from the brain stem as rootlets, there is continual debate as to how many nerves there actually are, and how they should be grouped. There is reason to consider both the olfactory (I) and Optic (II) nerves to be brain tracts, rather than cranial nerves. Further, the very small terminal nerve (nerve N or O) exists in humans but may not be functional. In other animals, it appears to be important to sexual receptivity based on perceptions of phermones
Other animals.
Cranial nerves are also present in other vertebrates. Other amniotes (non-amphibian tetrapods) have cranial nerves similar to those of humans. In anamniotes (fishes and amphibians), the accessory nerve (XI) and hypoglossal nerve (XII) do not exist, with the accessory nerve (XI) being an integral part of the vagus nerve (X); the hypoglossal nerve (XII) is represented by a variable number of spinal nerves emerging from vertebral segments fused into the occiput. These two nerves only became discrete nerves in the ancestors of amniotes (non-amphibian tetrapods).

</doc>
<doc id="37150" url="https://en.wikipedia.org/wiki?curid=37150" title="White cane">
White cane

A white cane is used by many people who are blind or visually impaired. Its primary uses are as a mobility tool and as a courtesy to others, but there are at least five varieties, each serving a slightly different need.
Types.
Mobility canes are often made from aluminium, graphite-reinforced plastic or other fibre-reinforced plastic, and can come with a wide variety of tips depending upon user preference.
White canes can be either collapsible or straight, with both versions having pros and cons. The National Federation of the Blind in the United States affirms that the lightness and greater length of the straight canes allows greater mobility and safety, though collapsible canes can be stored with more ease, giving them advantage in crowded areas such as classrooms and public events.
History.
Blind people have used canes as mobility tools for centuries, but it was not until after World War I that the white cane was introduced.
In 1921 James Biggs, a photographer from Bristol who became blind after an accident and was uncomfortable with the amount of traffic around his home, painted his walking stick white to be more easily visible.
In 1931 in France, Guilly d'Herbemont launched a national white stick movement for blind people. On February 7, 1931, Guilly d'Herbemont symbolically gave the first two white canes to blind people, in the presence of several French ministers. 5,000 more white canes were later sent to blind French veterans from World War I and blind civilians.
In the United States, the introduction of the white cane is attributed to George A. Bonham of the Lions Clubs International. In 1930, a Lions Club member watched as a man who was blind attempted to cross the street with a black cane that was barely visible to motorists against the dark pavement. The Lions decided to paint the cane white to make it more visible. In 1931, Lions Clubs International began a program promoting the use of white canes for people who are blind.
The first special white cane ordinance was passed in December 1930 in Peoria, Illinois granting blind pedestrians protections and the right-of-way while carrying a white cane. 
The long cane was improved upon by World War II veterans rehabilitation specialist, Richard E. Hoover, at Valley Forge Army Hospital. In 1944, he took the Lions Club white cane (originally made of wood) and went around the hospital blindfolded for a week. During this time he developed what is now the standard method of "long cane" training or the Hoover Method. He is now called the "Father of the Lightweight Long Cane Technique." The basic technique is to swing the cane from the center of the body back and forth before the feet. The cane should be swept before the rear foot as the person steps. Before he taught other rehabilitators, or "orientors," his new technique he had a special commission to have light weight, long white canes made for the veterans of the European fronts.
On October 6, 1964, a joint resolution of the Congress, HR 753, was signed into law authorizing the President of the United States to proclaim October 15 of each year as "White Cane Safety Day". President Lyndon Johnson was the first to make this proclamation. 
Legislation about canes.
While the white cane is commonly accepted as a "symbol of blindness", different countries still have different rules concerning what constitutes a "cane for the blind".
In the United Kingdom, the white cane indicates that the individual has a visual impairment; with two red bands added it indicates that the user is deafblind.
In the United States, laws vary from state to state, but in all cases, those carrying white canes are afforded the right-of-way when crossing a road. They are afforded the right to use their cane in any public place as well. In some cases, it is illegal for a non-blind person to use a white cane with the intent of being given right-of-way.
In November 2002, Argentina passed a law recognizing the use of green canes by people with low vision, stating that the nation would "Adopt from this law, the use of a green cane in the whole of Argentina as a means of orientation and mobility for people with low vision. It will have the same characteristics in weight, length, elastic grip and fluorescent ring as do white canes used by the blind."
Comparison to guide dogs.
While a guide dog, the other major mobility aid for blind people, can interact more with the user and the environment, making them more useful in certain locations, white canes are alternatives for reasons of price, care, and in case of some people, allergies. Despite the high profile of guide dogs, however, most blind people still use canes at least sometimes, and many still use canes entirely.
Children and canes.
In many countries, including the UK, a cane is not generally introduced to a child until they are between 7 and 10 years old. However, more recently canes have been started to be introduced as soon as a child learns to walk to aid development with great success.
Joseph Cutter and Lilli Nielsen, pioneers in research on the development of blind and multiple-handicapped children, have begun to introduce new research on mobility in blind infants in children. Cutter's book, "Independent Movement and Travel in Blind Children", recommends a cane to be introduced as early as possible, so that the blind child learns to use it and move around naturally and organically, the same way a sighted child learns to walk. A longer cane, between nose and chin height, is recommended to compensate for a child's more immature grasp and tendency to hold the handle of the cane by the side instead of out in front. Mature cane technique should not be expected from a child, and style and technique can be refined as the child gets older.

</doc>
<doc id="37151" url="https://en.wikipedia.org/wiki?curid=37151" title="Association for the Taxation of Financial Transactions and for Citizens' Action">
Association for the Taxation of Financial Transactions and for Citizens' Action

The Association pour la Taxation des Transactions financières et pour l'Action Citoyenne ("Association for the Taxation of financial Transactions and Citizen's Action", ATTAC) is an activist organization originally created for promoting the establishment of a tax on foreign exchange transactions.
Background.
Originally called "Action for a Tobin Tax to Assist the Citizen", ATTAC was a single-issue movement demanding the introduction of the so-called Tobin tax on currency speculation. ATTAC now devotes itself to a wide range of issues related to globalisation, monitoring the decisions of the World Trade Organization (WTO), the Organisation for Economic Co-operation and Development (OECD) and the International Monetary Fund (IMF). ATTAC attends the meetings of the G8 with the goal of influencing policymakers' decisions. Attac recently criticised Germany for what it called the criminalisation of anti-G8 groups.
At the founding, ATTAC had specific statutory objectives based on the promotion of the Tobin tax. For example, ATTAC Luxembourg specifies in article 1 of its statutes that it "aims to produce and communicate information, and to promote and carry out activities of all kinds for the recapture, by the citizens, of the power that the financial sector has on all aspects of political, economic, social and cultural life throughout the world. Such means include the taxation of transactions in foreign exchange markets (Tobin tax)."
ATTAC claims not to an anti-globalization movement, but it criticises the neoliberal ideology that it sees as dominating economic globalisation. It supports globalisation policies that they characterise as sustainable and socially just. One of ATTAC's slogans is "The World is not for sale", denouncing the "merchandisation" of society. Another slogan is "Another world is possible" pointing to an alternative globalization where people and not profit is in focus.
James Tobin opposing ATTAC.
Attac was originally founded to promote the Tobin tax by the Keynesian economist James Tobin. Tobin himself has accused Attac for misusing his name and said that he has nothing in common with Attac and is a supporter of free trade — "everything that these movements are attacking. They're misusing my name." 
Organisational history.
In December 1997, Ignacio Ramonet wrote in "Le Monde diplomatique" an editorial in which he advocated the establishment of the Tobin tax and the creation of an organisation to pressure governments around the world to introduce the tax. ATTAC was created on June 3, 1998, during a constitutive assembly in France. While it was founded in France it now exists in over forty countries around the world. In France, politicians from the left are members of the association. In Luxembourg, Francois Bausch of the left Green party is the founding politician in the association's initial member list.
ATTAC functions on a principle of decentralisation: local associations organise meetings, conferences, and compose documents that become counter-arguments to the perceived neoliberal discourse. ATTAC aims to formalise the possibility of an alternative to the neoliberal society that is currently required of globalisation. ATTAC aspires to be a movement of popular education.
Views on Attac and its members in different countries.
Finland.
Communist Juhani Lohikoski, previously a chairman of Communist Youth League and Socialist League, served as the chairman of Finnish Attac for two terms (2002 - 2004). Yrjö Hakanen, chairman of the Communist Party of Finland, was a member of the board and a member of the founding committee. In March 2002 Aimo Kairamo, the long-time chief editor of the party organ of the Social Democrat Party, resigned from Attac and recommended the same decision for other social democrats because of the left-wing minority communists' leading positions. Soon also the social democrat foreign minister Erkki Tuomioja considered to follow Kairamo's example.
Sweden.
Researcher Malin Gawell covers the birth and development of Attac Sweden in her doctoral thesis on activist entrepreneurship. She suggests that Attac in Sweden was formed by people seeking a new way of organising with flat hierarchy, and with the strongly sensed need of making a change as the driving force.
From another perspective, Sydsvenskan newspaper suggested that the downturn of memberships in Swedish Attac after the hype in the beginning of 2001 may be due to its views on trade policies.
Issues and activities.
The main issues covered by ATTAC today are:
In France, ATTAC associates with many other left-wing causes.
Nestlégate.
In the year 2008 Attac Switzerland was hit by a scandal which was later called Nestlégate by the local media. Between the years 2003 and 2005, the Swiss multinational food and beverage company Nestlé, engaged the external Security company Securitas AG, to spy on the Swiss Attac branch. Nestlé started the monitoring, when Attac Switzerland decided to work on a critical book about Nestlé.
Due to Nestlégate, Attac Switzerland filed a lawsuit against Nestlé which was decided in favour of Attac in January 2013, as the personal rights of the observed were violated. They received a compensation for damages of 3'000 Swiss francs each, which has an equivalent of about 3'230 USD at the date of the proclamation of sentence.

</doc>
<doc id="37153" url="https://en.wikipedia.org/wiki?curid=37153" title="Supercomputer">
Supercomputer

A supercomputer is a computer with a high-level computational capacity compared to a general-purpose computer. Performance of a supercomputer is measured in floating-point operations per second (FLOPS) instead of million instructions per second (MIPS). As of 2015, there are supercomputers which can perform up to quadrillions of FLOPS.
Supercomputers were introduced in the 1960s, made initially, and for decades primarily, by Seymour Cray at Control Data Corporation (CDC), Cray Research and subsequent companies bearing his name or monogram. While the supercomputers of the 1970s used only a few processors, in the 1990s machines with thousands of processors began to appear and, by the end of the 20th century, massively parallel supercomputers with tens of thousands of "off-the-shelf" processors were the norm. Since its introduction in June 2013, China's Tianhe-2 supercomputer is as of 2015 the fastest in the world at 33.86 petaFLOPS (PFLOPS), or 33.86 quadrillions of FLOPS.
Supercomputers play an important role in the field of computational science, and are used for a wide range of computationally intensive tasks in various fields, including quantum mechanics, weather forecasting, climate research, oil and gas exploration, molecular modeling (computing the structures and properties of chemical compounds, biological macromolecules, polymers, and crystals), and physical simulations (such as simulations of the early moments of the universe, airplane and spacecraft aerodynamics, the detonation of nuclear weapons, and nuclear fusion). Throughout their history, they have been essential in the field of cryptanalysis.
Systems with massive numbers of processors generally take one of the two paths: in one approach (e.g., in distributed computing), hundreds or thousands of discrete computers (e.g., laptops) distributed across a network (e.g., the Internet) devote some or all of their time to solving a common problem; each individual computer (client) receives and completes many small tasks, reporting the results to a central server which integrates the task results from all the clients into the overall solution. In another approach, thousands of dedicated processors are placed in proximity to each other (e.g. in a computer cluster); this saves considerable time moving data around and makes it possible for the processors to work together (rather than on separate tasks), for example in mesh and hypercube architectures.
The use of multi-core processors combined with centralization is an emerging trend; one can think of this as a small cluster (the multicore processor in a smartphone, tablet, laptop, etc.) that both depends upon and contributes to the cloud.
History.
The history of supercomputing goes back to the 1960s, with the Atlas at the University of Manchester and a series of computers at Control Data Corporation (CDC), designed by Seymour Cray. These used innovative designs and parallelism to achieve superior computational peak performance.
The Atlas was a joint venture between Ferranti and the Manchester University and was designed to operate at processing speeds approaching one microsecond per instruction, about one million instructions per second. The first Atlas was officially commissioned on 7 December 1962 as one of the world's first supercomputers considered to be the most powerful computer in the world at that time by a considerable margin, and equivalent to four IBM 7094s.
The CDC 6600, released in 1964, was designed by Cray to be the fastest in the world. Cray switched from use of germanium to silicon transistors, which could run very fast, solving the overheating problem by introducing refrigeration. Given that the 6600 outperformed all the other contemporary computers by about 10 times, it was dubbed a "supercomputer" and defined the supercomputing market when one hundred computers were sold at $8 million each.
Cray left CDC in 1972 to form his own company, Cray Research. Four years after leaving CDC, Cray delivered the 80 MHz Cray 1 in 1976, and it became one of the most successful supercomputers in history. The Cray-2 released in 1985 was an 8 processor liquid cooled computer and Fluorinert was pumped through it as it operated. It performed at 1.9 gigaflops and was the world's second fastest after M-13 supercomputer in Moscow .
While the supercomputers of the 1980s used only a few processors, in the 1990s, machines with thousands of processors began to appear both in the United States and Japan, setting new computational performance records. Fujitsu's Numerical Wind Tunnel supercomputer used 166 vector processors to gain the top spot in 1994 with a peak speed of 1.7 gigaFLOPS (GFLOPS) per processor. The Hitachi SR2201 obtained a peak performance of 600 GFLOPS in 1996 by using 2048 processors connected via a fast three-dimensional crossbar network. The Intel Paragon could have 1000 to 4000 Intel i860 processors in various configurations, and was ranked the fastest in the world in 1993. The Paragon was a MIMD machine which connected processors via a high speed two dimensional mesh, allowing processes to execute on separate nodes, communicating via the Message Passing Interface.
Hardware and architecture.
Approaches to supercomputer architecture have taken dramatic turns since the earliest systems were introduced in the 1960s. Early supercomputer architectures pioneered by Seymour Cray relied on compact innovative designs and local parallelism to achieve superior computational peak performance. However, in time the demand for increased computational power ushered in the age of massively parallel systems.
While the supercomputers of the 1970s used only a few processors, in the 1990s, machines with thousands of processors began to appear and by the end of the 20th century, massively parallel supercomputers with tens of thousands of "off-the-shelf" processors were the norm. Supercomputers of the 21st century can use over 100,000 processors (some being graphic units) connected by fast connections. The Connection Machine CM-5 supercomputer is a massively parallel processing computer capable of many billions of arithmetic operations per second.
Throughout the decades, the management of heat density has remained a key issue for most centralized supercomputers. The large amount of heat generated by a system may also have other effects, e.g. reducing the lifetime of other system components. There have been diverse approaches to heat management, from pumping Fluorinert through the system, to a hybrid liquid-air cooling system or air cooling with normal air conditioning temperatures.
Systems with a massive number of processors generally take one of two paths. In the grid computing approach, the processing power of many computers, organised as distributed, diverse administrative domains, is opportunistically used whenever a computer is available. In another approach, a large number of processors are used in proximity to each other, e.g. in a computer cluster. In such a centralized massively parallel system the speed and flexibility of the interconnect becomes very important and modern supercomputers have used various approaches ranging from enhanced Infiniband systems to three-dimensional torus interconnects. The use of multi-core processors combined with centralization is an emerging direction, e.g. as in the Cyclops64 system.
As the price, performance and energy efficiency of general purpose graphic processors (GPGPUs) have improved, a number of petaflop supercomputers such as Tianhe-I and Nebulae have started to rely on them. However, other systems such as the K computer continue to use conventional processors such as SPARC-based designs and the overall applicability of GPGPUs in general-purpose high-performance computing applications has been the subject of debate, in that while a GPGPU may be tuned to score well on specific benchmarks, its overall applicability to everyday algorithms may be limited unless significant effort is spent to tune the application towards it. However, GPUs are gaining ground and in 2012 the Jaguar supercomputer was transformed into Titan by retrofitting CPUs with GPUs.
High performance computers have an expected life cycle of about three years.
A number of "special-purpose" systems have been designed, dedicated to a single problem. This allows the use of specially programmed FPGA chips or even custom VLSI chips, allowing better price/performance ratios by sacrificing generality. Examples of special-purpose supercomputers include Belle, Deep Blue, and Hydra, for playing chess, Gravity Pipe for astrophysics, MDGRAPE-3 for protein structure computation
molecular dynamics and Deep Crack, for breaking the DES cipher.
Energy usage and heat management.
A typical supercomputer consumes large amounts of electrical power, almost all of which is converted into heat, requiring cooling. For example, Tianhe-1A consumes 4.04 megawatts (MW) of electricity. The cost to power and cool the system can be significant, e.g. 4 MW at $0.10/kWh is $400 an hour or about $3.5 million per year.
Heat management is a major issue in complex electronic devices, and affects powerful computer systems in various ways. The thermal design power and CPU power dissipation issues in supercomputing surpass those of traditional computer cooling technologies. The supercomputing awards for green computing reflect this issue.
The packing of thousands of processors together inevitably generates significant amounts of heat density that need to be dealt with. The Cray 2 was liquid cooled, and used a Fluorinert "cooling waterfall" which was forced through the modules under pressure. However, the submerged liquid cooling approach was not practical for the multi-cabinet systems based on off-the-shelf processors, and in System X a special cooling system that combined air conditioning with liquid cooling was developed in conjunction with the Liebert company.
In the Blue Gene system, IBM deliberately used low power processors to deal with heat density.
On the other hand, the IBM Power 775, released in 2011, has closely packed elements that require water cooling. The IBM Aquasar system, on the other hand uses "hot water cooling" to achieve energy efficiency, the water being used to heat buildings as well.
The energy efficiency of computer systems is generally measured in terms of "FLOPS per watt". In 2008, IBM's Roadrunner operated at 3.76 MFLOPS/W. In November 2010, the Blue Gene/Q reached 1,684 MFLOPS/W. In June 2011 the top 2 spots on the Green 500 list were occupied by Blue Gene machines in New York (one achieving 2097 MFLOPS/W) with the DEGIMA cluster in Nagasaki placing third with 1375 MFLOPS/W.
Because copper wires can transfer energy into a supercomputer with much higher power densities than forced air or circulating refrigerants can remove waste heat,
the ability of the cooling systems to remove waste heat is a limiting factor.
, many existing supercomputers have more infrastructure capacity than the actual peak demand of the machine designers generally conservatively design the power and cooling infrastructure to handle more than the theoretical peak electrical power consumed by the supercomputer. Designs for future supercomputers are power-limited the thermal design power of the supercomputer as a whole, the amount that the power and cooling infrastructure can handle, is somewhat more than the expected normal power consumption, but less than the theoretical peak power consumption of the electronic hardware.
Software and system management.
Operating systems.
Since the end of the 20th century, supercomputer operating systems have undergone major transformations, based on the changes in supercomputer architecture. While early operating systems were custom tailored to each supercomputer to gain speed, the trend has been to move away from in-house operating systems to the adaptation of generic software such as Linux.
Since modern massively parallel supercomputers typically separate computations from other services by using multiple types of nodes, they usually run different operating systems on different nodes, e.g. using a small and efficient lightweight kernel such as CNK or CNL on compute nodes, but a larger system such as a Linux-derivative on server and I/O nodes.
While in a traditional multi-user computer system job scheduling is, in effect, a tasking problem for processing and peripheral resources, in a massively parallel system, the job management system needs to manage the allocation of both computational and communication resources, as well as gracefully deal with inevitable hardware failures when tens of thousands of processors are present.
Although most modern supercomputers use the Linux operating system, each manufacturer has its own specific Linux-derivative, and no industry standard exists, partly due to the fact that the differences in hardware architectures require changes to optimize the operating system to each hardware design.
Software tools and message passing.
The parallel architectures of supercomputers often dictate the use of special programming techniques to exploit their speed. Software tools for distributed processing include standard APIs such as MPI and PVM, VTL, and open source-based software solutions such as Beowulf.
In the most common scenario, environments such as PVM and MPI for loosely connected clusters and OpenMP for tightly coordinated shared memory machines are used. Significant effort is required to optimize an algorithm for the interconnect characteristics of the machine it will be run on; the aim is to prevent any of the CPUs from wasting time waiting on data from other nodes. GPGPUs have hundreds of processor cores and are programmed using programming models such as CUDA or OpenCL.
Moreover, it is quite difficult to debug and test parallel programs. Special techniques need to be used for testing and debugging such applications.
Distributed supercomputing.
Opportunistic approaches.
Opportunistic Supercomputing is a form of networked grid computing whereby a "super virtual computer" of many loosely coupled volunteer computing machines performs very large computing tasks. Grid computing has been applied to a number of large-scale embarrassingly parallel problems that require supercomputing performance scales. However, basic grid and cloud computing approaches that rely on volunteer computing can not handle traditional supercomputing tasks such as fluid dynamic simulations.
The fastest grid computing system is the distributed computing project Folding@home. F@h reported 43.1 PFLOPS of x86 processing power . Of this, 42.5 PFLOPS are contributed by clients running on various GPUs, and the rest from various CPU systems.
The BOINC platform hosts a number of distributed computing projects. , BOINC recorded a processing power of over 5.5 PFLOPS through over 480,000 active computers on the network The most active project (measured by computational power), MilkyWay@home, reports processing power of over 700 teraFLOPS (TFLOPS) through over 33,000 active computers.
, GIMPS's distributed Mersenne Prime search achieved as of 2015 about 60 TFLOPS through over 25,000 registered computers. The Internet PrimeNet Server supports GIMPS's grid computing approach, one of the earliest and most successful grid computing projects, since 1997.
Quasi-opportunistic approaches.
Quasi-opportunistic supercomputing is a form of distributed computing whereby the “super virtual computer” of many networked geographically disperse computers performs computing tasks that demand huge processing power. Quasi-opportunistic supercomputing aims to provide a higher quality of service than opportunistic grid computing by achieving more control over the assignment of tasks to distributed resources and the use of intelligence about the availability and reliability of individual systems within the supercomputing network. However, quasi-opportunistic distributed execution of demanding parallel computing software in grids should be achieved through implementation of grid-wise allocation agreements, co-allocation subsystems, communication topology-aware allocation mechanisms, fault tolerant message passing libraries and data pre-conditioning.
Performance measurement.
Capability vs capacity.
Supercomputers generally aim for the maximum in "capability computing" rather than "capacity computing". Capability computing is typically thought of as using the maximum computing power to solve a single large problem in the shortest amount of time. Often a capability system is able to solve a problem of a size or complexity that no other computer can, e.g. a very complex weather simulation application.
Capacity computing, in contrast, is typically thought of as using efficient cost-effective computing power to solve a few somewhat large problems or many small problems. Architectures that lend themselves to supporting many users for routine everyday tasks may have a lot of capacity, but are not typically considered supercomputers, given that they do not solve a single very complex problem.
Performance metrics.
In general, the speed of supercomputers is measured and benchmarked in "FLOPS" ("FLoating point Operations Per Second"), and not in terms of "MIPS" (Million Instructions Per Second), as is the case with general-purpose computers. These measurements are commonly used with an SI prefix such as tera-, combined into the shorthand "TFLOPS" (1012 FLOPS, pronounced "teraflops"), or peta-, combined into the shorthand "PFLOPS" (1015 FLOPS, pronounced "petaflops".) "Petascale" supercomputers can process one quadrillion (1015) (1000 trillion) FLOPS. Exascale is computing performance in the exaFLOPS (EFLOPS) range. An EFLOPS is one quintillion (1018) FLOPS (one million TFLOPS).
No single number can reflect the overall performance of a computer system, yet the goal of the Linpack benchmark is to approximate how fast the computer solves numerical problems and it is widely used in the industry. The FLOPS measurement is either quoted based on the theoretical floating point performance of a processor (derived from manufacturer's processor specifications and shown as "Rpeak" in the TOP500 lists) which is generally unachievable when running real workloads, or the achievable throughput, derived from the LINPACK benchmarks and shown as "Rmax" in the TOP500 list. The LINPACK benchmark typically performs LU decomposition of a large matrix. The LINPACK performance gives some indication of performance for some real-world problems, but does not necessarily match the processing requirements of many other supercomputer workloads, which for example may require more memory bandwidth, or may require better integer computing performance, or may need a high performance I/O system to achieve high levels of performance.
The TOP500 list.
Since 1993, the fastest supercomputers have been ranked on the TOP500 list according to their LINPACK benchmark results. The list does not claim to be unbiased or definitive, but it is a widely cited current definition of the "fastest" supercomputer available at any given time.
This is a recent list of the computers which appeared at the top of the TOP500 list, and the "Peak speed" is given as the "Rmax" rating. For more historical data see History of supercomputing.
Largest Supercomputer Vendors according to the total Rmax (GFLOPS) operated.
Source : TOP500
Applications.
The stages of supercomputer application may be summarized in the following table:
The IBM Blue Gene/P computer has been used to simulate a number of artificial neurons equivalent to approximately one percent of a human cerebral cortex, containing 1.6 billion neurons with approximately 9 trillion connections. The same research group also succeeded in using a supercomputer to simulate a number of artificial neurons equivalent to the entirety of a rat's brain.
Modern-day weather forecasting also relies on supercomputers. The National Oceanic and Atmospheric Administration uses supercomputers to crunch hundreds of millions of observations to help make weather forecasts more accurate.
In 2011, the challenges and difficulties in pushing the envelope in supercomputing were underscored by IBM's abandonment of the Blue Waters petascale project.
The Advanced Simulation and Computing Program currently uses supercomputers to maintain and simulate the United States nuclear stockpile.
Research and development trends.
Given the current speed of progress, industry experts estimate that supercomputers will reach 1 EFLOPS (1018, 1,000 PFLOPS or one quintillion FLOPS) by 2018. The Chinese government in particular is pushing to achieve this goal after they briefly achieved the most powerful supercomputer in the world with Tianhe-1A in 2010 (ranked fifth by 2012). Using the Intel MIC multi-core processor architecture, which is Intel's response to GPU systems, SGI also plans to achieve a 500-fold increase in performance by 2018 in order to achieve one EFLOPS. Samples of MIC chips with 32 cores, which combine vector processing units with standard CPU, have become available. The Indian government has also stated ambitions for an EFLOPS-range supercomputer, which they hope to complete by 2017. In November 2014, it was reported that India is working on the fastest supercomputer ever, which is set to work at 132 EFLOPS.
Erik P. DeBenedictis of Sandia National Laboratories theorizes that a zettaFLOPS (1021, one sextillion FLOPS) computer is required to accomplish full weather modeling, which could cover a two-week time span accurately. Such systems might be built around 2030.
Many Monte Carlo simulations use the same algorithm to process a randomly generated data set; particularly, integro-differential equations describing physical transport processes, the random paths, collisions, and energy and momentum depositions of neutrons, photons, ions, electrons, etc. The next step for microprocessors may be into the third dimension; and specializing to Monte Carlo, the many layers could be identical, simplifying the design and manufacture process.
Energy use.
High performance supercomputers usually require high energy, as well. However, Iceland may be a benchmark for the future with the world's first zero-emission supercomputer. Located at the Thor Data Center in Reykjavik, Iceland, this supercomputer relies on completely renewable sources for its power rather than fossil fuels. The colder climate also reduces the need for active cooling, making it one of the greenest facilities in the world.
In fiction.
Many Science Fiction writers depicted supercomputers in their works, both before and after such computers were actually constructed. Much of such fiction deals with the relations of humans with the computers they created and the possibility of conflict eventually developing between them. Some such scenarios can be found on the AI takeover page.

</doc>
<doc id="37154" url="https://en.wikipedia.org/wiki?curid=37154" title="Coxsackie A virus">
Coxsackie A virus

Coxsackie A virus (CAV) is a cytolytic Coxsackievirus of the "Picornaviridae" family, an enterovirus (a group containing the polioviruses, coxsackieviruses, and echoviruses).
Diseases.
The most well known Coxsackie A disease is Hand, foot and mouth disease (unrelated to Foot-and-mouth disease), a common childhood illness which affects mostly children aged 5 or under, often produced by Coxsackie A16. In most cases infection is asymptomatic or causes only mild symptoms. In others, infection produces short-lived (7–10 days) fever and painful blisters in the mouth (a condition known as "herpangina"), on the palms and fingers of the hand, or on the soles of the feet. There can also be blisters in the throat, or on or above the tonsils. Adults can also be affected. The rash, which can appear several days after high temperature and painful sore throat, can be itchy and painful, especially on the hands/fingers and bottom of feet.
Other diseases include acute haemorrhagic conjunctivitis (A24 specifically), herpangina, and aseptic meningitis (both Coxsackie A and B viruses). Coxsackievirus A7 infrequently causes polio-like permanent paralysis.
Treatment.
Treatment is dependent on the disease process initiated by the virus.
There is no known cure or vaccine against this virus.

</doc>
<doc id="37160" url="https://en.wikipedia.org/wiki?curid=37160" title="Reinhard">
Reinhard

Reinhard is a surname or given name, and may refer to:
A surname:
A given name:
History:

</doc>
<doc id="37161" url="https://en.wikipedia.org/wiki?curid=37161" title="Fuel injection">
Fuel injection

Fuel injection is a system for introducing fuel into internal combustion engines, and into automotive engines, in particular. On diesel engines, fuel injection is a necessity, whilst on petrol engines fuel injection is an alternative to the carburetor.
On petrol engines, fuel injection became more common from the 1980s onwards. The primary difference between carburetors and fuel injection is that fuel injection atomizes the fuel through a small nozzle under high pressure, while a carburetor relies on suction created by intake air accelerated through a Venturi tube to draw the fuel into the airstream.
Objectives.
The functional objectives for fuel injection systems can vary. All share the central task of supplying fuel to the combustion process, but it is a design decision how a particular system is optimized. There are several competing objectives such as:
The modern digital electronic fuel injection system is more capable at optimizing these competing objectives consistently than earlier fuel delivery systems (such as carburetors). Carburetors have the potential to atomize fuel better (see Pogue and Allen Caggiano patents).
Benefits.
Benefits of fuel injection include smoother and more consistent transient throttle response, such as during quick throttle transitions, easier cold starting, more accurate adjustment to account for extremes of ambient temperatures and changes in air pressure, more stable idling, decreased maintenance needs, and better fuel efficiency.
Fuel injection also dispenses with the need for a separate mechanical choke, which on carburetor-equipped vehicles must be adjusted as the engine warms up to normal temperature. Furthermore, on spark ignition engines (direct) fuel injection has the advantage of being able to facilitate stratified combustion which have not been possible with carburetors.
It is only with the advent of multi-point fuel injection certain engine configurations such as inline five cylinder gasoline engines have become more feasible for mass production, as traditional carburetor arrangement with single or twin carburetors could not provide even fuel distribution between cylinders, unless a more complicated individual carburetor per cylinder is used.
Fuel injection systems are also able to operate normally regardless of orientation, whereas carburetors with floats are not able to operate upside down or in zero gravity, such as encountered on airplanes.
Environmental benefits.
Fuel injection generally increases engine fuel efficiency. With the improved cylinder-to-cylinder fuel distribution of multi-point fuel injection, less fuel is needed for the same power output (when cylinder-to-cylinder distribution varies significantly, some cylinders receive excess fuel as a side effect of ensuring that all cylinders receive "sufficient" fuel).
Exhaust emissions are cleaner because the more precise and accurate fuel metering reduces the concentration of toxic combustion byproducts leaving the engine, and because exhaust cleanup devices such as the catalytic converter can be optimized to operate more efficiently since the exhaust is of consistent and predictable composition.
History and development.
Herbert Akroyd Stuart developed the first device with a design similar to modern fuel injection, using a 'jerk pump' to meter out fuel oil at high pressure to an injector. This system was used on the hot bulb engine and was adapted and improved by Bosch and Clessie Cummins for use on diesel engines (Rudolf Diesel's original system employed a cumbersome 'air-blast' system using highly compressed air). Fuel injection was in widespread commercial use in diesel engines by the mid-1920s.
An early use of indirect gasoline injection dates back to 1902, when French aviation engineer Leon Levavasseur installed it on his pioneering Antoinette 8V aircraft powerplant, the first V8 engine of any type ever produced in any quantity.
Another early use of gasoline direct injection was on the Hesselman engine invented by Swedish engineer Jonas Hesselman in 1925. Hesselman engines use the ultra lean burn principle; fuel is injected toward the end of the compression stroke, then ignited with a spark plug. They are often started on gasoline and then switched to diesel or kerosene.
Direct fuel injection was used in notable World War II aero-engines such as the Junkers Jumo 210, the Daimler-Benz DB 601, the BMW 801, the Shvetsov ASh-82FN (M-82FN). German direct injection petrol engines used injection systems developed by Bosch from their diesel injection systems. Later versions of the Rolls-Royce Merlin and Wright R-3350 used single point fuel injection, at the time called "Pressure Carburettor". Due to the wartime relationship between Germany and Japan, Mitsubishi also had two radial aircraft engines utilizing fuel injection, the Mitsubishi Kinsei ("kinsei" means "venus") and the Mitsubishi Kasei ("kasei" means "mars").
Alfa Romeo tested one of the first electronic injection systems (Caproni-Fuscaldo) in Alfa Romeo 6C 2500 with "Ala spessa" body in 1940 Mille Miglia. The engine had six electrically operated injectors and were fed by a semi-high-pressure circulating fuel pump system.
Development in diesel engines.
All diesel engines (with the exception of some tractors and scale model engines) have fuel injected into the combustion chamber. See diesel engines.
Development in gasoline/petrol engines.
Mechanical injection.
The invention of mechanical injection for gasoline-fueled aviation engines was by the French inventor of the V8 engine configuration, Leon Levavasseur in 1902. Levavasseur designed the original Antoinette firm's series of V-form aero engines, starting with the Antoinette 8V to be used by the aircraft the Antoinette firm built that Levavasseur also designed, flown from 1906 to the firm's demise in 1910, with the world's first V16 engine, using Levavasseur's direct injection and producing around flying an Antoinette VII monoplane in 1907.
The first post-World War I example of direct gasoline injection was on the Hesselman engine invented by Swedish engineer Jonas Hesselman in 1925. Hesselman engines used the ultra lean burn principle and injected the fuel in the end of the compression stroke and then ignited it with a spark plug, it was often started on gasoline and then switched over to run on diesel or kerosene. The Hesselman engine was a low compression design constructed to run on heavy fuel oils.
Direct gasoline injection was applied during the Second World War to almost all higher-output production aircraft powerplants made in Germany (the widely used BMW 801 radial, and the popular inverted inline V12 Daimler-Benz DB 601, DB 603 and DB 605, along with the similar Junkers Jumo 210G, Jumo 211 and Jumo 213, starting as early as 1937 for both the Jumo 210G and DB 601), the Soviet Union (Shvetsov ASh-82FN radial, 1943, Chemical Automatics Design Bureau - KB Khimavtomatika) and the USA (Wright R-3350 "Duplex Cyclone" radial, 1944).
Immediately following the war, hot rodder Stuart Hilborn started to offer mechanical injection for race cars, salt cars, and midgets, well-known and easily distinguishable because of their prominent velocity stacks projecting upwards from the engines on which they were used.
The first automotive direct injection system used to run on gasoline was developed by Bosch, and was introduced by Goliath for their Goliath GP700 automobile, and Gutbrod in 1952. This was basically a high-pressure diesel direct-injection pump with an intake throttle valve. (Diesels only change the amount of fuel injected to vary output; there is no throttle.) This system used a normal gasoline fuel pump, to provide fuel to a mechanically driven injection pump, which had separate plungers per injector to deliver a very high injection pressure directly into the combustion chamber. The 1954 Mercedes-Benz W196 Formula 1 racing car engine used Bosch direct injection derived from wartime aero engines. Following this racetrack success, the 1955 Mercedes-Benz 300SL, the first production sports car to use fuel injection, used direct injection. The 1955 Mercedes-Benz 300SLR, in which Stirling Moss drove to victory in the 1955 Mille Miglia and Pierre Levegh crashed and died in the 1955 Le Mans disaster, had an engine developed from the W196 engine. The Bosch fuel injectors were placed into the bores on the cylinder wall used by the spark plugs in other Mercedes-Benz six-cylinder engines (the spark plugs were relocated to the cylinder head). Later, more mainstream applications of fuel injection favored the less-expensive indirect injection methods.
Chevrolet introduced a mechanical fuel injection option, made by General Motors' Rochester Products division, for its 283 V8 engine in 1956 (1957 U.S. model year). This system directed the inducted engine air across a "spoon shaped" plunger that moved in proportion to the air volume. The plunger connected to the fuel metering system that mechanically dispensed fuel to the cylinders via distribution tubes. This system was not a "pulse" or intermittent injection, but rather a constant flow system, metering fuel to all cylinders simultaneously from a central "spider" of injection lines. The fuel meter adjusted the amount of flow according to engine speed and load, and included a fuel reservoir, which was similar to a carburetor's float chamber. With its own high-pressure fuel pump driven by a cable from the distributor to the fuel meter, the system supplied the necessary pressure for injection. This was a "port" injection where the injectors are located in the intake manifold, very near the intake valve.
In 1956, Lucas developed its injection system, which was first used for Jaguar racing cars at Le Mans. The system was subsequently adopted very successfully in Formula One racing, securing championships by Cooper, BRM, Lotus, Brabham, Matra and Tyrrell in the years 1959 through 1973. While the racing systems used a simple "fuel cam" for metering, a more sophisticated "Mk 2" vacuum based "shuttle metering" was developed for production cars. This mechanical system was used by some Maserati, Aston Martin, and Triumph models between 1963 and 1975.
During the 1960s, other mechanical injection systems such as Hilborn were occasionally used on modified American V8 engines in various racing applications such as drag racing, oval racing, and road racing. These racing-derived systems were not suitable for everyday street use, having no provisions for low speed metering, or often none even for starting (starting required that fuel be squirted into the injector tubes while cranking the engine). However, they were a favorite in the aforementioned competition trials in which essentially wide-open throttle operation was prevalent. Constant-flow injection systems continue to be used at the highest levels of drag racing, where full-throttle, high-RPM performance is key.
In 1967, one of the first Japanese designed cars to use mechanical fuel injection was the Daihatsu Compagno.
Another mechanical system, made by Bosch called Jetronic, but injecting the fuel into the port above the intake valve, was used by several European car makers, particularly Porsche from 1969 until 1973 in the 911 production range and until 1975 on the Carrera 3.0 in Europe. Porsche continued using this system on its racing cars into the late seventies and early eighties. Porsche racing variants such as the 911 RSR 2.7 & 3.0, 904/6, 906, 907, 908, 910, 917 (in its regular normally aspirated or 5.5 Liter/1500 HP turbocharged form), and 935 all used Bosch or Kugelfischer built variants of injection. The early Bosch Jetronic systems were also used by Audi, Volvo, BMW, Volkswagen, and many others. The Kugelfischer system was also used by the BMW 2000/2002 Tii and some versions of the Peugeot 404/504 and Lancia Flavia.
A system similar to the Bosch inline mechanical pump was built by SPICA for Alfa Romeo, used on the Alfa Romeo Montreal and on U.S. market 1750 and 2000 models from 1969 to 1981. This was designed to meet the U.S. emission requirements with no loss in performance and it also reduced fuel consumption.
Electronic injection.
The first commercial electronic fuel injection (EFI) system was Electrojector, developed by the Bendix Corporation and was offered by American Motors Corporation (AMC) in 1957. The Rambler Rebel, showcased AMC's new engine. The Electrojector was an option and rated at . The EFI produced peak torque 500 rpm lower than the equivalent carburetored engine The Rebel Owners Manual described the design and operation of the new system. (due to cooler, therefore denser, intake air). The cost of the EFI option was US$395 and it was available on 15 June 1957. Electrojector's teething problems meant only pre-production cars were so equipped: thus, very few cars so equipped were ever sold and none were made available to the public. The EFI system in the Rambler ran fine in warm weather, but suffered hard starting in cooler temperatures.
Chrysler offered Electrojector on the 1958 Chrysler 300D, DeSoto Adventurer, Dodge D-500, and Plymouth Fury, arguably the first series-production cars equipped with an EFI system. It was jointly engineered by Chrysler and Bendix. The early electronic components were not equal to the rigors of underhood service, however, and were too slow to keep up with the demands of "on the fly" engine control. Most of the 35 vehicles originally so equipped were field-retrofitted with 4-barrel carburetors. The Electrojector patents were subsequently sold to Bosch.
Bosch developed an electronic fuel injection system, called "D-Jetronic" ("D" for "Druck", German for "pressure"), which was first used on the VW 1600TL/E in 1967. This was a speed/density system, using engine speed and intake manifold air density to calculate "air mass" flow rate and thus fuel requirements. This system was adopted by VW, Mercedes-Benz, Porsche, Citroën, Saab, and Volvo. Lucas licensed the system for production in Jaguar cars, initially in D-Jetronic form before switching to L-Jetronic in 1978 on the XK6 engine.
Bosch superseded the D-Jetronic system with the "K-Jetronic" and "L-Jetronic" systems for 1974, though some cars (such as the Volvo 164) continued using D-Jetronic for the following several years. In 1970, the Isuzu 117 Coupé was introduced with a Bosch-supplied D-Jetronic fuel injected engine sold only in Japan. In 1984 Rover fitted Lucas electronic fuel injection, which was based on some L-Jetronic patents, to the S-Series engine as used in the 200 model.
In Japan, the Toyota Celica used electronic, multi-port fuel injection in the optional 18R-E engine in January 1974. Nissan offered electronic, multi-port fuel injection in 1975 with the Bosch L-Jetronic system used in the Nissan L28E engine and installed in the Nissan Fairlady Z, Nissan Cedric, and the Nissan Gloria. Nissan also installed multi-point fuel injection in the Nissan Y44 V8 engine in the Nissan President. Toyota soon followed with the same technology in 1978 on the 4M-E engine installed in the Toyota Crown, the Toyota Supra, and the Toyota Mark II. In the 1980s, the Isuzu Piazza, and the Mitsubishi Starion added fuel injection as standard equipment, developed separately with both companies history of diesel powered engines. 1981 saw Mazda offer fuel injection in the Mazda Luce with the Mazda FE engine, and in 1983, Subaru offered fuel injection in the Subaru EA81 engine installed in the Subaru Leone. Honda followed in 1984 with their own system, called PGM-FI in the Honda Accord, and the Honda Vigor using the Honda ES3 engine.
The limited production Chevrolet Cosworth Vega was introduced in March 1975 using a Bendix EFI system with pulse-time manifold injection, four injector valves, an electronic control unit (ECU), five independent sensors and two fuel pumps. The EFI system was developed to satisfy stringent emission control requirements and market demands for a technologically advanced responsive vehicle. 5000 hand-built Cosworth Vega engines were produced but only 3,508 cars were sold through 1976.
The Cadillac Seville was introduced in 1975 with an EFI system made by Bendix and modelled very closely on Bosch's D-Jetronic. L-Jetronic first appeared on the 1974 Porsche 914, and uses a mechanical airflow meter (L for Luft, German for "air") that produces a signal that is proportional to "air volume". This approach required additional sensors to measure the atmospheric pressure and temperature, to ultimately calculate "air mass". L-Jetronic was widely adopted on European cars of that period, and a few Japanese models a short time later.
In 1980, Motorola (now Freescale) introduced the first electronic engine control unit, the EEC-III. Its integrated control of engine functions (such as fuel injection and spark timing) is now the standard approach for fuel injection systems. The Motorola technology was installed in Ford North American products.
Ellimination of carburetors.
In the 1970s and 1980s in the U.S. and Japan, the respective federal governments imposed increasingly strict exhaust emission regulations. During that time period, the vast majority of gasoline-fueled automobile and light truck engines did not use fuel injection. To comply with the new regulations, automobile manufacturers often made extensive and complex modifications to the engine carburetor(s). While a simple carburetor system is cheaper to manufacture than a fuel injection system, the more complex carburetor systems installed on many engines in the 1970s were much more costly than the earlier simple carburetors. To more easily comply with emissions regulations, automobile manufacturers began installing fuel injection systems in more gasoline engines during the late 1970s.
The open loop fuel injection systems had already improved cylinder-to-cylinder fuel distribution and engine operation over a wide temperature range, but did not offer further scope to sufficient control fuel/air mixtures, in order to further reduce exhaust emissions. Later Closed loop fuel injection systems improved the air/fuel mixture control with an exhaust gas oxygen sensor. Although not part of the injection control, a catalytic converter further reduces exhaust emissions.
Fuel injection was phased in through the latter 1970s and 80s at an accelerating rate, with the German, French, and U.S. markets leading and the UK and Commonwealth markets lagging somewhat. Since the early 1990s, almost all gasoline passenger cars sold in first world markets are equipped with electronic fuel injection (EFI). The carburetor remains in use in developing countries where vehicle emissions are unregulated and diagnostic and repair infrastructure is sparse. Fuel injection is gradually replacing carburetors in these nations too as they adopt emission regulations conceptually similar to those in force in Europe, Japan, Australia, and North America.
Many motorcycles still utilize carburetored engines, though all current high-performance designs have switched to EFI.
NASCAR finally replaced carburetors with fuel-injection, starting at the beginning of the 2012 NASCAR Sprint Cup Series season.
System components.
System overview.
The process of determining the necessary amount of fuel, and its delivery into the engine, are known as fuel metering. Early injection systems used mechanical methods to meter fuel, while nearly all modern systems use electronic metering.
Determining how much fuel to supply.
The primary factor used in determining the amount of fuel required by the engine is the amount (by weight) of air that is being taken in by the engine for use in combustion. Modern systems use a mass airflow sensor to send this information to the engine control unit.
Data representing the amount of power output desired by the driver (sometimes known as "engine load") is also used by the engine control unit in calculating the amount of fuel required. A throttle position sensor (TPS) provides this information. Other engine sensors used in EFI systems include a coolant temperature sensor, a camshaft or crankshaft position sensor (some systems get the position information from the distributor), and an oxygen sensor which is installed in the exhaust system so that it can be used to determine how well the fuel has been combusted, therefore allowing closed loop operation.
Supplying the fuel to the engine.
Fuel is transported from the fuel tank (via fuel lines) and pressurised using fuel pump(s). Maintaining the correct fuel pressure is done by a fuel pressure regulator. Often a fuel rail is used to divide the fuel supply into the required number of cylinders. The fuel injector injects liquid fuel into the intake air (the location of the fuel injector varies between systems).
Unlike carburettor-based systems, where the float chamber provides a reservoir, fuel injected systems depend on an uninterrupted flow of fuel. To avoid fuel starvation when subject to lateral G-forces, vehicles are often provided by an anti-surge vessel, usually integrated in the fuel tank, but sometimes as a separate, small anti-surge tank.
EFI gasoline engine components.
"Note: These examples specifically apply to a modern EFI gasoline engine. Parallels to fuels other than gasoline can be made, but only conceptually."
Engine control unit.
The engine control unit is central to an EFI system. The ECU interprets data from input sensors to, among other tasks, calculate the appropriate amount of fuel to inject.
Fuel injector.
When signalled by the engine control unit the fuel injector opens and sprays the pressurised fuel into the engine. The duration that the injector is open (called the pulse width) is proportional to the amount of fuel delivered. Depending on the system design, the timing of when injector opens is either relative each individual cylinder (for a sequential fuel injection system), or injectors for multiple cylinders may be signalled to open at the same time (in a batch fire system).
Target air/fuel ratios.
The relative proportions of air and fuel vary according to the type of fuel used and the performance requirements (i.e. power, fuel economy, or exhaust emissions).
See air-fuel ratio, stoichiometry, and combustion.
Various injection schemes.
Single-point injection.
Single-point injection (SPI) uses a single injector at the throttle body (the same location as was used by carburetors).
It was introduced in the 1940s in large aircraft engines (then called the pressure carburetor) and in the 1980s in the automotive world (called Throttle-body Injection by General Motors, Central Fuel Injection by Ford, PGM-CARB by Honda, and EGI by Mazda). Since the fuel passes through the intake runners (like a carburetor system), it is called a "wet manifold system".
The justification for single-point injection was low cost. Many of the carburetor's supporting components- such as the air cleaner, intake manifold, and fuel line routing- could be reused. This postponed the redesign and tooling costs of these components. Single-point injection was used extensively on American-made passenger cars and light trucks during 1980-1995, and in some European cars in the early and mid-1990s.
Continuous injection.
In a continuous injection system, fuel flows at all times from the fuel injectors, but at a variable flow rate. This is in contrast to most fuel injection systems, which provide fuel during short pulses of varying duration, with a constant rate of flow during each pulse. Continuous injection systems can be multi-point or single-point, but not direct.
The most common automotive continuous injection system is Bosch's K-Jetronic, introduced in 1974. K-Jetronic was used for many years between 1974 and the mid-1990s by BMW, Lamborghini, Ferrari, Mercedes-Benz, Volkswagen, Ford, Porsche, Audi, Saab, DeLorean, and Volvo. Chrysler used a continuous fuel injection system on the 1981-1983 Imperial.
In piston aircraft engines, continuous-flow fuel injection is the most common type. In contrast to automotive fuel injection systems, aircraft continuous flow fuel injection is all mechanical, requiring no electricity to operate. Two common types exist: the Bendix RSA system, and the TCM system. The Bendix system is a direct descendant of the pressure carburetor. However, instead of having a discharge valve in the barrel, it uses a "flow divider" mounted on top of the engine, which controls the discharge rate and evenly distributes the fuel to stainless steel injection lines to the intake ports of each cylinder. The TCM system is even more simple. It has no venturi, no pressure chambers, no diaphragms, and no discharge valve. The control unit is fed by a constant-pressure fuel pump. The control unit simply uses a butterfly valve for the air, which is linked by a mechanical linkage to a rotary valve for the fuel. Inside the control unit is another restriction, which controls the fuel mixture. The pressure drop across the restrictions in the control unit controls the amount of fuel flow, so that fuel flow is directly proportional to the pressure at the flow divider. In fact, most aircraft that use the TCM fuel injection system feature a fuel flow gauge that is actually a pressure gauge calibrated in "gallons per hour" or "pounds per hour" of fuel.
Central port injection.
From 1992 to 1996 General Motors implemented a system called Central Port Injection or Central Port Fuel Injection. The system uses tubes with poppet valves from a central injector to spray fuel at each intake port rather than the central throttle-body. Fuel pressure is similar to a single-point injection system. CPFI (used from 1992 to 1995) is a batch-fire system, while CSFI (from 1996) is a sequential system.
Multipoint fuel injection.
Multipoint fuel injection (also called PFI, port fuel injection) injects fuel into the intake ports just upstream of each cylinder's intake valve, rather than at a central point within an intake manifold. MPI systems can be sequential, in which injection is timed to coincide with each cylinder's intake stroke; batched, in which fuel is injected to the cylinders in groups, without precise synchronization to any particular cylinder's intake stroke; or simultaneous, in which fuel is injected at the same time to all the cylinders. The intake is only slightly wet, and typical fuel pressure runs between 40-60 psi.
Many modern EFI systems utilize sequential MPI; however, in newer gasoline engines, direct injection systems are beginning to replace sequential ones.
Direct injection.
In a direct injection engine, fuel is injected into the combustion chamber as opposed to injection before the intake valve (petrol engine) or a separate pre-combustion chamber (diesel engine).
In a common rail system, the fuel from the fuel tank is supplied to the common header (called the accumulator). This fuel is then sent through tubing to the injectors, which inject it into the combustion chamber. The header has a high pressure relief valve to maintain the pressure in the header and return the excess fuel to the fuel tank. The fuel is sprayed with the help of a nozzle that is opened and closed with a needle valve, operated with a solenoid. When the solenoid is not activated, the spring forces the needle valve into the nozzle passage and prevents the injection of fuel into the cylinder. The solenoid lifts the needle valve from the valve seat, and fuel under pressure is sent in the engine cylinder. Third-generation common rail diesels use piezoelectric injectors for increased precision, with fuel pressures up to .
Direct fuel injection costs more than indirect injection systems: the injectors are exposed to more heat and pressure, so more costly materials and higher-precision electronic management systems are required.
Diesel engines.
Most diesel engines (with the exception of some tractors and scale model engines) have fuel injected into the combustion chamber.
Earlier systems, relying on simpler injectors, often injected into a sub-chamber shaped to swirl the compressed air and improve combustion; this was known as indirect injection. However, this was less efficient than the now common direct injection in which initiation of combustion takes place in a depression (often toroidal) in the crown of the piston.
Throughout the early history of diesels, they were always fed by a mechanical pump with a small separate chamber for each cylinder, feeding separate fuel lines and individual injectors. Most such pumps were in-line, though some were rotary.
Most modern diesel engines use common rail or unit injector direct injection systems.
Gasoline engines.
Modern gasoline engines also utilise direct injection, which is referred to as gasoline direct injection. This is the next step in evolution from multi-point fuel injection, and offers another magnitude of emission control by eliminating the "wet" portion of the induction system along the inlet tract.
By virtue of better dispersion and homogeneity of the directly injected fuel, the cylinder and piston are cooled, thereby permitting higher compression ratios and earlier ignition timing, with resultant enhanced power output. More precise management of the fuel injection event also enables better control of emissions. Finally, the homogeneity of the fuel mixture allows for leaner air/fuel ratios, which together with more precise ignition timing can improve fuel efficiency. Along with this, the engine can operate with stratified (lean burn) mixtures, and hence avoid throttling losses at low and part engine load. Some direct-injection systems incorporate piezoelectronic fuel injectors. With their extremely fast response time, multiple injection events can occur during each cycle of each cylinder of the engine.
Swirl injection.
Swirl injectors are used in liquid rocket, gas turbine, and diesel engines to improve atomization and mixing efﬁciency.
The circumferential velocity component is ﬁrst generated as the propellant enters through helical or tangential inlets producing a thin, swirling liquid sheet. A gas-ﬁlled hollow core is then formed along the centerline inside the injector due to centrifugal force of the liquid sheet. Because of the presence of the gas core, the discharge coefﬁcient is generally low. In swirl injector, the spray cone angle is controlled by the ratio of the circumferential velocity to the axial velocity and is generally wide compared with nonswirl injectors.
Maintenance hazards.
Fuel injection introduces potential hazards in engine maintenance due to the high fuel pressures used. Residual pressure can remain in the fuel lines long after an injection-equipped engine has been shut down. This residual pressure must be relieved, and if it is done so by external bleed-off, the fuel must be safely contained. If a high-pressure diesel fuel injector is removed from its seat and operated in open air, there is a risk to the operator of injury by hypodermic jet-injection, even with only pressure. The first known such injury occurred in 1937 during a diesel engine maintenance operation.

</doc>
<doc id="37162" url="https://en.wikipedia.org/wiki?curid=37162" title="Roland Freisler">
Roland Freisler

Roland Freisler (30 October 1893 – 3 February 1945) was a pre-eminent Nazi lawyer and judge of the Third Reich. He was State Secretary of the Reich Ministry of Justice, and President of the People's Court ("Volksgerichtshof"). He was also an attendee at the Conference at Wannsee in 1942 which set in motion the Third Reich's administrative planning for the destruction of European Jewry. 
Early life.
Roland Freisler was born in Celle, Lower Saxony on 30 October 1893. He was the son of Julius Freisler (born 20 August 1862 in Klantendorf, Moravia), an engineer and teacher, and Charlotte Auguste Florentine Schwerdtfeger (born 30 April 1863 in Celle – died 20 March 1932 in Kassel). He was baptised as a Protestant on 13 December 1893. He had a younger brother, Oswald. In 1914 he was at law school when the outbreak of war interrupted his studies.
World War 1.
Freisler saw active service during World War 1. He was an officer cadet in 1914, and by 1915 he was a lieutenant. Whilst in the front-line he was awarded the Iron Cross both 2nd and 1st Class for heroism in action. In October 1915 he was wounded in action on the Eastern Front and taken prisoner of war by Russian forces.
Whilst a prisoner Freisler learned to speak Russian, and developed an interest in Marxism after the Russian Revolution had commenced. The Bolshevik provisional authority which took over responsibility for Freisler's prisoner of war camp made use of him as a 'Commissar' administratively organising its food supplies in 1917-1918. It is possible that after the Russian prisoner of war camps were emptying in 1918, with their internees being repatriated to Germany after the Armistice between Russia and the Central Powers had been signed, Freisler for a brief period became attached in some way to the Red Guards, though this is not supported by any known documentary evidence. Another possibility is that after the Russian Revolution the description "Commissar" was merely an administrative title given by the Bolshevik authority for any one employed in an administrative post in the prison camps without the political connotations that the title later acquired, though in the early days of his National Socialist German Workers' Party career in the 1920's Freisler was a part of the movement's left wing, and in the late 1930's he attended the Soviet Moscow Trials to watch the proceedings. Freisler later rejected any insinuation that he had ever co-operated with the Nazi Regime's ideological enemy, but his subsequent career as a political official in Germany was over-shadowed by rumours about his time as a "Commissar" with the "Reds".
Post-war legal career.
He returned to Germany in 1919 to complete his law studies at the University of Jena, and was awarded a Doctor of Law in 1922. From 1924 he worked as a solicitor in Kassel. He was also elected a city councillor as a member of the "Völkisch-Sozialer Block" ("People's Social Block"), an extreme nationalist splinter party. Freisler joined the National Socialist Workers' Party in July 1925 as Member #9679. and gained authority immediately within the organisation by using his legal training to defend members of it who were regularly facing prosecutions for acts of political violence. As the Party transitioned from a fringe political beer-hall and street fighting movement into a political one, Freisler was elected for it to the Prussian Landtag, and later he became a Member of the Reichstag.
In 1927 Karl Weinrich, a Nazi member of the Prussian Landtag along with Freisler, characterised his then reputation in the rapidly expanding Nazi movement in the late 1920's: "Rhetorically Freisler is equal to our best speakers, if not superior; particularly on the broad masses he has influence, but thinking people mostly reject him. Party Comrade Freisler is only usable as a speaker though and is unsuitable for any position of authority because of his unreliablity and moodiness." 
Career in Nazi Germany.
In February 1933, after the revolutionary take-over of the German state by Adolf Hitler with the Enabling Act of 1933, Freisler was appointed as the Director of the Prussian Ministry of Justice. He was Secretary of State in the Prussian Ministry of Justice in 1933–1934, and in the Reich Ministry of Justice from 1934 to 1942. 
Freisler's mastery of legal texts, mental agility, dramatic court-room verbal dexterity and verbal force, in combination with his zealous conversion to National Socialist ideology, made him the most feared judge in the Germany during the Third Reich, and the personification of Nazism in domestic Law. However, despite his talents and loyalty, Adolf Hitler never appointed him to a government post beyond the legal system. This might have been attributable to the fact of him being a lone figure lacking support within the senior echelons of the Nazi hierarchy, and also partly that he had been politically compromised through family association with his brother Oswald Freisler, who was also a lawyer, and who had appeared as the defence counsel in court against the Regime's authority several times in its programme of increasingly politically-driven trials with which it sought to enforce its tyrannical control of German society, and who had a habit of wearing his Nazi Party membership badge in court whilst doing so. Propaganda minister Joseph Goebbels reproved Oswald Freisler and reported his actions to Adolf Hitler, who in response ordered the expulsion of him from the Party. (Oswald Freisler committed suicide in 1939). In 1941 in a discussion at the "Führer Head Quarters" about who to appoint to replace Reich Justice Minister Franz Gürtner, the Reich Justice Minister, who had died, Joseph Goebbels suggested Freisler as an option; Hitler's reply in an echo of the "Red" past of Freisler was: "That old Bolshevik? No!" 
Contribution to the Nazification of the law.
Freisler was a committed National Socialist ideologist, and used his legal skills to adapt its theories into practical law making and judicature. He published a paper entitled ""Die rassebiologische Aufgabe bei der Neugestaltung des Jugendstrafrechts" ("The racial-biological task involved in the reform of Juvenile Criminal Law"). In this document he argued that "racially foreign, racially degenerate, racially incurable or seriously defective juveniles" should be sent to juvenile centres or correctional education centres and segregated from those who are "German and racially valuable."
He strongly advocated the creation of laws to punish "Rassenschande" ("race defilement", the Nazi term for sexual relations between "Aryans" and "inferior races"), to be classed as 'racial treason'. In 1933 he published a pamphlet calling for the legal prohibition of "mixed-blood" sexual intercourse, which faced expressions of public unease in the dying elements of the German free press and non-Nazi political classes and, at the time, lacked the public authorization from Nazi Party public policy which had only just obtained dictatorial control of the state. It also led to a clash with his superior Franz Gürtner, but Freisler's ideological views reflected things to come, as was shown by the enactment of the Nuremberg Laws within two years. 
In October 1939 Freisler introduced the concept of 'precocious juvenile criminal' in the "Juvenile Felons Decree". This "provided the legal basis for imposing the death penalty and penitentiary terms on juveniles for the first time in German legal history". From the period 1933 to 1945 the Reich's Courts sentenced at least 72 German juveniles to death, among them 17-year-old Helmuth Hübener, found guilty of high treason for distributing anti-war leaflets in 1942.
On the outbreak of World War II Freisler issued a legal "Decree against National Parasites" (September 1939) introducing the term "perpetrator type", which was used in combination with another National Socialist ideological term "parasite." The adoption of racial biological terminology into law portrayed juvenile criminality as 'parasitical', implying the need for harsher sentences to remedy it. He justified the new concept with: "In times of war, breaches of loyalty and baseness cannot find any leniency and must be met with the full force of the law."
The Wannsee Conference.
On 20 January 1942 Freisler, representing the Reich Minister Franz Schlegelberger, attended the Wannsee Conference of senior governmental officials in a villa on the outskirts of the South-West of Berlin to provide expert legal advice for the planning of the destruction of European Jewry. 
Presidency of the People's Court.
On 20 August 1942, Hitler promoted Otto Georg Thierack to Reich Justice Minister, replacing the retiring Schlegelberger, and named Freisler to succeed Thierack as president of the People's Court ("Volksgerichtshof"). This court had jurisdiction over a broad array of political offences, including black marketeering, work slowdowns and defeatism. These actions were viewed by Freisler as "Wehrkraftzersetzung" (undermining defensive capability) and were punished severely, death sentences being meted out in numerous cases. The People's Court under Freisler's domination almost always sided with the Prosecuting authority, to the point that being brought before it was tantamount to a capital charge. Its separate administrative existence beyond the ordinary judicial system increased its notoriety, and despite its judicial trappings it rapidly turned into an executive execution arm and psychological domestic terror weapon of Nazi Germany's totalitarian regime, in the tradition of the Revolutionary Tribunal, more than a court of law. 
Freisler chaired the First Senate of the People's Court wearing a blood scarlet judicial robe, in a hearing chamber bedecked with scarlet Swastika draped banners and a large black sculpted bust of Adolf Hitler's head upon a high pedastal behind his chair, opening each hearing session with the Nazi salute from the bench. He acted as prosecutor, judge and jury embodied into one role, and his own recorder, thereby controlling the record of the written grounds for the sentences that he passed.
The number of death sentences rose sharply under Freisler's rule. Approximately 90% of all proceedings that came before him received sentences of death or life imprisonment, the sentences frequently having been determined before the trial. Between 1942 and 1945, more than 5,000 death sentences were decreed by him, and of these 2600 through the court's First Senate, which Freisler controlled. He was responsible in his three years on the court for as many death sentences as all other senate sessions of the court put together in the court's existence between 1934 and 1945. 
Freisler became in this period notorious for berating in a personalized injudicial manner from the bench the steady stream of defendants passing before him on their way to their deaths, often shouting and occasionally yelling at them - particularly in cases of resistance to the authority of Nazi Germany - in an enraged, glaringly clarion, but dramatically controlled harsh voice, using a mastery of the art of court-room performance artifice. He was known to be interested in Andrei Vyshinsky, the Chief Prosecutor of the Soviet purge trials, and Freisler attended those show-trials to watch Vyshinsky's performances when he had been engaged in the same work in Moscow in 1938.
White Rose show-trials.
In 1943 Freisler punished several members of the White Rose resistance group that the Gestapo brought before him by ordering their execution by beheading using the Fallbeil.
20th July Plot show-trials.
In August 1944 a number of the arrested perpetrators of the failed assassination of Adolf Hitler were taken before Freisler for punishment, with the proceedings being recorded by film camera with the intention of displaying it to the German public in cinema newsreels. In the multiple hearings the atmosphere with which Freisler ran his court was revealed, showing him alternating between cerebrally clinically interrogating the prisoners to prove their guilt of the charges, verbally and psychologically toying with them, or yelling personalized theatrical enraged abuse at them from the bench. Nearly all were sentenced to death by hanging, the sentences being carried out within 2 hours of the verdicts being passed.
Death.
On the morning of 3 February 1945 Freisler was conducting a Saturday session of the People's Court when United States Army Air Force bombers attacked Berlin. Government and Nazi Party buildings were hit, including the Reich Chancellery, the Gestapo headquarters, the Party Chancellery and the People's Court. Hearing the air-raid sirens Freisler hastily adjourned the court and ordered that the prisoners before him be taken to an air-raid shelter, but paused himself to gather files before following. A sudden direct hit on the court-building at 11.08 A.M. caused a partial internal collapse, with Freisler being crushed by a masonary column and killed whilst still in the court-room. His body was found beneath the rubble still clutching the files that he had stopped to retrieve. 
Freisler's body was buried in the grave of his wife's family at the Waldfriedhof Dahlem Cemetery in Berlin. His name is not recorded on the gravestone.
Personal life.
Freisler married Marion Russegger on 24 March 1928, the marriage produced two sons, Harald and Roland. 
Cultural references.
Freisler appears in fictionalised form in the 1947 Hans Fallada novel "Every Man Dies Alone". In 1943 he tried and handed down death penalties to Otto and Elise Hampel, whose true story inspired Fallada's novel.
Freisler has been portrayed by screen actors at least five times: by Rainer Steffen in the 1984 German television film "Wannseekonferenz", by Roland Schäfer in the 1989 Anglo-French-German film "Reunion", by Brian Cox in the British 1996 television film "Witness Against Hitler", by Owen Teale in the 2001 BBC/HBO film "Conspiracy", by André Hennicke in the 2005 film "Sophie Scholl – The Final Days", and by Helmut Stauss in the 2008 film "Valkyrie".

</doc>
<doc id="37165" url="https://en.wikipedia.org/wiki?curid=37165" title="Grand Slam">
Grand Slam

Grand Slam or Grand slam may refer to:

</doc>
<doc id="37166" url="https://en.wikipedia.org/wiki?curid=37166" title="Openlaw">
Openlaw

Openlaw is a project at the Berkman Center for Internet and Society at Harvard Law School aimed at releasing case arguments under a copyleft license, in order to encourage public suggestions for improvement.
Berkman lawyers specialise in cyberlaw—hacking, copyright, encryption and so on—and the centre has strong ties with the EFF and the open source software community.
In 1998 faculty member Lawrence Lessig, now at Stanford Law School, was asked by online publisher Eldritch Press to mount a legal challenge to US copyright law. Eldritch takes books whose copyright has expired and publishes them on the Web,
but legislation called the Sonny Bono Copyright Term Extension Act extended copyright from 50 to 70 years after the author's death, cutting off its supply of new material.
Lessig invited law students at Harvard and elsewhere to help craft legal arguments challenging the new law on an online forum, which evolved into Open Law.
Normal law firms write arguments the way commercial software companies write code. Lawyers discuss a case behind closed doors, and although their final product is released in court, the discussions or "source code" that produced it remain secret. In contrast, Open Law crafts its arguments in public and releases them under a copyleft. "We deliberately used free software as a model," said Wendy Seltzer, who took over Open Law when Lessig moved to Stanford. Around 50 legal scholars worked on Eldritch's case, and Open Law has taken other cases, too.
"The gains are much the same as for software," Seltzer says. "Hundreds of people scrutinise the 'code' for bugs, and make suggestions how to fix it. And people will take underdeveloped parts of the argument, work on them, then patch them in." Armed with arguments crafted in this way, OpenLaw took Eldritch's case—deemed unwinnable at the outset—right through the system to the Supreme Court. The case, Eldred v. Ashcroft, lost in 2003.
Among the drawbacks to this approach: the arguments are made in public from the start, so OpenLaw can't spring a surprise in court. Nor can it take on cases where confidentiality is important. But where there's a strong public interest element, open sourcing has big advantages. Citizens' rights groups, for example, have taken parts of Open Law's legal arguments and used them elsewhere. "People use them on letters to Congress, or put them on flyers," Seltzer says.
Read further.
This modified article was originally written by New Scientist magazine (see http://www.newscientist.com/hottopics/copyleft/) and released under the copyleft license.

</doc>
<doc id="37167" url="https://en.wikipedia.org/wiki?curid=37167" title="Loris">
Loris

Loris is the common name for the strepsirrhine primates of the subfamily Lorinae (sometimes spelled Lorisinae) in the family Lorisidae. "Loris" is one genus in this subfamily and includes the slender lorises, while "Nycticebus" is the genus containing the slow lorises.
Lorises are nocturnal. They are found in tropical and woodland forests of India, Sri Lanka, and parts of southeast Asia. Loris locomotion is a slow and cautious climbing form of quadrupedalism. Some lorises are almost entirely insectivorous, while others also include fruits, gums, leaves, and slugs in their diet.
Female lorises practice infant parking, leaving their infants behind in nests. Before they do this, they bathe their young with allergenic saliva that is acquired by licking patches on the insides of their elbows, which produce a mild toxin that discourages most predators, though orangutans occasionally eat lorises.
Taxonomic classification.
The family Lorisidae is found within the infraorder Lemuriformes and superfamily Lorisoidea, along with the family Galagidae, the galagos. This infraorder is a sister taxon of Lemuriformes, the lemurs. Within Lorinae, there are ten species (and several more subspecies) of lorises across two genera:

</doc>
<doc id="37168" url="https://en.wikipedia.org/wiki?curid=37168" title="Friday the 13th">
Friday the 13th

Friday the 13th is considered an unlucky day in Western superstition. It occurs when the 13th day of the month in the Gregorian calendar falls on a Friday.
History.
The fear of the number 13 has been given a scientific name: "triskaidekaphobia"; and on analogy to this the fear of Friday the 13th is called "paraskevidekatriaphobia", from the Greek words "Paraskeví" (Παρασκευή, meaning "Friday"), and "dekatreís" (δεκατρείς, meaning "thirteen").
The superstition surrounding this day may have arisen in the Middle Ages, "originating from the story of Jesus' last supper and crucifixion" in which there were 13 individuals present in the Upper Room on the 13th of Nisan Maundy Thursday, the night before his death on Good Friday. While there is evidence of both Friday and the number 13 being considered unlucky, there is no record of the two items being referred to as especially unlucky in conjunction before the 19th century.
An early documented reference in English occurs in Henry Sutherland Edwards' 1869 biography of Gioachino Rossini, who died on a Friday 13th:
He was surrounded to the last by admiring friends; and if it be true that, like so many Italians, he regarded Fridays as an unlucky day and thirteen as an unlucky number, it is remarkable that on Friday 13th of November he passed away.
It is possible that the publication in 1907 of Thomas W. Lawson's popular novel "Friday, the Thirteenth", contributed to disseminating the superstition. In the novel, an unscrupulous broker takes advantage of the superstition to create a Wall Street panic on a Friday the 13th.
A suggested origin of the superstition—Friday, 13 October 1307, the date Philip IV of France arrested hundreds of the Knights Templar—may not have been put together until the 20th century. It is mentioned in the 1955 Maurice Druon historical novel "The Iron King" ("Le Roi de fer"), John J. Robinson's 1989 work "Born in Blood: The Lost Secrets of Freemasonry", Dan Brown's 2003 novel "The Da Vinci Code" and Steve Berry's "The Templar Legacy" (2006).
Tuesday the 13th in Hispanic and Greek culture.
In Spanish-speaking countries, instead of Friday, Tuesday the 13th ("martes trece") is considered a day of bad luck. The Greeks also consider Tuesday (and especially the 13th) an unlucky day. Tuesday is considered dominated by the influence of Ares, the god of war ("Mars" in Roman mythology). A connection can be seen in the Roman etymology of the name in some European languages ("Mardi" in French or "martes" in Spanish). The fall of Constantinople to the Fourth Crusade occurred on Tuesday, April 13, 1204, and the Fall of Constantinople to the Ottomans happened on Tuesday, 29 May 1453, events that strengthen the superstition about Tuesday. In addition, in Greek the name of the day is Triti ("Τρίτη") meaning literally the third (day of the week), adding weight to the superstition, since bad luck is said to "come in threes".
Friday the 17th in Italy.
In Italian popular culture, Friday the 17th (and not the 13th) is considered a day of bad luck. The origin of this belief could be traced in the writing of number 17, in Roman numerals: XVII. By shuffling the digits of the number one can easily get the word VIXI ("I have lived", implying death in the present), an omen of bad luck. In fact, in Italy, 13 is generally considered a lucky number. However, due to Americanization, young people consider Friday the 13th unlucky as well.
The 2000 parody film "Shriek If You Know What I Did Last Friday the Thirteenth" was released in Italy with the title "Shriek – Hai impegni per venerdì 17?" (""Shriek – Do You Have Something to Do on Friday the 17th?"").
Social impact.
According to the Stress Management Center and Phobia Institute in Asheville, North Carolina, an estimated 17 to 21 million people in the United States are affected by a fear of this day, making it the most feared day and date in history. Some people are so paralyzed by fear that they avoid their normal routines in doing business, taking flights or even getting out of bed. "It's been estimated that 800 or $900 million is lost in business on this day". Despite this, representatives for both Delta Air Lines and now-defunct Continental Airlines have stated that their airlines do not suffer from any noticeable drop in travel on those Fridays.
In Finland, a consortium of governmental and nongovernmental organizations led by the Ministry of Social Affairs and Health promotes the National Accident Day, which always falls on a Friday the 13th.
Rate of accidents.
A study in the "British Medical Journal", published in 1993, concluded that there "is a significant level of traffic-related incidences on Friday the 13th as opposed to a random day, such as Friday the 6th, in the UK." However, the Dutch Centre for Insurance Statistics (CVS) on 12 June 2008 stated that "fewer accidents and reports of fire and theft occur when the 13th of the month falls on a Friday than on other Fridays, because people are preventatively more careful or just stay home. Statistically speaking, driving is slightly safer on Friday the 13th, at least in the Netherlands; in the last two years, Dutch insurers received reports of an average 7,800 traffic accidents each Friday; but the average figure when the 13th fell on a Friday was just 7,500."
Occurrence.
The following months have a Friday the 13th:
This sequence, given here for 1900–2099, follows a 28-year cycle from 1 March 1900 to 28 February 2100. The months with a Friday the 13th are determined by the Dominical letter (G, F, GF, etc.) of the year. Any month that starts on a Sunday contains a Friday the 13th, and there is at least one Friday the 13th in every calendar year. There can be as many as three Friday the 13ths in a single calendar year; either in February, March and November in a common year starting on Thursday (such as 2009, 2015 or 2026) (D), or January, April and July in a leap year starting on Sunday (such as 2012) (AG).
The longest period that can occur without a Friday the 13th is fourteen months, either from July to September the following year being a common year starting on Tuesday (e.g., between 2001–02, 2012–13, and 2018–19), or from August to October the following year being a leap year starting on Saturday (e.g., between 1999–2000 or 2027–28).
Each Gregorian 400-year cycle contains 146,097 days (365 × 400 = 146,000 normal days, plus 97 leap days). 146,097 days ÷ 7 days per week = 20,871 weeks. Thus, each cycle contains the same pattern of days of the week (and thus the same pattern of Fridays that are on the 13th). The 13th day of the month is slightly more likely to be a Friday than any other day of the week. On average, there is a Friday the 13th once every 212.35 days (compared to Thursday the 13th, which occurs only once every 213.59 days).
The distribution of the 13th day over the 4,800 months is as follows:

</doc>
<doc id="37170" url="https://en.wikipedia.org/wiki?curid=37170" title="Red slender loris">
Red slender loris

The red slender loris ("Loris tardigradus") is a small, nocturnal strepsirrhine primate native to the rainforests of Sri Lanka. This is #6 of the 10 focal species and #22 of the 100 EDGE mammal species worldwide considered the most evolutionarily distinct and globally endangered. Two subspecies have been identified, "L. t. tardigradus" and "L. t. nycticeboides".
Taxonomy.
The ears are less prominent in "L. tardigradus tardigradus" compared to "Loris lydekkerianus". The ears of "L. tardigradus nycticeboides" are almost invisible.
Description.
This small, slender primate is distinguished by large forward-facing eyes used for precise depth perception, long slender limbs, a well-developed index finger, the absence of tail, and large prominent ears, which are thin, rounded and hairless at the edges. The soft dense fur is reddish-brown color on the back, and the underside is whitish-grey with a sprinkling of silver hair. Its body length on average is , with an average weight of a mere . This loris has a four-way grip on each foot. The big toe opposes the other 4 toes for a pincer-like grip on branches and food. It has a dark face mask with central pale stripe, much like the slow lorises.
"L. tardigradus tardigradus" is reddish brown in the back and creamy yellow below, while "L. tardigradus nycticeboides" is dark brown dorsally and very light brown in upperparts.
Behavior.
The red slender loris favors lowland rainforests (up to 700 m in altitude), tropical rainforests and inter-monsoon forests of the south western wet-zone of Sri Lanka. Masmullah Proposed Forest Reserve harbors one of few remaining red slender loris populations, and is considered a biodiversity hotspot. The most common plant species eaten was "Humboldtia laurifolia", occurring at 676 trees/ha, with overall density at 1077 trees/ha. "Humboldtia laurifolia" is vulnerable and has a mutualistic relationship with ants, providing abundant food for lorises. Reports from the 1960s suggest that it once also occurred in the coastal zone, however it is now thought to be extinct there.
The red slender loris differ from its close relative the gray slender loris in its frequent use of rapid arboreal locomotion. It forms small social groups, containing adults of both sexes as well as young animals. This species is among the most social of the nocturnal primates. During daylight hours the animals sleep in groups in branch tangles, or curled up on a branch with their heads between their legs. The groups also undertake mutual grooming and play at wrestling. The adults typically hunt separately during the night. They are primarily insectivorous but also eat bird eggs, berries, leaves, buds and occasionally invertebrates as well as geckos and lizards. To maximize protein and nutrient uptake they consume every part of their prey, including the scales and bones. They make nests out of leaves or find hollows of trees or a similar secure place to live in.
Reproduction.
Females are dominant. The female reaches her sexual maturity at 10 months and is receptive to the male twice a year. This species mates while hanging upside down from branches; individuals in captivity will not breed if no suitable branch is available. The gestation period is 166–169 days after which the female will bear 1–2 young which feed from her for 6–7 months. The lifespan of this species is believed to be around 15–18 years in the wild.
Threats.
This slender loris is an endangered species. Habitat destruction is a major threat. It is widely trapped and killed for use in supposed remedies for eye diseases and get killed by snakes, dogs, and some fish. Other threats include: electrocution on live wires, road accidents and the pet trade.
Conservation.
The red slender loris was identified as one of the top-10 "focal species" in 2007 by the Evolutionarily Distinct and Globally Endangered (EDGE) project.
One early success has been the rediscovery of the virtually unknown Horton Plains slender loris ("Loris tardigradus nycticeboides"). Originally documented in 1937, there have only been four known encounters in the past 72 years, and for more than 60 years until 2002 the sub-species had been believed to be extinct. The sub-species was rediscovered in 2002 by a team led by Anna Nekaris in Horton Plains National Park. The late 2009 capture by a team working under the Zoological Society of London's EDGE programme has resulted in the first detailed physical examination of the Horton Plains sub-species and the first-ever photographs of it. The limited available evidence suggests there may be only about 100 animals still existing, which would make it among the top five most-threatened primates worldwide.

</doc>
<doc id="37171" url="https://en.wikipedia.org/wiki?curid=37171" title="Cray-1">
Cray-1

The Cray-1 was a supercomputer designed, manufactured and marketed by Cray Research. The first Cray-1 system was installed at Los Alamos National Laboratory in 1976 and it went on to become one of the best known and most successful supercomputers in history. The Cray-1's architect was Seymour Cray; the chief engineer was Cray Research co-founder Lester Davis.
History.
In the years 1968 to 1972, Cray was working at Control Data Corporation (CDC) on a new machine known as the CDC 8600, the logical successor to his earlier CDC 6600 and CDC 7600 designs. The 8600 was essentially made up of four 7600s in a box with an additional special mode that allowed them to operate lock-step in a SIMD fashion.
Jim Thornton, formerly Cray's engineering partner on earlier designs, had started a more radical project known as the CDC STAR-100. Unlike the 8600's brute-force approach to performance, the STAR took an entirely different route. In fact the main processor of the STAR had less performance than the 7600, but added additional hardware and instructions to speed up particularly common supercomputer tasks.
By 1972, the 8600 had reached a dead end — the machine was so incredibly complex that it was impossible to get one working properly. Even a single faulty component would render the machine non-operational. Cray went to William Norris, Control Data's CEO, saying that a redesign from scratch was needed. At the time the company was in serious financial trouble, and with the STAR in the pipeline as well, Norris simply could not invest the money.
As a result, Cray left CDC and started a new company HQ only yards from the CDC lab. In the back yard of the land he purchased in Chippewa Falls he and a group of former CDC employees started looking for ideas. At first the concept of building another supercomputer seemed impossible, but after Cray's Chief Technology Officer traveled to Wall Street and found a lineup of investors more than willing to back Cray, all that was needed was a design.
For four years Cray designed its first computer. In 1975 the 80 MHz Cray-1 was announced. Excitement was so high that a bidding war for the first machine broke out between Lawrence Livermore National Laboratory and Los Alamos National Laboratory, the latter eventually winning and receiving serial number 001 in 1976 for a six-month trial. The National Center for Atmospheric Research (NCAR) was first official customer of Cray Research in 1977, paying US$8.86 million ($7.9 million plus $1 million for the disks) for serial number 3. The NCAR machine was decommissioned in 1989. The company expected to sell perhaps a dozen of the machines, and set the selling price accordingly, but ultimately over eighty Cray-1s of all types were sold, priced from $5M to $8M. The machine made Cray a celebrity and the company a success, lasting until the supercomputer crash in the early 1990s.
The 80 MFLOPS Cray-1 was succeeded in 1982 by the 800 MFLOPS Cray X-MP, the first Cray multi-processing computer. In 1985 the very advanced Cray-2, capable of 1.9 GFLOPS peak performance, succeeded the first two models but met a somewhat limited commercial success because of certain problems at producing sustained performance in real-world applications. A more conservatively designed evolutionary successor of the Cray-1 and X-MP models was therefore made by the name Cray Y-MP and launched in 1988.
As a comparison standpoint, the processor in a typical 2013 smartphone performs at roughly 1 GFLOPS.
Background.
Typical scientific workloads consist of reading in large data sets, transforming them in some way and then writing them back out again. Normally the transformations being applied are identical across all of the data points in the set. For instance, the program might add 5 to every number in a set of a million numbers.
In traditional computers the program would loop over all million numbers, adding five, thereby executing a million instructions saying codice_1. Internally the computer solves this instruction in several steps. First it reads the instruction from memory and decodes it, then it collects any additional information it needs, in this case the numbers b and c, and then finally runs the operation and stores the results. The end result is that the computer requires tens or hundreds of millions of cycles to carry out these operations.
Vector machines.
In the STAR, new instructions essentially wrote the loops for the user. The user told the machine where in memory the list of numbers was stored, then fed in a single instruction codice_2. At first glance it appears the savings are limited; in this case the machine fetches and decodes only a single instruction instead of 1,000,000, thereby saving 1,000,000 fetches and decodes, perhaps one-fourth of the overall time.
The real savings are not so obvious. Internally, the CPU of the computer is built up from a number of separate parts dedicated to a single task, for instance, adding a number, or fetching from memory. Normally, as the instruction flows through the machine, only one part is active at any given time. This means that each sequential step of the entire process must complete before a result can be saved. The addition of an instruction pipeline changes this. In such machines the CPU will "look ahead" and begin fetching succeeding instructions while the current instruction is still being processed. In this assembly line fashion any one instruction still requires as long to complete, but as soon as it finishes executing, the next instruction is right behind it, with most of the steps required for its execution already completed.
Vector processors use this technique with one additional trick. Because the data layout is in a known format — a set of numbers arranged sequentially in memory — the pipelines can be tuned to improve the performance of fetches. On the receipt of a vector instruction, special hardware sets up the memory access for the arrays and stuffs the data into the processor as fast as possible.
CDC's approach in the STAR used what is today known as a "memory-memory architecture". This referred to the way the machine gathered data. It set up its pipeline to read from and write to memory directly. This allowed the STAR to use vectors of any length, making it highly flexible. Unfortunately, the pipeline had to be very long in order to allow it to have enough instructions in flight to make up for the slow memory. That meant the machine incurred a high cost when switching from processing vectors to performing operations on individual randomly located operands. Additionally, the low scalar performance of the machine meant that after the switch had taken place and the machine was running scalar instructions, the performance was quite poor. The result was rather disappointing real-world performance, something that could, perhaps, have been forecast by Amdahl's law.
Cray's approach.
Cray was able to look at the failure of the STAR and learn from it. He decided that in addition to fast vector processing, his design would also require excellent all-around scalar performance as well. That way when the machine switched modes, it would still provide superior performance. Additionally they noticed that the workloads could be dramatically improved in most cases through the use of registers.
Just as earlier machines had ignored the fact that most operations were being applied to many data points, the STAR ignored the fact that those same data points would be repeatedly operated on. Whereas the STAR would read and process the same memory five times to apply five vector operations on a set of data, it would be much faster to read the data into the CPU's registers once, and then apply the five operations. However, there were limitations with this approach. Registers were significantly more expensive in terms of circuitry, so only a limited number could be provided. This implied that Cray's design would have less flexibility in terms of vector sizes. Instead of reading any sized vector several times as in the STAR, the Cray-1 would have to read only a portion of the vector at a time, but it could then run several operations on that data prior to writing the results back to memory. Given typical workloads, Cray felt that the small cost incurred by being required to break large sequential memory accesses into segments was a cost well worth paying.
Since the typical vector operation would involve loading a small set of data into the vector registers and then running several operations on it, the vector system of the new design had its own separate pipeline. For instance, the multiplication and addition units were implemented as separate hardware, so the results of one could be internally pipelined into the next, the instruction decode having already been handled in the machine's main pipeline. Cray referred to this concept as "chaining", as it allowed programmers to "chain together" several instructions and extract higher performance.
Description.
The new machine was the first Cray design to use integrated circuits (ICs). Although ICs had been available since the 1960s, it was only in the early 1970s that they reached the performance necessary for high-speed applications. The Cray-1 used only four different IC types, an ECL dual 5-4 NOR gate (one 5-input, and one 4-input, each with differential output), another slower MECL 10K 5-4 NOR gate used for address fanout, a 16×4-bit high speed (6 ns) static RAM (SRAM) used for registers and a 1,024×1-bit 48 ns SRAM used for the main memory. These integrated circuits were supplied by Fairchild Semiconductor and Motorola. In all, the Cray-1 contained about 200,000 gates.
ICs were mounted on large five-layer printed circuit boards, with up to 144 ICs per board. Boards were then mounted back to back for cooling (see below) and placed in twenty-four racks containing 72 double-boards. The typical module (distinct processing unit) required one or two boards. In all the machine contained 1,662 modules in 113 varieties.
Each cable between the modules was a twisted pair, cut to a specific length in order to guarantee the signals arrived at precisely the right time and minimize electrical reflection. Each signal produced by the ECL circuitry was a differential pair, so the signals were balanced. This tended to make the demand on the power supply more constant and reduce switching noise. The load on the power supply was so evenly balanced that Cray boasted that the power supply was unregulated. To the power supply, the entire computer system looked like a simple resistor.
The high-performance ECL circuitry generated considerable heat, and Cray's designers spent as much effort on the design of the refrigeration system as they did on the rest of the mechanical design. In this case, each circuit board was paired with a second, placed back to back with a sheet of copper between them. The copper sheet conducted heat to the edges of the cage, where liquid Freon running in stainless steel pipes drew it away to the cooling unit below the machine. The first Cray-1 was delayed six months due to problems in the cooling system; lubricant that is normally mixed with the Freon to keep the compressor running would leak through the seals and eventually coat the boards with oil until they shorted out. New welding techniques had to be used to properly seal the tubing. The only patents issued for the Cray-1 computer concerned the cooling system design.
In order to bring maximum speed out of the machine, the entire chassis was bent into a large C-shape. Speed-dependent portions of the system were placed on the "inside edge" of the chassis, where the wire-lengths were shorter. This allowed the cycle time to be decreased to 12.5 ns (80 MHz), not as fast as the 8 ns 8600 he had given up on, but fast enough to beat CDC 7600 and the STAR. NCAR estimated that the overall throughput on the system was 4.5 times the CDC 7600.
The Cray-1 was built as a 64-bit system, a departure from the 7600/6600, which were 60-bit machines (a change was also planned for the 8600). Addressing was 24-bit, with a maximum of 1,048,571 64-bit words (1 megaword) of main memory, where each word also had 8 parity bits for a total of 72 bits per word. There were 64 data bits and 8 check bits. Memory was spread across 16 interleaved memory banks, each with a 50 ns cycle time, allowing up to four words to be read per cycle. Smaller configurations could have 0.25 or 0.5 megawords of main memory.
The main register set consisted of eight 64-bit scalar (S) registers and eight 24-bit address (A) registers. These were backed by a set of sixty-four registers each for S and A temporary storage known as T and B respectively, which could not be seen by the functional units. The vector system added another eight 64-element by 64-bit vector (V) registers, as well as a vector length (VL) and vector mask (VM). Finally, the system also included a 64-bit real-time clock register and four 64-bit instruction buffers that held sixty-four 16-bit instructions each. The hardware was set up to allow the vector registers to be fed at one word per cycle, while the address and scalar registers required two cycles. In contrast, the entire 16-word instruction buffer could be filled in four cycles.
The Cray-1 had twelve pipelined functional units. The 24-bit address arithmetic was performed in an add unit and a multiply unit. The scalar portion of the system consisted of an add unit, a logical unit, a population count, a leading zero count unit and a shift unit. The vector portion consisted of add, logical and shift units. The floating point functional units were shared between the scalar and vector portions, and these consisted of add, multiply and reciprocal approximation units.
The system had limited parallelism. It could fetch one instruction per clock cycle, operate on multiple instructions in parallel and retire up to two every cycle. Its theoretical performance was thus 160 MIPS (80 MHz x 2 instructions), although there were a few limitations that made floating point performance generally about 160 MFLOPS. However, by using vector instructions carefully and building useful chains, the system could peak at 250 MFLOPS.
Since the machine was designed to operate on large data sets, the design also dedicated considerable circuitry to I/O. Earlier Cray designs at CDC had included separate computers dedicated to this task, but this was no longer needed. Instead the Cray-1 included four 6-channel controllers, each of which was given access to main memory once every four cycles. The channels were 16 bits wide and included 3 control bits and 4 for error correction, so the maximum transfer speed was 1 word per 100 ns, or 500 thousand words per second for the entire machine.
The initial model, the Cray-1A, weighed 5.5 tons including the Freon refrigeration system. Configured with 1 million words of main memory, the machine and its power supplies consumed about 115 kW of power; cooling and storage likely more than doubled this figure. A Data General SuperNova S/200 minicomputer served as the maintenance control unit (MCU), which was used to feed the Cray Operating System into the system at boot time, to monitor the CPU during use, and optionally as a front-end computer. Most, if not all Cray-1As were delivered using the follow-on Data General Eclipse as the MCU.
Cray-1S.
The Cray-1S, announced in 1979, was an improved Cray-1 that supported a larger main memory of 1, 2 or 4 million words. The larger main memory was made possible through the use of 4,096 x 1-bit bipolar RAM ICs with a 25 ns access time. The Data General minicomputers were optionally replaced with an in-house 16-bit design running at 80 MIPS. The I/O subsystem was separated from the main machine, connected to the main system via a 6 MB/s control channel and a 100 MB/s High Speed Data Channel. This separation made the 1S look like two "half Crays" separated by a few feet, which allowed the I/O system to be expanded as needed. Systems could be bought in a variety of configurations from the S/500 with no I/O and 0.5 million words of memory to the S/4400 with four I/O processors and 4 million words of memory.
Cray-1M.
The Cray-1M, announced in 1982, replaced the Cray-1S. It had a faster 12 ns cycle time and used less expensive MOS RAM in the main memory. The 1M was supplied in only three versions, the M/1200 with 1 million words in 8 banks, or the M/2200 and M/4200 with 2 or 4 million words in 16 banks. All of these machines included two, three or four I/O processors, and the system added an optional second High Speed Data Channel. Users could add a Solid-state Storage Device with 8 to 32 million words of MOS RAM.
Software.
In 1978 the first standard software package for the Cray-1 was released, consisting of three main products:
The United States Department of Energy funded sites from Lawrence Livermore Laboratory, Los Alamos Scientific Laboratory, Sandia National Laboratory and the National Science Foundation supercomputer centers (for high-energy physics) represented the second largest block with LLL's Cray Time Sharing System (CTSS). CTSS was written in a dynamic memory Fortran, first named LRLTRAN, which ran on CDC 7600s, renamed CVC (pronounced "Civic") when vectorization for the Cray-1 was added. Cray Research attempted to support these sites accordingly. These software choices had influences on later minisupercomputers, also known as "crayettes".
NCAR has its own operating system (NCAROS).
The National Security Agency developed its own operating system (Folklore) and language (IMP with ports of Cray Pascal and C and Fortran 90 later)
Libraries started with Cray Research's own offerings and Netlib.
Other operating systems existed, but most languages tended to be Fortran or Fortran-based. Bell Laboratories, as proof of both portability concept and circuit design, moved the first C compiler to their Cray-1 (non-vectorizing). This act would later give CRI a six-month head start on the Cray-2 Unix port to ETA Systems' detriment, and Lucasfilm's first computer generated test film, "The Adventures of André and Wally B.".
Application software generally tends to be either classified ("e.g." nuclear code, cryptanalytic code) or proprietary ("e.g." petroleum reservoir modeling). This was because little software was shared between customers and university customers. The few exceptions were climatological and meteorological programs until the NSF responded to the Japanese Fifth Generation Computer Systems project and created its supercomputer centers. Even then, little code was shared.
Museums.
Cray-1s are on display at the following locations:

</doc>
<doc id="37175" url="https://en.wikipedia.org/wiki?curid=37175" title="Lars Onsager">
Lars Onsager

Lars Onsager (November 27, 1903 – October 5, 1976) was a Norwegian-born American physical chemist and theoretical physicist. He held the Gibbs Professorship of Theoretical Chemistry at Yale University. He was awarded the Nobel Prize in Chemistry in 1968.
Education and early life.
Lars Onsager was born in Kristiania (today's Oslo), Norway. His father was a lawyer. After completing secondary school in Oslo, he attended the Norwegian Institute of Technology (NTH) in Trondheim, graduating as a chemical engineer in 1925. 
Career and research.
In 1925 he arrived at a correction to the Debye-Hückel theory of electrolytic solutions, to specify Brownian movement of ions in solution, and during 1926 published it. He traveled to Zürich, where Peter Debye was teaching, and confronted Debye, telling him his theory was wrong. He impressed Debye so much that he was invited to become Debye's assistant at the Eidgenössische Technische Hochschule (ETH), where he remained until 1928.
Johns Hopkins University.
Eventually in 1928 he went to the United States to take a faculty position at the Johns Hopkins University in Baltimore, Maryland. At JHU he had to teach freshman classes in chemistry, and it quickly became apparent that, while he was a genius at developing theories in physical chemistry, he had little talent for teaching. He was dismissed by JHU after one semester.
Brown University.
On leaving JHU, he accepted a position (involving the teaching of statistical mechanics to graduate students in chemistry) at Brown University in Providence, Rhode Island, where it became clear that he was no better at teaching advanced students than freshmen, but he made significant contributions to statistical mechanics and thermodynamics. The only graduate student who could really understand his lectures on electrolyte systems, Raymond Fuoss, worked under him and eventually joined him on the Yale chemistry faculty. In 1933, when the Great Depression limited Brown's ability to support a faculty member who was only useful as a researcher and not a teacher, he was let go by Brown, being hired after a trip to Europe by Yale University, where he remained for most of the rest of his life, retiring in 1972.
His research at Brown was concerned mainly with the effects on diffusion of temperature gradients, and produced the Onsager reciprocal relations, a set of equations published in 1929 and, in an expanded form, in 1931, in statistical mechanics whose importance went unrecognized for many years. However, their value became apparent during the decades following World War II, and by 1968 they were considered important enough to gain Onsager that year's Nobel Prize in Chemistry. In 1933, just before taking up the position at Yale, Onsager traveled to Austria to visit electrochemist Hans Falkenhagen. He met Falkenhagen's sister-in-law, Margrethe Arledter. They were married on September 7, 1933, and had three sons and a daughter.
Yale University.
At Yale, an embarrassing situation occurred: he had been hired as a postdoctoral fellow, but it was discovered that he had never received a Ph.D. While he had submitted an outline of his work in reciprocal relations to the Norwegian Institute of Technology, they had decided it was too incomplete to qualify as a doctoral dissertation. He was told that he could submit one of his published papers to the Yale faculty as a dissertation, but insisted on doing a new research project instead. His dissertation, entitled, "Solutions of the Mathieu equation of period 4 pi and certain related functions", was beyond the comprehension of the chemistry and physics faculty, and only when some members of the mathematics department, including the chairman, insisted that the work was good enough that "they" would grant the doctorate if the chemistry department would not, was he granted a Ph.D. in chemistry in 1935. Even before the dissertation was finished, he was appointed assistant professor in 1934, and promoted to associate professor in 1940. He quickly showed at Yale the same traits he had at JHU and Brown: he produced brilliant theoretical research, but was incapable of giving a lecture at a level that a student (even a graduate student) could comprehend. He was also unable to direct the research of graduate students, except for the occasional outstanding one.
During the late 1930s, Onsager researched the dipole theory of dielectrics, making improvements for another topic that had been studied by Peter Debye. However, when he submitted his paper to a journal that Debye edited in 1936, it was rejected. Debye would not accept Onsager's ideas until after World War II. During the 1940s, Onsager studied the statistical-mechanical theory of phase transitions in solids, deriving a mathematically elegant theory which was enthusiastically received. He obtained the exact solution for the two dimensional Ising model in zero field in 1944.
In 1935 he was awarded an honorary degree, doctor techn. honoris causa, at the Norwegian Institute of Technology, later part of Norwegian University of Science and Technology.
In 1945, Onsager was naturalized as an American citizen, and the same year he was awarded the title of "J. Willard Gibbs Professor of Theoretical Chemistry". This was particularly appropriate because Onsager, like Willard Gibbs, had been involved primarily in the application of mathematics to problems in physics and chemistry and, in a sense, could be considered to be continuing in the same areas Gibbs had pioneered.
In 1947, he was elected to the National Academy of Sciences, and in 1950 he joined the ranks of Alpha Chi Sigma.
After World War II, Onsager researched new topics of interest. 
He proposed a theoretical explanation of the superfluid properties of liquid helium in 1949; two years later the physicist Richard Feynman independently proposed the same theory. He also worked on the theories of liquid crystals and the electrical properties of ice. While on a Fulbright scholarship to the University of Cambridge, he worked on the magnetic properties of metals. He developed important ideas on the quantization of magnetic flux in metals. He was awarded the Lorentz Medal in 1958, Willard Gibbs Award in 1962, and the Nobel Prize in Chemistry in 1968. He was elected a Foreign Member of the Royal Society (ForMemRS) in 1975.
After Yale.
In 1972 Onsager retired from Yale and became emeritus. He then became a member of the Center for Theoretical Studies, University of Miami, and was appointed Distinguished University Professor of Physics. At the University of Miami he remained active in guiding and inspiring postdoctoral students as his teaching skills, although not his lecturing skills, had improved during the course of his career. He developed interests in semiconductor physics, biophysics and radiation chemistry. However, his death came before he could produce any breakthroughs comparable to those of his earlier years.
Personal life.
He remained in Florida until his death from an aneurysm in Coral Gables, Florida in 1976. Onsager was buried next to John Gamble Kirkwood at New Haven's Grove Street Cemetery. While Kirkwood's tombstone has a long list of awards and positions, including the American Chemical Society Award in Pure Chemistry, the Richards Medal, and the Lewis Award, Onsager's tombstone, in its original form, simply said "Nobel Laureate". When Onsager's wife Gretel died in 1991 and was buried there, his children added an asterisk after "Nobel Laureate," and "*etc." in the lower right corner of the stone.
Legacy.
The Norwegian Institute of Technology established the Lars Onsager Lecture and The Lars Onsager Professorship in 1993 to award outstanding scientists in the scientific fields of Lars Onsager; Chemistry, Physics and Mathematics. In 1997 his sons and daughter donated his scientific works and professional belongings to NTNU (before 1996 NTH) in Trondheim, Norway as his Alma Mater. These are now organized as "The Lars Onsager Archive" at the Gunnerus Library in Trondheim.

</doc>
<doc id="37183" url="https://en.wikipedia.org/wiki?curid=37183" title="Novikov self-consistency principle">
Novikov self-consistency principle

The Novikov self-consistency principle, also known as the Novikov self-consistency conjecture, is a principle developed by Russian physicist Igor Dmitriyevich Novikov in the mid-1980s to solve the problem of paradoxes in time travel, which is theoretically possible in certain solutions of general relativity that contain what are known as closed timelike curves. The principle asserts that if an event exists that would give rise to a paradox, or to any "change" to the past whatsoever, then the probability of that event is zero. It would thus be impossible to create time paradoxes.
History of the principle.
Physicists have long been aware that some solutions to the theory of general relativity contain closed timelike curves, or C.T.C.s—see for example the Gödel metric. Novikov discussed the possibility of C.T.C.s in books written in 1975 and 1983, offering the opinion that only self-consistent trips back in time would be permitted. In a 1990 paper by Novikov and several others, "Cauchy problem in spacetimes with closed timelike curves", the authors state:
Among the coauthors of this 1990 paper were Kip Thorne, Mike Morris, and Ulvi Yurtsever, who in 1988 had stirred up renewed interest in the subject of time travel in general relativity with their paper "Wormholes, Time Machines, and the Weak Energy Condition", which showed that a new general relativity solution known as a traversable wormhole could lead to closed timelike curves, and unlike previous CTC-containing solutions it did not require unrealistic conditions for the universe as a whole. After discussions with another coauthor of the 1990 paper, John Friedman, they convinced themselves that time travel need not lead to unresolvable paradoxes, regardless of what type of object was sent through the wormhole.
In response, another physicist named Joseph Polchinski sent them a letter that argued that one could avoid questions of free will by considering a potentially paradoxical situation involving a billiard ball sent through a wormhole that sends it back in time. In this scenario, the ball is fired into a wormhole at an angle such that, if it continues along that path, it will exit the wormhole in the past at just the right angle to collide with its earlier self, thereby knocking it off course and preventing it from entering the wormhole in the first place. Thorne deemed this problem "Polchinski's paradox".
After considering the problem, two students at Caltech (where Thorne taught), Fernando Echeverria and Gunnar Klinkhammer, were able to find a solution beginning with the original billiard ball trajectory proposed by Polchinski that managed to avoid any inconsistencies. In this situation, the billiard ball emerges from the future at a different angle than the one that generates the paradox, and delivers its younger self a glancing blow instead of knocking it completely away from the wormhole, a blow that changes its trajectory in just the right way so that it will travel back in time with the angle required to deliver its younger self this glancing blow. Echeverria and Klinkhammer actually found that there was more than one self-consistent solution, with slightly different angles for the glancing blow in each case. Later analysis by Thorne and Robert Forward showed that for certain initial trajectories of the billiard ball, there could actually be an infinite number of self-consistent solutions.
Echeverria, Klinkhammer and Thorne published a paper discussing these results in 1991; in addition, they reported that they had tried to see if they could find "any" initial conditions for the billiard ball for which there were no self-consistent extensions, but were unable to do so. Thus it is plausible that there exist self-consistent extensions for every possible initial trajectory, although this has not been proven. This only applies to initial conditions outside of the chronology-violating region of spacetime, which is bounded by a Cauchy horizon. This could mean that the Novikov self-consistency principle does not actually place any constraints on systems outside of the region of space-time where time travel is possible, only inside it.
Even if self-consistent extensions can be found for arbitrary initial conditions outside the Cauchy Horizon, the finding that there can be multiple distinct self-consistent extensions for the same initial condition—indeed, Echeverria et al. found an infinite number of consistent extensions for every initial trajectory they analyzed—can be seen as problematic, since classically there seems to be no way to decide which extension the laws of physics will choose. To get around this difficulty, Thorne and Klinkhammer analyzed the billiard ball scenario using quantum mechanics, performing a quantum-mechanical sum over histories (path integral) using only the consistent extensions, and found that this resulted in a well-defined probability for each consistent extension. The authors of "Cauchy problem in spacetimes with closed timelike curves" write:
Assumptions of the Novikov self-consistency principle.
The Novikov consistency principle assumes certain conditions about what sort of time travel is possible. Specifically, it assumes either that there is only one timeline, or that any alternative timelines (such as those postulated by the many-worlds interpretation of quantum mechanics) are not accessible.
Given these assumptions, the constraint that time travel must not lead to inconsistent outcomes could be seen merely as a tautology, a self-evident truth that can not possibly be false, because if you make the assumption that it is false this would lead to a logical paradox. However, the Novikov self-consistency principle is intended to go beyond just the statement that history must be consistent, making the additional nontrivial assumption that the universe obeys the same local laws of physics in situations involving time travel that it does in regions of space-time that lack closed timelike curves. This is clarified in the above-mentioned "Cauchy problem in spacetimes with closed timelike curves", where the authors write:
Implications for time travelers.
The assumptions of the self-consistency principle can be extended to hypothetical scenarios involving intelligent time travelers as well as unintelligent objects such as billiard balls. The authors of "Cauchy problem in spacetimes with closed timelike curves" commented on the issue in the paper's conclusion, writing:
Similarly, physicist and astronomer J. Craig Wheeler concludes that:
Time-loop logic.
"Time-loop logic", coined by the roboticist and futurist Hans Moravec, is the name of a hypothetical system of computation that exploits the Novikov self-consistency principle to compute answers much faster than possible with the standard model of computational complexity using Turing machines. In this system, a computer sends a result of a computation backwards through time and relies upon the self-consistency principle to force the sent result to be correct, providing the machine can reliably receive information from the future and providing the algorithm and the underlying mechanism are formally correct. An incorrect result or no result can still be produced if the time travel mechanism or algorithm are not guaranteed to be accurate.
A simple example is an iterative method algorithm. Moravec states:
Physicist David Deutsch showed in 1991 that this model of computation could solve NP problems in polynomial time, and Scott Aaronson later extended this result to show that the model could also be used to solve PSPACE problems in polynomial time.
Scientific acceptance.
Novikov's views are not widely accepted. Visser views causal loops and Novikov's self-consistency principle as an ad hoc solution, and supposes that there are far more damaging implications of time travel. Krasnikov similarly finds no inherent fault in causal loops, but finds other problems with time travel in general relativity.

</doc>
<doc id="37184" url="https://en.wikipedia.org/wiki?curid=37184" title="Colossus">
Colossus

Colossus, Colossos, or Colossi may refer to:

</doc>
<doc id="37185" url="https://en.wikipedia.org/wiki?curid=37185" title="Pope Leo VIII">
Pope Leo VIII

Pope Leo VIII (died 1 March 965) was Pope from 23 June 964 to his death in 965; before that, he was an antipope from 963 to 964, in opposition to Pope John XII and Pope Benedict V. An appointee of the Holy Roman Emperor, Otto I, his pontificate occurred during the period known as the Saeculum obscurum.
Biography.
Born in Rome in the region around the "Clivus Argentarius", Leo was the son of John who held the office of Protonotary, and a member of an illustrious noble family. Although a layperson, he was the "protoscriniarius" (or superintendent of the Roman public schools for scribes) in the papal court during the pontificate of John XII. In 963 he was included in a party that was sent by John to the Holy Roman Emperor, Otto I, who was besieging the King of Italy, Berengar II at the castle of St. Leo in Umbria. His instructions were to reassure the emperor that the pope was determined to correct the abuses of the papal court, as well as protesting about Otto’s actions in demanding that cities in the Papal States take an oath of fidelity to the emperor instead of the pope.
By the time Otto entered Rome to depose John, Leo had been appointed Protonotary to the Apostolic See. A synod convened by the emperor uncanonically deposed John (who had fled to Tibur) and proceeded to elect Leo, who was the emperor’s nominee, as pope on 4 December 963, although as he was still a layman such an election was also invalid. In the space of a day Leo was ordained Ostiarius, Lector, Acolyte, Subdeacon, Deacon and Priest by Sico, the cardinal-bishop of Ostia, who then proceeded to consecrate him as Bishop of Rome on 6 December 963. The deposed John however still had a large body of sympathisers within Rome; he offered large bribes to the Roman nobility if they would rise up and overthrow Otto and kill Leo, and so in early January 964, the Roman people staged an uprising that was quickly put down by Otto’s troops. Leo, hoping to reach out to the Roman nobility, persuaded Otto to release the hostages he had taken from the leading Roman families in exchange for their continued good behaviour. However, once Otto left Rome in around 12 January 964, the Romans again rebelled, and caused Leo to flee Rome and take refuge with Otto sometime in February 964.
John XII returned and in February convened a synod which in turn deposed Leo on 26 February 964, with John excommunicating Leo in the process. Leo remained with Otto, and with the death of John XII in May 964, the Romans elected Pope Benedict V. Otto proceeded to besiege Rome, taking Leo with him, and when the Romans eventually surrendered to Otto, Leo was reinstalled in the Lateran Palace as pope.
Together with Benedict’s clerical and lay supporters, and clad in his pontifical robes, the former Pope was then brought before Leo, who asked him how Benedict dared to assume the chair of Saint Peter while he was still alive. Benedict responded “If I have sinned, have mercy on me.” Having received a promise from the emperor that his life would be spared if he submitted, Benedict threw himself at Leo’s feet and acknowledged his guilt. Brought before a synod convened by Leo, Benedict’s ordination as Bishop was revoked, his pallium was torn from him, and his pastoral staff was broken over him by Leo. However, through the intercession of Otto, Benedict was allowed to retain the rank of deacon. Then, after having the Roman nobility swear an oath over the Tomb of Saint Peter to obey and be faithful to Leo, Otto departed Rome in late June 964.
Having been cowed by Otto, the remainder of Leo’s pontificate was reasonably trouble free. He issued numerous bulls, many of which detailed the granting of privileges to Otto and his successors. Some of the bulls were alleged to grant the German emperors the right of choosing their successors in the Kingdom of Italy, the right to nominate the Pope, and all popes, archbishops and bishops were to receive investiture from the emperor. In addition, Leo is also claimed to have relinquished to Otto all the territory of the Papal States that had been granted to the Apostolic See by Pepin the Short and Charlemagne. Although it is certain that Leo granted various concessions to his imperial patron, it is now believed that the “investiture” bulls associated with Leo were, if not completely fabricated during the Investiture Controversy, were at the very least so tampered with that it is now largely impossible to reconstruct them in their original form.
Leo VIII died on 1 March 965, and was succeeded by Pope John XIII. According to the Liber Pontificalis he was described as venerable, energetic and honourable. He had a number of streets dedicated to him in and around the "Clivus Argentarius", including the "descensus Leonis Prothi".
Status as pope.
Although Leo was for many years considered an antipope, his current status is still a source of confusion. The Annuario Pontificio makes the following point about the pontificate of Leo VIII:
”At this point, as again in the mid-eleventh century, we come across elections in which problems of harmonizing historical criteria and those of theology and canon law make it impossible to decide clearly which side possessed the legitimacy whose factual existence guarantees the unbroken lawful succession of the Successors of Saint Peter. The uncertainty that in some cases results has made it advisable to abandon the assignation of successive numbers in the list of the Popes.”
Due to Leo’s uncanonical election, it is now accepted that until the deposition of Benedict V, he was almost certainly an antipope. Further, although the deposition of John XII was invalid, the election of Benedict V certainly was canonical. However, if Liutprand of Cremona (who chronicled the events of this period) can be relied upon, if, as he wrote, Benedict did acquiesce to his deposition, and if as seems certain, no further protest was made against Leo's position, it has been the consensus of historians that he may be regarded as a true pope from July 964, to his death in 965. The fact that the next pope to assume the name Leo was consecrated Leo IX also seems to indicate that he is a true pope.

</doc>
<doc id="37186" url="https://en.wikipedia.org/wiki?curid=37186" title="Vagus nerve">
Vagus nerve

The vagus nerve ( ), historically cited as the pneumogastric nerve, is the tenth cranial nerve or CN X, and interfaces with parasympathetic control of the heart and digestive tract. The vagus nerves are paired; however, they are normally referred to in the singular. It is the longest nerve of the autonomic nervous system in the human body.
Structure.
Upon leaving the medulla oblongata between the pyramid and the inferior cerebellar peduncle, the vagus nerve extends through the jugular foramen, then passes into the carotid sheath between the internal carotid artery and the internal jugular vein down to the neck, chest and abdomen, where it contributes to the innervation of the viscera. Besides giving some output to various organs, the vagus nerve comprises between 80% and 90% of afferent nerves mostly conveying sensory information about the state of the body's organs to the central nervous system.
Right and left vagus nerves descend from the cranial vault through the jugular foramina, penetrating the carotid sheath between the internal and external carotid arteries, then passing posterolateral to the common carotid artery. The cell bodies of visceral afferent fibers of the vagus nerve are located bilaterally in the inferior ganglion of the vagus nerve (nodose ganglia).
The right vagus nerve gives rise to the right recurrent laryngeal nerve, which hooks around the right subclavian artery and ascends into the neck between the trachea and esophagus. The right vagus then crosses anterior to the right subclavian artery, runs posterior to the superior vena cava, descends posterior to the right main bronchus, and contributes to cardiac, pulmonary, and esophageal plexuses. It forms the posterior vagal trunk at the lower part of the esophagus and enters the diaphragm through the esophageal hiatus.
The left vagus nerve enters the thorax between left common carotid artery and left subclavian artery and descends on the aortic arch. It gives rise to the left recurrent laryngeal nerve, which hooks around the aortic arch to the left of the ligamentum arteriosum and ascends between the trachea and esophagus. The left vagus further gives off thoracic cardiac branches, breaks up into the pulmonary plexus, continues into the esophageal plexus, and enters the abdomen as the anterior vagal trunk in the esophageal hiatus of the diaphragm.
The vagus runs parallel to the common carotid artery and internal jugular vein inside the carotid sheath.
Nuclei.
The vagus nerve includes axons which emerge from or converge onto four nuclei of the medulla:
Development.
The motor division of the vagus nerve is derived from the basal plate of the embryonic medulla oblongata, while the sensory division originates from the cranial neural crest.
Function.
The vagus nerve supplies motor parasympathetic fibers to all the organs except the suprarenal (adrenal) glands, from the neck down to the second segment of the transverse colon. The vagus also controls a few skeletal muscles, notable ones being:
This means that the vagus nerve is responsible for such varied tasks as heart rate, gastrointestinal peristalsis, sweating, and quite a few muscle movements in the mouth, including speech (via the recurrent laryngeal nerve). It also has some afferent fibers that innervate the inner (canal) portion of the outer ear (via the auricular branch, also known as Alderman's nerve) and part of the meninges. This explains why a person may cough when tickled on the ear, such as when trying to remove ear wax with a cotton swab.
Afferent vagus nerve fibers innervating the pharynx and back of the throat are responsible for the gag reflex. In addition, 5-HT3 receptor-mediated afferent vagus stimulation in the gut due to gastroenteritis and other insults is a cause of vomiting.
The vagus nerve carries various types of axons. These include:
The vagus nerve and the heart.
Parasympathetic innervation of the heart is partially controlled by the vagus nerve and is shared by the thoracic ganglia. To be specific, vagal and spinal ganglionic nerves mediate the lowering of the heart rate. The right vagus branch innervates the sinoatrial node. Parasympathetic tone from these sources are obviously well matched to sympathetic tone in healthy people. Hyperstimulation of parasympathetic influence promotes bradyarrhythmias. When hyperstimulated, the left vagal branch predisposes the heart to conduction block at the atrioventricular node.
At this location, neuroscientist Otto Loewi first demonstrated that nerves secrete substances called neurotransmitters, which have effects on receptors in target tissues. In his experiment, Loewi electrically stimulated the vagus nerve of a frog heart, which slowed the heart. Then he took the fluid from the heart and transferred it to a second frog heart without a vagus nerve. The second heart slowed down without an electrical stimulation. Loewi described the substance released by the vagus nerve as vagusstoff, which was later found to be acetylcholine.
Drugs that inhibit the muscarinic receptors (anticholinergics) such as atropine and scopolamine, are called vagolytic because they inhibit the action of the vagus nerve on the heart, gastrointestinal tract, and other organs. Anticholinergic drugs increase heart rate and are used to treat bradycardia.
Physical and emotional effects.
Activation of the vagus nerve typically leads to a reduction in heart rate, blood pressure, or both. This occurs commonly in the setting of gastrointestinal illness such as viral gastroenteritis or acute cholecystitis, or in response to other stimuli, including carotid sinus massage, Valsalva maneuver or pain from any cause, in particular, having blood drawn. When the circulatory changes are great enough, vasovagal syncope results. Relative dehydration tends to amplify these responses. Symptoms of irritable Bowel Syndrome are thought to cause activation of the vagus nerve with many people reporting fainting, vision disturbances and dizziness, but there has been little research into this area as it is not deemed necessary and/or life-threatening.
Excessive activation of the vagal nerve during emotional stress, which is a parasympathetic overcompensation of a strong sympathetic nervous system response associated with stress, can also cause vasovagal syncope due to a sudden drop in cardiac output, causing cerebral hypoperfusion. Vasovagal syncope affects young children and women more than other groups. It can also lead to temporary loss of bladder control under moments of extreme fear.
Research has shown that women having had complete spinal cord injury can experience orgasms through the vagus nerve, which can go from the uterus, cervix, and, it is presumed, the vagina to the brain.
Insulin signaling activates the adenosine triphosphate (ATP)-sensitive potassium (KATP) channels in the arcuate nucleus, decreases AgRP release, and through the vagus nerve, leads to decreased glucose production by the liver by decreasing gluconeogenic enzymes: Phosphoenolpyruvate carboxykinase, Glucose 6-phosphatase.
Clinical significance.
Vagus nerve stimulation.
Vagus nerve stimulation (VNS) therapy using a pacemaker-like device implanted in the chest is a treatment used since 1997 to control seizures in epilepsy patients and has recently been approved for treating drug-resistant cases of clinical depression. A non-invasive VNS device that stimulates an afferent branch of the vagus nerve is also being developed and will soon undergo trials.
Clinical trials are currently underway in Antwerp, Belgium using VNS for the treatment of tonal tinnitus after a breakthrough study published in early 2011 by researchers at the University of Texas - Dallas showed successful tinnitus suppression in rats when tones were paired with brief pulses of stimulation of the vagus nerve.
VNS may also be achieved by one of the "vagal maneuvers": holding the breath for a few seconds, dipping the face in cold water, coughing, or tensing the stomach muscles as if to bear down to have a bowel movement. Patients with supraventricular tachycardia, atrial fibrillation, and other illnesses may be trained to perform vagal maneuvers (or find one or more on their own).
Vagus nerve blocking (VBLOC) therapy is similar to VNS but used only during the day. In a six-month open-label trial involving three medical centers in Australia, Mexico, and Norway, vagus nerve blocking has helped 31 obese participants lose an average of nearly 15 percent of their excess weight. A year-long 300-participant double-blind, phase II trial has begun.
Vagotomy.
Vagotomy (cutting of the vagus nerve) is a now-obsolete therapy that was performed for peptic ulcer disease. Vagotomy is currently being researched as a less invasive alternative weight-loss procedure to gastric bypass surgery. The procedure curbs the feeling of hunger and is sometimes performed in conjunction with putting bands on patients' stomachs, resulting in average weight loss of 43% at six months with diet and exercise.
One serious side effect of a vagotomy is a vitamin B12 deficiency later in life — perhaps after about 10 years — that is similar to pernicious anemia. The vagus normally stimulates the stomach's parietal cells to secrete acid and intrinsic factor. Intrinsic factor is needed to absorb vitamin B12 from food. The vagotomy reduces this secretion and ultimately leads to the deficiency, which, if left untreated, causes nerve damage, tiredness, dementia, paranoia, and ultimately death.
Researchers from Aarhus University and Aarhus University Hospital have demonstrated that vagotomy prevents the development of Parkinson's disease, suggesting that Parkinson's disease begins in the gastrointestinal tract and spreads via the vagus nerve to the brain.
Chagasic disease.
The majority of gradual devastation by Chagasic neuropathy is channeled to the major parasympathetic branches of the vagus nerve. Depending upon load, Chagasic vagal disease can cause megaesophagus, megacolon and cardiomyopathy.
History.
Etymology.
The medieval Latin word "vagus" means literally "wandering" (the words "vagrant", "vagabond", and "vague" come from the same root). Sometimes the branches are spoken of in the plural and are thus called vagi (, ). The vagus is also called the "pneumogastric" nerve since it innervates both the lungs and the stomach.

</doc>
<doc id="37190" url="https://en.wikipedia.org/wiki?curid=37190" title="Thomas Becket">
Thomas Becket

Thomas Becket (; also known as Saint Thomas of Canterbury, Thomas of London, and later Thomas à Becket; 21 December c. 1119 (or 1120) – 29 December 1170) was Archbishop of Canterbury from 1162 until his murder in 1170. He is venerated as a saint and martyr by both the Catholic Church and the Anglican Communion. He engaged in conflict with Henry II, King of England over the rights and privileges of the Church and was murdered by followers of the king in Canterbury Cathedral. Soon after his death, he was canonised by Pope Alexander III.
Sources.
The main sources for the life of Becket are a number of biographies that were written by contemporaries. A few of these documents are by unknown writers, although traditional historiography has given them names. The known biographers are John of Salisbury, Edward Grim, Benedict of Peterborough, William of Canterbury, William fitz Stephen, Guernes of Pont-Sainte-Maxence, Robert of Cricklade, Alan of Tewkesbury, Benet of St Albans, and Herbert of Bosham. The other biographers, who remain anonymous, are generally given the pseudonyms of Anonymous I, Anonymous II (or Anonymous of Lambeth), and Anonymous III (or Lansdowne Anonymous). Besides these accounts, there are also two other accounts that are likely contemporary that appear in the "Quadrilogus II" and the "Thómas saga Erkibyskups". Besides these biographies, there is also the mention of the events of Becket's life in the chroniclers of the time. These include Robert of Torigni's work, Roger of Howden's "Gesta Regis Henrici Secundi" and "Chronica", Ralph Diceto's works, William of Newburgh's "Historia Rerum", and Gervase of Canterbury's works.
Early life.
Becket was born about 1119, or in 1120 according to later tradition. He was born in Cheapside, London, on 21 December, which was the feast day of St Thomas the Apostle. He was the son of Gilbert Beket and Gilbert's wife Matilda. Gilbert's father was from Thierville in the lordship of Brionne in Normandy, and was either a small landowner or a petty knight. Matilda was also of Norman ancestry, and her family may have originated near Caen. Gilbert was perhaps related to Theobald of Bec, whose family also was from Thierville. Gilbert began his life as a merchant, perhaps as a textile merchant, but by the 1120s he was living in London and was a property owner, living on the rental income from his properties. He also served as the sheriff of the city at some point. They were buried in Old St Paul's Cathedral.
One of Becket's father's wealthy friends, Richer de L'Aigle, often invited Thomas to his estates in Sussex where Becket was exposed to hunting and hawking. According to Grim, Becket learned much from Richer, who was later a signatory of the Constitutions of Clarendon against Thomas.
Beginning when he was 10, Becket was sent as a student to Merton Priory in England and later attended a grammar school in London, perhaps the one at St Paul's Cathedral. He did not study any subjects beyond the trivium and quadrivium at these schools. Later, he spent about a year in Paris around age 20. He did not, however, study canon or civil law at this time and his Latin skill always remained somewhat rudimentary. Some time after Becket began his schooling, Gilbert Beket suffered financial reverses, and the younger Becket was forced to earn a living as a clerk. Gilbert first secured a place for his son in the business of a relative – Osbert Huitdeniers – and then later Becket acquired a position in the household of Theobald of Bec, by now the Archbishop of Canterbury.
Theobald entrusted him with several important missions to Rome and also sent him to Bologna and Auxerre to study canon law. Theobald in 1154 named Becket Archdeacon of Canterbury, and other ecclesiastical offices included a number of benefices, prebends at Lincoln Cathedral and St Paul's Cathedral, and the office of Provost of Beverley. His efficiency in those posts led to Theobald recommending him to King Henry II for the vacant post of Lord Chancellor, to which Becket was appointed in January 1155.
As Chancellor, Becket enforced the king's traditional sources of revenue that were exacted from all landowners, including churches and bishoprics. King Henry even sent his son Henry to live in Becket's household, it being the custom then for noble children to be fostered out to other noble houses. The younger Henry was reported to have said Becket showed him more fatherly love in a day than his father did for his entire life.
Primacy.
Becket was nominated as Archbishop of Canterbury in 1162, several months after the death of Theobald. His election was confirmed on 23 May 1162 by a royal council of bishops and noblemen. Henry may have hoped that Becket would continue to put the royal government first, rather than the church. However, the famous transformation of Becket into an ascetic occurred at this time.
Becket was ordained a priest on 2 June 1162 at Canterbury, and on 3 June 1162 was consecrated as archbishop by Henry of Blois, the Bishop of Winchester and the other suffragan bishops of Canterbury.
A rift grew between Henry and Becket as the new archbishop resigned his chancellorship and sought to recover and extend the rights of the archbishopric. This led to a series of conflicts with the King, including that over the jurisdiction of secular courts over English clergymen, which accelerated antipathy between Becket and the king. Attempts by Henry to influence the other bishops against Becket began in Westminster in October 1163, where the King sought approval of the traditional rights of the royal government in regard to the church. This led to Clarendon, where Becket was officially asked to agree to the King's rights or face political repercussions.
Constitutions of Clarendon.
Henry pursued the fugitive archbishop with a series of edicts, aimed at all his friends and supporters as well as Becket himself; but King Louis VII of France offered Becket protection. He spent nearly two years in the Cistercian abbey of Pontigny, until Henry's threats against the order obliged him to return to Sens. Becket fought back by threatening excommunication and interdict against the king and bishops and the kingdom, but Pope Alexander III, though sympathising with him in theory, favoured a more diplomatic approach. Papal legates were sent in 1167 with authority to act as arbitrators.
In 1170, Alexander sent delegates to impose a solution to the dispute. At that point, Henry offered a compromise that would allow Thomas to return to England from exile.
Assassination.
In June 1170, Roger de Pont L'Évêque, the archbishop of York, along with Gilbert Foliot, the Bishop of London, and Josceline de Bohon, the Bishop of Salisbury, crowned the heir apparent, Henry the Young King, at York. This was a breach of Canterbury's privilege of coronation, and in November 1170 Becket excommunicated all three. While the three clergymen fled to the king in Normandy, Becket continued to excommunicate his opponents in the church, the news of which also reached Henry.
Upon hearing reports of Becket's actions, Henry is said to have uttered words that were interpreted by his men as wishing Becket killed. The king's exact words are in doubt and several versions have been reported. The most commonly quoted, as handed down by oral tradition, is "Who will rid me of this troublesome priest?", but according to historian Simon Schama this is incorrect: he accepts the account of the contemporary biographer Edward Grim, writing in Latin, who gives us "What miserable drones and traitors have I nourished and brought up in my household, who let their lord be treated with such shameful contempt by a low-born cleric?" Many variations have found their way into popular culture.
Whatever Henry said, it was interpreted as a royal command, and four knights, Reginald fitzUrse, Hugh de Morville, William de Tracy and Richard le Breton, set out to confront the Archbishop of Canterbury.
On 29 December 1170 they arrived at Canterbury. According to accounts left by the monk Gervase of Canterbury and eyewitness Edward Grim, they placed their weapons under a tree outside the cathedral and hid their mail armour under cloaks before entering to challenge Becket. The knights informed Becket he was to go to Winchester to give an account of his actions, but Becket refused. It was not until Becket refused their demands to submit to the king's will that they retrieved their weapons and rushed back inside for the killing. Becket, meanwhile, proceeded to the main hall for vespers. The four knights, wielding drawn swords, caught up with him in a spot near a door to the monastic cloister, the stairs into the crypt, and the stairs leading up into the quire of the cathedral, where the monks were chanting vespers.
Several contemporary accounts of what happened next exist; of particular note is that of Edward Grim, who was himself wounded in the attack. This is part of the account from Edward Grim:
Another account can be found in "Expugnatio Hibernica" ("Conquest of Ireland", 1189) written by Gerald of Wales.
After Becket's death.
Following Becket's death, the monks prepared his body for burial. According to some accounts, it was discovered that Becket had worn a hairshirt under his archbishop's garments—a sign of penance. Soon after, the faithful throughout Europe began venerating Becket as a martyr, and on 21 February 1173—little more than two years after his death—he was canonised by Pope Alexander III in St Peter's Church in Segni. In 1173, Becket's sister Mary was appointed as abbess of Barking Abbey as reparation for the murder of her brother. On 12 July 1174, in the midst of the Revolt of 1173–74, Henry humbled himself with public penance at Becket's tomb as well as at the church of St. Dunstan's, which became one of the most popular pilgrimage sites in England.
Becket's assassins fled north to Knaresborough Castle, which was held by Hugh de Morville, where they remained for about a year. De Morville held property in Cumbria and this may also have provided a convenient bolt-hole, as the men prepared for a longer stay in the separate kingdom of Scotland. They were not arrested and neither did Henry confiscate their lands, but he failed to help them when they sought his advice in August 1171. Pope Alexander excommunicated all four. Seeking forgiveness, the assassins travelled to Rome and were ordered by the Pope to serve as knights in the Holy Lands for a period of fourteen years.
This last also inspired Knights of Saint Thomas, incorporated in 1191 at Acre, and which was to be modelled on the Teutonic Knights. It is the only military order native to England (with chapters in not only Acre, but London, Kilkenny, and Nicosia), like the Gilbertine Order being the only monastic order native to England as well. Nevertheless, Henry VIII dissolved both of these English institutions upon passing the Reformation, rather than merging foreign orders with them and nationalising them as elements of the Protestant Church of England.
The monks were afraid that Becket's body might be stolen. To prevent this Becket's remains were placed beneath the floor of the eastern crypt of the cathedral. A stone cover was placed over the burial place with two holes where pilgrims could insert their heads and kiss the tomb; this arrangement is illustrated in the "Miracle Windows" of the Trinity Chapel. A guard chamber (now called the Wax Chamber) had a clear view of the grave. In 1220, Becket's bones were moved to a new gold-plated and bejewelled shrine behind the high altar in the Trinity Chapel. The shrine was supported by three pairs of pillars, placed on a raised platform with three steps. This is also illustrated in one of the miracle windows. Canterbury, because of its religious history, had always seen a large number of pilgrims. However, after the death of Thomas Becket, the number of pilgrims visiting the city rose rapidly.
Cult in the Middle Ages.
On 7 July 1220, in the 50th jubilee year of his death, Becket's remains were moved from this first tomb to a shrine, in the recently completed Trinity Chapel. This act of translation was "one of the great symbolic events in the life of the medieval English Church" and was attended by King Henry III, the papal legate, the Archbishop of Canterbury Stephen Langton and large numbers of dignitaries and magnates secular and ecclesiastical. Thus a "major new feast day was instituted, commemorating the translation, that was celebrated each July almost everywhere in England and also in many French churches." This feast was suppressed in 1536 at the Reformation.
The shrine stood until it was destroyed in 1538, during the Dissolution of the Monasteries, on orders from King Henry VIII. The king also destroyed Becket's bones and ordered that all mention of his name be obliterated. The pavement where the shrine stood is today marked by a lit candle.
As the scion of the leading mercantile dynasty of later centuries, Mercers, Becket was very much regarded as a Londoner by the citizens and was adopted as London's co-patron saint with St Paul: both their images appeared on the seals of the city and of the Lord Mayor. The Bridge House Estates seal used only the image of Becket, while the reverse featured a depiction of his martyrdom.
Local legends regarding Becket arose after his canonisation. Though they are typical hagiographical stories, they also display Becket's particular gruffness. "Becket's Well", in Otford, Kent, is said to have been created after Becket had become displeased with the taste of the local water. Two springs of clear water are said to have bubbled up after he struck the ground with his crozier. The absence of nightingales in Otford is also ascribed to Becket, who is said to have been so disturbed in his devotions by the song of a nightingale that he commanded that none should sing in the town ever again. In the town of Strood, also in Kent, Becket is said to have caused the inhabitants of the town and their descendants to be born with tails. The men of Strood had sided with the king in his struggles against the archbishop, and to demonstrate their support, had cut off the tail of Becket's horse as he passed through the town.
The saint's fame quickly spread throughout the Norman world. The first holy image of Becket is thought to be a mosaic icon still visible in Monreale Cathedral, in Sicily, created shortly after his death. Becket's cousins obtained refuge at the Sicilian court during his exile, and King William II of Sicily wed a daughter of Henry II. The principal church of the Sicilian city of Marsala is dedicated to St Thomas Becket. Over forty-five medieval chasse reliquaries decorated in champlevé enamel showing similar scenes from Becket's life survive, including the Becket Casket, originally constructed to hold relics of the saint at Peterborough Abbey, and now housed in the Victoria and Albert Museum in London.
In Scotland, King William the Lion ordered the building of Arbroath Abbey in 1178. On completion in 1197 the new foundation was dedicated to Becket, whom the king had known personally while at the English court as a young man.

</doc>
<doc id="37194" url="https://en.wikipedia.org/wiki?curid=37194" title="Jonathan Edwards">
Jonathan Edwards

Jonathan Edwards may refer to:

</doc>
<doc id="37196" url="https://en.wikipedia.org/wiki?curid=37196" title="Causality">
Causality

Causality (also referred to as 'causation', or 'cause and effect') is the agency or efficacy that connects one process (the "cause") with another (the "effect"), where the first is understood to be partly responsible for the second, and the second is dependent on the first. In general, a process has many causes, which are said to be causal factors for it, and all lie in its past. An effect can in turn be a cause of many other effects, which all lie in its future.
Causality is an abstraction that indicates how the world progresses, so basic a concept that it is more apt as an explanation of other concepts of progression than as something to be explained by others more basic. The concept is like those of agency and efficacy. For this reason, a leap of intuition may be needed to grasp it. Accordingly, causality is built into the conceptual structure of ordinary language.
In Aristotelian philosophy, the word 'cause' is also used to mean 'explanation' or 'answer to a why question', including Aristotle's material, formal, efficient, and final "causes"; then the "cause" is the explanans for the explanandum. In this case, failure to recognize that different kinds of "cause" are being considered can lead to futile debate. Of Aristotle's four explanatory modes, the one nearest to the concerns of the present article is the "efficient" one.
The topic remains a staple in contemporary philosophy.
Concept.
Metaphysics.
The nature of cause and effect is a concern of the subject known as metaphysics.
Ontology.
A general metaphysical question about cause and effect is what kind of entity can be a cause, and what kind of entity can be an effect.
One viewpoint on this question is that cause and effect are of one and the same kind of entity, with causality an asymmetric relation between them. That is to say, it would make good sense grammatically to say either ""A" is the cause and "B" the effect" or ""B" is the cause and "A" the effect", though only one of those two can be actually true. In this view, one opinion, proposed as a metaphysical principle in process philosophy, is that every cause and every effect is respectively some process, event, becoming, or happening. An example is 'his tripping over the step was the cause, and his breaking his ankle the effect'. Another view is that causes and effects are 'states of affairs', with the exact natures of those entities being less restrictively defined than in process philosophy.
Another viewpoint on the question is the more classical one, that a cause and its effect can be of different kinds of entity. For example, in Aristotle's efficient causal explanation, an action can be a cause while an enduring object is its effect. For example, the generative actions of his parents can be regarded as the efficient cause, with Socrates being the effect, Socrates being regarded as an enduring object, in philosophical tradition called a 'substance', as distinct from an action.
Epistemology.
Since causality is a subtle metaphysical notion, considerable effort is needed to establish knowledge of it in particular empirical circumstances.
Geometrical significance.
Causality has the properties of antecedence and contiguity. These are topological, and are ingredients for space-time geometry. As developed by Alfred Robb, these properties allow the derivation of the notions of time and space. Max Jammer writes "the Einstein postulate ... opens the way to a straightforward construction of the causal topology ... of Minkowski space." Causal efficacy propagates no faster than light. Thus, the notion of causality is metaphysically prior to the notions of time and space.
Necessary and sufficient causes.
Causes are often distinguished into two types: Necessary and sufficient. A third type of causation, which requires neither necessity nor sufficiency in and of itself, but which contributes to the effect, is called a "contributory cause."
Necessary causes:
If "x" is a necessary cause of "y", then the presence of "y" necessarily implies the presence of "x". The presence of "x", however, does not imply that "y" will occur.
Sufficient causes:
If "x" is a sufficient cause of "y", then the presence of "x" necessarily implies the presence of "y". However, another cause "z" may alternatively cause "y". Thus the presence of "y" does not imply the presence of "x".
Contributory causes:
For some specific effect, in a singular case, factor that is a contributory cause is one amongst several co-occurrent causes. It is implicit that all of them are contributory. For the specific effect, in general, there is no implication that a contributory cause is necessary, though it may be so. In general, a factor that is a contributory cause is not sufficient, because it is by definition accompanied by other causes, which would not count as causes if it were sufficient. For the specific effect, a factor that is on some occasions a contributory cause might on some other occasions be sufficient, but on those other occasions it would not be merely contributory.
J. L. Mackie argues that usual talk of "cause", in fact refers to INUS conditions (insufficient but non-redundant parts of a condition which is itself unnecessary but sufficient for the occurrence of the effect). An example is a short circuit as a cause for a house burning down. Consider the collection of events: the short circuit, the proximity of flammable material, and the absence of firefighters. Together these are unnecessary but sufficient to the house's burning down (since many other collections of events certainly could have led to the house burning down, for example shooting the house with a flamethrower in the presence of oxygen and so forth). Within this collection, the short circuit is an insufficient (since the short circuit by itself would not have caused the fire) but non-redundant (because the fire would not have happened without it, everything else being equal) part of a condition which is itself unnecessary but sufficient for the occurrence of the effect. So, the short circuit is an INUS condition for the occurrence of the house burning down.
Causality contrasted with conditionals.
Conditional statements are "not" statements of causality. An important distinction is that statements of causality require the antecedent to precede or coincide with the consequent in time, whereas conditional statements do not require this temporal order. Confusion commonly arises since many different statements in English may be presented using "If ..., then ..." form (and, arguably, because this form is far more commonly used to make a statement of causality). The two types of statements are distinct, however.
For example, all of the following statements are true when interpreting "If ..., then ..." as the material conditional:
The first is true since both the antecedent and the consequent are true. The second is true in sentential logic and indeterminate in natural language, regardless of the consequent statement that follows, because the antecedent is false.
The ordinary indicative conditional has somewhat more structure than the material conditional. For instance, although the first is the closest, neither of the preceding two statements seems true as an ordinary indicative reading. But the sentence
intuitively seems to be true, even though there is no straightforward causal relation in this hypothetical situation between Shakespeare's not writing Macbeth and someone else's actually writing it.
Another sort of conditional, the counterfactual conditional, has a stronger connection with causality, yet even counterfactual statements are not all examples of causality. Consider the following two statements:
In the first case, it would not be correct to say that A's being a triangle "caused" it to have three sides, since the relationship between triangularity and three-sidedness is that of definition. The property of having three sides actually determines A's state as a triangle. Nonetheless, even when interpreted counterfactually, the first statement is true. An early version of Aristotle's "four cause" theory is described as recognizing "essential cause". In this version of the theory, that the closed polygon has three sides is said to be the "essential cause" of its being a triangle. This use of the word 'cause' is of course now far obsolete. Nevertheless, it is within the scope of ordinary language to say that it is essential to a triangle that it has three sides.
A full grasp of the concept of conditionals is important to understanding the literature on causality. In everyday language, loose conditional statements are often enough made, and need to be interpreted carefully.
Questionable cause.
Fallacies of questionable cause, also known as causal fallacies, "non-causa pro causa" (Latin for "non-cause for cause"), or false cause, are informal fallacies where a cause is incorrectly identified.
Theories.
Counterfactual theories.
Subjunctive conditionals are familiar from ordinary language. They are of the form, if A "were" the case, then B "would" be the case, or if A "had been" the case, then B "would have been" the case. Counterfactual conditionals are specifically subjunctive conditionals whose antecedents are in fact false, hence the name. However the term used technically may apply to conditionals with true antecedents as well.
Psychological research shows that people's thoughts about the causal relationships between events influences their judgments of the plausibility of counterfactual alternatives, and conversely, their counterfactual thinking about how a situation could have turned out differently changes their judgments of the causal role of events and agents. Nonetheless, their identification of the cause of an event, and their counterfactual thought about how the event could have turned out differently do not always coincide. People distinguish between various sorts of causes, e.g., strong and weak causes. Research in the psychology of reasoning shows that people make different sorts of inferences from different sorts of causes.
In the philosophical literature, the suggestion that causation is to be defined in terms of a counterfactual relation is made by the 18th Century Scottish philosopher David Hume. Hume remarks that we may define the relation of cause and effect such that ``where, if the first object had not been, the second never had existed." 
More full-fledged analysis of causation in terms of counterfactual conditionals only came in the 20th Century after development of the possible world semantics for the evaluation of counterfactual conditionals. In his 1973 paper "Causation," David Lewis proposed that the following definition of the notion of "causal dependence":
Causation is then defined as a chain of causal dependence. That is, C causes E if and only if there exists a sequence of events C, D1, D2, ... Dk, E such that each event in the sequence depends on the previous.
Note that the analysis does not purport to explain how we make causal judgements or how we reason about causation, but rather to give a metaphysical account of what it is for there to be a causal relation between some pair of events. If correct, the analysis has the power to explain certain features of causation. Knowing that causation is a matter of counterfactual dependence, we may reflect on the nature of counterfactual dependence to account for the nature of causation. For example, in his paper "Counterfactual Dependence and Time's Arrow," Lewis sought to account for the time-directedness of counterfactual dependence in terms of the semantics of the counterfactual conditional. If correct, this theory can serve to explain a fundamental part of our experience, which is that we can only causally affect the future but not the past.
Probabilistic causation.
Interpreting causation as a deterministic relation means that if "A" causes "B", then "A" must "always" be followed by "B". In this sense, war does not cause deaths, nor does smoking cause cancer or emphysema. As a result, many turn to a notion of probabilistic causation. Informally, "A" ("The person is a smoker") probabilistically causes "B" ("The person has now or will have cancer at some time in the future"), if the information that "A" occurred increases the likelihood of "B"s occurrence. Formally, P{"B"|"A"}≥ P{"B"} where P{"B"|"A"} is the conditional probability that "B" will occur given the information that "A" occurred, and P{"B"}is the probability that "B" will occur having no knowledge whether "A" did or did not occur. This intuitive condition is not adequate as a definition for probabilistic causation because of its being too general and thus not meeting our intuitive notion of cause and effect. For example, if "A" denotes the event "The person is a smoker," "B" denotes the event "The person now has or will have cancer at some time in the future" and "C" denotes the event "The person now has or will have emphysema some time in the future," then the following three relationships hold: P{"B"|"A"} ≥ P{"B"}, P{"C"|"A"} ≥ P{"C"} and P{"B"|"C"} ≥ P{"B"}. The last relationship states that knowing that the person has emphysema increases the likelihood that he will have cancer. The reason for this is having the information that the person has emphysema increases the likelihood that the person is a smoker thus indirectly increases the likelihood that the person will have cancer. However, we would not want to conclude that having emphysema causes cancer. Thus, we need additional conditions such as temporal relationship of "A" to be and a rational explanation as to the mechanism of action. It is hard to quantify this last requirement and thus different authors prefer somewhat different definitions.
Causal calculus.
When experimental interventions are infeasible or illegal, the derivation of cause effect relationship from observational studies must rest on some qualitative theoretical assumptions, for example, that symptoms do not cause diseases, usually expressed in the form of missing arrows in causal graphs such as Bayesian networks or path diagrams. The theory underlying these derivations relies on the distinction between "conditional probabilities", as in formula_1, and "interventional probabilities", as in formula_2. The former reads: "the probability of finding cancer in a person known to smoke, having started, unforced by the experimenter, to do so at an unspecified time in the past", while the latter reads: "the probability of finding cancer in a person forced by the experimenter to smoke at a specified time in the past". The former is a statistical notion that can be estimated by observation with negligible intervention by the experimenter, while the latter is a causal notion which is estimated in an experiment with an important controlled randomized intervention. It is specifically characteristic of quantal phenomena that observations defined by incompatible variables always involve important intervention by the experimenter, as described quantitatively by the Heisenberg uncertainty principle. In classical thermodynamics, processes are initiated by interventions called thermodynamic operations. In other branches of science, for example astronomy, the experimenter can often observe with negligible intervention.
The theory of "causal calculus" permits one to infer interventional probabilities from conditional probabilities in causal Bayesian networks with unmeasured variables. One very practical result of this theory is the characterization of confounding variables, namely, a sufficient set of variables that, if adjusted for, would yield the correct causal effect between variables of interest. It can be shown that a sufficient set for estimating the causal effect of formula_3 on formula_4 is any set of non-descendants of formula_3 that formula_6-separate formula_3 from formula_4 after removing all arrows emanating from formula_3. This criterion, called "backdoor", provides a mathematical definition of "confounding" and helps researchers identify accessible sets of variables worthy of measurement.
Structure learning.
While derivations in causal calculus rely on the structure of the causal graph, parts of the causal structure can, under certain assumptions, be learned from statistical data. The basic idea goes back to Sewall Wright's 1921 work on path analysis. A "recovery" algorithm was developed by Rebane and Pearl (1987) which rests on Wright's distinction between the three possible types of causal substructures allowed in a directed acyclic graph (DAG):
Type 1 and type 2 represent the same statistical dependencies (i.e., formula_3 and formula_14 are independent given formula_4) and are, therefore, indistinguishable within purely cross-sectional data. Type 3, however, can be uniquely identified, since formula_3 and formula_14 are marginally independent and all other pairs are dependent. Thus, while the "skeletons" (the graphs stripped of arrows) of these three triplets are identical, the directionality of the arrows is partially identifiable. The same distinction applies when formula_3 and formula_14 have common ancestors, except that one must first condition on those ancestors. Algorithms have been developed to systematically determine the skeleton of the underlying graph and, then, orient all arrows whose directionality is dictated by the conditional independencies observed.
Alternative methods of structure learning search through the "many" possible causal structures among the variables, and remove ones which are strongly incompatible with the observed correlations. In general this leaves a set of possible causal relations, which should then be tested by analyzing time series data or, preferably, designing appropriately controlled experiments. In contrast with Bayesian Networks, path analysis (and its generalization, structural equation modeling), serve better to estimate a known causal effect or to test a causal model than to generate causal hypotheses.
For nonexperimental data, causal direction can often be inferred if information about time is available. This is because (according to many, though not all, theories) causes must precede their effects temporally. This can be determined by statistical time series models, for instance, or with a statistical test based on the idea of Granger causality, or by direct experimental manipulation. The use of temporal data can permit statistical tests of a pre-existing theory of causal direction. For instance, our degree of confidence in the direction and nature of causality is much greater when supported by cross-correlations, ARIMA models, or cross-spectral analysis using vector time series data than by cross-sectional data.
Derivation theories.
The Nobel Prize holder Herbert A. Simon and Philosopher Nicholas Rescher claim that the asymmetry of the causal relation is unrelated to the asymmetry of any mode of implication that contraposes. Rather, a causal relation is not a relation between values of variables, but a function of one variable (the cause) on to another (the effect). So, given a system of equations, and a set of variables appearing in these equations, we can introduce an asymmetric relation among individual equations and variables that corresponds perfectly to our commonsense notion of a causal ordering. The system of equations must have certain properties, most importantly, if some values are chosen arbitrarily, the remaining values will be determined uniquely through a path of serial discovery that is perfectly causal. They postulate the inherent serialization of such a system of equations may correctly capture causation in all empirical fields, including physics and economics.
Manipulation theories.
Some theorists have equated causality with manipulability. Under these theories, "x" causes "y" only in the case that one can change "x" in order to change "y". This coincides with commonsense notions of causations, since often we ask causal questions in order to change some feature of the world. For instance, we are interested in knowing the causes of crime so that we might find ways of reducing it.
These theories have been criticized on two primary grounds. First, theorists complain that these accounts are circular. Attempting to reduce causal claims to manipulation requires that manipulation is more basic than causal interaction. But describing manipulations in non-causal terms has provided a substantial difficulty.
The second criticism centers around concerns of anthropocentrism. It seems to many people that causality is some existing relationship in the world that we can harness for our desires. If causality is identified with our manipulation, then this intuition is lost. In this sense, it makes humans overly central to interactions in the world.
Some attempts to defend manipulability theories are recent accounts that don't claim to reduce causality to manipulation. These accounts use manipulation as a sign or feature in causation without claiming that manipulation is more fundamental than causation.
Process theories.
Some theorists are interested in distinguishing between causal processes and non-causal processes (Russell 1948; Salmon 1984). These theorists often want to distinguish between a process and a pseudo-process. As an example, a ball moving through the air (a process) is contrasted with the motion of a shadow (a pseudo-process). The former is causal in nature while the latter is not.
Salmon (1984) claims that causal processes can be identified by their ability to transmit an alteration over space and time. An alteration of the ball (a mark by a pen, perhaps) is carried with it as the ball goes through the air. On the other hand, an alteration of the shadow (insofar as it is possible) will not be transmitted by the shadow as it moves along.
These theorists claim that the important concept for understanding causality is not causal relationships or causal interactions, but rather identifying causal processes. The former notions can then be defined in terms of causal processes.
Fields.
Science.
For the scientific investigation of efficient causality, the cause and effect are each best conceived of as temporally transient processes.
Within the conceptual frame of the scientific method, an investigator sets up several distinct and contrasting temporally transient material processes that have the structure of experiments, and records candidate material responses, normally intending to determine causality in the physical world. For instance, one may want to know whether a high intake of carrots causes humans to develop the bubonic plague. The quantity of carrot intake is a process that is varied from occasion to occasion. The occurrence or non-occurrence of subsequent bubonic plague is recorded. To establish causality, the experiment must fulfill certain criteria, only one example of which is mentioned here. (There are other criteria not mentioned here.) For example, instances of the hypothesized cause must be set up to occur at a time when the hypothesized effect is relatively unlikely in the absence of the hypothesized cause; such unlikelihood is to be established by empirical evidence. A mere observation of a correlation is not nearly adequate to establish causality. In nearly all cases, establishment of causality relies on repetition of experiments and probabilistic reasoning. Hardly ever is causality established more firmly than as more or less probable. It is often most convenient for establishment of causality if the contrasting material states of affairs are fully comparable, and differ through only one variable factor, perhaps measured by a real number. Otherwise, experiments are usually difficult or impossible to interpret.
In some sciences, it is very difficult or nearly impossible to set up material states of affairs that closely test hypotheses of causality. Such sciences can in some sense be regarded as "softer".
Physics.
It is useful to be careful in the use of the word cause in physics. Properly speaking, the hypothesized cause and the hypothesized effect are each temporally transient processes. For example, force is a useful concept for the explanation of acceleration, but force is not by itself a cause. More is needed. For example, a temporally transient process might be characterized by a definite change of force at a definite time. Such a process can be regarded as a cause. Causality is not inherently implied in equations of motion, but postulated as an additional constraint that needs to be satisfied (i.e. a cause always precedes its effect). This constraint has mathematical implications such as the Kramers-Kronig relations.
Causality is one of the most fundamental and essential notions of physics. Causal efficacy cannot propagate faster than light. Otherwise, reference coordinate systems could be constructed (using the Lorentz transform of special relativity) in which an observer would see an effect precede its cause (i.e. the postulate of causality would be violated).
Causal notions appear in the context of the flow of mass-energy. For example, it is commonplace to argue that causal efficacy can be propagated by waves (such as electromagnetic waves) only if they propagate no faster than light. Wave packets have group velocity and phase velocity. For waves that propagate causal efficacy, both of these must travel no faster than light. Thus light waves often propagate causal efficacy but de Broglie waves often have phase velocity faster than light and consequently cannot be propagating causal efficacy.
Causal notions are important in general relativity to the extent that the existence of an arrow of time demands that the universe's semi-Riemannian manifold be orientable, so that "future" and "past" are globally definable quantities.
Engineering.
A causal system is a system with output and internal states that depends only on the current and previous input values. A system that has "some" dependence on input values from the future (in addition to possible past or current input values) is termed an acausal system, and a system that depends "solely" on future input values is an anticausal system. Acausal filters, for example, can only exist as postprocessing filters, because these filters can extract future values from a memory buffer or a file.
Biology, medicine and epidemiology.
Austin Bradford Hill built upon the work of Hume and Popper and suggested in his paper "The Environment and Disease: Association or Causation?" that aspects of an association such as strength, consistency, specificity and temporality be considered in attempting to distinguish causal from noncausal associations in the epidemiological situation. (See Bradford-Hill criteria.) He did not note however, that temporality is the only necessary criterion among those aspects. Directed acyclic graphs (DAGs) are increasingly used in epidemiology to help enlighten causal thinking.
Psychology.
Psychologists take an empirical approach to causality, investigating how people and non-human animals detect or infer causation from sensory information, prior experience and innate knowledge.
Attribution theory is the theory concerning how people explain individual occurrences of causation. Attribution can be external (assigning causality to an outside agent or force – claiming that some outside thing motivated the event) or internal (assigning causality to factors within the person – taking personal responsibility or accountability for one's actions and claiming that the person was directly responsible for the event). Taking causation one step further, the type of attribution a person provides influences their future behavior.
The intention behind the cause or the effect can be covered by the subject of action. See also accident; blame; intent; and responsibility.
Whereas David Hume argued that causes are inferred from non-causal observations, Immanuel Kant claimed that people have innate assumptions about causes. Within psychology, Patricia Cheng (1997) attempted to reconcile the Humean and Kantian views. According to her power PC theory, people filter observations of events through a basic belief that causes have the power to generate (or prevent) their effects, thereby inferring specific cause-effect relations.
Our view of causation depends on what we consider to be the relevant events. Another way to view the statement, "Lightning causes thunder" is to see both lightning and thunder as two perceptions of the same event, viz., an electric discharge that we perceive first visually and then aurally.
David Sobel and Alison Gopnik from the Psychology Department of UC Berkeley designed a device known as "the blicket detector" which would turn on when an object was placed on it. Their research suggests that "even young children will easily and swiftly learn about a new causal power of an object and spontaneously use that information in classifying and naming the object."
Some researchers such as Anjan Chatterjee at the University of Pennsylvania and Jonathan Fugelsang at the University of Waterloo are using neuroscience techniques to investigate the neural and psychological underpinnings of causal launching events in which one object causes another object to move. Both temporal and spatial factors can be manipulated.
See Causal Reasoning (Psychology) for more information.
Statistics and economics.
Statistics and economics usually employ pre-existing data or experimental data to infer causality by regression methods. The body of statistical techniques involves substantial use of regression analysis. Typically a linear relationship such as
is postulated, in which formula_21 is the "i"th observation of the dependent variable (hypothesized to be the caused variable), formula_22 for "j"=1...,"k" is the "i"th observation on the "j"th independent variable (hypothesized to be a causative variable), and formula_23 is the error term for the "i"th observation (containing the combined effects of all other causative variables, which must be uncorrelated with the included independent variables). If there is reason to believe that none of the formula_24s is caused by "y", then estimates of the coefficients formula_25 are obtained. If the null hypothesis that formula_26 is rejected, then the alternative hypothesis that formula_27 and equivalently that formula_24 causes "y" cannot be rejected. On the other hand, if the null hypothesis that formula_26 cannot be rejected, then equivalently the hypothesis of no causal effect of formula_24 on "y" cannot be rejected. Here the notion of causality is one of contributory causality as discussed above: If the true value formula_31, then a change in formula_24 will result in a change in "y" "unless" some other causative variable(s), either included in the regression or implicit in the error term, change in such a way as to exactly offset its effect; thus a change in formula_24 is "not sufficient" to change "y". Likewise, a change in formula_24 is "not necessary" to change "y", because a change in "y" could be caused by something implicit in the error term (or by some other causative explanatory variable included in the model).
The above way of testing for causality requires belief that there is no reverse causation, in which "y" would cause formula_24. This belief can be established in one of several ways. First, the variable formula_24 may be a non-economic variable: for example, if rainfall amount formula_24 is hypothesized to affect the futures price "y" of some agricultural commodity, it is impossible that in fact the futures price affects rainfall amount (provided that cloud seeding is never attempted). Second, the instrumental variables technique may be employed to remove any reverse causation by introducing a role for other variables (instruments) that are known to be unaffected by the dependent variable. Third, the principle that effects cannot precede causes can be invoked, by including on the right side of the regression only variables that precede in time the dependent variable; this principle is invoked, for example, in testing for Granger causality and in its multivariate analog, vector autoregression, both of which control for lagged values of the dependent variable while testing for causal effects of lagged independent variables.
Regression analysis controls for other relevant variables by including them as regressors (explanatory variables). This helps to avoid false inferences of causality due to the presence of a third, underlying, variable that influences both the potentially causative variable and the potentially caused variable: its effect on the potentially caused variable is captured by directly including it in the regression, so that effect will not be picked up as an indirect effect through the potentially causative variable of interest.
Metaphysics.
The deterministic world-view holds that the history of the universe can be exhaustively represented as a progression of events following one after as cause and effect. The incompatibilist version of this holds that there is no such thing as "free will". Compatibilism, on the other hand, holds that determinism is compatible with, or even necessary for, free will.
Management.
For quality control in manufacturing in the 1960s, Kaoru Ishikawa developed a cause and effect diagram, known as an Ishikawa diagram or fishbone diagram. The diagram categorizes causes, such as into the six main categories shown here. These categories are then sub-divided. Ishikawa's method identifies "causes" in brainstorming sessions conducted among various groups involved in the manufacturing process. These groups can then be labeled as categories in the diagrams. The use of these diagrams has now spread beyond quality control, and they are used in other areas of management and in design and engineering. Ishikawa diagrams have been criticized for failing to make the distinction between necessary conditions and sufficient conditions. It seems that Ishikawa was not even aware of this distinction.
Humanities.
History.
In the discussion of history, events are sometimes considered as if in some way being agents that can then bring about other historical events. Thus, the combination of poor harvests, the hardships of the peasants, high taxes, lack of representation of the people, and kingly ineptitude are among the "causes" of the French Revolution. This is a somewhat Platonic and Hegelian view that reifies causes as ontological entities. In Aristotelian terminology, this use approximates to the case of the "efficient" cause.
Some philosophers of history such as Arthur Danto have claimed that "explanations in history and elsewhere" describe "not simply an event – something that happens – but a change". Like many practicing historians, they treat causes as intersecting actions and sets of actions which bring about "larger changes", in Danto’s words: to decide "what are the elements which persist through a change" is "rather simple" when treating an individual’s "shift in attitude", but "it is considerably more complex and metaphysically challenging when we are interested in such a change as, say, the break-up of feudalism or the emergence of nationalism".
Much of the historical debate about causes has focused on the relationship between communicative and other actions, between singular and repeated ones, and between actions, structures of action or group and institutional contexts and wider sets of conditions. John Gaddis has distinguished between exceptional and general causes (following Marc Bloch) and between "routine" and "distinctive links" in causal relationships: "in accounting for what happened at Hiroshima on August 6, 1945, we attach greater importance to the fact that President Truman ordered the dropping of an atomic bomb than to the decision of the Army Air Force to carry out his orders." He has also pointed to the difference between immediate, intermediate and distant causes. For his part, Christopher Lloyd puts forward four "general concepts of causation" used in history: the "metaphysical idealist concept, which asserts that the phenomena of the universe are products of or emanations from an omnipotent being or such final cause"; "the empiricist (or Humean) regularity concept, which is based on the idea of causation being a matter of constant conjunctions of events"; "the functional/teleological/consequential concept", which is "goal-directed, so that goals are causes"; and the "realist, structurist and dispositional approach, which sees relational structures and internal dispositions as the causes of phenomena".
Law.
According to law and jurisprudence, legal cause must be demonstrated to hold a defendant liable for a crime or a tort (i.e. a civil wrong such as negligence or trespass). It must be proven that causality, or a "sufficient causal link" relates the defendant's actions to the criminal event or damage in question. Causation is also an essential legal element that must be proven to qualify for remedy measures under international trade law.
Theology.
Note the concept of omnicausality in Abrahamic theology, which is the belief that God has set in motion all events at the dawn of time; he is the determiner and the cause of all things. It is therefore an attempt to rectify the apparent incompatibility between determinism and the existence of an omnipotent god.
History.
Western philosophy.
Aristotelian.
Aristotle identified four kinds of answer or explanatory mode to various "Why?" questions. He thought that, for any given topic, all four kinds of explanatory mode were important, each in its own right. As a result of traditional specialized philosophical peculiarities of language, with translations between ancient Greek, Latin, and English, the word 'cause' is nowadays in specialized philosophical writings used to label Aristotle's four kinds. In ordinary language, there are various meanings of the word cause, the commonest referring to efficient cause, the topic of the present article.
Of Aristotle's four kinds or explanatory modes, only one, the 'efficient cause' is a cause as defined in the leading paragraph of this present article. The other three explanatory modes might be rendered material composition, structure and dynamics, and, again, criterion of completion. The word that Aristotle used was . For the present purpose, that Greek word would be better translated as "explanation" than as "cause" as those words are most often used in current English. Another translation of Aristotle is that he meant "the four Becauses" as four kinds of answer to "why" questions.
Aristotle assumed efficient causality as referring to a basic fact of experience, not explicable by, or reducible to, anything more fundamental or basic.
In some works of Aristotle, the four causes are listed as (1) the essential cause, (2) the logical ground, (3) the moving cause, and (4) the final cause. In this listing, a statement of essential cause is a demonstration that an indicated object conforms to a definition of the word that refers to it. A statement of logical ground is an argument as to why an object statement is true. These are further examples of the idea that a "cause" in general in the context of Aristotle's usage is an "explanation".
The word "efficient" used here can also be translated from Aristotle as "moving" or "initiating".
Efficient causation was connected with Aristotelian physics, which recognized the four elements (earth, air, fire, water), and added the fifth element (aether). Water and earth by their intrinsic property "gravitas" or heaviness intrinsically fall toward, whereas air and fire by their intrinsic property "levitas" or lightness intrinsically rise away from, Earth's center—the motionless center of the universe—in a straight line while accelerating during the substance's approach to its natural place.
As air remained on Earth, however, and did not escape Earth while eventually achieving infinite speed—an absurdity—Aristotle inferred that the universe is finite in size and contains an invisible substance that held planet Earth and its atmosphere, the sublunary sphere, centered in the universe. And since celestial bodies exhibit perpetual, unaccelerated motion orbiting planet Earth in unchanging relations, Aristotle inferred that the fifth element, "aither", that fills space and composes celestial bodies intrinsically moves in perpetual circles, the only constant motion between two points. (An object traveling a straight line from point "A" to "B" and back must stop at either point before returning to the other.)
Left to itself, a thing exhibits "natural motion", but can—according to Aristotelian metaphysics—exhibit "enforced motion" imparted by an efficient cause. The form of plants endows plants with the processes nutrition and reproduction, the form of animals adds locomotion, and the form of humankind adds reason atop these. A rock normally exhibits "natural motion"—explained by the rock's material cause of being composed of the element earth—but a living thing can lift the rock, an "enforced motion" diverting the rock from its natural place and natural motion. As a further kind of explanation, Aristotle identified the final cause, specifying a purpose or criterion of completion in light of which something should be understood.
Aristotle himself explained,
Aristotle further discerned two modes of causation: proper (prior) causation and accidental (chance) causation. All causes, proper and accidental, can be spoken as potential or as actual, particular or generic. The same language refers to the effects of causes, so that generic effects are assigned to generic causes, particular effects to particular causes, and actual effects to operating causes.
Averting infinite regress, Aristotle inferred the first mover—an unmoved mover. The first mover's motion, too, must have been caused, but, being an unmoved mover, must have moved only toward a particular goal or desire.
Middle Ages.
In line with Aristotelian cosmology, Thomas Aquinas posed a hierarchy prioritizing Aristotle's four causes: "final > efficient > material > formal". Aquinas sought to identify the first efficient cause—now simply "first cause"—as everyone would agree, said Aquinas, to call it "God". Later in the Middle Ages, many scholars conceded that the first cause was God, but explained that many earthly events occur within God's design or plan, and thereby scholars sought freedom to investigate the numerous "secondary causes".
After the Middle Ages.
For Aristotelian philosophy before Aquinas, the word cause had a broad meaning. It meant 'answer to a why question' or 'explanation', and Aristotelian scholars recognized four kinds of such answers. With the end of the Middle Ages, in many philosophical usages, the meaning of the word 'cause' narrowed. It often lost that broad meaning, and was restricted to just one of the four kinds. For authors such as Niccolò Machiavelli, in the field of political thinking, and Francis Bacon, concerning science more generally, Aristotle's moving cause was the focus of their interest. A widely used modern definition of causality in this newly narrowed sense was assumed by David Hume. He undertook an epistemological and metaphysical investigation of the notion of moving cause. He denied that we can ever perceive cause and effect, except by developing a habit or custom of mind where we come to associate two types of object or event, always contiguous and occurring one after the other. In Part III, section XV of his book "A Treatise of Human Nature", Hume expanded this to a list of eight ways of judging whether two things might be cause and effect. The first three:
And then additionally there are three connected criteria which come from our experience and which are "the source of most of our philosophical reasonings":
And then two more:
In 1949, physicist Max Born distinguished determination from causality. For him, determination meant that actual events are so linked by laws of nature that certainly reliable predictions and retrodictions can be made from sufficient present data about them. For him, there are two kinds of causation, which we may here call nomic or generic causation, and singular causation. Nomic causality means that cause and effect are linked by more or less certain or probabilistic general laws covering many possible or potential instances; we may recognize this as a probabilized version of criterion 3. of Hume mentioned just above. An occasion of singular causation is a particular occurrence of a definite complex of events that are physically linked by antecedence and contiguity, which we may here recognize as criteria 1. and 2. of Hume mentioned just above.
Hindu philosophy.
Vedic period (ca.1750–500 BCE) literature has karma's Eastern origins. Karma is the belief held by Sanathana Dharma and major religions that a person's actions cause certain effects in the current life and/or in future life, positively or negatively. The various philosophical schools (darsanas) provide different accounts of the subject. The doctrine of satkaryavada affirms that the effect inheres in the cause in some way. The effect is thus either a real or apparent modification of the cause. The doctrine of asatkaryavada affirms that the effect does not inhere in the cause, but is a new arising. See Nyaya for some details of the theory of causation in the Nyaya school. In Brahma Samhita, Brahma describes Krishna as the prime cause of all causes.
Bhagavad-gītā 18.14 identifies five causes for any action (knowing which it can be perfected): the body, the individual soul, the senses, the efforts and the supersoul.
According to Monier-Williams, in the Nyāya causation theory from Sutra I.2.I,2 in the Vaisheshika philosophy, from casual non-existence is effectual non-existence; but, not effectual non-existence from casual non-existence. A cause precedes an effect. With a threads and cloth metaphors, three causes are:
Monier-Williams also proposed that Aristotle's and the Nyaya's causality are considered conditional aggregates necessary to man's productive work.
Buddhist philosophy.
The general or universal definition of pratityasamutpada (or "dependent origination" or "dependent arising" or "interdependent co-arising") is that everything arises in dependence upon multiple causes and conditions; nothing exists as a singular, independent entity. A traditional example in Buddhist texts is of three sticks standing upright and leaning against each other and supporting each other. If one stick is taken away, the other two will fall to the ground.
Causality in the Chittamatrin buddhist school approach, Asanga's (c. 400 CE) mind-only Buddhist school, asserts that objects cause consciousness in the mind's image. Because causes precede effects, which must be different entities, then subject and object are different. For this school, there are no objects which are entities external to a perceiving consciousness. The Chittamatrin and the Yogachara Svatantrika schools accept that there are no objects external to the observer's causality. This largely follows the Nikayas approach.
The Abhidharmakośakārikā approach is Vasubandhu's Abhidharma commentary text in the Sarvāstivāda school (c. 500 CE). It has four intricate causal conditioning constructions with the: 1) root cause, 2) immediate antecedent, 3) object support, and 4) predominance. Then, the six causes are: 1) instrumentality (kāraṇahetu), deemed the primary factor in result production; 2) simultaneity or coexistence, which connects phenomena that arise simultaneously; 3) homogeneity, explaining the homogenous flow that evokes phenomena continuity; 4) association, which operates only between mental factors and explains why consciousness appears as assemblages to mental factors; 5) dominance, which forms one's habitual cognitive and behaviorist dispositions; and 6) fruition, referring to whatever is the actively wholesome or unwholesome result. The four conditions and six causes interact with each other in explaining phenomenal experience: for instance, each conscious moment acts both as the homogenous cause, as well as the immediate antecedent consciousness condition rise, and its concomitants, in a subsequent moment.
The Vaibhashika (c. 500 CE) is an early buddhist school which favors direct object contact and accepts simultaneous cause and effects. This is based in the consciousness example which says, intentions and feelings are mutually accompanying mental factors that support each other like poles in tripod. In contrast, simultaneous cause and effect rejectors say that if the effect already exists, then it cannot effect the same way again. How past, present and future are accepted is a basis for various buddhist school's causality view points.

</doc>
<doc id="37197" url="https://en.wikipedia.org/wiki?curid=37197" title="Isotope separation">
Isotope separation

Isotope separation is the process of concentrating specific isotopes of a chemical element by removing other isotopes. The use of the nuclides produced is various. The largest variety is used in research (e.g. in chemistry where atoms of "marker" nuclide are used to figure out reaction mechanisms). By tonnage, separating natural uranium into enriched uranium and depleted uranium is the largest application. In the following text, mainly the uranium enrichment is considered. This process is a crucial one in the manufacture of uranium fuel for nuclear power stations, and is also required for the creation of uranium based nuclear weapons. Plutonium-based weapons use plutonium produced in a nuclear reactor, which must be operated in such a way as to produce plutonium already of suitable isotopic mix or "grade". 
While different chemical elements can be purified through chemical processes, isotopes of the same element have nearly identical chemical properties, which makes this type of separation impractical, except for separation of deuterium.
Separation techniques.
There are three types of isotope separation techniques:
The third type of separation is still experimental; practical separation techniques all depend in some way on the atomic mass. It is therefore generally easier to separate isotopes with a larger relative mass difference. For example, deuterium has twice the mass of ordinary (light) hydrogen and it is generally easier to purify it than to separate uranium-235 from the more common uranium-238. On the other extreme, separation of fissile plutonium-239 from the common impurity plutonium-240, while desirable in that it would allow the creation of gun-type nuclear weapons from plutonium, is generally agreed to be impractical.
Enrichment cascades.
All large-scale isotope separation schemes employ a number of similar stages which produce successively higher concentrations of the desired isotope. Each stage enriches the product of the previous step further before being sent to the next stage. Similarly, the tailings from each stage are returned to the previous stage for further processing. This creates a sequential enriching system called a cascade.
There are two important factors that affect the performance of a cascade. The first is the separation factor, which is a number greater than 1. The second is the number of required stages to get the desired purity.
Commercial materials.
To date, large-scale commercial isotope separation of only three elements has occurred. In each case, the rarer of the two most common isotopes of an element has been concentrated for use in nuclear technology:
Some isotopically purified elements are used in smaller quantities for specialist applications, especially in the semiconductor industry, where purified silicon is used to improve crystal structure and thermal conductivity, and carbon with greater isotopic purity to make diamonds with greater thermal conductivity.
Isotope separation is an important process for both peaceful and military nuclear technology, and therefore the capability that a nation has for isotope separation is of extreme interest to the intelligence community.
Alternatives.
The only alternative to isotope separation is to manufacture the required isotope in its pure form. This may be done by irradiation of a suitable target, but care is needed in target selection and other factors to ensure that only the required isotope of the element of interest is produced. Isotopes of other elements are not so great a problem as they can be removed by chemical means.
This is particularly relevant in the preparation of high-grade plutonium-239 for use in weapons. It is not practical to separate Pu-239 from Pu-240 or Pu-241. Fissile Pu-239 is produced following neutron capture by uranium-238, but further neutron capture will produce Pu-240 which is less fissile and worse, is a fairly strong neutron emitter, and Pu-241 which decays to Am-241, a strong alpha emitter that poses self-heating and radiotoxicity problems. Therefore, the uranium targets used to produce military plutonium must be irradiated for only a short time, to minimise the production of these unwanted isotopes. Conversely, blending plutonium with Pu-240 renders it less suitable for nuclear weapons.
Practical methods of separation.
Diffusion.
Often done with gases, but also with liquids, the diffusion method relies on the fact that in thermal equilibrium, two isotopes with the same energy will have different average velocities. The lighter atoms (or the molecules containing them) will travel more quickly and be more likely to diffuse through a membrane. The difference in speeds is proportional to the square root of the mass ratio, so the amount of separation is small and many cascaded stages are needed to obtain high purity. This method is expensive due to the work needed to push gas through a membrane and the many stages necessary.
The first large-scale separation of uranium isotopes was achieved by the United States in large gaseous diffusion separation plants at Oak Ridge Laboratories, which were established as part of the Manhattan Project. These used uranium hexafluoride gas as the process fluid. Nickel powder and electro-deposited nickel mesh diffusion barriers were pioneered by Edward Adler and Edward Norris. See gaseous diffusion.
Centrifugal.
Centrifugal schemes rapidly rotate the material allowing the heavier isotopes to go closer to an outer radial wall. This too is often done in gaseous form using a Zippe-type centrifuge.
The centrifugal separation of isotopes was first suggested by Aston and Lindemann in 1919 and the first successful experiments were reported by Beams and Haynes on isotopes of chlorine in 1936. However attempts to use the technology during the Manhattan project were unproductive. In modern times it is the main method used throughout the world to enrich uranium and as a result remains a fairly secretive process, hindering a more widespread uptake of the technology. In general a feed of UF6 gas is connected to a cylinder that is rotated at high speed. Near the outer edge of the cylinder heavier gas molecules containing U-238 collect, while molecules containing U-235 concentrate at the center and are then fed to another cascade stage. Use of gaseous centrifugal technology to enrich isotopes is desirable as power consumption is greatly reduced when compared to more conventional techniques such as diffusion plants since fewer cascade steps are required to reach similar degrees of separation. In fact, gas centrifuges using uranium hexafluoride have largely replaced gaseous diffusion technology for uranium enrichment. As well as requiring less energy to achieve the same separation, far smaller scale plants are possible, making them an economic possibility for a small nation attempting to produce a nuclear weapon. Pakistan is believed to have used this method in developing its nuclear weapons.
Vortex tubes were used by South Africa in their Helikon vortex separation process. The gas is injected tangentially into a chamber with special geometry that further increases its rotation to a very high rate, causing the isotopes to separate. The method is simple because vortex tubes have no moving parts, but energy intensive, about 50 times greater than gas centrifuges. A similar process, known as "jet nozzle", was created in Germany, with a demonstration plant built in Brazil, and they went as far as developing a site to fuel the country's nuclear plants.
Electromagnetic.
This method is a form of mass spectrometry, and is sometimes referred to by that name. It uses the fact that charged particles are deflected in a magnetic field and the amount of deflection depends upon the particle's mass. It is very expensive for the quantity produced, as it has an extremely low throughput, but it can allow very high purities to be achieved. This method is often used for processing small amounts of pure isotopes for research or specific use (such as isotopic tracers), but is impractical for industrial use.
At Oak Ridge and at the University of California, Berkeley, Ernest O. Lawrence developed electromagnetic separation for much of the uranium used in the first United States atomic bomb (see Manhattan Project). Devices using his principle are named calutrons. After the war the method was largely abandoned as impractical. It had only been undertaken (along with diffusion and other technologies) to guarantee there would be enough material for use, whatever the cost. Its main eventual contribution to the war effort was to further concentrate material from the gaseous diffusion plants to even higher levels of purity.
Laser.
In this method a laser is tuned to a wavelength which excites only one isotope of the material and ionizes those atoms preferentially. The resonant absorption of light for an isotope is dependent upon its mass and certain hyperfine interactions between electrons and the nucleus, allowing finely tuned lasers to interact with only one isotope. After the atom is ionized it can be removed from the sample by applying an electric field. This method is often abbreviated as AVLIS (atomic vapor laser isotope separation). This method has only recently been developed as laser technology has improved, and is currently not used extensively. However, it is a major concern to those in the field of nuclear proliferation because it may be cheaper and more easily hidden than other methods of isotope separation. Tunable lasers used in AVLIS include the dye laser and more recently diode lasers.
A second method of laser separation is known as molecular laser isotope separation (MLIS). In this method, an infrared laser is directed at uranium hexafluoride gas, exciting molecules that contain a U-235 atom. A second laser frees a fluorine atom, leaving uranium pentafluoride which then precipitates out of the gas. Cascading the MLIS stages is more difficult than with other methods because the UF5 must be refluorinated (back to UF6) before being introduced into the next MLIS stage. Alternative MLIS schemes are currently being developed (using a first laser in the near-infrared or visible region) where an enrichment of over 95% can be obtained in a single stage, but the methods have not (yet) reached industrial feasibility. This method is called OP-IRMPD (Overtone Pre-excitation—IR Multiple Photon Dissociation).
Finally, the SILEX process, developed by Silex Systems in Australia, has recently been licensed to General Electric for the development of a pilot enrichment plant. The method uses uranium hexafluoride as a feedstock, and uses magnets to separate the isotopes after one isotope is preferentially ionized. Further details of the process are not disclosed.
Quite recently yet another scheme has been proposed for the deuterium separation using Trojan wavepackets in circularly polarized electromagnetic field. The process of Trojan wave packet formation by the adiabatic-rapid passage depends in ultra-sensitive way on the reduced electron and nucleus mass which with the same field frequency further leads to excitation of Trojan or anti-Trojan wavepacket depending on the kind of the isotope. Those and their giant, rotating electric dipole moments are then formula_1-shifted in phase and the beam of such atoms splits in the gradient of the electric field in the analogy to Stern–Gerlach experiment.
Chemical methods.
Although isotopes of a single element are normally described as having the same chemical properties, this is not strictly true. In particular, reaction rates are very slightly affected by atomic mass.
Techniques using this are most effective for light atoms such as hydrogen. Lighter isotopes tend to react or evaporate more quickly than heavy isotopes, allowing them to be separated. This is how heavy water is produced commercially, see Girdler sulfide process for details. Lighter isotopes also disassociate more rapidly under an electric field. This process in a large cascade was used at the heavy water production plant at Rjukan.
One candidate for the largest kinetic isotopic effect ever measured at room temperature, 305, may eventually be used for the separation of tritium (T). The effects for the oxidation of triated formate anions to HTO were measured as:
Gravity.
Isotopes of carbon, oxygen, and nitrogen can be purified by chilling these gases or compounds nearly to their liquification temperature in very tall () columns. The heavier isotopes sink and the lighter isotopes rise, where they are easily collected. The process was developed in the late 1960s by scientists at Los Alamos National Laboratory. This process is also called "cryogenic distillation".
The SWU (separative work unit).
Separative Work Unit (SWU) is a complex unit which is a function of the amount of uranium processed and the degree to which it is enriched, "i.e." the extent of increase in the concentration of the U-235 isotope relative to the remainder.
The unit is strictly: Kilogram Separative Work Unit, and it measures the quantity of separative work (indicative of energy used in enrichment) when feed and product quantities are expressed in kilograms. The effort expended in separating a mass "F" of feed of assay "xf" into a mass "P" of product assay xp and waste of mass "W" and assay "xw" is expressed in terms of the number of separative work units needed, given by the expression SWU = "WV"("xw") + "PV"("xp") - "FV"("xf"), where "V"("x") is the "value function," defined as "V"("x") = (1 - 2"x") ln ((1 - "x") /"x").
Separative work is expressed in SWUs, kg SW, or kg UTA (from the German "Urantrennarbeit" )
If, for example, you begin with 100 kilograms (220 pounds) of natural uranium, it takes about 60 SWU to produce 10 kilograms (22 pounds) of uranium enriched in U-235 content to 4.5%
Isotope separators for research.
Radioactive beams of specific isotopes are widely used in the fields of experimental physics, biology and materials science. The production and formation of these radioactive atoms into an ionic beam for study is an entire field of research carried out at many laboratories throughout the world. The first isotope separator was developed at the Copenhagen Cyclotron by Bohr and co-workers using the principle of electromagnetic separation. Today, there are many laboratories around the world which supply beams of radioactive ions for use. Arguably the principal Isotope Separator On-Line (ISOL) is ISOLDE at CERN, which is a joint European facility spread across the Franco-Swiss border near the city of Geneva. This laboratory uses mainly proton spallation of uranium carbide targets to produce a wide range of radioactive fission fragments that are not found naturally on earth. During spallation (bombardment with high energy protons), a uranium carbide target is heated to several thousand degrees so that radioactive atoms produced in the nuclear reaction are released. Once out of the target, the vapour of radioactive atoms travels to an ionizer cavity. This ionizer cavity is a thin tube made of a refractory metal with a high work function allowing for collisions with the walls to liberate a single electron from a free atom (surface ionization effect). Once ionized, the radioactive species are accelerated by an electrostatic field and injected into an electromagnetic separator. As ions entering the separator are of approximately equal energy, those ions with a smaller mass will be deflected by the magnetic field by a greater amount than those with a heavier mass. This differing radius of curvature allows for isobaric purification to take place. Once purified isobarically, the ion beam is then sent to the individual experiments. In order to increase the purity of the isobaric beam, laser ionization can take place inside the ionizer cavity to selectively ionize a single element chain of interest. At CERN, this device is called the Resonance Ionization Laser Ion Source (RILIS). Currently over 60% of all experiments opt to use the RILIS to increase the purity of radioactive beams.
Beam production capability of ISOL facilities.
As the production of radioactive atoms by the ISOL technique depends on the free atom chemistry of the element to be studied, there are certain beams which cannot be produced by simple proton bombardment of thick actinide targets. Refractory metals such as tungsten and rhenium do not emerge from the target even at high temperatures due to their low vapour pressure. In order to produce these types of beams, a thin target is required. The Ion Guide Isotope Separator On Line (IGISOL) technique was developed in 1981 at the University of Jyvaskyla cyclotron laboratory in Finland. In this technique, a thin uranium target is bombarded with protons and nuclear reaction products recoil out of the target in a charged state. The recoils are stopped in a gas cell and then exit through a small hole in the side of the cell where they are accelerated electrostatically and injected into a mass separator. This method of production and extraction takes place on a shorter timescale compared to the standard ISOL technique and isotopes with short half-lives (sub millisecond) can be studied using an IGISOL. An IGISOL has also been combined with a laser ion source at the Leuven Isotope Separator On Line (LISOL) in Belgium. Thin target sources generally provide significantly lower quantities of radioactive ions than thick target sources and this is their main drawback.
As experimental nuclear physics progresses, it is becoming more and more important to study the most exotic of radioactive nuclei. In order to do so, more inventive techniques are required to create nuclei with extreme proton/neutron ratios. An alternative to the ISOL techniques described here is that of fragmentation beams, where the radioactive ions are produced by fragmentation reactions on a fast beam of stable ions impinging on a thin target (usually of beryllium atoms). This technique is used, for example, at the National Superconducting Cyclotron Laboratory (NSCL) at Michigan State University and at the Radioactive Isotope Beam Factory (RIBF) at RIKEN, in Japan.

</doc>
<doc id="37201" url="https://en.wikipedia.org/wiki?curid=37201" title="Larry Gelbart">
Larry Gelbart

Lawrence Simon "Larry" Gelbart (February 25, 1928 – September 11, 2009) was an American television writer, playwright, screenwriter and author, most famous as a creator and producer of the record-breaking hit TV show "M*A*S*H".
Biography.
Early life.
Gelbart was born in Chicago, Illinois, to Jewish immigrants Harry Gelbart, "a barber since his half of a childhood in Latvia," and Frieda Sturner, who migrated to America from Dąbrowa Górnicza, Poland. Marcia Gelbart Walkenstein was his sister.
His family later moved to Los Angeles and he attended Fairfax High School. Drafted shortly after World War Two, Gelbart worked for the Armed Forces Radio Service in Los Angeles.
Television.
Gelbart began as a writer at the age of sixteen for Danny Thomas's radio show after his father, who was Thomas's barber, showed Thomas some jokes Gelbart had written. During the 1940s Gelbart also wrote for Jack Paar and Bob Hope. In the 1950s, his most important work in television involved writing for Red Buttons, for Sid Caesar on "Caesar's Hour", and in Celeste Holm's "Honestly, Celeste!", as well as with writers Mel Tolkin, Michael Stewart, Selma Diamond, Neil Simon, Mel Brooks, Carl Reiner and Woody Allen on two Caesar specials.
In 1972, Gelbart was one of the main forces behind the creation of the television series "M*A*S*H", writing the pilot (for which he received a "Developed for Television by __" credit); then producing, often writing and occasionally directing the series for its first four seasons, from 1972 to 1976. "M*A*S*H" earned Gelbart a Peabody Award and an Emmy for Outstanding Comedy Series and went on to considerable commercial and critical success.
Films.
Gelbart's best known screen work is perhaps the screenplay for 1982's "Tootsie", which he co-wrote with Murray Schisgal. He was nominated for an Academy Award for that script, and also was Oscar-nominated for his original screenplay for 1977's "Oh, God!" starring John Denver and George Burns.
He collaborated with Burt Shevelove on the screenplay for the 1966 British film "The Wrong Box". Gelbart also co-wrote the golden-era film spoof "Movie Movie" (1978) starring George C. Scott in dual roles, the racy comedy "Blame It on Rio" (1984) starring Michael Caine and the 2000 remake of "Bedazzled" with Elizabeth Hurley and Brendan Fraser.
His script for "Rough Cut" (1980), a caper film starring Burt Reynolds, Lesley-Anne Down and David Niven, was credited under the pseudonym Francis Burns.
Gelbart-scripted films for television included "Barbarians at the Gate" (1993), a true story about the battle for control of the RJR Nabisco corporation starring James Garner that was based on the best-selling book of that name; the original comedy "Weapons of Mass Distraction" (1997) starring Ben Kingsley and Gabriel Byrne as rival media moguls; and "And Starring Pancho Villa as Himself" (2003) starring Antonio Banderas as the Mexican revolutionary leader.
Broadway.
Gelbart co-wrote the long-running Broadway musical farce "A Funny Thing Happened on the Way to the Forum" with Burt Shevelove and Stephen Sondheim in 1962. After the show received poor reviews and box-office returns during its previews in Washington, D.C., rewrites and restaging helped; it was a smash Broadway hit and ran for 964 performances. Its book won a Tony Award. A film version starring Zero Mostel and directed by Richard Lester, was released in 1966. Gelbart was critical of the movie, as most of his and Shevelove's libretto was largely rewritten.
Gelbart's other Broadway credits include the musical "City of Angels", which won him the Drama Desk Award for Outstanding Book of a Musical and an Edgar Award. He also wrote the Iran-contra satire "Mastergate", as well as "Sly Fox" and a musical adaptation of the Preston Sturges movie "Hail the Conquering Hero", whose grueling development inspired Gelbart to utter what evolved into the classic quip, "If Hitler is alive, I hope he's out of town with a musical."
Memoirs.
In 1997, Gelbart published his memoir, "Laughing Matters: On Writing M*A*S*H, Tootsie, Oh, God! and a Few Other Funny Things".
Blogger.
Gelbart was a contributing blogger at The Huffington Post, and also was a regular participant on the alt.tv.mash Usenet newsgroup as "Elsig".
Honors.
In 1995, a Golden Palm Star on the Palm Springs, California, Walk of Stars was dedicated to him.
He won an Emmy Award for Outstanding Comedy Series in 1974 for "M*A*S*H".
In 2002, Gelbart was inducted into the American Theatre Hall of Fame.
In 2008, he was inducted into the Television Hall of Fame.
Death.
Gelbart was diagnosed with cancer in June and died at his Beverly Hills home on September 11, 2009. His wife of 53 years, Pat Gelbart, said that after being married for so long, "we finished each other's sentences." She declined to specify the type of cancer he had. He was buried at the Hillside Memorial Park Cemetery in Culver City, California.
"M*A*S*H" episodes.
The following is a list of "M*A*S*H" episodes (42 Total) written and/or directed by Gelbart.

</doc>
<doc id="37206" url="https://en.wikipedia.org/wiki?curid=37206" title="Robert Watson-Watt">
Robert Watson-Watt

Sir Robert Alexander Watson-Watt, KCB, FRS, FRAeS (13 April 1892 – 5 December 1973) was a pioneer and significant contributor to the development of radar. Radar was initially nameless and researched elsewhere but it was greatly expanded on 1 September 1936 when Watson-Watt became Superintendent of a new establishment under the Air Ministry, Bawdsey Research Station near Felixstowe, Suffolk. Work there resulted in the design and installation of aircraft detection and tracking stations called Chain Home along the east and south coasts of England in time for the outbreak of the Second World War in 1939. This system provided the vital advance information that helped the Royal Air Force win the Battle of Britain.
Early years.
Born in Brechin, Angus, Scotland, on 13 April 1892 Watson-Watt (the hyphenated name is used herein for consistency, although this was not adopted until 1942) was a descendant of James Watt, the famous engineer and inventor of the practical steam engine. After attending Damacre Primary School and Brechin High School, he was accepted to University College, Dundee (then part of the University of St Andrews but became the University of Dundee in 1967). Watt had a successful time as a student, winning the Carnelley Prize for Chemistry and a class medal for Ordinary Natural Philosophy in 1910.
He graduated with a BSc in engineering in 1912, and was offered an assistantship by Professor William Peddie, the holder of the Chair of Physics at University College, Dundee from 1907 to 1942. It was Peddie who encouraged Watson-Watt to study radio, or "wireless telegraphy" as it was then known and who took him through what was effectively a postgraduate class of one on the physics of radio frequency oscillators and wave propagation. At the start of the Great War Watson-Watt was working as an assistant in the College's Engineering Department.
Early experiments.
In 1916 Watson-Watt wanted a job with the War Office, but nothing obvious was available in communications. Instead he joined the Meteorological Office, which was interested in his ideas on the use of radio for the detection of thunderstorms. Lightning gives off a radio signal as it ionizes the air, and his goal was to detect this signal to warn pilots of approaching thunderstorms. The signal occurs across a wide range of frequencies, and could be easily detected and amplified by naval longwave sets, in fact, lightning was a major problem for communications at these common wavelengths.
His early experiments were successful in detecting the signal and he quickly proved to be able to do so at ranges up to 2,500 km. However, there was some difficulty in determining location. This was accomplished by rotating a loop antenna to maximise (or minimise) the signal, thus "pointing" to the storm. However, the strikes were so fleeting that it was very difficult to turn the antenna in time to positively locate one. Instead, the operator would listen to many strikes and develop a rough average location.
At first, he worked at the Wireless Station of Air Ministry Meteorological Office in Aldershot, Hampshire. In 1924 when the War Department gave notice that they wished to re-occupy their Aldershot site, he moved to Ditton Park near Slough, Berkshire. The National Physical Laboratory (NPL) was already using this site and had two main devices that would prove pivotal to his work.
The first was an Adcock antenna, an arrangement of four masts that allowed the signal to be directed through phase differences. Using these as two separate loop antennas at right angles, one could make a simultaneous measurement of the lightning's direction in two axes. However, displaying the fleeting signals was a problem. This was solved by the second device, the WE-224 oscilloscope, recently acquired from Bell Labs. By feeding the signals from the two antennas into the X and Y channels of the oscilloscope, a single strike caused the appearance of a line on the display, indicating the direction of the strike. The scope's relatively "slow" phosphor allowed the signal to be read long after the strike had occurred. Watt's new system was being used in 1926 and was the topic of an extensive paper by Watt and Herd.
The Met and NPL radio teams were amalgamated in 1927 to form the Radio Research Station with Watt as director. Continuing research throughout, the teams had become interested in the causes of "static" radio signals, and found that much could be explained by distant signals located over the horizon being reflected off the upper atmosphere. This was the first direct indication of the reality of the Heaviside layer, proposed earlier but at this time largely dismissed by engineers. To determine the altitude of the layer, Watt, Appleton and others developed the 'squegger' to develop a 'time base' display, which would cause the oscilloscope's dot to move smoothly across the display at very high speed. By timing the squegger so that the dot arrived at the far end of the display at the same time as expected signals reflected off the Heaviside layer, the altitude of the layer could be determined. This time base circuit was key to the development of radar.
After a further reorganization in 1933, Watt became Superintendent of the Radio Department of NPL in Teddington.
RADAR.
The air defence problem.
During the First World War, the Germans had used Zeppelins as long-range bombers over London and other cities and defences had struggled to counter the threat. Since that time aircraft capabilities had improved considerably and the prospect of widespread aerial bombardment of civilian areas was causing the government anxiety. Heavy bombers were now able to approach at altitudes that anti-aircraft guns of the day were unable to reach. With enemy airfields across the English Channel potentially only 20 minutes’ flying-time away, bombers would have dropped their bombs and be returning to base before any intercepting fighters could get to altitude. The only answer seemed to be to have standing patrols of fighters in the air at all times but, with the limited cruising time of a fighter, this would require a huge air force. An alternative solution was urgently needed and in 1934, the Air Ministry set up a committee, the CSSAD (Committee for the Scientific Survey of Air Defence), chaired by Sir Henry Tizard to find ways to improve air defence in the UK.
Nazi Germany was rumoured to have a "death ray" using radio waves that was capable of destroying towns, cities and people. In January 1935, H.E. Wimperis, Director of Scientific Research at the Air Ministry, asked Watson-Watt about the possibility of building their version of a death-ray, specifically to be used against aircraft. Watson-Watt quickly returned a calculation carried out by his colleague, Arnold Wilkins, showing that the device was impossible to construct, and fears of a Nazi version soon vanished. However, he also mentioned in the same report a suggestion that was originally made to him by Wilkins, who had recently heard of aircraft disturbing shortwave communications, that radio waves may be capable of detecting aircraft: "Meanwhile attention is being turned to the still difficult, but less unpromising, problem of radio detection and numerical considerations on the method of detection by reflected radio waves will be submitted when required." Wilson's idea, checked by Watt, was promptly presented by Tizard to the CSSAD on January 28.
Aircraft detection and location.
On 12 February 1935, Watson-Watt sent the secret memo of the proposed system to the Air Ministry, "Detection and location of aircraft by radio methods". Although not as exciting as a death-ray, the concept clearly had potential but the Air Ministry, before giving funding, asked for a demonstration proving that radio waves could be reflected by an aircraft. This was ready by 26 February and consisted of two receiving antennas located about away from one of the BBC's shortwave broadcast stations at Daventry. The two antennas were phased such that signals travelling directly from the station cancelled themselves out, but signals arriving from other angles were admitted, thereby deflecting the trace on a CRT indicator (passive radar). Such was the secrecy of this test that only three people witnessed it: Watson-Watt, his colleague Arnold Wilkins, and a single member of the committee, A. P. Rowe. The demonstration was a success; on several occasions a clear signal was seen from a Handley Page Heyford bomber being flown around the site. Most importantly, the Prime Minister, Stanley Baldwin, was kept quietly informed of radar's progress. On 2 April 1935, Watson-Watt received a patent on a radio device for detecting and locating an aircraft.
In mid-May 1935, Wilkins left the Radio Research Station with a small party, including Edward George Bowen, to start further research at Orford Ness, an isolated peninsula on the Suffolk coast of the North Sea. By June they were detecting aircraft at a distance of , which was enough for scientists and engineers to stop all work on competing sound-based detection systems. By the end of the year the range was up to , at which point plans were made in December to set up five stations covering the approaches to London.
One of these stations was to be located on the coast near Orford Ness, and Bawdsey Manor was selected to become the main centre for all radar research. In an effort to put a radar defence in place as quickly as possible, Watson-Watt and his team created devices using existing available components, rather than creating new components for the project, and the team did not take additional time to refine and improve the devices. So long as the prototype radars were in workable condition they were put into production. They soon conducted "full scale" tests of a fixed radar radio tower system that would soon be known as Chain Home, an early detection system that attempted to detect an incoming bomber by radio signals. The tests were a complete failure, with the fighter only seeing the bomber after it had passed its target. The problem was not the radar, but the flow of information from trackers from the Observer Corps to the fighters, which took many steps and was very slow. Henry Tizard with Patrick Blackett and Hugh Dowding immediately set to work on this problem, designing a 'command and control air defence reporting system' with several layers of reporting that were eventually sent to a single large room for mapping. Observers watching the maps would then tell the fighter groups what to do via direct communications.
By 1937 the first three stations were ready, and the associated system was put to the test. The results were encouraging, and an immediate order by the government to commission an additional 17 stations was given, resulting in a chain of fixed radar towers along the east and south coast of England. By the start of the Second World War, 19 were ready to play a key part in the Battle of Britain, and by the end of the war over 50 had been built. The Germans were aware of the construction of Chain Home but were not sure of its purpose. They tested their theories with a flight of the Zeppelin LZ 130, but concluded the stations were a new long-range naval communications system.
As early as 1936, it was realized that the Luftwaffe would turn to night bombing if the day campaign did not go well, and Watson-Watt had put another of the staff from the Radio Research Station, Edward Bowen, in charge of developing a radar that could be carried by a fighter. Night time visual detection of a bomber was good to about 300 m, and the existing Chain Home systems simply did not have the accuracy needed to get the fighters that close. Bowen decided that an airborne radar should not exceed 90 kg (200 lb) in weight, 8 ft³ (230 L) in volume, and require no more than 500 watts of power. To reduce the drag of the antennas the operating wavelength could not be much greater than one m, difficult for the day's electronics. "AI" - Airborne Interception, was perfected by 1940, and was instrumental in eventually ending the Blitz of 1941. Bowen also fitted airborne radar to maritime patrol aircraft (known in this application as "ASV" - Air to Surface Vessel) and this eventually reduced the threat from submarines.
Watson-Watt justified his choice of a non-optimal frequency for his radar with his often-quoted “cult of the imperfect,” which he stated as “Give them the third-best to go on with; the second-best comes too late, the best never comes.”
Civil Service trade union activities.
Between 1934 and 1936, Watson-Watt was president of the Institution of Professional Civil Servants, now a part of Prospect, the "union for professionals". The union speculates that at this time he was involved in campaigning for an improvement in pay for Air ministry staff.
Contribution to Second World War.
In his "English History 1914–1945", historian A. J. P. Taylor paid the highest of praise to Watson-Watt, Sir Henry Tizard and their associates who developed and put in place radar, crediting them with being fundamental to victory in the Second World War.
In July 1938 Watson-Watt left Bawdsey Manor and took up the post of Director of Communications Development (DCD-RAE). In 1939 Sir George Lee took over the job of DCD, and Watson-Watt became Scientific Advisor on Telecommunications (SAT) to the Ministry of Aircraft Production, travelling to the USA in 1941 to advise them on the severe inadequacies of their air defence efforts illustrated by the Pearl Harbor attack. He was knighted in 1942.
Ten years after his knighthood, Watson-Watt was awarded £50,000 by the UK government for his contributions in the development of radar. He established a practice as a consulting engineer. In the 1950s he moved to Canada and later he lived in the USA, where he published "Three Steps to Victory" in 1958. Around 1958 he appeared as a mystery challenger on the American television programme "To Tell The Truth".
Watson-Watt reportedly was pulled over for speeding in Canada by a radar gun-toting policeman. His remark was, "Had I known what you were going to do with it I would never have invented it!" He wrote an ironic poem ("Rough Justice") afterwards:
Pity Sir Robert Watson-Watt,
And thus, with others I can mention,
His magical all-seeing eye
but now by some ironic twist
and bites, no doubt with legal wit,
Legacy.
On 3 September 2014 a statue of Sir Robert was unveiled in Brechin by HRH the Princess Royal.
On 4 September Watson-Watt featured in the BBC Two drama "Castles in the Sky", with Eddie Izzard in the role. Reviewing the film "The Daily Telegraph" concluded: "Overall, it all felt a bit worthy. This was history that everybody should know, but the erection of a statue might have done the job just as well."
A collection of some of the correspondence and papers of Watson-Watt is held by the National Library of Scotland. A collection of papers relating to Watson-Watt is also held by Archive Services at the University of Dundee.
Family life.
Watson-Watt was married on 20 July 1916 in Hammersmith, London to Margaret Robertson, the daughter of a draughtsman; they later divorced and he remarried in 1952 in Canada. His second wife was Jean Wilkinson, who died in 1964. He returned to Scotland in the 1960s. 
In 1966, at the age of 74, he proposed to Dame Katherine Trefusis Forbes, who was 67 years old at the time and had also played a significant role in the Battle of Britain as the founding Air Commander of the Women's Auxiliary Air Force, which supplied the radar-room operatives. They lived together in London in the winter, and at "The Observatory" – Trefusis Forbes' summer home in Pitlochry, Perthshire, during the warmer months. They remained together until her death in 1971. Watson-Watt died in 1973, aged 81, in Inverness. Both are buried in the churchyard of the Episcopal Church of the Holy Trinity at Pitlochry.

</doc>
<doc id="37207" url="https://en.wikipedia.org/wiki?curid=37207" title="Nuclear engineering">
Nuclear engineering

Nuclear engineering is the branch of engineering concerned with the application of the breakdown (fission) as well as the fusion of atomic nuclei and/or the application of other sub-atomic physics, based on the principles of nuclear physics. In the sub-field of nuclear fission, it particularly includes the interaction and maintenance of systems and components like nuclear reactors, nuclear power plants, and/or nuclear weapons. The field also includes the study of medical and other applications of (generally ionizing) radiation, nuclear safety, heat/thermodynamics transport, nuclear fuel and/or other related technology (e.g., radioactive waste disposal), and the problems of nuclear proliferation.
Professional areas.
The United States generates about 18% of its electricity from nuclear power plants. Nuclear engineers in this field generally work, directly or indirectly, in the nuclear power industry or for national laboratories. Current research in the industry is directed at producing economical, proliferation-resistant reactor designs with passive safety features. Although government labs research the same areas as industry, they also study a myriad of other issues such as nuclear fuels and nuclear fuel cycles, advanced reactor designs, and nuclear weapon design and maintenance. A principal pipeline for trained personnel for US reactor facilities is the Navy Nuclear Power Program. The job outlook for nuclear engineering from the year 2012 to the year 2022 is predicted to grow 9% due to many elder nuclear engineers retiring, safety systems needing to be updated in power plants, and the advancements made in nuclear medicine.
Nuclear medicine and medical physics.
An important field is medical physics, and its subfields nuclear medicine, radiation therapy, health physics, and diagnostic imaging. From x-ray machines to MRI to PET, among many others, medical physics provides most of modern medicine's diagnostic capability along with providing many treatment options. 
Nuclear materials.
Nuclear materials research focuses on two main subject areas, nuclear fuels and irradiation-induced modification of materials. Improvement of three nuclear fuels is crucial for obtaining increased efficiency from nuclear reactors. Irradiation effects studies have many purposes, from studying structural changes to reactor components to studying nano-modification of metals using ion-beams or particle accelerators.
Radiation protection and measurement.
Radiation measurement is fundamental to the science and practice of radiation protection, sometimes known as radiological protection, which is the protection of people and the environment from the harmful effects of ionizing radiation
Nuclear engineers and radiological scientists are interested in the development of more advanced ionizing radiation measurement and detection systems, and using these to improve imaging technologies. This includes detector design, fabrication and analysis, measurements of fundamental atomic and nuclear parameters, and radiation imaging systems, among other things.

</doc>
<doc id="37208" url="https://en.wikipedia.org/wiki?curid=37208" title="Landslide">
Landslide

A landslide, also known as a landslip, is a form of mass wasting that includes a wide range of ground movements, such as rockfalls, deep failure of slopes, and shallow debris flows. Landslides can occur in underwater, called a submarine landslide, coastal and onshore environments. Although the action of gravity is the primary driving force for a landslide to occur, there are other contributing factors affecting the original slope stability. Typically, pre-conditional factors build up specific sub-surface conditions that make the area/slope prone to failure, whereas the actual landslide often requires a trigger before being released. Landslides should not be confused with mud flows, a form of mass wasting involving very to extremely rapid flow of debris that has become partially or fully liquified by the addition of significant amounts of water to the source material.
Causes.
Landslides occur when the stability of the slope changes from a stable to an unstable condition. A change in the stability of a slope can be caused by a number of factors, acting together or alone. Natural causes of landslides include:
Landslides are aggravated by human activities, such as
Types.
Debris flow.
Slope material that becomes saturated with water may develop into a debris flow or mud flow. The resulting slurry of rock and mud may pick up trees, houses and cars, thus blocking bridges and tributaries causing flooding along its path.
Debris flow is often mistaken for flash flood, but they are entirely different processes.
Muddy-debris flows in alpine areas cause severe damage to structures and infrastructure and often claim human lives.
Muddy-debris flows can start as a result of slope-related factors and shallow landslides can dam stream beds, resulting in temporary water blockage. As the impoundments fail, a "domino effect" may be created, with a remarkable growth in the volume of the flowing mass, which takes up the debris in the stream channel. The solid-liquid mixture can reach densities of up to 2 tons/m³ and velocities of up to 14 m/s (Chiarle and Luino, 1998; Arattano, 2003). These processes normally cause the first severe road interruptions, due not only to deposits accumulated on the road (from several cubic metres to hundreds of cubic metres), but in some cases to the complete removal of bridges or roadways or railways crossing the stream channel. Damage usually derives from a common underestimation of mud-debris flows: in the alpine valleys, for example, bridges are frequently destroyed by the impact force of the flow because their span is usually calculated only for a water discharge. For a small basin in the Italian Alps (area = 1.76 km²) affected by a debris flow, Chiarle and Luino (1998) estimated a peak discharge of 750 m3/s for a section located in the middle stretch of the main channel. At the same cross section, the maximum foreseeable water discharge (by HEC-1), was 19 m³/s, a value about 40 times lower than that calculated for the debris flow that occurred.
Earthflows.
Earthflows are downslope, viscous flows of saturated, fine-grained materials, which move at any speed from slow to fast. Typically, they can move at speeds from . Though these are a lot like mudflows, overall they are more slow moving and are covered with solid material carried along by flow from within. They are different from fluid flows because they are more rapid. Clay, fine sand and silt, and fine-grained, pyroclastic material are all susceptible to earthflows. The velocity of the earthflow is all dependent on how much water content is in the flow itself: if there is more water content in the flow, the higher the velocity will be.
These flows usually begin when the pore pressures in a fine-grained mass increase until enough of the weight of the material is supported by pore water to significantly decrease the internal shearing strength of the material. This thereby creates a bulging lobe which advances with a slow, rolling motion. As these lobes spread out, drainage of the mass increases and the margins dry out, thereby lowering the overall velocity of the flow. This process causes the flow to thicken. The bulbous variety of earthflows are not that spectacular, but they are much more common than their rapid counterparts. They develop a sag at their heads and are usually derived from the slumping at the source.
Earthflows occur much more during periods of high precipitation, which saturates the ground and adds water to the slope content. Fissures develop during the movement of clay-like material which creates the intrusion of water into the earthflows. Water then increases the pore-water pressure and reduces the shearing strength of the material.
Debris landslide.
A debris slide is a type of slide characterized by the chaotic movement of rocks, soil, and debris mixed with water and/or ice. They are usually triggered by the saturation of thickly vegetated slopes which results in an incoherent mixture of broken timber, smaller vegetation and other debris. Debris avalanches differ from debris slides because their movement is much more rapid. This is usually a result of lower cohesion or higher water content and commonly steeper slopes.
Steep coastal cliffs can be caused by catastrophic debris avalanches. These have been common on the submerged flanks of ocean island volcanos such as the Hawaiian Islands and the Cape Verde Islands.
Another slip of this type was Storegga landslide.
Movement: Debris slides generally start with big rocks that start at the top of the slide and begin to break apart as they slide towards the bottom. This is much slower than a debris avalanche. Debris avalanches are very fast and the entire mass seems to liquefy as it slides down the slope. This is caused by a combination of saturated material, and steep slopes. As the debris moves down the slope it generally follows stream channels leaving a v-shaped scar as it moves down the hill. This differs from the more U-shaped scar of a slump. Debris avalanches can also travel well past the foot of the slope due to their tremendous speed.
Sturzstrom.
A sturzstrom is a rare, poorly understood type of landslide, typically with a long run-out. Often very large, these slides are unusually mobile, flowing very far over a low angle, flat, or even slightly uphill terrain. 
Shallow landslide.
Landslide in which the sliding surface is located within the soil mantle or weathered bedrock (typically to a depth from few decimetres to some metres)is called a shallow landslide. They usually include debris slides, debris flow, and failures of road cut-slopes. Landslides occurring as single large blocks of rock moving slowly down slope are sometimes called block glides.
Shallow landslides can often happen in areas that have slopes with high permeable soils on top of low permeable bottom soils. The low permeable, bottom soils trap the water in the shallower, high permeable soils creating high water pressure in the top soils. As the top soils are filled with water and become heavy, slopes can become very unstable and slide over the low permeable bottom soils. Say there is a slope with silt and sand as its top soil and bedrock as its bottom soil. During an intense rainstorm, the bedrock will keep the rain trapped in the top soils of silt and sand. As the topsoil becomes saturated and heavy, it can start to slide over the bedrock and become a shallow landslide. 
R. H. Campbell did a study on shallow landslides on Santa Cruz Island California. He notes that if permeability decreases with depth, a perched water table may develop in soils at intense precipitation. When pore water pressures are sufficient to reduce effective normal stress to a critical level, failure occurs.
Deep-seated landslide.
Landslides in which the sliding surface is mostly deeply located below the maximum rooting depth of trees (typically to depths greater than ten meters). Deep-seated landslides usually involve deep regolith, weathered rock, and/or bedrock and include large slope failure associated with translational, rotational, or complex movement. This type of landslides are potentially occur in an tectonic active region like Zagros Mountain in Iran. These typically move slowly, only several meters per year, but occasionally move faster. They tend to be larger than shallow landslides and form along a plane of weakness such as a fault or bedding plane. They can be visually identified by concave scarps at the top and steep areas at the toe.
Causing tsunamis.
Landslides that occur undersea, or have impact into water, can generate tsunamis. Massive landslides can also generate megatsunamis, which are usually hundreds of meters high. In 1958, one such tsunami occurred in Lituya Bay in Alaska.
Landslide prediction mapping.
Landslide hazard analysis and mapping can provide useful information for catastrophic loss reduction, and assist in the development of guidelines for sustainable land use planning. The analysis is used to identify the factors that are related to landslides, estimate the relative contribution of factors causing slope failures, establish a relation between the factors and landslides, and to predict the landslide hazard in the future based on such a relationship. The factors that have been used for landslide hazard analysis can usually be grouped into geomorphology, geology, land use/land cover, and hydrogeology. Since many factors are considered for landslide hazard mapping, GIS is an appropriate tool because it has functions of collection, storage, manipulation, display, and analysis of large amounts of spatially referenced data which can be handled fast and effectively. Cardenas reported evidence on the exhaustive use of GIS in conjunction of uncertainty modelling tools for landslide mapping. Remote sensing techniques are also highly employed for landslide hazard assessment and analysis. Before and after aerial photographs and satellite imagery are used to gather landslide characteristics, like distribution and classification, and factors like slope, lithology, and land use/land cover to be used to help predict future events. Before and after imagery also helps to reveal how the landscape changed after an event, what may have triggered the landslide, and shows the process of regeneration and recovery.
Using satellite imagery in combination with GIS and on-the-ground studies, it is possible to generate maps of likely occurrences of future landslides. Such maps should show the locations of previous events as well as clearly indicate the probable locations of future events. In general, to predict landslides, one must assume that their occurrence is determined by certain geologic factors, and that future landslides will occur under the same conditions as past events. Therefore, it is necessary to establish a relationship between the geomorphologic conditions in which the past events took place and the expected future conditions.
Natural disasters are a dramatic example of people living in conflict with the environment. Early predictions and warnings are essential for the reduction of property damage and loss of life. Because landslides occur frequently and can represent some of the most destructive forces on earth, it is imperative to have a good understanding as to what causes them and how people can either help prevent them from occurring or simply avoid them when they do occur. Sustainable land management and development is also an essential key to reducing the negative impacts felt by landslides.
GIS offers a superior method for landslide analysis because it allows one to capture, store, manipulate, analyze, and display large amounts of data quickly and effectively. Because so many variables are involved, it is important to be able to overlay the many layers of data to develop a full and accurate portrayal of what is taking place on the Earth's surface. Researchers need to know which variables are the most important factors that trigger landslides in any given location. Using GIS, extremely detailed maps can be generated to show past events and likely future events which have the potential to save lives, property, and money.
Prehistoric landslides.
A total volume of 3,500km3 debris was involved; comparable to a 34m thick area the size of Iceland. The landslide is thought to be among the largest in history.
Extraterrestrial landslides.
Evidence of past landslides has been detected on many bodies in the solar system, but since most observations are made by probes that only observe for a limited time and most bodies in the solar system appear to be geologically inactive not many landslides are known to have happened in recent times. Both Venus and Mars have been subject to long-term mapping by orbiting satellites, and examples of landslides have been observed on both.

</doc>
