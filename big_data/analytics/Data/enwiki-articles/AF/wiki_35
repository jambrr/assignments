<doc id="32496" url="https://en.wikipedia.org/wiki?curid=32496" title="Vacuum tube">
Vacuum tube

In electronics, a vacuum tube, an electron tube, or just a tube (North America), or valve (Britain and some other regions) is a device that controls electric current between electrodes in an evacuated container.
Vacuum tubes mostly rely on thermionic emission of electrons from a hot filament or a cathode heated by the filament. This type is called a thermionic tube or thermionic valve. A phototube, however, achieves electron emission through the photoelectric effect. Not all electronic circuit valves/electron tubes are vacuum tubes (evacuated); gas-filled tubes are similar devices containing a gas, typically at low pressure, which exploit phenomena related to electric discharge in gases, usually without a heater.
The simplest vacuum tube, the diode, contains only a heater, a heated electron-emitting cathode (the filament itself acts as the cathode in some diodes), and a plate (anode). Current can only flow in one direction through the device between the two electrodes, as electrons emitted by the cathode travel through the tube and are collected by the anode. Adding one or more control grids within the tube allows the current between the cathode and anode to be controlled by the voltage on the grid or grids. 
Tubes with grids can be used for many purposes, including amplification, rectification, switching, oscillation, and display.
Invented in 1904 by John Ambrose Fleming, vacuum tubes were a basic component for electronics throughout the first half of the twentieth century, which saw the diffusion of radio, television, radar, sound reinforcement, sound recording and reproduction, large telephone networks, analog and digital computers, and industrial process control.
Although some applications had counterparts using earlier technologies such as the spark gap transmitter or mechanical computers, it was the invention of the vacuum tube that made these technologies widespread and practical.
In the 1940s the invention of semiconductor devices made it possible to produce solid-state devices, which are smaller, more efficient, more reliable, more durable, and cheaper than tubes.
Hence, from the mid-1950s solid-state devices such as transistors gradually replaced tubes. The cathode-ray tube (CRT) remained the basis for televisions and video monitors until superseded in the 21st century. However, there are still a few applications for which tubes are preferred to semiconductors; for example, the magnetron used in microwave ovens, and certain high frequency amplifiers.
Classifications.
One classification of vacuum tubes is by the number of active electrodes, (neglecting the filament or heater). A device with two active elements is a diode, usually used for rectification. Devices with three elements are triodes used for amplification and switching. Additional electrodes create tetrodes, pentodes, and so forth, which have multiple additional functions made possible by the additional controllable electrodes.
Other classifications are:
Multiple classifications may apply to a device; for example similar dual triodes can be used for audio preamplification and as flip-flops in computers, although linearity is important in the former case and long life in the latter.
Tubes have different functions, such as cathode ray tubes which create a beam of electrons for display purposes (such as the television picture tube) in addition to more specialized functions such as electron microscopy and electron beam lithography. X-ray tubes are also vacuum tubes. Phototubes and photomultipliers rely on electron flow through a vacuum, though in those cases electron emission from the cathode depends on energy from photons rather than thermionic emission. Since these sorts of "vacuum tubes" have functions other than electronic amplification and rectification they are described in their own articles.
Description.
A vacuum tube consists of two or more electrodes in a vacuum inside an airtight enclosure. Most tubes have glass envelopes, though ceramic and metal envelopes (atop insulating bases) have been used. The electrodes are attached to leads which pass through the envelope via an airtight seal. On most tubes, the leads, in the form of pins, plug into a tube socket for easy replacement of the tube (tubes were a frequent cause of failure in electronic equipment, and consumers were expected to be able to replace tubes themselves). Some tubes had an electrode terminating at a top cap. The principal reason for doing this was to avoid leakage resistance through the tube base, particularly for the high impedance grid input. The bases were commonly made with phenolic insulation which performs poorly as an insulator in humid conditions. Other reasons for using a top cap include reduced grid to anode capacitance, improved high-frequency performance, keeping a very high plate voltage away from lower voltages, and accommodating one more electrode than allowed by the base. There was even an occasional design that had two top cap connections.
The earliest vacuum tubes evolved from incandescent light bulbs, containing a filament sealed in an evacuated glass envelope. When hot, the filament releases electrons into the vacuum, a process called thermionic emission. A second electrode, the anode or "plate", will attract those electrons if it is at a more positive voltage. The result is a net flow of electrons from the filament to plate. However, electrons cannot flow in the reverse direction because the plate is not heated and does not emit electrons. The filament ("cathode") has a dual function: it emits electrons when heated; and, together with the plate, it creates an electric field due to the potential difference between them. Such a tube with only two electrodes is termed a diode, and is used for rectification. Since current can only pass in one direction, such a diode (or "rectifier") will convert alternating current (AC) to pulsating DC. This can therefore be used in a DC power supply, and is also used as a demodulator of amplitude modulated (AM) radio signals and similar functions.
Early tubes used the directly heated filament as the cathode. Many more modern tubes employ indirect heating, with a separate electrically isolated "heater" inside a tubular cathode. The heater is not an electrode, but simply serves to heat the cathode sufficiently for thermionic emission of electrons. This allowed all the tubes to be heated through a common circuit (which can as well be AC) while allowing each cathode to arrive at a voltage independently of the others, removing an unwelcome constraint on circuit design.
The filaments require constant and often considerable power, even when amplifying signals at the microwatt level. Power is also dissipated when the electrons from the cathode slam into the anode (plate) and heat it; this can occur even in an idle amplifier due to quiescent currents necessary to ensure linearity and low distortion. In a power amplifier, this heating can be considerable and can destroy the tube if driven beyond its safe limits. Since the tube contains a vacuum, the anodes in most small and medium power tubes are cooled by radiation through the glass envelope. In some special high power applications, the anode forms part of the vacuum envelope to conduct heat to an external heat sink, usually cooled by a blower.
Klystrons and magnetrons often operate their anodes (called collectors in klystrons) at ground potential to facilitate cooling, particularly with water, without high voltage insulation. These tubes instead operate with high negative voltages on the filament and cathode.
Except for diodes, additional electrodes are positioned between the cathode and the plate (anode). These electrodes are referred to as grids as they are not solid electrodes but sparse elements through which electrons can pass on their way to the plate. The vacuum tube is then known as a triode, tetrode, pentode, etc., depending on the number of grids. A triode has three electrodes: the anode, cathode, and one grid, and so on. The first grid, known as the control grid, (and sometimes other grids) transforms the diode into a "voltage-controlled device": the voltage applied to the control grid affects the current between the cathode and the plate. When held negative with respect to the cathode, the control grid creates an electric field which repels electrons emitted by the cathode, thus reducing or even stopping the current between cathode and anode. As long as the control grid is negative relative to the cathode, essentially no current flows into it, yet a change of several volts on the control grid is sufficient to make a large difference in the plate current, possibly changing the output by hundreds of volts (depending on the circuit). The solid-state device which operates most like the pentode tube is the junction field-effect transistor (JFET), although vacuum tubes typically operate at over a hundred volts, unlike most semiconductors in most applications.
History and development.
The 19th century saw increasing research with evacuated tubes, such as the Geissler and Crookes tubes. The many scientists and inventors who experimented with such tubes include Thomas Edison, Eugen Goldstein, Nikola Tesla, and Johann Wilhelm Hittorf. With the exception of early light bulbs, such tubes were only used in scientific research or as novelties. The groundwork laid by these scientists and inventors, however, was critical to the development of subsequent vacuum tube technology.
Although thermionic emission was originally reported in 1873 by Frederick Guthrie, it was Thomas Edison's 1883 investigation that spurred future research, the phenomenon thus becoming known as the "Edison effect". Edison patented what he found, but he did not understand the underlying physics, nor did he have an inkling of the potential value of the discovery. It wasn't until the early 20th century that the rectifying property of such a device was utilized, most notably by John Ambrose Fleming, who used the diode tube to detect (demodulate) radio signals. Lee De Forest's 1906 "audion" was also developed as a radio detector, and soon led to the development of the triode tube. This was essentially the first electronic amplifier, leading to great improvements in telephony (such as the first coast-to-coast telephone line in the US) and revolutionizing the technology used in radio transmitters and receivers. The electronics revolution of the 20th century arguably began with the invention of the triode vacuum tube.
Diodes.
The English physicist John Ambrose Fleming worked as an engineering consultant for firms including Edison Telephone and the Marconi Company. In 1904, as a result of experiments conducted on Edison effect bulbs imported from the USA, he developed a device he called an "oscillation valve" (because it passes current in only one direction). The heated filament, or cathode, was capable of thermionic emission of electrons that would flow to the "plate" (or "anode") when it was at a higher voltage. Electrons, however, could not pass in the reverse direction because the plate was not heated and thus not capable of thermionic emission of electrons.
Later known as the Fleming valve, it could be used as a rectifier of alternating current and as a radio wave detector. This greatly improved the crystal set which rectified the radio signal using an early solid-state diode based on a crystal and a so-called cat's whisker. Unlike modern semiconductors, such a diode required painstaking adjustment of the contact to the crystal in order for it to rectify. The tube was relatively immune to vibration, and thus vastly superior on shipboard duty, particularly for navy ships with the shock of weapon fire commonly knocking the sensitive but delicate galena off its sensitive point (the tube was in general no more sensitive as a radio detector, but was adjustment free). The diode tube was a reliable alternative for detecting radio signals. Higher power diode tubes or "power rectifiers" found their way into power supply applications until they were eventually replaced by silicon rectifiers in the 1960s.
Triodes.
Originally, the only use for tubes in radio circuits was for rectification, not amplification. In 1906, Robert von Lieben filed for a patent for a cathode ray tube which included magnetic deflection. This could be used for amplifying audio signals and was intended for use in telephony equipment. He would later go on to help refine the triode vacuum tube.
However, it was Lee De Forest who is credited with inventing the triode tube in 1907 while continuing experiments to improve his original Audion tube, a crude forerunner of the triode. By placing an additional electrode between the filament (cathode) and plate (anode), he discovered the ability of the resulting device to amplify signals of all frequencies. As the voltage applied to the so-called control grid (or simply "grid") was lowered from the cathode's voltage to somewhat more negative voltages, the amount of current from the filament to the plate would be reduced. The negative electrostatic field created by the grid in the vicinity of the cathode would inhibit thermionic emission and reduce the current to the plate. Thus, a few volts' difference at the grid would make a large change in the plate current and could lead to a much larger voltage change at the plate; the result was voltage and power amplification. In 1907, De Forest filed for a patent for such a three-electrode version of his original Audion tube for use as an electronic amplifier in radio communications. This eventually became known as the triode.
De Forest's device was not a "hard vacuum" tube, as he erroneously believed that it depended on the presence of residual gas remaining after evacuation. In its Audion leaflets, the De Forest company even warned against any operation which might lead to too high a vacuum. In 1912 De Forest brought the audion to Harold Arnold in AT&T's engineering department. Arnold recommended that AT&T purchase the patent. He developed high-vacuum tubes which were tested in the summer of 1913 on AT&T's long distance network.
The Finnish inventor Eric Tigerstedt significantly improved on the original triode design in 1914, while working on his sound-on-film process in Berlin, Germany. Tigerstedt's innovation was to make the electrodes concentric cylinders with the cathode at the centre, thus greatly increasing the collection of emitted electrons at the anode. The first true vacuum triodes in production were the Pliotrons developed by Irving Langmuir at the General Electric research laboratory (Schenectady, New York) in 1915. Langmuir was one of the first scientists to realize that a harder vacuum would improve the amplifying behaviour of the triode, having improved Gaede's diffusion vacuum pump. Pliotrons were closely followed by the French type 'TM' and later the English type 'R' which were in widespread use by the allied military by 1916. These types were the first true hard vacuum tubes; early diodes and triodes performed as such despite a rather high residual gas pressure. Techniques to produce and maintain better vacua in tubes were then developed. Historically, vacuum levels in production vacuum tubes typically ranged from 10 µPa down to 10 nPa.
The triode and its derivatives (tetrodes and pentodes) are transconductance devices, in which the controlling signal applied to the grid is a "voltage", and the resulting amplified signal appearing at the anode is a "current". Compare this to the behavior of the bipolar junction transistor, in which the controlling signal is a current and the output is also a current. For vacuum tubes, transconductance or mutual conductance (gm) is defined as the change in the plate(anode)/cathode current divided by the corresponding change in the grid/cathode voltage, with a constant plate(anode)/cathode voltage. Typical values of gm for a small-signal vacuum tube are 1 to 10 millisiemens. It is one of the three 'constants' of a vacuum tube, the other two being its gain μ and plate resistance Rp or Ra. The Van der Bijl equation defines their relationship as follows: formula_1
The non-linear operating characteristic of the triode caused early tube audio amplifiers to exhibit harmonic distortion at low volumes. Plotting plate current as a function of applied grid voltage, it was seen that there was a range of grid voltages for which the transfer characteristics were approximately linear. To use this range, a negative bias voltage had to be applied to the grid to position the DC operating point in the linear region. This was called the idle condition, and the plate current at this point the "idle current". The controlling voltage was superimposed onto the bias voltage, resulting in a linear variation of plate current in response to both positive and negative variation of the input voltage around that point. This concept is called "grid bias". Many early radio sets had a third battery called the "C battery" (unrelated to the present-day C cell) whose positive terminal was connected to the cathode of the tubes (or "ground" in most circuits) and whose negative terminal supplied this bias voltage to the grids of the tubes. Later circuits, after tubes were made with heaters isolated from their cathodes, used cathode biasing, avoiding the need for a separate negative power supply. However C batteries continued to be included in some equipment even when the "A" and "B" batteries had been replaced by power from the AC mains. That was possible because there was essentially no current draw on these batteries; they could thus last for many years (often longer than all the tubes) without requiring replacement.
When triodes were first used in radio transmitters and receivers, it was found that tuned amplification stages had a tendency to oscillate unless their gain was very limited. This was due to the parasitic capacitance between the plate (the amplifier's output) and the control grid (the amplifier's input), known as the Miller capacitance. Eventually the technique of "neutralization" was developed whereby the RF transformer connected to the plate (anode) would include an additional winding in the opposite phase. This winding would be connected back to the grid through a small capacitor, and when properly adjusted would cancel the Miller capacitance. This technique was employed and led to the success of the Neutrodyne radio during the 1920s.
However, neutralization required careful adjustment and proved unsatisfactory when used over a wide ranges of frequencies.
Tetrodes and pentodes.
To combat the stability problems and limited voltage gain due to the Miller effect, the physicist Walter H. Schottky invented the tetrode tube in 1919. He showed that the addition of a second grid, located between the control grid and the plate (anode), known as the "screen grid", could solve these problems. ("Screen" in this case refers to electrical "screening" or shielding, not physical construction: all "grid" electrodes in between the cathode and plate are "screens" of some sort rather than solid electrodes since they must allow for the passage of electrons directly from the cathode to the plate). A positive voltage slightly lower than the plate (anode) voltage was applied to it, and was bypassed (for high frequencies) to ground with a capacitor. This arrangement decoupled the anode and the control grid, essentially eliminating the Miller capacitance and its associated problems. Consequently, higher voltage gains from a single tube became possible, reducing the number of tubes required in many circuits. This two-grid tube is called a "tetrode", meaning four active electrodes, and was common by 1926.
However, the tetrode had one new problem. In any tube, electrons strike the anode with sufficient energy to cause the emission of electrons from its surface. In a triode this so-called secondary emission of electrons is not important since they are simply re-captured by the more positive anode (plate). But in a tetrode they can be captured by the screen grid (thus also acting as an anode) since it is also at a high voltage, thus robbing them from the plate current and reducing the amplification of the device. Since secondary electrons can outnumber the primary electrons, in the worst case, particularly as the plate voltage dips below the screen voltage, the plate current can decrease with increasing plate voltage. This is the so-called "tetrode kink" and is an example of negative resistance which can itself cause instability. The otherwise undesirable negative resistance was exploited to produce an extremely simple oscillator circuit only requiring connection of the plate to a resonant LC circuit to oscillate; this was effective over a wide frequency range. The so-called dynatron oscillator thus operated on the same principle of negative resistance as the tunnel diode oscillator many years later. Another undesirable consequence of secondary emission is that in extreme cases enough charge can flow to the screen grid to overheat and destroy it. Later tetrodes had anodes treated to reduce secondary emission; earlier ones such as the type 77 sharp-cutoff pentode connected as a tetrode made better dynatrons.
The solution was to add another grid between the screen grid and the main anode, called the suppressor grid (since it suppressed secondary emission current toward the screen grid). This grid was held at the cathode (or "ground") voltage and its negative voltage (relative to the anode) electrostatically repelled secondary electrons so that they would be collected by the anode after all. This three-grid tube is called a pentode, meaning five electrodes. The pentode was invented in 1926 by Bernard D. H. Tellegen and became generally favored over the simple tetrode. Pentodes are made in two classes: those with the suppressor grid wired internally to the cathode (e.g. EL84/6BQ5) and those with the suppressor grid wired to a separate pin for user access (e.g. 803, 837). An alternative solution for power applications is the beam tetrode or "beam power tube", discussed below.
Multifunction and multisection tubes.
Superheterodyne receivers require a local oscillator and mixer, combined in the function of a single pentagrid converter tube. Various alternatives such as using a combination of a triode with a hexode and even an octode have been used for this purpose. The additional grids include both control grids (at a low potential) and screen grids (at a high voltage). Many designs used such a screen grid as an additional anode to provide feedback for the oscillator function, whose current was added to that of the incoming radio frequency signal. The pentagrid converter thus became widely used in AM receivers including the miniature tube version of the "All American Five". Octodes such as the 7A8 were rarely used in the US, but much more common in Europe, particularly in battery operated radios where the lower power consumption was an advantage.
To further reduce the cost and complexity of radio equipment, two separate structures (triode and pentode for instance) could be combined in the bulb of a single "multisection tube". An early example was the Loewe 3NF. This 1920s device had three triodes in a single glass envelope together with all the fixed capacitors and resistors required to make a complete radio receiver. As the Loewe set had only one tube socket, it was able to substantially undercut the competition since, in Germany, state tax was levied by the number of sockets. However, reliability was compromised, and production costs for the tube were much greater. In a sense, these were akin to integrated circuits. In the US, Cleartron briefly produced the "Multivalve" triple triode for use in the Emerson Baby Grand receiver. This Emerson set also had a single tube socket, but because it used a four-pin base, the additional element connections were made on a "mezzanine" platform at the top of the tube base.
By 1940 multisection tubes had become commonplace. There were constraints, however, due to patents and other licensing considerations (see British Valve Association). Constraints due to the number of external pins (leads) often forced the functions to share some of those external connections such as their cathode connections (in addition to the heater connection). The RCA Type 55 was a double diode triode used as a detector, automatic gain control rectifier and audio preamplifier in early AC powered radios. These sets often included the 53 Dual Triode Audio Output. Another early type of multi-section tube, the 6SN7, is a "dual triode" which performs the functions of two triode tubes, while taking up half as much space and costing less.
The 12AX7 is a dual "high mu" (high voltage gain) triode in a miniature enclosure, and became widely used in audio signal amplifiers, instruments, and guitar amplifiers.
The introduction of the miniature tube base (see below) which could have 9 pins, more than previously available, allowed other multi-section tubes to be introduced, such as the 6GH8/ECF82 triode-pentode, quite popular in television receivers. The desire to include even more functions in one envelope resulted in the General Electric Compactron which had 12 pins. A typical example, the 6AG11, contained two triodes and two diodes.
Some otherwise conventional tubes do not fall into standard categories; the 6JH8 had several common grids, followed by a pair of beam deflection electrodes which deflected the current towards either of two anodes. It was sometimes known as the 'sheet beam' tube, and was used in some color TV sets for demodulation of synchronous signals, as for example for color demodulation.
Beam power tubes.
The beam power tube is usually a tetrode with the addition of beam-forming electrodes, which take the place of the suppressor grid. These angled plates (not to be confused with the "anode") focus the electron stream onto certain spots on the anode which can withstand the heat generated by the impact of massive numbers of electrons, while also providing pentode behavior. The positioning of the elements in a beam power tube uses a design called "critical-distance geometry", which minimizes the "tetrode kink", plate to control grid capacitance, screen grid current, and secondary emission from the anode, thus increasing power conversion efficiency. The control grid and screen grid are also wound with the same pitch, or number of wires per inch.
Aligning the grid wires also helps to reduce screen current, which represents wasted energy. This design helps to overcome some of the practical barriers to designing high-power, high-efficiency power tubes. EMI engineers Cabot Bull and Sidney Rodda developed the design which became the 6L6, the first popular beam power tube, introduced by RCA in 1936 and later corresponding tubes in Europe the KT66, KT77 and KT88 made by the Marconi-Osram Valve subsidiary of GEC (the KT standing for "Kinkless Tetrode").
"Pentode operation" of beam power tubes is often described in manufacturers' handbooks and data sheets, resulting in some confusion in terminology.
Variations of the 6L6 design are still widely used in tube guitar amplifiers, making it one of the longest-lived electronic device families in history. Similar design strategies are used in the construction of large ceramic power tetrodes used in radio transmitters.
Beam power tubes can be connected as triodes for improved audio tonal quality but in triode mode deliver significantly reduced power output.
Gas-filled tubes.
Gas-filled tubes such as discharge tubes and cold cathode tubes are not "hard" vacuum tubes, though are always filled with gas at less than sea-level atmospheric pressure. Types such as the voltage-regulator tube and thyratron resemble hard vacuum tubes and fit in sockets designed for vacuum tubes. Their distinctive orange, red, or purple glow during operation indicates the presence of gas; electrons flowing in a vacuum do not produce light within that region. These types may still be referred to as "electron tubes" as they do perform electronic functions. High-power rectifiers use mercury vapor to achieve a lower forward voltage drop than high-vacuum tubes.
Miniature tubes.
Early tubes used a metal or glass envelope atop an insulating bakelite base. In 1938 a technique was developed to use an all-glass construction with the pins fused in the glass base of the envelope. This was used in the design of a much smaller tube outline, known as the miniature tube, having 7 or 9 pins. Making tubes smaller reduced the voltage where they could safely operate, and also reduced the power dissipation of the filament. Miniature tubes became predominant in consumer applications such as radio receivers and hi-fi amplifiers. However the larger older styles continued to be used especially as higher power rectifiers, in higher power audio output stages and as transmitting tubes. tubes with a size roughly that of half a cigarette were used in hearing-aid amplifiers. These tubes did not have pins plugging into a socket but were soldered in place. The "acorn" valve (named due to its shape) was also very small, as was the metal-cased RCA nuvistor from 1959, about the size of a thimble. The nuvistor was developed to compete with the early transistors and operated at higher frequencies than those early transistors could. The small size supported especially high-frequency operation; nuvistors were used in UHF television tuners and some HiFi FM radio tuners (Sansui 500A) until replaced by high-frequency capable transistors.
Improvements in construction and performance.
The earliest vacuum tubes strongly resembled incandescent light bulbs and were made by lamp manufacturers, who had the equipment needed to manufacture glass envelopes and the vacuum pumps required to evacuate the enclosures. De Forest used Heinrich Geissler's mercury displacement pump, which left behind a partial vacuum. The development of the diffusion pump in 1915 and improvement by Irving Langmuir led to the development of high-vacuum tubes. After World War I, specialized manufacturers using more economical construction methods were set up to fill the growing demand for broadcast receivers. Bare tungsten filaments operated at a temperature of around 2200 °C. The development of oxide-coated filaments in the mid-1920s reduced filament operating temperature to a dull red heat (around 700 °C), which in turn reduced thermal distortion of the tube structure and allowed closer spacing of tube elements. This in turn improved tube gain, since the gain of a triode is inversely proportional to the spacing between grid and cathode. Bare tungsten filaments remain in use in small transmitting tubes but are brittle and tend to fracture if handled roughly – e.g. in the postal services. These tubes are best suited to stationary equipment where impact and vibration is not present.
Indirectly heated cathodes.
The desire to power electronic equipment using AC mains power faced a difficulty with respect to the powering of the tubes' filaments, as these were also the cathode of each tube. Powering the filaments directly from a power transformer introduced mains-frequency (50 or 60 Hz) hum into audio stages. The invention of the "equipotential cathode" reduced this problem, with the filaments being powered by a balanced AC power transformer winding having a grounded center tap.
A superior solution, and one which allowed each cathode to "float" at a different voltage, was that of the indirectly heated cathode: a cylinder of oxide-coated nickel acted as electron-emitting cathode, and was electrically isolated from the filament inside it. Indirectly heated cathodes enable the cathode circuit to be separated from the heater circuit. The filament, no longer electrically connected to the tube's electrodes, became simply known as a "heater", and could as well be powered by AC without any introduction of hum. In the 1930s indirectly heated cathode tubes became widespread in equipment using AC power. Directly heated cathode tubes continued to be widely used in battery-powered equipment as their filaments required considerably less power than the heaters required with indirectly heated cathodes.
Tubes designed for high gain audio applications may have twisted heater wires to cancel out stray electric fields, fields that could induce objectionable hum into the program material.
Heaters may be energized with either alternating current (AC) or direct current (DC). DC is often used where low hum is required.
Use in electronic computers.
Vacuum tubes used as switches made electronic computing possible for the first time, but the cost and relatively short mean time to failure of tubes were limiting factors. "The common wisdom was that valves—which, like light bulbs, contained a hot glowing filament—could never be used satisfactorily in large numbers, for they were unreliable, and in a large installation too many would fail in too short a time". Tommy Flowers, who later designed "Colossus", "discovered that, so long as valves were switched on and left on, they could operate reliably for very long periods, especially if their 'heaters' were run on a reduced current". In 1934 Flowers built a successful experimental installation using over 3,000 tubes in small independent modules; when a tube failed, it was possible to switch off one module and keep the others going, thereby reducing the risk of another tube failure being caused; this installation was accepted by the Post Office (who operated telephone exchanges). Flowers was also a pioneer of using tubes as very fast (compared to electromechanical devices) electronic switches. Later work confirmed that tube unreliability was not as serious an issue as generally believed; the 1946 ENIAC, with over 17,000 tubes, had a tube failure (which took 15 minutes to locate) on average every two days. The quality of the tubes was a factor, and unfortunately the diversion of skilled people during the Second World War lowered the general quality of tubes. During the war Colossus was instrumental in breaking German codes. After the war, development continued with tube-based computers including, military computers ENIAC and Whirlwind, the Ferranti Mark 1 (the first commercially available electronic computer), and UNIVAC I, also available commercially.
Colossus.
Flowers's Colossus and its successor Colossus Mk2 were built by the British during World War II to substantially speed up the task of breaking the German high level Lorenz encryption. Using about 1,500 vacuum tubes (2,400 for Mk2), Colossus replaced an earlier machine based on relay and switch logic (the Heath Robinson). Colossus was able to break in a matter of hours messages that had previously taken several weeks; it was also much more reliable. Colossus was the first use of vacuum tubes "working in concert" on such a large scale for a single machine.
Once Colossus was built and installed, it ran continuously, powered by dual redundant diesel generators, the wartime mains supply being considered too unreliable. The only time it was switched off was for conversion to Mk2, with the addition of more tubes. Another nine Colossus Mk2s were built, and all ten machines were surprisingly reliable. The ten machines drew 15 kilowatts of power each continuously, largely for the tube heaters.
A Colossus reconstruction was switched on in 1996; it was upgraded to Mk2 configuration in 2004; it found the key for a wartime German ciphertext in 2007.
Whirlwind and "special-quality" tubes.
To meet the reliability requirements of the 1951 US digital computer Whirlwind, "special-quality" tubes with extended life, and a long-lasting cathode in particular, were produced. The problem of short lifetime was traced to evaporation of silicon, used in the tungsten alloy to make the heater wire easier to draw. Elimination of silicon from the heater wire alloy (and more frequent replacement of the wire drawing dies) allowed production of tubes that were reliable enough for the Whirlwind project. The tubes developed for Whirlwind were later used in the giant SAGE air-defense computer system. High-purity nickel tubing and cathode coatings free of materials that can poison emission (such as silicates and aluminium) also contribute to long cathode life. The first such "computer tube" was Sylvania's 7AK7 of 1948. By the late 1950s it was routine for special-quality small-signal tubes to last for hundreds of thousands of hours, if operated conservatively. This increased reliability also made mid-cable amplifiers in submarine cables possible.
Heat generation and cooling.
A considerable amount of heat is produced when tubes operate, both from the filament (heater) but also from the stream of electrons bombarding the plate. In power amplifiers this source of heat will exceed the power due to cathode heating.
A few types of tube permit operation with the anodes at a dull red heat; in other types, red heat indicates severe overload.
The requirements for heat removal can significantly change the appearance of high-power vacuum tubes. High power audio amplifiers and rectifiers required larger envelopes to dissipate heat. Transmitting tubes could be much larger still.
Heat escapes the device by black body radiation from the anode (plate) as infrared radiation, and by convection of air over the tube envelope. Convection is not possible in most tubes since the anode is surrounded by vacuum.
Tubes which generate relatively little heat, such as the 1.4-volt filament directly heated tubes designed for use in battery-powered equipment, often have shiny metal anodes. 1T4, 1R5 and 1A7 are examples. Gas-filled tubes such as thyratrons may also use a shiny metal anode, since the gas present inside the tube allows for heat convection from the anode to the glass enclosure.
The anode is often treated to make its surface emit more infrared energy. High-power amplifier tubes are designed with external anodes which can be cooled by convection, forced air or circulating water. The water-cooled 80 kg, 1.25 MW 8974 is among the largest commercial tubes available today.
In a water-cooled tube, the anode voltage appears directly on the cooling water surface, thus requiring the water to be an electrical insulator to prevent high voltage leakage through the cooling water to the radiator system. Water as usually supplied has ions which conduct electricity; deionized water, a good insulator, is required. Such systems usually have a built-in water-conductance monitor which will shut down the high-tension supply if the conductance becomes too high.
The screen grid may also generate considerable heat. Limits to screen grid dissipation, in addition to plate dissipation, are listed for power devices. If these are exceeded then tube failure is likely.
Tube packages.
Most modern tubes have glass envelopes, but metal, fused quartz (silica) and ceramic have also been used. A first version of the 6L6 used a metal envelope sealed with glass beads, while a glass disk fused to the metal was used in later versions. Metal and ceramic are used almost exclusively for power tubes above 2 kW dissipation. The nuvistor was a modern receiving tube using a very small metal and ceramic package.
The internal elements of tubes have always been connected to external circuitry via pins at their base which plug into a socket. Subminiature tubes were produced using wire leads rather than sockets, however these were restricted to rather specialized applications. In addition to the connections at the base of the tube, many early triodes connected the grid using a metal cap at the top of the tube; this reduces stray capacitance between the grid and the plate leads. Tube caps were also used for the plate (anode) connection, particularly in transmitting tubes and tubes using a very high plate voltage.
High-power tubes such as transmitting tubes have packages designed more to enhance heat transfer. In some tubes, the metal envelope is also the anode. The 4CX1000A is an external anode tube of this sort. Air is blown through an array of fins attached to the anode, thus cooling it. Power tubes using this cooling scheme are available up to 150 kW dissipation. Above that level, water or water-vapor cooling are used. The highest-power tube currently available is the Eimac , a forced water-cooled power tetrode capable of dissipating 2.5 megawatts. (By comparison, the largest power transistor can only dissipate about 1 kilowatt.)
Names.
The generic name " valve" used in the UK derives from the unidirectional current flow allowed by the earliest device, the thermionic diode emitting electrons from a heated filament, by analogy with a non-return valve in a water pipe. The US names "vacuum tube", "electron tube", and "thermionic tube" all simply describe a tubular envelope which has been evacuated ("vacuum"), has a heater, and controls electron flow.
In many cases manufacturers and the military gave tubes designations which said nothing about their purpose (e.g., 1614). In the early days some manufacturers used proprietary names which might convey some information, but only about their products; the KT66 and KT88 were "Kinkless Tetrodes". Later, consumer tubes were given names which conveyed some information, with the same name often used generically by several manufacturers. In the US, Radio Electronics Television Manufacturers' Association (RETMA) designations comprise a number, followed by one or two letters, and a number. The first number is the (rounded) heater voltage; the letters designate a particular tube but say nothing about its structure; and the final number is the total number of electrodes (without distinguishing between, say, a tube with many electrodes, or two sets of electrodes in a single envelope—a double triode, for example). For example, the 12AX7 is a double triode (two sets of three electrodes plus heater) with a 12.6V heater (which, as it happens, can also be connected to run from 6.3V). The "AX" has no meaning other than to designate this particular tube according to its characteristics. Similar, but not identical, tubes are the 12AD7, 12AE7...12AT7, 12AU7, 12AV7, 12AW7 (rare!), 12AY7, and the 12AZ7.
A system widely used in Europe known as the Mullard-Philips tube designation, also extended to transistors, uses a letter, followed by one or more further letters, and a number. The type designator specifies the heater voltage or current (one letter), the functions of all sections of the tube (one letter per section), the socket type (first digit), and the particular tube (remaining digits). For example, the ECC83 (equivalent to the 12AX7) is a 6.3V (E) double triode (CC) with a miniature base (8). In this system special-quality tubes (e.g., for long-life computer use) are indicated by moving the number immediately after the first letter: the E83CC is a special-quality equivalent of the ECC83, the E55L a power pentode with no consumer equivalent.
Special-purpose tubes.
Some special-purpose tubes are constructed with particular gases in the envelope. For instance, voltage-regulator tubes contain various inert gases such as argon, helium or neon, which will ionize at predictable voltages. The thyratron is a special-purpose tube filled with low-pressure gas or mercury vapor. Like vacuum tubes, it contains a hot cathode and an anode, but also a control electrode which behaves somewhat like the grid of a triode. When the control electrode starts conduction, the gas ionizes, after which the control electrode can no longer stop the current; the tube "latches" into conduction. Removing anode (plate) voltage lets the gas de-ionize, restoring its non-conductive state. Some thyratrons can carry large currents for their physical size. One example is the miniature type 2D21, often seen in 1950s jukeboxes as control switches for relays. A cold-cathode version of the thyratron, which uses a pool of mercury for its cathode, is called an ignitron; some can switch thousands of amperes. Thyratrons containing hydrogen have a very consistent time delay between their turn-on pulse and full conduction; they behave much like modern silicon-controlled rectifiers, also called thyristors due to their functional similarity to thyratrons. Thyratrons have long been used in radar transmitters.
An extremely specialized tube is the krytron, which is used for extremely precise and rapid high-voltage switching. Krytrons with certain specifications are suitable to initiate the precise sequence of detonations used to set off a nuclear weapon, and are heavily controlled at an international level.
X-ray tubes are used in medical imaging among other uses. X-ray tubes used for continuous-duty operation in fluoroscopy and CT imaging equipment may use a focused cathode and a rotating anode to dissipate the large amounts of heat thereby generated. These are housed in an oil-filled aluminium housing to provide cooling.
The photomultiplier tube is an extremely sensitive detector of light, which uses the photoelectric effect and secondary emission, rather than thermionic emission, to generate and amplify electrical signals. Nuclear medicine imaging equipment and liquid scintillation counters use photomultiplier tube arrays to detect low-intensity scintillation due to ionizing radiation.
Powering the tube.
Batteries.
Batteries provided the voltages required by tubes in early radio sets. Three different voltages were generally required, using three different batteries designated as the A, B, and C battery. The "A" battery or LT (low-tension) battery provided the filament voltage. Tube heaters were designed for single, double or triple-cell lead-acid batteries, giving nominal heater voltages of 2 V, 4 V or 6 V. In portable radios, dry batteries were sometimes used with 1.5 or 1 V heaters. Reducing filament consumption improved the life span of batteries. By 1955 towards the end of the tube era, tubes using only 50 mA down to as little as 10 mA for the heaters had been developed.
The high voltage applied to the anode (plate) was provided by the "B" battery or the HT (high-tension) supply or battery. These were generally of dry cell construction and typically came in 22.5-, 45-, 67.5-, 90-, 120- or 135-volt versions.
Early sets used a grid bias battery or "C" battery which was connected to provide a "negative" voltage. Since virtually no current flows through a tube's grid connection, these batteries had very low drain and lasted the longest. Even after AC power supplies became commonplace, some radio sets continued to be built with C batteries, as they would almost never need replacing. However more modern circuits were designed using cathode biasing, eliminating the need for a third power supply voltage; this became practical with tubes using indirect heating of the cathode.
The "C battery" for bias is a designation having no relation to the "C cell" battery size.
AC power.
Battery replacement was a major operating cost for early radio receiver users. The development of the battery eliminator, and, in 1925, batteryless receivers operated by household power, reduced operating costs and contributed to the growing popularity of radio. A power supply using a transformer with several windings, one or more rectifiers (which may themselves be vacuum tubes), and large filter capacitors provided the required direct current voltages from the alternating current source.
As a cost reduction measure, especially in high-volume consumer receivers, all the tube heaters could be connected in series across the AC supply using heaters requiring the same current and with a similar warm-up time. In one such design, a tap on the tube heater string supplied the 6 volts needed for the dial light. By deriving the high voltage from a half-wave rectifier directly connected to the AC mains, the heavy and costly power transformer was eliminated. This also allowed such receivers to operate on direct current, a so-called AC/DC receiver design. Many different US consumer AM radio manufacturers of the era used a virtually identical circuit, given the nickname All American Five.
Where the mains voltage was in the 100-120V range, this limited voltage proved suitable only for low-power receivers. Television receivers either required a transformer or could use a voltage doubling circuit. Where 230 V nominal mains voltage was used, television receivers as well could dispense with a power transformer.
Transformer-less power supplies required safety precautions in their design to limit the shock hazard to users, such as electrically insulated cabinets and an interlock tying the power cord to the cabinet back, so the line cord was necessarily disconnected if the user or service person opened the cabinet. A "cheater cord" was a power cord ending in the special socket used by the safety interlock; servicers could then power the device with the hazardous voltages exposed.
To avoid the warm-up delay, "instant on" television receivers passed a small heating current through their tubes even when the set was nominally off. At switch on, full heating current was provided and the set would play almost immediately.
Reliability.
One reliability problem of tubes with oxide cathodes is the possibility that the cathode may slowly become "poisoned" by gas molecules from other elements in the tube, which reduce its ability to emit electrons. Trapped gases or slow gas leaks can also damage the cathode or cause plate (anode) current runaway due to ionization of free gas molecules. Vacuum hardness and proper selection of construction materials are the major influences on tube lifetime. Depending on the material, temperature and construction, the surface material of the cathode may also diffuse onto other elements. The resistive heaters that heat the cathodes may break in a manner similar to incandescent lamp filaments, but rarely do, since they operate at much lower temperatures than lamps.
The heater's failure mode is typically a stress-related fracture of the tungsten wire or at a weld point and generally occurs after accruing many thermal (power on-off) cycles. Tungsten wire has a very low resistance when at room temperature. A negative temperature coefficient device, such as a thermistor, may be incorporated in the equipment's heater supply or a ramp-up circuit may be employed to allow the heater or filaments to reach operating temperature more gradually than if powered-up in a step-function. Low-cost radios had tubes with heaters connected in series, with a total voltage equal to that of the line (mains). Following World War II, tubes intended to be used in series heater strings were redesigned to all have the same ("controlled") warm-up time. Earlier designs had quite-different thermal time constants. The audio output stage, for instance, had a larger cathode, and warmed up more slowly than lower-powered tubes. The result was that heaters that warmed up faster also temporarily had higher resistance, because of their positive temperature coefficient. This disproportionate resistance caused them to temporarily operate with heater voltages well above their ratings, and shortened their life.
Another important reliability problem is caused by air leakage into the tube. Usually oxygen in the air reacts chemically with the hot filament or cathode, quickly ruining it. Designers developed tube designs that sealed reliably. This was why most tubes were constructed of glass. Metal alloys (such as Cunife and Fernico) and glasses had been developed for light bulbs that expanded and contracted in similar amounts, as temperature changed. These made it easy to construct an insulating envelope of glass, while passing connection wires through the glass to the electrodes.
When a vacuum tube is overloaded or operated past its design dissipation, its anode (plate) may glow red. In consumer equipment, a glowing plate is universally a sign of an overloaded tube. However, some large transmitting tubes are designed to operate with their anodes at red, orange, or in rare cases, white heat.
"Special quality" versions of standard tubes were often made, designed for improved performance in some respect, such as a longer life cathode, low noise construction, mechanical ruggedness via ruggedized filaments, low microphony, for applications where the tube will spend much of its time cut off, etc. The only way to know the particular features of a special quality part is by reading the data sheet. Names may reflect the standard name (12AU7==>12AU7A, its equivalent ECC82==>E82CC, etc.), or be absolutely anything (standard and special-quality equivalents of the same tube include 12AU7, ECC82, B329, CV491, E2163, E812CC, M8136, CV4003, 6067, VX7058, 5814A and 12AU7A).
The longest recorded valve life was earned by a Mazda AC/P pentode valve (serial No. 4418) in operation at the BBC's main Northern Ireland transmitter at Lisnagarvey. The valve was in service from 1935 until 1961 and had a recorded life of 232,592 hours. The BBC maintained meticulous records of their valves' lives with periodic returns to their central valve stores.
Vacuum.
The highest possible vacuum is desired in a tube. Remaining gas atoms will ionize and conduct electricity between the elements in an undesired manner. In a defective tube residual air pressure will lead to ionization, becoming visible as a pink-purple glow discharge between the tube elements. 
To prevent gases from compromising the tube's vacuum, modern tubes are constructed with "getters", which are usually small, circular troughs filled with metals that oxidize quickly, barium being the most common. While the tube envelope is being evacuated, the internal parts except the getter are heated by RF induction heating to evolve any remaining gas from the metal parts. The tube is then sealed and the getter is heated to a high temperature, again by radio frequency induction heating, which causes the getter material to vaporize and react with any residual gas. The vapor is deposited on the inside of the glass envelope, leaving a silver-colored metallic patch which continues to absorb small amounts of gas that may leak into the tube during its working life. Great care is taken with the valve design to ensure this material is not deposited on any of the working electrodes. If a tube develops a serious leak in the envelope, this deposit turns a white color as it reacts with atmospheric oxygen. Large transmitting and specialized tubes often use more exotic getter materials, such as zirconium. Early gettered tubes used phosphorus-based getters, and these tubes are easily identifiable, as the phosphorus leaves a characteristic orange or rainbow deposit on the glass. The use of phosphorus was short-lived and was quickly replaced by the superior barium getters. Unlike the barium getters, the phosphorus did not absorb any further gases once it had fired.
Getters act by chemically combining with residual or infiltrating gases, but are unable to counteract (non-reactive) inert gases. A known problem, mostly affecting valves with large envelopes such as Cathode Ray Tubes and camera tubes such as Iconoscopes and Orthicons/Image Orthicons, comes from helium infiltration. The effect appears as impaired or absent functioning, and as a diffuse glow along the electron stream inside the tube. This effect cannot be rectified (short of re-evacuation and resealing), and is responsible for working examples of such tubes becoming rarer and rarer. Unused ("New Old Stock") tubes can also exhibit inert gas infiltration, so there is no long-term guarantee of these tube types surviving into the future.
Transmitting tubes.
Large transmitting tubes have carbonized tungsten filaments containing a small trace (1% to 2%) of thorium. An extremely thin (molecular) layer of thorium atoms forms on the outside of the wire's carbonized layer and, when heated, serve as an efficient source of electrons. The thorium slowly evaporates from the wire surface, while new thorium atoms diffuse to the surface to replace them. Such thoriated tungsten cathodes usually deliver lifetimes in the tens of thousands of hours. The end-of-life scenario for a thoriated-tungsten filament is when the carbonized layer has mostly been converted back into another form of tungsten carbide and emission begins to drop off rapidly; a complete loss of thorium has never been found to be a factor in the end-of-life in a tube with this type of emitter.
WAAY-TV in Huntsville, Alabama achieved 163,000 hours of service from an Eimac external cavity klystron in the visual circuit of its transmitter; this is the highest documented service life for this type of tube. 
It has been said that transmitters with vacuum tubes are better able to survive lightning strikes than transistor transmitters do. While it was commonly believed that at RF power levels above approx. 20 kilowatts, vacuum tubes were more efficient than solid state circuits, this is no longer the case especially in medium wave (AM broadcast) service where solid state transmitters at nearly all power levels have measurably higher efficiency. FM broadcast transmitters with solid state power amplifiers up to approx. 15 kW also show better overall mains-power efficiency than tube-based power amplifiers.
Receiving tubes.
Cathodes in small "receiving" tubes are coated with a mixture of barium oxide and strontium oxide, sometimes with addition of calcium oxide or aluminium oxide. An electric heater is inserted into the cathode sleeve, and insulated from it electrically by a coating of aluminium oxide. This complex construction causes barium and strontium atoms to diffuse to the surface of the cathode and emit electrons when heated to about 780 degrees Celsius.
Failure modes.
Catastrophic failures.
A catastrophic failure is one which suddenly makes the vacuum tube unusable. A crack in the glass envelope will allow air into the tube and destroy it. Cracks may result from stress in the glass, bent pins or impacts; tube sockets must allow for thermal expansion, to prevent stress in the glass at the pins. Stress may accumulate if a metal shield or other object presses on the tube envelope and causes differential heating of the glass. Glass may also be damaged by high-voltage arcing.
Tube heaters may also fail without warning, especially if exposed to over voltage or as a result of manufacturing defects. Tube heaters do not normally fail by evaporation like lamp filaments, since they operate at much lower temperature. The surge of inrush current when the heater is first energized causes stress in the heater, and can be avoided by slowly warming the heaters, gradually increasing current with a NTC thermistor included in the circuit. Tubes intended for series-string operation of the heaters across the supply have a specified controlled warm-up time to avoid excess voltage on some heaters as others warm up. Directly heated filament-type cathodes as used in battery-operated tubes or some rectifiers may fail if the filament sags, causing internal arcing. Excess heater-to-cathode voltage in indirectly heated cathodes can break down the insulation between elements and destroy the heater.
Arcing between tube elements can destroy the tube. An arc can be caused by applying voltage to the anode (plate) before the cathode has come up to operating temperature, or by drawing excess current through a rectifier, which damages the emission coating. Arcs can also be initiated by any loose material inside the tube, or by excess screen voltage. An arc inside the tube allows gas to evolve from the tube materials, and may deposit conductive material on internal insulating spacers.
Tube rectifiers have limited current capability and exceeding ratings will eventually destroy a tube.
Degenerative failures.
Degenerative failures are those caused by the slow deterioration of performance over time.
Overheating of internal parts, such as control grids or mica spacer insulators, can result in trapped gas escaping into the tube; this can reduce performance. A getter is used to absorb gases evolved during tube operation, but has only a limited ability to combine with gas. Control of the envelope temperature prevents some types of gassing. A tube with an unusually high level of internal gas may exhibit a visible blue glow when plate voltage is applied. The getter (being a highly reactive metal) is effective against many atmospheric gases, but has no (or very limited) chemical reactivity to inert gases such as helium. One progressive type of failure, especially with physically large envelopes such as those used by camera tubes and cathode-ray tubes, comes from helium infiltration. The exact mechanism not clear: the metal-to-glass lead-in seals are one possible infiltration site.
Gas and ions within the tube contribute to grid current which can disturb operation of a vacuum tube circuit. Another effect of overheating is the slow deposit of metallic vapors on internal spacers, resulting in inter-element leakage.
Tubes on standby for long periods, with heater voltage applied, may develop high cathode interface resistance and display poor emission characteristics. This effect occurred especially in pulse and digital circuits, where tubes had no plate current flowing for extended times. Tubes designed specifically for this mode of operation were made.
Cathode depletion is the loss of emission after thousands of hours of normal use. Sometimes emission can be restored for a time by raising heater voltage, either for a short time or a permanent increase of a few percent. Cathode depletion was uncommon in signal tubes but was a frequent cause of failure of monochrome television cathode-ray tubes. Usable life of this expensive component was sometimes extended by fitting a boost transformer to increase heater voltage.
Other failures.
Vacuum tubes may have or develop defects in operation that make an individual tube unsuitable in a given device, although it may perform satisfactorily in another application. "Microphonics" refers to internal vibrations of tube elements which modulate the tube's signal in an undesirable way; sound or vibration pick-up may affect the signals, or even cause uncontrolled howling if a feedback path develops between a microphonic tube and, for example, a loudspeaker. Leakage current between AC heaters and the cathode may couple into the circuit, or electrons emitted directly from the ends of the heater may also inject hum into the signal. Leakage current due to internal contamination may also inject noise. Some of these effects make tubes unsuitable for small-signal audio use, although unobjectionable for many purposes. Selecting the best of a batch of nominally identical tubes for critical applications can produce better results.
Tube pins are designed to facilitate installation and removal from its socket but, due to the high operating temperatures of these devices and/or ingress of dirt and dust over time, pins can develop non-conducting or high resistance surface films. Pins can be easily cleaned to restore conductance to normal standards.
Testing.
Vacuum tubes can be tested outside of their circuitry using a vacuum tube tester.
Other vacuum tube devices.
Most small signal vacuum tube devices have been superseded by semiconductors, but some vacuum tube electronic devices are still in common use. The magnetron is the type of tube used in all microwave ovens. In spite of the advancing state of the art in power semiconductor technology, the vacuum tube still has reliability and cost advantages for high-frequency RF power generation.
Some tubes, such as magnetrons, traveling-wave tubes, carcinotrons, and klystrons, combine magnetic and electrostatic effects. These are efficient (usually narrow-band) RF generators and still find use in radar, microwave ovens and industrial heating. Traveling-wave tubes (TWTs) are very good amplifiers and are even used in some communications satellites. High-powered klystron amplifier tubes can provide hundreds of kilowatts in the UHF range.
Cathode ray tubes.
The cathode ray tube (CRT) is a vacuum tube used particularly for display purposes. Although there are still many televisions and computer monitors using cathode ray tubes, they are rapidly being replaced by flat panel displays whose quality has greatly improved even as their prices drop. This is also true of digital oscilloscopes (based on internal computers and analog to digital converters), although traditional analog scopes (dependent upon CRTs) continue to be produced, are economical, and preferred by many technicians. At one time many radios used "magic eye tubes", a specialized sort of CRT used in place of a meter movement to indicate signal strength, or input level in a tape recorder. A modern indicator device, the vacuum fluorescent display (VFD) is also a sort of cathode ray tube.
Gyrotrons or vacuum masers, used to generate high-power millimeter band waves, are magnetic vacuum tubes in which a small relativistic effect, due to the high voltage, is used for bunching the electrons. Gyrotrons can generate very high powers (hundreds of kilowatts).
Free electron lasers, used to generate high-power coherent light and even X-rays, are highly relativistic vacuum tubes driven by high-energy particle accelerators. Thus these are sorts of cathode ray tubes.
Electron multipliers.
A photomultiplier is a phototube whose sensitivity is greatly increased through the use of electron multiplication. This works on the principle of secondary emission, whereby a single electron emitted by the photocathode strikes a special sort of anode known as a dynode causing more electrons to be released from that dynode. Those electrons are accelerated toward another dynode at a higher voltage, releasing more secondary electrons; as many as 15 such stages provide a huge amplification. Despite great advances in solid state photodetectors, the single-photon detection capability of photomultiplier tubes makes this vacuum tube device excel in certain applications. Such a tube can also be used for detection of ionizing radiation as an alternative to the Geiger–Müller tube (itself not an actual vacuum tube). Historically, the image orthicon TV camera tube widely used in television studios prior to the development of modern CCD arrays also used multistage electron multiplication.
For decades, electron-tube designers tried to augment amplifying tubes with electron multipliers in order to increase gain, but these suffered from short life because the material used for the dynodes "poisoned" the tube's hot cathode. (For instance, the interesting RCA 1630 secondary-emission tube was marketed, but did not last.) However, eventually, Philips of the Netherlands developed the EFP60 tube that had a satisfactory lifetime, and was used in at least one product, a laboratory pulse generator. By that time, however, transistors were rapidly improving, making such developments superfluous.
One variant called a "channel electron multiplier" does not use individual dynodes but consists of a curved tube, such as a helix, coated on the inside with material with good secondary emission. One type had a funnel of sorts to capture the secondary electrons. The continuous dynode was resistive, and its ends were connected to enough voltage to create repeated cascades of electrons. The microchannel plate consists of an array of single stage electron multipliers over an image plane; several of these can then be stacked. This can be used, for instance, as an image intensifier in which the discrete channels substitute for focussing.
Tektronix made a high-performance wideband oscilloscope CRT with a channel electron multiplier plate behind the phosphor layer. This plate was a bundled array of a huge number of short individual c.e.m. tubes that accepted a low-current beam and intensified it to provide a display of practical brightness. (The electron optics of the wideband electron gun could not provide enough current to directly excite the phosphor.)
Vacuum tubes in the 21st century.
Niche applications.
Although vacuum tubes have been largely replaced by solid-state devices in most amplifying, switching, and rectifying applications, there are certain exceptions. In addition to the special functions noted above, tubes have some niche applications.
In general, vacuum tubes are much less susceptible than corresponding solid-state components to transient overvoltages, such as mains voltage surges or lightning, the electromagnetic pulse effect of nuclear explosions or geomagnetic storms produced by giant solar flares. This property kept them in use for certain military applications long after more practical and less expensive solid-state technology was available for the same applications, as for example with the MiG-25.
Vacuum tubes are still practical alternatives to solid state in generating high power at radio frequencies in applications such as industrial radio frequency heating, particle accelerators, and broadcast transmitters. This is particularly true at microwave frequencies where such devices as the klystron and traveling-wave tube provide amplification at power levels unattainable using semiconductor devices. The household microwave oven uses a magnetron tube to efficiently generate hundreds of watts of microwave power.
Audiophiles.
Enough people prefer tube sound to make tube amplifiers commercially viable in three areas: musical instrument (guitar) amplifiers, devices used in recording studios, and audiophile equipment.
Many guitarists prefer using valve amplifiers to solid-state models. Most popular vintage models use vacuum tubes.
Vacuum fluorescent display.
A modern display technology using a variation of cathode ray tube is often used in videocassette recorders, DVD players and recorders, microwave oven control panels, and automotive dashboards. Rather than raster scanning, these vacuum fluorescent displays (VFD) switch control grids and anode voltages on and off, for instance, to display discrete characters. The VFD uses phosphor-coated anodes as in other display cathode ray tubes. Because the filaments are in view, they must be operated at temperatures where the filament does not glow visibly. This is possible using more recent cathode technology, and these tubes also operate with quite low anode voltages (often less than 50 volts) unlike cathode ray tubes. Their high brightness allows reading the display in bright daylight. VFD tubes are flat and rectangular, as well as relatively thin. Typical VFD phosphors emit a broad spectrum of greenish-white light, permitting use of color filters, though different phosphors can give other colors even within the same display. The design of these tubes provides a bright glow despite the low energy of the incident electrons. This is because the distance between the cathode and anode is relatively small. (This technology is distinct from fluorescent lighting, which uses a discharge tube.)
Vacuum tubes using field electron emitters.
In the early years of the 21st century there has been renewed interest in vacuum tubes, this time with the electron emitter formed on a flat silicon substrate, as in integrated circuit technology. This subject is now called vacuum nanoelectronics. The most common design uses a cold cathode in the form of a large-area field electron source (for example a field emitter array). With these devices, electrons are field-emitted from a large number of closely spaced individual emission sites.
Their claimed advantages include much greater robustness and the ability to provide high power output at low power consumption. Operating on the same principles as traditional tubes, prototype device cathodes have been fabricated in several different ways. Although a common approach is to use a field emitter array, one interesting idea is to etch electrodes to form hinged flaps – similar to the technology used to create the microscopic mirrors used in digital light processing – that are stood upright by an electrostatic charge.
Such integrated microtubes may find application in microwave devices including mobile phones, for Bluetooth and Wi-Fi transmission, in radar and for satellite communication. they were being studied for possible applications in field emission display technology, but there were significant production problems.
As of 2014, NASA's Ames Research Center was reported on working on vacuum-channel transistors produced using CMOS techniques.

</doc>
<doc id="32497" url="https://en.wikipedia.org/wiki?curid=32497" title="Venice Film Festival">
Venice Film Festival

The Venice Film Festival or Venice International Film Festival (, "International Exhibition of Cinematographic Art of the Venice Biennale"), founded in 1932, is the oldest film festival in the world and one of the "Big Three" film festivals alongside the Cannes Film Festival and Berlin International Film Festival.
The film festival is part of the Venice Biennale, which was founded by the Venetian City Council in 1895. Today, the Biennale includes a range of separate events including: the International Art Exhibition; the International Festival of Contemporary Music; the International Theatre Festival; the International Architecture Exhibition; the International Festival of Contemporary Dance; the International Kids’ Carnival; and the annual Venice Film Festival, which is arguably the best-known of all the events.
The film festival has since taken place in late August or early September on the island of the Lido, Venice, Italy. Screenings take place in the historic Palazzo del Cinema on the Lungomare Marconi and in other venues nearby. Since its inception the Film Festival has become the most prestigious international film festival in the world.
The 73rd Festival is scheduled to be held from 31 August to 10 September 2016.
History.
The beginning.
The first edition of the Venice Film Festival was carried out from the 6 to the 21 of August in 1932.
The festival began with an idea of the president of the Venice Biennale Count Giuseppe Volpi di Misurata and Luciano De Feo, who was the very first director-selector. With good reason, the festival was considered the first international event of its type, receiving strong support from authorities. This first edition was held on the terrace of the Hotel Excelsior on the Venice Lido, and at that stage it was not a competitive event. The very first film to be shown in the history of the Festival was Rouben Mamoulian's "Dr. Jekyll and Mr. Hyde", that was screened at 9:15 p.m. on 6 August 1932.
The second edition was held two years later, from 1 to 20 of August in 1934. For the first time it included a competition. At least 19 countries took part with over 300 accredited journalists. The "Mussolini Cup" was introduced for best foreign film and best Italian film; however there was no actual jury. Instead, the awards were assigned by the President of the Biennale, after listening to the opinions of both experts and audiences, and in accordance with the "National Institute for Educational Cinema". Other awards were the "Great Gold Medals of the National Fascist Association for Entertainment" to best actor and actress. The prize for best foreign film went to Robert J. Flaherty's "Man of Aran" and was a confirmation of the taste of the time for auteur documentaries.
Starting with 1935 the Festival became a yearly event under the direction of Ottavio Croze. The actors' award was renamed "Volpi Cup". In 1936 an international jury was nominated for the first time and in 1937 the new Cinema Palace, designed by the architect Luigi Quagliata, was inaugurated.
1940s.
The 1940s represent one of the most difficult moments for the review.
The conclusion of the Second World War divides the decade in two. Before 1938 political pressures distorted and ruined the festival. With the advent of the conflict the situation degenerated to such a point that the editions of 1940, 1941 and 1942, subsequently are considered as if they did not happen because they were carried out in places far away from Lido. In addition, few countries participated and there was an absolute monopoly of institutions and directors that were members of the Rome-Berlin Axis.
After this sad digression, the festival resumed full speed in 1946, after the war. For the first time, the 1946 edition was held in the month of September, in accordance to an agreement with the newly-born Cannes Film Festival, which had just held its first review in the spring of that year. With the return of normalcy, Venice once again became a great icon of the film world.
In 1947 the festival was held at the Doge's Palace, a most magnificent backdrop for hosting a record 90 thousand participants. Surely it can be considered one of the greatest editions in the history of the festival.
Development and closure.
For the next twenty years the festival continued its development and expansion in accordance with the artistic plan set in motion after the war.
In 1963 the winds of change blow strongly during Luigi Chiarini’s directorship of the festival. During the years of his presidency, Chiarini aspired to renew the spirit and the structures of the festival, pushing for a total reorganization of the entire system. For six years the festival followed a consistent path, according to the rigid criteria put in place for the selection of works in competition, and took a firm stand against the political pressures and interference of more and more demanding movie studios, preferring the artistic quality of films to the growing commercialization of the film industry.
The social and political unrest of 1968 had strong repercussions on the Venice Bienniale. From 1969 to 1979 no prizes were awarded and the festival returned to the non-competitiveness of the first edition. In 1973, 1977 and 1978, the festival was not even held. The Golden Lion didn't make its return until 1980.
The rebirth.
The long-awaited rebirth came in 1979, thanks to the new director Carlo Lizzani, who decided to restore the image and value the festival had lost over the last decade. The 1979 edition laid the foundation for the restoration of international prestige. In an attempt to create a more modern image of the festival, the neo-director created a committee of experts to assist in selecting the works and to increase the diversity of submissions to the festival.
Awards.
The Film Festival's current awards are:
Orizzonti section (Horizons).
This section is open to all "custom-format" works, with a wider view towards new trends in the expressive languages that converge in film.
The awards of the Orizzonti section are:
Jaeger-LeCoultre partnership.
Jaeger-LeCoultre Glory to the Filmmaker Award, organized in collaboration with Jaeger-LeCoultre since 2006. It is dedicated to personalities who have made a significant contribution to contemporary cinema. This is the list of winners:
Past awards.
Mussolini Cup (Coppa Mussolini).
The Mussolini Cup was the top award from 1934 to 1942 for Best Italian and Best Foreign Film. Named after Italy's dictator Benito Mussolini, it was abandoned upon his ousting in 1943.
Great Gold Medals of the National Fascist Association for Entertainment.
"Le Grandi Medaglie d’Oro dell’Associazione Nazionale Fascista dello Spettacolo" in Italian.
This was awarded to "Best Actor" and "Best Actress".
It was later replaced by the Volpi Cup for actors and actresses.
The first time this prize was awarded to Katharine Hepburn for her role in Little Women by George Cukor 
Audience Referendum.
In the first edition of the festival in 1932, due to the lack of a jury and the awarding of official prizes, a list of acknowledgements was decided by popular vote, an tally determined by the number of people flocking to the films, and announced by the Organizing Committee. From this the "Best Director" was declared – Russian Nikolaj Ekk for the film "The Road to Life", while the film by René Clair "Give Us Liberty" was voted Best Film.

</doc>
<doc id="32498" url="https://en.wikipedia.org/wiki?curid=32498" title="Volume">
Volume

Volume is the quantity of three-dimensional space enclosed by some closed boundary, for example, the space that a substance (solid, liquid, gas, or plasma) or shape occupies or contains.
Volume is often quantified numerically using the SI derived unit, the cubic metre. The volume of a container is generally understood to be the capacity of the container, i. e. the amount of fluid (gas or liquid) that the container could hold, rather than the amount of space the container itself displaces.
Three dimensional mathematical shapes are also assigned volumes. Volumes of some simple shapes, such as regular, straight-edged, and circular shapes can be easily calculated using arithmetic formulas. Volumes of a complicated shape can be calculated by integral calculus if a formula exists for the shape's boundary. Where a variance in shape and volume occurs, such as those that exist between different human beings, these can be calculated using three-dimensional techniques such as the Body Volume Index. One-dimensional figures (such as lines) and two-dimensional shapes (such as squares) are assigned zero volume in the three-dimensional space.
The volume of a solid (whether regularly or irregularly shaped) can be determined by fluid displacement. Displacement of liquid can also be used to determine the volume of a gas. The combined volume of two substances is usually greater than the volume of one of the substances. However, sometimes one substance dissolves in the other and the combined volume is not additive.
In "differential geometry", volume is expressed by means of the volume form, and is an important global Riemannian invariant.
In "thermodynamics", volume is a fundamental parameter, and is a conjugate variable to pressure.
Units.
[[File:Volume measurements from The New Student's Reference Work.svg|thumb|220px|Volume measurements from the 1914 .
Approximate conversion to millilitres:
Any unit of length gives a corresponding unit of volume, namely the volume of a cube whose side has the given length. For example, a cubic centimetre (cm3) would be the volume of a cube whose sides are one centimetre (1 cm) in length.
In the International System of Units (SI), the standard unit of volume is the cubic metre (m3). The metric system also includes the litre (L) as a unit of volume, where one litre is the volume of a 10-centimetre cube. Thus
so
Small amounts of liquid are often measured in millilitres, where
Various other traditional units of volume are also in use, including the cubic inch, the cubic foot, the cubic mile, the teaspoon, the tablespoon, the fluid ounce, the fluid dram, the gill, the pint, the quart, the gallon, the minim, the barrel, the cord, the peck, the bushel, and the hogshead.
Related terms.
"Capacity" is defined by the Oxford English Dictionary as "the measure applied to the content of a vessel, and to liquids, grain, or the like, which take the shape of that which holds them". (The word "capacity" has other unrelated meanings, as in e.g. capacity management.) Capacity is not identical in meaning to volume, though closely related; the capacity of a container is always the volume in its interior. Units of capacity are the SI litre and its derived units, and Imperial units such as gill, pint, gallon, and others. Units of volume are the cubes of units of length. In SI the units of volume and capacity are closely related: one litre is exactly 1 cubic decimetre, the capacity of a cube with a 10 cm side. In other systems the conversion is not trivial; the capacity of a vehicle's fuel tank is rarely stated in cubic feet, for example, but in gallons (a gallon fills a volume of 0.1605 cu ft).
The "density" of an object is defined as the ratio of the mass to the volume. The inverse of density is "specific volume" which is defined as volume divided by mass. Specific volume is a concept important in thermodynamics where the volume of a working fluid is often an important parameter of a system being studied.
The volumetric flow rate in fluid dynamics is the volume of fluid which passes through a given surface per unit time (for example cubic meters per second s−1).
Volume in calculus.
In calculus, a branch of mathematics, the volume of a region "D" in R3 is given by a triple integral of the constant function formula_1 and is usually written as:
The volume integral in cylindrical coordinates is
and the volume integral in spherical coordinates (using the convention for angles with formula_4 as the azimuth and formula_5 measured from the polar axis (see more on conventions)) has the form
Volume formulas.
Volume ratios for a cone, sphere and cylinder of the same radius and height.
The above formulas can be used to show that the volumes of a cone, sphere and cylinder of the same radius and height are in the ratio 1 : 2 : 3, as follows.
Let the radius be "r" and the height be "h" (which is 2"r" for the sphere), then the volume of cone is
the volume of the sphere is
while the volume of the cylinder is
The discovery of the 2 : 3 ratio of the volumes of the sphere and cylinder is credited to Archimedes.
Volume formula derivations.
Sphere.
The volume of a sphere is the integral of an infinite number of infinitesimally small circular disks of thickness "dx".
The calculation for the volume of a sphere with center 0 and radius "r" is as follows.
The surface area of the circular disk is formula_10.
The radius of the circular disks, defined such that the x-axis cuts perpendicularly through them, is
formula_11
or
formula_12
where y or z can be taken to represent the radius of a disk at a particular x value.
Using y as the disk radius, the volume of the sphere can be calculated as formula_13
Now formula_14
Combining yields formula_15
This formula can be derived more quickly using the formula for the sphere's surface area, which is formula_16.
The volume of the sphere consists of layers of infinitesimally thin spherical shells, and the sphere volume is equal to
formula_17 = formula_18
Cone.
The cone is a type of pyramidal shape. The fundamental equation for pyramids, one-third times base times altitude, applies to cones as well.
However, using calculus, the volume of a cone is the integral of an infinite number of infinitesimally thin circular disks of thickness "dx".
The calculation for the volume of a cone of height "h", whose base is centered at (0,0,0) with radius "r", is as follows.
The radius of each circular disk is "r" if "x" = 0 and 0 if "x" = "h", and varying linearly in between—that is, formula_19
The surface area of the circular disk is then formula_20
The volume of the cone can then be calculated as formula_21
and after extraction of the constants: formula_22
Integrating gives us formula_23
Volume in differential geometry.
In differential geometry, a branch of mathematics, a volume form on a differentiable manifold is a differential form of top degree (i.e. whose degree is equal to the dimension of the manifold) that is nowhere equal to zero. A manifold has a volume form if and only if it is orientable. An orientable manifold has infinitely many volume forms, since multiplying a volume form by a non-vanishing function yields another volume form. On non-orientable manifolds, one may instead define the weaker notion of a density. Integrating the volume form gives the volume of the manifold according to that form.
Any oriented Riemannian (or pseudo-Riemannian) manifold has a natural volume (or pseudo volume) form. In local coordinates, it can be expressed as
where the formula_25 are the 1-forms providing an oriented basis for the cotangent bundle of the "n"-dimensional manifold. Here, formula_26 is the absolute value of the determinant of the matrix representation of the metric tensor on the manifold.
Volume in thermodynamics.
In thermodynamics, the volume of a system is an important extensive parameter for describing its thermodynamic state. The specific volume, an intensive property, is the system's volume per unit of mass. Volume is a function of state and is interdependent with other thermodynamic properties such as pressure and temperature. For example, volume is related to the pressure and temperature of an ideal gas by the ideal gas law.

</doc>
<doc id="32499" url="https://en.wikipedia.org/wiki?curid=32499" title="Vector graphics">
Vector graphics

Vector graphics is the use of polygons to represent images in computer graphics. Vector graphics are based on vectors, which lead through locations called control points or nodes. Each of these points has a definite position on the x and y axes of the work plane and determines the direction of the path; further, each path may be assigned a stroke color, shape, curve, thickness, and fill.
Overview.
One of the first uses of vector graphic displays was the US SAGE air defense system. Vector graphics systems were only retired from U.S. en route air traffic control in 1999, and are likely still in use in military and specialised systems. Vector graphics were also used on the TX-2 at the MIT Lincoln Laboratory by computer graphics pioneer Ivan Sutherland to run his program Sketchpad in 1963.
Subsequent vector graphics systems, most of which iterated through dynamically modifiable stored lists of drawing instructions, include the IBM 2250, Imlac PDS-1, and DEC GT40. There was a home gaming system that used vector graphics called Vectrex as well as various arcade games like "Asteroids", "Space Wars" and many cinematronics titles such as "Rip-Off", and "Tail Gunner" using vector monitors. Storage scope displays, such as the Tektronix 4014, could display vector images but not modify them without first erasing the display.
In computer typography, modern outline fonts describe printable characters (glyphs) by cubic or quadratic mathematical curves with control points. Nevertheless, bitmap fonts are still in use. Converting outlines requires filling them in; converting to bitmaps is not trivial, because bitmaps often don't have sufficient resolution to avoid "stairstepping" ("aliasing"), especially with smaller visible character sizes. Processing outline character data in sophisticated fashion to create satisfactory bitmaps for rendering is called "hinting". Although the term implies suggestion, the process is deterministic, and done by executable code, essentially a special-purpose computer language. While automatic hinting is possible, results can be inferior to that done by experts.
Modern vector graphics displays can sometimes be found at laser light shows, where two fast-moving X-Y mirrors position the beam to rapidly draw shapes and text as straight and curved strokes on a screen.
Vector graphics can be created in form using a pen plotter, a special type of printer that uses a series of ballpoint and felt-tip pens on a servo-driven mount that moves horizontally across the paper, with the plotter moving the paper back and forth through its paper path for vertical movement. Although a typical plot might easily require a few thousand paper motions, back and forth, the paper doesn't slip. In a tiny roll-fed plotter made by Alps in Japan, teeth on thin sprockets indented the paper near its edges on the first pass, and maintained registration on subsequent passes.
Some Hewlett-Packard pen plotters had two-axis pen carriers and stationery paper (plot size was limited). However, the moving-paper H-P plotters had grit wheels (akin to machine-shop grinding wheels) which, on the first pass, indented the paper surface, and collectively maintained registration.
Present-day vector graphic files such as engineering drawings are typically printed as bitmaps, after vector-to-raster conversion.
The term "vector graphics" is mainly used today in the context of two-dimensional computer graphics. It is one of several modes an artist can use to create an image on a raster display. Other modes include text, multimedia, and 3D rendering. Virtually all modern 3D rendering is done using extensions of 2D vector graphics techniques. Plotters used in technical drawing still draw vectors directly to paper.
Standards.
The World Wide Web Consortium (W3C) standard for vector graphics is Scalable Vector Graphics (SVG). The standard is complex and has been relatively slow to be established at least in part owing to commercial interests. Many web browsers now have some support for rendering SVG data but full implementations of the standard are still comparatively rare.
In recent years, SVG has become a significant format that is completely independent of the resolution of the rendering device, typically a printer or display monitor. SVG files are essentially printable text that describes both straight and curved paths, as well as other attributes. Wikipedia prefers SVG for images such as simple maps, line illustrations, coats of arms, and flags, which generally are not like photographs or other continuous-tone images. Rendering SVG requires conversion to raster format at a resolution appropriate for the current task. SVG is also a format for animated graphics.
There is also a version of SVG for mobile phones. In particular, the specific format for mobile phones is called SVGT (SVG Tiny version). These images can count links and also exploit anti-aliasing. They can also be displayed as wallpaper.
Conversion.
Modern displays and printers are raster devices; vector formats have to be converted to raster format (bitmaps – pixel arrays) before they can be rendered (displayed or printed). The size of the bitmap/raster-format file generated by the conversion will depend on the resolution required, but the size of the vector file generating the bitmap/raster file will always remain the same. Thus, it is easy to convert from a vector file to a range of bitmap/raster file formats but it is much more difficult to go in the opposite direction, especially if subsequent editing of the vector picture is required. It might be an advantage to save an image created from a vector source file as a bitmap/raster format, because different systems have different (and incompatible) vector formats, and some might not support vector graphics at all. However, once a file is converted from the vector format, it is likely to be bigger, and it loses the advantage of scalability without loss of resolution. It will also no longer be possible to edit individual parts of the image as discrete objects. The file size of a vector graphic image depends on the number of graphic elements it contains; it is a list of descriptions.
Printing.
Vector art is ideal for printing since the art is made from a series of mathematical curves, it will print very crisply even when resized. For instance, one can print a vector logo on a small sheet of copy paper, and then enlarge the same vector logo to billboard size and keep the same crisp quality. A low-resolution raster graphic would blur or pixelate excessively if it were enlarged from business card size to billboard size. (The precise resolution of a raster graphic necessary for high-quality results depends on the viewing distance; e.g., a billboard may still appear to be of high quality even at low resolution if the viewing distance is great enough.)
If we regard typographic characters as images, then the same considerations that we have made for graphics apply even to composition of written text for printing (typesetting). Older character sets were stored as bitmaps. Therefore, to achieve maximum print quality they had to be used at a given resolution only; these font formats are said to be non-scalable. High quality typography is nowadays based on character drawings (fonts) which are typically stored as vector graphics, and as such are scalable to any size. Examples of these vector formats for characters are Postscript fonts and TrueType fonts.
Operation.
Advantages to this style of drawing over raster graphics:
For example, consider a circle of radius "r". The main pieces of information a program needs in order to draw this circle are
Vector formats are not always appropriate in graphics work and also have numerous disadvantages. For example, devices such as cameras and scanners produce essentially continuous-tone raster graphics that are impractical to convert into vectors, and so for this type of work, an image editor will operate on the pixels rather than on drawing objects defined by mathematical expressions. Comprehensive graphics tools will combine images from vector and raster sources, and may provide editing tools for both, since some parts of an image could come from a camera source, and others could have been drawn using vector tools.
Some authors have criticized the term "vector graphics" as being confusing. In particular, "vector graphics" does not simply refer to graphics described by Euclidean vectors. Some authors have proposed to use "object-oriented graphics" instead. However this term can also be confusing as it can be read as any kind of graphics implemented using object-oriented programming.
Typical primitive objects.
Any particular vector file format supports only some kinds of primitive objects.
Nearly all vector file formats support simple and fast-rendering primitive objects:
Most vector file formats support
A few vector file formats support more complex objects as primitives:
If an image stored in one vector file format is converted to another file format that supports all the primitive objects used in that particular image, then the conversion can be lossless.
Vector operations.
Vector graphics editors typically allow rotation, movement (without rotation), mirroring, stretching, skewing, affine transformations, changing of z-order (loosely, what's in front of what) and combination of primitives into more complex objects.
More sophisticated transformations include set operations on closed shapes (union, difference, intersection, etc.).
Vector graphics are ideal for simple or composite drawings that need to be device-independent, or do not need to achieve photo-realism. For example, the PostScript and PDF page description languages use a vector graphics model.

</doc>
<doc id="32500" url="https://en.wikipedia.org/wiki?curid=32500" title="Vacuum pump">
Vacuum pump

A vacuum pump is a device that removes gas molecules from a sealed volume in order to leave behind a partial vacuum. The first vacuum pump was invented in 1650 by Otto von Guericke, and was preceded by the suction pump, which dates to antiquity.
History.
The predecessor to the vacuum pump was the suction pump, which was known to the Romans. Dual-action suction pumps were found in the city of Pompeii. Arabic engineer Al-Jazari also described suction pumps in the 13th century. He said that his model was a larger version of the siphons the Byzantines used to discharge the Greek fire. The suction pump later reappeared in Europe from the 15th century.
By the 17th century, water pump designs had improved to the point that they produced measurable vacuums, but this was not immediately understood. What was known was that suction pumps could not pull water beyond a certain height: 18 Florentine yards according to a measurement taken around 1635. (The conversion to metres is uncertain, but it would be about 9 or 10 metres.) This limit was a concern to irrigation projects, mine drainage, and decorative water fountains planned by the Duke of Tuscany, so the Duke commissioned Galileo to investigate the problem. Galileo advertised the puzzle to other scientists, including Gaspar Berti who replicated it by building the first water barometer in Rome in 1639. Berti's barometer produced a vacuum above the water column, but he could not explain it. The breakthrough was made by Evangelista Torricelli in 1643. Building upon Galileo's notes, he built the first mercury barometer and wrote a convincing argument that the space at the top was a vacuum. The height of the column was then limited to the maximum weight that atmospheric pressure could support; this is the limiting height of a suction pump, Some people believe that although Torricelli's experiment was crucial, it was Blaise Pascal's experiments that proved the top space really contained vacuum.
In 1654, Otto von Guericke invented the first vacuum pump and conducted his famous Magdeburg hemispheres experiment, showing that teams of horses could not separate two hemispheres from which the air had been evacuated. Robert Boyle improved Guericke's design and conducted experiments on the properties of vacuum. Robert Hooke also helped Boyle produce an air pump which helped to produce the vacuum. The study of vacuum then lapsed until 1855, when Heinrich Geissler invented the mercury displacement pump and achieved a record vacuum of about 10 Pa (0.1 Torr). A number of electrical properties become observable at this vacuum level, and this renewed interest in vacuum. This, in turn, led to the development of the vacuum tube.
In the 19th century, Nikola Tesla designed an apparatus that contains a Sprengel pump to create a high degree of exhaustion.
Types.
Pumps can be broadly categorized according to three techniques:
Positive displacement pumps use a mechanism to repeatedly expand a cavity, allow gases to flow in from the chamber, seal off the cavity, and exhaust it to the atmosphere. Momentum transfer pumps, also called molecular pumps, use high speed jets of dense fluid or high speed rotating blades to knock gas molecules out of the chamber. Entrapment pumps capture gases in a solid or adsorbed state. This includes cryopumps, getters, and ion pumps.
Positive displacement pumps are the most effective for low vacuums. Momentum transfer pumps in conjunction with one or two positive displacement pumps are the most common configuration used to achieve high vacuums. In this configuration the positive displacement pump serves two purposes. First it obtains a rough vacuum in the vessel being evacuated before the momentum transfer pump can be used to obtain the high vacuum, as momentum transfer pumps cannot start pumping at atmospheric pressures. Second the positive displacement pump backs up the momentum transfer pump by evacuating to low vacuum the accumulation of displaced molecules in the high vacuum pump. Entrapment pumps can be added to reach ultrahigh vacuums, but they require periodic regeneration of the surfaces that trap air molecules or ions. Due to this requirement their available operational time can be unacceptably short in low and high vacuums, thus limiting their use to ultrahigh vacuums. Pumps also differ in details like manufacturing tolerances, sealing material, pressure, flow, admission or no admission of oil vapor, service intervals, reliability, tolerance to dust, tolerance to chemicals, tolerance to liquids and vibration.
Positive displacement pump.
A partial vacuum may be generated by increasing the volume of a container. To continue evacuating a chamber indefinitely without requiring infinite growth, a compartment of the vacuum can be repeatedly closed off, exhausted, and expanded again. This is the principle behind a positive displacement pump, for example the manual water pump. Inside the pump, a mechanism expands a small sealed cavity to reduce its pressure below that of the atmosphere. Because of the pressure differential, some fluid from the chamber (or the well, in our example) is pushed into the pump's small cavity. The pump's cavity is then sealed from the chamber, opened to the atmosphere, and squeezed back to a minute size.
More sophisticated systems are used for most industrial applications, but the basic principle of cyclic volume removal is the same:
The base pressure of a rubber- and plastic-sealed piston pump system is typically 1 to 50 kPa, while a scroll pump might reach 10 Pa (when new) and a rotary vane oil pump with a clean and empty metallic chamber can easily achieve 0.1 Pa.
A positive displacement vacuum pump moves the same volume of gas with each cycle, so its pumping speed is constant unless it is overcome by backstreaming.
Momentum transfer pump.
In a momentum transfer pump, gas molecules are accelerated from the vacuum side to the exhaust side (which is usually maintained at a reduced pressure by a positive displacement pump). Momentum transfer pumping is only possible below pressures of about 0.1 kPa. Matter flows differently at different pressures based on the laws of fluid dynamics. At atmospheric pressure and mild vacuums, molecules interact with each other and push on their neighboring molecules in what is known as viscous flow. When the distance between the molecules increases, the molecules interact with the walls of the chamber more often than with the other molecules, and molecular pumping becomes more effective than positive displacement pumping. This regime is generally called high vacuum.
Molecular pumps sweep out a larger area than mechanical pumps, and do so more frequently, making them capable of much higher pumping speeds. They do this at the expense of the seal between the vacuum and their exhaust. Since there is no seal, a small pressure at the exhaust can easily cause backstreaming through the pump; this is called stall. In high vacuum, however, pressure gradients have little effect on fluid flows, and molecular pumps can attain their full potential.
The two main types of molecular pumps are the diffusion pump and the turbomolecular pump. Both types of pumps blow out gas molecules that diffuse into the pump by imparting momentum to the gas molecules. Diffusion pumps blow out gas molecules with jets of oil or mercury, while turbomolecular pumps use high speed fans to push the gas. Both of these pumps will stall and fail to pump if exhausted directly to atmospheric pressure, so they must be exhausted to a lower grade vacuum created by a mechanical pump.
As with positive displacement pumps, the base pressure will be reached when leakage, outgassing, and backstreaming equal the pump speed, but now minimizing leakage and outgassing to a level comparable to backstreaming becomes much more difficult.
Regenerative pump.
Regenerative pumps utilize vortex behavior of the fluid (air). The construction is based on hybrid concept of centrifugal pump and turbopump. Usually it consists of several sets of perpendicular teeth on the rotor circulating air molecules inside stationary hollow grooves like multistage centrifugal pump. They can reach to 1×10−5 mbar (when combinging with Holweck pump) and directly exhaust to atmospheric pressure. Examples of such pumps are Edwards EPX (technical paper ) and Pfeiffer OnToolTM Booster 150. It is sometimes referred as side channel pump. Due to high pumping rate from atmosphere to high vacuum and less contamination since bearing can be installed at exhaust side, this type of pumps are used in load lock in semiconductor manufacturing processes.
This type of pump suffers from high power consumption(~1 kW) compare to turbomolecular pump (<100W) at low pressure since most power is consumed to back atmospheric pressure. This can be reduced by nearly 10 times by backing with a small pump.
Entrapment pump.
An entrapment pump may be a cryopump, which use cold temperatures to condense gases to a solid or adsorbed state, chemical pumps, which react with gases to produce a solid residue, or ion pumps, which use strong electrical fields to ionize gases and propel the ions into a solid substrate. A cryomodule uses cryopumping. Other types are the sorption pump and non-evaporative getter pump.
Performance measures.
Pumping speed refers to the volume flow rate of a pump at its inlet, often measured in volume per unit of time. Momentum transfer and entrapment pumps are more effective on some gases than others, so the pumping rate can be different for each of the gases being pumped, and the average volume flow rate of the pump will vary depending on the chemical composition of the gases remaining in the chamber.
Throughput refers to the pumping speed multiplied by the gas pressure at the inlet, and is measured in units of pressure·volume/unit time. At a constant temperature, throughput is proportional to the number of molecules being pumped per unit time, and therefore to the mass flow rate of the pump. When discussing a leak in the system or backstreaming through the pump, throughput refers to the volume leak rate multiplied by the pressure at the vacuum side of the leak, so the leak throughput can be compared to the pump throughput.
Positive displacement and momentum transfer pumps have a constant volume flow rate (pumping speed), but as the chamber's pressure drops, this volume contains less and less mass. So although the pumping speed remains constant, the throughput and mass flow rate drop exponentially. Meanwhile, the leakage, evaporation, sublimation and backstreaming rates continue to produce a constant throughput into the system.
Techniques.
Vacuum pumps are combined with chambers and operational procedures into a wide variety of vacuum systems. Sometimes more than one pump will be used (in series or in parallel) in a single application. A partial vacuum, or rough vacuum, can be created using a positive displacement pump that transports a gas load from an inlet port to an outlet (exhaust) port. Because of their mechanical limitations, such pumps can only achieve a low vacuum. To achieve a higher vacuum, other techniques must then be used, typically in series (usually following an initial fast pump down with a positive displacement pump). Some examples might be use of an oil sealed rotary vane pump (the most common positive displacement pump) backing a diffusion pump, or a dry scroll pump backing a turbomolecular pump. There are other combinations depending on the level of vacuum being sought.
Achieving high vacuum is difficult because all of the materials exposed to the vacuum must be carefully evaluated for their outgassing and vapor pressure properties. For example, oils, and greases, and rubber, or plastic gaskets used as seals for the vacuum chamber must not boil off when exposed to the vacuum, or the gases they produce would prevent the creation of the desired degree of vacuum. Often, all of the surfaces exposed to the vacuum must be baked at high temperature to drive off adsorbed gases.
Outgassing can also be reduced simply by desiccation prior to vacuum pumping.
High vacuum systems generally require metal chambers with metal gasket seals such as Klein flanges or ISO flanges, rather than the rubber gaskets more common in low vacuum chamber seals. The system must be clean and free of organic matter to minimize outgassing. All materials, solid or liquid, have a small vapour pressure, and their outgassing becomes important when the vacuum pressure falls below this vapour pressure. As a result, many materials that work well in low vacuums, such as epoxy, will become a source of outgassing at higher vacuums.
With these standard precautions, vacuums of 1 mPa are easily achieved with an assortment of molecular pumps. With careful design and operation, 1 µPa is possible.
Several types of pumps may be used in sequence or in parallel. In a typical pumpdown sequence, a positive displacement pump would be used to remove most of the gas from a chamber, starting from atmosphere (760 Torr, 101 kPa) to 25 Torr (3 kPa). Then a sorption pump would be used to bring the pressure down to 10−4 Torr (10 mPa). A cryopump or turbomolecular pump would be used to bring the pressure further down to 10−8 Torr (1 µPa). An additional ion pump can be started below 10−6 Torr to remove gases which are not adequately handled by a cryopump or turbo pump, such as helium or hydrogen.
Ultra high vacuum generally requires custom-built equipment, strict operational procedures, and a fair amount of trial-and-error. Ultra-high vacuum systems are usually made of stainless steel with metal-gasketed vacuum flanges. The system is usually baked, preferably under vacuum, to temporarily raise the vapour pressure of all outgassing materials in the system and boil them off. If necessary, this outgassing of the system can also be performed at room temperature, but this takes much more time. Once the bulk of the outgassing materials are boiled off and evacuated, the system may be cooled to lower vapour pressures to minimize residual outgassing during actual operation. Some systems are cooled well below room temperature by liquid nitrogen to shut down residual outgassing and simultaneously cryopump the system.
In ultra-high vacuum systems, some very odd leakage paths and outgassing sources must be considered. The water absorption of aluminium and palladium becomes an unacceptable source of outgassing, and even the absorptivity of hard metals such as stainless steel or titanium must be considered. Some oils and greases will boil off in extreme vacuums. The porosity of the metallic vacuum chamber walls may have to be considered, and the grain direction of the metallic flanges should be parallel to the flange face.
The impact of molecular size must be considered. Smaller molecules can leak in more easily and are more easily absorbed by certain materials, and molecular pumps are less effective at pumping gases with lower molecular weights. A system may be able to evacuate nitrogen (the main component of air) to the desired vacuum, but the chamber could still be full of residual atmospheric hydrogen and helium. Vessels lined with a highly gas-permeable material such as palladium (which is a high-capacity hydrogen sponge) create special outgassing problems.
Applications.
Vacuum pumps are used in many industrial and scientific processes including composite plastic moulding processes, driving some of the flight instruments in older and simpler aircraft without electrical systems, production of most types of electric lamps, vacuum tubes, and CRTs where the device is either left evacuated or re-filled with a specific gas or gas mixture, semiconductor processing, notably ion implantation, dry etch and PVD, ALD, PECVD and CVD deposition and so on in photolithography, electron microscopy, medical processes that require suction, uranium enrichment, medical applications such as radiotherapy, radiosurgery and radiopharmacy, analytical instrumentation to analyse gas, liquid, solid, surface and bio materials, mass spectrometers to create a high vacuum between the ion source and the detector, vacuum coating on glass, metal and plastics for decoration, for durability and for energy saving, such as low-emissivity glass, hard coating for engine components (as in Formula One), ophthalmic coating, milking machines and other equipment in dairy sheds, vacuum impregnation of porous products such as wood or electric motor windings, air conditioning service (removing all contaminants from the system before charging with refrigerant), trash compactor, vacuum engineering, sewage systems (see EN1091:1997 standards), freeze drying, and fusion research
Vacuum may be used to power, or provide assistance to mechanical devices. In hybrid and diesel engine motor vehicles, a pump fitted on the engine (usually on the camshaft) is used to produce vacuum. In petrol engines, instead, vacuum is typically obtained as a side-effect of the operation of the engine and the flow restriction created by the throttle plate, but may be also supplemented by an electrically operated vacuum pump to boost braking assistance or improve fuel consumption. This vacuum may then be used to power the following motor vehicle components: vacuum servo booster for the hydraulic brakes, motors that move dampers in the ventilation system, throttle driver in the cruise control servomechanism, door locks or trunk releases.
In an aircraft, the vacuum source is often used to power gyroscopes in the various flight instruments. To prevent the complete loss of instrumentation in the event of an electrical failure, the instrument panel is deliberately designed with certain instruments powered by electricity and other instruments powered by the vacuum source.
Hazards.
Old vacuum-pump oils that were produced before circa 1980 often contain a mixture of several different dangerous polychlorinated biphenyls (PCBs), which are highly toxic, carcinogenic, persistent organic pollutants.

</doc>
<doc id="32502" url="https://en.wikipedia.org/wiki?curid=32502" title="Vacuum">
Vacuum

Vacuum is space void of matter. The word stems from the Latin adjective "vacuus" for "vacant" or "void". An approximation to such vacuum is a region with a gaseous pressure much less than atmospheric pressure. Physicists often discuss ideal test results that would occur in a "perfect" vacuum, which they sometimes simply call "vacuum" or free space, and use the term partial vacuum to refer to an actual imperfect vacuum as one might have in a laboratory or in space. In engineering and applied physics on the other hand, vacuum refers to any space in which the pressure is lower than atmospheric pressure. The Latin term in vacuo is used to describe an object as being in what would otherwise be a vacuum.
The "quality" of a partial vacuum refers to how closely it approaches a perfect vacuum. Other things equal, lower gas pressure means higher-quality vacuum. For example, a typical vacuum cleaner produces enough suction to reduce air pressure by around 20%. Much higher-quality vacuums are possible. Ultra-high vacuum chambers, common in chemistry, physics, and engineering, operate below one trillionth (10−12) of atmospheric pressure (100 nPa), and can reach around 100 particles/cm3. Outer space is an even higher-quality vacuum, with the equivalent of just a few hydrogen atoms per cubic meter on average. According to modern understanding, even if all matter could be removed from a volume, it would still not be "empty" due to vacuum fluctuations, dark energy, transiting gamma rays, cosmic rays, neutrinos, and other phenomena in quantum physics. In the electromagnetism in the 19th century, vacuum was thought to be filled with a medium called aether. In modern particle physics, the vacuum state is considered the ground state of matter.
Vacuum has been a frequent topic of philosophical debate since ancient Greek times, but was not studied empirically until the 17th century. Evangelista Torricelli produced the first laboratory vacuum in 1643, and other experimental techniques were developed as a result of his theories of atmospheric pressure. A torricellian vacuum is created by filling a tall glass container closed at one end with mercury, and then inverting the container into a bowl to contain the mercury.
Vacuum became a valuable industrial tool in the 20th century with the introduction of incandescent light bulbs and vacuum tubes, and a wide array of vacuum technology has since become available. The recent development of human spaceflight has raised interest in the impact of vacuum on human health, and on life forms in general.
Etymology.
The word "vacuum" comes , noun use of neuter of "vacuus", meaning "empty", related to "vacare", meaning "be empty".
"Vacuum" is one of the few words in the English language that contains two consecutive letters "u"'.
Historical interpretation.
Historically, there has been much dispute over whether such a thing as a vacuum can exist. Ancient Greek philosophers debated the existence of a vacuum, or void, in the context of atomism, which posited void and atom as the fundamental explanatory elements of physics. Following Plato, even the abstract concept of a featureless void faced considerable skepticism: it could not be apprehended by the senses, it could not, itself, provide additional explanatory power beyond the physical volume with which it was commensurate and, by definition, it was quite literally nothing at all, which cannot rightly be said to exist. Aristotle believed that no void could occur naturally, because the denser surrounding material continuum would immediately fill any incipient rarity that might give rise to a void.
In his "Physics", book IV, Aristotle offered numerous arguments against the void: for example, that motion through a medium which offered no impediment could continue "ad infinitum", there being no reason that something would come to rest anywhere in particular. Although Lucretius argued for the existence of vacuum in the first century BC and Hero of Alexandria tried unsuccessfully to create an artificial vacuum in the first century AD, it was European scholars such as Roger Bacon, Blasius of Parma and Walter Burley in the 13th and 14th century who focused considerable attention on these issues. Eventually following Stoic physics in this instance, scholars from the 14th century onward increasingly departed from the Aristotelian perspective in favor of a supernatural void beyond the confines of the cosmos itself, a conclusion widely acknowledged by the 17th century, which helped to segregate natural and theological concerns.
Almost two thousand years after Plato, René Descartes also proposed a geometrically based alternative theory of atomism, without the problematic nothing–everything dichotomy of void and atom. Although Descartes agreed with the contemporary position, that a vacuum does not occur in nature, the success of his namesake coordinate system and more implicitly, the spatial–corporeal component of his metaphysics would come to define the philosophically modern notion of empty space as a quantified extension of volume. By the ancient definition however, directional information and magnitude were conceptually distinct. With the acquiescence of Cartesian mechanical philosophy to the "brute fact" of action at a distance, and at length, its successful reification by force fields and ever more sophisticated geometric structure, the anachronism of empty space widened until "a seething ferment" of quantum activity in the 20th century filled the vacuum with a virtual pleroma.
The explanation of a "clepsydra" or water clock was a popular topic in the Middle Ages. Although a simple wine skin sufficed to demonstrate a partial vacuum, in principle, more advanced suction pumps had been developed in Roman Pompeii.
In the medieval Middle Eastern world, the physicist and Islamic scholar, Al-Farabi (Alpharabius, 872–950), conducted a small experiment concerning the existence of vacuum, in which he investigated handheld plungers in water. He concluded that air's volume can expand to fill available space, and he suggested that the concept of perfect vacuum was incoherent. However, according to Nader El-Bizri, the physicist Ibn al-Haytham (Alhazen, 965–1039) and the Mu'tazili theologians disagreed with Aristotle and Al-Farabi, and they supported the existence of a void. Using geometry, Ibn al-Haytham mathematically demonstrated that place ("al-makan") is the imagined three-dimensional void between the inner surfaces of a containing body. According to Ahmad Dallal, Abū Rayhān al-Bīrūnī also states that "there is no observable evidence that rules out the possibility of vacuum". The suction pump later appeared in Europe from the 15th century.
Medieval thought experiments into the idea of a vacuum considered whether a vacuum was present, if only for an instant, between two flat plates when they were rapidly separated. There was much discussion of whether the air moved in quickly enough as the plates were separated, or, as Walter Burley postulated, whether a 'celestial agent' prevented the vacuum arising. The commonly held view that nature abhorred a vacuum was called "horror vacui". Speculation that even God could not create a vacuum if he wanted to was shut down by the 1277 Paris condemnations of Bishop Etienne Tempier, which required there to be no restrictions on the powers of God, which led to the conclusion that God could create a vacuum if he so wished.
Jean Buridan reported in the 14th century that teams of ten horses could not pull open bellows when the port was sealed.
The 17th century saw the first attempts to quantify measurements of partial vacuum. Evangelista Torricelli's mercury barometer of 1643 and Blaise Pascal's experiments that both demonstrated a partial vacuum.
In 1654, Otto von Guericke invented the first vacuum pump and conducted his famous Magdeburg hemispheres experiment, showing that teams of horses could not separate two hemispheres from which the air had been partially evacuated. Robert Boyle improved Guericke's design and with the help of Robert Hooke further developed vacuum pump technology. Thereafter, research into the partial vacuum lapsed until 1850 when August Toepler invented the Toepler Pump and Heinrich Geissler invented the mercury displacement pump in 1855, achieving a partial vacuum of about 10 Pa (0.1 Torr). A number of electrical properties become observable at this vacuum level, which renewed interest in further research.
While outer space provides the most rarefied example of a naturally occurring partial vacuum, the heavens were originally thought to be seamlessly filled by a rigid indestructible material called aether. Borrowing somewhat from the pneuma of Stoic physics, aether came to be regarded as the rarefied air from which it took its name, (see Aether (mythology)). Early theories of light posited a ubiquitous terrestrial and celestial medium through which light propagated. Additionally, the concept informed Isaac Newton's explanations of both refraction and of radiant heat. 19th century experiments into this luminiferous aether attempted to detect a minute drag on the Earth's orbit. While the Earth does, in fact, move through a relatively dense medium in comparison to that of interstellar space, the drag is so minuscule that it could not be detected. In 1912, astronomer Henry Pickering commented: "While the interstellar absorbing medium may be simply the ether, is characteristic of a gas, and free gaseous molecules are certainly there".
In 1930, Paul Dirac proposed a model of the vacuum as an infinite sea of particles possessing negative energy, called the Dirac sea. This theory helped refine the predictions of his earlier formulated Dirac equation, and successfully predicted the existence of the positron, confirmed two years later. Werner Heisenberg's uncertainty principle formulated in 1927, predict a fundamental limit within which instantaneous position and momentum, or energy and time can be measured. This has far reaching consequences on the "emptiness" of space between particles. In the late 20th century, so-called virtual particles that arise spontaneously from empty space were confirmed.
Classical field theories.
The strictest criteria to define a vacuum is a region of space and time where all the components of the stress–energy tensor are zero. It means that this region is empty of energy and momentum, and by consequence, it must be empty of particles and other physical fields (such as electromagnetism) that contain energy and momentum.
Gravity.
In general relativity, a vanishing stress-energy tensor implies, through Einstein field equations, the vanishing of all the components of the Ricci tensor. Vacuum does not mean that the curvature of space-time is necessarily flat: the gravitational field can still produce curvature in a vacuum in the form of tidal forces and gravitational waves (technically, these phenomena are the components of the Weyl tensor). The black hole (with zero electric charge) is an elegant example of a region completely "filled" with vacuum, but still showing a strong curvature.
Electromagnetism.
In classical electromagnetism, the vacuum of free space, or sometimes just "free space" or "perfect vacuum", is a standard reference medium for electromagnetic effects. Some authors refer to this reference medium as "classical vacuum", a terminology intended to separate this concept from QED vacuum or QCD vacuum, where vacuum fluctuations can produce transient virtual particle densities and a relative permittivity and relative permeability that are not identically unity.
In the theory of classical electromagnetism, free space has the following properties:
The vacuum of classical electromagnetism can be viewed as an idealized electromagnetic medium with the constitutive relations in SI units:
relating the electric displacement field D to the electric field E and the magnetic field or "H"-field H to the magnetic induction or "B"-field B. Here r is a spatial location and "t" is time.
Quantum mechanics.
In quantum mechanics and quantum field theory, the vacuum is defined as the state (that is, the solution to the equations of the theory) with the lowest possible energy (the ground state of the Hilbert space). In quantum electrodynamics this vacuum is referred to as 'QED vacuum' to distinguish it from the vacuum of quantum chromodynamics, denoted as QCD vacuum. QED vacuum is a state with no matter particles (hence the name), and also no photons. As described above, this state is impossible to achieve experimentally. (Even if every matter particle could somehow be removed from a volume, it would be impossible to eliminate all the blackbody photons.) Nonetheless, it provides a good model for realizable vacuum, and agrees with a number of experimental observations as described next.
QED vacuum has interesting and complex properties. In QED vacuum, the electric and magnetic fields have zero average values, but their variances are not zero. As a result, QED vacuum contains vacuum fluctuations (virtual particles that hop into and out of existence), and a finite energy called vacuum energy. Vacuum fluctuations are an essential and ubiquitous part of quantum field theory. Some experimentally verified effects of vacuum fluctuations include spontaneous emission and the Lamb shift. Coulomb's law and the electric potential in vacuum near an electric charge are modified.
Theoretically, in QCD vacuum multiple vacuum states can coexist. The starting and ending of cosmological inflation is thought to have arisen from transitions between different vacuum states. For theories obtained by quantization of a classical theory, each stationary point of the energy in the configuration space gives rise to a single vacuum. String theory is believed to have a huge number of vacua — the so-called string theory landscape.
Outer space.
Outer space has very low density and pressure, and is the closest physical approximation of a perfect vacuum. But no vacuum is truly perfect, not even in interstellar space, where there are still a few hydrogen atoms per cubic meter.
Stars, planets, and moons keep their atmospheres by gravitational attraction, and as such, atmospheres have no clearly delineated boundary: the density of atmospheric gas simply decreases with distance from the object. The Earth's atmospheric pressure drops to about at of altitude, the Kármán line, which is a common definition of the boundary with outer space. Beyond this line, isotropic gas pressure rapidly becomes insignificant when compared to radiation pressure from the Sun and the dynamic pressure of the solar winds, so the definition of pressure becomes difficult to interpret. The thermosphere in this range has large gradients of pressure, temperature and composition, and varies greatly due to space weather. Astrophysicists prefer to use number density to describe these environments, in units of particles per cubic centimetre.
But although it meets the definition of outer space, the atmospheric density within the first few hundred kilometers above the Kármán line is still sufficient to produce significant drag on satellites. Most artificial satellites operate in this region called low Earth orbit and must fire their engines every few days to maintain orbit. The drag here is low enough that it could theoretically be overcome by radiation pressure on solar sails, a proposed propulsion system for interplanetary travel. Planets are too massive for their trajectories to be significantly affected by these forces, although their atmospheres are eroded by the solar winds.
All of the observable universe is filled with large numbers of photons, the so-called cosmic background radiation, and quite likely a correspondingly large number of neutrinos. The current temperature of this radiation is about 3 K, or −270 degrees Celsius or −454 degrees Fahrenheit.
Measurement.
The quality of a vacuum is indicated by the amount of matter remaining in the system, so that a high quality vacuum is one with very little matter left in it. Vacuum is primarily measured by its absolute pressure, but a complete characterization requires further parameters, such as temperature and chemical composition. One of the most important parameters is the mean free path (MFP) of residual gases, which indicates the average distance that molecules will travel between collisions with each other. As the gas density decreases, the MFP increases, and when the MFP is longer than the chamber, pump, spacecraft, or other objects present, the continuum assumptions of fluid mechanics do not apply. This vacuum state is called "high vacuum", and the study of fluid flows in this regime is called particle gas dynamics. The MFP of air at atmospheric pressure is very short, 70 nm, but at 100 mPa (~) the MFP of room temperature air is roughly 100 mm, which is on the order of everyday objects such as vacuum tubes. The Crookes radiometer turns when the MFP is larger than the size of the vanes.
Vacuum quality is subdivided into ranges according to the technology required to achieve it or measure it. These ranges do not have universally agreed definitions, but a typical distribution is shown in the following table. As we travel into orbit, outer space and ultimately intergalactic space, the pressure varies by several orders of magnitude.
Relative versus absolute measurement.
Vacuum is measured in units of pressure, typically as a subtraction relative to ambient atmospheric pressure on Earth. But the amount of relative measurable vacuum varies with local conditions. On the surface of Jupiter, where ground level atmospheric pressure is much higher than on Earth, much higher relative vacuum readings would be possible. On the surface of the moon with almost no atmosphere, it would be extremely difficult to create a measurable vacuum relative to the local environment.
Similarly, much higher than normal relative vacuum readings are possible deep in the Earth's ocean. A submarine maintaining an internal pressure of 1 atmosphere submerged to a depth of 10 atmospheres (98 metres; a 9.8 metre column of seawater has the equivalent weight of 1 atm) is effectively a vacuum chamber keeping out the crushing exterior water pressures, though the 1 atm inside the submarine would not normally be considered a vacuum.
Therefore, to properly understand the following discussions of vacuum measurement, it is important that the reader assumes the relative measurements are being done on Earth at sea level, at exactly 1 atmosphere of ambient atmospheric pressure.
Measurements relative to 1 atm.
The SI unit of pressure is the pascal (symbol Pa), but vacuum is often measured in torrs, named for Torricelli, an early Italian physicist (1608–1647). A torr is equal to the displacement of a millimeter of mercury (mmHg) in a manometer with 1 torr equaling 133.3223684 pascals above absolute zero pressure. Vacuum is often also measured on the barometric scale or as a percentage of atmospheric pressure in bars or atmospheres. Low vacuum is often measured in millimeters of mercury (mmHg) or pascals (Pa) below standard atmospheric pressure. "Below atmospheric" means that the absolute pressure is equal to the current atmospheric pressure.
In other words, most low vacuum gauges that read, for example 50.79 Torr. Many inexpensive low vacuum gauges have a margin of error and may report a vacuum of 0 Torr but in practice this generally requires a two-stage rotary vane or other medium type of vacuum pump to go much beyond (lower than) 1 torr.
Measuring instruments.
Many devices are used to measure the pressure in a vacuum, depending on what range of vacuum is needed.
Hydrostatic gauges (such as the mercury column manometer) consist of a vertical column of liquid in a tube whose ends are exposed to different pressures. The column will rise or fall until its weight is in equilibrium with the pressure differential between the two ends of the tube. The simplest design is a closed-end U-shaped tube, one side of which is connected to the region of interest. Any fluid can be used, but mercury is preferred for its high density and low vapour pressure. Simple hydrostatic gauges can measure pressures ranging from 1 torr (100 Pa) to above atmospheric. An important variation is the McLeod gauge which isolates a known volume of vacuum and compresses it to multiply the height variation of the liquid column. The McLeod gauge can measure vacuums as high as 10−6 torr (0.1 mPa), which is the lowest direct measurement of pressure that is possible with current technology. Other vacuum gauges can measure lower pressures, but only indirectly by measurement of other pressure-controlled properties. These indirect measurements must be calibrated via a direct measurement, most commonly a McLeod gauge.
The kenotometer is a particular type of hydrostatic gauge, typically used in power plants using steam turbines. The kenotometer measures the vacuum in the steam space of the condenser, that is, the exhaust of the last stage of the turbine.
Mechanical or elastic gauges depend on a Bourdon tube, diaphragm, or capsule, usually made of metal, which will change shape in response to the pressure of the region in question. A variation on this idea is the capacitance manometer, in which the diaphragm makes up a part of a capacitor. A change in pressure leads to the flexure of the diaphragm, which results in a change in capacitance. These gauges are effective from 103 torr to 10−4 torr, and beyond.
Thermal conductivity gauges rely on the fact that the ability of a gas to conduct heat decreases with pressure. In this type of gauge, a wire filament is heated by running current through it. A thermocouple or Resistance Temperature Detector (RTD) can then be used to measure the temperature of the filament. This temperature is dependent on the rate at which the filament loses heat to the surrounding gas, and therefore on the thermal conductivity. A common variant is the Pirani gauge which uses a single platinum filament as both the heated element and RTD. These gauges are accurate from 10 torr to 10−3 torr, but they are sensitive to the chemical composition of the gases being measured.
Ion gauges are used in ultrahigh vacuum. They come in two types: hot cathode and cold cathode. In the hot cathode version an electrically heated filament produces an electron beam. The electrons travel through the gauge and ionize gas molecules around them. The resulting ions are collected at a negative electrode. The current depends on the number of ions, which depends on the pressure in the gauge. Hot cathode gauges are accurate from 10−3 torr to 10−10 torr. The principle behind cold cathode version is the same, except that electrons are produced in a discharge created by a high voltage electrical discharge. Cold cathode gauges are accurate from 10−2 torr to 10−9 torr. Ionization gauge calibration is very sensitive to construction geometry, chemical composition of gases being measured, corrosion and surface deposits. Their calibration can be invalidated by activation at atmospheric pressure or low vacuum. The composition of gases at high vacuums will usually be unpredictable, so a mass spectrometer must be used in conjunction with the ionization gauge for accurate measurement.
Uses.
Vacuum is useful in a variety of processes and devices. Its first widespread use was in the incandescent light bulb to protect the filament from chemical degradation. The chemical inertness produced by a vacuum is also useful for electron beam welding, cold welding, vacuum packing and vacuum frying. Ultra-high vacuum is used in the study of atomically clean substrates, as only a very good vacuum preserves atomic-scale clean surfaces for a reasonably long time (on the order of minutes to days). High to ultra-high vacuum removes the obstruction of air, allowing particle beams to deposit or remove materials without contamination. This is the principle behind chemical vapor deposition, physical vapor deposition, and dry etching which are essential to the fabrication of semiconductors and optical coatings, and to surface science. The reduction of convection provides the thermal insulation of thermos bottles. Deep vacuum lowers the boiling point of liquids and promotes low temperature outgassing which is used in freeze drying, adhesive preparation, distillation, metallurgy, and process purging. The electrical properties of vacuum make electron microscopes and vacuum tubes possible, including cathode ray tubes. The elimination of air friction is useful for flywheel energy storage and ultracentrifuges.
Vacuum-driven machines.
Vacuums are commonly used to produce suction, which has an even wider variety of applications. The Newcomen steam engine used vacuum instead of pressure to drive a piston. In the 19th century, vacuum was used for traction on Isambard Kingdom Brunel's experimental atmospheric railway. Vacuum brakes were once widely used on trains in the UK but, except on heritage railways, they have been replaced by air brakes.
Manifold vacuum can be used to drive accessories on automobiles. The best-known application is the vacuum servo, used to provide power assistance for the brakes. Obsolete applications include vacuum-driven windscreen wipers and Autovac fuel pumps. Some aircraft instruments (Attitude Indicator (AI) and the Heading Indicator (HI)) are typically vacuum-powered, as protection against loss of all (electrically powered) instruments, since early aircraft often did not have electrical systems, and since there are two readily available sources of vacuum on a moving aircraft—the engine and an external venturi.
Vacuum induction melting uses electromagnetic induction within a vacuum.
Maintaining a vacuum in the Condenser is an important aspect of the efficient operation of steam turbines. A steam jet ejector or liquid ring vacuum pump is used for this purpose. The typical vacuum maintained in the Condenser steam space at the exhaust of the turbine (also called Condenser Backpressure) is in the range 5 to 15 kPa (absolute), depending on the type of condenser and the ambient conditions.
Outgassing.
Evaporation and sublimation into a vacuum is called outgassing. All materials, solid or liquid, have a small vapour pressure, and their outgassing becomes important when the vacuum pressure falls below this vapour pressure. In man-made systems, outgassing has the same effect as a leak and can limit the achievable vacuum. Outgassing products may condense on nearby colder surfaces, which can be troublesome if they obscure optical instruments or react with other materials. This is of great concern to space missions, where an obscured telescope or solar cell can ruin an expensive mission.
The most prevalent outgassing product in man-made vacuum systems is water absorbed by chamber materials. It can be reduced by desiccating or baking the chamber, and removing absorbent materials. Outgassed water can condense in the oil of rotary vane pumps and reduce their net speed drastically if gas ballasting is not used. High vacuum systems must be clean and free of organic matter to minimize outgassing.
Ultra-high vacuum systems are usually baked, preferably under vacuum, to temporarily raise the vapour pressure of all outgassing materials and boil them off. Once the bulk of the outgassing materials are boiled off and evacuated, the system may be cooled to lower vapour pressures and minimize residual outgassing during actual operation. Some systems are cooled well below room temperature by liquid nitrogen to shut down residual outgassing and simultaneously cryopump the system.
Pumping and ambient air pressure.
Fluids cannot generally be pulled, so a vacuum cannot be created by suction. Suction can spread and dilute a vacuum by letting a higher pressure push fluids into it, but the vacuum has to be created first before suction can occur. The easiest way to create an artificial vacuum is to expand the volume of a container. For example, the diaphragm muscle expands the chest cavity, which causes the volume of the lungs to increase. This expansion reduces the pressure and creates a partial vacuum, which is soon filled by air pushed in by atmospheric pressure.
To continue evacuating a chamber indefinitely without requiring infinite growth, a compartment of the vacuum can be repeatedly closed off, exhausted, and expanded again. This is the principle behind positive displacement pumps, like the manual water pump for example. Inside the pump, a mechanism expands a small sealed cavity to create a vacuum. Because of the pressure differential, some fluid from the chamber (or the well, in our example) is pushed into the pump's small cavity. The pump's cavity is then sealed from the chamber, opened to the atmosphere, and squeezed back to a minute size.
The above explanation is merely a simple introduction to vacuum pumping, and is not representative of the entire range of pumps in use. Many variations of the positive displacement pump have been developed, and many other pump designs rely on fundamentally different principles. Momentum transfer pumps, which bear some similarities to dynamic pumps used at higher pressures, can achieve much higher quality vacuums than positive displacement pumps. Entrapment pumps can capture gases in a solid or absorbed state, often with no moving parts, no seals and no vibration. None of these pumps are universal; each type has important performance limitations. They all share a difficulty in pumping low molecular weight gases, especially hydrogen, helium, and neon.
The lowest pressure that can be attained in a system is also dependent on many things other than the nature of the pumps. Multiple pumps may be connected in series, called stages, to achieve higher vacuums. The choice of seals, chamber geometry, materials, and pump-down procedures will all have an impact. Collectively, these are called "vacuum technique". And sometimes, the final pressure is not the only relevant characteristic. Pumping systems differ in oil contamination, vibration, preferential pumping of certain gases, pump-down speeds, intermittent duty cycle, reliability, or tolerance to high leakage rates.
In ultra high vacuum systems, some very "odd" leakage paths and outgassing sources must be considered. The water absorption of aluminium and palladium becomes an unacceptable source of outgassing, and even the adsorptivity of hard metals such as stainless steel or titanium must be considered. Some oils and greases will boil off in extreme vacuums. The permeability of the metallic chamber walls may have to be considered, and the grain direction of the metallic flanges should be parallel to the flange face.
The lowest pressures currently achievable in laboratory are about 10−13 torr (13 pPa). However, pressures as low as (6.7 fPa) have been indirectly measured in a 4 K cryogenic vacuum system. This corresponds to ≈100 particles/cm3.
Effects on humans and animals.
Humans and animals exposed to vacuum will lose consciousness after a few seconds and die of hypoxia within minutes, but the symptoms are not nearly as graphic as commonly depicted in media and popular culture. The reduction in pressure lowers the temperature at which blood and other body fluids boil, but the elastic pressure of blood vessels ensures that this boiling point remains above the internal body temperature of Although the blood will not boil, the formation of gas bubbles in bodily fluids at reduced pressures, known as ebullism, is still a concern. The gas may bloat the body to twice its normal size and slow circulation, but tissues are elastic and porous enough to prevent rupture. Swelling and ebullism can be restrained by containment in a flight suit. Shuttle astronauts wore a fitted elastic garment called the Crew Altitude Protection Suit (CAPS) which prevents ebullism at pressures as low as 2 kPa (15 Torr). Rapid boiling will cool the skin and create frost, particularly in the mouth, but this is not a significant hazard.
Animal experiments show that rapid and complete recovery is normal for exposures shorter than 90 seconds, while longer full-body exposures are fatal and resuscitation has never been successful. There is only a limited amount of data available from human accidents, but it is consistent with animal data. Limbs may be exposed for much longer if breathing is not impaired. Robert Boyle was the first to show in 1660 that vacuum is lethal to small animals.
An experiment indicates that plants are able to survive in a low pressure environment (1.5 kPa) for about 30 minutes.
During 1942, in one of a series of experiments on human subjects for the Luftwaffe, the Nazi regime experimented on prisoners in Dachau concentration camp by exposing them to low pressure.
Cold or oxygen-rich atmospheres can sustain life at pressures much lower than atmospheric, as long as the density of oxygen is similar to that of standard sea-level atmosphere. The colder air temperatures found at altitudes of up to 3 km generally compensate for the lower pressures there. Above this altitude, oxygen enrichment is necessary to prevent altitude sickness in humans that did not undergo prior acclimatization, and spacesuits are necessary to prevent ebullism above 19 km. Most spacesuits use only 20 kPa (150 Torr) of pure oxygen. This pressure is high enough to prevent ebullism, but decompression sickness and gas embolisms can still occur if decompression rates are not managed.
Rapid decompression can be much more dangerous than vacuum exposure itself. Even if the victim does not hold his or her breath, venting through the windpipe may be too slow to prevent the fatal rupture of the delicate alveoli of the lungs. Eardrums and sinuses may be ruptured by rapid decompression, soft tissues may bruise and seep blood, and the stress of shock will accelerate oxygen consumption leading to hypoxia. Injuries caused by rapid decompression are called barotrauma. A pressure drop of 13 kPa (100 Torr), which produces no symptoms if it is gradual, may be fatal if it occurs suddenly.
Some extremophile microrganisms, such as tardigrades, can survive vacuum for a period of days or weeks.

</doc>
<doc id="32503" url="https://en.wikipedia.org/wiki?curid=32503" title="Villa Savoye">
Villa Savoye

Villa Savoye () is a modernist villa in Poissy, in the outskirts of Paris, France. It was designed by Swiss architects Le Corbusier and his cousin, Pierre Jeanneret, and built between 1928 and 1931 using reinforced concrete.
A manifesto of Le Corbusier's "five points" of new architecture, the villa is representative of the bases of modern architecture, and is one of the most easily recognizable and renowned examples of the International style.
The house was originally built as a country retreat on behest of the Savoye family. After being purchased by the neighbouring school it passed on to be property of the French state in 1958, and after surviving several plans of demolition, it was designated as an official French historical monument in 1965 (a rare occurrence, as Le Corbusier was still living at the time). It was thoroughly renovated from 1985 to 1997, and under the care of the Centre des monuments nationaux, the refurbished house is now open to visitors year-round.
Background.
By the end of the 1920s Corbusier was already an internationally known architect. His book "Vers une Architecture" had been translated into several languages, his work with the Centrosoyuz in Moscow involved him with the Russian avant-garde and his problems with the League of Nations competition had been widely publicised. Also he was one of the first members of Congrès International d'Architecture Moderne (CIAM) and was becoming known as a champion of modern architecture.
The villas designed by Corbusier in the early part of the 1920s demonstrated what he termed the "precision" of architecture, where each feature of the design needed to be justified in design and urban terms. His work in the later part of the decade, including his urban designs for Algiers, began to be more free-form.
History of the commission.
Pierre and Emilie Savoye approached Corbusier about building a country home in Poissy in the spring of 1928. The site was on a green field on an otherwise wooded plot of land with a magnificent landscape view to the north west that corresponded with the approach to the site along the road. Other than an initial brief prepared by Emile for a summer house, space for cars, an extra bedroom and a caretaker's lodge, Corbusier had such freedom with the job that he was only limited by his own architectural palette. He began work on the project in September 1928. His initial ideas were those that eventually manifested themselves in the final building but between Autumn 1928 and Spring 1929 he undertook a series of alternatives that were influenced primarily by the Savoye's concern about cost. The eventual solution to this problem was to reduce the volume of the building by moving the master bedroom down to the first floor and reducing the grid spacing down from 5 metres to 4.75 metres.
Construction.
Estimates of the cost in February 1929 were approximately half a million Francs, although this excluded the cost of the lodge and the landscaping elements (almost twice the original budget). The project was tendered in February with contracts awarded in March 1929. Changes made to the design whilst the project was being built including an amendment to the storey height and the exclusion and then re-introduction of the chauffeur's accommodation led to the costs rising to approximately 800,000 Francs. At the time the project started on site no design work had been done on the lodge and the final design was only presented to the client in June 1929. The design was for a double lodge but this was reduced to a single lodge as the costs were too high. Although construction of the whole house was complete within a year it was not habitable until 1931.
Design.
The Villa Savoye is probably Corbusier's best known building from the 1930s, and it had enormous influence on international modernism. It was designed addressing his emblematic "Five Points", the basic tenets in his new architectural aesthetic:
Unlike his earlier town villas Corbusier was able to carefully design all four sides of the Villa Savoye in response to the view and the orientation of the sun. On the ground floor he placed the main entrance hall, ramp and stairs, garage, chauffeur and maid's rooms. At first floor the master bedroom, the son's bedroom, guest bedroom, kitchen, salon and external terraces. The salon was oriented to the south east whilst the terrace faced the east. The son's bedroom faced the north west and the kitchen and service terrace were on the south west. At second floor level were a series of sculpted spaces that formed a solarium.
The plan was set out using the principal ratios of the Golden section: in this case a square divided into sixteen equal parts, extended on two sides to incorporate the projecting façades and then further divided to give the position of the ramp and the entrance.
In his book "Vers une Architecture" Corbusier exclaimed "the motor car is an object with a simple function (to travel) and complicated aims (comfort, resistance, appearance)...". The house, designed as a second residence and sited as it was outside Paris was designed with the car in mind. The sense of mobility that the car gave translated into a feeling of movement that is integral to the understanding of the building. The approach to the house was by car, past the caretaker's lodge and eventually under the building itself. Even the curved arc of the industrial glazing to the ground floor entrance was determined by the turning circle of a car. Dropped off by the chauffeur, the car proceeded around the curve to park in the garage. Meanwhile, the occupants entered the house on axis into the main hall through a portico of flanking columns.
The four columns in the entrance hall seemingly direct the visitor up the ramp. This ramp, that can be seen from almost everywhere in the house continues up to the first floor living area and salon before continuing externally from the first floor roof terrace up to the second floor solarium. Throughout his career Corbusier was interested in bringing a feeling of sacredness into the act of dwelling and acts such as washing and eating were given significance by their positioning. At the Villa Savoye the act of cleansing is represented both by the sink in the entrance hall and the celebration of the health-giving properties of the sun in the solarium on the roof which is given significance by being the culmination of ascending the ramp.
Corbusier's piloti perform a number of functions around the house, both inside and out. On the two longer elevations they are flush with the face of the façade and imply heaviness and support, but on the shorter sides they are set back giving a floating effect that emphasises the horizontal feeling of the house. The wide strip window to the first floor terrace has two baby piloti to support and stiffen the wall above. Although these piloti are in a similar plane to the larger columns below a false perspective when viewed from outside the house gives the impression that they are further into the house than they actually are.
The Villa Savoye uses the horizontal ribbon windows found in his earlier villas. Unlike his contemporaries, Corbusier often chose to use timber windows rather than metal ones. It has been suggested that this is because he was interested in glass for its planar properties and that the set-back position of the glass in the timber frame allowed the façade to be seen as a series of parallel planes.
Later history.
Problems with the Savoyes caused by all the requests for additional payment from the contractors for all the changes were compounded by the requirement for early repairs to the new house. Each autumn the Savoyes suffered problems with rainwater leaks through the roof. The Savoyes continued to live in the house until 1940, leaving during World War II. It was occupied twice during the war: first by the Germans - when it was used as a hay store - and then by the Americans, with both occupations damaging the building severely. The Savoyes returned to their estate after the war, but, no longer in position to live as they had done before the war, they abandoned the house again shortly after. The villa was expropriated by the town of Poissy in 1958, which first used it as a public youth center and later considered demolishing it to make way for a schoolhouse complex. Protest from architects who felt the house should be saved, and the intervention of Corbusier himself, spared the house from demolition. A first attempt of renovation was begun in 1963 by architect Jean Debuisson, despite opposition from Corbusier. The villa was added to the French register of historical monuments in 1965, becoming the first modernist building designated as historical monument in France, and also the first to be the object of renovation while its architect was still living. In 1985, a thorough state-funded restoration process, led by architect Jean-Louis Véret, was undertaken, being completed in 1997. The restoration included structural and surface repairs to the facades and terraces because of deterioration of the concrete, the installation of lighting and security cameras, and the reinstatement of some of the original fixtures and fittings.
Legacy.
The Villa Savoye was a very influential building of the 1930s and imitations of it can be found all over the world. The building featured in two hugely influential books of the time: Hitchcock and Johnson's "The International Style" published in 1932 and F. R. S. Yorke's "The Modern House" published in 1934, as well as the second volume of Corbusier's own series "The Complete Works". In his 1947 essay "The Mathematics of the Ideal Villa", Colin Rowe compared the Villa Savoye to Palladio's Villa Rotunda.
The freedom given to Corbusier by the Savoyes resulted in a house that was governed more by his five principles than any requirements of the occupants. Despite this, it was the last time this happened in such a complete way and the house marked the end of a phase in his design thinking as well as being the last of a series of buildings dominated by the colour white.
Criticism has been levelled at Corbusier's five points of architecture from a general point of view and these apply specifically to the Villa Savoye in terms of:
After the Villa Savoye Corbusier's experimentation with Surrealism informed his design for the Beistegui apartments, but his next villa design, for Mademoiselle Mandrot near Toulon had a regionalist agenda and relied on local stone for its finish.
The west wing of the Australian Institute of Aboriginal and Torres Strait Islander Studies in Canberra designed by Ashton Raggatt McDougall, is a near exact replica of the Villa Savoye, except its black colour. This antipodean architectural quotation is according to Howard Raggat "a kind of inversion, a reflection, but also a kind of shadow".

</doc>
<doc id="32504" url="https://en.wikipedia.org/wiki?curid=32504" title="Vancouver (disambiguation)">
Vancouver (disambiguation)

Vancouver is a major city in British Columbia, Canada.
Vancouver may also refer to:

</doc>
<doc id="32505" url="https://en.wikipedia.org/wiki?curid=32505" title="Vapor">
Vapor

In physics a vapor (American English spelling) or vapour (British) is a substance in the gas phase at a temperature lower than its critical point, which means that the vapor can be condensed to a liquid by increasing the pressure on it without reducing the temperature. A vapor is different than an aerosol. An aerosol is a suspension of tiny particles of liquid, solid, or both within a gas.
For example, water has a critical temperature of 374 °C (647 K), which is the highest temperature at which liquid water can exist. In the atmosphere at ordinary temperatures, therefore, gaseous water (known as water vapor) will condense into a liquid if its partial pressure is increased sufficiently.
A vapor may co-exist with a liquid (or a solid). When this is true, the two phases will be in equilibrium, and the gas-partial pressure will be equal to the equilibrium vapor pressure of the liquid (or solid).
Properties.
"Vapor" refers to a gas phase at a temperature where the same substance can also exist in the liquid or solid state, below the critical temperature of the substance. (For example, water has a critical temperature of 374 °C (647 K), which is the highest temperature at which liquid water can exist.) If the vapor is in contact with a liquid or solid phase, the two phases will be in a state of equilibrium. The term "gas" refers to a compressible fluid phase. Fixed gases are gases for which no liquid or solid can form at the temperature of the gas, such as air at typical ambient temperatures. A liquid or solid does not have to boil to release a vapor.
Vapor is responsible for the familiar processes of cloud formation and condensation. It is commonly employed to carry out the physical processes of distillation and headspace extraction from a liquid sample prior to gas chromatography.
The constituent molecules of a vapor possess vibrational, rotational, and translational motion. These motions are considered in the kinetic theory of gases.
Vapor pressure.
The vapor pressure is the equilibrium pressure from a liquid or a solid at a specific temperature. The equilibrium vapor pressure of a liquid or solid is not affected by the amount of contact with the liquid or solid interface.
The normal boiling point of a liquid is the temperature at which the vapor pressure is equal to normal atmospheric pressure.
For two-phase systems (e.g., two liquid phases), the vapor pressure of the individual phases are equal. In the absence of stronger inter-species attractions between like-like or like-unlike molecules, the vapor pressure follows Raoult's Law, which states that the partial pressure of each component is the product of the vapor pressure of the pure component and its mole fraction in the mixture. The total vapor pressure is the sum of the component partial pressures.
Measuring vapor.
Since it is in the gas phase, the amount of vapor present is quantified by the partial pressure of the gas. Also, vapors obey the barometric formula in a gravitational field just as conventional atmospheric gases do.

</doc>
<doc id="32506" url="https://en.wikipedia.org/wiki?curid=32506" title="Venus (disambiguation)">
Venus (disambiguation)

Venus is the second planet from the sun.
Venus or VENUS may also refer to:

</doc>
<doc id="32509" url="https://en.wikipedia.org/wiki?curid=32509" title="Vitamin C">
Vitamin C

Vitamin C or L-ascorbic acid, or simply ascorbate (the anion of ascorbic acid), is an essential nutrient for humans and certain other animal species. Vitamin C describes several vitamers that have vitamin C activity in animals, including ascorbic acid and its salts, and some oxidized forms of the molecule like dehydroascorbic acid. Ascorbate and ascorbic acid are both naturally present in the body when either of these is introduced into cells, since the forms interconvert according to pH.
Vitamin C is a cofactor in at least eight enzymatic reactions, including several collagen synthesis reactions that, when dysfunctional, cause the most severe symptoms of scurvy. In animals, these reactions are especially important in wound-healing and in preventing bleeding from capillaries. Ascorbate may also act as an antioxidant, protecting against oxidative stress.
Ascorbate (the anion of ascorbic acid) is required for a range of essential metabolic reactions in all animals and plants. It is made internally by almost all organisms; the main exceptions are most bats, all guinea pigs, capybaras, and the Haplorrhini (one of the two major primate suborders, consisting of tarsiers, monkeys, and humans and other apes). Ascorbate is also not synthesized by some species of birds and fish. All species that do not synthesize ascorbate require it in the diet. Deficiency in this vitamin causes the disease scurvy in humans.
Ascorbic acid is also widely used as a food additive, to prevent oxidation.
Vitamers.
The name 'vitamin C' always refers to the L-enantiomer of ascorbic acid and its oxidized forms. The opposite D-enantiomer called D-ascorbate has equal antioxidant power, but is not found in nature, and has no physiological significance. When D-ascorbate is synthesized and given to animals that require vitamin C in their diets, it has been found to have far less vitamin activity than the L-enantiomer. Therefore, unless written otherwise, "ascorbate" and "ascorbic acid" refer in the nutritional literature to L-ascorbate and L-ascorbic acid, respectively. This notation will be followed in this article. Similarly, their oxidized derivatives (dehydroascorbate, etc., see below) are all L-enantiomers, and also need not be written with full stereochemical notation here.
Ascorbic acid is a weak sugar acid structurally related to glucose. In biological systems, ascorbic acid can be found only at low pH, but in neutral solutions above pH 5 is predominantly found in the ionized form, ascorbate. All of these molecules have vitamin C activity, therefore, and are used synonymously with vitamin C, unless otherwise specified.
Biological significance.
The biological role of ascorbate is to act as a reducing agent, donating electrons to various enzymatic and a few non-enzymatic reactions. The one- and two-electron oxidized forms of vitamin C, semidehydroascorbic acid and dehydroascorbic acid, respectively, can be reduced in the body by glutathione and NADPH-dependent enzymatic mechanisms. The presence of glutathione in cells and extracellular fluids helps maintain ascorbate in a reduced state.
Biosynthesis.
The vast majority of animals and plants are able to synthesize vitamin C, through a sequence of enzyme-driven steps, which convert monosaccharides to vitamin C. In plants, this is accomplished through the conversion of mannose or galactose to ascorbic acid. In some animals, glucose needed to produce ascorbate in the liver (in mammals and perching birds) is extracted from glycogen; ascorbate synthesis is a glycogenolysis-dependent process. In reptiles and birds the biosynthesis is carried out in the kidneys.
Among the animals that have lost the ability to synthesize vitamin C are simians and tarsiers, which together make up one of two major primate suborders, Haplorrhini. This group includes humans. The other more primitive primates (Strepsirrhini) have the ability to make vitamin C. Synthesis does not occur in a number of species (perhaps all species) in the small rodent family Caviidae that includes guinea pigs and capybaras, but occurs in other rodents (rats and mice do not need vitamin C in their diet, for example).
A number of species of passerine birds also do not synthesize, but not all of them, and those that do not are not clearly related; there is a theory that the ability was lost separately a number of times in birds. In particular, the ability to synthesize vitamin C is presumed to have been lost and then later re-acquired in at least two cases.
All tested families of bats, including major insect and fruit-eating bat families, cannot synthesize vitamin C. A trace of gulonolactone oxidase (GULO) was detected in only 1 of 34 bat species tested, across the range of 6 families of bats tested. However, recent results show that there are at least two species of bats, frugivorous bat ("Rousettus leschenaultii") and insectivorous bat ("Hipposideros armiger"), that retain their ability of vitamin C production. The ability to synthesize vitamin C has also been lost in teleost fish.
These animals all lack the L-gulonolactone oxidase (GULO) enzyme, which is required in the last step of vitamin C synthesis, because they have a differing non-synthesizing gene for the enzyme (Pseudogene ΨGULO). A similar non-functional gene is present in the genome of the guinea pigs and in primates, including humans. Some of these species (including humans) are able to make do with the lower levels available from their diets by recycling oxidised vitamin C.
Most simians consume the vitamin in amounts 10 to 20 times higher than that recommended by governments for humans. This discrepancy constitutes much of the basis of the controversy on current recommended dietary allowances. It is countered by arguments that humans are very good at conserving dietary vitamin C, and are able to maintain blood levels of vitamin C comparable with other simians, on a far smaller dietary intake.
Like plants and animals, some microorganisms such as the yeast "Saccharomyces cerevisiae" have been shown to be able to synthesize vitamin C from simple sugars.
Evolution.
Ascorbic acid or vitamin C is a common enzymatic cofactor in mammals used in the synthesis of collagen. Ascorbate is a powerful reducing agent capable of rapidly scavenging a number of reactive oxygen species (ROS). Freshwater teleost fishes also require dietary vitamin C in their diet or they will get scurvy. The most widely recognized symptoms of vitamin C deficiency in fishes are scoliosis, lordosis and dark skin coloration. Freshwater salmonids also show impaired collagen formation, internal/fin hemorrhage, spinal curvature and increased mortality. If these fishes are housed in seawater with algae and phytoplankton, then vitamin supplementation seems to be less important, it is presumed because of the availability of other, more ancient, antioxidants in natural marine environment.
Some scientists have suggested that loss of the vitamin C biosynthesis pathway may have played a role in rapid evolutionary changes, leading to hominids and the emergence of human beings. However, another theory is that the loss of ability to make vitamin C in simians may have occurred much farther back in evolutionary history than the emergence of humans or even apes, since it evidently occurred soon after the appearance of the first primates, yet sometime after the split of early primates into the two major suborders Haplorrhini (which cannot make vitamin C) and its sister suborder of non-tarsier prosimians, the Strepsirrhini ("wet-nosed" primates), which retained the ability to make vitamin C. According to molecular clock dating, these two suborder primate branches parted ways about 63 to 60 Mya. Approximately three to five million years later (58 Mya), only a short time afterward from an evolutionary perspective, the infraorder Tarsiiformes, whose only remaining family is that of the tarsier (Tarsiidae), branched off from the other haplorrhines. Since tarsiers also cannot make vitamin C, this implies the mutation had already occurred, and thus must have occurred between these two marker points (63 to 58 Mya).
It has been noted that the loss of the ability to synthesize ascorbate strikingly parallels the inability to break down uric acid, also a characteristic of primates. Uric acid and ascorbate are both strong reducing agents. This has led to the suggestion that, in higher primates, uric acid has taken over some of the functions of ascorbate.
Absorption, transport, and excretion.
Ascorbic acid is absorbed in the body by both active transport and simple diffusion. Sodium-Dependent Active Transport—Sodium-Ascorbate Co-Transporters (SVCTs) and Hexose transporters (GLUTs)—are the two transporters required for absorption. SVCT1 and SVCT2 import the reduced form of ascorbate across plasma membrane. GLUT1 and GLUT3 are the two glucose transporters, and transfer only the dehydroascorbic acid form of Vitamin C. Although dehydroascorbic acid is absorbed in higher rate than ascorbate, the amount of dehydroascorbic acid found in plasma and tissues under normal conditions is low, as cells rapidly reduce dehydroascorbic acid to ascorbate. Thus, SVCTs appear to be the predominant system for vitamin C transport in the body.
SVCT2 is involved in vitamin C transport in almost every tissue, the notable exception being red blood cells, which lose SVCT proteins during maturation. "SVCT2 knockout" animals genetically engineered to lack this functional gene, die shortly after birth, suggesting that SVCT2-mediated vitamin C transport is necessary for life.
With regular intake the absorption rate varies between 70 and 95%. However, the degree of absorption decreases as intake increases. At high intake (1.25 g), fractional human absorption of ascorbic acid may be as low as 33%; at low intake (<200 mg) the absorption rate can reach up to 98%.
Ascorbate concentrations over the renal re-absorption threshold pass freely into the urine and are excreted. At high dietary doses (corresponding to several hundred mg/day in humans) ascorbate is accumulated in the body until the plasma levels reach the renal resorption threshold, which is about 1.5 mg/dL in men and 1.3 mg/dL in women. Concentrations in the plasma larger than this value (thought to represent body saturation) are rapidly excreted in the urine with a half-life of about 30 minutes. Concentrations less than this threshold amount are actively retained by the kidneys, and the excretion half-life for the remainder of the vitamin C store in the body thus increases greatly, with the half-life lengthening as the body stores are depleted. This half-life rises until it is as long as 83 days by the onset of the first symptoms of scurvy.
Although the body's maximal store of vitamin C is largely determined by the renal threshold for blood, there are many tissues that maintain vitamin C concentrations far higher than in blood. Biological tissues that accumulate over 100 times the level in blood plasma of vitamin C are the adrenal glands, pituitary, thymus, corpus luteum, and retina. Those with 10 to 50 times the concentration present in blood plasma include the brain, spleen, lung, testicle, lymph nodes, liver, thyroid, small intestinal mucosa, leukocytes, pancreas, kidney, and salivary glands.
Ascorbic acid can be oxidized (broken down) in the human body by the enzyme L-ascorbate oxidase. Ascorbate that is not directly excreted in the urine as a result of body saturation or destroyed in other body metabolism is oxidized by this enzyme and removed.
Deficiency.
Scurvy is an avitaminosis resulting from lack of vitamin C, since without this vitamin, the synthesized collagen is too unstable to perform its function. Scurvy leads to the formation of brown spots on the skin, spongy gums, and bleeding from all mucous membranes. The spots are most abundant on the thighs and legs, and a person with the ailment looks pale, feels depressed, and is partially immobilized. In advanced scurvy there are open, suppurating wounds and loss of teeth and, eventually, death. The human body can store only a certain amount of vitamin C, and so the body stores are depleted if fresh supplies are not consumed. The time frame for onset of symptoms of scurvy in unstressed adults on a completely vitamin C free diet, however, may range from one month to more than six months, depending on previous loading of vitamin C.
Western societies generally consume far more than sufficient vitamin C to prevent scurvy. In 2004, a Canadian Community health survey reported that Canadians of 19 years and above have intakes of vitamin C from food of 133 mg/d for males and 120 mg/d for females; these are higher than the RDA recommendations.
Notable human dietary studies of experimentally induced scurvy have been conducted on conscientious objectors during WW II in Britain, and on Iowa state prisoners in the late 1960s to the 1980s. These studies both found that all obvious symptoms of scurvy previously induced by an experimental scorbutic diet with extremely low vitamin C content could be completely reversed by additional vitamin C supplementation of only 10 mg a day. In these experiments, there was no clinical difference noted between men given 70 mg vitamin C per day (which produced blood level of vitamin C of about 0.55 mg/dl, about 1/3 of tissue saturation levels), and those given 10 mg per day. Men in the prison study developed the first signs of scurvy about 4 weeks after starting the vitamin C free diet, whereas in the British study, six to eight months were required, possibly due to the pre-loading of this group with a 70 mg/day supplement for six weeks before the scorbutic diet was fed.
Men in both studies on a diet devoid, or nearly devoid, of vitamin C had blood levels of vitamin C too low to be accurately measured when they developed signs of scurvy, and in the Iowa study, at this time were estimated (by labeled vitamin C dilution) to have a body pool of less than 300 mg, with daily turnover of only 2.5 mg/day, implying an instantaneous half-life of 83 days by this time (elimination constant of 4 months).
Supplementation.
Studies of the potential of vitamin C supplementation to provide health benefits have provided conflicting results.
A 2013 systematic review by the U.S. Preventative Diseases Task Force found no clear evidence that vitamin C supplementation conferred benefit in the prevention of cardiovascular disease or cancer. Similarly, a 2012 Cochrane review found no effect of vitamin C supplementation on overall mortality.
Cancer prevention.
A 2013 Cochrane review found no evidence that vitamin C supplementation reduces the risk of lung cancer in healthy or high risk (smokers and asbestos-exposed) people. A 2014 meta-analysis found weak evidence that vitamin C intake might protect against lung cancer risk. A second meta analysis found no effect on the risk of prostate cancer.
Two meta analyses evaluated the effect of vitamin C supplementation on the risk of colorectal cancer. One found a weak association between vitamin C consumption and reduced risk, and the other found no effect of supplementation.
A 2011 meta analysis failed to find support for the prevention of breast cancer with vitamin C supplementation, but a second study concluded that vitamin C may be associated with increased survival in those already diagnosed.
Cardiovascular disease.
A 2013 meta analysis found no evidence that vitamin C supplementation reduces the risk of myocardial infarction, stroke, cardiovascular mortality, or all-cause mortality. However, a second analysis found an inverse relationship between circulating vitamin C levels or dietary vitamin C and the risk of stroke.
A meta-analysis of 44 clinical trials has shown a significant positive effect of vitamin C on endothelial function when taken at doses greater than 500 mg per day. The researchers noted that the effect of vitamin C supplementation appeared to be dependent on health status, with stronger effects in those at higher cardiovascular disease risk.
Chronic diseases.
A 2010 review in the journal "Alternative Therapies in Health and Medicine" found no role for vitamin C supplementation in the treatment of rheumatoid arthritis.
Studies examining the effects of vitamin C intake on the risk of Alzheimer's disease have reached conflicting conclusions. Maintaining a healthy dietary intake is probably more important than supplementation for achieving any potential benefit.
Vitamin C supplementation above the RDA has been used in trials to study a potential effect on preventing and slowing the progression of age-related cataract, however no significant effects were found from the research.
Treatment of the common cold.
Vitamin C's effect on the common cold has been extensively researched. It has not been shown effective in prevention or treatment of the common cold, except in limited circumstances (specifically, individuals exercising vigorously in cold environments). Routine vitamin C supplementation does not reduce the incidence or severity of the common cold in the general population, though it may reduce the duration of illness.
Role in mammals.
In humans, vitamin C is essential to a healthy diet as well as being a highly effective antioxidant, acting to lessen oxidative stress; a substrate for ascorbate peroxidase in plants (APX is plant specific enzyme); and an enzyme cofactor for the biosynthesis of many important biochemicals. Vitamin C acts as an electron donor for important enzymes:
Enzymatic cofactor.
Ascorbic acid performs numerous physiological functions in the human body. These functions include the synthesis of collagen, carnitine, and neurotransmitters; the synthesis and catabolism of tyrosine; and the metabolism of microsome. During biosynthesis ascorbate acts as a reducing agent, donating electrons and preventing oxidation to keep iron and copper atoms in their reduced states.
Vitamin C acts as an electron donor for eight different enzymes:
Immune system.
Vitamin C is found in high concentrations in immune cells, and is consumed quickly during infections. It is not certain how vitamin C interacts with the immune system; it has been hypothesized to modulate the activities of phagocytes, the production of cytokines and lymphocytes, and the number of cell adhesion molecules in monocytes.
Role in plants.
Ascorbic acid is associated with chloroplasts and apparently plays a role in ameliorating the oxidative stress of photosynthesis. In addition, it has a number of other roles in cell division and protein modification. Plants appear to be able to make ascorbate by at least one other biochemical route that is different from the major route in animals, although precise details remain unknown.
Daily requirements.
The North American Dietary Reference Intake recommends 90 milligrams per day and no more than 2 grams (2,000 milligrams) per day. Other related species sharing the same inability to produce vitamin C require exogenous vitamin C consumption 20 to 80 times this reference intake. There is continuing debate within the scientific community over the best dose schedule (the amount and frequency of intake) of vitamin C for maintaining optimal health in humans. A balanced diet without supplementation usually contains enough vitamin C to prevent scurvy in an average healthy adult, while those who are pregnant, smoke tobacco, or are under stress require slightly more.
Government recommended intake.
Recommendations for vitamin C intake have been set by various national agencies:
Testing for ascorbate levels in the body.
Simple tests use dichlorophenolindophenol, a redox indicator, to measure the levels of vitamin C in the urine and in serum or blood plasma. However these reflect recent dietary intake rather than the level of vitamin C in body stores. Reverse phase high performance liquid chromatography is used for determining the storage levels of vitamin C within lymphocytes and tissue.
It has been observed that while serum or blood plasma levels follow the circadian rhythm or short term dietary changes, those within tissues themselves are more stable and give a better view of the availability of ascorbate within the organism. However, very few hospital laboratories are adequately equipped and trained to carry out such detailed analyses, and require samples to be analyzed in specialized laboratories.
Adverse effects.
Common side-effects.
Relatively large doses of ascorbic acid may cause indigestion, particularly when taken on an empty stomach. However, taking vitamin C in the form of sodium ascorbate and calcium ascorbate may minimize this effect. When taken in large doses, ascorbic acid causes diarrhea in healthy subjects. In one trial in 1936, doses of up to 6 grams of ascorbic acid were given to 29 infants, 93 children of preschool and school age, and 20 adults for more than 1400 days. With the higher doses, toxic manifestations were observed in five adults and four infants. The signs and symptoms in adults were nausea, vomiting, diarrhea, flushing of the face, headache, fatigue and disturbed sleep. The main toxic reactions in the infants were skin rashes.
Possible side-effects.
As vitamin C enhances iron absorption, iron poisoning can become an issue to people with rare iron overload disorders, such as haemochromatosis. A genetic condition that results in inadequate levels of the enzyme glucose-6-phosphate dehydrogenase (G6PD) can cause sufferers to develop hemolytic anemia after ingesting specific oxidizing substances, such as very large dosages of vitamin C.
There is a longstanding belief among the mainstream medical community that vitamin C causes kidney stones, which is based on little science.
Although recent studies have found a relationship, a clear link between excess ascorbic acid intake and kidney stone formation has not been generally established. Some case reports exist for a link between patients with oxalate deposits and a history of high-dose vitamin C usage.
In a study conducted on rats, during the first month of pregnancy, high doses of vitamin C may suppress the production of progesterone from the corpus luteum. Progesterone, necessary for the maintenance of a pregnancy, is produced by the corpus luteum for the first few weeks, until the placenta is developed enough to produce its own source. By blocking this function of the corpus luteum, high doses of vitamin C (1000+ mg) are theorized to induce an early miscarriage. In a group of spontaneously aborting women at the end of the first trimester, the mean values of vitamin C were significantly higher in the aborting group. However, the authors do state: 'This could not be interpreted as an evidence of causal association.' However, in a previous study of 79 women with threatened, previous spontaneous, or habitual abortion, Javert and Stander (1943) had 91% success with 33 patients who received vitamin C together with bioflavonoids and vitamin K (only three abortions), whereas all of the 46 patients who did not receive the vitamins aborted.
A study in rats and humans suggested that adding Vitamin C supplements to an exercise training program lowered the expected effect of training on VO2 Max. Although the results in humans were not statistically significant, this study is often cited as evidence that high doses of Vitamin C have an adverse effect on exercise performance. In rats, it was shown that the additional Vitamin C resulted in lowered mitochondria production. Since rats are able to produce all of their needed Vitamin C, however, it is questionable whether they offer a relevant model of human physiological processes in this regard.
A cancer-causing mechanism of hexavalent chromium may be triggered by vitamin C.
Overdose.
Vitamin C is water-soluble, with dietary excesses not absorbed, and excesses in the blood rapidly excreted in the urine. It exhibits remarkably low toxicity. The (the dose that will kill 50% of a population) in rats is generally accepted to be 11.9 grams per kilogram of body weight when given by forced gavage (orally). The mechanism of death from such doses (1.2% of body weight, or 0.84 kg for a 70 kg human) is unknown, but may be more mechanical than chemical. The LD50 in humans remains unknown, given lack of any accidental or intentional poisoning death data. However, as with all substances tested in this way, the rat LD50 is taken as a guide to its toxicity in humans.
Dietary sources.
The richest natural sources are fruits and vegetables, and of those, the Kakadu plum and the camu camu fruit contain the highest concentration of the vitamin. It is also present in some cuts of meat, especially liver. Vitamin C is the most widely taken nutritional supplement and is available in a variety of forms, including tablets, drink mixes, crystals in capsules or naked crystals.
Vitamin C is absorbed by the intestines using a sodium-ion dependent channel. It is transported through the intestine via both glucose-sensitive and glucose-insensitive mechanisms. The presence of large quantities of sugar either in the intestines or in the blood can slow absorption.
Plant sources.
While plants are generally a good source of vitamin C, the amount in foods of plant origin depends on the precise variety of the plant, soil condition, climate where it grew, length of time since it was picked, storage conditions, and method of preparation.
The following table is approximate and shows the relative abundance in different raw plant sources. As some plants were analyzed fresh while others were dried (thus, artifactually increasing concentration of individual constituents like vitamin C), the data are subject to potential variation and difficulties for comparison. The amount is given in milligrams per 100 grams of fruit or vegetable and is a rounded average from multiple authoritative sources:
† average of 3 sources; dried
Source:
Animal sources.
The overwhelming majority of species of animals (but "not" humans or guinea pigs) and plants synthesize their own vitamin C. Therefore, some animal products can be used as sources of dietary vitamin C.
Vitamin C is most present in the liver and least present in the muscle. Since muscle provides the majority of meat consumed in the western human diet, animal products are not a reliable source of the vitamin. Vitamin C is present in human breast milk, but only in limited quantity in raw cow's milk. All excess vitamin C is disposed of through the urinary system.
The following table shows the relative abundance of vitamin C in various foods of animal origin, given in milligrams of vitamin C per 100 grams of food:
Food preparation.
Vitamin C chemically decomposes under certain conditions, many of which may occur during the cooking of food. Vitamin C concentrations in various food substances decrease with time in proportion to the temperature they are stored at and cooking can reduce the Vitamin C content of vegetables by around 60% possibly partly due to increased enzymatic destruction as it may be more significant at sub-boiling temperatures. Longer cooking times also add to this effect, as will copper food vessels, which catalyse the decomposition.
Another cause of vitamin C being lost from food is leaching, where the water-soluble vitamin dissolves into the cooking water, which is later poured away and not consumed. However, vitamin C does not leach in all vegetables at the same rate; research shows broccoli seems to retain more than any other. Research has also shown that freshly cut fruits do not lose significant nutrients when stored in the refrigerator for a few days.
Supplements.
Vitamin C is available in caplets, tablets, capsules, drink mix packets, in multi-vitamin formulations, in multiple antioxidant formulations, and as crystalline powder. Timed release versions are available, as are formulations containing bioflavonoids such as quercetin, hesperidin, and rutin. Tablet and capsule sizes range from 25 mg to 1500 mg. Vitamin C (as ascorbic acid) crystals are typically available in bottles containing 300 g to 1 kg of powder (a 5 ml teaspoon of vitamin C crystals equals 5,000 mg). The bottles are usually airtight and brown or opaque in order to prevent oxidation, in which case the vitamin C would become useless, if not damaging.
Industrial synthesis.
Vitamin C is produced from glucose by two main routes. The Reichstein process, developed in the 1930s, uses a single pre-fermentation followed by a purely chemical route. The modern two-step fermentation process, originally developed in China in the 1960s, uses additional fermentation to replace part of the later chemical stages. Both processes yield approximately 60% vitamin C from the glucose feed.
Research is underway at the Scottish Crop Research Institute in the interest of creating a strain of yeast that can synthesize vitamin C in a single fermentation step from galactose, a technology expected to reduce manufacturing costs considerably.
World production of synthesized vitamin C is currently estimated at approximately 110,000 tonnes annually. The main producers have been BASF/Takeda, DSM, Merck and the China Pharmaceutical Group Ltd. of the People's Republic of China. By 2008 only the DSM plant in Scotland remained operational outside the strong price competition from China. The world price of vitamin C rose sharply in 2008 partly as a result of rises in basic food prices but also in anticipation of a stoppage of the two Chinese plants, situated at Shijiazhuang near Beijing, as part of a general shutdown of polluting industry in China over the period of the Olympic games. Five Chinese manufacturers met in 2010, among them Northeast Pharmaceutical Group and North China Pharmaceutical Group, and agreed to temporarily stop production in order to maintain prices. In 2011 an American suit was filed against four Chinese companies that allegedly colluded to limit production and fix prices of vitamin C in the United States. According to the plaintiffs, after the agreement was made spot prices for vitamin C shot to as high as $7 per kilogram in December 2002 from $2.50 per kilogram in December 2001. The companies did not deny the accusation but say in their defense that the Chinese government compelled them to act in this way. In January 2012 a US judge ruled that the Chinese companies can be sued in the U.S. by buyers acting as a group.
Food fortification.
In 2005, Health Canada evaluated the effect of fortification of foods with ascorbate in the guidance document, "Addition of Vitamins and Minerals to Food". Ascorbate was categorized as a 'Risk Category A nutrient', meaning it is a nutrient for which an upper limit for intake is set but allows a wide margin of intake that has a narrow margin of safety but non-serious critical adverse effects.
History.
The need to include fresh plant food or raw animal flesh in the diet to prevent disease was known from ancient times. Native people living in marginal areas incorporated this into their medicinal lore. For example, spruce needles were used in temperate zones in infusions, or the leaves from species of drought-resistant trees in desert areas. In 1536, the French explorers Jacques Cartier and Daniel Knezevic, exploring the St. Lawrence River, used the local natives' knowledge to save his men who were dying of scurvy. He boiled the needles of the arbor vitae tree to make a tea that was later shown to contain 50 mg of vitamin C per 100 grams.
In the 1497 expedition of Vasco de Gama, the curative effects of citrus fruit were known. 
The Portuguese planted fruit trees and vegetables in Saint Helena, a stopping point for homebound voyages from Asia, and left their sick, suffering from scurvy and other ailments to be taken home, if they recovered, by the next ship.
Authorities occasionally recommended the benefit of plant food to promote health and prevent scurvy during long sea voyages. John Woodall, the first appointed surgeon to the British East India Company, recommended the preventive and curative use of lemon juice in his book, "The Surgeon's Mate", in 1617. The Dutch writer, Johann Bachstrom, in 1734, gave the firm opinion that ""scurvy is solely owing to a total abstinence from fresh vegetable food, and greens, which is alone the primary cause of the disease.""
Scurvy had long been a principal killer of sailors during the long sea voyages. According to Jonathan Lamb, "In 1499, Vasco da Gama lost 116 of his crew of 170; In 1520, Magellan lost 208 out of 230;...all mainly to scurvy."
While the earliest documented case of scurvy was described by Hippocrates around 400 BC, the first attempt to give scientific basis for the cause of this disease was by a ship's surgeon in the British Royal Navy, James Lind. Scurvy was common among those with poor access to fresh fruit and vegetables, such as remote, isolated sailors and soldiers. While at sea in May 1747, Lind provided some crew members with two oranges and one lemon per day, in addition to normal rations, while others continued on cider, vinegar, sulfuric acid or seawater, along with their normal rations. In the history of science, this is considered to be the first occurrence of a controlled experiment. The results conclusively showed that citrus fruits prevented the disease. Lind published his work in 1753 in his "Treatise on the Scurvy".
Lind's work was slow to be noticed, partly because his "Treatise" was not published until six years after his study, and also because he recommended a lemon juice extract known as "rob". Fresh fruit was very expensive to keep on board, whereas boiling it down to juice allowed easy storage but destroyed the vitamin (especially if boiled in copper kettles). Ship captains concluded wrongly that Lind's other suggestions were ineffective because those juices failed to prevent or cure scurvy.
It was 1795 before the British navy adopted lemons or lime as standard issue at sea. Limes were more popular, as they could be found in British West Indian Colonies, unlike lemons, which were not found in British Dominions, and were therefore more expensive. This practice led to the American use of the nickname "limey" to refer to the British. Captain James Cook had previously demonstrated and proven the principle of the advantages of carrying "Sour krout" on board, by taking his crews to the Hawaiian Islands and beyond without losing any of his men to scurvy. For this otherwise unheard of feat, the British Admiralty awarded him a medal.
The name "antiscorbutic" was used in the eighteenth and nineteenth centuries as general term for those foods known to prevent scurvy, even though there was no understanding of the reason for this. These foods included but were not limited to: lemons, limes, and oranges; sauerkraut, cabbage, malt, and portable soup.
Even before the antiscorbutic substance was identified, there were indications that it was present in amounts sufficient to prevent scurvy, in nearly all fresh (uncooked and uncured) foods, including raw animal-derived foods. In 1928, the Arctic anthropologist Vilhjalmur Stefansson attempted to prove his theory of how the Inuit are able to avoid scurvy with almost no plant food in their diet, despite the disease's striking European Arctic explorers living on similar high cooked-meat diets. Stefansson theorised that the natives get their vitamin C from fresh meat that is minimally cooked. Starting in February 1928, for one year he and a colleague lived on an exclusively minimally cooked meat diet while under medical supervision; they remained healthy. Later studies done after vitamin C could be quantified in mostly raw traditional food diets of the Yukon First Nations, Dene, Inuit, and Métis of the Northern Canada, showed that their daily intake of vitamin C averaged between 52 and 62 mg/day, an amount approximately the dietary reference intake (DRI), even at times of the year when little plant-based food was eaten.
Discovery.
In 1907 a laboratory animal model which would help to isolate and identify the antiscorbutic factor was discovered: Axel Holst and Theodor Frølich, two Norwegian physicians studying shipboard beriberi in the Norwegian fishing fleet, wanted a small test mammal to substitute for the pigeons then used in beriberi research. They fed guinea pigs their test diet of grains and flour, which had earlier produced beriberi in their pigeons, and were surprised when classic scurvy resulted instead. This was a serendipitous choice of animal. Until that time, scurvy had not been observed in any organism apart from humans, and had been considered an exclusively human disease. (Pigeons, as seed-eating birds, make their own vitamin C.) Holst and Frølich found they could cure the disease in guinea pigs with the addition of various fresh foods and extracts. This discovery of an animal experimental model for scurvy, made even before the essential idea of "vitamins" in foods had even been put forward, has been called the single most important piece of vitamin C research.
In 1912, the Polish biochemist Casimir Funk, while researching beriberi in pigeons, developed the concept of vitamins to refer to the non-mineral micronutrients that are essential to health. The name is a blend of "vital", due to the vital biochemical role they play, and "amines" because Funk thought that all these materials were chemical amines. Although the "e" was dropped after skepticism that all these compounds were amines, the word vitamin remained as a generic name for them. One of the "vitamins" was thought to be the hypothesised anti-scorbutic factor in certain foods, such as those tested by Holst and Frølich. In 1928, this vitamin was referred to as "water-soluble C," although its chemical structure had still not been determined.
From 1928 to 1932, the Hungarian research team of Albert Szent-Györgyi and Joseph L. Svirbely, as well as the American team led by Charles Glen King in Pittsburgh, first identified the anti-scorbutic factor. Szent-Györgyi had isolated the chemical hexuronic acid (actually, L-hexuronic acid) from animal adrenal glands at the Mayo clinic, and suspected it to be the antiscorbutic factor but could not prove it without a biological assay. At the same time, for five years King's laboratory at the University of Pittsburgh had been trying to isolate the antiscorbutic factor in lemon juice using the original 1907 model of scorbutic guinea pigs which developed scurvy when not fed fresh foods but were cured by lemon juice. They had also considered hexuronic acid, but had been put off the trail when a coworker made the explicit (and mistaken) experimental claim that this substance was not the antiscorbutic substance.
Finally, in late 1931, Szent-Györgyi gave Svirbely, formerly of King's lab, the last of his hexuronic acid with the suggestion that it might be the anti-scorbutic factor. By the spring of 1932, King's laboratory had proven this but published the result without giving Szent-Györgyi credit for it, leading to a bitter dispute over priority claims (in reality it had taken a team effort by both groups, since Szent-Györgyi was unwilling to do the difficult and messy animal studies).
Meanwhile, by 1932, Szent-Györgyi had moved to Hungary and his group had discovered that paprika peppers, a common spice in the Hungarian diet, was a rich source of hexuronic acid, the antiscorbutic factor. With a new and plentiful source of the vitamin, Szent-Györgyi sent a sample to noted British sugar chemist Walter Norman Haworth, who chemically identified it and proved the identification by synthesis in 1933. Haworth and Szent-Györgyi now proposed that the substance L-hexuronic acid be called a-scorbic acid, and chemically L-ascorbic acid, in honor of its activity against scurvy. Ascorbic acid turned out "not" to be an amine, nor even to contain any nitrogen.
In part, in recognition of his accomplishment with vitamin C, Szent-Györgyi was awarded the unshared 1937 Nobel Prize in Medicine. Haworth also shared that year's Nobel Prize in Chemistry, in part for his vitamin C synthetic work.
Between 1933 and 1934 not only Haworth and Edmund Hirst had synthesized vitamin C, but also, independently, Tadeus Reichstein succeeded in synthesizing the vitamin in bulk, making it the first vitamin to be artificially produced. The latter process made possible the cheap mass-production of semi-synthetic vitamin C, which was quickly marketed. Only Haworth was awarded the 1937 Nobel Prize in Chemistry in part for this work, but the Reichstein process, a combined chemical and bacterial fermentation sequence still used today to produce vitamin C, retained Reichstein's name. In 1934 Hoffmann–La Roche, which bought the Reichstein process patent, became the first pharmaceutical company to mass-produce and market synthetic vitamin C, under the brand name of Redoxon.
In 1957, J.J. Burns showed that the reason some mammals are susceptible to scurvy is the inability of their liver to produce the active enzyme L-gulonolactone oxidase, which is the last of the chain of four enzymes that synthesize vitamin C. American biochemist Irwin Stone was the first to exploit vitamin C for its food preservative properties. He later developed the theory that humans possess a mutated form of the L-gulonolactone oxidase coding gene.
In 2008, researchers at the University of Montpellier discovered that in humans and other primates the red blood cells have evolved a mechanism to more efficiently utilize the vitamin C present in the body by recycling oxidized L-dehydroascorbic acid (DHA) back into ascorbic acid which can be reused by the body. The mechanism was not found to be present in mammals that synthesize their own vitamin C.
Society and culture.
In February 2011, the Swiss Post issued a postage stamp bearing a depiction of a model of a molecule of vitamin C to mark the International Year of Chemistry. Tadeus Reichstein synthesized the vitamin for the first time in 1933.
Measurement of vitamin C in foods.
Vitamin C content of a food sample such as fruit juice can be calculated by measuring the volume of the sample required to decolorize a solution of dichlorophenolindophenol (DCPIP) and then calibrating the results by comparison with a known concentration of vitamin C.

</doc>
<doc id="32511" url="https://en.wikipedia.org/wiki?curid=32511" title="Vietnamese language">
Vietnamese language

Vietnamese () is an Austroasiatic language that originated in the north of Vietnam and is the national and official language of the country. It is the native language of the Vietnamese (Kinh) people, as well as a first or second language for the many ethnic minorities of Vietnam. As the result of Vietnamese emigration and cultural influence, Vietnamese speakers are found throughout the world, notably in East and Southeast Asia, North America, Australia and Western Europe. Vietnamese has also been officially recognized as a minority language in the Czech Republic.
It is part of the Austroasiatic language family of which it has by far the most speakers (several times as many as the other Austroasiatic languages combined). Vietnamese vocabulary has borrowings from Chinese, and it formerly used a modified set of Chinese characters called chữ nôm given vernacular pronunciation. The Vietnamese alphabet (quốc ngữ) in use today is a Latin alphabet with additional diacritics for tones, and certain letters.
Geographic distribution.
As the national language, Vietnamese is spoken throughout Vietnam by ethnic Vietnamese and by Vietnam's many minorities. Vietnamese is also the native language of the Gin minority group in southern Guangxi Province in China. A significant number of native speakers also reside in neighboring Cambodia and Laos.
In the United States, Vietnamese is the sixth most spoken language, with over 1.5 million speakers, who are concentrated in a handful of states. It is the third most spoken language in Texas, fourth in Arkansas and Louisiana, and fifth in California. Vietnamese is the seventh most spoken language in Australia. In France, it is the most spoken Asian language and the eighth most spoken immigrant language at home.
Official status.
Vietnamese is the sole official and national language of Vietnam. It is the first language of the majority of the Vietnamese population, as well as a first or second language for country's ethnic minority groups.
In the Czech Republic, Vietnamese has been recognized as one of 14 minority languages, on the basis of communities that have either traditionally or on a long-term basis resided in the country. This status grants Czech citizens from the Vietnamese community the right to use Vietnamese with public authorities and at courts anywhere in the country. Moreover, it also grants the usage of Vietnamese in public signage, election information, cultural institutions and access to legal information and assistance in municipalities where at least 10% of the population is of the minority group.
As a foreign language.
Vietnamese is increasingly being taught in schools and institutions outside of Vietnam. In countries with strongly established Vietnamese-speaking communities such as the USA, France, Australia and Canada, Vietnamese language education largely serves as a cultural role to link descendants of Vietnamese immigrants to their ancestral culture. Meanwhile, in countries near Vietnam such as Cambodia, Laos, Thailand and South Korea, the increased role of Vietnamese in foreign language education is largely due to the growth and influence of Vietnam's economy.
Since the 1980s, Vietnamese language schools ("") have been established for youth in many Vietnamese-speaking communities around the world, notably in the United States.
Historic and stronger trade and diplomatic relations with Vietnam and a growing interest among the French Vietnamese population (one of France's most established non-European ethnic groups) of their ancestral culture have also led to an increasing number of institutions in France, including universities, to offer formal courses in the language.
Since the late 1980s, the Vietnamese German community has enlisted the support of city governments to bring Vietnamese into high school curricula for the purpose of teaching and reminding Vietnamese German students of their mother-tongue. Furthermore, there has also been a number of Germans studying Vietnamese due to increased economic investment in Vietnam.
Vietnamese is taught in schools in the form of dual immersion to a varying degree in Cambodia, Laos, and the United States. Classes teach students subjects in Vietnamese and another language. Furthermore, in Thailand, Vietnamese is one of the most popular foreign languages in schools and colleges.
Linguistic classification.
Vietnamese was identified more than 150 years ago as part of the Mon–Khmer branch of the Austroasiatic language family (a family that also includes Khmer, spoken in Cambodia, as well as various tribal and regional languages, such as the Munda and Khasi languages spoken in eastern India, and others in southern China). Later, Muong was found to be more closely related to Vietnamese than other Mon–Khmer languages, and a Viet–Muong subgrouping was established, also including Thavung, Chut, Cuoi, etc. The term "Vietic" was proposed by Hayes (1992), who proposed to redefine Viet–Muong as referring to a subbranch of Vietic containing only Vietnamese and Muong. The term "Vietic" is used, among others, by Gérard Diffloth, with a slightly different proposal on subclassification, within which the term "Viet–Muong" refers to a lower subgrouping (within an eastern Vietic branch) consisting of Vietnamese dialects, Muong dialects, and Nguồn (of Quảng Bình Province).
Lexicon.
As a result of 1000 years of Chinese rule, much of the Vietnamese lexicon relating to science and politics is derived from Chinese — see Sino-Vietnamese vocabulary. Some 30% to 60% of the lexical stock has naturalized word borrowings from Chinese, although many compound words are composed of native Vietnamese words combined with naturalized word borrowings (i.e. having Vietnamese pronunciation). As a result of French occupation, Vietnamese has since had many words borrowed from the French language, for example cà phê (from French "café"). Nowadays, many new words are being added to the language's lexicon due to heavy Western cultural influence; these are usually borrowed from English, for example TV (though usually seen in the written form as "tivi"). Sometimes these borrowings are calques literally translated into Vietnamese (for example, "software" is calqued into "phần mềm", which literally means "soft part").
Phonology.
Vowels.
Like other Southeast Asian languages, Vietnamese has a comparatively large number of vowels. 
Below is a vowel diagram of Hanoi Vietnamese (including centering diphthongs):
Front, central, and low vowels ("i", "ê", "e", "ư", "â", "ơ", "ă", "a") are unrounded, whereas the back vowels ("u", "ô", "o") are rounded. The vowels "â" and "ă" are pronounced very short, much shorter than the other vowels. Thus, "ơ" and "â" are basically pronounced the same except that "ơ" is of normal length while "â" is short – the same applies to the vowels long "a" and short "ă" .
The centering diphthongs are formed with only the three high vowels ("i", "ư", "u"). They are generally spelled as "ia", "ưa", "ua" when they end a word and are spelled "iê", "ươ", "uô", respectively, when they are followed by a consonant.
In addition to single vowels (or monophthongs) and centering diphthongs, Vietnamese has closing diphthongs and triphthongs. The closing diphthongs and triphthongs consist of a main vowel component followed by a shorter semivowel offglide or . There are restrictions on the high offglides: cannot occur after a front vowel ("i", "ê", "e") nucleus and cannot occur after a back vowel ("u", "ô", "o") nucleus.
The correspondence between the orthography and pronunciation is complicated. For example, the offglide is usually written as "i"; however, it may also be represented with "y". In addition, in the diphthongs and the letters "y" and "i" also indicate the pronunciation of the main vowel: "ay" = "ă" + , "ai" = "a" + . Thus, "tay" "hand" is while "tai" "ear" is . Similarly, "u" and "o" indicate different pronunciations of the main vowel: "au" = "ă" + , "ao" = "a" + . Thus, "thau" "brass" is while "thao" "raw silk" is .
Consonants.
The consonants that occur in Vietnamese are listed below in the Vietnamese orthography with the phonetic pronunciation to the right.
Some consonant sounds are written with only one letter (like "p"), other consonant sounds are written with a two-letter digraph (like "ph"), and others are written with more than one letter or digraph (the velar stop is written variously as "c", "k", or "q"). The velar stop /k/ may be pronounced as a uvular stop /q/ by some speakers next to back vowels, but this is not reflected in the spelling.
Not all dialects of Vietnamese have the same consonant in a given word (although all dialects use the same spelling in the written language). See the language variation section for further elaboration.
The analysis of syllable-final orthographic "ch" and "nh" in Hanoi Vietnamese has had different analyses. One analysis has final "ch", "nh" as being phonemes contrasting with syllable-final "t", "c" and "n", "ng" and identifies final "ch" with the syllable-initial "ch" . The other analysis has final "ch" and "nh" as predictable allophonic variants of the velar phonemes and that occur after the upper front vowels "i" and "ê" . (See Vietnamese phonology: Analysis of final "ch", "nh" for further details.)
Tones.
Vietnamese vowels are all pronounced with an inherent tone. (More formally, diacritics indicate the tone of the entire word, centered on the main vowel or group of vowels, whereas accents qualify the vowel(s).) Tones differ in:
Tone is indicated by diacritics written above or below the vowel (most of the tone diacritics appear above the vowel; however, the "nặng" tone dot diacritic goes below the vowel). The six tones in the northern varieties (including Hanoi), with their self-referential Vietnamese names, are:
Other dialects of Vietnamese have fewer tones (typically only five). See the language variation section for a brief survey of tonal differences among dialects.
In Vietnamese poetry, tones are classed into two groups:
Words with tones belonging to a particular tone group must occur in certain positions within the poetic verse.
Vietnamese Catholics practice a distinctive style of prayer recitation called "", in which each tone is assigned a specific note or sequence of notes.
Language variation.
There are various mutually intelligible regional varieties (or dialects), the main five being:
Vietnamese has traditionally been divided into three dialect regions: North, Central, and South. However, Michel Ferlus and Nguyễn Tài Cẩn offer evidence for considering a North-Central region separate from Central. The term "Haut-Annam" refers to dialects spoken from northern Nghệ An Province to southern (former) Thừa Thiên Province that preserve archaic features (like consonant clusters and undiphthongized vowels) that have been lost in other modern dialects.
These dialect regions differ mostly in their sound systems (see below), but also in vocabulary (including basic vocabulary, non-basic vocabulary, and grammatical words) and grammar. The North-central and Central regional varieties, which have a significant amount of vocabulary differences, are generally less mutually intelligible to Northern and Southern speakers. There is less internal variation within the Southern region than the other regions due to its relatively late settlement by Vietnamese speakers (in around the end of the 15th century). The North-central region is particularly conservative; its pronunciation has diverged less from Vietnamese orthography than the other varieties, which tend to merge certain sounds. Along the coastal areas, regional variation has been neutralized to a certain extent, while more mountainous regions preserve more variation. As for sociolinguistic attitudes, the North-central varieties are often felt to be "peculiar" or "difficult to understand" by speakers of other dialects.
The large movements of people between North and South beginning in the mid-20th century and continuing to this day have resulted in a sizeable number of Southern residents speaking in the Northern accent/dialect and, to a greater extent, Northern residents speaking in the Southern accent/dialect. Following the Geneva Accords of 1954 that called for the temporary division of the country, about a million northerners (mainly from Hanoi, Haiphong and the surrounding Red River Delta areas) moved south (mainly to Saigon and heavily to Biên Hòa and Vũng Tàu, and the surrounding areas) as part of Operation Passage to Freedom. About 3% (~30,000) of that number of people made the move in the reverse direction.
Following the reunification of Vietnam in 1975–76, Northern and North-Central speakers from the densely populated Red River Delta and the traditionally poorer provinces of Nghệ An, Hà Tĩnh and Quảng Bình have continued to move South to look for better economic opportunities, beginning with the Hanoi government's "New Economic Zones program" which lasted from 1975–85. The first half of the program (1975–80), resulted in 1.3 million people sent to the New Economic Zones (NEZs), majority of which were relocated in the southern half of the country in previously uninhabited areas, of which 550,000 were Northerners. The second half (1981–85) saw almost 1 million Northerners relocated to the NEZs. As well, government and military personnel, many from Northern and north-central Vietnam, are posted to various locations throughout the country, often away from their home regions. More recently, the growth of the free market system has resulted in business people and tourists traveling to distant parts of Vietnam. These movements have resulted in some small blending of the dialects, but more significantly, have made the Northern dialect more easily understood in the South and vice versa. Most Southerners, when singing modern/popular Vietnamese songs, do so in the Northern accent. This is true in Vietnam as well as in the overseas Vietnamese communities.
The syllable-initial "ch" and "tr" digraphs are pronounced distinctly in North-central, Central, and Southern varieties, but are merged in Northern varieties (i.e. they are both pronounced the same way). The North-central varieties preserve three distinct pronunciations for "d", "gi", and "r" whereas the North has a three-way merger and the Central and South have a merger of "d" and "gi" while keeping "r" distinct. At the end of syllables, palatals "ch" and "nh" have merged with alveolars "t" and "n", which, in turn, have also partially merged with velars "c" and "ng" in Central and Southern varieties.
In addition to the regional variation described above, there is also a merger of "l" and "n" in certain rural varieties:
Variation between "l" and "n" can be found even in mainstream Vietnamese in certain words. For example, the numeral "five" appears as "năm" by itself and in compound numerals like "năm mươi" "fifty" but appears as "lăm" in "mười lăm" "fifteen". (See Vietnamese syntax: Cardinal numerals.) In some northern varieties, this numeral appears with an initial "nh" instead of "l": "hai mươi nhăm" "twenty-five" vs. mainstream "hai mươi lăm".
The consonant clusters that were originally present in Middle Vietnamese (of the 17th century) have been lost in almost all modern Vietnamese varieties (but retained in other closely related Vietic languages). However, some speech communities have preserved some of these archaic clusters: "sky" is "blời" with a cluster in Hảo Nho (Yên Mô prefecture, Ninh Bình Province) but "trời" in Southern Vietnamese and "giời" in Hanoi Vietnamese (initial single consonants , respectively).
Tones.
Generally, the Northern varieties have six tones while those in other regions have five tones. The "hỏi" and "ngã" tones are distinct in North and some North-central varieties (although often with different pitch contours) but have merged in Central, Southern, and some North-central varieties (also with different pitch contours). Some North-central varieties (such as "Hà Tĩnh" Vietnamese) have a merger of the "ngã" and "nặng" tones while keeping the "hỏi" tone distinct. Still other North-central varieties have a three-way merger of "hỏi", "ngã", and "nặng" resulting in a four-tone system. In addition, there are several phonetic differences (mostly in pitch contour and phonation type) in the tones among dialects.
The table above shows the pitch contour of each tone using Chao tone number notation (where 1 = lowest pitch, 5 = highest pitch); glottalization (creaky, stiff, harsh) is indicated with the symbol; breathy voice with ; glottal stop with ; sub-dialectal variants are separated with commas. (See also the tone section below.)
Grammar.
Vietnamese, like many languages in Southeast Asia, is an analytic (or isolating) language. Vietnamese does not use morphological marking of case, gender, number or tense (and, as a result, has no finite/nonfinite distinction). Also like other languages in the region, Vietnamese syntax conforms to subject–verb–object word order, is head-initial (displaying modified-modifier ordering), and has a noun classifier system. Additionally, it is pro-drop, wh-in-situ, and allows verb serialization.
Some Vietnamese sentences with English word glosses and translations are provided below.
Writing systems.
Up to the late 19th century, two writing systems based on Chinese characters were used in Vietnam.
All formal writing, including government business, scholarship and formal literature, was done in Literary Chinese ("chữ nho" "scholar's characters").
Folk literature in Vietnamese was recorded using the "Chữ Nôm" script, in which many Chinese characters were borrowed and many more modified and invented to represent native Vietnamese words.
Created in the 13th century or earlier, the "Nôm" writing reached its zenith in the 18th century when many Vietnamese writers and poets composed their works in Nôm, most notably Nguyễn Du and Hồ Xuân Hương (dubbed "the Queen of Nôm poetry").
However it was only used for official purposes during the brief Hồ and Tây Sơn dynasties.
A Vietnamese Catholic, Nguyen Truong To, sent petitions to the Court which suggested a Chinese character-based syllabary which would be used for Vietnamese sounds; however, his petition failed. The French colonial administration sought to eliminate the Chinese writing system, Confucianism, and other Chinese influences from Vietnam by getting rid of Nôm.
A romanization of Vietnamese was codified in the 17th century by the French Jesuit missionary Alexandre de Rhodes (1591–1660), based on works of earlier Portuguese missionaries Gaspar do Amaral and António Barbosa. This Vietnamese alphabet ("chữ quốc ngữ" or "national script") was gradually expanded from its initial domain in Christian writing to become more popular among the general public.
However, the Romanized script did not come to predominate until the beginning of the 20th century, when education became widespread and a simpler writing system was found more expedient for teaching and communication with the general population.
Under French colonial rule, French superseded Chinese in administration.
Vietnamese written with the alphabet became required for all public documents in 1910 by issue of a decree by the French Résident Supérieur of the protectorate of Tonkin. By the middle of the 20th century virtually all writing was done in "chữ quốc ngữ", which became the official script on independence. Chữ nho was still in use on early North Vietnamese and late French Indochinese banknotes issued after World War II but fell out of official use shortly thereafter.
Only a few scholars and some extremely elderly people are able to read "chữ nôm" today. In China, members of the Jing minority still write in Chữ Nôm.
Changes in the script were made by French scholars and administrators and by conferences held after independence during 1954–1974. The script now reflects a so-called "Middle Vietnamese" dialect that has vowels and final consonants most similar to northern dialects and initial consonants most similar to southern dialects (Nguyễn 1996). This Middle Vietnamese is presumably close to the Hanoi variety as spoken sometime after 1600 but before the present. (This is not unlike how English orthography is based on the Chancery Standard of late Middle English, with many spellings retained even after significant phonetic change.)
Computer support.
The Unicode character set contains all Vietnamese characters and the Vietnamese currency symbol. On systems that do not support Unicode, many 8-bit Vietnamese code pages are available such as VISCII or CP1258. Where ASCII must be used, Vietnamese letters are often typed using the VIQR convention, though this is largely unnecessary with the increasing ubiquity of Unicode. There are many software tools that help type true Vietnamese text on US keyboards, such as WinVNKey and Unikey on Windows, or MacVNKey on Macintosh.
History.
It seems likely that in the distant past, Vietnamese shared more characteristics common to other languages in the Austroasiatic family, such as an inflectional morphology and a richer set of consonant clusters, which have subsequently disappeared from the language. However, Vietnamese appears to have been heavily influenced by its location in the Southeast Asian sprachbund, with the result that it has acquired or converged toward characteristics such as isolating morphology and phonemically distinctive tones, through processes of tonogenesis. These characteristics have become part of many of the genetically unrelated languages of Southeast Asia; for example, Thai (one of the Tai–Kadai languages), Tsat (a member of the Malayo-Polynesian group within Austronesian), and Vietnamese each developed tones as a phonemic feature.
The ancestor of the Vietnamese language is usually believed to have been originally based in the area of the Red River in what is now northern Vietnam. However, Chamberlain argues that the Red River Delta region was originally Tai-speaking and became Vietnamese-speaking only between the seventh and ninth centuries AD, as a result of immigration from the south, i. e., modern central Vietnam, where the highly distinctive and conservative North-Central Vietnamese dialects are spoken today. Therefore, the region of origin of Vietnamese (and the earlier Viet–Muong) was well south of the Red River.
Like the ethnonym Lao, the name Yue/Việt originally referred to Tai–Kadai-speaking groups. In northern Vietnam, these later adopted Viet–Muong and further north Chinese varieties, where the designation Yue Chinese preserves the ethnonym. (Both in Vietnam and southern China, however, many Tai–Kadai languages remain in use.) This explains the fact that the same ethnonym Yue ~ Việt is associated with groups that speak Tai–Kadai, Austroasiatic and Chinese languages, which are typologically similar and share significant amounts of lexicon, but have different origins.
Distinctive tonal variations emerged during the subsequent expansion of the Vietnamese language and people into what is now central and southern Vietnam through conquest of the ancient nation of Champa and the Khmer people of the Mekong Delta in the vicinity of present-day Ho Chi Minh City, also known as Saigon.
Vietnamese was primarily influenced by Chinese, which came to predominate politically in the 2nd century BC. After Vietnam achieved independence in the 10th century, the ruling class adopted Literary Chinese as the medium of government, scholarship and literature. With the dominance of Chinese came radical importation of Chinese vocabulary and grammatical influence. Much of the Vietnamese lexicon in all realms consists of Sino-Vietnamese words.
When France invaded Vietnam in the late 19th century, French gradually replaced Chinese as the official language in education and government. Vietnamese adopted many French terms, such as "đầm" (dame, from "madame"), "ga" (train station, from "gare"), "sơ mi" (shirt, from "chemise"), and "búp bê" (doll, from "poupée"). In addition, many Sino-Vietnamese terms were devised for Western ideas imported through the French.
Henri Maspero described six periods of the Vietnamese language:
Proto-Viet–Muong.
The following diagram shows the phonology of Proto-Viet–Muong (the nearest ancestor of Vietnamese and the closely related Muong language), along with the outcomes in the modern language:
The following initial clusters occurred, with outcomes indicated:
Note also that a large number of words were borrowed from Middle Chinese, forming part of the Sino-Vietnamese vocabulary. These caused the original introduction of the retroflex sounds and (modern "s", "tr") into the language.
Origin of the tones.
Proto-Viet–Muong had no tones to speak of. The tones later developed in some of the daughter languages from distinctions in the initial and final consonants. Vietnamese tones developed as follows:
Glottal-ending syllables ended with a glottal stop , while fricative-ending syllables ended with or . Both types of syllables could co-occur with a resonant (e.g. or ).
At some point, a tone split occurred, as in many other Southeast Asian languages. Essentially, an allophonic distinction developed in the tones, whereby the tones in syllables with voiced initials were pronounced differently from those with voiceless initials. (Approximately speaking, the voiced allotones were pronounced with additional breathy voice or creaky voice and with lowered pitch. The quality difference predominates in today's northern varieties, e.g. in Hanoi, while in the southern varieties the pitch difference predominates, as in Ho Chi Minh City.) Subsequent to this, the plain-voiced stops became voiceless and the allotones became new phonemic tones. Note that the implosive stops were unaffected, and in fact developed tonally as if they were unvoiced. (This behavior is common to all East Asian languages with implosive stops.)
As noted above, Proto-Viet–Muong had sesquisyllabic words with an initial minor syllable (in addition to, and independent of, initial clusters in the main syllable). When a minor syllable occurred, the main syllable's initial consonant was intervocalic and as a result suffered lenition, becoming a voiced fricative. The minor syllables were eventually lost, but not until the tone split had occurred. As a result, words in modern Vietnamese with voiced fricatives occur in all six tones, and the tonal register reflects the voicing of the minor-syllable prefix and not the voicing of the main-syllable stop in Proto-Viet–Muong that produced the fricative. For similar reasons, words beginning with and occur in both registers. (Thompson 1976 reconstructed voiceless resonants to account for outcomes where resonants occur with a first-register tone, but this is no longer considered necessary, at least by Ferlus.)
Middle Vietnamese.
The writing system used for Vietnamese is based closely on the system developed by Alexandre de Rhodes for his Vietnamese–Portuguese–Latin dictionary, published in 1651. It reflects the pronunciation of the Vietnamese of Hanoi at that time, a stage commonly termed "Middle Vietnamese" (""). The pronunciation of the "rime" of the syllable, i.e. all parts other than the initial consonant (optional glide, vowel nucleus, tone and final consonant), appears nearly identical between Middle Vietnamese and modern Hanoi pronunciation. On the other hand, the Middle Vietnamese pronunciation of the initial consonant differs greatly from all modern dialects, and in fact is significantly closer to the modern Saigon dialect than the modern Hanoi dialect.
The following diagram shows the orthography and pronunciation of Middle Vietnamese:
Note that "b" and "p" never contrast in any position, suggesting that they are allophones; likewise for "gi" and "y/i/ĕ" .
The language also has three clusters at the beginning of syllables, which have since disappeared:
Most of the unusual correspondences between spelling and modern pronunciation are explained by Middle Vietnamese. Note in particular:
de Rhodes's orthography also made use of an apex diacritic to indicate a final labial-velar nasal , an allophone of that is peculiar to the Hanoi dialect to the present day. This diacritic is often mistaken for a tilde in modern reproductions of early Vietnamese writing.
Examples.
See "The Tale of Kieu" for an extract of the first six lines of "Truyện Kiều", an epic narrative poem by the celebrated poet Nguyễn Du, (), which is often considered the most significant work of Vietnamese literature. It was originally written in Nôm (titled "Đoạn Trường Tân Thanh" ) and is widely taught in Vietnam today.
External links.
Research projects and data resources

</doc>
<doc id="32512" url="https://en.wikipedia.org/wiki?curid=32512" title="Vitamin">
Vitamin

A vitamin ( and ) is an organic compound and a vital nutrient that an organism requires in limited amounts. An organic chemical compound (or related set of compounds) is called a vitamin when the organism cannot synthesize the compound in sufficient quantities, and it must be obtained through the diet; thus, the term "vitamin" is conditional upon the circumstances and the particular organism. For example, ascorbic acid (one form of vitamin C) is a vitamin for humans, but not for most other animal organisms. Supplementation is important for the treatment of certain health problems, but there is little evidence of nutritional benefit when used by otherwise healthy people.
By convention the term "vitamin" includes neither other essential nutrients, such as dietary minerals, essential fatty acids, or essential amino acids (which are needed in greater amounts than vitamins) nor the great number of other nutrients that promote health, and are required less often to maintain the health of the organism. Thirteen vitamins are universally recognized at present. Vitamins are classified by their biological and chemical activity, not their structure. Thus, each "vitamin" refers to a number of "vitamer" compounds that all show the biological activity associated with a particular vitamin. Such a set of chemicals is grouped under an alphabetized vitamin "generic descriptor" title, such as "vitamin A", which includes the compounds retinal, retinol, and four known carotenoids. Vitamers by definition are convertible to the active form of the vitamin in the body, and are sometimes inter-convertible to one another, as well.
Vitamins have diverse biochemical functions. Some, such as vitamin D, have hormone-like functions as regulators of mineral metabolism, or regulators of cell and tissue growth and differentiation (such as some forms of vitamin A). Others function as antioxidants (e.g., vitamin E and sometimes vitamin C). The largest number of vitamins, the B complex vitamins, function as enzyme cofactors (coenzymes) or the precursors for them; coenzymes help enzymes in their work as catalysts in metabolism. In this role, vitamins may be tightly bound to enzymes as part of prosthetic groups: For example, biotin is part of enzymes involved in making fatty acids. They may also be less tightly bound to enzyme catalysts as coenzymes, detachable molecules that function to carry chemical groups or electrons between molecules. For example, folic acid may carry methyl, formyl, and methylene groups in the cell. Although these roles in assisting enzyme-substrate reactions are vitamins' best-known function, the other vitamin functions are equally important.
Until the mid-1930s, when the first commercial yeast-extract vitamin B complex and semi-synthetic vitamin C supplement tablets were sold, vitamins were obtained solely through food intake, and changes in diet (which, for example, could occur during a particular growing season) usually greatly altered the types and amounts of vitamins ingested. However, vitamins have been produced as commodity chemicals and made widely available as inexpensive semisynthetic and synthetic-source multivitamin dietary and food supplements and additives, since the middle of the 20th century. Study of structural activity, function and their role in maintaining health is called vitaminology.
List of vitamins.
Each vitamin is typically used in multiple reactions, and, therefore, most have multiple functions.
Health effects.
Vitamins are essential for the normal growth and development of a multicellular organism. Using the genetic blueprint inherited from its parents, a fetus begins to develop, at the moment of conception, from the nutrients it absorbs. It requires certain vitamins and minerals to be present at certain times. These nutrients facilitate the chemical reactions that produce among other things, skin, bone, and muscle. If there is serious deficiency in one or more of these nutrients, a child may develop a deficiency disease. Even minor deficiencies may cause permanent damage.
For the most part, vitamins are obtained with food, but a few are obtained by other means. For example, microorganisms in the intestine — commonly known as "gut flora" — produce vitamin K and biotin, while one form of vitamin D is synthesized in the skin with the help of the natural ultraviolet wavelength of sunlight. Humans can produce some vitamins from precursors they consume. Examples include vitamin A, produced from beta carotene, and niacin, from the amino acid tryptophan.
Once growth and development are completed, vitamins remain essential nutrients for the healthy maintenance of the cells, tissues, and organs that make up a multicellular organism; they also enable a multicellular life form to efficiently use chemical energy provided by food it eats, and to help process the proteins, carbohydrates, and fats required for respiration.
Supplements.
In those who are otherwise healthy, there is little evidence that supplements have any benefits with respect to cancer or heart disease. Vitamin A and E supplements not only provide no health benefits for generally healthy individuals, but they may increase mortality, though the two large studies that support this conclusion included smokers for whom it was already known that beta-carotene supplements can be harmful. While other findings suggest that vitamin E toxicity is limited to only a specific form when taken in excess.
The European Union and other countries of Europe have regulations that define limits of vitamin (and mineral) dosages for their safe use as food supplements. Most vitamins that are sold as food supplements cannot exceed a maximum daily dosage. Vitamin products above these legal limits are not considered food supplements and must be registered as prescription or non-prescription (over-the-counter drugs) due to their potential side effects. As a result, most of the fat-soluble vitamins (such as the vitamins A, D, E, and K) that contain amounts above the daily allowance are drug products. The daily dosage of a vitamin supplement for example cannot exceed 300% of the recommended daily allowance, and for vitamin A, this limit is even lower (200%). Such regulations are applicable in most European countries.
Dietary supplements often contain vitamins, but may also include other ingredients, such as minerals, herbs, and botanicals. Scientific evidence supports the benefits of dietary supplements for persons with certain health conditions. In some cases, vitamin supplements may have unwanted effects, especially if taken before surgery, with other dietary supplements or medicines, or if the person taking them has certain health conditions. They may also contain levels of vitamins many times higher, and in different forms, than one may ingest through food.
Effect of cooking.
Shown below is percentage loss of vitamins after cooking averaged for common foods such as vegetables, meat or fish.
It should be noted however that some vitamins may become more "bio-available" – that is, usable by the body – when steamed or cooked.
The table below shows whether various vitamins are susceptible to loss from heat—such as heat from boiling, steaming, cooking etc.—and other agents. The effect of cutting vegetables can be seen from exposure to air and light. Water-soluble vitamins such as B and C seep into the water when a vegetable is boiled.
Deficiencies.
Humans must consume vitamins periodically but with differing schedules, to avoid deficiency. The human body's stores for different vitamins vary widely; vitamins A, D, and B12 are stored in significant amounts in the human body, mainly in the liver, and an adult human's diet may be deficient in vitamins A and D for many months and B12 in some cases for years, before developing a deficiency condition. However, vitamin B3 (niacin and niacinamide) is not stored in the human body in significant amounts, so stores may last only a couple of weeks. For vitamin C, the first symptoms of scurvy in experimental studies of complete vitamin C deprivation in humans have varied widely, from a month to more than six months, depending on previous dietary history that determined body stores.
Deficiencies of vitamins are classified as either primary or secondary. A primary deficiency occurs when an organism does not get enough of the vitamin in its food. A secondary deficiency may be due to an underlying disorder that prevents or limits the absorption or use of the vitamin, due to a "lifestyle factor", such as smoking, excessive alcohol consumption, or the use of medications that interfere with the absorption or use of the vitamin. People who eat a varied diet are unlikely to develop a severe primary vitamin deficiency. In contrast, restrictive diets have the potential to cause prolonged vitamin deficits, which may result in often painful and potentially deadly diseases.
Well-known human vitamin deficiencies involve thiamine (beriberi), niacin (pellagra), vitamin C (scurvy), and vitamin D (rickets). In much of the developed world, such deficiencies are rare; this is due to (1) an adequate supply of food and (2) the addition of vitamins and minerals to common foods, often called fortification. In addition to these classical vitamin deficiency diseases, some evidence has also suggested links between vitamin deficiency and a number of different disorders.
Side-effects.
In large doses, some vitamins have documented side-effects that tend to be more severe with a larger dosage. The likelihood of consuming too much of any vitamin from food is remote, but overdosing (vitamin poisoning) from vitamin supplementation does occur. At high enough dosages, some vitamins cause side-effects such as nausea, diarrhea, and vomiting. When side-effects emerge, recovery is often accomplished by reducing the dosage. The doses of vitamins differ because individual tolerances can vary widely and appear to be related to age and state of health.
In 2008, overdose exposure to all formulations of vitamins and multivitamin-mineral formulations was reported by 68,911 individuals to the American Association of Poison Control Centers (nearly 80% of these exposures were in children under the age of 6), leading to 8 "major" life-threatening outcomes, but no deaths.
Pharmacology.
Vitamins are classified as either water-soluble or fat-soluble. In humans there are 13 vitamins: 4 fat-soluble (A, D, E, and K) and 9 water-soluble (8 B vitamins and vitamin C). Water-soluble vitamins dissolve easily in water and, in general, are readily excreted from the body, to the degree that urinary output is a strong predictor of vitamin consumption. Because they are not as readily stored, more consistent intake is important. Many types of water-soluble vitamins are synthesized by bacteria. Fat-soluble vitamins are absorbed through the intestinal tract with the help of lipids (fats). Because they are more likely to accumulate in the body, they are more likely to lead to hypervitaminosis than are water-soluble vitamins. Fat-soluble vitamin regulation is of particular significance in cystic fibrosis.
History.
The value of eating a certain food to maintain health was recognized long before vitamins were identified. The ancient Egyptians knew that feeding liver to a person would help cure night blindness, an illness now known to be caused by a vitamin A deficiency. The advancement of ocean voyages during the Renaissance resulted in prolonged periods without access to fresh fruits and vegetables, and made illnesses from vitamin deficiency common among ships' crews.
In 1747, the Scottish surgeon James Lind discovered that citrus foods helped prevent scurvy, a particularly deadly disease in which collagen is not properly formed, causing poor wound healing, bleeding of the gums, severe pain, and death. In 1753, Lind published his "Treatise on the Scurvy", which recommended using lemons and limes to avoid scurvy, which was adopted by the British Royal Navy. This led to the nickname limey for sailors of that organization. Lind's discovery, however, was not widely accepted by individuals in the Royal Navy's Arctic expeditions in the 19th century, where it was widely believed that scurvy could be prevented by practicing good hygiene, regular exercise, and maintaining the morale of the crew while on board, rather than by a diet of fresh food. As a result, Arctic expeditions continued to be plagued by scurvy and other deficiency diseases. In the early 20th century, when Robert Falcon Scott made his two expeditions to the Antarctic, the prevailing medical theory at the time was that scurvy was caused by "tainted" canned food.
During the late 18th and early 19th centuries, the use of deprivation studies allowed scientists to isolate and identify a number of vitamins. Lipid from fish oil was used to cure rickets in rats, and the fat-soluble nutrient was called "antirachitic A". Thus, the first "vitamin" bioactivity ever isolated, which cured rickets, was initially called "vitamin A"; however, the bioactivity of this compound is now called vitamin D. In 1881, Russian surgeon Nikolai Lunin studied the effects of scurvy while at the University of Tartu in present-day Estonia. He fed mice an artificial mixture of all the separate constituents of milk known at that time, namely the proteins, fats, carbohydrates, and salts. The mice that received only the individual constituents died, while the mice fed by milk itself developed normally. He made a conclusion that "a natural food such as milk must therefore contain, besides these known principal ingredients, small quantities of unknown substances essential to life." However, his conclusions were rejected by his advisor, Gustav von Bunge, even after other students reproduced his results. A similar result by Cornelius Pekelharing appeared in a Dutch medical journal in 1905, but it was not widely reported.
In east Asia, where polished white rice was the common staple food of the middle class, beriberi resulting from lack of vitamin B1 was endemic. In 1884, Takaki Kanehiro, a British trained medical doctor of the Imperial Japanese Navy, observed that beriberi was endemic among low-ranking crew who often ate nothing but rice, but not among officers who consumed a Western-style diet. With the support of the Japanese navy, he experimented using crews of two battleships; one crew was fed only white rice, while the other was fed a diet of meat, fish, barley, rice, and beans. The group that ate only white rice documented 161 crew members with beriberi and 25 deaths, while the latter group had only 14 cases of beriberi and no deaths. This convinced Takaki and the Japanese Navy that diet was the cause of beriberi, but they mistakenly believed that sufficient amounts of protein prevented it. That diseases could result from some dietary deficiencies was further investigated by Christiaan Eijkman, who in 1897 discovered that feeding unpolished rice instead of the polished variety to chickens helped to prevent beriberi in the chickens. The following year, Frederick Hopkins postulated that some foods contained "accessory factors" — in addition to proteins, carbohydrates, fats "etc." — that are necessary for the functions of the human body. Hopkins and Eijkman were awarded the Nobel Prize for Physiology or Medicine in 1929 for their discoveries.
In 1910, the first vitamin complex was isolated by Japanese scientist Umetaro Suzuki, who succeeded in extracting a water-soluble complex of micronutrients from rice bran and named it aberic acid (later "Orizanin"). He published this discovery in a Japanese scientific journal. When the article was translated into German, the translation failed to state that it was a newly discovered nutrient, a claim made in the original Japanese article, and hence his discovery failed to gain publicity. In 1912 Polish-born biochemist Casimir Funk, working in London, isolated the same complex of micronutrients and proposed the complex be named "vitamine". It was later to be known as vitamin B3 (niacin), though he described it as "anti-beri-beri-factor" (which would today be called thiamine or vitamin B1). Funk proposed the hypothesis that other diseases, such as rickets, pellagra, coeliac disease, and scurvy could also be cured by vitamins. Max Nierenstein a friend and reader of Biochemistry at Bristol University reportedly suggested the "vitamine" name (from "vital amine").). The name soon became synonymous with Hopkins' "accessory factors", and, by the time it was shown that not all vitamins are amines, the word was already ubiquitous. In 1920, Jack Cecil Drummond proposed that the final "e" be dropped to deemphasize the "amine" reference, after researchers began to suspect that not all "vitamines" (in particular, vitamin A) have an amine component.
In 1930, Paul Karrer elucidated the correct structure for beta-carotene, the main precursor of vitamin A, and identified other carotenoids. Karrer and Norman Haworth confirmed Albert Szent-Györgyi's discovery of ascorbic acid and made significant contributions to the chemistry of flavins, which led to the identification of lactoflavin. For their investigations on carotenoids, flavins and vitamins A and B2, they both received the Nobel Prize in Chemistry in 1937.
In 1931, Albert Szent-Györgyi and a fellow researcher Joseph Svirbely suspected that "hexuronic acid" was actually vitamin C, and gave a sample to Charles Glen King, who proved its anti-scorbutic activity in his long-established guinea pig scorbutic assay. In 1937, Szent-Györgyi was awarded the Nobel Prize in Physiology or Medicine for his discovery. In 1943, Edward Adelbert Doisy and Henrik Dam were awarded the Nobel Prize in Physiology or Medicine for their discovery of vitamin K and its chemical structure. In 1967, George Wald was awarded the Nobel Prize (along with Ragnar Granit and Haldan Keffer Hartline) for his discovery that vitamin A could participate directly in a physiological process.
Etymology.
The term "vitamin" was derived from "vitamine", a compound word coined in 1912 by the Polish biochemist Kazimierz Funk when working at the Lister Institute of Preventive Medicine. The name is from "vital" and "amine", meaning amine of life, because it was suggested in 1912 that the organic micronutrient food factors that prevent beriberi and perhaps other similar dietary-deficiency diseases might be chemical amines. This was true of thiamine, but after it was found that other such micronutrients were not amines the word was shortened to vitamin in English.
Society and culture.
Once discovered, vitamins were actively promoted in articles and advertisements in "McCall's", "Good Housekeeping", and other media. Marketers enthusiastically promoted cod-liver oil, a source of Vitamin D, as "bottled sunshine", and bananas as a “natural vitality food". They promoted foods such as yeast cakes, a source of B vitamins, on the basis of scientifically-determined nutritional value, rather than taste or appearance. World War II researchers focused on the need to ensure adequate nutrition, especially in processed foods. Robert W. Yoder is credited with first using the term "vitamania", in 1942, to describe the appeal of relying on nutritional supplements rather than on obtaining vitamins from a varied diet of foods.
Governmental regulation.
Most countries place dietary supplements in a special category under the general umbrella of "foods", not drugs. As a result, the manufacturer, and not the government, has the responsibility of ensuring that its dietary supplement products are safe before they are marketed. Regulation of supplements varies widely by country. In the United States, a dietary supplement is defined under the Dietary Supplement Health and Education Act of 1994. There is no FDA approval process for dietary supplements, and no requirement that manufacturers prove the safety or efficacy of supplements introduced before 1994. The Food and Drug Administration must rely on its Adverse Event Reporting System to monitor adverse events that occur with supplements. In 2007, the US Code of Federal Regulations (CFR) Title 21, part III took effect, regulating GMP practices in the manufacturing, packaging, labeling, or holding operations for dietary supplements. Even though product registration is not required, these regulations mandate production and quality control standards (including testing for identity, purity and adulterations) for dietary supplements. In the European Union, the Food Supplements Directive requires that only those supplements that have been proven safe can be sold without a prescription.
For most vitamins, pharmacopoeial standards have been established. In the United States, the United States Pharmacopeia (USP) sets standards for the most commonly used vitamins and preparations thereof. Likewise, monographs of the European Pharmacopoeia (Ph.Eur.) regulate aspects of identity and purity for vitamins on the European market.
Naming.
The reason that the set of vitamins skips directly from E to K is that the vitamins corresponding to letters F–J were either reclassified over time, discarded as false leads, or renamed because of their relationship to vitamin B, which became a complex of vitamins.
The German-speaking scientists who isolated and described vitamin K (in addition to naming it as such) did so because the vitamin is intimately involved in the coagulation of blood following wounding (from the German word "Koagulation"). At the time, most (but not all) of the letters from F through to J were already designated, so the use of the letter K was considered quite reasonable. The table "nomenclature of reclassified vitamins" lists chemicals that had previously been classified as vitamins, as well as the earlier names of vitamins that later became part of the B-complex.
There are other missing B vitamins which were reclassified or determined not to be vitamins. For example, B9 is folic acid and five of the folates are in the range B11 through B16, forms of other vitamins already discovered, not required as a nutrient by the entire population (like B10, PABA for internal use), biologically inactive, toxic, or with unclassifiable effects in humans, or not generally recognised as vitamins by science, such as the highest-numbered, which some naturopath practitioners call B21 and B22. There are also nine lettered B complex vitamins (e.g. Bm). There are other D vitamins now recognised as other substances, which some sources of the same type number up to D7. The controversial cancer treatment laetrile was at one point lettered as vitamin B17. There appears to be no consensus on any vitamins Q, R, T, V, W, X, Y or Z, nor are there substances officially designated as Vitamins N or I, although the latter may have been another form of one of the other vitamins or a known and named nutrient of another type.
Anti-vitamins.
Anti-vitamins are chemical compounds that inhibit the absorption or actions of vitamins. For example, avidin is a protein in egg whites that inhibits the absorption of biotin. Pyrithiamine is similar to thiamine, vitamin B1, and inhibits the enzymes that use thiamine.
See also.
Provitamin

</doc>
<doc id="32513" url="https://en.wikipedia.org/wiki?curid=32513" title="Viroid">
Viroid

Viroids are among the smallest infectious pathogens known, larger only than prions, which are misfolded proteins. Viroids consist solely of short strands of circular, single-stranded RNA without protein coats. They are mostly plant pathogens, some of which are of economic importance. Viroid genomes are extremely small in size, ranging from 246 to 467 nucleobases. In comparison, the genome of the smallest known viruses capable of causing an infection by themselves are around 2,000 nucleobases in size. The human pathogen hepatitis D virus is a defective RNA virus similar to viroids.
Viroids, the first known representatives of a new domain of "sub-viral pathogens", were discovered, initially characterized, and named by Theodor Otto Diener, plant pathologist at the U.S Department of Agriculture's Research Center in Beltsville, Maryland, in 1971. The first viroid to be identified was "Potato spindle tuber viroid" (PSTVd). Some 33 species have been identified.
Viroids do not code for any protein. Viroid's replication mechanism uses RNA polymerase II, a host cell enzyme normally associated with synthesis of messenger RNA from DNA, which instead catalyzes "rolling circle" synthesis of new RNA using the viroid's RNA as a template. Some viroids are ribozymes, having catalytic properties which allow self-cleavage and ligation of unit-size genomes from larger replication intermediates.
With Diener’s 1989 hypothesis that viroids may represent "living relics" from the widely assumed, ancient, and non-cellular RNA world—extant before the evolution of DNA or proteins—viroids have assumed significance beyond plant pathology to evolutionary science, by representing the most plausible RNAs capable of performing crucial steps in abiogenesis, the evolution of life from inanimate matter.
Transmission.
Viroid infections are transmitted by cross contamination following mechanical damage to plants as a result of horticultural or agricultural practices. Some are transmitted by aphids and they can also be transferred from plant to plant by leaf contact.
Replication.
Viroids replicate in the nucleus ("Pospiviroidae") or chloroplasts ("Avsunviroidae") of plant cells in three steps through an RNA-based mechanism. They require RNA polymerase II, a host cell enzyme normally associated with synthesis of messenger RNA from DNA, which instead catalyzes "rolling circle" synthesis of new RNA using the viroid as template Some viroids are ribozymes, having catalytic properties which allow self-cleavage and ligation of unit-size genomes from larger replication intermediates.
RNA silencing.
There has long been uncertainty over how viroids induce symptoms in plants without encoding any protein products within their sequences. Evidence suggests that RNA silencing is involved in the process. First, changes to the viroid genome can dramatically alter its virulence. This reflects the fact that any siRNAs produced would have less complementary base pairing with target messenger RNA. Secondly, siRNAs corresponding to sequences from viroid genomes have been isolated from infected plants. Finally, transgenic expression of the noninfectious hpRNA of potato spindle tuber viroid develops all the corresponding viroid-like symptoms. This indicates that when viroids replicate via a double stranded intermediate RNA, they are targeted by a dicer enzyme and cleaved into siRNAs that are then loaded onto the RNA-induced silencing complex. The viroid siRNAs contain sequences capable of complementary base pairing with the plant's own messenger RNAs, and induction of degradation or inhibition of translation causes the classic viroid symptoms.
Living relics of the RNA world.
Diener's 1989 hypothesis proposed that unique properties of viroids make them more plausible macromolecules than introns, or other RNAs considered in the past as possible "living relics" of a hypothetical, pre-cellular RNA world. If so, viroids have assumed significance beyond plant virology for evolutionary science, because their properties make them more plausible candidates than other RNAs to perform crucial steps in the evolution of life from inanimate matter (abiogenesis).
These properties are:
Diener's hypothesis was mostly forgotten until 2014, when it was resurrected in a review article by Flores et al., in which the authors summarized Diener's evidence supporting his hypothesis (see above). In the same year, "New York Times" science writer Carl Zimmer published a popularized piece that mistakenly credited Flores et al. with the hypothesis' original conception.
The presence, in extant cells, of RNAs with molecular properties predicted for RNAs of the RNA World constitutes another powerful argument supporting the RNA World hypothesis.
History.
In the 1920s, symptoms of a previously unknown potato disease were noticed in New York and New Jersey fields. Because tubers on affected plants become elongated and misshaped, they named it the potato spindle tuber disease.
The symptoms appeared on plants onto which pieces from affected plants had been budded—indicating that the disease was caused by a transmissible pathogenic agent. However, a fungus or bacterium could not be found consistently associated with symptom-bearing plants, and therefore, it was assumed the disease was caused by a virus. Despite numerous attempts over the years to isolate and purify the assumed virus, using increasingly sophisticated methods, these were unsuccessful when applied to extracts from potato spindle tuber disease-afflicted plants.
In 1971 Theodor O. Diener showed that the agent was not a virus, but a totally unexpected novel type of pathogen, one-80th the size of typical viruses, for which he proposed the term "viroid". Parallel to agriculture-directed studies, more basic scientific research elucidated many of viroids' physical, chemical, and macromolecular properties. Viroids were shown to consist of short stretches (a few hundred nucleobases) of single-stranded RNA and, unlike viruses, did not have a protein coat. Compared with other infectious plant pathogens, viroids are extremely small in size, ranging from 246 to 467 nucleobases; they thus consist of fewer than 10,000 atoms. In comparison, the genomes of the smallest known viruses capable of causing an infection by themselves are around 2,000 nucleobases long.
In 1976, Sänger et al. presented evidence that potato spindle tuber viroid is a "single-stranded, covalently closed, circular RNA molecule, existing as a highly base-paired rod-like structure"—believed to be the first such molecule described. Circular RNA, unlike linear RNA, forms a covalently closed continuous loop, in which the 3' and 5' ends present in linear RNA molecules have been joined together. Sänger et al. also provided evidence for the true circularity of viroids by finding that the RNA could not be phosphorylated at the 5' terminus. Then, in other tests, they failed to find even one free 3' end, which ruled out the possibility of the molecule having two 3’ ends. Viroids thus are true circular RNAs.
The single-strandedness and circularity of viroids was confirmed by electron microscopy, and Gross et al. determined the complete nucleotide sequence of potato spindle tuber viroid in 1978. PSTV was the first pathogen of a eukaryotic organism for which the complete molecular structure has been established. Over thirty plant diseases have since been identified as viroid-, not virus-caused, as had been assumed.

</doc>
<doc id="32516" url="https://en.wikipedia.org/wiki?curid=32516" title="Vladimir Vernadsky">
Vladimir Vernadsky

Vladimir Ivanovich Vernadsky (; ;  – 6 January 1945) was a Russian, Ukrainian, and Soviet mineralogist and geochemist who is considered one of the founders of geochemistry, biogeochemistry, and of radiogeology, founder of the Ukrainian Academy of Sciences (now National Academy of Sciences of Ukraine). His ideas of noosphere were an important contribution to Russian cosmism. He is most noted for his 1926 book "The Biosphere" in which he inadvertently worked to popularize Eduard Suess’ 1885 term biosphere, by hypothesizing that life is the geological force that shapes the earth. In 1943 he was awarded the Stalin Prize.
Biography.
Vernadsky was born in Saint Petersburg, Russian Empire, on in family of the native Kiev residents Russian-Ukrainian economist Ivan Vernadsky and music instructor Hanna Konstantynovych. According to family legend, his father was a descendent of Zaporozhian Cossacks. He had been a professor of political economy in Kiev before moving to Saint Petersburg. His mother was a Russian noblewoman of Ukrainian Cossack descent.
Vernadsky graduated from Saint Petersburg State University in 1885. As the position of mineralogist in Saint Petersburg State University was vacant, and Vasily Dokuchaev, a soil scientist, and Alexey Pavlov, a geologist, had been teaching Mineralogy for a while, Vernadsky chose to enter Mineralogy. He wrote to his wife Natasha on 20 June 1888 from Switzerland:
While trying to find a topic for his doctorate, he first went to Naples to study under crystallographer Arcangelo Scacchi, who was senile by that time. Scacchi's condition led Vernadsky to go to Germany to study under Paul Groth. Vernadsky learned to use Groth's modern equipment, who had developed a machine to study the optical, thermal, elastic, magnetic and electrical properties of crystals. He also gained access to the physics lab of Leonhard Sohncke (Direktor, Physikalisches Institut der Universität Jena, 1883–1886; Professor der Physik an der Technischen Hochschule München 1886 -1897), who was studying crystallisation during that period.
Vernadsky participated in the First General Congress of the zemstvos, held in Petersburg on the eve of the 1905 revolution to discuss how best to pressure the government to the needs of the Russian society; became a member of the liberal Constitutional Democratic Party (KD); and served in parliament, resigning to protest the Tsar's proroguing of the Duma. He served as professor and later as vice rector of Moscow University, from which he also resigned in 1911 in protest over the government's reactionary policies. After the February revolution of 1917, he served on several commissions of agriculture and education of the provisional government, including as assistant minister of education.
Vernadsky first popularized the concept of the noosphere and deepened the idea of the biosphere to the meaning largely recognized by today's scientific community. The word 'biosphere' was invented by Austrian geologist Eduard Suess, whom Vernadsky met in 1911.
In Vernadsky's theory of the Earth's development, the noosphere is the third stage in the earth's development, after the geosphere (inanimate matter) and the biosphere (biological life). Just as the emergence of life fundamentally transformed the geosphere, the emergence of human cognition will fundamentally transform the biosphere. In this theory, the principles of both life and cognition are essential features of the Earth's evolution, and must have been implicit in the earth all along. This systemic and geological analysis of living systems complements Charles Darwin's theory of natural selection, which looks at each individual species, rather than at its relationship to a subsuming principle.
Vernadsky's visionary pronouncements were not widely accepted in the West. However, he was one of the first scientists to recognize that the oxygen, nitrogen and carbon dioxide in the Earth's atmosphere result from biological processes. During the 1920s he published works arguing that living organisms could reshape the planets as surely as any physical force. Vernadsky was an important pioneer of the scientific bases for the environmental sciences.
Vernadsky was a member of the Russian and Soviet Academies of Sciences since 1912 and was a founder and first president of the Ukrainian Academy of Sciences in Kiev, Ukraine (1918). He was a founder of the National Library of Ukrainian State and worked closely with the Tavrida University in Crimea. During the Russian Civil War, he hosted gatherings of the young intellectuals who later founded the émigré Eurasianism movement.
In the late 1930s and early 1940s Vernadsky played an early advisory role in the Soviet atomic bomb project, as one of the most forceful voices arguing for the exploitation of nuclear power, the surveying of Soviet uranium sources, and having nuclear fission research conducted at his Radium Institute. He died, however, before a full project was pursued.
On religious views, Vernadsky was an atheist. He was interested in Hinduism and Rig Veda
Vernadsky's son George Vernadsky (1887–1973) emigrated to the United States where he published numerous books on medieval and modern Russian history.
The National Library of Ukraine, the Tavrida National University in Crimea and many streets and avenues in Ukraine and Russia are named in honor of Vladimir Vernadsky.
UNESCO sponsored an international scientific conference, "Globalistics-2013", at Moscow State University on October 23–25, 2013, in honor of Vernadsky's 150th birthday.

</doc>
<doc id="32517" url="https://en.wikipedia.org/wiki?curid=32517" title="VAX">
VAX

VAX was an instruction set architecture (ISA), developed by Digital Equipment Corporation (DEC) in the mid-1970s. The VAX-11/780, introduced on October 25, 1977, was the first of a range of popular and influential computers implementing that architecture.
A 32-bit complex instruction set computer based on DEC's earlier PDP-11, VAX (""virtual address extension"") was designed to extend or replace DEC's various PDP ISAs. The VAX architecture's primary features were virtual addressing (for example demand paged virtual memory) and its orthogonal instruction set.
VAX has been perceived as the quintessential CISC ISA, with its very large number of programmer-friendly addressing modes and machine instructions, highly orthogonal architecture, and instructions for complex operations such as queue insertion or deletion and polynomial evaluation.
Name.
The name "VAX" originated as an acronym for "virtual address extension", both because the VAX was seen as a 32-bit extension of the older 16-bit PDP-11 and because it was (after Prime Computer) an early adopter of virtual memory to manage this larger address space. Early versions of the VAX processor implemented a "compatibility mode" that emulated many of the PDP-11's instructions, and were in fact called VAX-11 to highlight this compatibility and the fact that VAX-11 was an outgrowth of the PDP-11 family. Later versions offloaded the compatibility mode and some of the less used CISC instructions to emulation in the operating system software.
Instruction set.
The VAX instruction set was designed to be powerful and orthogonal. When it was introduced, many programs were written in assembly language, so having a "programmer-friendly" instruction set was important. In time, as more programs were written in higher-level language, the instruction set became less visible, and the only ones much concerned about it were compiler writers.
One unusual aspect of the VAX instruction set is the presence of register masks at the start of each subprogram. These are arbitrary bit patterns that specify, when control is passed to the subprogram, which registers are to be preserved. Since register masks are a form of data embedded within the executable code, they can make linear parsing of the machine code difficult. This can complicate optimization techniques that are applied on machine code.
Operating systems.
The "native" VAX operating system is DEC's VAX/VMS (renamed to "OpenVMS" in 1991 or early 1992 when it was ported to Alpha, modified to comply with POSIX standards, and "branded" as compliant with XPG4 by the X/Open consortium). The VAX architecture and VMS operating system were "engineered concurrently" to take maximum advantage of each other, as was the initial implementation of the VAXcluster facility. Other VAX operating systems have included various releases of BSD UNIX up to 4.3BSD, Ultrix-32, VAXELN and Xinu. More recently, NetBSD and OpenBSD support various VAX models and some work has been done on porting Linux to the VAX architecture.
History.
The first VAX model sold was the VAX-11/780, which was introduced on October 25, 1977 at the Digital Equipment Corporation's Annual Meeting of Shareholders. Bill Strecker, C. Gordon Bell's doctoral student at Carnegie Mellon University, was responsible for the architecture. Many different models with different prices, performance levels, and capacities were subsequently created. VAX superminicomputers were very popular in the early 1980s.
For a while the VAX-11/780 was used as a standard in CPU benchmarks. It was initially described as a one-MIPS machine, because its performance was equivalent to an IBM System/360 that ran at one MIPS, and the System/360 implementations had previously been de facto performance standards. The actual number of instructions executed in 1 second was about 500,000, which led to complaints of marketing exaggeration. The result was the definition of a "VAX MIPS," the speed of a VAX-11/780; a computer performing at 27 VAX MIPS would run the same program roughly 27 times faster than the VAX-11/780. Within the Digital community the term "VUP" (VAX Unit of Performance) was the more common term, because MIPS do not compare well across different architectures. The related term "cluster VUPs" was informally used to describe the aggregate performance of a VAXcluster. (The performance of the VAX-11/780 still serves as the baseline metric in the BRL-CAD Benchmark, a performance analysis suite included in the BRL-CAD solid modeling software distribution.) The VAX-11/780 included a subordinate stand-alone LSI-11 computer that performed microcode load, booting, and diagnostic functions for the parent computer. This was dropped from subsequent VAX models. Enterprising VAX-11/780 users could therefore run three different Digital Equipment Corporation operating systems: VMS on the VAX processor, and either RSX-11M or RT-11 on the LSI-11.
The VAX went through many different implementations. The original VAX 11/780 was implemented in TTL and filled a four-by-five-foot cabinet with a single CPU. CPU implementations that consisted of multiple ECL gate array or macrocell array chips included the VAX 8600 and 8800 superminis and finally the VAX 9000 mainframe class machines. CPU implementations that consisted of multiple MOSFET custom chips included the 8100 and 8200 class machines. The VAX 11-730 and 725 low end machines were built using bit-slice components.
The MicroVAX I represented a major transition within the VAX family. At the time of its design, it was not yet possible to implement the full VAX architecture as a single VLSI chip (or even a few VLSI chips as was later done with the V-11 CPU of the VAX 8200/8300). Instead, the MicroVAX I was the first VAX implementation to move some of the more complex VAX instructions (such as the packed decimal and related opcodes) into emulation software. This partitioning substantially reduced the amount of microcode required and was referred to as the "MicroVAX" architecture. In the MicroVAX I, the ALU and registers were implemented as a single gate-array chip while the rest of the machine control was conventional logic.
A full VLSI (microprocessor) implementation of the MicroVAX architecture arrived with the MicroVAX II's 78032 (or DC333) CPU and 78132 (DC335) FPU. The 78032 was the first microprocessor with an on-board memory management unit The MicroVAX II was based on a single, quad-sized processor board which carried the processor chips and ran the MicroVMS or Ultrix-32 operating systems. The machine featured 1 MB of on-board memory and a Q22-bus interface with DMA transfers. The MicroVAX II was succeeded by many further MicroVAX models with much improved performance and memory.
Further VLSI VAX processors followed in the form of the V-11, CVAX, CVAX SOC ("System On Chip", a single-chip CVAX), Rigel, Mariah and NVAX implementations. The VAX microprocessors extended the architecture to inexpensive workstations and later also supplanted the high-end VAX models. This wide range of platforms (mainframe to workstation) using one architecture was unique in the computer industry at that time. Sundry graphics were etched onto the CVAX microprocessor die. The phrase "CVAX... when you care enough to steal the very best" was etched in broken Russian as a play on a Hallmark Cards slogan, intended as a message to Soviet engineers who were known to be both purloining DEC computers for military applications and reverse engineering their chip design.
In DEC's product offerings, the VAX architecture was eventually superseded by RISC technology. In 1989 DEC introduced a range of workstations and servers that ran Ultrix, the DECstation and DECsystem respectively, based on processors that implemented the MIPS architecture. In 1992 DEC introduced their own RISC instruction set architecture, the Alpha AXP (later renamed Alpha), and their own Alpha-based microprocessor, the DECchip 21064, a high performance 64-bit design capable of running OpenVMS.
In August 2000, Compaq announced that the remaining VAX models would be discontinued by the end of the year. By 2005 all manufacturing of VAX computers had ceased, but old systems remain in widespread use.
The Stromasys CHARON-VAX, SIMH and Vere Technologies vtVAX software-based VAX emulators remain available.
Processor architecture.
Virtual memory map.
The VAX virtual memory is divided into four sections, each of which is one gigabyte (In the context of addressing, 230 bytes) in size:
For VMS, P0 was used for user process space, P1 for process stack, S0 for the operating system, and S1 was reserved.
Privilege modes.
The VAX has four hardware implemented privilege modes:
Addressing modes.
The VAX supports many addressing modes: literal, register, postincrement, predecrement, register deferred, postincrement deferred, predecrement deferred, displacement (byte, word, long), displacement (byte, word, long) deferred; also indexed, which may be combined with many of these. An "immediate" mode is synonymous with program counter (PC) postincrement, and many addressing modes could use the program counter (which is also R15) instead of other registers. This provided for easy generation of position-independent code through "PC-relative" addressing. The VAX also has some "load effective address" instructions, which do not access memory but compute the address that should be used.
VAX-based systems.
The first VAX-based system was the VAX-11/780, a member of the VAX-11 family. The high-end VAX 8600 replaced the VAX-11/780 in October 1984 and was joined by the entry-level MicroVAX minicomputers and the VAXstation workstations in the mid-1980s. The MicroVAX was superseded by the VAX 4000, the VAX 8000 was superseded by the VAX 6000 in the late 1980s and the mainframe-class VAX 9000 was introduced. In the early 1990s, the fault-tolerant VAXft was introduced, as were the Alpha compatible VAX 7000/10000. A variant of various VAX-based systems were sold as the VAXserver.
Cancelled systems.
Cancelled systems include the ""BVAX"", a high-end ECL-based VAX, and two other ECL-based VAX models: ""Argonaut"" and ""Raven"". A VAX known as ""Gemini"" was also cancelled, which was a fall-back in case the LSI-based "Scorpio" failed. It never shipped.
Clones.
A number of VAX clones, both authorized and unauthorized, were produced. Examples include:

</doc>
<doc id="32519" url="https://en.wikipedia.org/wiki?curid=32519" title="Valens">
Valens

Valens (328 – 9 August 378), fully "Flavius Julius Valens Augustus" (), was Eastern Roman Emperor from 364 to 378. He was given the eastern half of the empire by his brother Valentinian I after the latter's accession to the throne. Valens, sometimes known as the Last True Roman, was defeated and killed in the Battle of Adrianople, which marked the beginning of the collapse of the decaying Western Roman Empire.
Life.
Appointment as emperor.
Valens and his brother Valentinian were both born in Cibalae (in present-day Croatia) into an Illyrian family in 328 and 321 respectively. They had grown up on estates purchased by their father Gratian the Elder in Africa and Britain. While Valentinian had enjoyed a successful military career prior to his appointment as emperor, Valens apparently had not. He had spent much of his youth on the family's estate and only joined the army in the 360s, participating with his brother in the Persian campaign of Emperor Julian.
In February 364, reigning Emperor Jovian, while hastening to Constantinople to secure his claim to the throne, was asphyxiated during a stop at Dadastana, 100 miles east of Ankara. Among Jovian's lieutenants was Valentinian, a "tribunus scutariorum". He was proclaimed Augustus on 26 February, 364. Valentinian felt that he needed help to govern the large and troublesome empire, and, on 28 March of the same year, appointed his brother Valens as co-emperor in the palace of Hebdomon. The two "Augusti" travelled together through Adrianople and Naissus to Sirmium, where they divided their personnel, and Valentinian went on to the West.
Valens obtained the eastern half of the Empire Greece, Egypt, Syria and Anatolia as far east as Persia. Valens was back in his capital of Constantinople by December 364.
365 Crete earthquake.
In 365, an undersea earthquake between magnitudes 8 and 9 near Crete caused a tsunami that hit the coasts of the Eastern Mediterranean.
Revolt of Procopius.
Valens inherited the eastern portion of an empire that had recently retreated from most of its holdings in Mesopotamia and Armenia because of a treaty that his predecessor Jovian had made with Shapur II of the Sassanid Empire. Valens's first priority after the winter of 365 was to move east in hopes of shoring up the situation. By the autumn of 365 he had reached Cappadocian Caesarea when he learned that a usurper, named Procopius, had proclaimed himself in Constantinople. When he died, Julian the emperor had left behind one surviving relative, a maternal cousin named Procopius. Procopius had been charged with overseeing a northern division of his relative's army during the Persian expedition and had not been present when Jovian was named his successor. Though Jovian made accommodations to appease this potential claimant, Procopius fell increasingly under suspicion in the first year of Valens' reign.
After narrowly escaping arrest, he went into hiding and reemerged at Constantinople where he was able to convince two military units passing through the capital to proclaim him emperor on 28 September 365. Though his early reception in the city seems to have been lukewarm, Procopius won favor quickly by using propaganda to his advantage: he sealed off the city to outside reports and began spreading rumors that Valentinian had died; he began minting coinage flaunting his connections to the Constantinian dynasty; and he further exploited dynastic claims by using the widow and daughter of Constantius II to act as showpieces for his regime. This program met with some success, particularly among soldiers loyal to the Constantinians and eastern intellectuals who had already begun to feel persecuted by the Valentinians.
Valens, meanwhile, faltered. When news arrived that Procopius had revolted, Valens considered abdication and perhaps even suicide. Even after he steadied his resolve to fight, Valens's efforts to forestall Procopius were hampered by the fact that most of his troops had already crossed the Cilician gates into Syria when he learned of the revolt. Even so, Valens sent two legions to march on Procopius, who easily persuaded them to desert to him. Later that year, Valens himself was nearly captured in a scramble near Chalcedon. Troubles were exacerbated by the refusal of Valentinian to do any more than protect his own territory from encroachment. The failure of imperial resistance in 365 allowed Procopius to gain control of the dioceses of Thrace and Asiana by year's end.
Only in the spring of 366 had Valens assembled enough troops to deal with Procopius effectively. Marching out from Ancyra through Pessinus, Valens proceeded into Phrygia where he defeated Procopius's general Gomoarius at the Battle of Thyatira. He then met Procopius himself at Nacoleia and convinced his troops to desert him. Procopius was executed on 27 May and his head sent to Valentinian in Trier for inspection.
War against the Goths.
The Gothic people in the northern region had supported Procopius in his revolt against Valens, and Valens had learned the Goths were planning an uprising of their own. These Goths, more specifically the Thervingi, were at the time under the leadership of Athanaric and had apparently remained peaceful since their defeat under Constantine in 332. In the spring of 367, Valens crossed the Danube and marched on Athanaric's Goths. These fled into the Carpathian Mountains, and eluded Valens' advance, forcing him to return later that summer. The following spring, a Danube flood prevented Valens from crossing; instead the Emperor occupied his troops with the construction of fortifications. In 369, Valens crossed again, from Noviodunum, and attacked the north-easterly Gothic tribe of Greuthungi before facing Athanaric's Tervingi and defeating them. Athanaric pled for treaty terms and Valens gladly obliged. The treaty seems to have largely cut off relations between Goths and Romans, including free trade and the exchange of troops for tribute. Valens would feel this loss of military manpower in the following years.
Conflict with the Sassanids.
Among Valens' reasons for contracting a hasty and not entirely favorable peace in 369 was the deteriorating state of affairs in the East. Jovian had surrendered Rome's much disputed claim to control over Armenia in 363, and Shapur II was eager to make good on this new opportunity. The Sassanid ruler began enticing Armenian lords over to his camp and eventually forced the defection of the Arsacid Armenian king, Arsaces II (Arshak II), whom he quickly arrested and incarcerated. Shapur then sent an invasion force to seize Caucasian Iberia and a second to besiege Arsaces II's son, Papas (Pap), in the fortress of Artogerassa, probably in 367. By the following spring, Papas had engineered his escape from the fortress and flight to Valens, whom he seems to have met at Marcianople while campaigning against the Goths.
Already in the summer following his Gothic settlement, Valens sent his general Arinthaeus to re-impose Papas on the Armenian throne. This provoked Shapur himself to invade and lay waste to Armenia. Papas, however, once again escaped and was restored a second time under escort of a much larger force in 370. The following spring, larger forces were sent under Terentius to regain Iberia and to garrison Armenia near Mount Npat. When Shapur counterattacked into Armenia in 371, his forces were bested by Valens' generals Trajanus and Vadomarius at Bagavan. Valens had overstepped the 363 treaty and then successfully defended his transgression. A truce settled after the 371 victory held as a quasi-peace for the next five years while Shapur was forced to deal with a Kushan invasion on his eastern frontier.
Meanwhile, troubles broke out with the boy-king Papas, who began acting in high-handed fashion, even executing the Armenian bishop Narses and demanding control of a number of Roman cities, including Edessa. Pressed by his generals and fearing that Papas would defect to the Persians, Valens made an unsuccessful attempt to capture the prince and later had him executed inside Armenia. In his stead, Valens imposed another Arsacid Varasdates (Varazdat), who ruled under the regency of the "sparapet" Mushegh I Mamikonian, a friend of Rome.
None of this sat well with the Persians, who began agitating again for compliance with the 363 treaty. As the eastern frontier heated up in 375, Valens began preparations for a major expedition. Meanwhile, trouble was brewing elsewhere. In Isauria, the mountainous region of western Cilicia, a major revolt had broken out in 375 which diverted troops formerly stationed in the East. Furthermore, by 377, the Saracens under Queen Mavia had broken into revolt and devastated a swath of territory stretching from Phoenicia and Palestine as far as the Sinai. Though Valens successfully brought both uprisings under control, the opportunities for action on the eastern frontier were limited by these skirmishes closer to home.
In 375, Valens' older brother Valentinian suffered a burst blood vessel in his skull while in Pannonia, which resulted in his death on 17 November, 375. Gratian, Valentinian's son and Valens' nephew, had already been associated with his father in the imperial dignity and was joined by his half-brother Valentinian II who was elevated, on their father's death, to Augustus by the imperial troops in Pannonia.
Gothic War.
Valens' plans for an eastern campaign were never realized. A transfer of troops to the Western Empire in 374 had left gaps in Valens' mobile forces. In preparation for an eastern war, Valens initiated an ambitious recruitment program designed to fill those gaps. It was thus not unwelcome news when Valens learned that the Gothic tribes had been displaced from their homeland by an invasion of Huns in 375 and were seeking asylum from him. In 376, the Visigoths advanced to the far shores of the lower Danube and sent an ambassador to Valens who had set up his capital in Antioch. The Goths requested shelter and land in Illyria. An estimated 200,000 Gothic Warriors and altogether 1,000,000 Gothic persons were along the Danube in Moesia and the ancient land of Dacia.
As Valens' advisers were quick to point out, these Goths could supply troops who would at once swell Valens' ranks and decrease his dependence on provincial troop levies — thereby increasing revenues from the recruitment tax. Among the Goths seeking asylum was a group led by the chieftain Fritigern. Fritigern had enjoyed contact with Valens in the 370s when Valens supported him in a struggle against Athanaric stemming from Athanaric's persecution of Gothic Christians. Though a number of Gothic groups apparently requested entry, Valens granted admission only to Fritigern and his followers. This did not, however, prevent others from following.
When Fritigern and his Goths undertook the crossing, Valens's mobile forces were tied down in the east, on the Persian frontier and in Isauria. This meant that only limitanei units were present to oversee the Goths' settlement. The small number of imperial troops present prevented the Romans from stopping a Danube crossing by a group of Goths and later by Huns and Alans. What started out as a controlled resettlement mushroomed into a massive influx. And the situation grew worse. When the generals present began abusing the Visigoths under their charge, they revolted in early 377 and defeated the Roman units in Thrace outside of Marcianople.
After joining forces with the Ostrogoths and eventually the Huns and Alans, the combined barbarian group marched widely before facing an advance force of imperial soldiers sent from both east and west. In a battle at "Ad Salices", the Goths were once again victorious, winning free run of Thrace south of the Haemus. By 378, Valens himself was able to march west from his eastern base in Antioch. He withdrew all but a skeletal force — some of them Goths — from the east and moved west, reaching Constantinople by 30 May, 378. Meanwhile, Valens' councilors, Comes Richomeres, and his generals Frigerid, Sebastian, and Victor cautioned Valens and tried to persuade him to wait for Gratian's arrival with his victorious legionaries from Gaul, something that Gratian himself strenuously advocated. What happened next is an example of hubris, the impact of which was to be felt for years to come. Valens, jealous of his nephew Gratian's success, decided he wanted this victory for himself.
Battle of Adrianople and death of Valens.
After a brief stay aimed at building his troop strength and gaining a toehold in Thrace, Valens moved out to Adrianople. From there, he marched against the confederated barbarian army on 9 August 378 in what would become known as the Battle of Adrianople. Although negotiations were attempted, these broke down when a Roman unit sallied forth and carried both sides into battle. The Romans held their own early on but were crushed by the surprise arrival of Visigoth cavalry which split their ranks.
The primary source for the battle is Ammianus Marcellinus. Valens had left a sizeable guard with his baggage and treasures depleting his force. His right wing, cavalry, arrived at the Gothic camp sometime before the left wing arrived. It was a very hot day and the Roman cavalry was engaged without strategic support, wasting its efforts while they suffered in the heat.
Meanwhile Fritigern once again sent an emissary of peace in his continued manipulation of the situation. The resultant delay meant that the Romans present on the field began to succumb to the heat. The army's resources were further diminished when an ill timed attack by the Roman archers made it necessary to recall Valens' emissary, Comes Richomeres. The archers were beaten and retreated in humiliation.
Returning from foraging to find the battle in full swing, Gothic cavalry under the command of Althaeus and Saphrax now struck and, with what was probably the most decisive event of the battle, the Roman cavalry fled. From here, Ammianus gives two accounts of Valens' demise. In the first account, Ammianus states that Valens was "mortally wounded by an arrow, and presently breathed his last breath," (XXXI.12) His body was never found or given a proper burial. In the second account, Ammianus states the Roman infantry was abandoned, surrounded and cut to pieces. Valens was wounded and carried to a small wooden hut. The hut was surrounded by the Goths who put it to the torch, evidently unaware of the prize within. According to Ammianus, this is how Valens perished (XXXI.13.14-6). A third apocryphal account states that Valens was struck in the face by a Gothic dart and then perished while leading a charge. He wore no helmet to encourage his men. This action turned the tide of the battle which resulted in a tactical victory but a strategic loss.
The church historian Socrates likewise gives two accounts for the death of Valens.
Some have asserted that he was burnt to death in a village whither he had retired, which the barbarians assaulted and set on fire. But others affirm that having put off his imperial robe he ran into the midst of the main body of infantry; and that when the cavalry revolted and refused to engage, the infantry were surrounded by the barbarians, and completely destroyed in a body. Among these it is said the Emperor fell, but could not be distinguished, in consequence of his not having on his imperial habit.
When the battle was over, two-thirds of the eastern army lay dead. Many of their best officers had also perished. What was left of the army of Valens was led from the field under the cover of night by Comes Richomer and General Victor.
J.B. Bury, a noted historian of the period, provides specific interpretation on the significance the battle: it was "a disaster and disgrace that need not have occurred."
For Rome, the battle incapacitated the government. Emperor Gratian, nineteen years old, was overcome by the debacle, and until he appointed Theodosius I, unable to deal with the catastrophe which spread out of control.
Legacy.
"Valens was utterly undistinguished, still only a "protector", and possessed no military ability: he betrayed his consciousness of inferiority by his nervous suspicion of plots and savage punishment of alleged traitors," writes A.H.M. Jones. But Jones admits that "he was a conscientious administrator, careful of the interests of the humble. Like his brother, he was an earnest Christian." To have died in so inglorious a battle has thus come to be regarded as the nadir of an unfortunate career. This is especially true because of the profound consequences of Valens' defeat. Adrianople spelled the beginning of the end for Roman territorial integrity in the late Empire and this fact was recognized even by contemporaries. Ammianus understood that it was the worst defeat in Roman history since the Battle of Cannae (31.13.19), and Rufinus called it "the beginning of evils for the Roman empire then and thereafter."
Valens is also credited with the commission of a short history of the Roman State. This work, produced by Valens' secretary Eutropius, and known with the name "Breviarium ab Urbe condita", tells the story of Rome from its founding. According to some historians, Valens was motivated by the necessity of learning Roman history, that he, the royal family and their appointees might better mix with the Roman Senatorial class.
Struggles with the religious nature of the Empire.
During his reign, Valens had to confront the theological diversity that was beginning to create division in the Empire. Julian (361–363), had tried to revive the pagan religions. His reactionary attempt took advantage of the dissensions between the different factions among the Christians and a largely Pagan rank and file military. However, in spite of broad support, his actions were often viewed as excessive, and before he died in a campaign against the Persians, he was often treated with disdain. His death was considered a sign from God.
Like the brothers Constantius II and Constans, Valens and Valentinian I held divergent theological views. Valens was an Arian and Valentinian I upheld the Nicene Creed. When Valens died however, the cause of Arianism in the Roman East was to come to an end. His successor Theodosius I would endorse the Nicene Creed.

</doc>
<doc id="32521" url="https://en.wikipedia.org/wiki?curid=32521" title="VCR (disambiguation)">
VCR (disambiguation)

A VCR is a videocassette recorder
VCR may also refer to:

</doc>
<doc id="32524" url="https://en.wikipedia.org/wiki?curid=32524" title="Batavia (ship)">
Batavia (ship)

Batavia () was a ship of the Dutch East India Company (VOC). It was built in Amsterdam in 1628, and armed with 24 cast-iron cannons and a number of bronze guns. "Batavia" was shipwrecked on her maiden voyage, and was made famous by the subsequent mutiny and massacre that took place among the survivors. A twentieth-century replica of the ship is also called the "Batavia" and can be visited in Lelystad, Netherlands.
Mutiny on the "Batavia".
Departure and voyage.
On 27 October 1628, the newly built "Batavia", commissioned by the Dutch East India Company, sailed from Texel for the Dutch East Indies, to obtain spices. It sailed under "commandeur" and "opperkoopman" (upper- or senior merchant) Francisco Pelsaert, with Ariaen Jacobsz serving as skipper. These two had previously encountered each other in Surat, India. Although some animosity had developed between them there, it is not known whether Pelsaert even remembered Jacobsz when he boarded "Batavia". Also on board was the "onderkoopman" (under- or junior merchant) Jeronimus Cornelisz, a bankrupt pharmacist from Haarlem who was fleeing the Netherlands, in fear of arrest because of his heretical beliefs associated with the painter Johannes van der Beeck, also known as Torrentius.
During the voyage, Jacobsz and Cornelisz conceived a plan to take the ship, which would allow them to start a new life somewhere, using the huge supply of trade gold and silver then on board. After leaving Cape Town, where they had stopped for supplies, Jacobsz deliberately steered the ship off course, away from the rest of the fleet. Jacobsz and Cornelisz had already gathered a small group of men around them and arranged an incident from which the mutiny was to ensue. This involved molesting a high-ranking young female passenger, Lucretia Jans, in order to provoke Pelsaert into disciplining the crew. They hoped to paint his discipline as unfair and recruit more members out of sympathy. However, the woman was able to identify her attackers. The mutineers were then forced to wait until Pelsaert made arrests, but he never acted, as he was suffering from an unknown illness.
Shipwreck.
On 4 June 1629 the ship struck Morning Reef near Beacon Island (), part of the Houtman Abrolhos off the Western Australian coast. Of the 322 aboard, most of the passengers and crew managed to get ashore, although 40 people drowned. The survivors, including all the women and children, were then transferred to nearby islands in the ship's longboat and yawl. An initial survey of the islands found no fresh water and only limited food (sea lions and birds). Pelsaert realised the dire situation and decided to search for water on the mainland.
A group comprising Captain Jacobsz, Francisco Pelsaert, senior officers, a few crewmembers, and some passengers left the wreck site in a 30-foot (9.1 m) longboat (a replica of which has also been made), in search of drinking water. After an unsuccessful search for water on the mainland, they abandoned the other survivors and headed north in a danger-fraught voyage to the city of Batavia, now known as Jakarta. This journey, which ranks as one of the greatest feats of navigation in open boats, took 33 days and, extraordinarily, all aboard survived.
After their arrival in Batavia, the boatswain, a man named Jan Evertsz, was arrested and executed for negligence and "outrageous behaviour" before the loss of the ship (he was suspected to have been involved). Jacobsz was also arrested for negligence, although his position in the potential mutiny was not guessed by Pelsaert.
Batavia's Governor General, Jan Coen, immediately gave Pelsaert command of the "Sardam" to rescue the other survivors, as well as to attempt to salvage riches from the "Batavia"'s wreck. He arrived at the islands two months after leaving Batavia, only to discover that a bloody mutiny had taken place amongst the survivors, reducing their numbers by at least a hundred.
Murders.
Jeronimus Cornelisz, who had been left in charge of the survivors, was well aware that if that party ever reached the port of Batavia, Pelsaert would report the impending mutiny, and his position in the planned mutiny might become apparent. Therefore, he made plans to hijack any rescue ship that might return and use the vessel to seek another safe haven. Cornelisz even made far-fetched plans to start a new kingdom, using the gold and silver from the wrecked "Batavia". However, to carry out this plan, he first needed to eliminate possible opponents.
Cornelisz's first deliberate act was to have all weapons and food supplies commandeered and placed under his control. He then moved a group of soldiers, led by Wiebbe Hayes, to nearby West Wallabi Island, under the false pretence of searching for water. They were told to light signal fires when they found water and they would then be rescued. Convinced that they would be unsuccessful, he then left them there to die.
Cornelisz then had complete control. The remaining survivors would face two months of unrelenting butchery and savagery.
"With a dedicated band of murderous young men, Cornelisz began to systematically kill anyone he believed would be a problem to his reign of terror, or a burden on their limited resources. The mutineers became intoxicated with killing, and no one could stop them. They needed only the smallest of excuses to drown, bash, strangle or stab to death any of their victims, including women and children."
Cornelisz never committed any of the murders himself, although he tried and failed to poison a baby (who was eventually strangled). Instead, he used his powers of persuasion to coerce others into doing it for him, firstly under the pretence that the victim had committed a crime such as theft. Eventually, the mutineers began to kill for pleasure, or simply because they were bored. He planned to reduce the island's population to around 45 so that their supplies would last as long as possible. In total, his followers murdered at least 110 men, women, and children.
Rescue.
Although Cornelisz had left the soldiers, led by Wiebbe Hayes, to die, they had in fact found good sources of water and food on their islands. Initially, they were unaware of the barbarity taking place on the other islands and sent pre-arranged smoke signals announcing their finds. However, they soon learned of the massacres from survivors fleeing Cornelisz' island. In response, the soldiers devised makeshift weapons from materials washed up from the wreck. They also set a watch so that they were ready for the mutineers, and built a small fort out of limestone and coral blocks.
Cornelisz seized on the news of water on the other island, as his own supply was dwindling and the continued survival of the soldiers threatened his own success. He went with his men to try to defeat the soldiers marooned on West Wallabi Island. However, the trained soldiers were by now much better fed than the mutineers and easily defeated them in several battles, eventually taking Cornelisz hostage. The mutineers who escaped regrouped under a man named Wouter Loos and tried again, this time employing muskets to besiege Hayes' fort and almost defeated the soldiers.
But Wiebbe Hayes' men prevailed again, just as Pelsaert arrived. A race to the rescue ship ensued between Cornelisz's men and the soldiers. Wiebbe Hayes reached the ship first and was able to present his side of the story to Pelsaert. After a short battle, the combined force captured all of the mutineers.
Aftermath.
Pelsaert decided to conduct a trial on the islands, because the "Saardam" on the return voyage to Batavia would have been overcrowded with survivors and prisoners. After a brief trial, the worst offenders were taken to Seal Island and executed. Cornelisz and several of the major mutineers had both hands chopped off before being hanged. Wouter Loos and a cabin boy, considered only minor offenders, were marooned on mainland Australia, never to be heard of again. Reports of unusually light-skinned Aborigines in the area by later British settlers have been suggested as evidence that the two men might have been adopted into a local Aboriginal clan. Some amongst the Amangu people of the mainland have a blood group specific to Leyden, in Holland. However, numerous other European shipwreck survivors, such as those from the wreck of the "Zuytdorp" in the same region in 1712, may also have had such contact with indigenous inhabitants.
The remaining mutineers were taken to Batavia for trial. Five were hanged, while several others were flogged. Cornelisz's second in command, Jacop Pietersz, was broken on the wheel, the most severe punishment available at the time.
Captain Jacobsz, despite being tortured, did not confess to his part in planning the mutiny and escaped execution due to lack of evidence. What finally became of him is unknown. It is suspected that he died in prison in Batavia.
A board of inquiry decided that Pelsaert had exercised a lack of authority and was therefore partly responsible for what had happened. His financial assets were seized, and he died a broken man within a year.
On the other hand, the common soldier Wiebbe Hayes was hailed as a hero. The Dutch East India Company promoted him to sergeant, and later to lieutenant, which increased his salary fivefold.
Of the original 341 people on board the "Batavia", only 68 made it to the port of Batavia.
Wreckage, discovery and recovery.
During Admiralty surveys of the Abrolhos Islands on the north-west coast in April 1840, Captain Stokes of HMS "Beagle" reported that:
"On the south west point of an island the beams of a large vessel were discovered, and as the crew of the "Zeewyk", lost in 1728, reported having seen a wreck of a ship on this part, there is little doubt that the remains were those of the "Batavia", Commodore Pelsart, lost in 1629. We in consequence named our temporary anchorage Batavia Road, and the whole group Pelsart Group."
However, Stokes appears to have confused the wreck of the "Zeewyk" for that of the "Batavia".. In the 1950s, historian Henrietta Drake-Brockman, who had learnt of the story due to her association with the children of the Abrolhos Islands guano merchant F. C. Broadhurst, son of Charles Edward Broadhurst, argued from extensive archival research and translations by E. D. Drok, that the wreck must lie in the Wallabi Group of islands. Surveyor Bruce Melrose and diving journalist Hugh Edwards agreed with the theory. In association with Drake-Brockman, Edwards organised a number of search expeditions near Beacon Island in the early 1960s and narrowly missed locating the site. After Edwards provided his research to them, and after being led to the place by Abrolhos rock lobster-fisherman Dave Johnson (who had seen an anchor from his boat while setting lobster pots), on 4 June 1963 Max and Graham Cramer with Greg Allen became the first to dive on the site. Its location, together with those of the VOC ship "Vergulde Draeck" (Gilt Dragon) and the English East India Company "Triall" ("Tryal"), in the early 1960s, led to the formation of the Departments of Maritime Archaeology and Materials Conservation and Restoration at the Western Australian Museum.
In the period 1970 through to 1974, under the leadership of maritime archaeologist Jeremy Green of the Western Australian Museum, some of the cannon from the "Batavia" wreck, an anchor, and many artifacts were salvaged, including timbers from the port side of the ship's stern. These were then conserved by the Museum's conservation laboratories under the leadership of Colin Pearson and his successors Neil North and Ian MacLeod. Monitoring and treatment of the timbers is ongoing and is under the leadership of Ian Godfrey and Vicki Richards.
In order to facilitate the monitoring and any future treatment, the hull timbers were erected on a steel frame designed and erected by Geoff Kimpton, a member of Green's staff. The design, and that of a stone arch, or portico, which was also raised from the seabed, is such that individual components can be removed for treatment without affecting those adjacent, or the exhibit as a whole.
In 1972, the Netherlands transferred all rights to Dutch shipwrecks on the Australian coasts to Australia. Some of the items, including human remains, which were excavated, are now on display in the Western Australian Museum – Shipwreck Galleries in Fremantle, Australia. Others are held by the Western Australian Museum, Geraldton. These two museums presently share the remains: a replica stone arch is held in The Western Australian Museum – Shipwreck Galleries, which was intended to serve as a stone welcome arch for the city of Batavia and the actual stone arch is held in the Western Australian Museum, Geraldton; the original timbers from the ship's hull are held at the Western Australian Museum – Shipwreck Galleries. While a great deal of materials have been recovered from the wreck-site, the majority of the cannons and anchors have been left "in-situ". As a result, the wreck remains one of the premier dive sites on the West Australian coast and is part of the museum's wreck trail, or underwater "museum-without-walls" concept.
Replica.
A replica of the "Batavia" was built at the "Bataviawerf" (Batavia shipyard) in Lelystad in the Netherlands. The project lasted from 1985 to 7 April 1995, and was conducted as an employment project for young people under master-shipbuilder Willem Vos. The shipyard is currently reconstructing another 17th century ship. In contrast to the merchant ship "Batavia", Michiel de Ruyters' flagship, the "Zeven Provinciën", is a ship of the line.
The "Batavia" replica was built with traditional materials, such as oak and hemp, and using the tools and methods of the time of the original ship's construction. For the design, good use was made of the remains of the original ship in Fremantle (and of the "Vasa" in Stockholm), as well as historical sources, such as 17th century building descriptions (actual building plans weren't made at the time), and prints and paintings by artists (who, at the time, generally painted fairly true to nature), of similar ships.
On 25 September 1999, the new "Batavia" was transported to Australia by barge, and moored at the National Maritime Museum in Sydney. In 2000, "Batavia" was the flagship for the Dutch Olympic Team during the 2000 Olympic Games. During its stay in Australia, the ship was towed to the ocean once, where it sailed on its own. On 12 June 2001, the ship returned to the "Bataviawerf" in Lelystad, where it remains on display to visitors. On the evening of 13 October 2008, a fire ripped through the shipyard. The museum's workshops, rigging loft, block shop, offices, part of a restaurant and the entire hand-sewn suit of sails of the ship were lost to the blaze, however the replica of "De Zeven Provinciën" nearby was undamaged. The moored "Batavia" was never in danger.
Publications and other media.
The following list is selective – the fascination with the wreck of "Batavia" has created an industry – with many other books and articles written, besides the items shown below.

</doc>
<doc id="32525" url="https://en.wikipedia.org/wiki?curid=32525" title="Amsterdam (VOC ship)">
Amsterdam (VOC ship)

The Amsterdam () was an 18th-century cargo ship of the Dutch East India Company (Dutch: "Vereenigde Oost-Indische Compagnie"; "VOC"). The ship started its maiden voyage from Texel to Batavia on 8 January 1749, but was wrecked in a storm on the English Channel on 26 January 1749. The shipwreck was discovered in 1969 in the bay of Bulverhythe, United Kingdom, and is sometimes visible during low tides. The wreck site is protected under the Protection of Wrecks Act since 1974. Some of the findings from the site are in The Shipwreck Museum in Hastings. A replica of the ship is on display in Amsterdam.
Ship.
The "Amsterdam" was an East Indiaman or "Transom return ship" () built for transport between the Dutch Republic and the settlements and strongholds of the Dutch East India Company in the East Indies. On an outward voyage these ships carried guns and bricks for the settlements and strongholds, and silver and golden coins to purchase Asian goods. On a return journey the ships carried the goods that were purchased, such as spices, fabrics, and china. In both directions the ships carried victuals, clothes, and tools for the sailors and soldiers on the ship. On an outward voyage of eight months, the ships were populated by around 240 men, and on a return journey by around 70.
The "Amsterdam" was built in the shipyard for the Amsterdam chamber of the Dutch East India Company in Amsterdam. The ship was made of oak wood.
Maiden voyage.
The maiden voyage of the "Amsterdam" was planned from the Dutch island Texel to the settlement Batavia in the East Indies. The ship, commanded by the 33-year-old captain Willem Klump, had 203 crew, 127 soldiers, and 5 passengers. The "Amsterdam" was laden with textiles, wine, stone ballast, cannon, paper, pens, pipes, domestic goods and 27 chests of silver guilder coins. The whole cargo would be worth several million euros in modern money.
On 15 November 1748 the ship made its first attempt but returned on 19 November 1748 due to an adverse wind. The ship made a second attempt on 21 November 1748, which also failed and from which the ship returned on 6 December 1748. The third attempt was made on 8 January 1749. The "Amsterdam" had problems in the English Channel tacking into a strong westerly storm. For many days she got no further than Beachy Head near Eastbourne. Black Death appeared amongst the crew and a mutiny broke out. Finally the rudder broke off and the ship, helpless in a storm, grounded in the mud and sand of in the bay of Bulverhythe on 26 January 1749, 5 km to the west of Hastings.
She began to sink into the mud, where much of the keel remains today, perfectly preserved. Some of the cargo, including silver coinage, was removed for safekeeping by local authorities. There was some looting and English troops had to be called in to bring the situation to order. The crew were looked after locally before being returned to the Netherlands.
Shipwreck.
In 1969, the "Amsterdam" was discovered after being exposed by a low spring tide. It is the best-preserved VOC ship ever found. Archaeologist Peter Marsden did the first surveying of the wreck, and he advised further excavation. 
The wrecksite was designated under the Protection of Wrecks Act on 5 February 1974.
The VOC Ship Amsterdam Foundation started researching the wreck, followed by major excavations in 1984, 1985 and 1986, during which huge numbers of artifacts were found. Although the wreck is submerged in the sand and mud of the beach (and is even visible at very low tides), much of the excavation was done by divers, for whom a small tower was constructed near the wreck. Additionally the wreck was surrounded by an iron girder frame. The archeological output was so dense that new ways of researching needed to be developed, all of which were needed to understand the technological, socio-economic and cultural features of the VOC. Some of the finds are on show at the Shipwreck Museum in Hastings, East Sussex, UK, with the exception of the anchor, which is now on display as public art at St Katharine Docks in London. The wreck is protected and diving on it or removing timbers or any artefacts is forbidden. The ship may be visited as the timbers are exposed at very low tides in the sand just opposite the footbridge over the railway line at Bulverhythe.
Ship replica.
A replica of the ship was built in Iroko wood by 400 volunteers using tools of the period, between 1985 and 1990 at Lelystad. It was floated to Amsterdam and is moored next to the Netherlands Maritime Museum, where it is open to visitors of the museum (which has now reopened after being closed for several years for renovations). As for the original ship, there had been hopes in the 1980s that the Dutch Government, which still owns it, might excavate the whole wreck and return it for restoration and display in Amsterdam, like the "Regalskeppet Vasa" in Sweden, or the "Mary Rose" in Portsmouth, but the funds were not forthcoming. Several decks and much of the bowsprit lie submerged in the mud and are in remarkably good condition, being naturally preserved by the mud, and much of the cargo is still aboard.
Popular culture.
The comic book "Angst op de "Amsterdam"" of Spike and Suzy is about the "Amsterdam". The book was published in 1985 in The Red Series of Spike and Suzy.
In the miniature park Madurodam in The Hague is a model of the "Amsterdam" on a scale of 1:25.

</doc>
<doc id="32526" url="https://en.wikipedia.org/wiki?curid=32526" title="Vasa">
Vasa

Vasa may refer to:

</doc>
<doc id="32528" url="https://en.wikipedia.org/wiki?curid=32528" title="Visual cortex">
Visual cortex

The visual cortex of the brain is the part of the cerebral cortex responsible for processing visual information. This article addresses the ventral/dorsal model of the visual cortex. Another model for the perceptual/conceptual neuropsychological model of the visual cortex was studied by Raftopolous. In Russian neuropsychology, yet another model was discussed by Alexander Luria for the anterior/posterior approach to understanding the visual cortex. The visual cortex is located in the occipital lobe (one of the four major lobes of the cerebral cortex) which is in turn located at the back of the head or skull. The visual cortex is made up of Brodmann area 17 (the primary visual cortex), and Brodmann areas 18 and 19, the extrastriate cortical areas.
The primary (parts of the cortex that receive sensory inputs from the thalamus) visual cortex is also known as V1, Visual area one, and the striate cortex. The extrastriate areas consist of visual areas two (V2), three (V3), four (V4), and five (V5).
Both hemispheres of a brain contain a visual cortex; the left hemisphere visual cortex receives signals from the right visual field, and the right visual cortex from the left visual field.
Introduction.
This article addresses the ventral/dorsal model of the visual cortex. Another model for the perceptual/conceptual neuropsychological model of the visual cortex was studied by Raftopolous. In Russian neurospychology, yet another model was discussed by Alexander Luria for the anterior/posterior approach to understanding the visual cortex. The primary visual cortex, V1, is the koniocortex (sensory type) located in and around the calcarine fissure in the occipital lobe. Each hemisphere's V1 receives information directly from its ipsilateral lateral geniculate nucleus that receives signals from the contralateral visual hemifield.
Each V1 transmits information to two primary pathways, called the ventral stream and the dorsal stream.
The what vs. where account of the ventral/dorsal pathways was first described by Ungerleider and Mishkin. More recently, Goodale and Milner extended these ideas and suggested that the ventral stream is critical for visual perception whereas the dorsal stream mediates the visual control of skilled actions. Although these ideas are contentious among some vision scientists and psychologists, the proposed division of labor between "vision-for-perception" and "vision-for-action" is supported by a broad range of findings from neuropsychology, neurophysiology, and neuroimaging. Some of the most controversial evidence comes from studies of visuomotor behaviour in normal observers. For example, it has been shown that visual illusions such as the Ebbinghaus illusion distort judgements of a perceptual nature, but when the subject responds with an action, such as grasping, no distortion occurs. Other work such as the one from Scharnowski and Gegenfurtner suggests that both the action and perception systems are equally fooled by such illusions. More recent studies, however, provide strong support for the idea that skilled actions such as grasping are not affected by pictorial illusions and suggest that the action/perception dissociation is a useful way to characterize the functional division of labor between the dorsal and ventral visual pathways in the cerebral cortex.
Neurons in the visual cortex fire action potentials when visual stimuli appear within their receptive field. By definition, the receptive field is the region within the entire visual field that elicits an action potential. But, for any given neuron, it may respond best to a subset of stimuli within its receptive field. This property is called "neuronal tuning". In the earlier visual areas, neurons have simpler tuning. For example, a neuron in V1 may fire to any vertical stimulus in its receptive field. In the higher visual areas, neurons have complex tuning. For example, in the inferior temporal cortex (IT), a neuron may fire only when a certain face appears in its receptive field.
The visual cortex receives its blood supply primarily from the calcarine branch of the posterior cerebral artery.
Current research.
Research on the primary visual cortex can involve recording action potentials from electrodes within the brain of cats, ferrets, rats, mice, or monkeys, or through recording intrinsic optical signals from animals or EEG, MEG, or fMRI signals from human and monkey V1.
One recent discovery concerning the human V1 is that signals measured by fMRI show very large attentional modulation. This result is consistent with another recent electrophysiology study. The study found that although V1 processes visual information before V2 and V4, the attentional modulation occurs in V4 followed by V2 and then finally in V1 suggesting attentional modulation occurs through feedback from higher-level visual areas to lower-level visual areas. Other current work on V1 seeks to fully characterize its tuning properties, and to use it as a model area for the canonical cortical circuit.
Lesions to primary visual cortex usually lead to a scotoma, or hole in the visual field. Note that patients with scotomas are often able to make use of visual information presented to their scotomas, despite being unable to consciously perceive it. This phenomenon has been partially covered in one aspect of what Larry Weiskrantz of Oxford university called blindsight, and is widely studied by scientists who are also interested in the neural correlates of consciousness.
Primary visual cortex (V1).
The primary visual cortex is the best-studied visual area in the brain. In all mammals studied, it is located in the posterior pole of the occipital cortex (the occipital cortex is responsible for processing visual stimuli). It is the simplest, earliest cortical visual area. It is highly specialized for processing information about static and moving objects and is excellent in pattern recognition.
The functionally defined primary visual cortex is approximately equivalent to the anatomically defined striate cortex. The name "striate cortex" is derived from the line of Gennari, a distinctive stripe visible to the naked eye that represents myelinated axons from the lateral geniculate body terminating in layer 4 of the gray matter.
The primary visual cortex is divided into six functionally distinct layers, labeled 1 through 6. Layer 4, which receives most visual input from the lateral geniculate nucleus (LGN), is further divided into 4 layers, labelled 4A, 4B, 4Cα, and 4Cβ. Sublamina 4Cα receives most magnocellular input from the LGN, while layer 4Cβ receives input from parvocellular pathways.
The occipital cortex where the visual cortex resides is the smallest of the four cortexes of the human brain, which also includes the temporal cortex, parietal cortex, and frontal cortex. The average number of neurons in the adult human primary visual cortex, in each hemisphere, has been estimated at around 140 million.
Function.
V1 has a very well-defined map of the spatial information in vision. For example, in humans, the upper bank of the calcarine sulcus responds strongly to the lower half of visual field (below the center), and the lower bank of the calcarine to the upper half of visual field. In concept, this retinotopic mapping is a transformation of the visual image from retina to V1. The correspondence between a given location in V1 and in the subjective visual field is very precise: even the blind spots are mapped into V1. In terms of evolution, this correspondence is very basic and found in most animals that possess a V1. In human and animals with a fovea in the retina, a large portion of V1 is mapped to the small, central portion of visual field, a phenomenon known as cortical magnification. Perhaps for the purpose of accurate spatial encoding, neurons in V1 have the smallest receptive field size of any visual cortex microscopic regions.
The tuning properties of V1 neurons (what the neurons respond to) differ greatly over time. Early in time (40 ms and further) individual V1 neurons have strong tuning to a small set of stimuli. That is, the neuronal responses can discriminate small changes in visual orientations, spatial frequencies and colors. Furthermore, individual V1 neurons in human and animals with binocular vision have ocular dominance, namely tuning to one of the two eyes. In V1, and primary sensory cortex in general, neurons with similar tuning properties tend to cluster together as cortical columns. David Hubel and Torsten Wiesel proposed the classic ice-cube organization model of cortical columns for two tuning properties: ocular dominance and orientation. However, this model cannot accommodate the color, spatial frequency and many other features to which neurons are tuned . The exact organization of all these cortical columns within V1 remains a hot topic of current research. The mathematical modeling of this function has been compared to Gabor transforms.
Later in time (after 100 ms), neurons in V1 are also sensitive to the more global organisation of the scene (Lamme & Roelfsema, 2000). These response properties probably stem from recurrent feedback processing (the influence of higher-tier cortical areas on lower-tier cortical areas) and lateral connections from pyramidal neurons (Hupe et al. 1998). While feedforward connections are mainly driving, feedback connections are mostly modulatory in their effects (Angelucci et al., 2003; Hupe et al., 2001). Evidence shows that feedback originating in higher-level areas such as V4, IT, or MT, with bigger and more complex receptive fields, can modify and shape V1 responses, accounting for contextual or extra-classical receptive field effects (Guo et al., 2007; Huang et al., 2007; Sillito et al., 2006).
The visual information relayed to V1 is not coded in terms of spatial (or optical) imagery but rather are better described as edge detection. As an example, for an image comprising half side black and half side white, the divide line between black and white has strongest local contrast (that is, edge detection) and is encoded, while few neurons code the brightness information (black or white per se). As information is further relayed to subsequent visual areas, it is coded as increasingly non-local frequency/phase signals. Note that, at these early stages of cortical visual processing, spatial location of visual information is well preserved amid the local contrast encoding (edge detection).
V2.
Visual area V2, or secondary visual cortex, also called prestriate cortex, is the second major area in the visual cortex, and the first region within the visual association area. It receives strong feedforward connections from V1 (direct and via the pulvinar) and sends strong connections to V3, V4, and V5. It also sends strong feedback connections to V1.
In terms of anatomy, V2 is split into four quadrants, a dorsal and ventral representation in the left and the right hemispheres. Together, these four regions provide a complete map of the visual world. V2 has many properties in common with V1: Cells are tuned to simple properties such as orientation, spatial frequency, and color. The responses of many V2 neurons are also modulated by more complex properties, such as the orientation of illusory contours, binocular disparity, and whether the stimulus is part of the figure or the ground (Qiu and von der Heydt, 2005). Recent research has shown that V2 cells show a small amount of attentional modulation (more than V1, less than V4), are tuned for moderately complex patterns, and may be driven by multiple orientations at different subregions within a single receptive field.
It is argued that the entire ventral visual-to-hippocampal stream is important for visual memory. This theory, unlike the dominant one, predicts that object-recognition memory (ORM) alterations could result from the manipulation in V2, an area that is highly interconnected within the ventral stream of visual cortices. In the monkey brain, this area receives strong feedforward connections from the primary visual cortex (V1) and sends strong projections to other secondary visual cortices (V3, V4, and V5). Most of the neurons of this area are tuned to simple visual characteristics such as orientation, spatial frequency, size, color, and shape. V2 cells also respond to various complex shape characteristics, such as the orientation of illusory contours and whether the stimulus is part of the figure or the ground. Anatomical studies implicate layer 3 of area V2 in visual-information processing. In contrast to layer 3, layer 6 of the visual cortex is composed of many types of neurons, and their response to visual stimuli is more complex.
In a recent study, the Layer 6 cells of the V2 cortex were found to play a very important role in the storage of Object Recognition Memory as well as the conversion of short-term object memories into long-term memories.
Third visual complex, including area V3.
The term third visual complex refers to the region of cortex located immediately in front of V2, which includes the region named visual area V3 in humans. The "complex" nomenclature is justified by the fact that some controversy still exists regarding the exact extent of area V3, with some researchers proposing that the cortex located in front of V2 may include two or three functional subdivisions. For example, David Van Essen and others (1986) have proposed the existence of a "dorsal V3" in the upper part of the cerebral hemisphere, which is distinct from the "ventral V3" (or ventral posterior area, VP) located in the lower part of the brain. Dorsal and ventral V3 have distinct connections with other parts of the brain, appear different in sections stained with a variety of methods, and contain neurons that respond to different combinations of visual stimulus (for example, colour-selective neurons are more common in the ventral V3). Additional subdivisions, including V3A and V3B have also been reported in humans. These subdivisions are located near dorsal V3, but do not adjoin V2.
Dorsal V3 is normally considered to be part of the dorsal stream, receiving inputs from V2 and from the primary visual area and projecting to the posterior parietal cortex. It may be anatomically located in Brodmann area 19. Braddick using fMRI has suggested that area V3/V3A may play a role in the processing of global motion Other studies prefer to consider dorsal V3 as part of a larger area, named the dorsomedial area (DM), which contains a representation of the entire visual field. Neurons in area DM respond to coherent motion of large patterns covering extensive portions of the visual field (Lui and collaborators, 2006).
Ventral V3 (VP), has much weaker connections from the primary visual area, and stronger connections with the inferior temporal cortex. While earlier studies proposed that VP contained a representation of only the upper part of the visual field (above the point of fixation), more recent work indicates that this area is more extensive than previously appreciated, and like other visual areas it may contain a complete visual representation. The revised, more extensive VP is referred to as the ventrolateral posterior area (VLP) by Rosa and Tweedale.
V4.
Visual area V4 is one of the visual areas in the extrastriate visual cortex. In macaques, it is located anterior to V2 and posterior to posterior inferotemporal area (PIT). It comprises at least four regions (left and right V4d, left and right V4v), and some groups report that it contains rostral and caudal subdivisions as well. It is unknown what the human homologue of V4 is, and this issue is currently the subject of much scrutiny.
V4 is the third cortical area in the ventral stream, receiving strong feedforward input from V2 and sending strong connections to the PIT. It also receives direct inputs from V1, especially for central space. In addition, it has weaker connections to V5 and dorsal prelunate gyrus (DP).
V4 is the first area in the ventral stream to show strong attentional modulation. Most studies indicate that selective attention can change firing rates in V4 by about 20%. A seminal paper by Moran and Desimone characterizing these effects was the first paper to find attention effects anywhere in the visual cortex.
Like V2, V4 is tuned for orientation, spatial frequency, and color. Unlike V2, V4 is tuned for object features of intermediate complexity, like simple geometric shapes, although no one has developed a full parametric description of the tuning space for V4. Visual area V4 is not tuned for complex objects such as faces, as areas in the inferotemporal cortex are.
The firing properties of V4 were first described by Semir Zeki in the late 1970s, who also named the area. Before that, V4 was known by its anatomical description, the prelunate gyrus. Originally, Zeki argued that the purpose of V4 was to process color information. Work in the early 1980s proved that V4 was as directly involved in form recognition as earlier cortical areas. This research supported the Two Streams hypothesis, first presented by Ungerleider and Mishkin in 1982.
Recent work has shown that V4 exhibits long-term plasticity, encodes stimulus salience, is gated by signals coming from the frontal eye fields and shows changes in the spatial profile of its receptive fields with attention.
V5/MT.
Visual area V5, also known as visual area MT (middle temporal), is a region of extrastriate visual cortex that is thought to play a major role in the perception of motion, the integration of local motion signals into global percepts, and the guidance of some eye movements.
Connections.
MT is connected to a wide array of cortical and subcortical brain areas. Its inputs include the visual cortical areas V1, V2, and dorsal V3 (dorsomedial area), the koniocellular regions of the LGN, and the inferior pulvinar. The pattern of projections to MT changes somewhat between the representations of the foveal and peripheral visual fields, with the latter receiving inputs from areas located in the midline cortex and retrosplenial region.
A standard view is that V1 provides the "most important" input to MT. Nonetheless, several studies have demonstrated that neurons in MT are capable of responding to visual information, often in a direction-selective manner, even after V1 has been destroyed or inactivated. Moreover, research by Semir Zeki and collaborators has suggested that certain types of visual information may reach MT before it even reaches V1.
MT sends its major outputs to areas located in the cortex immediately surrounding it, including areas FST, MST, and V4t (middle temporal crescent). Other projections of MT target the eye movement-related areas of the frontal and parietal lobes (frontal eye field and lateral intraparietal area).
Function.
The first studies of the electrophysiological properties of neurons in MT showed that a large portion of the cells are tuned to the speed and direction of moving visual stimuli These results suggested that MT plays a significant role in the processing of visual motion.
Lesion studies have also supported the role of MT in motion perception and eye movements. Neuropsychological studies of a patient unable to see motion, seeing the world in a series of static "frames" instead, suggested that V5 in the primate is homologous to MT in the human.
However, since neurons in V1 are also tuned to the direction and speed of motion, these early results left open the question of precisely what MT could do that V1 could not. Much work has been carried out on this region, as it appears to integrate local visual motion signals into the global motion of complex objects.
For example, "lesion" to the V5 leads to deficits in perceiving motion and processing of complex stimuli. It contains many neurons selective for the motion of complex visual features (line ends, corners). "Microstimulation" of a neuron located in the V5 affects the perception of motion. For example, if one finds a neuron with preference for upward motion in a monkey's V5 and stimulates it with an electrode, then the monkey becomes more likely to report 'upward' motion when presented with stimuli containing 'left' and 'right' as well as 'upward' components.
There is still much controversy over the exact form of the computations carried out in area MT and some research suggests that feature motion is in fact already available at lower levels of the visual system such as V1.
Functional organization.
MT was shown to be organized in direction columns. DeAngelis argued that MT neurons were also organized based on their tuning for binocular disparity.
V6.
The dorsomedial area (DM) also known as V6, appears to respond to visual stimuli associated with self-motion and wide-field stimulation. V6, is a subdivision of the visual cortex of primates first described by John Allman and Jon Kaas in 1975. V6 is located in the dorsal part of the extrastriate cortex, near the deep groove through the centre of the brain (medial longitudinal fissure), and typically also includes portions of the medial cortex, such as the parieto-occipital sulcus. DM contains a topographically organized representation of the entire field of vision. Like the middle temporal area V5, DM receives direct connections from the primary visual cortex. Also similar to V5, DM is also characterized by high myelin content, a characteristic that is usually present in brain structures involved in fast transmission of information.
For many years, it was considered that DM only existed in New World monkeys. However, more recent research has suggested that DM also exists in Old World monkeys and perhaps humans. V6 is also sometimes referred to as the parietooccipital area (PO), although the correspondence is not exact.
Properties.
Neurons in area DM/V6 have unique response properties, including an extremely sharp selectivity for the orientation of visual contours, and preference for long, uninterrupted lines covering large parts of the visual field. However, in comparison with area MT, a much smaller proportion of DM cells shows selectivity for the direction of motion of visual patterns. Another notable difference is that cells in DM are attuned to low spatial frequency components of an image, and respond poorly to the motion of textured patterns such as a field of random dots. In contrast, cells in MT are often strongly responsive to such stimuli. These response properties suggest that DM and MT may work in parallel, with the former analyzing self-motion relative to the environment, and the latter analyzing the motion of individual objects relative to the background.
Recently, an area responsive to wide-angle flow fields has been identified in the human and is thought to be a homologue of macaque area V6.
Pathways.
The connections and response properties of cells in DM/ V6 suggest that this area is a key node in a sub-set of the "dorsal stream", referred to by some as the "dorsomedial pathway". This pathway is likely to be important for the control of skeletomotor activity, including postural reactions and reaching movements towards objects The main "feedforward" connection of DM is to the cortex immediately rostral to it, in the interface between the occipital and parietal lobes (V6A). This region has, in turn, relatively direct connections with the regions of the frontal lobe that control arm movements, including the premotor cortex.

</doc>
<doc id="32529" url="https://en.wikipedia.org/wiki?curid=32529" title="Velociraptor">
Velociraptor

Velociraptor (; meaning "swift seizer" in Latin) is a genus of dromaeosaurid theropod dinosaur that lived approximately 75 to 71 million years ago during the later part of the Cretaceous Period. Two species are currently recognized, although others have been assigned in the past. The type species is "V. mongoliensis"; fossils of this species have been discovered in Mongolia. A second species, "V. osmolskae", was named in 2008 for skull material from Inner Mongolia, China.
Smaller than other dromaeosaurids like "Deinonychus" and "Achillobator", "Velociraptor" nevertheless shared many of the same anatomical features. It was a bipedal, feathered carnivore with a long tail and an enlarged sickle-shaped claw on each hindfoot, which is thought to have been used to tackle prey. "Velociraptor" can be distinguished from other dromaeosaurids by its long and low skull, with an upturned snout.
"Velociraptor" (commonly shortened to "raptor") is one of the dinosaur genera most familiar to the general public due to its prominent role in the "Jurassic Park" motion picture series. Today, "Velociraptor" is well known to paleontologists, with over a dozen described fossil skeletons, the most of any dromaeosaurid. One particularly famous specimen preserves a "Velociraptor" locked in combat with a "Protoceratops".
Description.
"Velociraptor" was a mid-sized dromaeosaurid, with adults measuring up to long, high at the hip, and weighing up to . The skull, which grew up to long, was uniquely up-curved, concave on the upper surface and convex on the lower. The jaws were lined with 26–28 widely spaced teeth on each side, each more strongly serrated on the back edge than the front.
"Velociraptor", like other dromaeosaurids, had a large manus ('hand') with three strongly curved claws, which were similar in construction and flexibility to the wing bones of modern birds. The second digit was the longest of the three digits present, while the first was shortest. The structure of the carpal (wrist) bones prevented pronation of the wrist and forced the 'hands' to be held with the palmar surface facing inwards (medially), not downwards. The first digit of the foot, as in other theropods, was a small dewclaw. However, whereas most theropods had feet with three digits contacting the ground, dromaeosaurids like "Velociraptor" walked on only their third and fourth digits. The second digit, for which "Velociraptor" is most famous, was highly modified and held retracted off the ground. It bore a relatively large, sickle-shaped claw, typical of dromaeosaurid and troodontid dinosaurs. This enlarged claw, which could grow to over long around its outer edge, was most likely a predatory device used to tear into or restrain struggling prey.
As in other dromaeosaurs, "Velociraptor" tails had long bony projections (prezygapophyses) on the upper surfaces of the vertebrae, as well as ossified tendons underneath. The prezygapophyses began on the tenth tail (caudal) vertebra and extended forward to brace four to ten additional vertebrae, depending on position in the tail. These were once thought to fully stiffen the tail, forcing the entire tail to act as a single rod-like unit. However, at least one specimen has preserved a series of intact tail vertebrae curved sideways into an "S"-shape, suggesting that there was considerably more horizontal flexibility than once thought.
In 2007, paleontologists reported the discovery of quill knobs on a well-preserved "Velociraptor mongoliensis" forearm from Mongolia, confirming the presence of feathers in this species.
Feathers.
Fossils of dromaeosaurids more primitive than "Velociraptor" are known to have had feathers covering their bodies and fully developed feathered wings. The fact that the ancestors of "Velociraptor" were feathered and possibly capable of flight had long suggested to paleontologists that "Velociraptor" bore feathers as well, since even flightless birds today retain most of their feathers. In September 2007, researchers found quill knobs on the forearm of a "Velociraptor" found in Mongolia. These bumps on bird wing bones show where feathers anchor, and their presence on "Velociraptor" indicate it too had feathers. According to paleontologist Alan Turner,
Co-author Mark Norell, Curator-in-Charge of fossil reptiles, amphibians and birds at the American Museum of Natural History, also weighed in on the discovery, saying:
According to Turner and co-authors Norell and Peter Makovicky, quill knobs are not found in all prehistoric birds, and their absence does not mean that an animal was not feathered – flamingos, for example, have no quill knobs. However, their presence confirms that "Velociraptor" bore modern-style wing feathers, with a rachis and vane formed by barbs. The forearm specimen on which the quill knobs were found (specimen number IGM 100/981) represents an animal 1.5 meters in length (5 ft) and 15 kilograms (33 lbs) in weight. Based on the spacing of the six preserved knobs in this specimen, the authors suggested that "Velociraptor" bore 14 secondaries (wing feathers stemming from the forearm), compared with 12 or more in "Archaeopteryx", 18 in "Microraptor", and 10 in "Rahonavis". This type of variation in the number of wing feathers between closely related species, the authors asserted, is to be expected, given similar variation among modern birds.
Turner and colleagues interpreted the presence of feathers on "Velociraptor" as evidence against the idea that the larger, flightless maniraptorans lost their feathers secondarily due to larger body size. Furthermore, they noted that quill knobs are almost never found in flightless bird species today, and that their presence in "Velociraptor" (presumed to have been flightless due to its relatively large size and short forelimbs) is evidence that the ancestors of dromaeosaurids could fly, making "Velociraptor" and other large members of this family secondarily flightless, though it is possible the large wing feathers inferred in the ancestors of "Velociraptor" had a purpose other than flight. The feathers of the flightless "Velociraptor" may have been used for display, for covering their nests while brooding, or for added speed and thrust when running up inclined slopes.
History of discovery.
During an American Museum of Natural History expedition to the Outer Mongolian Gobi Desert, on 11 August 1923 Peter Kaisen recovered the first "Velociraptor" fossil known to science: a crushed but complete skull, associated with one of the raptorial second toe claws (AMNH 6515). In 1924, museum president Henry Fairfield Osborn designated the skull and claw (which he assumed to come from the hand) as the type specimen of his new genus, "Velociraptor". This name is derived from the Latin words "velox" ('swift') and "raptor" ('robber' or 'plunderer') and refers to the animal's cursorial nature and carnivorous diet. Osborn named the type species "V. mongoliensis" after its country of origin. Earlier that year, Osborn had mentioned the animal in a popular press article, under the name "Ovoraptor djadochtari" (not to be confused with the similarly named "Oviraptor"). However, because the name "Ovoraptor" was not published in a scientific journal or accompanied by a formal description, it is considered a "nomen nudum" ('naked name'), and the name "Velociraptor" retains priority.
While North American teams were shut out of communist Mongolia during the Cold War, expeditions by Soviet and Polish scientists, in collaboration with Mongolian colleagues, recovered several more specimens of "Velociraptor". The most famous is part of the legendary "Fighting Dinosaurs" specimen (GIN 100/25), discovered by a Polish-Mongolian team in 1971. This fossil preserves a single "Velociraptor" in the midst of battle against a lone "Protoceratops". This specimen is considered a national treasure of Mongolia, although in 2000 it was loaned to the American Museum of Natural History in New York City for a temporary exhibition.
Between 1988 and 1990, a joint Chinese-Canadian team discovered "Velociraptor" remains in northern China. American scientists returned to Mongolia in 1990, and a joint Mongolian-American expedition to the Gobi, led by the American Museum of Natural History and the Mongolian Academy of Sciences, turned up several well-preserved skeletons. One such specimen, IGM 100/980, was nicknamed "Ichabodcraniosaurus" by Norell's team because the fairly complete specimen was found without its skull (an allusion to the Washington Irving character Ichabod Crane). This specimen may belong to "Velociraptor mongoliensis", but Norell and Makovicky concluded that it was not complete enough to say for sure, and it awaits a formal description.
Maxillae and a lacrimal (the main tooth-bearing bones of the upper jaw, and the bone that forms the anterior margin of the eye socket, respectively) recovered in 1999 by the Sino-Belgian Dinosaur Expeditions were found to pertain to "Velociraptor", but not to the type species "V. mongoliensis". Pascal Godefroit and colleagues named these bones "V. osmolskae" (for Polish paleontologist Halszka Osmólska) in 2008.
Classification.
"Velociraptor" is a member of the group Eudromaeosauria, a derived sub-group of the larger family Dromaeosauridae. It is often placed within its own "subfamily", Velociraptorinae. In phylogenetic taxonomy, Velociraptorinae is usually defined as "all dromaeosaurs more closely related to "Velociraptor" than to "Dromaeosaurus"." However, dromaeosaurid classification is highly variable. Originally, the subfamily Velociraptorinae was erected solely to contain "Velociraptor". Other analyses have often included other genera, usually "Deinonychus" and "Saurornitholestes", and more recently "Tsaagan". However, several studies published during the 2010s, including expanded versions of the analyses that found support for Velociraptorinae, have failed to resolve it as a distinct group, but rather have suggested it is a paraphyletic grade which gave rise to the Dromaeosaurinae.
In the past, other dromaeosaurid species, including "Deinonychus antirrhopus" and "Saurornitholestes langstoni", have sometimes been classified in the genus "Velociraptor". Since "Velociraptor" was the first to be named, these species were renamed "Velociraptor antirrhopus" and "V. langstoni". However, the only currently recognized species of "Velociraptor" are "V. mongoliensis" and "V. osmolskae".
When first described in 1924, "Velociraptor" was placed in the family Megalosauridae, as was the case with most carnivorous dinosaurs at the time (Megalosauridae, like "Megalosaurus", functioned as a sort of 'wastebin' taxon, where many unrelated species were grouped together). As dinosaur discoveries multiplied, "Velociraptor" was later recognized as a dromaeosaurid. All dromaeosaurids have also been referred to the family Archaeopterygidae by at least one author (which would, in effect, make "Velociraptor" a flightless bird).
The cladogram below follows a 2015 analysis by paleontologists Robert DePalma, David Burnham, Larry Martin, Peter Larson, and Robert Bakker, using updated data from the Theropod Working Group.
Paleobiology.
Predatory behavior.
The "Fighting Dinosaurs" specimen, found in 1971, preserves a "Velociraptor mongoliensis" and "Protoceratops andrewsi" in combat and provides direct evidence of predatory behavior. When originally reported, it was hypothesized that the two animals drowned. However, as the animals were preserved in ancient sand dune deposits, it is now thought that the animals were buried in sand, either from a collapsing dune or in a sandstorm. Burial must have been extremely fast, judging from the lifelike poses in which the animals were preserved. Parts of the "Protoceratops" are missing, which has been seen as evidence of scavenging by other animals. Comparisons between the scleral rings of "Velociraptor", "Protoceratops", and modern birds and reptiles indicates that "Velociraptor" may have been nocturnal, while "Protoceratops" may have been cathemeral, active throughout the day during short intervals, suggesting that the fight may have occurred at twilight or during low-light conditions.
The distinctive claw, on the second digit of dromaeosaurids, has traditionally been depicted as a slashing weapon; its assumed use being to cut and disembowel prey. In the "Fighting Dinosaurs" specimen, the "Velociraptor" lies underneath, with one of its sickle claws apparently embedded in the throat of its prey, while the beak of "Protoceratops" is clamped down upon the right forelimb of its attacker. This suggests "Velociraptor" may have used its sickle claw to pierce vital organs of the throat, such as the jugular vein, carotid artery, or trachea (windpipe), rather than slashing the abdomen. The inside edge of the claw was rounded and not unusually sharp, which may have precluded any sort of cutting or slashing action, although only the bony core of the claw is known. The thick abdominal wall of skin and muscle of large prey species would have been difficult to slash without a specialized cutting surface. The slashing hypothesis was tested during a 2005 BBC documentary, "The Truth About Killer Dinosaurs". The producers of the program created an artificial "Velociraptor" leg with a sickle claw and used a pork belly to simulate the dinosaur's prey. Though the sickle claw did penetrate the abdominal wall, it was unable to tear it open, indicating that the claw was not used to disembowel prey.
Remains of "Deinonychus", a closely related dromaeosaurid, have commonly been found in aggregations of several individuals. "Deinonychus" has also been found in association with a large herbivore, "Tenontosaurus", which has been seen as evidence of cooperative hunting. The only solid evidence for social behavior among dromaeosaurids comes from a Chinese trackway of fossil footprints, which shows six individuals of a large species moving as a group, though no evidence of cooperative hunting was found. Although many isolated fossils of "Velociraptor" have been found in Mongolia, none were closely associated with any other individuals. Therefore, while "Velociraptor" is commonly depicted as a pack hunter, as in "Jurassic Park", there is only limited fossil evidence to support this theory for dromaeosaurids in general, and none specific to "Velociraptor" itself. The pack hunting theory was based on a discovery of several specimens of "Deinonychus" found around the remains of a "Tenontosaurus". No other group of dromaeosaurids has been found in close association.
In 2011, Denver Fowler and colleagues suggested a new method by which dromaeosaurs like "Velociraptor" and similar dromaeosaurs may have captured and restrained prey. This model, known as the "raptor prey restraint" (RPR) model of predation, proposes that dromaeosaurs killed their prey in a manner very similar to extant accipitrid birds of prey: by leaping onto their quarry, pinning it under their body weight, and gripping it tightly with the large, sickle-shaped claws. Like accipitrids, the dromaeosaur would then begin to feed on the animal while still alive, until it eventually died from blood loss and organ failure. This proposal is based primarily on comparisons between the morphology and proportions of the feet and legs of dromaeosaurs to several groups of extant birds of prey with known predatory behaviors. Fowler found that the feet and legs of dromaeosaurs most closely resemble those of eagles and hawks, especially in terms of having an enlarged second claw and a similar range of grasping motion. The short metatarsus and foot strength, however, would have been more similar to that of owls. The RPR method of predation would be consistent with other aspects of "Velociraptor"s anatomy, such as their unusual jaw and arm morphology. The arms, which could exert a lot of force but were likely covered in long feathers, may have been used as flapping stabilizers for balance while atop a struggling prey animal, along with the stiff counterbalancing tail. The jaws, thought by Fowler and colleagues to be comparatively weak, would have been useful for row saw motion bites like the modern day Komodo dragon, which also has a weak bite, to finish of its prey if the kicks weren't powerful enough. These predatory adaptations working together may also have implications for the origin of flapping in paravians.
Scavenging behavior.
In 2010, Hone and colleagues published a paper on their 2008 discovery of shed teeth of what they believed to be a "Velociraptor" near a tooth-marked jaw bone of what they believed to be a "Protoceratops" in the Bayan Mandahu Formation. The authors concluded that the find represented "late-stage carcass consumption by "Velociraptor"" as the predator would have eaten other parts of a freshly killed "Protoceratops" before biting in the jaw area. The evidence was seen as supporting the inference from the "Fighting Dinosaurs" fossil that "Protoceratops" was part of the diet of "Velociraptor". In 2012, Hone and colleagues published a paper that described a "Velociraptor" specimen with a long bone of an azhdarchid pterosaur in its gut. This was interpreted as showing scavenging behaviour.
Metabolism.
"Velociraptor" was warm-blooded to some degree, as it required a significant amount of energy to hunt. Modern animals that possess feathery or furry coats, like "Velociraptor" did, tend to be warm-blooded, since these coverings function as insulation. However, bone growth rates in dromaeosaurids and some early birds suggest a more moderate metabolism, compared with most modern warm-blooded mammals and birds. The kiwi is similar to dromaeosaurids in anatomy, feather type, bone structure and even the narrow anatomy of the nasal passages (usually a key indicator of metabolism). The kiwi is a highly active, if specialized, flightless bird, with a stable body temperature and a fairly low resting metabolic rate, making it a good model for the metabolism of primitive birds and dromaeosaurids.
Pathology.
One "Velociratoptor mongoliensis" skull bears two parallel rows of small punctures that match the spacing and size of "Velociraptor" teeth. Scientists believe that the wound was likely inflicted by another "Velociraptor" during a fight. Further, because the fossil bone shows no sign of healing near the bite wounds, the injury probably killed it. Another specimen, found with the bones of an azhdarchid pterosaur within its stomach cavity, was carrying or recovering from an injury sustained to its ribs. From evidence on the pterosaur bones, which were devoid of pitting or deformations from digestion, the "Velociraptor" died shortly after, possibly from the earlier injury.
Provenance.
All known specimens of "Velociraptor mongoliensis" were discovered in the Djadochta Formation (also spelled Djadokhta), in the Mongolian province of Ömnögovi. Species of "Velociraptor" have also been reported from the slightly younger Barun Goyot Formation of Mongolia, though these are indeterminate and may belong to a related genus instead. These geologic formations are estimated to date back to the Campanian stage (between 83 and 70 million years ago) of the Late Cretaceous Epoch.
"V. mongoliensis" has been found at many of the most famous and prolific Djadochta localities. The type specimen was discovered at the Flaming Cliffs site (also known as Bayn Dzak and Shabarakh Usu), while the "Fighting Dinosaurs" were found at the Tugrig locality (also known as Tugrugeen Shireh). The well-known Barun Goyot localities of Khulsan and Khermeen Tsav have also produced remains which may belong to "Velociraptor" or a related genus. Teeth and partial remains attributed to juvenile "V. mongoliensis" have also been reported from the Bayan Mandahu Formation, a prolific site in Inner Mongolia, China that is contemporaneous with the Djadochta Formation. However, these fossils had not been prepared or studied as of 2008. A partial adult skull from the Bayan Mandahu Formation has been assigned to a distinct species, "Velociraptor osmolskae".
Paleoecology.
All of the fossil sites that have yielded "Velociraptor" remains preserve an arid environment with fields of sand dunes and only intermittent streams, although the younger Barun Goyot environment seems to have been slightly wetter than the older Djadochta. The posture of some complete fossils, as well as the mode of preservation most show within structureless sandstone deposits, may show that a number of specimens were buried alive during sandstorm events common to the three environments.
Many of the same genera were present across these formations, though they varied at the species level. For example, the Djadochta was inhabited by "Velociraptor mongoliensis", "Protoceratops andrewsi", and "Pinacosaurus grangeri", while the Bayan Mandahu was home to "Velociraptor osmolskae", "Protoceratops hellenikorhinus", and "Pinacosaurus mephistocephalus". These differences in species composition may be due a natural barrier separating the two formations, which are relatively close to each other geographically. However, given the lack of any known barrier which would cause the specific faunal compositions found in these areas, it is more likely that those differences indicate a slight time difference.
Other dinosaurs known from the same locality as "V. mongoliensis" include the troodontid "Saurornithoides mongoliensis", the oviraptorid "Oviraptor philoceratops", and the dromaeosaurid "Mahakala omnogovae". "V. osmolskae" lived alongside the ceratopsian species "Magnirostris dodsoni", as well as the oviraptorid "Machairasaurus leptonychus" and the dromaeosaurid "Linheraptor exquisitus".
In popular culture.
"Velociraptor" are well known for their role as vicious and cunning killers thanks to their portrayal in the 1990 novel "Jurassic Park" by Michael Crichton and its 1993 film adaptation, directed by Steven Spielberg. The "raptors" portrayed in "Jurassic Park" were actually modeled after the closely related dromaeosaurid "Deinonychus". Paleontologists in both the novel and film excavate a skeleton in Montana, far from the central Asian range of "Velociraptor" but characteristic of the "Deinonychus" range. A character in Crichton's novel also states that ""Deinonychus" is now considered one of the velociraptors", which suggests that Crichton used the controversial taxonomy proposed by Gregory S. Paul, even though the "raptors" in the novel are at another point referred to as "V. mongoliensis". Crichton met with the discoverer of "Deinonychus", John Ostrom, several times at Yale University to discuss details of the animal's possible range of behaviors and appearance. Crichton at one point apologetically told Ostrom that he had decided to use the name "Velociraptor" in place of "Deinonychus" because the former name was "more dramatic". According to Ostrom, Crichton stated that the "Velociraptor" of the novel was based on "Deinonychus" in almost every detail, and that only the name had been changed. The "Jurassic Park" filmmakers also requested all of Ostrom's published papers on "Deinonychus" during production. They portrayed the animals with the size, proportions, and snout shape of "Deinonychus" rather than "Velociraptor".
Production on "Jurassic Park" began before the discovery of the large dromaeosaurid "Utahraptor" was made public in 1991, but as Jody Duncan wrote about this discovery: "Later, after we had designed and built the Raptor, there was a discovery of a Raptor skeleton in Utah, which they labeled 'super-slasher'. They had uncovered the largest Velociraptor to date - and it measured five-and-a-half-feet tall, just like ours. So we designed it, we built it, and then they discovered it. That still boggles my mind." Spielberg was particularly pleased with the discovery of the "Utahraptor" because of the boost it gave to the velociraptors in his film. Spielberg's name was briefly considered for naming of the new dinosaur. In reality, "Velociraptor", like many other maniraptoran theropods, was covered in feathers. "Jurassic Park" and its sequel "" were released before this discovery, so the creatures in both films are depicted as featherless with scales all over in the manner of modern reptiles. For "Jurassic Park III," the male "Velociraptor" was given quill-like structures along the back of the head and neck. While this was the extent to which CGI effects were able to render feathers at the time, the structures do not resemble the down-like feathers real-life dromaeosaurids bore or the fully developed arm feathers, akin to the wing feathers of modern birds, borne by "Velociraptor".

</doc>
<doc id="32530" url="https://en.wikipedia.org/wiki?curid=32530" title="Visigoths">
Visigoths

The Visigoths (UK: ; US: , ) were the western branches of the nomadic tribes of Germanic peoples referred to collectively as the Goths. These tribes flourished and spread during the late Roman Empire in Late Antiquity, or the Migration Period. The Visigoths emerged from earlier Gothic groups (possibly the Thervingi) who had invaded the Roman Empire beginning in 376 and had defeated the Romans at the Battle of Adrianople in 378. Relations between the Romans and the Visigoths were variable, alternately warring with one another and making treaties when convenient. The Visigoths invaded Italy under Alaric I and sacked Rome in 410. After the Visigoths sacked Rome, they began settling down, first in southern Gaul and eventually in Spain and Portugal, where they founded the Visigothic Kingdom and maintained a presence from the 5th to the 8th centuries AD.
The Visigoths first settled in southern Gaul as "foederati" of the Romans – a relationship established in 418. However, they soon fell out with their Roman hosts (for reasons that are now obscure) and established their own kingdom with its capital at Toulouse. They next extended their authority into Hispania at the expense of the Suebi and Vandals. In 507, however, their rule in Gaul was ended by the Franks under Clovis I, who defeated them in the Battle of Vouillé. After that, the Visigoth kingdom was limited to Hispania, and they never again held territory north of the Pyrenees other than Septimania. A small, elite group of Visigoths came to dominate the governance of that region at the expense of those who had previously ruled there, particularly in the Byzantine province of Spania and the Kingdom of the Suebi.
In or around 589, the Visigoths under Reccared I converted from Arianism to Nicene Christianity, gradually adopting the culture of their Hispano-Roman subjects. Their legal code, the "Visigothic Code" (completed in 654) abolished the longstanding practice of applying different laws for Romans and Visigoths. Once legal distinctions were no longer being made between "Romani" and "Gothi", they became known collectively as "Hispani". In the century that followed, the region was dominated by the Councils of Toledo and the episcopacy. (Little else is known about the Visigoths' history during the 7th century, since records are relatively sparse.) In 711 or 712, a force of invading Arabs and Berbers defeated the Visigoths in the Battle of Guadalete. Their king and many members of their governing elite were killed, and their kingdom rapidly collapsed. Gothic identity survived, however, especially in Marca Hispanica and the Kingdom of Asturias, which had been founded by the Visigothic nobleman Pelagius of Asturias after his victory over the Moors at the Battle of Covadonga.
During their governance of the Kingdom of Hispania, the Visigoths built several churches that survive. They also left many artifacts, which have been discovered in increasing numbers by archaeologists in recent times. The Treasure of Guarrazar of votive crowns and crosses is the most spectacular. They founded the only new cities in western Europe from the fall of the Western half of the Roman Empire until the rise of the Carolingian dynasty. Many Visigothic names are still in use in modern Spanish and Portuguese. Their most notable legacy, however, was the "Visigothic Code", which served, among other things, as the basis for court procedure in most of Christian Iberia until the Late Middle Ages, centuries after the demise of the kingdom.
Nomenclature: Vesi, Ostrogothi, Tervingi, Greuthungi.
Contemporaneous references to the Gothic tribes use the terms "Vesi" (Latin for Visigoths), "Ostrogothi", "Thervingi", and "Greuthungi." Most scholars have concluded that the terms "Vesi" and "Tervingi" were both used to refer to one particular tribe, while the terms "Ostrogothi" and "Greuthungi" were used to refer to another. Herwig Wolfram points out that while primary sources occasionally list all four names (as in, for example, "Gruthungi, Austrogothi, Tervingi, Visi"), whenever they mention two different tribes, they always refer either to "the Vesi and the Ostrogothi" or to "the Tervingi and the Greuthungi", and they never pair them up in any other combination. This conclusion is supported by Jordanes, who identified the Visigoth (Vesi) kings from Alaric I to Alaric II as the heirs of the 4th century Tervingian king Athanaric, and the Ostrogoth kings from Theoderic the Great to Theodahad as the heirs of the Greuthungi king Ermanaric. In addition, the "Notitia Dignitatum" equates the Vesi with the Tervingi in a reference to the years 388–391.
The earliest sources for each of the four names are roughly contemporaneous. The first recorded reference to "the Tervingi" is in a eulogy of the emperor Maximian (285–305), delivered in or shortly after 291 (perhaps at Trier on 20 April 292) and traditionally ascribed to Claudius Mamertinus. It says that the "Tervingi, another division of the Goths" ("Tervingi pars alia Gothorum"), joined with the Taifali to attack the Vandals and Gepidae. (The term "Vandals" may have been a mistaken reference to the "Victohali", since around 360 the historian Eutropius reports that Dacia was currently inhabited by Taifali, Victohali, and Tervingi.) The first recorded reference to "the Greuthungi" is by Ammianus Marcellinus, writing no earlier than 392 and perhaps later than 395, recounting the words of a Tervingian chieftain who is attested as early as 376. The first known use of the term "Ostrogoths" is in a document dated September 392 from Milan. (Claudian mentions that they, together with the "Gruthungi", inhabit Phrygia.)
Wolfram notes that "Vesi" and "Ostrogothi" were terms each tribe used to boastfully describe itself and argues that "Tervingi" and "Greuthungi" were geographical identifiers each tribe used to describe the other. This would explain why the latter terms dropped out of use shortly after 400, when the Goths were displaced by the Hunnic invasions. As an example of this geographical naming practice, Wolfram cites an account by Zosimus of a group of people living north of the Danube who called themselves "the Scythians" but were called "the Greutungi" by members of a different tribe living north of the Ister. Wolfram believes that the people Zosimus describes were those Tervingi who had remained behind after the Hunnic conquest. For the most part, all of the terms discriminating between different Gothic tribes gradually disappeared after they moved into the Roman Empire. The last indication that the Goths whose king reigned at Toulouse thought of themselves as "Vesi" is found in a panegyric on Avitus by Sidonius Apollinaris dated 1 January 456.
Most recent scholars (notably Peter Heather) have concluded that Visigothic group identity emerged only within the Roman Empire. Roger Collins believes that the Visigothic identity emerged from the Gothic War of 376–382 when a collection of Tervingi, Greuthungi, and other "barbarian" contingents banded together in multiethnic "foederati" (Wolfram's "federate armies") under Alaric I in the eastern Balkans, since they had become a multiethnic group and could no longer claim to be exclusively Tervingian.
The term "Visigoth" was an invention of the 6th century. Cassiodorus, a Roman in the service of Theoderic the Great, invented the term "Visigothi" to match that of "Ostrogothi", terms he thought of as signifying "western Goths" and "eastern Goths" respectively. The western–eastern division was a simplification (and a literary device) of 6th century historians; political realities were more complex. Further, Cassiodorus used the term "Goths" to refer only to the Ostrogoths, whom he served, and reserved the geographical term "Visigoths" for the Gallo-Spanish Goths. This usage, however, was adopted by the Visigoths themselves in their communications with the Byzantine Empire and was still in use in the 7th century.
Other names for other Gothic divisions abounded. A "Germanic" Byzantine or Italian author referred to one of the two peoples as the "Valagothi", meaning "Roman Goths", and in 469 the Visigoths were called the "Alaric Goths".
Etymology of Tervingi and Vesi/Visigothi.
The name "Tervingi" may mean "forest people". This is supported by evidence that geographic descriptors were commonly used to distinguish people living north of the Black Sea both before and after Gothic settlement there, by evidence of forest-related names among the Tervingi, and by the lack of evidence for an earlier date for the name pair Tervingi–Greuthungi than the late 3rd century. That the name "Tervingi" has pre-Pontic, possibly Scandinavian, origins still has support today.
The Visigoths are called "Wesi" or "Wisi" by Trebellius Pollio, Claudian, and Sidonius Apollinaris. The word is Gothic for "good", implying the "good or worthy people", related to Gothic "iusiza" "better" and a reflex of Indo-European *"wesu" "good", akin to Welsh "gwiw" "excellent", Greek "eus" "good", Sanskrit "vásu-ş" "id.". Jordanes relates the tribe's name to a river, though this is most likely a folk etymology or legend like his similar story about the Greuthung name. The name "Visigothi" is an invention of Cassiodorus, who combined "Visi" and "Gothi" under the misapprehension that it meant "west Goths".
History.
Early origins.
The Visigoths emerged from the Gothic tribes, most likely a derivative name for the Gutones, a people believed to have their origins in Scandinavia and who migrated southeastwards into eastern Europe. Such understanding of their origins is largely the result of Gothic traditions and their true genesis as a people is as equally obscure as those of the Franks and Alamanni. The Visigoths spoke an eastern Germanic language which by the 4th century AD was distinct. Eventually the Gothic language died as a result of contact with other European people during the Middle Ages.
Long struggles between the neighboring Vandili and Lugii people with the Goths may have contributed to their earlier exodus into mainland Europe. The vast majority of them settled between the Oder and Vistula rivers until overpopulation (according to Gothic legends) forced them to move south and east, where they settled just north of the Black Sea. Unfortunately this legend is not supported by archaeological evidence so its validity is disputable. Historian Malcolm Todd contends that while this large "en masse" migration is possible, the movement of Gothic peoples south-east was more likely the result of warrior bands moving closer to the wealth of the Ukraine and the cities of the Black Sea coast. Perhaps what is most notable about the Gothic people in this regard was that by the middle of the 3rd century AD, they were "the most formidable military power beyond the lower Danube frontier."
Contact with Rome.
Throughout the 3rd and 4th centuries AD, there were numerous conflicts and exchanges of varying types between the Goths and their neighbors. In AD 238 the Goths invaded across the Danube into the Roman province of Moesia, pillaging and exacting payment through hostage taking. During that same year consequent the war with the Persians in AD 238, Goths also appear in the Roman armies of Gordian III. When subsidies to the Goths were stopped, the Goths organized and in AD 250 joined a major barbarian invasion led by the Germanic king, Kniva. Success on the battlefield against the Romans inspired additional invasions into the northern Balkans and deeper into Asia Minor. Starting in approximately AD 255, the Goths added a new dimension to their attacks by taking to the sea and invading harbors which brought them into conflict with the Greeks as well. When the city of Pityus fell to the Goths in 256, the Goths were further emboldened. Sometime between AD 266–267 the Goths raided Greece but when they attempted to move into the Bosporus straits to attack Byzantium, they were repulsed. Along with other Germanic tribes, they attacked further into Asia Minor, assaulting Crete and Cyprus on the way; shortly thereafter, they pillaged Troy and the temple of Artemis at Ephesus. Throughout the reign of emperor Constantine I, the Visigoths continued to conduct raids on Roman territory south of the Danube River. By AD 332, relations between the Goths and Romans were stabilized by a treaty but this was not to last.
War with Rome (376–382).
The Goths remained in Dacia until 376, when one of their leaders, Fritigern, appealed to the Roman emperor Valens to be allowed to settle with his people on the south bank of the Danube. Here, they hoped to find refuge from the Huns. Valens permitted this, as he saw in them "a splendid recruiting ground for his army." However, a famine broke out and Rome was unwilling to supply them with either the food they were promised or the land. Generally, the Goths were abused by the Romans who began exchanging food for slaves from among the Goths. Open revolt ensued leading to 6 years of plundering and destruction throughout the Balkans, the death of a Roman Emperor and the destruction of an entire Roman army.
The Battle of Adrianople in 378 was the decisive moment of the war. The Roman forces were slaughtered and the Emperor Valens was killed during the fighting. Precisely how Valens fell remains uncertain but Gothic legend tells of how the emperor was taken to a farmhouse which was set on fire above his head, a tale made more popular by its symbolic representation of a heretical emperor receiving hell's torment. Many of Rome's leading officers and some of their most elite fighting men died during the battle which struck a major blow to Roman prestige and the Empire's military capabilities. Adrianople shocked the Roman world and eventually forced the Romans to negotiate with and settle the tribe within the empire's boundaries, a development with far reaching consequences for the eventual fall of Rome. Fourth-century Roman soldier and historian, Ammianus Marcellinus, ended his chronology of Roman history with this battle.
Despite the severe consequences for Rome, Adrianople was not nearly as productive overall for the Visigoths and their gains were short-lived. Still confined to a small and relatively impoverished province of the Empire, another Roman army was being gathered against them, an army which also had amid its ranks, other disaffected Goths. Intense campaigns against the Visigoths followed their victory at Adrianople for upwards of three years. Approach routes across the Danube provinces were effectively sealed off by concerted Roman efforts and while there was no decisive victory to claim, it was essentially a Roman triumph ending in a treaty in AD 382. The treaty struck with the Goths was to be the first "foedus" on imperial Roman soil. It required these semi-autonomous Germanic tribes to raise troops for the Roman army in exchange for arable land and freedom from Roman legal structures within the Empire.
Reign of Alaric I.
The new emperor, Theodosius I, made peace with the rebels, and this peace held essentially unbroken until Theodosius died in 395. In that year, the Visigoths' most famous king, Alaric I, took the throne. Theodosius was succeeded by his incapable sons: Arcadius in the east and Honorius in the west. In AD 397, Alaric was named commander of the eastern Illyrician prefecture by Arcadius.
Over the next 15 years, an uneasy peace was broken by occasional conflicts between Alaric and the powerful Germanic generals who commanded the Roman armies in the east and west, wielding the real power of the empire. Finally, after the western general Stilicho was executed by Honorius in 408 and the Roman legions massacred the families of 30,000 barbarian soldiers serving in the Roman army, Alaric declared war. After two defeats in Northern Italy and a siege of Rome ended by a negotiated pay-off, Alaric was cheated by another Roman faction. He resolved to cut the city off by capturing its port. On August 24, 410, however, Alaric's troops entered Rome through the Salarian Gate, to plunder its riches in the sack of Rome. While Rome was no longer the official capital of the Western Roman Empire (it had been moved to Ravenna for strategic reasons), its fall severely shook the Empire's foundations. Material resources in hand after taking the western Empire’s capital, Alaric and the Visigoths extracted as much as they could from Italy and then made their way into northern Africa. Unfortunately, Alaric died before reaching Africa and was succeeded by his wife’s brother Ataulf.
Visigothic kingdom.
The Visigothic Kingdom was a Western European power in the 5th to 7th centuries, created in Gaul when the Romans lost their control of the western half of their empire. In response to the invasion of Roman Hispania of 409 by the Vandals, Alans and Suevi, Honorius, the emperor in the West, enlisted the aid of the Visigoths to regain control of the territory. In 418, Honorius rewarded his Visigothic federates by giving them land in Gallia Aquitania on which to settle. This was probably done under "hospitalitas", the rules for billeting army soldiers. The settlement formed the nucleus of the future Visigothic kingdom that would eventually expand across the Pyrenees and onto the Iberian peninsula. That Visigothic settlement proved paramount to Europe's future as had it not been for the Visigothic warriors who fought side-by-side with the Roman troops under general Flavius Aetius, it quite probable that Attila the Hun would have seized control of Gaul and not the Romans.
The Visigoths' second great king, Euric, unified the various quarreling factions among the Visigoths and, in 475, forced the Roman government to grant them full independence. At his death, the Visigoths were the most powerful of the successor states to the Western Roman Empire and were at the very heights of their power.
At this point, the Visigoths were also the dominant power in the Iberian Peninsula, quickly crushing the Alans and forcing the Vandals into north Africa. By 500, the Visigothic Kingdom, centred at Toulouse, controlled Aquitania and Gallia Narbonensis and most of Hispania with the exception of the Suevic kingdom in the northwest and small areas controlled by the Basques and Cantabrians. However, in 507, the Franks under Clovis I defeated the Visigoths in the Vouillé and wrested control of Aquitaine. King Alaric II was killed in battle.
After Alaric's death, Visigothic nobles spirited his heir, the child-king Amalaric, first to Narbonne, which was the last Gothic outpost in Gaul, and further across the Pyrenees into Hispania. The center of Visigothic rule shifted first to Barcelona, then inland and south to Toledo. From 511 to 526, the Visigoths were ruled by Theoderic the Great of the Ostrogoths as "de jure" regent for the young Amalaric.
In 554, Granada and southernmost Hispania Baetica were lost to representatives of the Byzantine Empire (to form the province of Spania) who had been invited in to help settle a Visigothic dynastic struggle, but who stayed on, as a hoped-for spearhead to a "Reconquest" of the far west envisaged by emperor Justinian I.
The last Arian Visigothic king, Liuvigild, conquered most of the northern regions (Cantabria) in 574, the Suevic kingdom in 585, and regained part of the southern areas lost to the Byzantines, which King Suintila reconquered completely in 624. The kingdom survived until 711, when King Roderic (Rodrigo) was killed while opposing an invasion from the south by the Umayyad Muslims in the Battle of Guadalete on July 19. This marked the beginning of the Muslim conquest of Hispania in which most of the peninsula came under Islamic rule by 718.
A Visigothic nobleman, Pelayo, is credited with beginning the Christian "Reconquista" of Iberia in 718, when he defeated the Umayyads in battle and established the Kingdom of Asturias in the northern part of the peninsula. Other Visigoths who refused to adopt the Muslim faith or live under their rule, fled north to the kingdom of the Franks, and Visigoths played key roles in the empire of Charlemagne a few generations later. In the early years of the Emirate of Córdoba, a group of Visigoths who remained under Muslim dominance constituted the personal bodyguard of the Emir, the Al-Haras.
During their long reign in Spain, the Visigoths were responsible for the only new cities founded in Western Europe between the 5th and 8th centuries. It is certain (through contemporary Spanish accounts) that they founded four: Reccopolis, Victoriacum (modern Vitoria-Gasteiz, though perhaps Iruña-Veleia), Luceo, and Olite. There is also a possible fifth city ascribed to them by a later Arabic source: "Baiyara" (perhaps modern Montoro). All of these cities were founded for military purposes and three of them in celebration of victory. Oddly enough, despite that the Visigoths reigned in Spain for upwards of 250 years, there are almost no recognizable remnants of the Gothic language borrowed into Spanish.
Culture.
Law.
The Visigothic Code of Law ("forum judicum"), which had been part of aristocratic oral tradition, was set in writing in the early 7th century— and survives in two separate codices preserved at the Escorial. It goes into more detail than a modern constitution commonly does and reveals a great deal about Visigothic social structure.
One of the greatest contributions of the Visigoths to family law was their protection of the property rights of married women, which was continued by Spanish law and ultimately evolved into the community property system now in force in part of the United States.
Religion.
Prior to the Middle Ages, the Visigoths, as well as other Germanic peoples, followed what is now referred to as Germanic paganism. While the Germanic peoples were slowly converted to Christianity by varying means, many elements of the pre-Christian culture and indigenous beliefs remained firmly in place after the conversion process, particularly in the more rural and distant regions.
The Visigoths, Ostrogoths, and Vandals were Christianized while they were still outside the bounds of the Roman Empire; however, they converted to Arianism rather than to the Nicean ("Catholic") version followed by most Romans, who considered them heretics. The Visigothic leadership maintained its Arianism up until at least the reign of King Liuvigild.
There was a religious gulf between the Visigoths, who had for a long time adhered to Arianism, and their Catholic subjects in Hispania. The Iberian Visigoths continued to be Arians until 589. There were also deep sectarian splits among the Catholic population of the peninsula. The ascetic Priscillian of Avila was martyred by the Catholic usurper Magnus Maximus in 385, who was trying to prove his correct religious credentials against heretics, before the Visigothic period, and the persecution continued in subsequent generations as "Priscillianist" heretics were rooted out. At the very beginning of Leo I's pontificate, in the years 444–447, Turribius, bishop of Astorga in León, sent to Rome a memorandum warning that Priscillianism was by no means dead, reporting that it numbered even bishops among its supporters, and asking the aid of the Roman See. The distance was insurmountable in the 5th century. Nevertheless, Leo intervened, by forwarding a set of propositions that each bishop was required to sign: all did. But if Priscillianist bishops hesitated to be barred from their sees, a passionately concerned segment of Christian communities in Iberia were disaffected from the more orthodox hierarchy and welcomed the tolerant Arian Visigoths. The Visigoths scorned to interfere among Catholics but were interested in decorum and public order.
When the Visigoths took over Spain, Jews constituted a large and very ancient proportion of the population. Many were farmers, but they worked in a wide range of occupations, and were a major component of the urbanized population of the larger towns particularly of eastern Spain. During the period in which the Visigoths adhered to Arianism, the situation of the Jews seems to have remained relatively good. Previous Roman and Byzantine law determined their status, and it already sharply discriminated against them, but royal jurisdiction was in any case quite limited: local lords and populations related to Jews as they saw fit. We read of rabbis being asked by non-Jews to bless their fields, for example. "Some Jews held ranking posts in the government or the army; others were recruited and organized for garrison service; still others continued to hold senatorial rank." In general, then, they were well respected and well treated.
However, this changed with the conversion of King Reccared to Catholicism in 589. Catholic conversion across Visigothic society reduced much of the friction between their people and the native Spanish population. One chief purpose of this conversion was to unify the realm under the Church, and one of the key complaints of the Church had long been that Jews had too much status, prosperity and influence. Local nobles relied on their Jewish and non-Jewish sectors of the population to enhance the local economy and the noble's independent power. Visigothic political structure had traditionally given extensive powers to local nobles (who even elected their kings), so the king was in many ways merely 'the first amongst equals,' and central authority was weak. The status of the Jews therefore impacted both symbolically and politically on local aristocrats. Almost immediately, therefore, King Reccared convened the first Council of Toledo to "regulate" relations between Christians and Jews. The discriminatory laws passed at this Council seem not to have been well nor universally enforced, however, as indicated by several more Councils of Toledo that were held in subsequent years that repeated these laws, and extended their stringency. These entered canon law and became legal precedents in other parts of Europe as well. The culmination of this process occurred under King Sisibut, in 613, with a decree ordering the forced conversion of all Jews in Spain. However, even this apparently achieved only partial success: similar decrees were repeated with increasing irritation and effect by later kings, as central power was consolidated. These laws either decreed the forcible baptism of the Jews or forbade circumcision, Jewish rites and observance of the Sabbath and festivals. Throughout the 7th century, Jews were flogged, executed, had their property confiscated, were subjected to ruinous taxes, forbidden to trade and, at times, dragged to the baptismal font. Many were obliged to accept Christianity but continued privately to observe the Jewish religion and practices. The decree of 613 set off a century of torment for Spanish Jewry, which was only ended by the Muslim conquest.
The political aspects of the imposition of Church power cannot be ignored in these matters. With the conversion of the Visigothic kings to Chalcedonian Christianity, the bishops increased in power, until, at the Fourth Council of Toledo in 633 AD, they took upon themselves the right that the nobles had previously had to select a king from among the royal family. This was the same synod that declared that all Jews must be baptised.
In the eighth through 11th centuries the "muwallad" clan of the Banū Qāsī claimed descent from the Visigothic Count Cassius.

</doc>
<doc id="32533" url="https://en.wikipedia.org/wiki?curid=32533" title="Euclidean vector">
Euclidean vector

In mathematics, physics, and engineering, a Euclidean vector (sometimes called a geometric or spatial vector, or—as here—simply a vector) is a geometric object that has magnitude (or length) and direction and can be added to other vectors according to vector algebra. A Euclidean vector is frequently represented by a line segment with a definite direction, or graphically as an arrow, connecting an "initial point" "A" with a "terminal point" "B", and denoted by formula_1
A vector is what is needed to "carry" the point "A" to the point "B"; the Latin word "vector" means "carrier". It was first used by 18th century astronomers investigating planet rotation around the Sun. The magnitude of the vector is the distance between the two points and the direction refers to the direction of displacement from "A" to "B". Many algebraic operations on real numbers such as addition, subtraction, multiplication, and negation have close analogues for vectors, operations which obey the familiar algebraic laws of commutativity, associativity, and distributivity. These operations and associated laws qualify Euclidean vectors as an example of the more generalized concept of vectors defined simply as elements of a vector space.
Vectors play an important role in physics: velocity and acceleration of a moving object and forces acting on it are all described by vectors. Many other physical quantities can be usefully thought of as vectors. Although most of them do not represent distances (except, for example, position or displacement), their magnitude and direction can be still represented by the length and direction of an arrow. The mathematical representation of a physical vector depends on the coordinate system used to describe it. Other vector-like objects that describe physical quantities and transform in a similar way under changes of the coordinate system include pseudovectors and tensors.
History.
The concept of vector, as we know it today, evolved gradually over a period of more than 200 years. About a dozen people made significant contributions.
Giusto Bellavitis abstracted the basic idea in 1835 when he established the concept of equipollence. Working in a Euclidean plane, he made equipollent any pair of line segments of the same length and orientation. Essentially he realized an equivalence relation on the pairs of points in the plane and thus erected the first space of vectors in the plane.
The term vector was introduced by William Rowan Hamilton as part of his system of quaternions "q" = "s" + "v" where "scalar" s ∈ ℝ and "vector" "v" ∈ ℝ3. Thus Hamilton's vectors are 3-dimensional. Like Bellavitis, Hamilton viewed vectors as representative of classes of equipollent directed segments. As complex numbers use an imaginary unit to complement the real line, Hamilton considered vectors "v" to be the "imaginary part" of quaternions:
Several other mathematicians developed vector-like systems in the middle of the nineteenth century, including Augustin Cauchy, Hermann Grassmann, August Möbius, Comte de Saint-Venant, and Matthew O'Brien. Grassmann's 1840 work "Theorie der Ebbe und Flut" (Theory of the Ebb and Flow) was the first system of spatial analysis similar to today's system and had ideas corresponding to the cross product, scalar product and vector differentiation. Grassmann's work was largely neglected until the 1870s.
Peter Guthrie Tait carried the quaternion standard after Hamilton. His 1867 "Elementary Treatise of Quaternions" included extensive treatment of the nabla or del operator ∇.
In 1878 "Elements of Dynamic" was published by William Kingdon Clifford. Clifford simplified the quaternion study by isolating the dot product and cross product of two vectors from the complete quaternion product. This approach made vector calculations available to engineers and others working in three dimensions and skeptical of the fourth.
Josiah Willard Gibbs, who was exposed to quaternions through James Clerk Maxwell's "Treatise on Electricity and Magnetism", separated off their vector part for independent treatment. The first half of Gibbs's "Elements of Vector Analysis", published in 1881, presents what is essentially the modern system of vector analysis. In 1901 Edwin Bidwell Wilson published "Vector Analysis", adapted from Gibb's lectures, which banished any mention of quaternions in the development of vector calculus.
Overview.
In physics and engineering, a vector is typically regarded as a geometric entity characterized by a magnitude and a direction. It is formally defined as a directed line segment, or arrow, in a Euclidean space. In pure mathematics, a vector is defined more generally as any element of a vector space. In this context, vectors are abstract entities which may or may not be characterized by a magnitude and a direction. This generalized definition implies that the above-mentioned geometric entities are a special kind of vectors, as they are elements of a special kind of vector space called Euclidean space.
This article is about vectors strictly defined as arrows in Euclidean space. When it becomes necessary to distinguish these special vectors from vectors as defined in pure mathematics, they are sometimes referred to as geometric, spatial, or Euclidean vectors.
Being an arrow, a Euclidean vector possesses a definite "initial point" and "terminal point". A vector with fixed initial and terminal point is called a bound vector. When only the magnitude and direction of the vector matter, then the particular initial point is of no importance, and the vector is called a free vector. Thus two arrows formula_2 and formula_3 in space represent the same free vector if they have the same magnitude and direction: that is, they are equivalent if the quadrilateral "ABB′A′" is a parallelogram. If the Euclidean space is equipped with a choice of origin, then a free vector is equivalent to the bound vector of the same magnitude and direction whose initial point is the origin.
The term "vector" also has generalizations to higher dimensions and to more formal approaches with much wider applications.
Examples in one dimension.
Since the physicist's concept of force has a direction and a magnitude, it may be seen as a vector. As an example, consider a rightward force "F" of 15 newtons. If the positive axis is also directed rightward, then "F" is represented by the vector 15 N, and if positive points leftward, then the vector for "F" is −15 N. In either case, the magnitude of the vector is 15 N. Likewise, the vector representation of a displacement Δ"s" of 4 meters to the right would be 4 m or −4 m, and its magnitude would be 4 m regardless.
In physics and engineering.
Vectors are fundamental in the physical sciences. They can be used to represent any quantity that has magnitude, has direction, and which adheres to the rules of vector addition. An example is velocity, the magnitude of which is speed. For example, the velocity "5 meters per second upward" could be represented by the vector (0,5) (in 2 dimensions with the positive "y" axis as 'up'). Another quantity represented by a vector is force, since it has a magnitude and direction and follows the rules of vector addition. Vectors also describe many other physical quantities, such as linear displacement, displacement, linear acceleration, angular acceleration, linear momentum, and angular momentum. Other physical vectors, such as the electric and magnetic field, are represented as a system of vectors at each point of a physical space; that is, a vector field. Examples of quantities that have magnitude and direction but fail to follow the rules of vector addition: Angular displacement and electric current. Consequently, these are not vectors.
In Cartesian space.
In the Cartesian coordinate system, a vector can be represented by identifying the coordinates of its initial and terminal point. For instance, the points "A" = (1,0,0) and "B" = (0,1,0) in space determine the free vector formula_2 pointing from the point "x"=1 on the "x"-axis to the point "y"=1 on the "y"-axis.
Typically in Cartesian coordinates, one considers primarily bound vectors. A bound vector is determined by the coordinates of the terminal point, its initial point always having the coordinates of the origin "O" = (0,0,0). Thus the bound vector represented by (1,0,0) is a vector of unit length pointing from the origin along the positive "x"-axis.
The coordinate representation of vectors allows the algebraic features of vectors to be expressed in a convenient numerical fashion. For example, the sum of the vectors (1,2,3) and (−2,0,4) is the vector
Euclidean and affine vectors.
In the geometrical and physical settings, sometimes it is possible to associate, in a natural way, a "length" or magnitude and a direction to vectors. In turn, the notion of direction is strictly associated with the notion of an "angle" between two vectors. When the length of vectors is defined, it is possible to also define a dot product — a scalar-valued product of two vectors — which gives a convenient algebraic characterization of both length (the square root of the dot product of a vector by itself) and angle (a function of the dot product between any two non-zero vectors). In three dimensions, it is further possible to define a cross product which supplies an algebraic characterization of the area and orientation in space of the parallelogram defined by two vectors (used as sides of the parallelogram).
However, it is not always possible or desirable to define the length of a vector in a natural way. This more general type of spatial vector is the subject of vector spaces (for bound vectors) and affine spaces (for free vectors). An important example is Minkowski space that is important to our understanding of special relativity, where there is a generalization of length that permits non-zero vectors to have zero length. Other physical examples come from thermodynamics, where many of the quantities of interest can be considered vectors in a space with no notion of length or angle.
Generalizations.
In physics, as well as mathematics, a vector is often identified with a tuple of components, or list of numbers, that act as scalar coefficients for a set of basis vectors. When the basis is transformed, for example by rotation or stretching, then the components of any vector in terms of that basis also transform in an opposite sense. The vector itself has not changed, but the basis has, so the components of the vector must change to compensate. The vector is called "covariant" or "contravariant" depending on how the transformation of the vector's components is related to the transformation of the basis. In general, contravariant vectors are "regular vectors" with units of distance (such as a displacement) or distance times some other unit (such as velocity or acceleration); covariant vectors, on the other hand, have units of one-over-distance such as gradient. If you change units (a special case of a change of basis) from meters to millimeters, a scale factor of 1/1000, a displacement of 1 m becomes 1000 mm–a contravariant change in numerical value. In contrast, a gradient of 1 K/m becomes 0.001 K/mm–a covariant change in value. See covariance and contravariance of vectors. Tensors are another type of quantity that behave in this way; a vector is one type of tensor.
In pure mathematics, a vector is any element of a vector space over some field and is often represented as a coordinate vector. The vectors described in this article are a very special case of this general definition because they are contravariant with respect to the ambient space. Contravariance captures the physical intuition behind the idea that a vector has "magnitude and direction".
Representations.
Vectors are usually denoted in lowercase boldface, as a or lowercase italic boldface, as a. (Uppercase letters are typically used to represent matrices.) Other conventions include formula_5 or "a", especially in handwriting. Alternatively, some use a tilde (~) or a wavy underline drawn beneath the symbol, e.g. formula_6, which is a convention for indicating boldface type. If the vector represents a directed distance or displacement from a point "A" to a point "B" (see figure), it can also be denoted as formula_2 or "AB". Especially in literature in German it was common to represent vectors with small fraktur letters as formula_8.
Vectors are usually shown in graphs or other diagrams as arrows (directed line segments), as illustrated in the figure. Here the point "A" is called the "origin", "tail", "base", or "initial point"; point "B" is called the "head", "tip", "endpoint", "terminal point" or "final point". The length of the arrow is proportional to the vector's magnitude, while the direction in which the arrow points indicates the vector's direction.
On a two-dimensional diagram, sometimes a vector perpendicular to the plane of the diagram is desired. These vectors are commonly shown as small circles. A circle with a dot at its centre (Unicode U+2299 ⊙) indicates a vector pointing out of the front of the diagram, toward the viewer. A circle with a cross inscribed in it (Unicode U+2297 ⊗) indicates a vector pointing into and behind the diagram. These can be thought of as viewing the tip of an arrow head on and viewing the flights of an arrow from the back.
In order to calculate with vectors, the graphical representation may be too cumbersome. Vectors in an "n"-dimensional Euclidean space can be represented as coordinate vectors in a Cartesian coordinate system. The endpoint of a vector can be identified with an ordered list of "n" real numbers ("n"-tuple). These numbers are the coordinates of the endpoint of the vector, with respect to a given Cartesian coordinate system, and are typically called the scalar components (or scalar projections) of the vector on the axes of the coordinate system.
As an example in two dimensions (see figure), the vector from the origin "O" = (0,0) to the point "A" = (2,3) is simply written as
The notion that the tail of the vector coincides with the origin is implicit and easily understood. Thus, the more explicit notation formula_10 is usually not deemed necessary and very rarely used.
In "three dimensional" Euclidean space (or ), vectors are identified with triples of scalar components:
This can be generalised to "n-dimensional" Euclidean space (or ).
These numbers are often arranged into a column vector or row vector, particularly when dealing with matrices, as follows:
Another way to represent a vector in "n"-dimensions is to introduce the standard basis vectors. For instance, in three dimensions, there are three of them:
These have the intuitive interpretation as vectors of unit length pointing up the "x", "y", and "z" axis of a Cartesian coordinate system, respectively. In terms of these, any vector a in can be expressed in the form:
or
where a1, a2, a3 are called the vector components (or vector projections) of a on the basis vectors or, equivalently, on the corresponding Cartesian axes "x", "y", and "z" (see figure), while "a"1, "a"2, "a"3 are the respective scalar components (or scalar projections).
In introductory physics textbooks, the standard basis vectors are often instead denoted formula_18 (or formula_19, in which the hat symbol ^ typically denotes unit vectors). In this case, the scalar and vector components are denoted respectively "a"x, "a"y, "a"z, and ax, ay, az (note the difference in boldface). Thus,
The notation e"i" is compatible with the index notation and the summation convention commonly used in higher level mathematics, physics, and engineering.
Decomposition or resolution.
As explained above a vector is often described by a set of vector components that add up to form the given vector. Typically, these components are the projections of the vector on a set of mutually perpendicular reference axes (basis vectors). The vector is said to be "decomposed" or "resolved with respect to" that set.
The decomposition or resolution of a vector into components is not unique, because it depends on the choice of the axes on which the vector is projected.
Moreover, the use of Cartesian unit vectors such as formula_19 as a basis in which to represent a vector is not mandated. Vectors can also be expressed in terms of an arbitrary basis, including the unit vectors of a cylindrical coordinate system (formula_22) or spherical coordinate system (formula_23). The latter two choices are more convenient for solving problems which possess cylindrical or spherical symmetry respectively.
The choice of a basis doesn't affect the properties of a vector or its behaviour under transformations.
A vector can also be broken up with respect to "non-fixed" basis vectors that change their orientation as a function of time or space. For example, a vector in three-dimensional space can be decomposed with respect to two axes, respectively "normal", and "tangent" to a surface (see figure). Moreover, the "radial" and "tangential components" of a vector relate to the "radius of rotation" of an object. The former is parallel to the radius and the latter is orthogonal to it.
In these cases, each of the components may be in turn decomposed with respect to a fixed coordinate system or basis set (e.g., a "global" coordinate system, or inertial reference frame).
Basic properties.
The following section uses the Cartesian coordinate system with basis vectors
and assumes that all vectors have the origin as a common base point. A vector a will be written as
Equality.
Two vectors are said to be equal if they have the same magnitude and direction. Equivalently they will be equal if their coordinates are equal. So two vectors
and
are equal if
Opposite, parallel, and antiparallel vectors.
Two vectors are opposite if they have the same magnitude but opposite direction. So two vectors
and
are opposite if
Two vectors are parallel if they have the same direction but not necessarily the same magnitude, or antiparallel if they have opposite direction but not necessarily the same magnitude.
Addition and subtraction.
Assume now that a and b are not necessarily equal vectors, but that they may have different magnitudes and directions. The sum of a and b is
The addition may be represented graphically by placing the tail of the arrow b at the head of the arrow a, and then drawing an arrow from the tail of a to the head of b. The new arrow drawn represents the vector a + b, as illustrated below:
This addition method is sometimes called the "parallelogram rule" because a and b form the sides of a parallelogram and a + b is one of the diagonals. If a and b are bound vectors that have the same base point, this point will also be the base point of a + b. One can check geometrically that a + b = b + a and (a + b) + c = a + (b + c).
The difference of a and b is
Subtraction of two vectors can be geometrically defined as follows: to subtract b from a, place the tails of a and b at the same point, and then draw an arrow from the head of b to the head of a. This new arrow represents the vector a − b, as illustrated below:
Subtraction of two vectors may also be performed by adding the opposite of the second vector to the first vector, that is, a − b = a + (−b).
Scalar multiplication.
A vector may also be multiplied, or re-"scaled", by a real number "r". In the context of conventional vector algebra, these real numbers are often called scalars (from "scale") to distinguish them from vectors. The operation of multiplying a vector by a scalar is called "scalar multiplication". The resulting vector is
Intuitively, multiplying by a scalar "r" stretches a vector out by a factor of "r". Geometrically, this can be visualized (at least in the case when "r" is an integer) as placing "r" copies of the vector in a line where the endpoint of one vector is the initial point of the next vector.
If "r" is negative, then the vector changes direction: it flips around by an angle of 180°. Two examples ("r" = −1 and "r" = 2) are given below:
Scalar multiplication is distributive over vector addition in the following sense: "r"(a + b) = "r"a + "r"b for all vectors a and b and all scalars "r". One can also show that a − b = a + (−1)b.
Length.
The "length" or "magnitude" or "norm" of the vector a is denoted by ‖a‖ or, less commonly, |a|, which is not to be confused with the absolute value (a scalar "norm").
The length of the vector a can be computed with the Euclidean norm
A "unit vector" is any vector with a length of one; normally unit vectors are used simply to indicate direction. A vector of arbitrary length can be divided by its length to create a unit vector. This is known as "normalizing" a vector. A unit vector is often indicated with a hat as in â.
To normalize a vector , scale the vector by the reciprocal of its length ‖a‖. That is:
The "zero vector" is the vector with length zero. Written out in coordinates, the vector is , and it is commonly denoted formula_37, 0, or simply 0. Unlike any other vector, it has an arbitrary or indeterminate direction, and cannot be normalized (that is, there is no unit vector that is a multiple of the zero vector). The sum of the zero vector with any vector a is a (that is, ).
Dot product.
The "dot product" of two vectors a and b (sometimes called the "inner product", or, since its result is a scalar, the "scalar product") is denoted by a ∙ b and is defined as:
where "θ" is the measure of the angle between a and b (see trigonometric function for an explanation of cosine). Geometrically, this means that a and b are drawn with a common start point and then the length of a is multiplied with the length of that component of b that points in the same direction as a.
The dot product can also be defined as the sum of the products of the components of each vector as
Cross product.
The "cross product" (also called the "vector product" or "outer product") is only meaningful in three or seven dimensions. The cross product differs from the dot product primarily in that the result of the cross product of two vectors is a vector. The cross product, denoted a × b, is a vector perpendicular to both a and b and is defined as
where "θ" is the measure of the angle between a and b, and n is a unit vector perpendicular to both a and b which completes a right-handed system. The right-handedness constraint is necessary because there exist "two" unit vectors that are perpendicular to both a and b, namely, n and (–n).
The cross product a × b is defined so that a, b, and a × b also becomes a right-handed system (but note that a and b are not necessarily orthogonal). This is the right-hand rule.
The length of a × b can be interpreted as the area of the parallelogram having a and b as sides.
The cross product can be written as
For arbitrary choices of spatial orientation (that is, allowing for left-handed as well as right-handed coordinate systems) the cross product of two vectors is a pseudovector instead of a vector (see below).
Scalar triple product.
The "scalar triple product" (also called the "box product" or "mixed triple product") is not really a new operator, but a way of applying the other two multiplication operators to three vectors. The scalar triple product is sometimes denoted by (a b c) and defined as:
It has three primary uses. First, the absolute value of the box product is the volume of the parallelepiped which has edges that are defined by the three vectors. Second, the scalar triple product is zero if and only if the three vectors are linearly dependent, which can be easily proved by considering that in order for the three vectors to not make a volume, they must all lie in the same plane. Third, the box product is positive if and only if the three vectors a, b and c are right-handed.
In components ("with respect to a right-handed orthonormal basis"), if the three vectors are thought of as rows (or columns, but in the same order), the scalar triple product is simply the determinant of the 3-by-3 matrix having the three vectors as rows
The scalar triple product is linear in all three entries and anti-symmetric in the following sense:
Multiple Cartesian bases.
All examples thus far have dealt with vectors expressed in terms of the same basis, namely, e1, e2, e3. However, a vector can be expressed in terms of any number of different bases that are not necessarily aligned with each other, and still remain the same vector. For example, using the vector a from above,
where n1, n2, n3 form another orthonormal basis not aligned with e1, e2, e3. The values of "u", "v", and "w" are such that the resulting vector sum is exactly a.
It is not uncommon to encounter vectors known in terms of different bases (for example, one basis fixed to the Earth and a second basis fixed to a moving vehicle). In order to perform many of the operations defined above, it is necessary to know the vectors in terms of the same basis. One simple way to express a vector known in one basis in terms of another uses column matrices that represent the vector in each basis along with a third matrix containing the information that relates the two bases. For example, in order to find the values of "u", "v", and "w" that define a in the n1, n2, n3 basis, a matrix multiplication may be employed in the form
where each matrix element "c""jk" is the direction cosine relating n"j" to e"k". The term "direction cosine" refers to the cosine of the angle between two unit vectors, which is also equal to their dot product.
By referring collectively to e1, e2, e3 as the "e" basis and to n1, n2, n3 as the "n" basis, the matrix containing all the "c""jk" is known as the "transformation matrix from "e" to "n"", or the "rotation matrix from "e" to "n"" (because it can be imagined as the "rotation" of a vector from one basis to another), or the "direction cosine matrix from "e" to "n"" (because it contains direction cosines).
The properties of a rotation matrix are such that its inverse is equal to its transpose. This means that the "rotation matrix from "e" to "n"" is the transpose of "rotation matrix from "n" to "e"".
By applying several matrix multiplications in succession, any vector can be expressed in any basis so long as the set of direction cosines is known relating the successive bases.
Other dimensions.
With the exception of the cross and triple products, the above formulae generalise to two dimensions and higher dimensions. For example, addition generalises to two dimensions as
and in four dimensions as
The cross product does not readily generalise to other dimensions, though the closely related exterior product does, whose result is a bivector. In two dimensions this is simply a pseudoscalar
A seven-dimensional cross product is similar to the cross product in that its result is a vector orthogonal to the two arguments; there is however no natural way of selecting one of the possible such products.
Physics.
Vectors have many uses in physics and other sciences.
Length and units.
In abstract vector spaces, the length of the arrow depends on a dimensionless scale. If it represents, for example, a force, the "scale" is of physical dimension length/force. Thus there is typically consistency in scale among quantities of the same dimension, but otherwise scale ratios may vary; for example, if "1 newton" and "5 m" are both represented with an arrow of 2 cm, the scales are 1:250 and 1 m:50 N respectively. Equal length of vectors of different dimension has no particular significance unless there is some proportionality constant inherent in the system that the diagram represents. Also length of a unit vector (of dimension length, not length/force, etc.) has no coordinate-system-invariant significance.
Vector-valued functions.
Often in areas of physics and mathematics, a vector evolves in time, meaning that it depends on a time parameter "t". For instance, if r represents the position vector of a particle, then r("t") gives a parametric representation of the trajectory of the particle. Vector-valued functions can be differentiated and integrated by differentiating or integrating the components of the vector, and many of the familiar rules from calculus continue to hold for the derivative and integral of vector-valued functions.
Position, velocity and acceleration.
The position of a point x = ("x"1, "x"2, "x"3) in three-dimensional space can be represented as a position vector whose base point is the origin
The position vector has dimensions of length.
Given two points x = ("x"1, "x"2, "x"3), y = ("y"1, "y"2, "y"3) their displacement is a vector
which specifies the position of "y" relative to "x". The length of this vector gives the straight-line distance from "x" to "y". Displacement has the dimensions of length.
The velocity v of a point or particle is a vector, its length gives the speed. For constant velocity the position at time "t" will be
where x0 is the position at time "t"=0. Velocity is the time derivative of position. Its dimensions are length/time.
Acceleration a of a point is vector which is the time derivative of velocity. Its dimensions are length/time2.
Force, energy, work.
Force is a vector with dimensions of mass×length/time2 and Newton's second law is the scalar multiplication
Work is the dot product of force and displacement
2 : cm, and that of force 5 N : cm. Thus a scale ratio of 2.5 kg : 1 is used for mass. Similarly, if displacement has a scale of 1:1000 and velocity of 0.2 cm : 1 m/s, or equivalently, 2 ms : 1, a scale ratio of 0.5 : s is used for time.
Vectors as directional derivatives.
A vector may also be defined as a "directional derivative": consider a function formula_55 and a curve formula_56. Then the directional derivative of formula_57 is a scalar defined as
where the index formula_59 is summed over the appropriate number of dimensions (for example, from 1 to 3 in 3-dimensional Euclidean space, from 0 to 3 in 4-dimensional spacetime, etc.). Then consider a vector tangent to formula_56:
The directional derivative can be rewritten in differential form (without a given function formula_57) as
Therefore, any directional derivative can be identified with a corresponding vector, and any vector can be identified with a corresponding directional derivative. A vector can therefore be defined precisely as
Vectors, pseudovectors, and transformations.
An alternative characterization of Euclidean vectors, especially in physics, describes them as lists of quantities which behave in a certain way under a coordinate transformation. A "contravariant vector" is required to have components that "transform opposite to the basis" under changes of basis. The vector itself does not change when the basis is transformed; instead, the components of the vector make a change that cancels the change in the basis. In other words, if the reference axes (and the basis derived from it) were rotated in one direction, the component representation of the vector would rotate in the opposite way to generate the same final vector. Similarly, if the reference axes were stretched in one direction, the components of the vector would reduce in an exactly compensating way. Mathematically, if the basis undergoes a transformation described by an invertible matrix "M", so that a coordinate vector x is transformed to , then a contravariant vector v must be similarly transformed via . This important requirement is what distinguishes a contravariant vector from any other triple of physically meaningful quantities. For example, if "v" consists of the "x", "y", and "z"-components of velocity, then "v" is a contravariant vector: if the coordinates of space are stretched, rotated, or twisted, then the components of the velocity transform in the same way. On the other hand, for instance, a triple consisting of the length, width, and height of a rectangular box could make up the three components of an abstract vector, but this vector would not be contravariant, since rotating the box does not change the box's length, width, and height. Examples of contravariant vectors include displacement, velocity, electric field, momentum, force, and acceleration.
In the language of differential geometry, the requirement that the components of a vector transform according to the same matrix of the coordinate transition is equivalent to defining a "contravariant vector" to be a tensor of contravariant rank one. Alternatively, a contravariant vector is defined to be a tangent vector, and the rules for transforming a contravariant vector follow from the chain rule.
Some vectors transform like contravariant vectors, except that when they are reflected through a mirror, they flip "and" gain a minus sign. A transformation that switches right-handedness to left-handedness and vice versa like a mirror does is said to change the "orientation" of space. A vector which gains a minus sign when the orientation of space changes is called a "pseudovector" or an "axial vector". Ordinary vectors are sometimes called "true vectors" or "polar vectors" to distinguish them from pseudovectors. Pseudovectors occur most frequently as the cross product of two ordinary vectors.
One example of a pseudovector is angular velocity. Driving in a car, and looking forward, each of the wheels has an angular velocity vector pointing to the left. If the world is reflected in a mirror which switches the left and right side of the car, the "reflection" of this angular velocity vector points to the right, but the "actual" angular velocity vector of the wheel still points to the left, corresponding to the minus sign. Other examples of pseudovectors include magnetic field, torque, or more generally any cross product of two (true) vectors.
This distinction between vectors and pseudovectors is often ignored, but it becomes important in studying symmetry properties. See parity (physics).

</doc>
<doc id="32534" url="https://en.wikipedia.org/wiki?curid=32534" title="Valhalla">
Valhalla

In Norse mythology, Valhalla (from Old Norse Valhöll "hall of the slain") is a majestic, enormous hall located in Asgard, ruled over by the god Odin. Chosen by Odin, half of those who die in combat travel to Valhalla upon death, led by valkyries, while the other half go to the goddess Freyja's field Fólkvangr. In Valhalla, the dead join the masses of those who have died in combat known as Einherjar, as well as various legendary Germanic heroes and kings, as they prepare to aid Odin during the events of Ragnarök. Before the hall stands the golden tree Glasir, and the hall's ceiling is thatched with golden shields. Various creatures live around Valhalla, such as the stag Eikþyrnir and the goat Heiðrún, both described as standing atop Valhalla and consuming the foliage of the tree Læraðr.
Valhalla is attested in the "Poetic Edda", compiled in the 13th century from earlier traditional sources, the "Prose Edda", written in the 13th century by Snorri Sturluson, "Heimskringla", also written in the 13th century by Snorri Sturluson, and in stanzas of an anonymous 10th century poem commemorating the death of Eric Bloodaxe known as "Eiríksmál" as compiled in "Fagrskinna". Valhalla has inspired various works of art, publication titles, popular culture references, and has become a term synonymous with a martial (or otherwise) hall of the chosen dead.
Attestations.
"Poetic Edda".
Valhalla is referenced at length in the "Poetic Edda" poem "Grímnismál", and "Helgakviða Hundingsbana II", while Valhalla receives lesser direct references in stanza 33 of the "Völuspá", where the god Baldr's death is referred to as the "woe of Valhalla", and in stanzas 1 to 3 of "Hyndluljóð", where the goddess Freyja states her intention of riding to Valhalla with Hyndla, in an effort to help Óttar, as well as in stanzas 6 through 7, where Valhalla is mentioned again during a dispute between the two.
"Grímnismál".
In stanzas 8 to 10 of "Grímnismál", the god Odin (in the guise of "Grímnir") states that Valhalla is located in the realm of Glaðsheimr. Odin describes Valhalla as shining and golden, and that it "rises peacefully" when seen from afar. From Valhalla, every day Odin chooses from those who have died in combat. Valhalla has spear-shafts for rafters, a roof thatched with shields, coats of mail are strewn over its benches, a wolf hangs in front of its west doors, and an eagle hovers above it.
From stanzas 22 to 24, more details are given by Odin about Valhalla: the holy doors of the ancient gate Valgrind stand before Valhalla, Valhalla has five hundred and forty doors that eight hundred men can exit from at once (from which the einherjar will flow forth to engage the wolf Fenrir at Ragnarök). Within Valhalla exists Thor's hall Bilskirnir, and within it exist five hundred and forty rooms, and of all the halls within Valhalla, Odin states that he thinks his son's may be greatest. In stanzas 25 through 26, Odin states that the goat Heiðrún and the hart Eikþyrnir stand on top of Valhalla and graze on the branches of the tree Læraðr. Heiðrún produces vats of mead that liquor cannot be compared to, and from Eikþyrnir's antlers drip liquid into the spring Hvergelmir from which flows forth all waters.
"Helgakviða Hundingsbana II".
In stanza 38 of the poem "Helgakviða Hundingsbana II", the hero Helgi Hundingsbane dies and goes to Valhalla. In stanza 38, Helgi's glory there is described:
Prose follows after this stanza, stating that a burial-mound was made for Helgi, and that when Helgi arrived in Valhalla, he was asked by Odin to manage things with him. In stanza 39, Helgi, now in Valhalla, has his former enemy Hunding—also in Valhalla—do menial tasks; fetching foot-baths for all of the men there, kindling fire, tying dogs, keeping watch of horses, and feeding the pigs before he can get any sleep. In stanzas 40 to 42, Helgi has returned to Midgard from Valhalla with a host of men. An unnamed maid of Sigrún, Helgi's valkyrie wife, sees Helgi and his large host of men riding into the mound. The maid asks if she is experiencing a delusion, if Ragnarök has begun, or if Helgi and his men have been allowed to return.
In the stanzas that follow, Helgi responds that none of these things have occurred, and so Sigrún's maid goes home to Sigrún. The maid tells Sigrún that the burial mound has opened up, and that Sigrún should go to Helgi there, as Helgi has asked her to come and tend his wounds, which have opened up and are bleeding. Sigrún goes into the mound, and finds that Helgi is drenched in gore, his hair is thick with frost. Filled with joy at the reunion, Sigrún kisses him before he can remove his coat of mail, and asks how she can heal him. Sigrún makes a bed there, and the two sleep together in the enclosed burial mound. Helgi awakens, stating that he must "ride along the blood-red roads, to set the pale horse to tread the path of the sky," and return before the rooster Salgófnir crows. Helgi and the host of men ride away, and Sigrún and her servant go back to their house. Sigrún has her maid wait for him by the mound the next night, but when she arrives at dawn, she finds that he has not returned. The prose narrative at the end of the poem relates that Sigrún dies of sadness, but that the two are thought to have been reborn as Helgi Haddingjaskati and the valkyrie Kára.
"Prose Edda".
Valhalla is referenced in the "Prose Edda" books "Gylfaginning" and "Skáldskaparmál".
"Gylfaginning".
Valhalla is first mentioned in chapter 2 of the "Prose Edda" book "Gylfaginning", where it is described partially in euhemerized form. In the chapter, King Gylfi sets out to Asgard in the guise of an old man going by the name of "Gangleri" to find the source of the power of the gods. The narrative states that the Æsir foresaw his arrival and had prepared grand illusions for him, so that when Gangerli enters the fortress, he sees a hall of such a height that he has trouble seeing over it, and notices that the roof of the hall is covered in golden shields, as if they were shingles. Snorri then quotes a stanza by the skald Þjóðólfr of Hvinir (c. 900). As he continues, Gangleri sees a man in the doorway of the hall juggling short swords, and keeping seven in the air at once. Among other things, the man says that the hall belongs to his king, and adds that he can take Gangleri to the king. Gangleri follows him, and the door closes behind him. All around him he sees many living areas, and throngs of people, some of which are playing games, some are drinking, and others are fighting with weapons. Gangleri sees three thrones, and three figures sitting upon them: High sitting on the lowest throne, Just-As-High sitting on the next highest throne, and Third sitting on the highest. The man guiding Gangleri tells him that High is the king of the hall.
In chapter 20, Third states that Odin mans Valhalla with the Einherjar: the dead who fall in battle and become Odin's adopted sons. In chapter 36, High states that valkyries serve drinks and see to the tables in Valhalla, and "Grímnismál" stanzas 40 to 41 are then quoted in reference to this. High continues that the valkyries are sent by Odin to every battle, where they choose who is to die, and determine victory.
In chapter 38, Gangleri says: "You say that all men who have fallen in battle from the beginning of the world are now with Odin in Valhalla. With what does he feed them? I should think the crowd there is large." High responds that this is indeed true, that a huge amount are already in Valhalla, but yet this amount will seem to be too few when "the wolf comes." High describes that there are never too many to feed in Valhalla, for they feast from Sæhrímnir (here described as a boar), and that this beast is cooked every day and is again whole every night. "Grímnismál" stanza 18 is then recounted. Gangleri asks if Odin himself eats the same food as the Einherjar, and High responds that Odin needs nothing to eat—Odin only consumes wine—and he gives his food to his wolves Geri and Freki. "Grímnismál" stanza 19 is then recounted. High additionally states that at sunrise, Odin sends his ravens Huginn and Muninn from Valhalla to fly throughout the entire world, and they return in time for the first meal there.
In chapter 39, Gangleri asks about the food and drinks the Einherjar consume, and asks if only water is available there. High replies that, of course, Valhalla has food and drinks fit for kings and jarls, for the mead consumed in Valhalla is produced from the udders of the goat Heiðrún, who in turn feeds on the leaves of the "famous tree" Læraðr. The goat produces so much mead in a day that it fills a massive vat large enough for all of the Einherjar in Valhalla to satisfy their thirst from it. High further states that the stag Eikþyrnir stands atop Valhalla and chews on the branches of Læraðr. So much moisture drips from his horns that it falls down to the well Hvelgelmir, resulting in numerous rivers.
In chapter 40, Gangleri muses that Valhalla must be quite crowded, to which High responds by stating that Valhalla is massive and remains roomy despite the large amount of inhabitants, and then quotes "Grímnismál" stanza 23. In chapter 41, Gangleri says that Odin seems to be quite a powerful lord, as he controls quite a big army, but he yet wonders how the Einherjar keep themselves busy when they are not drinking. High replies that daily, after they've dressed and put on their war gear, they go out to the courtyard and battle one another in one-on-one combat for sport. Then, when mealtime comes, they ride home to Valhalla and drink. High then quotes "Vafþrúðnismál" stanza 41. In chapter 42, High describes that, "right at the beginning, when the gods were settling" they had established Asgard and then built Valhalla. The death of the god Baldr is recounted in chapter 49, where the mistletoe that is used to kill Baldr is described as growing west of Valhalla.
"Skáldskaparmál".
At the beginning of "Skáldskaparmál", a partially euhemerized account is given of Ægir visiting the gods in Asgard and shimmering swords are brought out and used as their sole source of light as they drink. There, numerous gods feast, they have plenty of strong mead, and the hall has wall-panels covered with attractive shields. This location is confirmed as Valhalla in chapter 33.
In chapter 2, a quote from the anonymous 10th century poem Eiríksmál is provided (see the "Fagrskinna" section below for more detail and another translation from another source):
What sort of dream is that, Odin? I dreamed I rose up before dawn to clear up Val-hall for slain people. I aroused the Einheriar, bade them get up to strew the benches, clean the beer-cups, the valkyries to serve wine for the arrival of a prince.
In chapter 17 of "Skáldskaparmál", the jötunn Hrungnir is in a rage and, while attempting to catch up and attack Odin on his steed Sleipnir, ends up at the doors to Valhalla. There, the Æsir invite him in for a drink. Hrungnir goes in, demands a drink, and becomes drunk and belligerent, stating that he will remove Valhalla and take it to the land of the jötunn, Jötunheimr, among various other things. Eventually, the gods tire of his boasting and invoke Thor, who arrives. Hrungnir states that Thor is under their protection, and subsequently he can't be harmed while in Valhalla. After an exchange of words, Hrungnir challenges Thor to a duel at the location of Griotunagardar, resulting in Hrungnir's death.
In chapter 34, the tree Glasir is stated as located in front of the doors of Valhalla. The tree is described as having foliage of red gold and being the most beautiful tree among both gods and men. A quote from a work by the 9th century skald Bragi Boddason is presented that confirms the description.
"Heimskringla".
Valhalla is mentioned in euhemerized form and as an element of remaining Norse pagan belief in "Heimskringla". In chapter 8 of "Ynglinga saga", the "historical" Odin is described as ordaining burial laws over his country. These laws include that all the dead are to be burned on a pyre on a burial mound with their possessions, and their ashes are to be brought out to sea or buried in the earth. The dead would then arrive in Valhalla with everything that one had on their pyre, and whatever one had hidden in the ground. Valhalla is additionally referenced in the phrase "visiting Odin" in a work by the 10th century skald Þjóðólfr of Hvinir describing that, upon his death, King Vanlandi went to Valhalla.
In chapter 32 of "Hákonar saga Góða", Haakon I of Norway is given a pagan burial, which is described as sending him on his way to Valhalla. Verses from "Hákonarmál" are then quoted in support, themselves containing references to Valhalla.
"Fagrskinna".
In chapter 8 of "Fagrskinna", a prose narrative states that, after the death of her husband Eric Bloodaxe, Gunnhild Mother of Kings had a poem composed about him. The composition is by an anonymous author from the 10th century and is referred to as "Eiríksmál", and describes Eric Bloodaxe and five other kings arriving in Valhalla after their death. The poem begins with comments by Odin (as Old Norse "Óðinn"):
The god Bragi asks where a thundering sound is coming from, and says that the benches of Valhalla are creaking—as if the god Baldr had returned to Valhalla—and that it sounds like the movement of a thousand. Odin responds that Bragi knows well that the sounds are for Eric Bloodaxe, who will soon arrive in Valhalla. Odin tells the heroes Sigmund and Sinfjötli to rise to greet Eric and invite him into the hall, if it is indeed he.
Sigmund asks Odin why he would expect Eric more than any other king, to which Odin responds that Eric has reddened his gore-drenched sword with many other lands. Eric arrives, and Sigmund greets him, tells him that he is welcome to come into the hall, and asks him what other lords he has brought with him to Valhalla. Eric says that with him are five kings, that he will tell them the name of them all, and that he, himself, is the sixth.
Locations.
Multiple places have been named after Valhalla. These include:
Locations named after Valhalla also exist :

</doc>
<doc id="32538" url="https://en.wikipedia.org/wiki?curid=32538" title="Viking Age">
Viking Age

The Viking Age is the period A.D. from late 8th century to mid 11th century in European history, especially Northern European and Scandinavian history, following the Germanic Iron Age. It is the period of history when Scandinavian Norsemen explored Europe by its seas and rivers for trade, raids and conquest. In this period, the Norsemen settled in Norse Greenland, Newfoundland, and present-day Faroe Islands, Iceland, Normandy, Scotland, England, Ukraine, Ireland, Russia, Germany, and Anatolia. Though Viking travellers and colonists were seen at many points in history as brutal raiders, many historical documents suggest that their invasion of other countries was retaliation in response to the encroachment upon tribal lands by Christian missionaries, and perhaps by the Saxon Wars prosecuted by Charlemagne and his kin to the south, or, were motivated by overpopulation, trade inequities, and the lack of viable farmland in their homeland. Information about the Viking Age is drawn largely from what was written about the Vikings by their enemies, and primary sources of archaeology, supplied with secondary sources like the Icelandic Sagas.
Historical considerations.
In England, the beginning of the Viking Age is dated to 8 June 793, when Vikings destroyed the abbey on Lindisfarne, a centre of learning on an island off the northeast coast of England in Northumberland, and famous across the continent. Monks were killed in the abbey, thrown into the sea to drown, or carried away as slaves along with the church treasures, giving rise to the traditional (but unattested) prayer—"A furore Normannorum libera nos, Domine", "From the fury of the Northmen deliver us, Lord."
Three Viking ships had beached in Portland Bay four years earlier (although due to a scribal error the "Anglo-Saxon Chronicle" dates this event to 787 rather than 789), but that incursion may have been a trading expedition that went wrong rather than a piratical raid. Lindisfarne was different. The Viking devastation of Northumbria's Holy Island was reported by the Northumbrian scholar Alcuin of York, who wrote: "Never before in Britain has such a terror appeared".
Vikings were portrayed as uniformly violent and bloodthirsty by their enemies. The chronicles of medieval England portrayed them as rapacious "wolves among sheep".
The first challenges to the many anti-Viking images in Britain emerged in the 17th century. Pioneering scholarly works on the Viking Age reached a small readership in Britain. Archaeologists began to dig up Britain's Viking past. Linguistics traced the Viking-Age origins of rural idioms and proverbs. New dictionaries of the Old Norse language enabled more Victorians to read the Icelandic Sagas.
In Scandinavia, the 17th century Danish scholars Thomas Bartholin and Ole Worm and Swedish scholar Olaus Rudbeck were the first to use runic inscriptions and Icelandic Sagas as primary historical sources. During the Enlightenment and Nordic Renaissance, historians such as the Danish-Norwegian Ludvig Holberg and Swedish Olof von Dalin developed a more "rational" and "pragmatic" approach to historical scholarship.
By the latter half of the 18th century, while the Icelandic Sagas were still used as important historical sources, the Viking Age had again come to be regarded as a barbaric and uncivilized period in the history of the Nordic countries.
Not until the 1890s, during Victoria's reign in Britain, did scholars outside Scandinavia begin to extensively reassess the achievements of the Vikings, recognizing their artistry, technological skills, and seamanship.
Until recently, however, the history of the Viking Age was still largely based on "Icelandic Sagas", the history of the Danes written by Saxo Grammaticus, the Kyivan Rus' "Primary Chronicle" and "The War of the Irish with the Foreigners". Today most scholars take these texts as sources not to be understood literally and are relying more on concrete archaeological findings, numismatics and other direct scientific disciplines and methods.
Historical background.
The Vikings who invaded western and eastern Europe were chiefly pagans from Denmark, Norway and Sweden. They also settled in the Faroe Islands, Ireland, Iceland, Scotland (Caithness, the Hebrides and the Northern Isles), Greenland, and Canada.
Their North Germanic language, Old Norse, became the mother-tongue of present-day Scandinavian languages. By 801, a strong central authority appears to have been established in Jutland, and the Danes were beginning to look beyond their own territory for land, trade and plunder.
In Norway, mountainous terrain and fjords formed strong natural boundaries. Communities there remained independent of each other, unlike the situation in Denmark which is lowland. By 800, some 30 small kingdoms existed in Norway.
The sea was the easiest way of communication between the Norwegian kingdoms and the outside world. It was in the 8th century that Scandinavians began to build ships of war and send them on raiding expeditions to initiate the Viking Age. The North Sea rovers were traders, colonisers and explorers as well as plunderers.
Probable causes of Norse expansion.
Norse society was based on agriculture and trade with other people and placed great emphasis on the concept of honor, both in combat and in the criminal justice system. It was, for example, unfair and wrong to attack an enemy already in a fight with another.
This era coincided with the Medieval Warm Period (800–1300) and stopped with the start of the Little Ice Age (about 1250–1850). The start of the Viking Age, with the sack of Lindisfarne, also coincided with Charlemagne's Saxon Wars, or Christian wars with pagans in Saxony. Historians Rudolf Simek and Bruno Dumézil theorise that the Viking attacks may have been in response to the spread of Christianity among pagan peoples. Professor Rudolf Simek believes that "it is not a coincidence if the early Viking activity occurred during the reign of Charlemagne". Because of the penetration of Christianity in Scandinavia, serious conflict divided Norway for almost a century.
With the means of travel (longships and open water), their desire for goods led Scandinavian traders to explore and develop extensive trading partnerships in new territories. It has been suggested that the Scandinavians suffered from unequal trade practices imposed by Christian advocates and that this eventually led to the breakdown in trade relations and raiding. British merchants who declared openly that they were Christian and would not trade with heathens and infidels (Muslims and the Norse) would get preferred status for availability and pricing of goods through a Christian network of traders. A two-tiered system of pricing existed with both declared and undeclared merchants trading secretly with banned parties. Viking raiding expeditions were separate from and coexisted with regular trading expeditions. A people with the tradition of raiding their neighbours when their honour had been impugned might easily fall to raiding foreign peoples who impugned their honour.
Historians also suggest that the Scandinavian population was too large for the peninsula and there was not enough good farmland for everyone. This led to a hunt for more land. Particularly for the settlement and conquest period that followed the early raids, internal strife in Scandinavia resulted in the progressive centralisation of power into fewer hands. Formerly empowered local lords who did not want to be oppressed by greedy kings emigrated overseas. Iceland became Europe's first modern republic, with an annual assembly of elected officials called the "Althing", though only "goði" (wealthy landowners) had the right to vote there.
Historic overview.
The earliest date given for a Viking raid is 789 AD when, according to the "Anglo-Saxon Chronicle", a group of men from Norway sailed to the Isle of Portland in Dorset although due to a scribal error the "Anglo-Saxon Chronicle" dates this event to 787. There, they were mistaken for merchants by a royal official. They murdered him when he tried to get them to accompany him to the king's manor to pay a trading tax on their goods. The beginning of the Viking Age in the British Isles is, however, often given as 793. It was recorded in the "Anglo-Saxon Chronicle" that the Northmen raided the important island monastery of Lindisfarne (note that the generally accepted date is actually 8 June, not January):
In 794, according to the "Annals of Ulster", there was a serious attack on Lindisfarne's mother-house of Iona, which was followed in 795 by raids upon the northern coast of Ireland. From bases there, the Norsemen attacked Iona again in 802, causing great slaughter amongst the "Céli Dé" Brethren, and burning the abbey to the ground.
The end of the Viking Age is traditionally marked in England by the failed invasion attempted by the Norwegian king Harald III (Haraldr Harðráði), who was defeated by Saxon King Harold Godwinson in 1066 at the Battle of Stamford Bridge; in Ireland, the capture of Dublin by Strongbow and his Hiberno-Norman forces in 1171; and 1263 in Scotland by the defeat of King Hákon Hákonarson at the Battle of Largs by troops loyal to Alexander III. Godwinson was subsequently defeated within a month by another Viking descendant, William, Duke of Normandy (Normandy had been conquered by Vikings (Normans) in 911). Scotland took its present form when it regained territory from the Norse between the 13th and the 15th centuries; the Western Isles and the Isle of Man remained under Scandinavian authority until 1266. Orkney and Shetland belonged to the king of Norway as late as 1469.
In Scandinavia the Viking age is considered to have ended with the establishment of royal authority in the Scandinavian countries and the establishment of Christianity as the dominant religion. The date is usually put somewhere in the early 11th century in all three Scandinavian countries. The end of the Viking-era in Norway is marked by the Battle of Stiklestad in 1030. Although Olafr Haraldsson's (later known as Olav the Holy) army lost the battle, Christianity spread, partly on the strength of rumours of miraculous signs after his death. Norwegians would no longer be called Vikings. In Sweden, the reign of king Olov Skötkonung (appr. 995–1020) is considered to be the transition from the Viking age to the Middle Ages, because he was the first Christian king of the Swedes and he is associated with a growing influence of the church in what is today southwestern and central Sweden.
The clinker-built longships used by the Scandinavians were uniquely suited to both deep and shallow waters. They extended the reach of Norse raiders, traders and settlers along coastlines and along the major river valleys of north-western Europe. Rurik also expanded to the east and in 859 became ruler either by conquest or invitation by local people of the city of Novgorod (which means "new city") on the Volkhov River. His successors moved further, founding the early East Slavic state of Kievan Rus' with the capital in Kiev. This persisted until 1240, when the Mongols invaded Russia.
Other Norse people, particularly those from the area that is now modern-day Sweden and Norway, continued south to the Black Sea and then on to Constantinople. Whenever these Viking ships ran aground in shallow waters, the Vikings would reportedly turn them on their sides and drag them across the shallows into deeper waters. The Eastern connections of these "Varangians" brought Byzantine silk, coins from Samarkand, even a cowrie shell from the Red Sea, to Viking York.
The Kingdom of the Franks under Charlemagne was particularly hard-hit by these raiders, who could sail up the Seine with near impunity. Near the end of Charlemagne's reign (and throughout the reigns of his sons and grandsons), a string of Norse raids began, culminating in a gradual Scandinavian conquest and settlement of the region now known as Normandy.
In 911, French King Charles the Simple was able to make an agreement with the Viking warleader Rollo, a chieftain of disputed Norwegian or Danish origins. Charles gave Rollo the title of duke and granted him and his followers possession of Normandy. In return, Rollo swore fealty to Charles, converted to Christianity, and undertook to defend the northern region of France against the incursions of other Viking groups. Several generations later, the Norman descendants of these Viking settlers not only identified themselves as Norman but carried the Norman language (a Romance language with Germanic influence), and their Norman culture, into England in 1066. With the Norman Conquest, they became the ruling aristocracy of Anglo-Saxon England.
Geography.
There are various theories concerning the causes of the Viking invasions. For people living along the coast, it would seem natural to seek new land by the sea. Another reason was that during this period England, Wales and Ireland, which were divided into many different warring kingdoms, were in internal disarray and became easy prey. The Franks, however, had well-defended coasts and heavily fortified ports and harbours. Pure thirst for adventure may also have been a factor. A reason for the raids is believed by some to be over-population caused by technological advances, such as the use of iron, or a shortage of women due to selective female infanticide. Although another cause could well have been pressure caused by the Frankish expansion to the south of Scandinavia and their subsequent attacks upon the Viking peoples. Another possible contributing factor is that Harald I of Norway ("Harald Fairhair") had united Norway around this time, and the bulk of the Vikings were displaced warriors who had been driven out of his kingdom and who had nowhere to go. Consequently, these Vikings became raiders, in search of subsistence and bases to launch counter-raids against Harald. One theory that has been suggested is that the Vikings would plant crops after the winter and go raiding as soon as the ice melted on the sea, then returned home with their loot, in time to harvest the crops.
One important centre of trade was at Hedeby. Close to the border with the Franks, it was effectively a crossroads between the cultures, until its eventual destruction by the Norwegians in an internecine dispute around 1050. York was the centre of the kingdom of Jórvík from 866, and discoveries there (e.g. a silk cap, a counterfeit of a coin from Samarkand and a cowry shell from the Red Sea or the Persian Gulf) suggest that Scandinavian trade connections in the 10th century reached beyond Byzantium. However, those items could also have been Byzantine imports, and there is no reason to assume that the Varangians travelled significantly beyond Byzantium and the Caspian Sea.
Northwestern Europe.
England.
According to the "Anglo-Saxon Chronicles", Viking raiders struck England in 793 and raided Lindisfarne, the monastery that held Saint Cuthbert’s relics. The raiders killed the monks and captured the valuables. This raid marks the beginning of the "Viking Age of Invasion", made possible by the Viking longship. There was great but sporadic violence from the last decade of the 8th century on England’s northern and eastern shores: Viking raids continued on a small scale across coastal England. While the initial raiding groups were small, it is believed that a great amount of planning was involved. The Norwegians raided during the winter between 840 and 841, rather than the usual summer, having waited on an island off Ireland. In 850 Vikings overwintered for the first time in England, on the island of Thanet, Kent. In 854 a raiding party overwintered a second time, at the Isle of Sheppey in the Thames estuary. In 864 they reverted to Thanet for their winter encampment.
The following year the Great Heathen Army led by the Brothers Ivar the Boneless, Halfdan and Ubba, and also by another Viking Guthrum, arrived in East Anglia. They proceeded to cross England into Northumbria and captured York, establishing the Viking community of Jorvik, where some settled as farmers and craftsmen. Most of the English kingdoms, being in turmoil, could not stand against the Vikings. In 867 Northumbria became the northern kingdom of the coalescing Danelaw, after its conquest by the brothers Halfdan Ragnarsson and Ivar the Boneless, who installed an Englishman, Ecgberht, as a puppet king. By 870 the "Great Summer Army" arrived in England, led by a Viking leader called Bagsecg and his Five Earls. Aided by the Great Heathen Army (which had already overrun much of England from its base in Jorvik), Bagsecg's forces, and Halfdan's forces (through an alliance), the combined Viking forces raided much of England until 871, when they planned an invasion of Wessex. On 8 January 871, Bagsecg was killed at the Battle of Ashdown along with his Earls. As a result, many of the Vikings returned to northern England, where Jorvic had become the centre of the Viking kingdom but Alfred of Wessex managed to keep them out of his country. Alfred and his successors continued to drive back the Viking frontier and take York. A new wave of Norwegian Vikings appeared in England in 947 when Eric Bloodaxe captured York.
In 1003 the Danish King Sweyn Forkbeard started a series of raids against England. This culminated in a full-scale invasion that led to Sweyn being crowned king of England in 1013. Sweyn was also king of Denmark and parts of Norway at this time. The throne of England passed to Edmund Ironside of Wessex after Sweyn's death in 1014. Sweyn's son, Cnut the Great, won the throne of England in 1016 through conquest. When Cnut the Great died in 1035 he was a king of Denmark, England, Norway, and parts of Sweden. Harold Harefoot became king of England after Cnut's death and Viking rule of England ceased.
The Viking presence dwindled until 1066, when the invading Norsemen lost their final battle with the English at Stamford Bridge. Nineteen days later the Normans, themselves descended from Norsemen, invaded England and defeated the weakened English army at the Battle of Hastings.
In 1152, Eystein II of Norway led a plundering raid down the east coast of Britain.
Ireland.
Longphort phase.
Norwegian Vikings and other Scandinavians conducted extensive raids in Ireland. They founded Limerick in 812, then established a settlement near Waterford in 853, invaded Dublin and maintained control until 1169, and founded trading ports in Cork in the 9th century. Predominantly Norwegians, and to a smaller extent other Scandinavians, settled down and intermixed with the Irish. Literature, crafts, and decorative styles in Ireland and Britain reflected West Norse culture. Vikings traded at Irish markets in Dublin and solidified Dublin as an important city. Excavations found imported fabrics from England, Byzantium, Persia and central Asia. Dublin became so crowded by the 11th century that houses were constructed outside the town walls.
The Vikings pillaged monasteries on Ireland's west coast in 795 and then spread out to cover the rest of the coastline. The north and east of the island were most affected. During the first 40 years, the raids were conducted by small, mobile Viking groups. By 830, the groups consisted of large fleets of Viking ships. From 840, the Vikings began establishing permanent bases at the coasts. Dublin was the most significant settlement in the long term. The Irish became accustomed to the Viking presence. In some cases they became allies and married each other.
In 832, a Viking fleet of about 120 invaded kingdoms on Ireland’s northern and eastern coasts. Some believe that the increased number of invaders coincided with Scandinavian leaders' desires to control the profitable raids on the western shores of Ireland. During the mid-830s, raids began to push deeper into Ireland, as opposed to just touching the coasts. Navigable waterways made this deeper penetration possible. After 840, the Vikings had several bases in strategic locations dispersed throughout Ireland.
In 838, a small Viking fleet entered the River Liffey in eastern Ireland. The Vikings set up a base, which the Irish called a longphort. This longphort eventually became Dublin. After this interaction, the Irish experienced Viking forces for about 40 years. The Vikings also established longphorts in Cork, Limerick, Waterford, and Wexford. The Vikings could sail through on the main river and branch off into different areas of the country.
Battle of Clontarf.
One of the last major battles involving Vikings was the Battle of Clontarf on 23 April 1014, in which Vikings fought both for the Irish over-king Brian Boru's army and for the Viking-led army opposing him. Irish and Viking literature depict the Battle of Clontarf as a gathering of this world and the supernatural. For example, witches, goblins, and demons were present. A Viking poem portrays the environment as strongly pagan. Valkyries chanted and decided who would live and die.
Kvenland.
Kvenland, known as "Cwenland", "Kænland" and similar terms in medieval sources, is an ancient name for an area in Scandinavia and Fennoscandia. A contemporary reference to Kvenland is provided in an Old English account written in the 9th century. It utilized the information provided by the Norwegian adventurer and traveler named Ohthere. Kvenland, in that or close to that spelling, is also known from Nordic sources, primarily Icelandic, but also one that was possibly written in the modern-day area of Norway.
All the remaining Nordic sources discussing Kvenland, using that or close to that spelling, date to the 12th and 13th centuries, but some of them – in part at least – are believed to be rewrites of older texts. Other references and possible references to Kvenland by other names and/or spellings are discussed in the main article of Kvenland.
Scotland.
While there are few records, the Vikings are thought to have led their first raids in Scotland on the holy island of Iona in 794, the year following the raid on the other holy island of Lindisfarne, Northumbria.
In 839, a large Norse fleet invaded via the River Tay and River Earn, both of which were highly navigable, and reached into the heart of the Pictish kingdom of Fortriu. They defeated Eogán mac Óengusa, king of the Picts, his brother Bran and the king of the Scots of Dál Riata, Áed mac Boanta, along with many members of the Pictish aristocracy in battle. The sophisticated kingdom that had been built fell apart, as did the Pictish leadership, which had been stable for more than a hundred years since the time of Óengus mac Fergusa (The accession of Cináed mac Ailpín as king of both Picts and Scots can be attributed to the aftermath of this event).
Earldom of Orkney.
By the mid-9th century the Norsemen had settled in Shetland, Orkney (the Nordreys- "Norðreyjar"), the Hebrides and Isle of Man, (the Sudreys- "Súðreyjar" – this survives in the Diocese of Sodor and Man) and parts of mainland Scotland. The Norse settlers were to some extent integrating with the local Gaelic population ("see-Gall Gaidheal") in the Hebrides and Man. These areas were ruled over by local Jarls, originally captains of ships or Hersirs. The Jarl of Orkney and Shetland however, claimed supremacy.
In 875, King Harald Fairhair led a fleet from Norway to Scotland. In his attempt to unite Norway, he found that many of those opposed to his rise to power had taken refuge in the Isles. From here, they were raiding not only foreign lands but were also attacking Norway itself. He organised a fleet and was able to subdue the rebels, and in doing so brought the independent Jarls under his control, many of the rebels having fled to Iceland. He found himself ruling not only Norway, but the Isles, Man and parts of Scotland.
Kings of the Isles.
In 876 the Gall-Gaidheal of Man and the Hebrides rebelled against Harald. A fleet was sent against them led by Ketil Flatnose to regain control. On his success, Ketil was to rule the Sudreys as a vassal of King Harald. His grandson Thorstein the Red and Sigurd the Mighty, Jarl of Orkney invaded Scotland were able to exact tribute from nearly half the kingdom until their deaths in battle. Ketil declared himself King of the Isles. Ketil was eventually outlawed and fearing the bounty on his head fled to Iceland.
The Gall-Gaidheal Kings of the Isles continued to act semi independently, in 973 forming a defensive pact with the Kings of Scotland and Strathclyde. In 1095, the King of Mann and the Isles Godred Crovan was killed by Magnus Barelegs, King of Norway. Magnus and King Edgar of Scotland agreed a treaty. The islands would be controlled by Norway, but mainland territories would go to Scotland. The King of Norway nominally continued to be king of the Isles and Man. However, in 1156, The kingdom was split into two. The Western Isles and Man continued as to be called the "Kingdom of Man and the Isles", but the Inner Hebrides came under the influence of Somerled, a Gaelic speaker, who was styled 'King of the Hebrides'. His kingdom was to develop latterly into the Lordship of the Isles.
In eastern Aberdeenshire the Danes invaded at least as far north as the area near Cruden Bay.
The Jarls of Orkney continued to rule much of Northern Scotland until 1196, when Harald Maddadsson agreed to pay tribute to William the Lion, King of Scots for his territories on the Mainland.
The end of the Viking age "proper" in Scotland is generally considered to be in 1266. In 1263, King Haakon IV of Norway, in retaliation for a Scots expedition to Skye, arrived on the west coast with a fleet from Norway and Orkney. His fleet linked up with those of King Magnus of Man and King Dougal of the Hebrides. After peace talks failed, his forces met with the Scots at Largs, in Ayrshire. The battle proved indecisive, but it did ensure that the Norse were not able to mount a further attack that year. Haakon died overwintering in Orkney, and by 1266, his son Magnus the Law-mender ceded the Kingdom of Man and the Isles, with all territories on mainland Scotland to Alexander III, through the Treaty of Perth.
Orkney and Shetland continued to be ruled as autonomous Jarldoms under Norway until 1468, when King Christian I pledged them as security on the dowry of his daughter, who was betrothed to James III of Scotland. Although attempts were made during the 17th and 18th centuries to redeem Shetland, without success, and Charles II ratifying the pawning in the 1669 Act for annexation of Orkney and Shetland to the Crown, explicitly exempting them from any "dissolution of His Majesty’s lands", they are currently considered as being officially part of the United Kingdom.
Wales.
Wales was not colonised by the Vikings as heavily as eastern England. The Vikings did, however, settle in the south around St. David's, Haverfordwest, and Gower, among other places. Place names such as Skokholm, Skomer, and Swansea remain as evidence of the Norse settlement. The Vikings, however, did not subdue the Welsh mountain kingdoms.
Iceland.
According to Sagas, Iceland was discovered by Naddodd, a Viking from the Faroe Islands, after which it was settled by mostly Norwegians fleeing the oppressive rule of Harald Fairhair (late 9th century). While harsh, the land allowed for a pastoral farming life familiar to the Norse. According to the saga of Erik the Red, when Erik was exiled from Iceland he sailed west and pioneered Greenland.
Greenland.
The Viking Age settlements in Greenland were established in the sheltered fjords of the southern and western coast. They settled in three separate areas along approximately of the western coast. While harsh, the microclimates along some fjords allowed for a pastoral lifestyle similar to that of Iceland, until the climate changed for the worse with the "Little Ice Age" around 1400.
Southern and eastern Europe.
The Varangians or Varyags (Russian, , "Varyagi"; , "Varahi"; Greek: Βάραγγοι, Βαριάγοι, "Varangoi") sometimes referred to as "Variagians" were Scandinavians, often Swedes, who migrated eastwards and southwards through what is now Russia, Belarus and Ukraine mainly in the 9th and 10th centuries. Engaging in trade, piracy and mercenary activities, they roamed the river systems and portages of Gardariki, reaching the Caspian Sea and Constantinople.
Contemporary English publications also use the name "Viking" for early Varangians in some contexts.
The term Varangian remained in usage in the Byzantine Empire until the 13th century, largely disconnected from its Scandinavian roots by then.
Having settled Aldeigja (Ladoga) in the 750s, Scandinavian colonists were probably an element in the early ethnogenesis of the Rus' people, and likely played a role in the formation of the Rus' Khaganate. The Varangians (Varyags, in Old East Slavic) are first mentioned by the Primary Chronicle as having exacted tribute from the Slavic and Finnic tribes in 859. It was the time of rapid expansion of the Vikings in Northern Europe; England began to pay Danegeld in 859, and the Curonians of Grobin faced an invasion by the Swedes at about the same date.
In 862, the Finnic and Slavic tribes rebelled against the Varangian Rus, driving them overseas back to Scandinavia, but soon started to conflict with each other. The disorder prompted the tribes to invite back the Varangian Rus "to come and rule them" and bring peace to the region. This was a somewhat bilateral relation with the Varagians defending the cities that they ruled. Led by Rurik and his brothers Truvor and Sineus, the invited Varangians (called Rus') settled around the town of Novgorod (Holmgard).
In the 9th century, the Rus' operated the Volga trade route, which connected Northern Russia (Gardariki) with the Middle East (Serkland). As the Volga route declined by the end of the century, the Trade route from the Varangians to the Greeks rapidly overtook it in popularity. Apart from Ladoga and Novgorod, Gnezdovo and Gotland were major centres for Varangian trade.
Western historians tend to agree with the Primary Chronicle that these Scandinavians founded Kievan Rus' in the 880s and gave their name to the land. Many Slavic scholars are opposed to this theory of Germanic influence on the Rus' and have suggested alternative scenarios for this part of Eastern European history.
In contrast to the intense Scandinavian influence in Normandy and the British Isles, Varangian culture did not survive to a great extent in the East. Instead, the Varangian ruling classes of the two powerful city-states of Novgorod and Kiev were thoroughly Slavicised by the end of the 10th century. Old Norse was spoken in one district of Novgorod, however, until the 13th century.
Central Europe.
Viking Age Scandinavian settlements were set up along the southern coast of the Baltic Sea, primarily for trade purposes. Their appearance coincides with the settlement and consolidation of the Slavic tribes in the respective areas. Scandinavians had contacts to the Slavs since their very immigration, these first contacts were soon followed by both the construction of Scandinavian emporia and Slavic burghs in their vicinity. The Scandinavian settlements were larger than the early Slavic ones, their craftsmen had a considerably higher productivity, and in contrast to the early Slavs, the Scandinavians were capable of seafaring. Their importance for trade with the Slavic world however was limited to the coastal regions and their hinterlands.
Scandinavian settlements at the Mecklenburgian coast include Reric (Groß Strömkendorf) on the eastern coast of Wismar Bay, and Dierkow (near Rostock). Reric was set up around the year 700, but following later warfare between Obodrites and Danes, the merchants were resettled to Haithabu. Dierkow prospered from the late 8th to the early 9th century.
Scandinavian settlements at the Pomeranian coast include Wolin (on the isle of Wolin), Ralswiek (on the isle of Rügen), Altes Lager Menzlin (at the lower Peene river), and Bardy-Świelubie near modern Kołobrzeg. Menzlin was set up in the mid-8th century. Wolin and Ralswiek began to prosper in the course of the 9th century. A merchants' settlement has also been suggested near Arkona, but no archeological evidence supports this theory. Menzlin and Bardy-Świelubie were vacated in the late 9th century, Ralswiek made it into the new millennium, but at the time when written chronicles reported the site in the 12th century it had lost all its importance. Wolin, thought to be identical with legendary Vineta and semilegendary Jomsborg, base of the Jomsvikings, was destroyed by the Danes in the 12th century.
Scandinavian arrowheads from the 8th and 9th centuries were found between the coast and the lake chains in the Mecklenburgian and Pomeranian hinterlands, pointing at periods of warfare between the Scandinavians and Slavs.
Scandinavian settlements existed along the southeastern Baltic coast in Truso and Kaup (Old Prussia), and in Grobin (Courland, Latvia).
Western Europe.
France.
The French region of Normandy takes its name from the Viking invaders who were called "Normanni", which means ‘men of the North’. Today, "nordmann" (pron. Norman) in the Norwegian language, denotes a Norwegian person.
The first Viking raids began between 790 and 800 along the coasts of western France. They were carried out primarily in the summer, as the Vikings wintered in Scandinavia. Several coastal areas were lost during the reign of Louis the Pious (814–840). But the Vikings took advantage of the quarrels in the royal family caused after the death of Louis the Pious to settle their first colony in the south-west (Gascony) of the kingdom of Francia, which was more or less abandoned by the Frankish kings after their two defeats at Roncevaux. The incursions in 841 caused severe damage to Rouen and Jumièges. The Viking attackers sought to capture the treasures stored at monasteries, easy prey given the monks' lack of defensive capacity. In 845 an expedition up the Seine reached Paris. The presence of Carolingian "deniers" of "ca" 847, found in 1871 among a hoard at Mullaghboden, County Limerick, where coins were neither minted nor normally used in trade, probably represents booty from the raids of 843–6. After 851, Vikings began to stay in the lower Seine valley for the winter. Twice more in the 860s Vikings rowed to Paris, leaving only when they acquired sufficient loot or bribes from the Carolingian rulers.
The Carolingian kings tended to have contradictory politics, which had severe consequences. In 867, Charles the Bald signed the Treaty of Compiègne, by which he agreed to yield the Cotentin Peninsula to the Breton king Salomon, on the condition that Salomon would take an oath of fidelity and fight as an ally against the Vikings. Nevertheless, in 911 the Viking leader Rollo, forced Charles the Simple to sign the Treaty of Saint-Clair-sur-Epte, under which Charles gave Rouen and the area of present-day Upper Normandy to Rollo, establishing the Duchy of Normandy. In exchange, Rollo pledged vassalage to Charles in 940, agreed to be baptised, and vowed to guard the estuaries of the Seine from further Viking attacks, even though the exact opposite was often the case. The Duchy of Normandy also annexed further areas in Northern France, expanding the territory which was originally negotiated.
While many buildings were pillaged, burned, or destroyed by the Viking raids, ecclesiastical sources may have been overly negative as no city was completely destroyed. On the other hand, many monasteries were pillaged and all the abbeys were destroyed. Rollo and his successors brought about rapid recoveries from the raids.
The Scandinavian colonization was principally Norwegian and Danish under Norwegian leadership by Rollo. A few Swedes were present. The merging of the Scandinavian and native elements contributed to the creation of one of the most powerful feudal states of Western Europe. The naval ability of the Normans would allow them to conquer England and southern Italy, and play a key role in the Crusades.
Italy.
In 860, according to an account by the Norman monk Dudo of Saint-Quentin, a Viking fleet, probably under Björn Ironside and Hastein, landed at the Ligurian port of Luni and sacked the city. The Vikings then moved another 60 miles down the Tuscan coast to the mouth of the Arno, sacking Pisa and then, following the river upstream, also the hill-town of Fiesole above Florence; and others victory around the Mediterranean (including in Sicily and North Africa).
Many Anglo-Danish and Varangian mercenaries fought in Southern Italy, including Harald Hardrada and William de Hauteville who conquered parts of Sicily between 1038 and 1040, and Edgar the Ætheling who participated in the Norman conquest of southern Italy. Runestones were raised in Sweden in memory of warriors who died in Langbarðaland (Land of the Lombards), the Old Norse name for southern Italy.
Spain.
After 842, when the Vikings set up a permanent base at the mouth of the Loire river, they could strike as far as northern Spain. They attacked Cadiz in AD 844. In some of their raids they were crushed either by Kingdom of Asturias or Emirate armies. These Vikings were Hispanised in all Christian kingdoms, while they kept their ethnic identity and culture in Al-Andalus.
In 1015, a Viking fleet entered the river Minho and sacked the episcopal city of Tui (Galicia); no new bishop was appointed until 1070.
Portugal.
In 844, many dozens of drakkars appeared in the "Mar da Palha" ("the Sea of Straw", mouth of the Tagus river). After a siege, the Vikings conquered Lisbon (at the time, the city was under Muslim rule and known as Al-Ushbuna). They left after 13 days, following a resistance led by Alah Ibn Hazm and the city's inhabitants.
Another raid was attempted in 966, without success.
North America.
In about 986, the Norwegian Vikings Bjarni Herjólfsson, Leif Ericson and Þórfinnr Karlsefni from Greenland reached North America and attempted to settle the land they called Vinland. They created a small settlement on the northern peninsula of present-day Newfoundland, near "L'Anse aux Meadows". Conflict with indigenous peoples and lack of support from Greenland brought the Vinland colony to an end within a few years. The archaeological remains are now a UNESCO World Heritage Site.
Old Norse influence on the English language.
The long-term linguistic effect of the Viking settlements in England was threefold: over a thousand Old Norse words eventually became part of Standard English; numerous places in the East and North-east of England have Danish names, and many English personal names are of Scandinavian origin. Scandinavian words that entered the English language included "landing, score, beck, fellow, take, busting" and "steersman". The vast majority of loan words did not appear in documents until the early 12th century; these included many modern words which used "sk-" sounds, such as "skirt, sky," and "skin"; other words appearing in written sources at this time included "again, awkward, birth, cake, dregs, fog, freckles, gasp, law, moss, neck, ransack, root, scowl, sister, seat, sly, smile, want, weak" and "window" from Old Norse meaning "wind-eye". Some of the words that came into use are among the most common in English, such as "to go, to come, to sit, to listen, to eat, both, same, get" and "give". The system of personal pronouns was affected, with "they, them" and "their" replacing the earlier forms. Old Norse influenced the verb "to be"; the replacement of "sindon" by "are" is almost certainly Scandinavian in origin, as is the third-person-singular ending "-s" in the present tense of verbs.
There are more than 1,500 Scandinavian place names in England, mainly in Yorkshire and Lincolnshire (within the former boundaries of the "Danelaw"): over 600 end in "-by", the Scandinavian word for "village" — for example "Grimsby, Naseby" and "Whitby"; many others end in "-thorpe" ("farm"), "-thwaite" ("clearing"), and "-toft" ("homestead").
The distribution of family names showing Scandinavian influence is still, as an analysis of names ending in "-son" reveals, concentrated in the north and east, corresponding to areas of former Viking settlement. Early medieval records indicate that over 60% of personal names in Yorkshire and North Lincolnshire showed Scandinavian influence.
Technology.
The Vikings were equipped with the technologically superior longships; for purposes of conducting trade however, another type of ship, the "knarr", wider and deeper in draft, were customarily used. The Vikings were competent sailors, adept in land warfare as well as at sea, and they often struck at accessible and poorly defended targets, usually with near impunity. The effectiveness of these tactics earned Vikings a formidable reputation as raiders and pirates. Chroniclers paid little attention to other aspects of medieval Scandinavian culture. This slant was accentuated by the absence of contemporary primary source documentation from within the Viking Age communities themselves. Little documentary evidence was available until later, when Christian sources began to contribute. As historians and archaeologists have developed more resources to challenge the one-sided descriptions of the chroniclers, a more balanced picture of the Norsemen has become apparent.
The Vikings used their longships to travel vast distances and attain certain tactical advantages in battle. They could perform highly efficient hit-and-run attacks, in which they quickly approached a target, then left as rapidly as possible before a counter-offensive could be launched. Because of the ships' negligible draft, the Vikings could sail in shallow waters, allowing them to invade far inland along rivers. The ships' speed was also prodigious for the time, estimated at a maximum of . The use of the longships ended when technology changed, and ships began to be constructed using saws instead of axes. This led to a lesser quality of ships.
While battles at sea were rare, they would occasionally occur when Viking ships attempted to board European merchant vessels in Scandinavian waters. When larger scale battles ensued, Viking crews would rope together all nearby ships and slowly proceed towards the enemy targets. While advancing, the warriors hurled spears, arrows, and other projectiles at the opponents. When the ships were sufficiently close, melee combat would ensue using axes, swords, and spears until the enemy ship could be easily boarded. The roping technique allowed Viking crews to remain strong in numbers and act as a unit, but this uniformity also created problems. A Viking ship in the line could not retreat or pursue hostiles without breaking the formation and cutting the ropes, which weakened the overall Viking fleet and was a burdensome task to perform in the heat of battle. In general, these tactics enabled Vikings to quickly destroy the meagre opposition posted during raids.
Together with an increasing centralization of government in the Scandinavian countries, the old system of "leidang" — a fleet mobilization system, where every "skipen" (ship community) had to deliver one ship and crew — was discontinued. Changes in shipbuilding in the rest of Europe led to the demise of the longship for military purposes. By the 11th and 12th centuries, European fighting ships were built with raised platforms fore and aft, from which archers could shoot down into the relatively low longships.
The nautical achievements of the Vikings were exceptional. For instance, they made distance tables for sea voyages that were remarkably precise. They have been found to differ only 2–4% from modern satellite measurements, even on such long distances as across the Atlantic Ocean..
The archaeological find known as the Visby lenses from the Swedish island of Gotland may be components of a telescope. It appears to date from long before the invention of the telescope in the 17th century. Recent evidence suggests that the Vikings also made use of an optical compass as a navigation aid, using the light-splitting and polarization-filtering properties of Iceland spar to find the location of the sun when it was not directly visible.
An archaeological find in Sweden consists of a bone fragment fixated with in-operated material; the piece is as yet undated. These bones might be the remains of a trader from the Middle East.
Trade centres.
Some of the most important trading ports founded by the Norse during the period, include both existing and former cities such as Aarhus (Denmark), Ribe (Denmark), Hedeby (Germany), Vineta (Pomerania), Truso (Poland), Bjørgvin (Norway), Kaupang (Norway), Skiringssal (Norway), Birka (Sweden), Bordeaux (France), York (England), Dublin (Ireland) and Aldeigjuborg (Russia).
Settlements outside Scandinavia.
England
Ireland
Isle of Man
Scotland

</doc>
